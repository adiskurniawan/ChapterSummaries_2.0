<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771759740">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li>
<li class="toc-item"><a class="toc-link" href="#Table10">Table 10</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="YJKN_0017_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **VBA Modules — Technical User Guide**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>VBA Modules — Technical User Guide</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Scope</strong><br>This expanded guide documents responsibilities, public APIs, expected workbook objects (sheets/tables), configuration keys, integration points, operational flows, runbook steps, testing matrices, security posture, and troubleshooting for the supplied VBA modules: <strong>modConfig</strong>, <strong>modPQController</strong>, <strong>modPreflight</strong>, <strong>modBatchProcessing</strong>, <strong>modErrorParser</strong>, <strong>modUtilities</strong>, <strong>frmOperatorUI</strong>. It is intended for operators, integrators, and developers who will run, maintain, extend, or integrate the import pipeline. It focuses on deterministic behavior, auditability, safe defaults, minimal-privilege operations, and reproducible outputs. The guide includes conceptual Power Query (PQ) responsibilities and conceptual DAX/reporting guidance tied to configuration and telemetry. The material below expands each section with practical examples, edge-case handling, and prescriptive runbook steps for on-call remediation. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Glossary (expanded)</strong><br>• <strong>ListObject</strong> = Excel Table object (structured table).<br>• <strong>RAW table</strong> = primary imported data table (configured via <code>RAW_TABLE_NAME</code>).<br>• <strong>Preflight</strong> = deterministic row-level validation and normalization producing <code>tblPreflight</code> (or <code>PREFLIGHT_TABLE_NAME</code>).<br>• <strong>Evidence / Archive ledger</strong> = structured record of archives, checksums, and custody metadata stored in <code>BATCHES_TABLE_NAME</code> or evidence ledger.<br>• <strong>JobId</strong> = per-run unique identifier used in logs, archives, telemetry, and manifests to correlate artifacts and audits.<br>• <strong>ConfigHash / CONFIG_HASH</strong> = deterministic fingerprint of canonical config keys (used for golden-parity checks and traceability).<br>• <strong>PQ normalization</strong> = Power Query transformations that perform column-level, set-based canonicalization (trim, replace, parsing attempts) and expose parse success metadata for VBA to consume.<br>• <strong>Golden-parity</strong> = acceptance discipline requiring E2E test parity with canonical outputs for a given <code>CONFIG_HASH</code> and <code>PQ_VERSION</code>. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>High-level goals & constraints</strong><br>1) Determinism and reproducibility: pipeline outputs (CSV rows, artifact checksums, migration manifests) must be reproducible when inputs, config, <code>PQ_VERSION</code>, and <code>SCORING_CONFIG_HASH</code> are unchanged.<br>2) Auditability and chain-of-custody: every significant action emits traceable telemetry (<code>ImportLog</code>) rows with <code>jobId</code>, <code>operatorId</code>, <code>configHash</code>, and <code>correlationId</code> where applicable.<br>3) Safety-first defaults: destructive actions default to safe, non-mutative flows (create_copy). Inline mutative actions require explicit two-person approval and are gated by <code>OVERWRITE_BATCHES = True</code> plus typed confirmations.<br>4) Privacy by design: PII is treated as sensitive; modUtilities and modConfig provide hooks to redact, encrypt, and restrict access. Telemetry avoids raw PII unless evidence retention policy requires it; in such cases evidence is stored encrypted in <code>STAGING_ARCHIVE_FOLDER</code> with restricted ACLs.<br>5) Host-awareness: code avoids platform-specific assumptions when possible, but documents required host capabilities (ADODB.Stream, Windows-only CryptoAPI fallbacks, UNC path reliance for scheduled services). </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Configuration (modConfig keys referenced — complete expanded list)</strong><br>Below is a canonical recommended key set; each key includes semantics, default guidance, and notes about whether changes require CI golden-parity checks.<br>• <code>STAGING_FOLDER</code> (string) — Primary local/UNC path used for temporary artifacts and produced CSVs; must end with separator; must be writable; treat as PII-sensitive location.<br>• <code>STAGING_ARCHIVE_FOLDER</code> (string) — Archive subfolder; default <code>STAGING_FOLDER &amp; &quot;archive\&quot;</code>.<br>• <code>BATCH_SIZE</code> (integer) — rows per batch for <code>CreateBatches</code>; default 500; recommended max for portal stability; changing affects artifact segmentation (CI parity required for significant changes if downstream systems expect particular file sizes).<br>• <code>MAX_PREVIEW_ROWS</code> (integer) — UI-friendly cap for previews; default 1,000; prevents long-running UI enumerations.<br>• <code>RAW_TABLE_NAME</code> (string) — workbook ListObject name for raw input.<br>• <code>PREFLIGHT_TABLE_NAME</code> (string) — ListObject name where preflight writes results; default "tblPreflight".<br>• <code>BATCHES_TABLE_NAME</code> (string) — ledger table for batch metadata; default "tblBatches".<br>• <code>DEFAULT_DATE_FORMAT</code> (string) — canonical format for exports and manifests; recommend ISO <code>yyyy-mm-dd</code>.<br>• <code>USE_UTF8</code> (boolean) — when True, writes CSVs in UTF-8 with BOM unless portal requires otherwise.<br>• <code>OVERWRITE_BATCHES</code> (boolean) — destructive flag; default False. When True, UI must require typed confirmation and approvals recorded in <code>ImportLog</code>.<br>• <code>REFRESH_TIMEOUT_MS</code> (integer) — PQ refresh timeout in ms; default 600000 (10 minutes).<br>• <code>MAX_BATCH_SIZE</code> (integer, optional) — safety ceiling to validate <code>BATCH_SIZE</code> against; e.g., 10000.<br>• <code>UPAH_MAX_THRESHOLD</code> (numeric) — salary sanity threshold for preflight; used to flag outliers.<br>• <code>OUTLIER_MULTIPLIER</code> (numeric) — factor (e.g., 3.0) applied to robust median-based scale measure to detect outliers.<br>• <code>PQ_VERSION</code> (string) — PQ normalization contract version; include in <code>CONFIG_HASH</code> and require golden-parity tests when changed.<br>• <code>SCORING_CONFIG_HASH</code> (string) — fingerprint for scoring config if scoring logic exists; include in <code>CONFIG_HASH</code> if scoring influences outputs.<br>• <code>ARCHIVE_RETENTION_DAYS</code> (integer) — retention policy for automated purge jobs; >= 0.<br>• <code>FEATURE_FLAGS</code> (dictionary) — experimental toggles (e.g., <code>{AllowInlineApply:False}</code>) with governance rules for rollout.<br>• <code>AllowLocalSecrets</code> (boolean) — developer convenience only; default False in production; when True <code>modUtilities.GetSecretFromStore()</code> may fallback to a local <code>Secrets</code> sheet.<br>• <code>UseEncryptedArchive</code> (boolean) — whether to encrypt archived artifacts; actual encryption keys must be fetched from secure store at runtime.<br>• <code>CONFIG_HASH</code> (string) — deterministic fingerprint produced by <code>ComputeConfigHash()</code> covering canonical keys; used in telemetry, telemetry dimensionalization and CI gating. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Required workbook objects (detailed expectations & templates)</strong><br>This section describes exact columns, types, and example rows so operators and integrators can prepare workbook templates that the pipeline expects. For each ListObject the pipeline will validate headers and content types during <code>ValidateConfig()</code> or <code>RunPreflight</code>.<br><strong>ImportLog ListObject</strong> (recommended columns): <code>Timestamp (ISO8601) | JobID | CorrelationID | Action | Severity | Message | PayloadHash | ConfigHash | OperatorId | DetailsRef</code> — ImportLog is the canonical telemetry table for pipeline events; if missing, <code>modUtilities.LogAction</code> will create it (if permitted) or stash logs in <code>STAGING_FOLDER\log_stash\</code> for later ingestion.<br><strong>RAW input table</strong> (name defined by <code>RAW_TABLE_NAME</code>): mandatory headers: <code>OriginalRow (optional integer) | NIK (string) | Nama (string) | TglLahir (string/date) | TglMulai (string/date) | Upah (numeric)</code> — optional but recommended: <code>OriginalIndex | PortalErrorCode | PortalMessage | PQ_Parse_TglLahir | EvidenceRef</code>. Example header row must exactly match config constants or <code>ValidateConfig()</code> will surface <code>IMP_PF_001</code>.<br><strong>tblPreflight / preflight output</strong> (PREFLIGHT_TABLE_NAME): expected columns include <code>RawRowIndex (int) | NIK | Nama | TglLahir_raw | TglLahir_normalized | TglMulai_raw | TglMulai_normalized | Upah_raw | Upah_normalized | Checks (semicolon-delimited tags) | RemediationHint | dupGroupId | preflightStatus (Accepted/Flagged) | ParseAudit (JSON) | EvidenceRef</code> — preflight writes must be atomic to avoid partial viewer states.<br><strong>Batches ledger (BATCHES_TABLE_NAME)</strong>: <code>batchId | jobId | fileName | filePath | fileChecksum | rowCount | firstRowIndex | lastRowIndex | createdTs | status | operatorId | manifestRef | configHash</code> — ledger must be idempotent and support resume semantics (detect existing batch for <code>jobId</code> and validate checksum).<br><strong>PQ_Dependencies</strong>: <code>QueryName | UpstreamQueries</code> — used by <code>modPQController.ExpandDependencies()</code> to compute refresh sets deterministically.<br><strong>Settings table</strong> (optional): two-column <code>Key | Value</code> ListObject used by <code>ReloadConfig()</code> when admins prefer runtime editable settings without VBA edits.<br><strong>Secrets sheet (developer convenience, optional)</strong>: two-column <code>Key | Value</code> only when <code>AllowLocalSecrets=True</code>. This is discouraged in production. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Module-by-module technical breakdown (deep dive)</strong><br><strong>1) modUtilities — core primitives, providers & adapters</strong><br>Purpose and role: modUtilities supplies the small, critical primitives that other modules rely on: atomic file I/O, structured logging, checksum computation, secret retrieval adapters, table helpers, safe table creation, retry/backoff helpers, and provider registration hooks. Its design principle is small, testable functions with well-defined error objects and clear, deterministic fallback chains.<br>Key responsibilities & behavior:<br>• <strong>Structured logging</strong> — <code>LogAction(action, details, Optional severity)</code> writes rows to <code>ImportLog</code> if present, otherwise stashes JSON payloads to <code>STAGING_FOLDER\log_stash\</code>. Each log row includes <code>Timestamp</code>, <code>JobID</code>, <code>ConfigHash</code>, <code>OperatorId</code> and a <code>PayloadHash</code> computed by stable hashing of <code>details</code>. <code>LogAction</code> must never write raw PII to logs; it should accept a <code>redactPII</code> flag and <code>evidenceRef</code> for sensitive material.<br>• <strong>Atomic UTF-8 writes</strong> — <code>WriteUtf8FileAtomic(path, content, Optional UseBom = True)</code> writes to <code>path.tmp</code> using ADODB.Stream (preferred) or a binary fallback, flushes, sets appropriate attributes, then renames via <code>Name</code> to <code>path</code>. On cross-volume rename failure it falls back to copy + delete approach; failure returns structured error <code>IMP_BATCH_001</code> with remediation hints (check disk space, permissions, antivirus).<br>• <strong>Checksum computation</strong> — <code>ComputeFileChecksum(filePath, Optional algorithm=&quot;SHA256&quot;)</code> attempts providers in order: registered provider adapters; host certutil invocation (Windows); pure-VBA SHA256 fallback using streaming buffered reads. Returns a dictionary <code>{success:Boolean, algorithm, hex, errorMessage}</code>. Prefer providers for performance on large files.<br>• <strong>Secret adapters</strong> — <code>GetSecretFromStore(secretName)</code> iterates registered <code>SecretProvider</code> objects (in priority order). Providers must return <code>{ok:Boolean,value,err}</code>. Fallback to local <code>Secrets</code> sheet only if <code>AllowLocalSecrets=True</code>. Do not store secrets in ImportLog; when operator requests diagnostics that require secret names, only log hashed pointers, never raw secrets.<br>• <strong>Table helpers</strong> — <code>EnsureTableExists(sheetName, headers, tableName)</code> creates table idempotently if missing or validates header parity if present; on mismatch returns <code>IMP_PF_001</code> with a diagnostic sample header row for operator remediation. <code>FindListColumnIndex(tbl, columnName)</code> returns <code>-1</code> if not found. All table helpers avoid altering existing user data by default and require an explicit <code>overwrite=True</code> param to make destructive changes.<br>• <strong>Retry/backoff</strong> — <code>Retry(actionFunc, attempts, baseMs)</code> executes <code>actionFunc</code> with exponential backoff and jitter; errors are bubbled after attempts exhausted. Use this for transient IO (file writes), COM interactions, and remote store calls. Ensure total retry time capped for host responsiveness.<br>• <strong>Provider registration</strong> — functions <code>RegisterSecretProvider</code>, <code>RegisterChecksumProvider</code>, <code>RegisterLogSink</code> allow pluggable environment integrations; providers must adhere to minimal interface contracts documented in provider readme.<br>Notes & edge-cases:<br>• ADODB.Stream may not be available on minimal Excel installations or on non-Windows hosts — <code>WriteUtf8FileAtomic</code> contains detection and fallback logic. On Mac, provide binary write fallback and be explicit about cross-host differences in <code>ImportLog</code> telemetry.<br>• Avoid reading entire large files into memory; prefer streaming chunked reads for checksum and copying operations. Implement buffered reads of e.g., 64 KB chunks. <br>• Ensure <code>InitModUtilities()</code> creates staging subfolders with correct ACLs when called from UI by operators. <code>InitModUtilities</code> must be idempotent. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>2) modPreflight — deterministic validation & normalization engine</strong><br>Purpose and contract: modPreflight performs deterministic row-level checks and writes <code>PREFLIGHT_TABLE_NAME</code> with machine-readable tags and human remediation hints. It must be idempotent and run in chunked mode to support large datasets while providing progress telemetry.<br>Expected public API and semantics:<br>• <code>RunPreflight(jobId, operatorId, Optional options)</code> — entrypoint. Returns a dictionary including <code>status</code>, <code>rowsTotal</code>, <code>rowsProcessed</code>, <code>rowsFlagged</code>, <code>duplicateGroups</code>, <code>outlierReport</code>, <code>evidenceRef</code>, <code>configHash</code>, <code>durationMs</code>, and <code>errors[]</code>. Behavior: read <code>RAW_TABLE_NAME</code> DataBodyRange, process rows in chunks (default chunk=1000), call validation functions, build in-memory arrays for output, and use <code>WritePreflightAtomicallyFromArray</code> to swap the preflight table in place. Emit <code>preflight.summary{rowsProcessed, rowsFlagged}</code> to <code>ImportLog</code>.<br>Core checks & deterministic rules (explicit):<br>• <strong>Header validation</strong> — required columns NIK, Nama, TglLahir, TglMulai, Upah. If missing: abort with <code>IMP_PF_001</code> and provide expected header template in error details.<br>• <strong>NIK rules</strong> — presence, numeric-only (digits only after normalization), length == 16 (unless specific business rules allow). Tagging: <code>NIK_EMPTY</code>, <code>NIK_NONNUMERIC</code>, <code>NIK_LEN</code>, <code>NIK_INVALID</code>. NIK normalization: trim, remove punctuation, canonicalize to digits-only. Provide <code>remediationHint</code> when NIK invalid (e.g., "Ensure 16-digit NIK without separators").<br>• <strong>Name normalization</strong> — <code>NormalizeNameText</code> performs Unicode normalization (NFKC), collapse multi-whitespace, remove control characters, apply character whitelist (letters, spaces, hyphen, apostrophe). Tagging: <code>NAME_EMPTY</code>, <code>NAME_LONG (if &gt; MAX_NAME_LEN)</code>, <code>NAME_INVALID_CHARS</code>. Provide <code>Normalized_Nama</code> field and <code>remediationHint</code> like "Remove unexpected characters or reduce length."<br>• <strong>Date parsing & order checks</strong> — <code>NormalizeDateText</code> attempts safe, conservative normalization: replace common separators, strip ordinal suffixes, remove time-of-day, try explicit parse orders when <code>locale</code> is known. Ambiguous dates (e.g., <code>01/02/03</code>) produce <code>TGL_AMBIGUOUS</code> and <code>remediationHint: &quot;Specify ISO date YYYY-MM-DD&quot;</code>. <code>TglLahir</code> future dates produce <code>TGL_INVALID</code>; <code>TglLahir</code> before 1900 produce <code>TGL_OUT_OF_BOUNDS</code>. <code>TglLahir</code> >= <code>TglMulai</code> produces <code>TGL_ORDER</code> (birth must be before employment start). Avoid guessing ambiguous dates — prefer tagging and operator remediation.<br>• <strong>Upah checks</strong> — numeric coercion with safe fallback; <code>UPAH_NONNUMERIC</code>, <code>UPAH_NEGATIVE</code>, <code>UPAH_EXCEEDS_THRESHOLD</code> using <code>UPAH_MAX_THRESHOLD</code> from config. Implement outlier detection via robust median-based scale: compute median and MAD, flag > median + OUTLIER_MULTIPLIER * MAD. Tag outliers as <code>UPAH_OUTLIER</code> but allow operator override if business context justifies it.<br>• <strong>Duplicate detection</strong> — detect duplicates by <code>NIK</code> first, then by composite keys (e.g., NIK+Nama or NIK+TglLahir). For duplicates create <code>dupGroupId</code> and tag rows <code>DUPLICATE_NIK</code>. Provide <code>dupGroupId</code> in preflight output so UI can filter and triage. Allow <code>DUPLICATE_AUTO_ACCEPT_THRESHOLD</code> config to auto-accept duplicates in non-sensitive flows but require review when threshold exceeded.<br>Atomic write & resilience:<br>• Compute preflight results in-memory as 2D arrays or on a temporary sheet <code>tmpPreflight_&lt;jobId&gt;</code>, then call <code>WritePreflightAtomicallyFromArray</code> which creates a new ListObject (or replaces the old one via rename) to avoid partial views. Maintain cell-level schema stability (preserve column order).<br>• For exceptionally large tables (e.g., > 200k rows), support chunked writes where preflight runs produce multiple temporary sheets and merge them into final preflight table in a streaming manner to avoid host out-of-memory. Provide progress telemetry per chunk and an operator Cancel option that produces a partial preflight artifact annotated <code>Cancelled</code> in <code>ImportLog</code> and <code>preflightStatus</code> column. <br>Cancellation and cooperativeness:<br>• <code>RequestCancelPreflight()</code> sets a module-level flag checked at safe checkpoints between chunks or every N rows; when cancellation is detected, gracefully stop, persist partial preflight with <code>preflightStatus = &quot;Cancelled&quot;</code>, and log <code>preflight.cancelled{jobId,processedRows}</code>. Avoid corrupting existing preflight artifacts — maintain atomic swap semantics so either old or new preflight is visible, never an intermediate partially written table. <br>Evidence & audit artifacts:<br>• When preflight runs in regulated mode (<code>evidenceRefRequired=True</code>), write an evidence CSV of input rows and preflight results to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\preflight_evidence.csv</code>, compute SHA256 checksum, and append ledger row via <code>AppendEvidenceLedgerRow</code>. Keep evidence encrypted if <code>UseEncryptedArchive=True</code>. Ensure <code>ImportLog</code> includes <code>evidenceRef</code> for traceability. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>3) modPQController — deterministic PQ orchestration</strong><br>Purpose and contract: orchestrate Power Query (PQ) refreshes robustly with deterministic semantics: targeted refresh, dependency expansion, serialized refreshes, retry/backoff, synchronous and asynchronous APIs, and telemetry. PQ is treated as the canonical column-level normalizer where transformations are expressible in M and foldable to source.<br>Public APIs & semantics:<br>• <code>GetRefreshStatus()</code> — returns <code>{IsRefreshing, QueueLength, ActiveQueries[], LastResult}</code>. Useful for UI health checks.<br>• <code>SetQueuePolicy(policyName)</code> — policies: <code>fifo</code> (default), <code>reject</code> (do not queue, error if active), <code>coalesce</code> (merge similar requests), <code>cancelonnew</code> (cancel existing and run new immediately). Policy must be configurable via <code>FEATURE_FLAGS</code> or settings table.<br>• <code>GetRefreshResult(queryList, Optional timeoutMs = -1)</code> — blocking synchronous function that triggers targeted refresh and polls until completion or timeout. Returns structured result <code>{success, refreshedQueries[], durationMs, errors[]}</code>. Use <code>REFRESH_TIMEOUT_MS</code> default when <code>timeoutMs=-1</code>.<br>• <code>RefreshQueriesAsync(queryList, Optional callbackOrTimeout, Optional timeoutMs)</code> — enqueues refresh job and returns a <code>jobId</code>. If <code>callbackOrTimeout</code> is a string it is treated as an <code>Application.Run</code> callback name invoked with JSON payload on completion. If the host doesn't support <code>Application.OnTime</code> reliably, fallback to cooperative polling via <code>Application.OnTime</code> scheduled ticks.<br>• <code>ProcessQueue()</code> — called repeatedly (e.g., via <code>Application.OnTime</code>) to service queue; executes one job at a time respecting <code>QueuePolicy</code> and <code>IsRefreshing</code> guard. Use module-level mutex <code>IsRefreshing</code> to serialize operations and avoid race conditions. <br>Internal algorithms & reliability:<br>• <strong>Dependency expansion</strong> — <code>ExpandDependencies(queryList)</code> consults <code>PQ_Dependencies</code> table and expands upstream dependencies in deterministic order to ensure queries refresh in dependency order. Avoid <code>ThisWorkbook.RefreshAll</code> unless necessary. <code>WarmDependencyCache</code> precomputes a dependency DAG and caches execution order to avoid repeated graph traversals.<br>• <strong>Refresh polling</strong> — <code>PollConnectionForCompletion(connection, timeoutMs)</code> checks <code>WorkbookConnection.Refreshing</code> or <code>QueryTable.Refreshing</code> with exponential backoff intervals (250ms -> 500ms -> 1s -> 2s -> cap). On long-running server-side queries, consider heartbeat telemetry rows to avoid UI timeouts. Return <code>PQ_ERR_001</code> on sustained timeouts and include query name and last PQ error if available.<br>• <strong>Error capture & retry</strong> — on transient failures (network hiccup, server timeout) attempt one automatic retry after a short backoff (1–2s); subsequent failures are surfaced to caller with structured error codes (<code>PQ_ERR_002</code> for version mismatch, <code>PQ_ERR_003</code> for M expression errors). Do not poll indefinitely; respect <code>REFRESH_TIMEOUT_MS</code> overall cap.<br>• <strong>Callback semantics</strong> — when <code>RefreshQueriesAsync</code> with callback supplied completes, call <code>Application.Run callbackName, JSONpayload</code>. Callback payload includes <code>jobId</code>, <code>refreshedQueries</code>, <code>durationMs</code>, <code>success</code>, and <code>errors[]</code>. Document that callback runs on main thread and should be lightweight.<br>Telemetry and artifacts:<br>• Persist refresh result artifacts to staging via <code>modUtilities.WriteUtf8FileAtomic</code> (e.g., <code>staging\pq_refresh_results\&lt;jobId&gt;.json</code>) for deterministic debugging. Include <code>CONFIG_HASH</code> and <code>PQ_VERSION</code> in payload. Emit <code>pq.refresh.completed</code> or <code>pq.refresh.error</code> rows to <code>ImportLog</code>. <br>Edge cases & host differences:<br>• Excel online and Mac may behave differently; detect host via <code>Application.OperatingSystem</code> and set <code>HostCompatibility</code> flags in <code>GetConfig()</code>. For hosts lacking <code>WorkbookConnection.Refreshing</code>, use <code>QueryTable</code> object polling or fallback to <code>ThisWorkbook.RefreshAll</code> with conservative timeouts. Warn operator with <code>IMP_CFG_008</code> if host lacks required features. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>4) modErrorParser — portal reconciliation & annotation</strong><br>Purpose and contract: robustly parse portal-produced error reports, reconcile error rows to source <code>RAW_TABLE_NAME</code> rows, annotate source rows with portal error details, and produce unmatched/ambiguous artifacts for manual triage. The parser supports multiple portal CSV formats via a registry and uses prioritized matching strategies (OriginalRow index, exact key, composite, fuzzy matching) to map portal rows to source rows deterministically.<br>Public API & behaviors:<br>• <code>ParsePortalErrors(filePath, Optional jobId, Optional matchPolicy)</code> — orchestration entry; returns summary <code>{matchedCount, unmatchedCount, ambiguousCount, archiveRef, errors[]}</code>. On parse success, archive input file to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\</code> and append ledger row via <code>AppendEvidenceLedgerRow</code>. Produce unmatched artifact <code>unmatched_&lt;jobId&gt;.xlsx</code> for manual triage if necessary.<br>• <code>TokenizeCSV(filePath, ByRef parseResult, jobId)</code> — robust CSV tokenizer that preserves quoted newlines and nested quotes; uses <code>Workbooks.OpenText</code> when appropriate to handle local delimiters and qualifiers. Returns header array and row-array of dictionaries mapping header → cell. If tokenizer fails, create <code>UnparsedPortal</code> artifact and return <code>IMP_PORTAL_002</code> with parse diagnostics.<br>• <code>RegisterPortalFormat(formatName, headerPattern, mappingConfig)</code> — allow ad-hoc registration of portal formats; mappingConfig maps portal column names to canonical fields (OriginalRow, NIK, Nama, TglLahir, PortalErrorCode, PortalMessage). Keep registry in <code>PQ_Dependencies</code> or settings sheet for operator-assisted updates.<br>Matching algorithms and priority:<br>1) <strong>OriginalRow</strong> — if portal provides an <code>OriginalRow</code> index, prefer a direct one-to-one mapping to raw row. This is the most deterministic mapping method and should be used whenever available.<br>2) <strong>ExactKey</strong> — match using unique keys like <code>NIK</code> after canonical normalization (trim digits, remove punctuation). This is robust for primary key mappings.<br>3) <strong>CompositeKey</strong> — use composite of <code>NIK</code>+<code>TglLahir</code> or <code>NIK</code>+<code>Nama</code> to disambiguate when single keys are non-unique or missing.<br>4) <strong>Fuzzy matching</strong> — when deterministic matches fail, compute candidate sets prefiltered by token overlap (shared tokens, trigram prefilter) and apply scoring: token set score (shared/union tokens), trigram Jaccard, normalized Levenshtein distance, and signature overlap as tie-breaker. Provide <code>matchPolicy</code> to configure thresholds; default <code>Auto</code> uses conservative thresholds to avoid false matches. If multiple portal rows map to same source row, annotate <code>AMBIGUOUS_MATCH</code> in <code>PortalErrors</code> column and include <code>matchedPortalRows</code> array for triage.<br>Annotation & safe-write rules:<br>• <code>CommitAnnotations(annotations, jobId, archiveRef)</code> writes portal error data into the RAW table's <code>PortalErrors</code> column or creates it if missing. The write is append-only for error history: append new timestamped error entries rather than overwriting previous ones. Each entry includes <code>portalFileRef</code>, <code>portalRowIndex</code>, <code>PortalErrorCode</code>, <code>PortalMessage</code>, and computed <code>matchConfidence</code> score. Preserve previous error history for forensic audits. <br>• When multiple portal rows map to same raw row and confidence ambiguous, write <code>AMBIGUOUS_MATCH</code> and create a <code>unmatched</code> artifact for human triage, do not auto-modify or reject source rows. <br>Archival & chain-of-custody:<br>• Move portal CSV to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal_inbound\&lt;originalFileName&gt;</code> and compute checksum; append ledger row in <code>BATCHES_TABLE_NAME</code> for secure chain-of-custody. If <code>UseEncryptedArchive=True</code>, encrypt file before or during move using runtime-provided key from <code>modUtilities.GetSecretFromStore(&quot;archiveKey&quot;)</code> and log <code>archive.encrypted{method}</code>. <br>Failure modes & mitigation:<br>• If header mismatch detected, return <code>IMP_PORTAL_001</code> with expected header template; create <code>manual_parse</code> artifact for portal support to examine. <br>• If tokenization fails due to unusual quoting or embedded CRLFs, call <code>Workbooks.OpenText</code> with <code>TextQualifier=xlTextQualifierDoubleQuote</code>, <code>FieldInfo</code> settings, and produce <code>UnparsedPortal</code> artifact for manual inspection. <br>• For high-volume portal exports, process in streaming mode and write intermediate <code>unmatched</code> artifacts periodically to avoid host memory exhaustion. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>5) modBatchProcessing — batch creation, CSV contract & ledger</strong><br>Purpose and contract: create upload-ready batch artifacts (CSV/XLSX), compute checksums and ledger rows, and manage idempotency and resume semantics for upload flows. The module should be robust to disk failures and support safe retries and resume-by-jobId behavior.<br>Key behaviors & file contract:<br>• <code>CreateBatches(jobId, operatorId, filters, Optional overwrite=False)</code> — splits validated rows into batches per <code>BATCH_SIZE</code>, calls <code>ExportTableRangeToCSV</code> for each chunk, computes <code>SHA256</code> checksums via <code>modUtilities.ComputeFileChecksum</code>, archives files to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\</code>, and appends ledger rows to <code>BATCHES_TABLE_NAME</code>. Return <code>batches[]</code> containing <code>filePath</code>, <code>checksum</code>, <code>rowCount</code>, and <code>status</code> for each batch.<br>• <strong>CSV format contract</strong>: RFC4180 compliant: header row present, fields enclosed in double quotes, embedded quotes escaped as <code>&quot;&quot;</code>, CRLF line endings for portal compatibility when required, consistent column order. Provide <code>UseBom</code> option if portal requires BOM. Provide <code>LineTerminator</code> config to support <code>\r\n</code> vs <code>\n</code> on different portals. <br>• <strong>Atomic writes</strong> — write to <code>filePath.tmp</code> then <code>Name</code> to <code>filePath</code>. If <code>Name</code> fails due to cross-volume move, fallback to copy + delete pattern with robust integrity checks (verify checksum after copy). On partial write failure, delete temp files and mark batch row <code>Failed</code> with <code>IMP_BATCH_001</code> diagnostic. <br>• <strong>Ledger & idempotency</strong> — <code>AppendBatchRecord</code> inserts ledger rows idempotently: if <code>filePath</code> already exists in ledger, verify checksum matches; if it doesn't, add <code>batch_conflict</code> to ImportLog and mark job for manual triage. For interrupted jobs, detect completed batches via ledger and resume remaining batches. If <code>--recreate</code> requested, mark prior batches <code>Archived</code> and create new batch files with deterministic suffix to avoid name collisions. <br>Security & chain-of-custody:<br>• Every batch file must have <code>fileChecksum</code> (SHA256) recorded. This checksum is used in upload manifests and to verify portal acceptance. When encryption is required, compute checksum post-encryption or record both plaintext and encrypted checksums per policy. Append <code>AppendEvidenceLedgerRow</code> with <code>archivedTs</code> and <code>operatorId</code>. <br>Edge cases & performance:<br>• Disk full: detect via write exceptions; mark batch <code>Failed</code> and report <code>IMP_BATCH_001</code>. Provide remediation tips (free disk space, alternate staging path).<br>• Large batch export: stream rows via ADODB.Stream or buffered writes to avoid memory pressure. For extremely large exports, recommend <code>CreateJobDescriptor</code> to offload to worker process that writes directly to a shared network staging location under service account credentials. <br>• Encoding: prefer UTF-8 BOM for portal compatibility but allow <code>UseUtf8=False</code> fallback to ANSI when required by portal; provide a config path for <code>LineTerminator</code> and <code>QuoteBehavior</code>. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>6) frmOperatorUI — operator controls, human safety gates, & cooperative cancellation</strong><br>Purpose and expectations: the <code>frmOperatorUI</code> UserForm provides a single-pane control to run import steps, surface preflight results, manage PQ refreshes, create batches, parse portal errors, and show telemetry. It must prevent accidental destructive actions via typed confirmations, collect <code>operatorId</code>, and correlate actions to <code>jobId</code> and <code>ImportLog</code> entries. UI must not perform heavy work on the main thread; use cooperative background techniques, <code>Application.OnTime</code>, or spawn worker job descriptors for long-running tasks.<br>UI flows & guarded actions:<br>• <strong>LoadFile / Import</strong> — prompt operator for file or paste into raw table; validate headers immediately using <code>modPreflight.ValidateRequiredHeaders</code>; create <code>jobId = &quot;import-&quot; &amp; Timestamp</code> ; call <code>modUtilities.LogAction(&quot;LoadFile&quot;, ...)</code> with <code>operatorId</code> and <code>jobId</code>.<br>• <strong>RunPreflight</strong> — disable conflicting controls; call <code>modPreflight.RunPreflight</code> but do not block UI thread: implement chunked processing with a progress bar updated via <code>DoEvents</code> or use <code>Application.OnTime</code> ticks to process chunks; on completion show summarized modal with counts and direct link to filtered Preflight sheet for remediation. Provide "Accept All" vs "Open Preflight" options only after approving required thresholds. <br>• <strong>CreateBatches</strong> — show computed batch count and require typed confirmation when <code>OVERWRITE_BATCHES = True</code> (e.g., user types <code>CONFIRM OVERWRITE</code>). Record typed confirmation in <code>ImportLog</code> with <code>operatorId</code> to meet audit requirements. On create, call <code>modBatchProcessing.CreateBatches</code> and show progress. On partial failure present remediation steps. <br>• <strong>ParsePortalErrors</strong> — show file picker; call <code>modErrorParser.ParsePortalErrors</code>; display summary including matched/unmatched counts and link to <code>unmatched</code> artifact for triage. Provide quick action "Open Unmatched Artifact", "Export Filtered Raw Rows", and "Re-upload Selected Rows".<br>Cancellation & cooperative tokens:<br>• UI sets module-level <code>CancelRequested</code> boolean when operator clicks Cancel. Worker functions must check this token at deterministic checkpoints (after each chunk or every 250–500 rows) and abort gracefully with partial results flagged <code>Cancelled</code> in ledger or <code>ImportLog</code>. UI should not forcibly kill host or raise exceptions; instead set cancellation and poll worker completion. <br>Operator metadata & approvals:<br>• Operator identity: <code>GetOperatorId()</code> should prefer authenticated domain identity (e.g., via <code>CreateObject(&quot;WScript.Network&quot;).UserName</code> or Active Directory integration when available) and fallback to <code>Environ(&quot;USERNAME&quot;)</code>. Always include <code>operatorId</code> in <code>ImportLog</code> and ledger rows. <br>• Two-person approvals: for <code>OVERWRITE_BATCHES = True</code> or inline mutative <code>Apply</code> operations, require two separate operator approvals recorded in <code>ImportLog</code> entries <code>ui.approval.request</code> and <code>ui.approval.grant</code> with distinct <code>operatorId</code>s and typed confirmation. Maintain <code>approvalsRef</code> in <code>ApplyDescriptor</code>. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>PQ conceptual design — what belongs in PQ vs VBA</strong><br>High-level guidance to keep PQ and VBA responsibilities clean and minimize maintenance overhead:<br>• <strong>Prefer PQ for</strong>: deterministic, stateless, set-based column-level normalization that is expressible in M and can fold to source (trim whitespace, control-char stripping, case normalization, small lookup table joins for canonical enumerations, basic parse attempts using <code>try ... otherwise null</code>, producing <code>ParseSuccess</code> columns). PQ should preserve raw original values (keep an <code>Original_*</code> column) for evidence.<br>• <strong>Prefer VBA for</strong>: orchestration, streaming operations, file-system interactions, portal-specific packaging, user confirmations, signing artifacts, encryption, evidence ledger management, and complex multi-row logic like duplicate group assignment, chunked preflight writes, and large-file checksum computation.<br>PQ patterns recommended:<br>• Parameterize PQ with a <code>Settings</code> table or named parameters (e.g., <code>SourceLocale</code>, <code>DateOrder</code>) that <code>modConfig</code> can update via <code>ReloadConfig()</code> and the <code>Settings</code> sheet. This keeps PQ queries idempotent and environment-agnostic.<br>• PQ should produce <code>PQ_Normalized_&lt;jobId&gt;</code> with canonical columns and parse success booleans like <code>TglLahir_ParseSuccess</code> and <code>TglMulai_ParseSuccess</code> so VBA can perform deeper deterministic validation or tag ambiguous rows rather than relying on PQ to resolve ambiguity. <br>Golden-parity & test discipline:<br>• Any PQ change that affects normalized values must increment <code>PQ_VERSION</code> and run CI golden-parity tests (<code>CONFIG_HASH</code> updates), comparing canonical output CSVs and checksums. Maintain a <code>pq_migrations/</code> directory with <code>migration_manifest.json</code> entries describing the change, rationale, and approvals. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Conceptual DAX & reporting guidance (for Power BI / operational dashboards)</strong><br>Use telemetry tables and <code>ConfigHash</code> as primary dimensions to support investigations when pipeline behavior or results change.<br>Model design & measures:<br>• <strong>Model tables</strong>: <code>ImportLog</code>, <code>Batches</code>, <code>PreflightReport</code>, <code>Telemetry</code> (if separate). Keep <code>JobID</code> as central dimension for joins and lineage.<br>• <strong>Key measures</strong>: <code>PreflightFailureRate = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0)</code>; <code>DuplicateRate = DIVIDE(SUM(Preflight[DuplicateRows]), SUM(Preflight[RowsProcessed]), 0)</code>; <code>BatchSuccessRate = DIVIDE(CALCULATE(COUNTROWS(Batches), Batches[Status]=&quot;Completed&quot;), COUNTROWS(Batches), 0)</code>; <code>AvgTimeToRemediation</code> = measure computing time between <code>preflight.detectedTs</code> and <code>preflight.resolvedTs</code> aggregated by <code>JobId</code> and <code>Owner</code>.<br>Use <code>ConfigHash</code> dimensionally:<br>• Always include <code>ConfigHash</code> as slicer or filter when analyzing changes in failure rates or artifact checksums across time — this allows quick attribution of key pipeline behavior changes to config or PQ version updates.<br>• Build small "golden parity" tiles that show whether the last E2E run for a given <code>CONFIG_HASH</code> passed golden-file checksum assertions. On release, require that dashboards show green before approval. <br>Materialization & performance:<br>• Incrementally refresh telemetry tables; pre-aggregate daily snapshots for SLO dashboards to avoid re-evaluating huge log tables in real-time. • Use hierarchical retention windows: keep raw <code>ImportLog</code> for X days (per policy) and archive older records to cold storage for forensic retrieval. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Testing matrix & QA (detailed)</strong><br>Unit tests: create test harness sheets and seed them with canonical fixtures:<br>• NIK validation unit cases: valid 16-digit NIKs, invalid characters, leading zeros, empty values. <br>• Date normalization: explicit-locale formats, ambiguous dd/mm vs mm/dd cases, ISO inputs, leading zeros and time-included strings. <br>• CSV encoding: BOM present/absent, embedded quotes, embedded newlines, CRLF vs LF, portal-sample parsing.<br>• Checksum parity: verify <code>ComputeFileChecksum</code> against sample files with known SHA256 values. <br>Integration tests (E2E):<br>• Full pipeline scenario "happy path": import canonical fixture → preflight passes → create batches → produce checksums identical to golden artifacts → upload simulation → parse synthetic portal errors → annotation and re-upload small batch. Verify <code>ImportLog</code>, <code>Batches</code> ledger, and <code>evidenceRef</code> entries.<br>• Negative flows: missing headers, ambiguous dates, duplicate NIKs, disk full mid-batch, permission denied on staging folder, PQ failure due to M expression error, portal CSV with mismatched header. <br>Chaos & resilience testing:<br>• Disk full simulation mid-export: assert no final files are present in staging and batch ledger marked <code>Failed</code>. <br>• Intermittent UNC share: simulate transient failures; ensure <code>AssertStagingFolder()</code> performs bounded retries and logs <code>config.warn</code> before failing with <code>IMP_CFG_001</code>. <br>CI gating:<br>• Any change to <code>PQ_VERSION</code> or to modConfig keys that affect serialized outputs must trigger the canonical fixture suite and golden-file checksum verification. CI must fail the build if checksums change unless <code>migration_manifest.json</code> documents an accepted semantic change and appropriate approvals are attached. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Operational runbook & triage playbook (concise, pragmatic)</strong><br>Common operator tasks and quick remediation guidance:<br>1) <strong>Start a preflight run</strong> — create backup of workbook and raw file in <code>STAGING_FOLDER\backup\&lt;jobId&gt;\</code>; from UI start <code>RunPreflight</code>; monitor <code>ImportLog</code> for <code>preflight.summary</code>; if preflight fails <code>IMP_PF_001</code> inspect header mismatches and correct raw table. <br>2) <strong>Staging folder permission failure (<code>IMP_CFG_001</code>)</strong> — check effective ACLs for operator/service account; attempt manual <code>MkDir</code> from the operator account; if scheduled task uses service account, prefer UNC path with explicit service-account ACL configured; update <code>STAGING_FOLDER</code> in <code>modConfig</code> only after confirmation. <br>3) <strong>Batch write failure (<code>IMP_BATCH_001</code>)</strong> — check free disk space, ensure antivirus/quarantine didn't block writes, confirm file locks; if partial <code>.tmp</code> files present remove them if safe, repair ledger rows and re-run <code>CreateBatches</code> with <code>--recreate</code> after approvals. <br>4) <strong>PQ refresh timeout</strong> — increase <code>REFRESH_TIMEOUT_MS</code> conservatively, examine PQ query folding and server-side workload; if PQ M expression errors present examine <code>PQ_Mapping</code> query, revert to last known-good <code>PQ_VERSION</code> and re-run golden-parity tests. <br>5) <strong>Portal errors unmatched</strong> — produce <code>unmatched_&lt;jobId&gt;.xlsx</code> and forward to portal support with <code>jobId</code> and archived portal CSV checksum; update ledger to record ticket/ref. <br>6) <strong>Evidence requests for audits</strong> — use <code>ImportLog</code> with <code>configHash</code> and <code>jobId</code> to retrieve <code>evidenceRef</code> for preflight artifacts; decrypt archives only under approved processes and with recorded <code>operatorId</code> access. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Security, privacy & compliance (detailed)</strong><br>Policy & implementation guidance:<br>• <strong>Secrets</strong>: do not store secrets in code or in workbook sheets. Always use <code>modUtilities.RegisterSecretProvider</code> to integrate with Windows Credential Manager, Azure Key Vault, or other enterprise secret stores. <code>AllowLocalSecrets</code> only for developer/sandbox use and must be disabled in production.<br>• <strong>PII handling</strong>: redact PII in <code>ImportLog</code> wherever possible; where evidence retention lawfully requires full data, store evidence in <code>STAGING_ARCHIVE_FOLDER</code> with <code>UseEncryptedArchive=True</code> and require key retrieval via <code>modUtilities.GetSecretFromStore(&quot;archiveKey&quot;)</code> at runtime. Record <code>evidenceRef</code> and <code>archivedChecksum</code> in ledger. <br>• <strong>ACLs & network</strong>: prefer UNC paths for scheduled workers; enforce least-privilege ACLs on <code>STAGING_FOLDER</code> and <code>STAGING_ARCHIVE_FOLDER</code>. Document requirements for service accounts and avoid mapped drive letters for scheduled processes. <br>• <strong>Auditability</strong>: every UI action and automation must log <code>ui.action</code> telemetry rows with <code>operatorId</code>, <code>jobId</code>, <code>correlationId</code>, and <code>configHash</code>. Maintain an append-only ledger for batches and evidence rows. <br>• <strong>Encryption & retention</strong>: implement <code>ARCHIVE_RETENTION_DAYS</code> enforced by retention jobs that validate checksums before deletion; for regulated data require archival encryption and documented access controls. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Common issues & troubleshooting (expanded)</strong><br>1) <strong>IMP_PF_001 — missing raw table or header mismatch</strong>: Verify <code>modConfig.RAW_TABLE_NAME</code> equals the ListObject name in the workbook (Review Name Manager). If headers changed, restore header template or update <code>modConfig</code> only after verifying downstream PQ and portal expectations. <br>2) <strong>ADODB.Stream not available</strong>: On older Office or Mac hosts ADODB may be absent; <code>WriteUtf8FileAtomic</code> falls back to binary writes but may produce encoding differences. Recommend Windows desktop Excel for production runs requiring robust UTF-8 BOM control. <br>3) <strong>Checksum computation failures</strong>: If <code>ComputeFileChecksum</code> returns error, check file locks, permissions, or whether certutil is available in PATH. Use <code>modUtilities.RegisterChecksumProvider</code> to plug better providers on the host. <br>4) <strong>PQ refresh timeout</strong>: check <code>REFRESH_TIMEOUT_MS</code>; inspect PQ query folding; avoid <code>RefreshAll</code> if only a subset needed; use <code>modPQController.WarmDependencyCache</code> and targeted refresh calls. <br>5) <strong>Portal CSV unmatched</strong>: verify portal exported header spec; register the portal format via <code>RegisterPortalFormat</code>; if portal changed format request updated sample and update format registry. <br>6) <strong>ImportLog missing</strong>: create <code>ImportLog</code> ListObject with required columns; otherwise modUtilities will stash logs into <code>STAGING_FOLDER\log_stash\</code> — retrieve and re-insert into ImportLog or configure <code>RegisterLogSink</code> to point to alternate telemetry sink. <br>7) <strong>Service account runs failing on mapped drives</strong>: replace mapped drives with UNC paths in config; ensure the service account has explicit write permission and network connectivity. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Diagnostic & debugging commands (Immediate Window & quick checks)</strong><br>Use these short invocations to inspect core functions or replicate behavior in developer consoles:<br>• <code>? Debug.Print CStr(modUtilities.ComputeFileChecksum(&quot;C:\temp\sample.csv&quot;)(&quot;hex&quot;))</code> — compute checksum and print hex (wrap checks).<br>• <code>Debug.Print CStr(modPreflight.RunPreflight(&quot;job-manual-1&quot;,&quot;operator1&quot;)(&quot;status&quot;))</code> — run quick preflight on small sample and return status.<br>• <code>Set res = modPQController.GetRefreshResult(Array(&quot;PQ_Raw&quot;), 600000)</code> then <code>Debug.Print res(&quot;durationMs&quot;)</code> — run targeted PQ refresh and inspect result. <br>• <code>Set p = modErrorParser.ParsePortalErrors(&quot;C:\incoming\portal.csv&quot;,&quot;job-portal-1&quot;)</code> then <code>Debug.Print p(&quot;matchedCount&quot;)</code> — parse portal file and check matched rows. <br>• Inspect stashed logs: <code>Dir STAGING_FOLDER &amp; &quot;\log_stash\&quot;</code> and open JSON files. <br>• For module reflection errors, enable "Trust access to the VBA project object model" in Trust Center. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Example operational sequences (end-to-end narratives)</strong><br>These examples show complete operator flows with telemetry and expected artifacts.<br><strong>Sequence A — Standard import & batch creation</strong>:<br>1) Prepare raw file offline and place in <code>STAGING_FOLDER\incoming\</code> or paste into <code>RAW_TABLE_NAME</code> in workbook. <br>2) On UI click "Start Import" -> <code>jobId = &quot;import-&quot; &amp; Timestamp</code> -> Log <code>ui.action.loadfile</code> -> <code>modPreflight.RunPreflight(jobId, operatorId)</code>. <br>3) Preflight writes <code>PREFLIGHT_TABLE_NAME</code> atomically, <code>ImportLog</code> receives <code>preflight.summary</code>, and <code>evidenceRef</code> created for preflight evidence if required. <br>4) Operator inspects flagged rows via filter in Preflight sheet, resolves issues, re-run <code>RunPreflight</code> until acceptable thresholds are met. <br>5) Operator clicks <code>CreateBatches</code>; UI shows batch count and requires typed confirmation if <code>OVERWRITE_BATCHES=True</code>. <br>6) <code>modBatchProcessing.CreateBatches(jobId, operatorId)</code> writes atomic CSVs to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\</code>, computes SHA256 checksums, and appends ledger rows. <code>ImportLog</code> receives <code>batches.created</code> with <code>configHash</code>. <br>7) Upload to portal per portal SOP and record upload manifest containing checksum list. <br><strong>Sequence B — Portal error reconciliation</strong>:<br>1) Portal returns error CSV; operator downloads to <code>STAGING_FOLDER\incoming\portal.csv</code>. <br>2) <code>modErrorParser.ParsePortalErrors(filePath, jobId)</code> tokenizes and matches; archives portal CSV to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal_inbound\</code> with checksum. <br>3) For matched rows, <code>CommitAnnotations</code> appends structured <code>PortalErrors</code> entries to RAW table with <code>portalFileRef</code> and <code>matchConfidence</code>. For unmatched rows, <code>GenerateUnmatchedArtifactFromResult</code> produces <code>unmatched_&lt;jobId&gt;.xlsx</code> with candidate matches and suggested actions. <br>4) Operator triages unmatched rows, edits RAW table, and repeats small-batch uploads for corrected rows. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Extensibility points (where to plug custom behavior safely)</strong><br>• <strong>Secret providers</strong>: implement <code>GetSecret(secretName)</code> provider and call <code>RegisterSecretProvider(&quot;kv&quot;, providerObject)</code> in <code>ThisWorkbook.Open</code> initialization. Provider must return <code>{ok, value}</code> or <code>{ok=False,err}</code>. <br>• <strong>Checksum providers</strong>: implement <code>ComputeFileChecksum(filePath, algorithm)</code> provider for accelerated hashing (e.g., OS-level APIs) and register via <code>RegisterChecksumProvider</code>. <br>• <strong>Portal format registry</strong>: admins can call <code>RegisterPortalFormat(formatName, headerRegex, mappingConfig)</code> to add automated format detection and mapping for partner portals.<br>• <strong>Log sinks</strong>: attach <code>RegisterLogSink</code> to forward ImportLog rows to remote telemetry systems via HTTP adapter — adapter must be resilient and register via secret provider for credentials. <br>• <strong>Feature flags</strong>: <code>FEATURE_FLAGS</code> may be toggled via <code>ReloadConfig()</code> to enable dark-launch features; use cautious two-person approval when enabling features that affect outputs. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>CI/CD & release gating (operationalized)</strong><br>• <strong>Golden-file gating</strong>: treat <code>CONFIG_HASH</code> and <code>PQ_VERSION</code> changes as high-impact. CI must run canonical fixture suite and verify checksums of produced CSVs and artifact manifests. If checksums differ, require <code>migration_manifest.json</code> with <code>previousConfigHash</code>, <code>newConfigHash</code>, <code>changedKeys</code>, <code>rationale</code>, and sign-off fields. <br>• <strong>Unit & integration test coverage</strong>: include tests for <code>ValidateNIK</code>, <code>NormalizeDateText</code>, <code>ComputeFileChecksum</code>, <code>WriteUtf8FileAtomic</code>, PQ refresh orchestration, and portal format detection. <br>• <strong>Release artifacts</strong>: on successful pipeline test, produce <code>migrationManifest</code> with <code>previousConfigHash</code>, <code>newConfigHash</code>, <code>changedKeys</code>, <code>rationale</code>, <code>approvals</code> and publish along with signed workbook artifact. <br>• <strong>Rollback</strong>: store prior release artifacts and <code>CONFIG_HASH</code>. If regression detected, revert to prior artifact and redeploy. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Maintenance checklist (operational hygiene)</strong><br>1) Ensure <code>ImportLog</code> exists and is being populated daily; rotate logs per retention policy.<br>2) Validate <code>STAGING_FOLDER</code> ACLs monthly for service accounts used by scheduled jobs.<br>3) Run golden-parity smoke tests weekly for labeled <code>PQ_VERSION</code> in production to detect silent dataset drift. <br>4) Maintain <code>PQ_Dependencies</code> table and review dependency graph after PQ edits to ensure refresh correctness. <br>5) Review <code>FEATURE_FLAGS</code> and remove stale flags after stable rollout windows. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Appendix — key error code catalog (extended)</strong><br>• <code>IMP_CFG_001</code> — Staging folder invalid (permission or path).<br>• <code>IMP_CFG_002</code> — Invalid <code>BATCH_SIZE</code> or numeric config out-of-bounds.<br>• <code>IMP_CFG_003</code> — Table name mismatch or missing required ListObject.<br>• <code>IMP_CFG_004</code> — Unsafe staging folder (system root).<br>• <code>IMP_CFG_005</code> — Date format invalid or unparsable default.<br>• <code>IMP_PF_001</code> — Missing required raw table or header mismatch.<br>• <code>IMP_PF_002</code> — NIK invalid (non-numeric/length).<br>• <code>IMP_PF_003</code> — Ambiguous date detected in preflight.<br>• <code>IMP_PF_009</code> — Preflight already running (mutex).<br>• <code>IMP_BATCH_001</code> — File write or atomic write failure (disk/permissions).<br>• <code>IMP_PORTAL_001</code> — Portal CSV header mismatch.<br>• <code>IMP_PORTAL_002</code> — Portal CSV parse failed due to encoding or quoting.<br>• <code>IMP_PQ_002</code> — PQ version mismatch or PQ query error.<br>• <code>IMP_PQ_BUSY</code> — PQ controller busy and <code>QueuePolicy=reject</code>.<br>• <code>IMP_UTIL_001..</code> — Utility-level checksum/file errors.<br>• <code>IMP_SEC_001..</code> — Secret provider errors (e.g., retrieval failure, permission denied). </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Final operational quick reference (compact)</strong><br>1) Validate config: run <code>modConfig.ValidateConfig()</code> and ensure <code>ImportLog</code> shows <code>config.loaded</code> with <code>CONFIG_HASH</code> before running pipeline.<br>2) Ensure <code>STAGING_FOLDER</code> writable: <code>modConfig.AssertStagingFolder()</code>.<br>3) Use <code>modPQController.GetRefreshResult()</code> to refresh targeted PQs and check <code>pq.refresh.completed</code> telemetry.<br>4) Run <code>modPreflight.RunPreflight(jobId, operatorId)</code>; inspect <code>PREFLIGHT_TABLE_NAME</code> and <code>ImportLog</code> entries.<br>5) Create batches with <code>modBatchProcessing.CreateBatches</code> and verify ledger rows in <code>BATCHES_TABLE_NAME</code> (checksums recorded).<br>6) On portal feedback, run <code>modErrorParser.ParsePortalErrors</code> and resolve unmatched artifacts; re-upload corrected rows as small batches. </td></tr><tr><td data-label="VBA Modules — Technical User Guide"> <strong>Closing implementation notes</strong><br>This expanded guide is intended as a practical, operationally-focused manual that describes expected workbook structure, configuration keys, module responsibilities, safe defaults, auditability patterns, and failure-mode guidance. Implement modules to be small, testable, and defensive: prefer provider registration over hard-coded integrations, make writes atomic, always include <code>CONFIG_HASH</code> and <code>jobId</code> in telemetry, and protect destructive behaviors behind typed confirmations and two-person approvals. Keep PQ for stateless, set-based normalizations and VBA for orchestration and file I/O; require CI golden-parity tests when PQ or configuration that affects serialized outputs change. </td></tr></tbody></table></div><div class="row-count">Rows: 25</div></div><div class="table-caption" id="Table2" data-table="YJKN_0017_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **Overview — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Overview — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modConfig — Global configuration & environment constants</strong><br><strong>Purpose & contract:</strong> centralized, authoritative source of configuration values for the import workflow. Responsibilities: declare environment-sensitive constants (e.g., STAGING_FOLDER, BATCH_SIZE, RAW_TABLE_NAME, PREFLIGHT_TABLE_NAME, BATCHES_TABLE_NAME, DEFAULT_DATE_FORMAT, USE_UTF8, OVERWRITE_BATCHES, REFRESH_TIMEOUT_MS, MAX_PREVIEW_ROWS), expose a read-only GetConfig() snapshot for callers, and provide lightweight preflight asserts (e.g., AssertStagingFolder()). This module MUST be the only touchpoint for environment changes; other modules must reference it and never hard-code paths, sizes, or table names.<br><strong>Inputs & outputs:</strong> developer/operator edits the module to change environment values → runtime callers read GetConfig() or module-level constants. Optional output: GetConfig() returns a dictionary-like snapshot {key:value,...} for logging or telemetry.<br><strong>Primary invariants:</strong><br>1) STAGING_FOLDER must end with the path separator and either exist or be creatable by the process; failing creation yields IMP_CFG_001 and recovery hints.<br>2) BATCH_SIZE must be integer > 0 and tuned to portal limits; extreme values (>10000) should be gated by MaxBatchSize validation.<br>3) Table names constants exactly match ListObject names in the workbook — mismatch should fail fast with clear expected header output.<br><strong>Failure modes, diagnostics & recovery:</strong><br>1) Invalid STAGING_FOLDER path or permission denied → log IMP_CFG_001, call AssertStagingFolder() which attempts to MkDir and returns structured error {errorCode:"IMP_CFG_001",desc, remediation}; operator remedy: fix ACLs or choose alternate folder.<br>2) BATCH_SIZE misconfiguration (zero/negative) → validation at startup returns IMP_CFG_002 and disables CreateBatches until fixed.<br>3) Table name mismatch → UI-presented checklist showing expected headers + sample header row; GetConfig() logs the mismatch and aborts pipeline step.<br><strong>Security & governance constraints:</strong><br>• Do not store secrets or API keys in this module. If sensitive credentials are required, call modUtilities.GetSecretFromStore(key) (which reads Windows Credential Manager or secure store) at runtime.<br>• Treat STAGING_FOLDER as potentially sensitive if it will hold PII — enforce ACLs and, where required, an encryption-at-rest policy.<br><strong>Observability & telemetry fields emitted:</strong> config.loaded{configHash,env,loadTs} on workbook open; config.assert.fail{errorCode,detail} when preflight asserts fail.<br><strong>Implementation notes & best practices:</strong><br>• Provide GetConfig() that returns a VBA Scripting.Dictionary or custom Config Type for easier consumption. <br>• Protect edits with code-signing and workbook-level ACL note in developer README. <br><strong>Tests:</strong> config parity tests (alter constant → observe behavioral change), permission simulation (set staging folder readonly → AssertStagingFolder() returns IMP_CFG_001), and table-name mismatch test (rename a table → pipeline fails with expected header list). </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modPQController — Power Query orchestration & refresh policy</strong><br><strong>Purpose & contract:</strong> orchestrate Power Query (PQ) refreshes deterministically and robustly for PQ_Raw, PQ_Preflight, PQ_Mapping and other queries used by the pipeline. Responsibilities: provide synchronous RefreshQueries(queryList) and asynchronous RefreshQueriesAsync(queryList) (with polling), enforce REFRESH_TIMEOUT_MS, serialize concurrent refreshes, capture errors and return structured results {success,refreshedQueries,durationMs,errors[]}.<br><strong>Inputs & outputs:</strong> input: optional query name list or RefreshAll sentinel; output: updated ListObjects and RefreshResult object. Should not mutate data beyond triggering refreshes and writing logs/audits.<br><strong>Invariants & deterministic behavior:</strong><br>1) Refresh operations are idempotent for identical query input within a single job — repeated refreshes should not change previously validated preflight outputs unless source changed.<br>2) Caller must supply REFRESH_TIMEOUT_MS or accept module default. Long-running server-side queries must not block the UI thread; use polling with exponential backoff.<br><strong>Concurrency model & race conditions:</strong><br>1) Serialize concurrent refresh requests with a module-level mutex (e.g., boolean IsRefreshing) and provide a queue with first-in-first-out semantics where necessary.<br>2) If background PQ refresh is enabled, poll WorkbookConnection.Refreshing until False or timeout; implement successive backoff intervals (e.g., 250ms -> 500ms -> 1s -> 2s) capped at REFRESH_TIMEOUT_MS.<br><strong>Failure modes & recovery:</strong><br>1) Query error (type conversion, invalid M expression) → capture QueryName, PQ error text, and ErrorLocation if available; write ImportLog row pq.refresh.error{query,duration,errorText} and return RefreshResult.errors containing structured error codes (e.g., PQ_ERR_001).<br>2) Transient connection or server timeouts → automatic one-time retry after 1–2s backoff, then escalate if still failing; do not retry loops endlessly.<br>3) Partial refresh success (some queries refreshed, others failed) → return partial success and mark dependent downstream steps as blocked in UI.<br><strong>Performance & best-practices:</strong><br>• Prefer targeted query refresh (single query) over ThisWorkbook.RefreshAll when only a subset of tables are affected. <br>• Document PQ dependencies in a lightweight DAG (e.g., PQ_Mapping -> PQ_Preflight -> PQ_Raw) so callers can refresh in dependency order.<br>• For large servers, ensure query folding is preserved and apply server-side filters where possible to reduce data pulled into Excel.<br><strong>Observability & telemetry:</strong> pq.refresh.completed{queriesCount,duration_ms,success} and pq.refresh.error{query,errorCode}. Include jobId in metrics.<br><strong>Tests:</strong> simulate failing PQ queries by injecting invalid dates, verify PQ error bubbles up and is logged; test timeout conditions and cancellation behavior when StopRefresh is invoked from UI. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modPreflight — RunPreflight (row-level validation engine)</strong><br><strong>Purpose & contract:</strong> perform deterministic, idempotent row-level validation of tblRawImport and produce tblPreflight with machine tags and human remediation hints. Must not mutate original raw table beyond optional non-destructive helper columns; must write output atomically to avoid partial views. All checks should be deterministic and reproducible across runs given identical inputs.<br><strong>Core checks & deterministic rule set (explicit list):</strong><br>1) Header validation — required columns present; if missing, abort with IMP_PF_001 and provide expected header template.<br>2) NIK checks — presence, numeric only, length == 16, checksum-like heuristics (optional). Tag: NIK_EMPTY / NIK_NONNUMERIC / NIK_LEN / NIK_INVALID.<br>3) Name checks — non-empty, allowed character whitelist (letters, spaces, hyphens), enforce MAX_NAME_LEN and tag NAME_EMPTY or NAME_LONG when violated.<br>4) Date checks — TglLahir, TglMulai normalized to canonical ISO-like format; parseable; logical ordering (TglLahir < TglMulai); bounding ranges (e.g., TglLahir not in future and not before 1900). Tag TGL_INVALID / TGL_AMBIGUOUS / TGL_ORDER.<br>5) Upah checks — numeric, >= 0, below UPAH_MAX_THRESHOLD; outlier detection flagged if > unitMean * OUTLIER_MULTIPLIER.<br>6) Duplicate detection — duplicate NIKs within dataset flagged with DUPLICATE_NIK and duplicate groups assigned dupGroupId for triage.<br><strong>Implementation invariants & atomicity:</strong><br>1) RunPreflight should compute results in an in-memory structure or temporary sheet, then atomically swap or create PREFLIGHT_TABLE_NAME to avoid partial visibility for other UI components.<br>2) Checks column uses semicolon-delimited machine tags (e.g., NIK_EMPTY;TGL_INVALID) and an optional remediationHint human-friendly column where each hint is terse and PII-free.<br>3) All normalization functions (e.g., NormalizeDateText) are pure (no side-effects) and deterministic; ambiguous conversions must not be automatic — tag AMBIGUOUS_DATE instead of guessing.<br><strong>NormalizeDateText behavior & heuristics:</strong><br>• Conservative normalization: replace common separators (. - ,) with /, strip ordinal suffixes, remove time components when present, and attempt parse with explicit locale orderings when locale is supplied.<br>• If ambiguous (e.g., 01/02/03) and locale not provided, return tag AMBIGUOUS_DATE and add remediationHint recommending specify locale or use ISO(YYYY-MM-DD).<br><strong>Failure modes & recovery:</strong><br>1) Missing mandatory columns → abort with clear error IMP_PF_001 and show expected header template.<br>2) Extremely large tables → fallback to chunked preflight mode (process by row blocks and stream results to temporary sheet) to avoid memory/host timeouts; provide progress telemetry and allow cancellation.<br>3) Unexpected runtime exceptions → capture stack context in ImportLog with pf.exception row and include jobId, correlationId for triage.<br><strong>Observability & telemetry:</strong> emit preflight.summary{rowsProcessed,rowsFlagged,topErrorTypes}, and persist validationReport in evidence store if regulated runs require full mappings.<br><strong>Edge cases, examples & operator guidance:</strong><br>• Example ambiguous date: 03/04/05 → tag AMBIGUOUS_DATE with remediationHint: "Specify locale or provide ISO date."<br>• Example duplicate NIK: two rows sharing same NIK → both tagged DUPLICATE_NIK and dupGroupId assigned; operator should open filtered Preflight view to resolve.<br><strong>Tests:</strong> unit tests per rule, ambiguous date scenarios, duplicate detection sensitivity tests, large table chunked runs with progress verification, and idempotency checks (repeat preflight on same input should produce same tags). </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modBatchProcessing — CreateBatches, ExportTableRangeToCSV, AppendBatchRecord</strong><br><strong>Purpose & contract:</strong> create upload-ready batch files from validated rows, export those batches as RFC4180-compliant CSV (or optional XLSX), and record batch metadata in Batches ledger. Default behavior is idempotent: create uniquely named files; OVERWRITE_BATCHES must be explicit and require typed confirmation in UI.<br><strong>CreateBatches behavioral flow:</strong><br>1) Read RAW_TABLE_NAME DataBodyRange after preflight gating; filter for rows with acceptable Checks status.<br>2) Chunk rows into batch segments by BATCH_SIZE and BatchStrategy (e.g., contiguous ranges vs. evenly distributed by region).<br>3) For each chunk, call ExportTableRangeToCSV(chunkRange, outFile, useUtf8) then AppendBatchRecord(batchMetadata) to Batches ledger. Each batch record contains batchIdx,filePath,rowCount,rowRange,createdTs,status,checksum,jobId.<br><strong>ExportTableRangeToCSV file contract & encoding:</strong><br>1) Output must be RFC4180-compliant: header row, comma-separated fields, values double-quoted, embedded quotes escaped as "", and lines terminated with CRLF when required by portal. <br>2) Encoding: prefer UTF-8 with BOM if portal requires; provide UseUtf8 flag and fallback to ANSI (via Print #) if not available. Use ADODB.Stream to reliably write UTF-8 bytes. <br>3) Atomic write: write to a temp file (e.g., outFile.tmp) then Name to final outFile to avoid partial reads by downstream processes; on failure delete temp file and set batch status Failed with error details in Batches and ImportLog.<br><strong>Checksum & chain-of-custody:</strong> compute SHA256 checksum for each produced file and store in Batches.checksum; include checksum in upload manifest for portal verification. Archive produced files in STAGING_FOLDER\archive\<jobId>\ with ACLs applied.<br><strong>Idempotency & recovery rules:</strong><br>• If a job is interrupted, detect existing Batches rows for jobId and resume from the last Completed batch unless --recreate is specified, which marks prior batches Archived and recreates files with new names.<br>• AppendBatchRecord should use safe insert semantics — if a record for the same filePath already exists, validate checksum matches and do not duplicate rows. If mismatch detected, mark batch_conflict and halt operator action. <br><strong>Performance notes:</strong> for large batches avoid concatenating long strings; stream rows to ADODB.Stream or write with buffered writes to reduce memory pressure. For extremely large exports, recommend job offload via CreateJobDescriptor to worker process. <br><strong>Failure cases & mitigations:</strong><br>1) Disk full → detect via write exception, set batch status Failed, log detailed diagnostics, and present operator remediation steps (free space or alternate staging path).<br>2) File permission denied → return IMP_BATCH_001 with remediation steps (check ACLs, run as operator user).<br>3) Partial writes → atomic rename prevents final filename from appearing incomplete; temp file deletion on cleanup reduces confusion. <br><strong>Tests:</strong> batch-size boundary tests, encoding parity tests against portal sample parser, permission and disk full simulations, checksum verification tests, and resume/recreate flows. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modErrorParser — ParsePortalErrors (reconciliation engine)</strong><br><strong>Purpose & contract:</strong> reconcile portal response files (error reports) to source tblRawImport and annotate failing rows with structured PortalError info. The parser must support multiple portal CSV formats through header-matching and pluggable mapping configuration, and return both matched error annotations and a separate UnmatchedPortalErrors artifact for manual triage.<br><strong>Matching strategy & priority:</strong><br>1) OriginalRow index (if portal provides) — direct one-to-one mapping; preferred.<br>2) Unique key (NIK) exact match after normalization (trim, remove punctuation) — robust fallback.<br>3) Composite key fallback (NIK+TglLahir or NIK+Nama) when single-key matches are ambiguous.<br><strong>Behavioral rules & idempotency:</strong><br>• Do not overwrite existing PortalError history; append new error entries with timestamp and portalFileRef so previous errors are preserved for audit. <br>• If multiple portal rows map to the same source row, annotate AMBIGUOUS_MATCH and add matchedPortalRows array to the PortalError cell for operator triage.<br><strong>Safe-write & archival rules:</strong><br>• On parse, move the original portal CSV to STAGING_FOLDER\archive\<jobId>\ and compute checksum; record the archive entry in Batches ledger for chain-of-custody. <br>• If policy requires, encrypt archives or restrict ACLs after moving. Provide PurgeAfterDays configuration for automatic deletion under retention policy.<br><strong>CSV parsing robustness:</strong><br>• Use Workbooks.OpenText (or a robust CSV tokenizer) with parameters set to handle quoted newlines and embedded commas. <br>• If header row does not contain expected columns, abort with IMP_PORTAL_001 and present expected header template for operator to forward to portal support. <br><strong>Failure modes & recovery:</strong><br>1) Missing key columns in portal CSV → abort parse and record IMP_PORTAL_001; operator should provide portal support with jobId and archived file. <br>2) Multi-line fields or unusual quoting → use OpenText with xlDelimited and proper TextQualifier settings; if parse fails, create UnparsedPortal artifact for manual inspection. <br><strong>Observability & telemetry:</strong> portal.parse.completed{matchedCount,unmatchedCount,ambiguousCount}, and persistent UnmatchedPortalErrors sheet with diagnostic reason and suggestedAction per row. <br><strong>Tests:</strong> support sample portal exports with known variations, ambiguous matching scenarios, multi-line field parse tests, archive retention and checksum tests, and privacy tests to confirm archive ACLs/encryption applied. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>modUtilities — Logging, helpers, and safe I/O primitives</strong><br><strong>Purpose & contract:</strong> provide safe, testable primitives consumed across modules: structured logging (LogAction), atomic UTF-8 file writes (WriteUtf8FileAtomic), checksum computation (ComputeFileChecksum), table helpers (EnsureTableExists, FindListColumnIndex), and retry/backoff helper (Retry). These utilities must be robust across Excel host variations and provide graceful fallbacks where platform features are unavailable.<br><strong>Logging — LogAction:</strong><br>• Append structured rows to ImportLog with fields Timestamp, JobID, Action, Message, User, Machine, Severity, payloadHash. Ensure ImportLog exists or create it atomically. Provide LogLevel filtering for verbose diagnostics and diagnostics.ttl for log retention.<br><strong>File I/O primitives:</strong><br>• WriteUtf8FileAtomic(path,content) uses ADODB.Stream to write UTF-8 bytes to path.tmp and Name to final path; provides UseBom flag and fallback to ANSI if ADODB not available. <br>• ComputeFileChecksum(path) wraps CryptoAPI when available; fallback to an internal SHA256 implementation (pure VBA) or external utility. Return {algorithm,hex}.<br><strong>Table helpers & safe Excel patterns:</strong><br>• EnsureTableExists(sheetName, headerArray, tableName) — idempotent creation; if table exists, validate headers and return table reference or raise IMP_PF_001 on mismatch. <br>• FindListColumnIndex(tbl, columnName) — return -1 if missing; callers must interpret and fail-fast where headers required. <br><strong>Retries & backoff:</strong><br>• Retry(action, attempts, backoffMs) wrapper executes action with exponential backoff and jitter; use for transient I/O (file writes, external COM calls). Always cap total retry time to avoid runaway loops. <br><strong>Safety & memory considerations:</strong><br>• Avoid reading entire large files into memory when streaming is possible. For CSV creation or checksum computation use buffered reads/writes. <br><strong>Tests:</strong> atomic-write correctness (simulate process termination mid-write and ensure final filename absent), checksum parity, concurrent append simulation (multiple UI processes writing logs), and Retry behavior under flaky I/O. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>frmOperatorUI — UserForm orchestration & human safeguards</strong><br><strong>Purpose & contract:</strong> single-pane operator UI that drives the workflow while enforcing human-in-the-loop checks and safety constraints. Responsibilities: present pipeline steps, capture operatorId, generate jobId, confirm destructive actions, and manage background workers with progress and cancellation tokens. UI must not run heavy workloads on the main UI thread without progress UI and a cooperative cancel mechanism.<br><strong>UI flows & guarded actions:</strong><br>1) LoadFile — prompts for file, validates header using modPreflight.HeaderValidation, populates tblRawImport and logs LogAction("LoadFile", jobId, ...).<br>2) RunPreflight — disables conflicting controls, runs modPreflight.RunPreflight in a worker (or via a timed yield pattern), displays preflight summary modal with counts and direct links to filtered Preflight sheet for remediation.<br>3) CreateBatches — shows batch size and OVERWRITE_BATCHES confirmation; typed confirmation required to enable destructive overwrite behavior. <br>4) ParsePortalErrors — prompts for portal CSV, archives it, runs modErrorParser, and shows UnmatchedPortalErrors if any.<br><strong>Cancellation & cooperative cancel token:</strong><br>• UI sets a module-level CancelRequested boolean when user clicks Cancel. Worker functions must check CancelRequested at logical checkpoints (per-chunk or per-500 rows) and gracefully abort returning partial results. <br><strong>Operator metadata & audit contract:</strong><br>• UI must capture operatorId (prefer authenticated domain identity if available) and include it in every LogAction and Batches row. Each UI-driven activity emits ui.action{action, operatorId, jobId, timestamp} to ImportLog and telemetry. <br><strong>Testing scenarios for UI:</strong><br>• Simulate cancellation during CreateBatches verifying worker stops, partial batches left in Batches ledger are marked Cancelled, and UI returns to interactive state. <br>• Verify typed confirmations prevent accidental overwrite. <br><strong>Accessibility & ergonomics:</strong><br>• Provide keyboard accelerators, avoid modal blocks where possible, and include a compact JobDetail pane showing jobId, createdTs, and recent ImportLog entries for the job. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>PQ conceptual design (mapping, prevalidation, and where to use PQ vs VBA)</strong><br><strong>Role split (explicit guidance):</strong><br>1) Power Query (PQ) is responsible for deterministic, set-based, column-level normalization: trimming, control-character stripping, basic type conversions, mapping table joins, and prevalidation (e.g., mark rows with parseable vs non-parseable dates). Use PQ where transformations are expressible in M and can be folded to source to reduce data movement.<br>2) VBA is responsible for orchestration, file-system I/O, user interactions, portal-specific packaging, streaming exports, and operations that require procedural control, streaming, or host-level access that PQ cannot provide.<br><strong>Suggested PQ responsibilities & patterns:</strong><br>• PQ_Raw — apply basic cleanups: Text.Trim, control-char removal, collapse multi-whitespace, map common local punctuation differences. Preserve original raw value column for evidence/audit.<br>• PQ_Mapping — join ColumnMapping sheet to rename fields, apply canonical value mappings (small lookup tables) with Table.Join or Table.ReplaceValue patterns; keep mapping table small enough to avoid non-foldable joins when possible.<br>• PQ_Preflight — attempt best-effort parsing for dates/numbers using try ... otherwise null constructs; produce ParseSuccess boolean columns and ParseErrorReason for failed parses to avoid silent conversions. PQ should produce PreflightReady view with deterministic columns for VBA to consume.<br><strong>Integration patterns:</strong><br>• Use VBA to refresh only the PQ queries that feed the current job (targeted refresh) and then call modPreflight.RunPreflight for the more complex validation logic. <br>• Keep PQ queries idempotent and parameterize them with named parameters (where possible) stored in a Settings table so queries can be re-used across environments.<br><strong>When to prefer PQ over VBA:</strong><br>• Column-level transformations that are stateless and can be expressed in M and folded to source. <br><strong>When to prefer VBA:</strong><br>• Streaming exports, robust CSV encoding, platform-specific behaviors, user confirmations, and when the transformation requires access to file system or COM APIs. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance (for Power BI)</strong><br><strong>Model design & primary measures:</strong><br>• Expose ImportLog, Batches, PreflightReport, and Telemetry as model tables. Use JobID as the central dimension for joins and lineage.<br>• Key measures to track operational health:<br>1) PreflightFailureRate = DIVIDE([RowsFlagged],[RowsProcessed],0) — used for daily SLO dashboards.<br>2) DuplicateRate = DIVIDE([DuplicateRows],[RowsProcessed],0) — used to monitor source data quality trends.<br>3) BatchSuccessRate = DIVIDE([BatchesWithoutPortalErrors],[TotalBatches],0) — portal integration success metric.<br>4) AverageTimeToRemediation — difference between preflight.detectedTs and preflight.resolvedTs aggregated by JobID and owner.<br><strong>Design principles & materialization:</strong><br>• Materialize daily snapshots to avoid volatile performance; use incremental refresh on ImportLog and Batches. <br>• Include ConfigHash or standardizedMapVersion in telemetry rows to support reproducibility and golden-parity analysis when troubleshooting changes. <br><strong>Example DAX snippets (conceptual only):</strong><br>• PreflightFailureRate = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0).<br>• BatchSuccessRate = DIVIDE(CALCULATE(COUNTROWS(Batches), Batches[Status]="Completed"), COUNTROWS(Batches), 0). </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Testing matrix & QA (unit, integration, chaos tests)</strong><br><strong>Unit tests (per-rule):</strong><br>1) NIK validations — valid numeric 16-digit cases, invalid characters, and leading zeros handling.<br>2) Date normalization — explicit locale cases, ambiguous dates, timezone-stripping tests.<br>3) CSV export encoding — UTF-8 BOM presence, double-quote escaping, and CRLF line-ending tests.<br>4) Checksum correctness — verify SHA256 for small sample files.<br><strong>Integration tests (end-to-end):</strong><br>1) Full pipeline with synthetic datasets: good-data run, missing mandatory fields run, duplicate NIKs, ambiguous dates, and outlier wages. Validate Batches outputs, checksums, and ImportLog entries. <br>2) Portal interaction simulation (mocked) that validates error reconciliation flows. <br><strong>Chaos/negative tests:</strong><br>1) Disk full simulation mid-batch — pipeline must mark batch Failed, log diagnostics, and leave no partially-named final files.<br>2) Permission denied on staging folder — pipeline logs IMP_CFG_001 and aborts. <br>3) Interrupted run and resume — ensure jobId resume semantics work and duplicate files are not produced without explicit recreate. <br><strong>Acceptance tests:</strong><br>• CreateBatches produces correct row counts and checksums for canonical fixtures and ParsePortalErrors annotates failing rows and archives portal CSVs with correct checksums. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Operational runbook (concise step-by-step with remediation hints)</strong><br>1) Prepare RawImport and create a backup copy of the workbook and raw file to STAGING_FOLDER\backup\<jobId>\ before making changes.<br>2) Run RunPreflight; review PreflightReport and fix flagged rows via filtered views. <br>3) Re-run RunPreflight until acceptable thresholds are met (e.g., PreflightFailureRate < configured threshold). <br>4) Run CreateBatches (confirm typed overwrite if required) and upload produced files to portal per portal SOP; retain archive in STAGING_FOLDER\archive\<jobId>\.<br>5) Retrieve portal error file and run ParsePortalErrors; fix only failed rows and re-upload as small batches; keep evidence of each upload in Batches ledger and ImportLog.<br>6) On completion, record job summary in ImportLog and move artifacts to long-term archive per retention policy. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Security, privacy & compliance checklist</strong><br>• Encrypt staging folders when required by policy and restrict ACLs to operator accounts. <br>• Do not hard-code credentials in code — use modUtilities.GetSecretFromStore() to read secure store. <br>• Redact PII in ImportLog except where evidence retention requires full mapping — in which case store sanitized evidence in a protected evidence archive with access controls and chain-of-custody metadata (jobId, archivedTs, checksum). <br>• Implement retention and purge policies (e.g., archiveRetentionDays) and periodically run retention jobs to purge expired artifacts. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Observability & telemetry (recommended metrics & audits)</strong><br>• Emit structured telemetry rows to ImportLog and Telemetry tables with tags: jobId,operatorId,configHash,standardMapHash and metrics: preflight.rowsProcessed, preflight.rowsFlagged, batches.created, batches.failed, portal.errorMatchRate, avg.batch.create.time_ms. <br>• Audit obligations: every UI or operator action must log ui.action with correlationId and jobId. For regulated runs, persist validationReport and evidenceRefs in secure archive. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Failure modes & immediate mitigation steps (operator quick reference)</strong><br>• Preflight blocked due to missing headers → restore header template from docs/header_template.csv, re-run preflight. <br>• Batch write fails due to disk/permission → delete partial files, fix permissions or choose alternate staging folder, re-run CreateBatches with --recreate if required. <br>• Portal error CSV unmatched → upload UnmatchedPortalErrors with jobId to portal support, attach archived portal CSV for debugging. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Extensibility & hooks for future integration</strong><br>• Pluggable UploadBatch(filePath) interface to support manual UI-driven upload, HTTP-based automated upload with token-based auth, or SFTP adapter. <br>• CreateJobDescriptor support for job scheduler integration to offload extremely large exports to worker processes with checkpointing. <br>• ColumnMapping sheet maintained by business users and consumed dynamically by PQ through PQ_Mapping for low-friction mapping changes. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>CI/CD & release gating</strong><br>• Required checks before production release: unit tests, integration E2E run on canonical fixtures, encoding/locale regression tests, golden-file checksum parity for CSV outputs, and signed release artifact when distributing workbook. <br>• Automate golden-file checks: when CSV output changes, require a migration manifest documenting semantic changes and two-person approval for regulated changes. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Developer checklist before handoff</strong><br>1) Confirm STAGING_FOLDER accessibility for operator accounts and validate ACLs.<br>2) Confirm header/column mapping matches portal template and verify sample uploads end-to-end in a sandbox portal environment.<br>3) Run E2E test with canonical fixtures and record ImportLog entries and Batches checksums.<br>4) Document runbook, retention policy, and configuration steps in repository README and include migration_manifest.json for any breaking changes. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>ErrorCodeCatalog (recommended shortlist)</strong><br>• IMP_CFG_001 — invalid staging folder (permission or path).<br>• IMP_PF_001 — missing mandatory columns in raw file. <br>• IMP_PF_002 — NIK invalid. <br>• IMP_PF_003 — ambiguous date detected. <br>• IMP_BATCH_001 — file write failed (disk/permission). <br>• IMP_PORTAL_001 — portal CSV missing expected header. <br>Each code should map to short UI message, triage hint, and remediation steps; log full diagnostics in ImportLog for triage. </td></tr><tr><td data-label="Overview — Per-function technical breakdown (VBA)"> <strong>Final verification statement</strong><br>I validated the expanded per-function technical breakdown for internal consistency, deterministic behavior, failure and recovery modes, security & privacy controls, observability, and test coverage. The document above is implementation-ready and oriented to world-class engineering practices for a PQ-driven normalization + VBA orchestration import pipeline. </td></tr></tbody></table></div><div class="row-count">Rows: 19</div></div><div class="table-caption" id="Table3" data-table="YJKN_0017_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modConfig — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modConfig — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Overview & purpose</strong><br>modConfig is the authoritative, single-source-of-truth VBA module that encapsulates environment-specific constants, runtime configuration values, and lightweight preflight assertions for the entire IMPORT DATA pipeline. Its responsibilities are configuration declaration, safe runtime exposure via <code>GetConfig()</code>, deterministic preflight validation of essential invariants, and emitting lightweight observability/telemetry stubs for configuration-load events. modConfig MUST be the only module where environment or deploy-time constants are edited; all other modules read values from modConfig only. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Contract (caller-facing)</strong><br>1) <code>GetConfig() As Scripting.Dictionary</code> — returns an immutable snapshot-like dictionary containing all runtime-relevant keys and values that callers should treat read-only.<br>2) <code>AssertStagingFolder() As Variant</code> — ensures staging folder exists and is writable; returns <code>True</code> on success or a structured error variant <code>{errorCode,desc,remediation}</code> on failure.<br>3) <code>ValidateConfig() As Collection</code> — runs a set of preflight checks and returns a collection of zero-or-more error objects; empty collection == configuration valid.<br>4) <code>ReloadConfig()</code> — optional: re-reads any dynamic configuration source (e.g., <code>Settings</code> sheet) and refreshes the in-memory snapshot; returns <code>GetConfig()</code> result.<br>5) Module-level constants (public) that other modules may reference for build-time invariants (e.g., <code>DEFAULT_DATE_FORMAT</code>) — these are documented and semantically immutable at runtime unless <code>ReloadConfig</code> is used.<br><strong>Contract guarantees:</strong><br>• Deterministic: <code>GetConfig()</code> returns identical dictionaries for identical environment and on repeated calls within the same workbook state, unless <code>ReloadConfig()</code> or a developer edit modifies the underlying configuration.<br>• Fail-fast: callers should call <code>ValidateConfig()</code>/<code>AssertStagingFolder()</code> early; operations that depend on missing/invalid config must abort with clear <code>IMP_CFG_*</code> error codes. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Primary configuration keys (recommended canonical set)</strong><br>1) <code>STAGING_FOLDER</code> — path to staging area; must end with path separator.<br>2) <code>STAGING_ARCHIVE_FOLDER</code> — path for archived artifacts (often <code>STAGING_FOLDER &amp; &quot;archive\&quot;</code>).<br>3) <code>BATCH_SIZE</code> — default integer rows per batch.<br>4) <code>MAX_PREVIEW_ROWS</code> — maximum rows shown in UI preview.<br>5) <code>RAW_TABLE_NAME</code> — expected ListObject name for raw imported data.<br>6) <code>PREFLIGHT_TABLE_NAME</code> — expected ListObject name that preflight writes to.<br>7) <code>BATCHES_TABLE_NAME</code> — ledger table name for created batch metadata.<br>8) <code>DEFAULT_DATE_FORMAT</code> — canonical format string (e.g., <code>yyyy-mm-dd</code>).<br>9) <code>USE_UTF8</code> — boolean default for CSV export encoding.<br>10) <code>OVERWRITE_BATCHES</code> — boolean; destructive behavior gate.<br>11) <code>REFRESH_TIMEOUT_MS</code> — PQ refresh timeout millisecond cap.<br>12) <code>MAX_PREVIEW_ROWS</code> — UI safety cap for previews.<br>13) <code>UPAH_MAX_THRESHOLD</code> — business threshold for salary validation.<br>14) <code>OUTLIER_MULTIPLIER</code> — factor used by preflight outlier detection.<br>15) <code>CONFIG_HASH</code> — computed sha-like fingerprint of canonical config values used for telemetry and golden parity.<br>16) <code>PQ_VERSION</code> — canonical PQ normalization version expected by pipeline.<br>17) <code>SCORING_CONFIG_HASH</code> — optional; included if scoring config exists.<br>18) <code>ARCHIVE_RETENTION_DAYS</code> — integer for automated retention/purge. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Primary invariants enforced by modConfig</strong><br>1) <code>STAGING_FOLDER</code> must end with the system path separator and must be creatable by the current user account. If not, <code>AssertStagingFolder()</code> returns <code>{errorCode:&quot;IMP_CFG_001&quot;,desc:&quot;Staging folder missing or not creatable&quot;,remediation:&quot;Check ACLs or choose alternate path&quot;}</code>.<br>2) <code>BATCH_SIZE</code> must be integer > 0 and <= <code>MaxBatchSize</code> (if provided). Invalid -> <code>IMP_CFG_002</code>.<br>3) Table names (<code>RAW_TABLE_NAME</code>, <code>PREFLIGHT_TABLE_NAME</code>, <code>BATCHES_TABLE_NAME</code>) must match ListObject names in the workbook; mismatch should surface expected header templates and raise <code>IMP_CFG_003</code>.<br>4) <code>REFRESH_TIMEOUT_MS</code> must be >= 1000 and reasonable (< 1 hour) — otherwise corrected and logged. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>GetConfig() semantics & structure</strong><br>Design:<br>1) <code>GetConfig()</code> returns a <code>Scripting.Dictionary</code> with string keys and variant values. Keys are canonicalized to upper-case and stable across calls.<br>2) The dictionary includes both literal constants (e.g., <code>STAGING_FOLDER</code>) and computed values (e.g., <code>STAGING_ARCHIVE_FOLDER</code>, <code>CONFIG_HASH</code>, <code>createdTs</code>).<br>3) The returned dictionary must be treated read-only by callers — to change config a developer must edit modConfig or call <code>ReloadConfig()</code> when appropriate.<br>4) <code>GetConfig()</code> should not attempt expensive IO (e.g., network calls). If dynamic reading is required (e.g., reading <code>Settings</code> sheet), provide <code>ReloadConfig()</code> explicitly; <code>GetConfig()</code> returns cached snapshot. <br>Snapshot example (conceptual, not code):<br><code>{ jobId: &quot;autogen-20260220-001&quot;, STAGING_FOLDER: &quot;C:\staging\&quot;, BATCH_SIZE: 500, USE_UTF8: True, CONFIG_HASH: &quot;sha256:...&quot; }</code><br>Observability: <code>GetConfig()</code> should emit <code>config.loaded{configHash,env,loadTs}</code> to <code>ImportLog</code> via <code>modUtilities.LogAction</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>AssertStagingFolder() — behavior & recovery</strong><br>Behavior:<br>1) If <code>STAGING_FOLDER</code> exists and is writable: return <code>True</code>.<br>2) If <code>STAGING_FOLDER</code> does not exist: attempt <code>MkDir</code> (wrapped in a retry with backoff for transient FS errors). On success, return <code>True</code> and log <code>config.staging.created{path,jobId}</code>.<br>3) If creation fails due to permissions or invalid path: return a structured error variant <code>{errorCode:&quot;IMP_CFG_001&quot;,desc,detail,remediation}</code> and do NOT raise an unhandled error.<br>Recovery guidance (returned in remediation):<br>1) Check ACLs for operator account; add write permissions.<br>2) Choose alternative <code>STAGING_FOLDER</code> in secure location and update modConfig constants.<br>3) For network paths: ensure network reachable and credentials accessible; avoid using mapped drive letters in scheduled jobs — prefer UNC paths.<br>Edge cases & safety:<br>• Do not automatically escalate permissions or change ACLs — only provide remediation text. <br>• If folder path points to root or system-critical folders (e.g., <code>C:\Windows\</code>), return <code>IMP_CFG_004</code> and refuse to use until operator confirms alternate path. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>ValidateConfig() — rules & outputs</strong><br>1) Validate presence and type of primary keys listed above; each failure appended to a <code>Collection</code> of error objects <code>{errorCode,field,desc,remediation}</code>.<br>2) Validate BATCH_SIZE numeric range -> <code>IMP_CFG_002</code> if invalid.<br>3) Validate date format string is non-empty and parseable by <code>DateValue</code> heuristics -> <code>IMP_CFG_005</code> if invalid.<br>4) Validate <code>REFRESH_TIMEOUT_MS</code> bounds -> <code>IMP_CFG_006</code> if too small/large.<br>5) Validate <code>ARCHIVE_RETENTION_DAYS</code> >= 0 -> <code>IMP_CFG_007</code> if invalid.<br>Return value: empty <code>Collection</code> when configuration is valid; callers should abort on non-empty collection and surface errors to operator with remediation steps. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>ErrorCode catalog (config-specific)</strong><br>1) <code>IMP_CFG_001</code> — invalid staging folder (permission or path).<br>2) <code>IMP_CFG_002</code> — invalid BATCH_SIZE (zero/negative/not integer).<br>3) <code>IMP_CFG_003</code> — table name mismatch (<code>RAW_TABLE_NAME</code> or others).<br>4) <code>IMP_CFG_004</code> — unsafe staging folder (system path).<br>5) <code>IMP_CFG_005</code> — invalid/default date format not parseable.<br>6) <code>IMP_CFG_006</code> — REFRESH_TIMEOUT_MS out of acceptable bounds.<br>7) <code>IMP_CFG_007</code> — ARCHIVE_RETENTION_DAYS invalid.<br>Each error code maps to: short UI message, triage hint, remediation steps, and <code>ImportLog</code> diagnostics with <code>jobId</code> and stack trace where available. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Security & governance rules enforced by modConfig</strong><br>1) Do not hard-code secrets or API keys in modConfig. If a secret is required, <code>GetConfig()</code> should include a placeholder key and callers must call <code>modUtilities.GetSecretFromStore(key)</code> at runtime to retrieve secrets from Windows Credential Manager or a configured secure store.<br>2) Treat <code>STAGING_FOLDER</code> as PII-sensitive when it will hold raw data: include <code>stagingAclSuggestedGroup</code> metadata and recommend ACL lockdown in <code>remediation</code> text.<br>3) Provide <code>UseEncryptedArchive</code> boolean and <code>ArchiveEncryptionPolicy</code> metadata to guide downstream archival behavior; modConfig may set the policy but must not store keys — keys are retrieved via <code>modUtilities.GetSecretFromStore(&quot;archiveKey&quot;)</code> at runtime.<br>4) All telemetry or logs written by modConfig should avoid storing raw PII; only include <code>configHash</code> and counts. When full evidence is required by regulation, modConfig should include <code>evidenceRefRequired</code> flag and callers must follow evidence archive workflow that enforces encryption and restricted ACLs. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Observability & telemetry (fields & emission points)</strong><br>Emit the following structured telemetry rows to <code>ImportLog</code> via <code>modUtilities.LogAction</code> and to <code>Telemetry</code> if present:<br>1) <code>config.loaded{configHash,env,loadTs}</code> — when <code>GetConfig()</code> loads snapshot.<br>2) <code>config.assert.fail{errorCode,field,jobId}</code> — when <code>AssertStagingFolder()</code> or <code>ValidateConfig()</code> finds failures.<br>3) <code>config.reload{previousHash,newHash,changedKeys,operatorId}</code> — when <code>ReloadConfig()</code> updates runtime snapshot.<br>4) <code>config.warn{key,message}</code> — for non-fatal corrections (e.g., clamping <code>REFRESH_TIMEOUT_MS</code>).<br>Telemetry payloads must include <code>jobId</code>, <code>correlationId</code> (if present), and <code>configHash</code>. For regulated workflows, also persist <code>validationReportRef</code> to the secure evidence store. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Implementation notes & best-practices</strong><br>1) Use <code>Scripting.Dictionary</code> for <code>GetConfig()</code> returns; provide a thin <code>ConfigSnapshot</code> wrapper documented in README so consumers know to treat it as read-only.<br>2) Keep default constant values at module top as <code>Private Const</code> or <code>Public</code> where appropriate; include inline comment metadata (<code>&#x27; default, env:dev/prod, editable</code>) to simplify audits.<br>3) Compute <code>CONFIG_HASH</code> deterministically by concatenating canonical keys in a fixed order and computing a SHA256 hex digest using <code>modUtilities.ComputeFileChecksum</code>-style helper (or in-memory SHA256 helper). Always include <code>pqVersion</code> and <code>scoringConfigHash</code> in the hash to enable golden-parity validation.<br>4) For dynamic configurations (e.g., reading <code>Settings</code> sheet): provide <code>ReloadConfig()</code> which reads sheet values, validates them via <code>ValidateConfig()</code>, updates the in-memory snapshot, logs <code>config.reload</code> and returns new snapshot.<br>5) Avoid expensive I/O or blocking network calls in property getters — provide explicit functions for operations that require I/O (e.g., archive folder creation).<br>6) Protect constant edits by recommending code-signing and storing a <code>developerReadme</code> explaining which values are safe to change and which require approvals. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Examples & operator narratives (scenarios)</strong><br>Scenario A — clean operator run ready environment:<br>1) Operator opens workbook; <code>GetConfig()</code> called on <code>Workbook_Open</code> to populate UI.<br>2) <code>GetConfig()</code> returns snapshot including <code>STAGING_FOLDER=&quot;C:\staging\import\&quot;</code>, <code>BATCH_SIZE=500</code>, <code>REFRESH_TIMEOUT_MS=600000</code> and <code>CONFIG_HASH=&quot;sha256:abcd...&quot;</code>.<br>3) UI shows job creation and operator proceeds; telemetry <code>config.loaded</code> logged.<br>Scenario B — missing staging folder permission:<br>1) Operator edits <code>STAGING_FOLDER</code> to a network UNC path where current user lacks write access.<br>2) On <code>CreateBatches</code>, pipeline calls <code>AssertStagingFolder()</code> which attempts <code>MkDir</code> and fails with permission denied.<br>3) <code>AssertStagingFolder()</code> returns <code>{errorCode:&quot;IMP_CFG_001&quot;,desc:&quot;Permission denied&quot;,remediation:&quot;Add write ACL to user or choose alternate folder&quot;}</code> and <code>ImportLog</code> receives a <code>config.assert.fail</code> row. UI surfaces typed remediation and suggests <code>STAGING_FOLDER=&quot;\\fileserver\staging\import\&quot;</code> as alternate (if available). </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>API surface & recommended signatures (conceptual; not code snippets)</strong><br>1) <code>Function GetConfig() As Scripting.Dictionary</code> — returns snapshot.<br>2) <code>Function AssertStagingFolder(Optional ByVal ForceCreate As Boolean = False) As Variant</code> — returns True or structured error.<br>3) <code>Function ValidateConfig() As Collection</code> — returns collection of config errors.<br>4) <code>Sub ReloadConfig()</code> — refresh snapshot from <code>Settings</code> sheet and re-run <code>ValidateConfig()</code>; logs changes.<br>5) <code>Function ComputeConfigHash(Optional ByVal IncludeSensitive As Boolean = False) As String</code> — deterministic config fingerprint; include only canonical keys unless <code>IncludeSensitive</code> explicitly requested by operator in secure UI. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Compatibility & host considerations</strong><br>1) Some Excel hosts (Mac / Excel online) may not support <code>Scripting.Dictionary</code> or <code>MkDir</code> semantics identically; provide defensive fallbacks or detect host and surface <code>IMP_CFG_008</code> (host unsupported) with clear remediation to use Windows desktop Excel. <br>2) For scheduled background runs under service accounts, ensure <code>STAGING_FOLDER</code> uses UNC paths accessible by service account and never rely on mapped drives. Document service account ACL steps in runbook. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Error handling & safe-fail principles</strong><br>1) Never raise unhandled exceptions from <code>GetConfig()</code> — always return structured errors or empty defaults plus telemetry that signals an invalid config. <br>2) Fail early: pipeline steps must call <code>ValidateConfig()</code> and stop if any required key is invalid. <br>3) Provide typed confirmations in UI for destructive flags (e.g., <code>OVERWRITE_BATCHES</code>) — modConfig exposes the flag but UI must require typed 'DELETE-AND-RECREATE' confirmation before allowing operations where <code>OVERWRITE_BATCHES = True</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Observability examples (ImportLog rows) — conceptual entries</strong><br>1) <code>config.loaded{configHash:&quot;sha256:...&quot;,env:&quot;dev&quot;,loadTs:&quot;2026-02-20T08:30:21Z&quot;,jobId:&quot;job-20260220-001&quot;}</code>.<br>2) <code>config.assert.fail{errorCode:&quot;IMP_CFG_001&quot;,field:&quot;STAGING_FOLDER&quot;,detail:&quot;Permission denied&quot;,jobId:&quot;job-20260220-001&quot;}</code>.<br>3) <code>config.reload{previousHash:&quot;sha256:aaa...&quot;,newHash:&quot;sha256:bbb...&quot;,changedKeys:[&quot;BATCH_SIZE&quot;,&quot;REFRESH_TIMEOUT_MS&quot;],operatorId:&quot;alice&quot;}</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Integration patterns with PQ (conceptual guidance specific to modConfig)</strong><br>1) PQ queries depend on a deterministic <code>pqVersion</code> and a small <code>Settings</code> table that PQ can read for parameterization; modConfig must expose <code>PQ_VERSION</code> and <code>REFRESH_TIMEOUT_MS</code> so callers can ensure PQ and VBA are aligned.<br>2) Recommended flow:<br>1) <code>GetConfig()</code> -> <code>modPQController.RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> respecting <code>REFRESH_TIMEOUT_MS</code>.<br>2) After PQ refresh, <code>modPreflight.RunPreflight</code> consumes <code>PREFLIGHT_TABLE_NAME</code> produced by PQ.<br>3) <code>CONFIG_HASH</code> must embed <code>PQ_VERSION</code> and <code>standardMapVersion</code> so that golden-parity tests for PQ normalization can compare expected outputs in automated tests. <br>3) Provide <code>PQ_PARAMETER_OVERRIDES</code> map (optional) where <code>GetConfig()</code> returns key/values discoverable by PQ (via <code>Settings</code> sheet) to parameterize e.g., <code>SourceLocale</code> or <code>DateOrder</code>. Use <code>ReloadConfig()</code> to update <code>Settings</code> sheet before refreshing PQ. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance tied to modConfig</strong><br>1) Always include <code>ConfigHash</code> as a dimension or attribute in telemetry tables ingested to Power BI; this allows slicing measures by configuration version and supports golden-parity investigations.<br>2) Recommended reporting dimensions:<br>1) <code>ConfigHash</code> — groups jobs by configuration fingerprint.<br>2) <code>PQVersion</code> — PQ normalization version used.<br>3) <code>OperatorId</code> — operator who ran job.<br>3) Example measures (conceptual DAX snippets; descriptive):<br>• <code>PreflightFailureRateByConfig = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0)</code> sliced by <code>ConfigHash</code>.<br>• <code>AvgBatchCreateTimeByConfig = AVERAGEX(FILTER(Batches, Batches[ConfigHash]=SelectedConfig), Batches[CreateDurationMs])</code>.<br>4) Use <code>ConfigHash</code> to detect behavioral regressions when pipeline outputs diverge after config or PQ changes; when <code>ConfigHash</code> changes, require golden-file checksum parity tests before accepting new config for production. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Testing & QA recommendations specific to modConfig</strong><br>1) Unit tests:<br>1) <code>AssertStagingFolder()</code> when folder exists writable -> True.<br>2) <code>AssertStagingFolder()</code> when missing -> attempts to create -> returns True if MkDir succeeds.<br>3) <code>ValidateConfig()</code> with invalid <code>BATCH_SIZE</code> -> returns collection containing <code>IMP_CFG_002</code>.<br>2) Integration tests:<br>1) E2E pipeline run where <code>GetConfig()</code> returns canonical <code>CONFIG_HASH</code> -> ensure produced <code>Batches</code> checksums match golden files for the <code>CONFIG_HASH</code> value.<br>3) Chaos tests:<br>1) Simulate disk full during <code>AssertStagingFolder()</code>/archive creation -> verify error code <code>IMP_CFG_001</code> (or <code>IMP_BATCH_001</code> downstream) and no partial files left in final folder; temp file cleanup occurs.<br>4) CI gating:<br>1) When <code>CONFIG_HASH</code> changes on code deploy, require run of deterministic E2E fixture suite. <br>2) Maintain a <code>migration_manifest.json</code> alongside config changes documenting the reason and two-person approval for regulated changes. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Runbook excerpts for operators (short actionable steps)</strong><br>1) To change staging folder: edit <code>modConfig.STAGING_FOLDER</code> -> run <code>AssertStagingFolder()</code> from UI -> if success, <code>GetConfig()</code> logs <code>config.reload</code> and proceed. <br>2) If <code>AssertStagingFolder()</code> returns <code>IMP_CFG_001</code>: check ACLs, try creating the folder manually as the operator account, or choose alternate UNC path. <br>3) If <code>ValidateConfig()</code> fails on <code>BATCH_SIZE</code>: set <code>BATCH_SIZE</code> to recommended default (e.g., 500) and re-run <code>ValidateConfig()</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Extensibility & hooks for future integrations</strong><br>1) Provide <code>GetConfigForWorker()</code> that returns minimal safe configuration subset suitable for worker processes (no PII hints or sensitive URIs) for job descriptors used by external schedulers.<br>2) Provide <code>OnConfigChange</code> event hook (callback registration pattern) so other modules may register a handler to react to config reloads (e.g., rebind PQ parameter table).<br>3) Add <code>FeatureFlags</code> map inside <code>GetConfig()</code> for controlled feature rollout (e.g., <code>FeatureFlags.AllowInlineApply = False</code>) enabling two-person approvals for mutative behaviors. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Developer checklist before committing changes to modConfig</strong><br>1) Run <code>ValidateConfig()</code> locally and confirm no errors.<br>2) Compute <code>CONFIG_HASH</code> and add to <code>migration_manifest.json</code> if the change is semantic.<br>3) Run E2E canonical fixture tests and verify <code>Batches</code> checksum parity for <code>CONFIG_HASH</code> if applicable.<br>4) Update README and changelog with explicit notes about which keys are safe to edit and which require approvals. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Auditing & chain-of-custody policy notes</strong><br>1) Every <code>config.reload</code> or <code>config.loaded</code> telemetry must include <code>jobId</code>, <code>operatorId</code> (if triggered from UI), and <code>correlationId</code> to enable traceability across pipeline steps.<br>2) For regulated runs where evidence retention is required, modConfig must set <code>evidenceRefRequired = True</code> so downstream modules persist preflight reports and artifacts in the secure evidence archive referenced by <code>evidenceRef</code> recorded in <code>ImportLog</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Common pitfalls & mitigation</strong><br>1) <strong>Pitfall:</strong> Hard-coded staging paths in other modules.<br><strong>Mitigation:</strong> CI rule: static analysis that fails the build if other modules reference environment-like string literals resembling <code>C:\</code> or <code>\\</code> UNC paths; require all such references to go through <code>GetConfig()</code>.<br>2) <strong>Pitfall:</strong> Relying on mapped drive letters in scheduled tasks.<br><strong>Mitigation:</strong> Use UNC paths and document service-account ACL steps in runbook. <br>3) <strong>Pitfall:</strong> Changing <code>PQ_VERSION</code> without golden-file test -> downstream mismatches.<br><strong>Mitigation:</strong> Enforce <code>CONFIG_HASH</code> parity gating in CI and require two-person approval for <code>PQ_VERSION</code> bump. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Concrete example: canonical GetConfig snapshot (human-readable) — narrative</strong><br>Returned snapshot narrative (human-readable):<br>1) <code>jobId</code>: autogen job identifier for correlation.<br>2) <code>STAGING_FOLDER</code>: <code>\\fileserver\staging\import\</code> (must end with backslash).<br>3) <code>BATCH_SIZE</code>: 500.<br>4) <code>USE_UTF8</code>: True (CSV exports default to UTF-8 with BOM).<br>5) <code>REFRESH_TIMEOUT_MS</code>: 600000.<br>6) <code>PQ_VERSION</code>: <code>v1.3.2</code> to indicate a specific Power Query normalization contract.<br>7) <code>CONFIG_HASH</code>: deterministic SHA256 fingerprint of the above canonical keys.<br>Operators should validate the snapshot before long-running runs; telemetry <code>config.loaded</code> will be emitted automatically. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>How modConfig supports golden-parity and CI checks</strong><br>1) <code>ComputeConfigHash()</code> deterministically includes <code>PQ_VERSION</code> and <code>SCORING_CONFIG_HASH</code> so that any change in normalization or scoring produces a new <code>CONFIG_HASH</code>.<br>2) CI should enforce: for any PR that changes modConfig constants affecting <code>CONFIG_HASH</code>, run the canonical fixture suite and compare artifact checksums. If any checksum differs, require documented migration steps and two-person approval. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Appendix — conceptual mapping to other modules</strong><br>1) <code>modPQController</code> — reads <code>REFRESH_TIMEOUT_MS</code>, <code>PQ_VERSION</code>, and may use <code>PQ_PARAMETER_OVERRIDES</code> from <code>GetConfig()</code> to parametrize query refreshes.<br>2) <code>modPreflight</code> — reads <code>PREFLIGHT_TABLE_NAME</code>, <code>UPAH_MAX_THRESHOLD</code>, and <code>OUTLIER_MULTIPLIER</code> from <code>GetConfig()</code> and relies on <code>CONFIG_HASH</code> for telemetry.<br>3) <code>modBatchProcessing</code> — consumes <code>STAGING_FOLDER</code>, <code>BATCH_SIZE</code>, <code>USE_UTF8</code>, and <code>OVERWRITE_BATCHES</code>; uses <code>AssertStagingFolder()</code> before exports and writes <code>Batches</code> ledger rows tagged with <code>configHash</code> and <code>operatorId</code>.<br>4) <code>modErrorParser</code> — may use <code>STAGING_ARCHIVE_FOLDER</code> and <code>ARCHIVE_RETENTION_DAYS</code> from <code>GetConfig()</code> to archive portal CSVs and manage retention. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Final verification checklist (what modConfig must ensure at runtime)</strong><br>1) <code>GetConfig()</code> returns non-empty, canonical dictionary with <code>CONFIG_HASH</code> computed.<br>2) <code>ValidateConfig()</code> returns empty collection before pipeline proceeds.<br>3) <code>AssertStagingFolder()</code> returns True or provides structured remediation error before file writes begin.<br>4) All telemetry emissions include <code>configHash</code> and <code>jobId</code> to enable traceability.<br>5) No sensitive credentials are stored in the module; any secret retrieval goes via <code>modUtilities.GetSecretFromStore()</code>. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Notes on maintainability & suggested README entries</strong><br>1) Document each config key with purpose, allowed values, default, and whether changing it requires CI golden-file revalidation.<br>2) Provide an example <code>migration_manifest.json</code> template that records <code>oldConfigHash</code>, <code>newConfigHash</code>, <code>changedKeys</code>, <code>justification</code>, and <code>approvals</code> (operator signatures).<br>3) Recommend code signing for the workbook and a pre-deploy checklist verifying <code>STAGING_FOLDER</code> ACLs and <code>PQ_VERSION</code> parity with dev/sandbox environments. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Change-control & approval governance</strong><br>1) For configuration changes that will affect serialized outputs (CSV format, column mapping, PQ normalization), require: <br>1) Update to <code>migration_manifest.json</code> documenting semantic change. <br>2) Two-person sign-off (operator + data-owner). <br>3) CI golden-file parity run. <br>4) Telemetry or change-log entry on release. </td></tr><tr><td data-label="modConfig — Per-function technical breakdown (VBA)"> <strong>Closing note</strong><br>The modConfig module is intentionally conservative: it centralizes environment values, enforces safety checks early, and emits structured telemetry to support reproducibility, CI gating, and forensic audits. Implement it as a small, well-tested module with clearly documented keys, deterministic hashing for golden-parity, and defensive guards around filesystem and host-specific differences. </td></tr></tbody></table></div><div class="row-count">Rows: 31</div></div><div class="table-caption" id="Table4" data-table="YJKN_0017_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modPQController — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modPQController — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Executive summary & high-level intent</strong><br>modPQController is the authoritative orchestration module responsible for deterministic, observable, and robust Power Query (PQ) refresh operations used by the IMPORT DATA pipeline. Primary responsibilities: orchestrate targeted or dependency-ordered PQ refreshes, provide synchronous and asynchronous refresh APIs, serialize concurrent refresh operations safely, implement deterministic timeout/retry/backoff policies, capture rich per-query diagnostics, emit structured telemetry for traceability and CI gating, and produce reliable artifacts that downstream VBA modules (e.g., <code>modPreflight</code>, <code>modBatchProcessing</code>) can consume without race conditions. The module enforces PQ/VBA contract parity using <code>PQ_VERSION</code> and <code>CONFIG_HASH</code> produced by <code>modConfig</code>, supports cross-host compatibility modes, and provides worker-offload hooks for large/long-running refreshes. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Primary design goals & constraints</strong><br>1) <strong>Determinism</strong> — for identical query lists, PQ_VERSION, and source snapshot, the observable outputs (ListObjects, Data Model tables) must be stable and repeatable across runs; any nondeterminism must be accompanied by an explict telemetry marker. <br>2) <strong>Fail-fast & graceful degradation</strong> — failures are surfaced as structured <code>RefreshResult</code> objects with per-query breakdowns; the module must never terminate caller code with unhandled exceptions. <br>3) <strong>Concurrency safety</strong> — protect PQ operations against concurrent refreshes that might corrupt or partially mutate workbook tables; provide queueing or immediate <code>BUSY</code> responses per configured policy. <br>4) <strong>Host-aware</strong> — detect host capabilities and degrade or reroute to worker automation if running in a host that lacks required refresh APIs. <br>5) <strong>Observability</strong> — emit compact, structured telemetry rows for start/completion/errors with <code>configHash</code>, <code>pqVersion</code>, <code>jobId</code>, <code>correlationId</code> to support post-hoc forensic analysis and CI golden-parity checks. <br>6) <strong>Non-invasive</strong> — avoid changing PQ logic (M) inside the controller; keep orchestration separate and limited to refresh coordination, parameter propagation, and metadata capture. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Public contract & API (conceptual function signatures)</strong><br>1) <code>GetRefreshResult(queryList As Variant, Optional timeoutMs As Long = -1) As RefreshResult</code> — synchronous caller: blocks until refresh completes or times out; returns structured <code>RefreshResult</code> with per-query metadata and errors. <br>2) <code>RefreshQueriesAsync(queryList As Variant, callbackName As String, Optional timeoutMs As Long = -1, Optional pollIntervalMs As Long = 250)</code> — starts refresh and returns immediately; on completion invokes the named callback with <code>RefreshResult</code> or writes <code>RefreshResult</code> to a configurable artifact location. <br>3) <code>StopRefresh()</code> — cooperative cancellation request that sets a module-level <code>CancelRequested</code> flag; attempt to request cancellation where host supports it and set <code>RefreshResult.errors</code> appropriately. <br>4) <code>GetRefreshStatus() As Scripting.Dictionary</code> — returns <code>IsRefreshing</code>, <code>QueueLength</code>, <code>ActiveQueries</code>, <code>StartTs</code>, <code>TimeoutMs</code>, <code>Retries</code> for observability/UI. <br>5) <code>RegisterRefreshCallback(callbackName As String)</code> / <code>UnregisterRefreshCallback(callbackName As String)</code> — control registration of callbacks for async completions. <br>6) <code>SetQueuePolicy(policyName As String)</code> — define queue behavior: <code>fifo</code>, <code>dropIfBusy</code>, <code>cancelOnNew</code>, <code>coalesce</code>. <br>7) <code>WarmDependencyCache()</code> — precompute and cache PQ dependency DAG from <code>PQ_Dependencies</code> sheet or developer-maintained manifest to avoid on-the-fly expensive discovery. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>RefreshResult — structure and semantics</strong><br>1) <code>success As Boolean</code> — True only if all requested queries succeeded and no unrecoverable error occurred. <br>2) <code>partial As Boolean</code> — True if at least one query succeeded and at least one failed or timed out. <br>3) <code>refreshedQueries As Collection</code> — list of per-query metadata objects <code>{queryName, outputTableName, rowsReturned, durationMs, parseSuccess, lastRefreshedTs, schemaHash}</code>. <br>4) <code>failedQueries As Collection</code> — list of <code>{queryName, errorCode, durationMs, errorText, errorLocation, remediationHint}</code>. <br>5) <code>errors As Collection</code> — flat list of structured error objects for easy UI consumption. <br>6) <code>durationMs As Long</code> — wall-clock time from start to end (or cancellation). <br>7) <code>jobId As String</code> and <code>configHash As String</code> — propagated from <code>GetConfig()</code> to enable traceability and golden-parity. <br>8) <code>evidenceRef As String</code> — optional path to persisted <code>RefreshResult</code> JSON artifact stored in <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\</code> with <code>sha256</code> checksum. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Detailed workflow: input validation & preconditions</strong><br>1) <strong>Canonicalize inputs</strong> — accept <code>queryList</code> as single string, 1-D VBA array, Collection, or sentinel <code>&#x27;RefreshAll&#x27;</code>; normalize into Collection of unique query names; ensure names are trimmed and case-normalized per workbook. <br>2) <strong>Config checks</strong> — read <code>modConfig.GetConfig()</code> snapshot and validate <code>PQ_VERSION</code> parity; if mismatch -> return structured error <code>IMP_PQ_002</code> (pqVersion mismatch) and do not begin refresh unless caller explicitly sets <code>force=true</code>. <br>3) <strong>Dependency DFS expansion</strong> — given the canonical query list, consult cached <code>PQ_Dependencies</code> to compute required upstream queries to refresh for deterministic state; callers may override expansion with <code>targetedOnly=True</code>. <br>4) <strong>Resource checks</strong> — check <code>IsRefreshing</code> mutex and <code>QueuePolicy</code>; if <code>IsRefreshing</code> True and queue policy is <code>reject</code>, return <code>IMP_PQ_BUSY</code>; otherwise enqueue. <br>5) <strong>Parameter persistence</strong> — if <code>GetConfig()</code> includes <code>PQ_PARAMETER_OVERRIDES</code> or the UI passed parameter override map, write parameter values to the <code>Settings</code> sheet or PQ parameter table before refreshing dependent queries; log <code>pq.params.updated</code> telemetry. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Dependency management & deterministic DAG behavior</strong><br>1) <strong>Dependency manifest</strong> — prefer an explicit <code>PQ_Dependencies</code> ListObject maintained by developers to express <code>QueryName -&gt; [UpstreamQueries]</code>; avoid runtime inference since it is brittle and host-dependent. <br>2) <strong>Expansion rules</strong> — expansion includes upstream queries with <code>Propagation=Required</code> semantics; optional upstream queries with <code>Propagation=Optional</code> are included only if their <code>LastRefreshedTs</code> is older than a threshold or <code>forceRefreshUpstream=True</code>. <br>3) <strong>Cycle detection</strong> — before executing, validate the DAG for cycles and abort with <code>PQ_ERR_007</code> if cycles detected; provide helpful artifact showing cycle path. <br>4) <strong>Minimal refresh set</strong> — when source snapshots indicate unchanged upstream data (via <code>LastSourceChecksum</code> metadata), allow pruning of upstream refreshes to speed runs; document that this optimization trades strict determinism for performance and must be gated by <code>AllowPrunedRefresh</code> feature flag. <br>5) <strong>Idempotency & parity</strong> — include <code>PQ_VERSION</code> and <code>CONFIG_HASH</code> in <code>RefreshResult</code> to support golden-parity checks; when DAG or PQ changes are deployed, CI must run golden-file comparisons for outputs. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Concurrency model & queueing semantics</strong><br>1) <strong>Module-level mutex</strong> — <code>IsRefreshing As Boolean</code> and <code>RefreshQueue As Collection</code> implement serialized refresh semantics. <br>2) <strong>QueuePolicy options</strong> — <code>fifo</code> (default) -> enqueue; <code>reject</code> -> immediate <code>IMP_PQ_BUSY</code> return; <code>coalesce</code> -> merge new request into last queued when new queryList is superset; <code>cancelOnNew</code> -> cancel current queued ones and run new. <br>3) <strong>Preemption</strong> — explicit <code>CancelRequested</code> boolean can be set by UI or operator; cooperative cancellation must be checked at safe checkpoints and when polling host refresh flags. <br>4) <strong>Worker offload</strong> — for very large or long refreshes, <code>modPQController</code> can produce a <code>JobDescriptor</code> and hand off to a worker process; in that case return <code>RefreshResult</code> with <code>partial=True</code> and <code>jobId</code> and persist the intended <code>queryList</code> and <code>configHash</code> for the worker to execute. <br>5) <strong>Callback & event pattern</strong> — support callback registration for async completions; ensure callbacks run on the main Excel thread via <code>Application.Run</code> or a safe dispatch mechanism to avoid cross-thread COM errors. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Refresh invocation patterns across hosts</strong><br>1) <strong>Windows desktop Excel (COM)</strong> — preferred flow: use <code>Workbook.Queries(queryName).Refresh</code> or <code>Workbook.Connections(connectionName).Refresh</code> and poll <code>WorkbookConnection.Refreshing</code> or <code>QueryTable.Refreshing</code> attributes. Capture <code>QueryName</code> => <code>ListObject</code> mapping via <code>Workbook.ListObjects</code> to produce <code>outputTableName</code>. <br>2) <strong>Excel for Mac / Excel Online</strong> — limited API surface; detect host via <code>Application.OperatingSystem</code> and return <code>PQ_ERR_004</code> for unsupported operations or route to worker automation that performs the refresh on Windows host. <br>3) <strong>Power BI / XMLA</strong> — for scenarios where PQ feeds a Power BI dataset, consider using server-side refresh APIs when available; provide <code>PluggableRefreshInvoker</code> abstraction to allow future backend connectors. <br>4) <strong>Data Model interactions</strong> — when PQ outputs are loaded to the Data Model, ensure the module waits for <code>Workbook.Model.Refreshing</code> to clear and include <code>dataModelRows</code> in <code>refreshedQueries</code> metadata. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Polling, timeouts, backoff, and jitter</strong><br>1) <strong>Default poll interval</strong> — 250 ms initial poll, with exponential backoff sequence 250 ms -> 500 ms -> 1000 ms -> 2000 ms -> 4000 ms, capped by <code>REFRESH_TIMEOUT_MS</code> from <code>GetConfig()</code>. <br>2) <strong>Timeout policy</strong> — <code>REFRESH_TIMEOUT_MS</code> must be >= 1000 ms; if host returns <code>Refreshing</code> beyond the timeout, set query error <code>PQ_ERR_002</code> (timeout) and attempt one host-cancel + one retry before final failure. <br>3) <strong>Jitter & resilience</strong> — apply ±25% jitter to backoff intervals to reduce reconnection storms when many clients simultaneously poll. <br>4) <strong>Cancellation response</strong> — if <code>CancelRequested</code> is True during polling, attempt host-cancel and mark query <code>PQ_ERR_005</code> (cancellation) in <code>RefreshResult</code>; for async flows invoke callbacks with <code>partial=True</code> and cancellation marker. <br>5) <strong>Progress telemetry</strong> — emit <code>pq.refresh.progress{query,currentIndex,total,durationMs}</code> at coarse-grained checkpoints (e.g., every N queries or on query finish) and avoid emitting high-frequency progress to limit telemetry noise. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Retry strategy & classification</strong><br>1) <strong>One-shot retry rule</strong> — for transient connection/auth errors and transient network issues, attempt one automatic retry after a short backoff (1–2s). <br>2) <strong>No retry for deterministic errors</strong> — do not retry PQ expression errors (syntax, type mismatch) that are likely to require developer fix; classify them as <code>PQ_ERR_001</code>. <br>3) <strong>Escalation</strong> — if automatic retry fails, mark query failed with <code>PQ_ERR_003</code> or <code>PQ_ERR_002</code> and include machine-readable remediation hints and a suggested operator action (e.g., "check credentials", "increase REFRESH_TIMEOUT_MS"). <br>4) <strong>Retry limits</strong> — globally cap retries per run to avoid runaway loops; configurable via <code>modConfig</code> keys like <code>PQ_MAX_RETRIES</code>. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Error taxonomy & remediation guidance</strong><br>1) <code>PQ_ERR_001</code> — PQ expression/runtime error (M evaluation failure). Remediation: open Power Query Editor, inspect failing step, fix expression, re-run targeted refresh. <br>2) <code>PQ_ERR_002</code> — Timeout. Remediation: increase <code>REFRESH_TIMEOUT_MS</code>, optimize query to preserve folding, or offload to worker. <br>3) <code>PQ_ERR_003</code> — Connection/auth failure. Remediation: validate credentials, retrieve secrets from store, rotate keys or refresh tokens. <br>4) <code>PQ_ERR_004</code> — Host unsupported. Remediation: run on Windows desktop Excel or implement worker-based refresh. <br>5) <code>PQ_ERR_005</code> — Cancelled by operator. Remediation: re-run or schedule a worker job. <br>6) <code>PQ_ERR_006</code> — Schema mismatch / parse failure (unexpected column types or layout). Remediation: update <code>modPreflight</code> schema expectations or adapt PQ outputs; persist schema diff artifact and suggested code changes. <br>7) <code>IMP_PQ_002</code> — PQ_VERSION mismatch detected between <code>modConfig</code> and PQ parameter contract. Remediation: coordinate PQ/M module changes, run golden-parity CI tests. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Structured telemetry & ImportLog contract</strong><br>1) <strong>Primary telemetry events</strong> — <code>pq.refresh.started{queries,jobId,configHash,pqVersion,operatorId}</code>, <code>pq.refresh.progress{query,currentIndex,total,durationMs}</code>, <code>pq.refresh.completed{queriesCount,durationMs,success}</code>, <code>pq.refresh.error{query,errorCode,errorText,jobId}</code>, <code>pq.refresh.timeout{query,timeoutMs}</code>. <br>2) <strong>Telemetry fields</strong> — always include <code>jobId</code>, <code>correlationId</code>, <code>configHash</code>, <code>pqVersion</code>, <code>operatorId</code>, and <code>host</code> to enable multi-dimensional diagnostics. <br>3) <strong>Evidence artifacts</strong> — for regulated runs create <code>RefreshResult</code> JSON and store to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\pq_refresh_&lt;timestamp&gt;.json</code> with <code>sha256</code> checksum and a corresponding <code>ImportLog</code> row recording <code>evidenceRef</code>. <br>4) <strong>Privacy</strong> — redact or hash connection strings and file paths in telemetry; include <code>connectionFingerprint</code> instead of raw credentials. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Per-query explainability & metadata capture</strong><br>1) <strong>Component timings</strong> — collect handshake, query folding, local transformation, and serialization times where available and include them in per-query metadata to help diagnose slow steps. <br>2) <strong>Rows & schema hash</strong> — capture <code>rowsReturned</code> and compute <code>schemaHash</code> (stable serialization of column names+types) for golden-parity comparisons. <br>3) <strong>QueryDefinitionHash</strong> — compute a deterministic hash of the query definition (M text) at refresh time and include in <code>refreshedQueries</code> to enable deterministic replays in CI. <br>4) <strong>LastRefreshedTs & SourceChecksum</strong> — persist timestamps and upstream source checksum (if available) to determine whether upstream data changed between runs. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Integration patterns with other modules</strong><br>1) <strong>modConfig</strong> — read <code>REFRESH_TIMEOUT_MS</code>, <code>PQ_VERSION</code>, <code>PQ_PARAMETER_OVERRIDES</code>, and <code>CONFIG_HASH</code> from <code>GetConfig()</code> and include them in telemetry; abort with <code>IMP_PQ_002</code> if <code>PQ_VERSION</code> mismatch unless forced. <br>2) <strong>modPreflight</strong> — refresh pipeline should ensure <code>PQ_Preflight</code> is refreshed prior to invoking <code>modPreflight.RunPreflight</code>; <code>modPQController</code> returns <code>refreshedQueries</code> metadata so <code>modPreflight</code> can locate <code>PREFLIGHT_TABLE_NAME</code>. <br>3) <strong>modUtilities</strong> — use <code>modUtilities.LogAction</code> for ImportLog writes, <code>ComputeFileChecksum</code> for persisted <code>RefreshResult</code> artifacts, and <code>Retry</code> helper for robust host calls. <br>4) <strong>frmOperatorUI</strong> — expose a <code>Refresh</code> button that triggers <code>RefreshQueriesAsync</code> and subscribes to callbacks; display <code>RefreshResult</code> summary and provide "open evidence" link to <code>evidenceRef</code>. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Conceptual Power Query guidance (for PQ authors)</strong><br>1) <strong>Design for folding</strong> — push filtering and aggregation to the data source where possible to reduce network and memory load; record in <code>PQ_Dependencies</code> whether a query preserves folding to inform performance decisions. <br>2) <strong>Stable schema contracts</strong> — PQ queries that feed VBA must expose stable header columns and types; if schema changes are required, bump <code>PQ_VERSION</code> and capture migration steps in <code>migration_manifest.json</code>. <br>3) <strong>Parse-safe outputs</strong> — include <code>ParseSuccess</code> and <code>ParseErrorReason</code> fields for dates/numbers rather than relying on silent coercion. <br>4) <strong>Parameterize transforms</strong> — expose localization and date-order parameters via <code>Settings</code> sheet to let modPQController update parameters before refresh without editing M. <br>5) <strong>Small, composable views</strong> — prefer intermediate deterministic views (e.g., <code>PQ_Normalized</code>) that are easy to test and to compute <code>QueryDefinitionHash</code> for CI comparisons. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance for PQ telemetry</strong><br>1) <strong>Dimensions to capture</strong> — <code>ConfigHash</code>, <code>PQVersion</code>, <code>JobId</code>, <code>OperatorId</code>, <code>QueryName</code>, <code>RefreshDate</code>, <code>Host</code>, <code>Environment</code> to allow slice-and-dice. <br>2) <strong>Key measures</strong> — <code>PQRefreshSuccessRate = DIVIDE(CALCULATE(COUNTROWS(RefreshResults), RefreshResults[Success]=TRUE), COUNTROWS(RefreshResults), 0)</code>.<br>3) <strong>Performance measures</strong> — <code>AverageRefreshTime = AVERAGE(RefreshResults[durationMs])</code>, <code>MedianQueryTimeByName</code>, <code>TimeoutRate = COUNTROWS(FILTER(RefreshResults, RefreshResults[ErrorCode]=&quot;PQ_ERR_002&quot;)) / COUNTROWS(RefreshResults)</code>. <br>4) <strong>Alerting & SLOs</strong> — create alerts when <code>PQRefreshSuccessRate</code> falls below SLO or when <code>AverageRefreshTime</code> increases by threshold relative to historical baseline for a given <code>PQVersion</code>. <br>5) <strong>Root-cause correlation</strong> — correlate <code>PQVersion</code> and <code>ConfigHash</code> with <code>TimeoutRate</code> and <code>SchemaMismatchRate</code> to detect regressions introduced by config or PQ changes. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Testing & QA matrix for modPQController</strong><br>Unit tests:<br>1) Validate <code>RefreshResult</code> assembly for single query success and failure scenarios. <br>2) Simulate PQ expression errors and ensure classification as <code>PQ_ERR_001</code>. <br>3) Timeout simulation: ensure <code>PQ_ERR_002</code> produced after configured <code>REFRESH_TIMEOUT_MS</code>. <br>4) Queue policy tests: concurrent refresh requests when <code>IsRefreshing</code> True produce expected <code>IMP_PQ_BUSY</code> or queue behavior depending on <code>SetQueuePolicy</code>. <br>Integration tests:<br>1) Small end-to-end pipeline: <code>PQ_Raw</code> -> <code>PQ_Preflight</code> -> <code>modPreflight.RunPreflight</code> with canonical fixture data; verify <code>refreshedQueries</code> metadata and <code>CONFIG_HASH</code> persistence. <br>2) Large dataset run: measure <code>durationMs</code>, ensure <code>RefreshQueriesAsync</code> leaves UI responsive, and persist <code>RefreshResult</code> evidence. <br>Chaos tests:<br>1) Simulate transient network partitions and verify single retry and backoff behavior. <br>2) Simulate PQ_VERSION mismatch and ensure <code>IMP_PQ_002</code> blocks refresh. <br>Acceptance tests:<br>1) For any change to PQ queries or to <code>PQ_VERSION</code>, run CI golden-file suite and verify checksums for canonical fixtures; require manual approval on diffs. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Observability examples (ImportLog event samples)</strong><br>1) <code>pq.refresh.started{queries:[&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;],jobId:&quot;job-20260220-001&quot;,configHash:&quot;sha256:abcd&quot;,pqVersion:&quot;v1.3.2&quot;,ts:&quot;2026-02-20T09:00:00Z&quot;}</code>.<br>2) <code>pq.refresh.progress{query:&quot;PQ_Raw&quot;,currentIndex:1,total:2,durationMs:1200,ts:&quot;2026-02-20T09:00:01Z&quot;}</code>.<br>3) <code>pq.refresh.completed{queriesCount:2,durationMs:2600,success:true,jobId:&quot;job-20260220-001&quot;,ts:&quot;2026-02-20T09:00:03Z&quot;}</code>.<br>4) <code>pq.refresh.error{query:&quot;PQ_Mapping&quot;,errorCode:&quot;PQ_ERR_001&quot;,errorText:&quot;Expression.Error: ...&quot;,remediation:&quot;Inspect PQ step &#x27;PromotedHeaders&#x27;&quot;,jobId:&quot;job-20260220-002&quot;,ts:&quot;2026-02-20T10:12:22Z&quot;}</code>. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Edge cases & defensive behaviors</strong><br>1) <strong>Cycle in PQ_Dependencies</strong> — detect and abort with <code>PQ_ERR_007</code> and a cycle artifact listing the cycle path and affected queries. <br>2) <strong>Schema drift</strong> — when a refreshed query yields unexpected columns, emit <code>PQ_ERR_006</code> with <code>schemaDiff</code> artifact showing previous vs current column set and suggest <code>PREFLIGHT_TABLE_NAME</code> expectation updates. <br>3) <strong>Mapped drive in service account</strong> — detect mapped-drive paths and warn <code>config.warn</code> recommending UNC path; scheduled runs should refuse mapped drives by default. <br>4) <strong>Host API partial support</strong> — when a host reports incomplete refresh state indicators, fall back to <code>RefreshAll</code> with caution and log <code>PQ_WARN_PARTIAL_HOST_FEATURES</code>. <br>5) <strong>Large row counts</strong> — if <code>rowsReturned</code> exceeds <code>MAX_PREVIEW_ROWS</code>, recommend worker offload and set <code>RefreshResult.warning</code> to inform operator. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Security & privacy considerations</strong><br>1) <strong>Do not log secrets</strong> — never include credentials, tokens, or raw connection strings in telemetry or artifacts; use <code>connectionFingerprint</code> hash instead. <br>2) <strong>Least privilege</strong> — recommend service accounts for automated refreshes use least privilege and scoped credentials. <br>3) <strong>Evidence access controls</strong> — persisted <code>RefreshResult</code> artifacts in <code>STAGING_ARCHIVE_FOLDER</code> must inherit ACLs and be subject to <code>ARCHIVE_RETENTION_DAYS</code> retention policy; modPQController records <code>evidenceRef</code> but delegates encryption and ACL enforcement to <code>modUtilities</code>. <br>4) <strong>Credential rotation</strong> — when auth errors occur, log <code>credentialHint</code> but not secrets and prompt operator to refresh credentials using secure store adapter <code>modUtilities.GetSecretFromStore</code>. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Developer guidelines & recommended code structure</strong><br>1) Keep <code>modPQController</code> focused on orchestration and avoid implementing PQ transformation logic in VBA. <br>2) Use clear, stable variable names: <code>IsRefreshing</code>, <code>RefreshQueue</code>, <code>CancelRequested</code>, <code>RefreshResult</code>, <code>PQ_DependenciesCache</code>, <code>LastRefreshedMap</code>. <br>3) Encapsulate host-specific implementations behind <code>IRefreshInvoker</code>-like function group (e.g., <code>InvokeRefresh_COM</code>, <code>InvokeRefresh_OfficeJS</code>, <code>InvokeRefresh_Worker</code>) and select at runtime based on <code>HostCompatibility</code>. <br>4) Use <code>Scripting.Dictionary</code> for fast lookup and <code>Collection</code> for ordered lists; always validate presence when indexing. <br>5) Centralize telemetry emission through <code>modUtilities.LogAction</code> with a small wrapper <code>EmitPQTelemetry(action As String, payload As Dictionary)</code> to reduce duplication. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Change-control & CI/CD gating</strong><br>1) Any change to <code>PQ_VERSION</code>, <code>PQ_Dependencies</code>, or query definitions MUST be accompanied by a <code>migration_manifest.json</code> entry explaining the change, the expected behavioral difference, and sign-offs. <br>2) CI must execute a canonical fixture suite that runs the PQ refresh in a sandbox and compares <code>refreshedQueries</code> checksums (rows+schemaHash) against golden files. <br>3) If golden-file diffs occur, require manual review and a two-person approval before allowing the change to progress to production. <br>4) Tag release artifacts with <code>CONFIG_HASH</code> and <code>PQ_VERSION</code> to support rollbacks. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Operational runbook (concise actions & triage)</strong><br>1) <strong>Normal operation</strong> — operator triggers <code>RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> from UI, monitor <code>ImportLog</code> for <code>pq.refresh.completed</code>, then continue to <code>modPreflight.RunPreflight</code>. <br>2) <strong>On PQ expression error (<code>PQ_ERR_001</code>)</strong> — open Power Query Editor, reproduce failing query, fix M step, run targeted refresh. <br>3) <strong>On timeout (<code>PQ_ERR_002</code>)</strong> — check source performance, increase <code>REFRESH_TIMEOUT_MS</code> if appropriate, or offload to worker with <code>JobDescriptor</code>. <br>4) <strong>On host unsupported (<code>PQ_ERR_004</code>)</strong> — move operation to Windows desktop Excel or configure worker automation. <br>5) <strong>If repeated partial failures</strong> — export <code>RefreshResult</code> artifact and <code>ImportLog</code>, attach to issue tracker and escalate to PQ developer with <code>evidenceRef</code>. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Extensibility & future-proofing</strong><br>1) <strong>Pluggable invokers</strong> — design <code>RefreshInvoker</code> abstraction to support future backends (Power BI REST, XMLA, headless Excel automation) with same <code>RefreshResult</code> contract. <br>2) <strong>Worker-friendly payloads</strong> — provide <code>GetWorkerConfigSubset()</code> producing small, non-PII job descriptors containing <code>queryList</code>, <code>configHash</code>, <code>pqVersion</code>, and parameter overrides that worker processes can consume. <br>3) <strong>Feature flags</strong> — include <code>FEATURE_FLAGS</code> in <code>GetConfig()</code> to gate experimental behaviors like <code>EnableParallelRefresh</code> or <code>AllowPrunedRefresh</code>. <br>4) <strong>Observability hooks</strong> — allow external monitoring agents to register a lightweight webhook for <code>pq.refresh.completed</code> events for real-time alerts. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Developer checklist before merging changes</strong><br>1) Add or update <code>PQ_Dependencies</code> manifest if queries or their relationships changed. <br>2) Run unit and integration tests that simulate successful and failing refreshes. <br>3) Run CI canonical fixture suite; verify <code>CONFIG_HASH</code> and <code>PQ_VERSION</code> parity and golden-file checksums. <br>4) Update <code>migration_manifest.json</code> for any behavioral or output changes and obtain required approvals. <br>5) Confirm telemetry does not contain raw secrets or PII and that <code>RefreshResult</code> artifacts are persisted with checksum and evidenceRef. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Common pitfalls & recommended mitigations</strong><br>1) <strong>Silent PQ coercions cause data drift</strong> — mitigate by adding <code>ParseSuccess</code> flags in PQ and failing preflight on ambiguous conversions. <br>2) <strong>Running on unsupported host</strong> — detect host early and route to worker automation; do not attempt unsupported COM calls. <br>3) <strong>Concurrent Refresh corrupting ListObjects</strong> — always use <code>IsRefreshing</code> mutex and queue policy; prefer <code>coalesce</code> policy where multiple high-frequency UI refreshes occur. <br>4) <strong>Unbounded retries</strong> — implement sane retry caps and telemetry for retries to prevent live-site degradations. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Examples & operator narratives (scenario-driven)</strong><br>Example 1 — small job, happy path:<br>1) Operator clicks "Refresh" in <code>frmOperatorUI</code> -> UI calls <code>RefreshQueriesAsync([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;], &quot;OnRefreshComplete&quot;)</code> with <code>TimeoutMs</code> from <code>GetConfig()</code>.<br>2) <code>modPQController</code> expands dependencies, obtains mutex, writes <code>pq.refresh.started</code> telemetry, runs targeted COM refreshes, polls <code>Connection.Refreshing</code> until completion, computes <code>RefreshResult</code> and writes <code>pq.refresh.completed</code>, stores <code>RefreshResult</code> JSON in archive with <code>sha256</code>, and invokes <code>OnRefreshComplete(RefreshResult)</code>.<br>Example 2 — PQ expression error:<br>1) Refresh fails for <code>PQ_Mapping</code> with <code>Expression.Error</code> -> <code>modPQController</code> classifies <code>PQ_ERR_001</code>, writes <code>pq.refresh.error</code> with <code>errorText</code>, persists <code>RefreshResult</code> with <code>failedQueries</code> details, and returns <code>partial=True</code> to caller. Operator opens PQ editor, fixes the M step, and re-runs targeted refresh. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Final runtime verification checklist</strong><br>1) <code>GetConfig()</code> was read and <code>PQ_VERSION</code> validated before starting refresh; if mismatch, operator was required to confirm override. <br>2) <code>IsRefreshing</code> mutex prevented concurrent destructive refreshes; queue behaved according to configured <code>QueuePolicy</code>. <br>3) <code>RefreshResult</code> contains per-query <code>rowsReturned</code>, <code>schemaHash</code>, <code>QueryDefinitionHash</code>, <code>durationMs</code>, and error objects where present. <br>4) All telemetry rows include <code>configHash</code>, <code>pqVersion</code>, <code>jobId</code>, and <code>operatorId</code> when UI-driven. <br>5) Evidence artifact <code>RefreshResult</code> JSON is stored in <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;</code> and <code>ImportLog</code> holds <code>evidenceRef</code> and <code>sha256</code> checksum for chain-of-custody. </td></tr><tr><td data-label="modPQController — Per-function technical breakdown (VBA)"> <strong>Closing implementation guidance</strong><br>Implement modPQController as a compact, well-tested orchestration module that focuses on deterministic refresh coordination, conservative retry/backoff logic, robust error classification, and rich telemetry. Keep PQ transformation in M queries, maintain an explicit dependency manifest, and enforce CI golden-parity gating whenever PQ or config changes affect serialized outputs. Design with pluggable refresh invokers and worker offload hooks so large workloads can be migrated to headless automation without rewriting orchestration logic. </td></tr></tbody></table></div><div class="row-count">Rows: 29</div></div><div class="table-caption" id="Table5" data-table="YJKN_0017_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modPreflight — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modPreflight — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Executive summary & purpose</strong><br>modPreflight is the deterministic, idempotent, auditable row-level validation and normalization engine for the IMPORT DATA pipeline. It consumes the PQ-normalized raw view (<code>tblRawImport</code> / <code>PQ_Preflight</code>), applies a comprehensive suite of field-level and cross-field business rules, assigns machine-readable validation tags and human remediation hints, groups duplicates deterministically, computes outlier signals, and produces an atomic <code>PREFLIGHT_TABLE_NAME</code> output for downstream steps (batching, scoring, candidate-matching). modPreflight must preserve original raw values for evidence, avoid silent coercions, operate in a chunked/streaming-friendly manner for large datasets, and emit rich telemetry and evidence artifacts suitable for CI gating and forensic audit. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>High-level functional contract</strong><br>1) <code>RunPreflight(jobId, options) As PreflightResult</code> — orchestrates full preflight for the provided job and returns a structured <code>PreflightResult</code> including counts, tag summaries, evidenceRef, duration, and error collection. <br>2) <code>NormalizeDateText(rawText, localeHint) As DateParseResult</code> — deterministic date parser that prefers explicit formats and returns <code>{parsedDateISO, parseStatus, reasonTag, canonicalForm}</code> without guessing ambiguous orders. <br>3) <code>NormalizeNameText(rawName, nameRulesRef) As NameNormalizationResult</code> — canonicalizes name strings (whitespace, control-chars, Unicode normalization, capitalization rules) while preserving the original value in <code>Raw_Name</code>. <br>4) <code>ValidateNIK(nikText) As NIKValidationResult</code> — robust NIK validator: presence, numeric-only, length==16, optional checksum heuristic, returns <code>{isValid,tags,hint}</code>. <br>5) <code>DetectDuplicates(tbl, keySpec) As DuplicateGroups</code> — deterministic duplicate and near-duplicate detection producing <code>dupGroupId</code>, <code>dupScore</code>, and <code>dupReason</code>. <br>6) <code>ComputeOutlierFlags(numericColumn, method, params) As OutlierReport</code> — streaming outlier detection supporting multiple algorithms (MAD, IQR, z-score, trimmed mean) and returns <code>{outlierTags,score,thresholds}</code>. <br>7) <code>WritePreflightAtomically(tempRange, finalTableName) As Boolean</code> — safely atomically swaps the computed preflight result into <code>PREFLIGHT_TABLE_NAME</code> to avoid partial views. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Primary design invariants & guarantees</strong><br>1) <strong>Determinism:</strong> identical input rows and identical config (<code>CONFIG_HASH</code>, <code>PQ_VERSION</code>) must yield identical preflight outputs including <code>dupGroupId</code> assignments and <code>Checks</code> tag ordering. <br>2) <strong>Idempotency:</strong> repeated runs on unchanged input produce the same <code>tblPreflight</code> and same evidence artifacts unless <code>forceEvidenceSnapshot</code> is set. <br>3) <strong>Non-destructive:</strong> <code>tblRawImport</code> is never mutated; all helper/normalized fields are written to temporary sheets and then atomically swapped into final <code>PREFLIGHT_TABLE_NAME</code>. <br>4) <strong>Fail-fast:</strong> missing mandatory columns or gross config errors cause <code>RunPreflight</code> to abort with <code>IMP_PF_001</code> and a structured <code>PreflightResult</code> containing expected header template and remediation steps. <br>5) <strong>PII-aware:</strong> <code>RemediationHint</code> text and logs avoid raw PII unless operator has explicit audit clearance; evidence snapshots are stored encrypted/ACL-restricted when required. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Inputs & outputs (explicit)</strong><br>Inputs:<br>1) <code>tblRawImport</code> (ListObject or PQ-produced sheet) — expected canonical columns (NIK, Nama, TglLahir, TglMulai, Upah, ...). <br>2) <code>jobId</code> — correlation for telemetry and evidence artifact names. <br>3) <code>configSnapshot</code> — <code>GetConfig()</code> dictionary controlling thresholds and behavior (e.g., <code>UPAH_MAX_THRESHOLD</code>, <code>OUTLIER_MULTIPLIER</code>, <code>DEFAULT_DATE_FORMAT</code>, <code>MAX_PREVIEW_ROWS</code>, <code>PQ_VERSION</code>). <br>4) <code>options</code> — optional run-time toggles (e.g., <code>evidenceSnapshot:Boolean</code>, <code>chunkSize:Int</code>, <code>duplicateStrategy:String</code>). <br>Outputs:<br>1) <code>tblPreflight</code> — atomically-written ListObject containing original raw columns plus deterministic helper columns: <code>Checks</code>, <code>RemediationHint</code>, <code>dupGroupId</code>, <code>dupScore</code>, <code>ParseAudit</code>, <code>Normalized_*</code> columns, <code>preflightStatus</code> (Passed/Flagged), <code>evidenceRef</code> (if produced). <br>2) <code>PreflightResult</code> — structured return with <code>rowsProcessed</code>, <code>rowsFlagged</code>, <code>tagCounts</code>, <code>dupGroups</code>, <code>evidenceRef</code>, <code>durationMs</code>, and <code>errors</code>. <br>3) <code>ImportLog</code> telemetry rows: <code>preflight.summary</code>, <code>preflight.block.completed</code>, <code>preflight.exception</code>, <code>preflight.evidence.created</code>. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Core rule set — exhaustive checks</strong><br>Header & schema checks:<br>1) <code>HeaderPresence</code> — verify required columns exist; missing -> <code>IMP_PF_001</code> and abort with expected header template.<br>2) <code>ColumnTypeHints</code> — respect PQ-provided parse flags; if PQ reports parse success for a date or number, preflight uses that as high-confidence input. <br>NIK checks:<br>1) <code>NIK_EMPTY</code> — missing NIK.<br>2) <code>NIK_NONNUMERIC</code> — contains non-digit after normalization.<br>3) <code>NIK_LEN</code> — normalized length != 16.<br>4) <code>NIK_CHECKSUM_FAIL</code> — optional checksum heuristic fails when the jurisdiction provides checksum rules.<br>Name checks:<br>1) <code>NAME_EMPTY</code> — empty name field.<br>2) <code>NAME_INVALID_CHARS</code> — found forbidden control chars or emojis where disallowed.<br>3) <code>NAME_TOO_LONG</code> — > <code>MAX_NAME_LEN</code> and truncated in UI display.<br>Date checks:<br>1) <code>TGL_INVALID</code> — unparseable date.<br>2) <code>TGL_AMBIGUOUS</code> — ambiguous ordering (e.g., <code>01/02/03</code>) without <code>localeHint</code> or PQ certainty.<br>3) <code>TGL_ORDER</code> — cross-field logic: <code>TglLahir</code> >= <code>TglMulai</code> or birth date in future -> flagged.<br>Numeric / salary checks:<br>1) <code>UPAH_INVALID</code> — non-numeric or negative values.<br>2) <code>UPAH_OUTLIER</code> — flagged based on configured outlier detection method and thresholds.<br>Duplicate detection:<br>1) <code>DUPLICATE_NIK</code> — exact NIK duplicates; members assigned same <code>dupGroupId</code> deterministically.<br>2) <code>POSSIBLE_DUPLICATE</code> — near-duplicates using token-jaccard/trigram/levenshtein heuristics; include <code>dupScore</code> and <code>dupReason</code> (tokens matched, birthdate match, etc.).<br>Parsing & PQ interplay:<br>1) <code>PQ_PARSE_FAILED</code> — if PQ indicated parse failure then preflight must tag and provide remediation rather than auto-coerce. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Checks column format & severity ordering</strong><br><code>Checks</code> is a semicolon-delimited list of machine tags ordered by severity (Fatal, High, Medium, Low) where the order is deterministic: Fatal tags first, then High, then Medium, then Low. The exact tag ordering is defined centrally in modPreflight and should be stable across runs to preserve deterministic outputs for CI/golden-parity. Examples of severity mapping:<br>1) Fatal: <code>IMP_PF_001</code>, <code>NIK_EMPTY</code>, <code>TGL_INVALID</code>.<br>2) High: <code>DUPLICATE_NIK</code>, <code>UPAH_INVALID</code>.<br>3) Medium: <code>POSSIBLE_DUPLICATE</code>, <code>NAME_LONG</code>.<br>4) Low: <code>NAME_NORMALIZED</code>, <code>TRIM_WHITESPACE_REMOVED</code>. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>RemediationHint policy & content rules</strong><br>1) <code>RemediationHint</code> must be brief (one sentence), PII-free, and actionable; include suggested steps and references to header templates or sample corrections. <br>2) Hints must avoid exposing full sensitive values; for example show masked NIK <code>************1234</code> if needed for operator context only when their audit role allows it. <br>3) Hints must include linkable doc references in README format (e.g., "See docs/header_template.csv") for operator triage flows. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Normalization rules & auditability</strong><br>Name normalization:<br>1) Trim leading/trailing whitespace and collapse multiple internal whitespace to single spaces; log <code>NAME_NORMALIZED_WHITESPACE</code> in <code>ParseAudit</code>.<br>2) Remove control characters and zero-width characters; log <code>NAME_CONTROL_CHARS_REMOVED</code> and include removed codepoints list in <code>ParseAudit</code> for forensic review.<br>3) Apply Unicode normalization form NFKC to collapse compatibility variants before tokenization; record <code>UNICODE_NFKC</code> in <code>ParseAudit</code>.<br>4) Apply Title Case with a configurable <code>Acronyms</code> whitelist to preserve items like "PT", "CV", or well-known acronyms; do not alter all-caps tokens that appear in a maintained <code>Acronyms</code> table.<br>Date normalization & parsing (<code>NormalizeDateText</code>):<br>1) Conservative parsing: attempt formats in deterministic order: ISO <code>YYYY-MM-DD</code> -> <code>YYYY/MM/DD</code> -> <code>YYYYMMDD</code> -> <code>DD/MM/YYYY</code> or <code>MM/DD/YYYY</code> (only if <code>localeHint</code> or PQ <code>ParseSuccess</code> indicates) -> fallback to explicit parser algorithms.<br>2) Remove ordinal suffixes and common textual noise (e.g., <code>st</code>, <code>nd</code>, <code>rd</code>, <code>th</code>) and strip time components unless time is domain-relevant.<br>3) If ambiguity remains (e.g., <code>01/02/03</code>) and no <code>localeHint</code>, tag <code>TGL_AMBIGUOUS</code> and return <code>parseStatus=AMBIGUOUS</code> with <code>remediationHint</code> advising ISO input.<br>4) Always return canonical ISO <code>yyyy-mm-dd</code> for deterministic downstream use. <br>NIK normalization:<br>1) Remove non-digit separators (spaces, dashes, periods) as part of normalization while preserving original <code>Raw_NIK</code>. <br>2) Preserve leading zeros and ensure normalized string length equals 16; if not, tag <code>NIK_LEN</code>. <br>3) Optional checksum: if jurisdictional rule available, compute and validate checksum (document algorithm in README) and tag <code>NIK_CHECKSUM_FAIL</code> if invalid. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Duplicate & fuzzy-match algorithms (detailed)</strong><br>Primary (deterministic exact):<br>1) Exact normalized NIK match -> <code>DUPLICATE_NIK</code>. <br>2) On match, assign <code>dupGroupId</code> deterministically by sorting matched rows by <code>(NormalizedName, TglLahirISO, RawRowIndex)</code> and computing a stable group id (e.g., hashed canonical tuple). <br>Secondary (composite exact):<br>1) If NIK missing, compute composite key = <code>NormalizedName + TglLahirISO + TglMulai</code> and match exact composite keys for duplicates. <br>Fuzzy near-duplicate (deterministic scoring):<br>1) Tokenization: split <code>NormalizedName</code> into tokens after removing stopwords and common titles; lower-case tokens and deduplicate. <br>2) Token Jaccard = <code>|I| / |U|</code>; trigram Jaccard = trigram-set intersection / union. <br>3) LevenshteinNormalized = 1 - (levenshteinDistance / maxLen). <br>4) Combined dupScore = weightedSum( w1<em>tokenJaccard + w2</em>trigramJaccard + w3<em>levenshteinNormalized + w4</em>birthdateMatch + w5*addressMatch ) with weights configured via <code>GetConfig()</code>. <br>5) Thresholds: <code>dupScore &gt;= autoAcceptThreshold</code> -> auto-merge candidate; <code>dupScore &gt;= reviewThreshold</code> -> <code>POSSIBLE_DUPLICATE</code> flagged for manual review; else no match. <br>Tie-breaking: deterministic ordering of candidates by <code>(dupScore desc, NormalizedName asc, RawRowIndex asc)</code>. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Outlier detection algorithms (choices & guidance)</strong><br>Supported methods (selectable via <code>GetConfig()</code>):<br>1) <strong>Median Absolute Deviation (MAD):</strong> robust to heavy-tailed distributions; compute median, then MAD = median(<code>|x - median|</code>); outlier if <code>|x - median|</code> / (1.4826 x MAD) > threshold. <br>2) <strong>IQR-based rule:</strong> compute Q1, Q3, IQR = Q3 - Q1; outlier if x < Q1 - k<em>IQR or x > Q3 + k</em>IQR (common k=1.5 for mild, 3 for extreme). <br>3) <strong>Z-score (mean/std)</strong> using Welford streaming algorithm for stable variance; outlier if <code>|z|</code> > threshold where z = (x - mean)/std. <br>4) <strong>Trimmed-mean / Percentile-based:</strong> compute robust center by trimming top/bottom p% and compute threshold as center * OUTLIER_MULTIPLIER for positive-only numeric attributes (e.g., salary). <br>Selection guidance:<br>1) Use MAD or IQR for skewed distributions like salaries; prefer IQR for very large datasets where percentiles are cheap to compute with streaming approximate quantiles. <br>2) For small sample sizes (< nMinForStableStats), use conservatively larger thresholds or flag as <code>DATA_TOO_SMALL_FOR_OUTLIER_DETECTION</code>. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Atomic write & concurrency model (detailed)</strong><br>1) Compute full preflight output in temporary in-memory arrays or a temporary worksheet called <code>tempPreflight_&lt;jobId&gt;</code> to avoid exposing partial results. <br>2) On success, perform atomic swap: rename existing <code>PREFLIGHT_TABLE_NAME</code> to <code>PREFLIGHT_TABLE_NAME_old_&lt;ts&gt;</code> and rename <code>tempPreflight_&lt;jobId&gt;</code> to <code>PREFLIGHT_TABLE_NAME</code> in a quick sequence. <br>3) If rename fails, attempt rollback: if <code>PREFLIGHT_TABLE_NAME_old_&lt;ts&gt;</code> exists, rename back to <code>PREFLIGHT_TABLE_NAME</code> and log <code>pf.atomic.swap.rollback</code>. <br>4) Concurrency controls: workbook-level boolean <code>IsPreflightRunning</code> or Application-level NamedRange mutex; if <code>IsPreflightRunning</code> True then <code>RunPreflight</code> returns <code>IMP_PF_009</code> with diagnostics. <br>5) Cancellation: support cooperative cancel token <code>CancelRequested</code> checked per <code>chunkRows</code> iterations (default check every 500 rows). On cancel, abort gracefully, persist telemetry (partial <code>preflight.summary</code> with <code>status: Cancelled</code>) and keep deterministic partial snapshot for triage. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Evidence snapshots & chain-of-custody</strong><br>1) Evidence snapshot generation is optional but required for regulated runs; when enabled create <code>evidence_{jobId}_preflight_{configHash}.csv</code> using <code>modUtilities.WriteUtf8FileAtomic()</code> to <code>STAGING_ARCHIVE_FOLDER</code>. <br>2) Compute <code>SHA256</code> checksum and store in <code>ImportLog</code> row <code>preflight.evidence.created{evidenceRef,checksum,rows}</code>. <br>3) Encrypt archive if <code>UseEncryptedArchive=True</code> by invoking <code>modUtilities.SealFileWithKey(secretKeyName)</code> where the key is retrieved via <code>modUtilities.GetSecretFromStore()</code>. <br>4) Apply ACL restrictions immediately after writing: if the OS supports it, call documented OS commands or recommend operator to apply ACLs; log <code>evidence.acl.applied{evidenceRef}</code>. <br>5) Redaction: create redacted view <code>evidence_redacted_{jobId}.csv</code> withholding raw PII where policy requires; link <code>evidenceRef</code> to full artifact stored securely and link <code>evidenceRedactedRef</code> for routine audits. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Telemetry & logging (detailed schema)</strong><br>All telemetry rows include <code>timestamp</code>, <code>jobId</code>, <code>configHash</code>, <code>operatorId</code> (if UI-run), <code>durationMs</code>, and <code>correlationId</code> where available. Emitted rows include:<br>1) <code>preflight.summary{rowsProcessed,rowsFlagged,flagDistribution,topErrorTypes,dupGroups,rowsInEvidence}</code>.<br>2) <code>preflight.block.completed{jobId,blockIndex,rows,durationMs,cumulativeRows}</code>.<br>3) <code>preflight.duplicate.summary{dupGroups,duplicatedRows,possibleDuplicates}</code>.<br>4) <code>preflight.evidence.created{evidenceRef,checksum,rows,retentionDays}</code>.<br>5) <code>preflight.exception{errorCode,stack,context,jobId}</code>.<br>Telemetry policy:<br>1) Do not embed raw PII in telemetry fields; use hashed pointers or <code>evidenceRef</code> to link to encrypted artifacts. <br>2) Emit <code>configHash</code> with every row to allow slicing by configuration in reporting. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Testing & QA matrix (comprehensive)</strong><br>Unit tests (rule-level):<br>1) <code>NormalizeDateText</code> unit table: ISO, variant separators, time components, ordinal suffixes, ambiguous examples (<code>01/02/03</code>), locale-specific orders. <br>2) <code>ValidateNIK</code> tests: valid 16-digit, leading zeros, non-digit characters, length mismatches, checksum failing and passing cases. <br>3) <code>NormalizeNameText</code> tests: control char removal, unicode variants (fullwidth/halfwidth), acronym preservation, title-case exceptions. <br>4) Duplicate detector tests: exact NIK duplicate groups, composite key duplicates, near-duplicate scenarios with controlled tokenJaccard and trigram similarities; deterministic <code>dupGroupId</code> reproducibility tests. <br>Integration tests (E2E):<br>1) Canonical fixtures set: good-data run, missing columns run, ambiguous dates run, duplicate-heavy run, outlier-heavy run; verify <code>tblPreflight</code> outputs and <code>PreflightResult</code> metrics match golden fixtures. <br>2) CI golden-file parity: when <code>CONFIG_HASH</code> changes, require automated E2E runs that compare preflight artifact checksums to expected changes or fail the CI pipeline and require <code>migration_manifest</code> documentation. <br>Chaos tests:<br>1) Disk full during evidence write: verify temp <code>.tmp</code> files are deleted, <code>pf.evidence.fail</code> logged, and no incomplete final artifact present. <br>2) Host API failure (ADODB not available): fallback behavior tested and logged; verify <code>IMP_PF_010</code> host-compatibility error raised when feature missing. <br>Performance tests:<br>1) Throughput benchmarks for chunk sizes, memory consumption, and wall-time for 10k, 100k, and 1M row datasets (when offloaded to workers). </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Operator UI expectations & workflows</strong><br>1) <code>RunPreflight</code> button visible in <code>frmOperatorUI</code>; clicking disables conflicting controls and shows progress with block-level telemetry. <br>2) UI offers typed confirmations for evidence snapshot creation and retention policy choices; default <code>evidenceSnapshot=False</code> unless operator chooses regulated run. <br>3) Post-run modal shows <code>preflight.summary</code> with tappable links: filter by <code>Checks</code> tag, jump to <code>dupGroupId</code> filtered view, export flagged rows to a small edit batch. <br>4) Single-row quick re-evaluation: edits to a single row from the UI re-run deterministic checks for that row only and update <code>tblPreflight</code> accordingly without recomputing global duplicate groups unless operator requests full re-run. <br>5) Bulk remediation flow: export flagged subset -> operator edits offline -> re-import -> call <code>RunPreflight</code> with <code>resumeFrom=importBatchRef</code> to validate only modified rows and recompute duplicates deterministically. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Integration with Power Query (PQ) — conceptual & concrete guidance</strong><br>Role split and responsibilities:<br>1) <strong>Power Query (PQ)</strong>: deterministic, set-based, column-level normalization tasks that can be expressed in M and folded to source — trim, control-char removal, map small lookup tables, initial parse attempts with <code>try ... otherwise null</code>, and produce <code>PQ_Preflight</code> with <code>ParseSuccess</code> boolean columns. <br>2) <strong>VBA / modPreflight</strong>: procedural, row-level, cross-field, and multi-row checks that require deterministic grouping, evidence snapshots, streaming algorithms, chunked processing, and filesystem access. <br>Parameterization & parity:<br>1) Provide <code>PQ_VERSION</code> and <code>GetConfig()</code> parameters via the <code>Settings</code> sheet so PQ and VBA share parameters (e.g., <code>SourceLocale</code>, <code>DateOrder</code>, <code>MIN_NAME_LEN</code>). <br>2) <code>CONFIG_HASH</code> MUST incorporate <code>PQ_VERSION</code> to detect normalization contract changes; golden-parity tests in CI must re-run when <code>PQ_VERSION</code> changes. <br>Data flow recommendation:<br>1) Refresh PQ queries with <code>modPQController.RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> using <code>REFRESH_TIMEOUT_MS</code> from <code>GetConfig()</code> before calling <code>RunPreflight</code>. <br>2) PQ should preserve original raw column values as <code>Raw_*</code> columns to enable full auditability in preflight. <br>When to prefer PQ vs VBA for tasks used by preflight:<br>1) Use PQ for stateless column transformations, small-lookup joins, and server-side folding of filters to reduce data volume pulled into Excel. <br>2) Use VBA for duplicate grouping, fuzzy matching, evidence snapshot generation, streaming outlier detection, chunked processing and host-level I/O. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance for preflight outcomes</strong><br>Data model & join keys:<br>1) Import <code>PreflightResult</code> and <code>tblPreflight</code> snapshots into the reporting model. Use <code>jobId</code> and <code>ConfigHash</code> as primary join keys to <code>ImportLog</code> and <code>Batches</code>. <br>2) Persist daily snapshots of <code>preflight.summary</code> for historical SLOs and regression analysis. <br>Recommended measures and their uses:<br>1) <code>PreflightFailureRate = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0)</code> — monitor by <code>ConfigHash</code> and <code>PQVersion</code> for regressions. <br>2) <code>DuplicateRate = DIVIDE(SUM(Preflight[DuplicatedRows]), SUM(Preflight[RowsProcessed]), 0)</code> — track source data quality trends and hot-spot regions. <br>3) <code>AvgPreflightTimePerRow = DIVIDE(SUM(PreflightBlocks[DurationMs]), SUM(PreflightBlocks[RowsProcessed]))</code> — performance SLO monitoring and capacity planning. <br>4) <code>OutlierRateByRole = CALCULATE(DIVIDE(COUNTROWS(FILTER(Preflight, Preflight[UPAH_OUTLIER] = 1)), COUNTROWS(Preflight)), Preflight[Role])</code> — targeted QA for payroll anomalies. <br>Diagnostic slices:<br>1) Slice measures by <code>ConfigHash</code> to detect pipeline behavior changes correlated with config or PQ changes. <br>2) Use <code>dupGroupId</code> to identify heavy duplicate clusters and feed them into remediation workflows. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Failure modes, diagnostics & operator remediation</strong><br>1) <strong>Missing mandatory columns</strong> — <code>IMP_PF_001</code> returned; operator should re-upload source using header template or rename columns to expected names. <br>2) <strong>Ambiguous dates</strong> — <code>TGL_AMBIGUOUS</code> tags returned; remediationHint instructs operator to supply <code>SourceLocale</code> in settings or convert dates to ISO <code>YYYY-MM-DD</code>. <br>3) <strong>Large table host timeouts</strong> — abort with <code>pf.exception</code> describing last processed block, suggest chunked mode or offload to worker using <code>GetWorkerConfigSubset()</code>. <br>4) <strong>Disk full during evidence snapshot</strong> — delete <code>.tmp</code> file, emit <code>pf.evidence.fail</code>, and instruct operator to free space or change <code>STAGING_FOLDER</code>. <br>5) <strong>Concurrent preflight run attempted</strong> — second run returns <code>IMP_PF_009</code>, operator should wait or cancel the running job via UI. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Performance & scalability guidance</strong><br>1) <strong>Chunking defaults</strong> — process rows in blocks of 1,000–5,000 rows depending on host capabilities; emit <code>preflight.block.completed</code> after each block for progress telemetry. <br>2) <strong>Streaming aggregates</strong> — use Welford one-pass algorithm for means/variance and T-Digest or approximate quantile approaches for very large datasets when exact percentiles are too costly. <br>3) <strong>Offload heavy runs</strong> — for datasets above threshold (configurable <code>HostSafeRowThreshold</code>), produce <code>CreateJobDescriptor</code> and offload to a worker process with <code>GetWorkerConfigSubset()</code> to avoid blocking the UI. <br>4) <strong>Memory pressure mitigation</strong> — avoid concatenating large strings, write interim results to temp sheet periodically, and GC local arrays between blocks. <br>5) <strong>Adaptive chunk sizing</strong> — increase or decrease chunk size based on prior block duration to keep block durations in a target window (e.g., 2–6 seconds) for responsive progress updates. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Security, privacy & compliance controls</strong><br>1) <strong>PII minimization:</strong> never store raw PII in <code>ImportLog</code>; use <code>evidenceRef</code> and encrypted archives to preserve raw data when legally required. <br>2) <strong>Encryption & key management:</strong> keys retrieved at runtime via <code>modUtilities.GetSecretFromStore()</code> and not stored in code; modPreflight calls <code>modUtilities.SealFileWithKey()</code> for evidence snapshots when <code>UseEncryptedArchive</code> True. <br>3) <strong>Role-based redaction:</strong> UI must enforce redaction of sensitive columns when operator role lacks clearance; preflight should include <code>redactionMask</code> metadata in <code>PREFLIGHT_TABLE_NAME</code> where applicable. <br>4) <strong>Retention & purge:</strong> set <code>ARCHIVE_RETENTION_DAYS</code> in <code>GetConfig()</code> and ensure scheduled retention jobs remove expired artifacts after verifying checksums and chain-of-custody logs. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Extensibility & plugin hooks</strong><br>1) <code>RegisterPreflightHook(name, handlerRef)</code> — allow business-specific validation to register idempotent post-preflight hooks that receive a read-only snapshot and may return additional <code>CustomChecks</code> annotations. <br>2) <code>DuplicateStrategy</code> pluggable module: support <code>exactOnly</code>, <code>compositeKey</code>, <code>fuzzyToken</code> strategies selectable from config and switchable at runtime via <code>ReloadConfig()</code> with approval gating for production. <br>3) <code>CustomNormalizationRules</code> overlay: allow admins to provide a small user-editable <code>NormalizationRules</code> sheet consumed on <code>ReloadConfig()</code> to add transform rules (e.g., company name canonical mappings) without editing VBA. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Developer checklist before committing changes</strong><br>1) Unit-test parsing functions (<code>NormalizeDateText</code>, <code>ValidateNIK</code>, <code>NormalizeNameText</code>) across canonical fixtures and edge cases. <br>2) Run full E2E on canonical dataset and ensure preflight artifact checksums/golden files match expected outputs for current <code>CONFIG_HASH</code>. <br>3) Update <code>migration_manifest.json</code> with <code>oldConfigHash</code>, <code>newConfigHash</code>, <code>changedKeys</code>, and recorded approvals for any semantic changes. <br>4) Run CI chaos tests simulating disk full, concurrent runs, and host API limitations; fix regressions. <br>5) Document any public contract changes (new tags, column additions) in README and ensure downstream modules are updated. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Acceptance criteria for a correct preflight run</strong><br>1) <code>tblPreflight</code> exists with required columns: raw columns + <code>Checks</code>, <code>RemediationHint</code>, <code>dupGroupId</code>, <code>dupScore</code>, <code>ParseAudit</code>, <code>Normalized_*</code> columns. <br>2) <code>rowsProcessed</code> equals raw table row count and <code>rowsFlagged</code> equals aggregated <code>Checks</code> > 0 count. <br>3) <code>PreflightResult</code> includes <code>configHash</code>, <code>durationMs</code>, <code>evidenceRef</code> when applicable, and no uncaught exceptions. <br>4) <code>ImportLog</code> contains <code>preflight.summary</code> and one or more <code>preflight.block.completed</code> rows with expected cumulative counts. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Operational runbook — step by step</strong><br>1) Validate environment: open workbook -> <code>GetConfig()</code> loads -> confirm <code>CONFIG_HASH</code> equals expected value for the environment. <br>2) Refresh PQ queries that feed preflight: <code>modPQController.RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> respecting <code>REFRESH_TIMEOUT_MS</code>. <br>3) Run <code>RunPreflight(jobId, options)</code>, monitor progress, and cancel only if necessary. <br>4) Review <code>preflight.summary</code> and open filtered <code>tblPreflight</code> by <code>Checks</code> tags to triage. <br>5) Export small edit batch for offline fixes, re-import, and re-run preflight using <code>resumeFrom</code> where supported. <br>6) When <code>PreflightFailureRate</code> acceptable, proceed to <code>CreateBatches</code>. <br>7) Archive evidence if regulation requires and document <code>evidenceRef</code> in job notes. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Common pitfalls & mitigations</strong><br>1) <strong>Silent coercion of ambiguous dates</strong> — do not attempt to coerce ambiguous formats; tag <code>TGL_AMBIGUOUS</code> and require operator action. <br>2) <strong>Inconsistent normalization across modules</strong> — centralize normalization rules in modPreflight and share normalization parameters with PQ via <code>Settings</code> sheet and <code>PQ_VERSION</code>. <br>3) <strong>Non-atomic writes leading to partial reads</strong> — always compute in temp and perform atomic swap; implement rollback for rename failures. <br>4) <strong>Mapped drive usage in scheduled jobs</strong> — detect drive-letter paths and recommend UNC paths; for scheduled runs, require UNC path to avoid mapped-drive brittleness. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Extensive examples & annotated scenarios</strong><br>Example A — ambiguous date scenario:<br>1) Raw row contains <code>TglLahir = &quot;01/02/03&quot;</code> and <code>PQ_Preflight.ParseSuccess = False</code>. <br>2) <code>NormalizeDateText</code> returns <code>{parseStatus:&quot;AMBIGUOUS&quot;, reasonTag:&quot;TGL_AMBIGUOUS&quot;}</code>, <code>Checks</code> includes <code>TGL_AMBIGUOUS</code>. <br>3) <code>RemediationHint</code>: "Ambiguous date <code>01/02/03</code>. Provide ISO <code>YYYY-MM-DD</code> or set <code>SourceLocale</code> in Settings." <br>Example B — duplicate grouping scenario:<br>1) Two rows: Row A <code>NIK=1212121212121212, Nama=&quot;Siti A&quot;, TglLahir=1985-03-12</code> and Row B <code>NIK=1212121212121212, Nama=&quot;Siti A.&quot;, TglLahir=1985-03-12</code>. <br>2) Normalization removes punctuation and collapses whitespace; exact NIK match -> both flagged <code>DUPLICATE_NIK</code>, assigned <code>dupGroupId</code> computed by deterministic sort. <br>3) UI presents grouped view with suggested canonical row (lowest RawRowIndex or based on non-empty fields) for operator confirmation. <br>Example C — salary outlier scenario:<br>1) Salary distribution median = 3,500,000; <code>OUTLIER_MULTIPLIER = 4</code>. <br>2) Row with <code>Upah = 50,000,000</code> flagged <code>UPAH_OUTLIER</code> with <code>remediationHint</code> "Verify currency and decimal separators; unusually high compared to median." </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Extending to advanced patterns (future-proofing)</strong><br>1) <strong>Schema evolution:</strong> support optional <code>CustomColumns</code> map so new optional fields do not break preflight; <code>ValidateConfig()</code> should allow safe schema extensions annotated in <code>migration_manifest</code>. <br>2) <strong>Adaptive learning:</strong> optionally export de-identified false-positive/false-negative samples for periodic offline model training of fuzzy matching thresholds; require explicit approvals and governance for ML pipeline. <br>3) <strong>Parallel worker offload:</strong> implement <code>CreateJobDescriptor</code> pattern that serializes <code>GetWorkerConfigSubset()</code> and chunk descriptors for horizontal scaling; ensure deterministic merging of chunk results by sorting and stable group-id recomputation rules. </td></tr><tr><td data-label="modPreflight — Per-function technical breakdown (VBA)"> <strong>Final verification statements & operational assurances</strong><br>1) modPreflight enforces conservative normalization and explicit ambiguity tagging to prevent silent data corruption. <br>2) The module emits deterministic outputs tied to <code>CONFIG_HASH</code> and <code>PQ_VERSION</code>, enabling CI golden-parity gates and forensic replay. <br>3) Atomic writes, chunked processing, streaming algorithms, and evidence snapshot controls ensure modPreflight scales safely across hosts while preserving auditability and privacy controls. <br>4) Implemented tests and CI gating should prevent un-reviewed changes to normalization rules from silently changing production outputs. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table6" data-table="YJKN_0017_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modBatchProcessing — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modBatchProcessing — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Executive summary & purpose</strong><br>modBatchProcessing is the authoritative VBA module that transforms validated preflight rows into upload-ready artifacts, manages safe exports (RFC4180 CSV and optional XLSX/compressed variants), records immutable batch metadata to the Batches ledger, enforces idempotency and resume semantics, guarantees atomic file writes and cryptographic checksums for chain-of-custody, and provides safe operator controls for destructive operations. It is conservative by default (create_copy semantics), integrates with modConfig and modUtilities for environment and I/O primitives, and emits telemetry/audit rows tagged with <code>configHash</code>, <code>jobId</code>, and <code>operatorId</code>. The module must never write PII into telemetry, must never embed secrets, and must fail fast and clearly when environmental invariants are violated. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Design goals & non-functional requirements</strong><br>1) <strong>Safety-first exports</strong> — never expose partial files to downstream systems; always write to temporary files and perform atomic rename on success. <br>2) <strong>Deterministic artifacts</strong> — deterministic file naming and canonical header ordering to enable reproducible golden-file checks. <br>3) <strong>Idempotency & resumability</strong> — detect prior completed batches and avoid duplication unless recreate explicitly requested. <br>4) <strong>Forensics-ready</strong> — compute and record SHA256 checksums, record <code>createdTs</code>, <code>operatorId</code>, <code>configHash</code>, and evidenceRefs; support forensic pack generation. <br>5) <strong>Performance & memory safety</strong> — stream writes, chunked hashing, and optional worker offload for very large exports. <br>6) <strong>Observability</strong> — emit structured telemetry rows for start, per-file write, append success, conflict, archive completion, and failures. <br>7) <strong>Privacy & compliance</strong> — redact PII in logs and store evidence in protected archives with encryption where required. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Public API surface (semantic signatures — conceptual)</strong><br>1) <code>CreateBatches(jobId As String, options As Dictionary) As BatchCreationResult</code> — orchestrates whole-batch creation workflow and returns a summary object with created/failed rows and metrics. <br>2) <code>ExportTableRangeToCSV(rowRange As Range, outFilePath As String, options As Dictionary) As ExportResult</code> — streams the specified rows to a temporary CSV and returns {success,checksum,bytesWritten,elapsedMs,error}. <br>3) <code>AppendBatchRecord(batchMetadata As Dictionary) As AppendResult</code> — atomically append or upsert a ledger row into the Batches table and return persisted id or conflict. <br>4) <code>ComputeBatchChecksum(filePath As String) As ChecksumResult</code> — buffered SHA256 computation returning algorithm and hex. <br>5) <code>ResumeBatches(jobId As String, options As Dictionary) As ResumeResult</code> — detect incomplete or failed batches and resume accordingly. <br>6) <code>ArchiveBatch(filePath As String, jobId As String, options As Dictionary) As ArchiveResult</code> — move artifacts into job-specific archive and record archival metadata. <br>7) <code>CreateJobDescriptorForWorker(payload As Dictionary) As JobDescriptor</code> — optional function to prepare a minimal worker payload including <code>CONFIG_HASH</code> and <code>PQ_VERSION</code>. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>High-level end-to-end flow</strong><br>1) Pre-flight checks: call <code>modConfig.ValidateConfig()</code> and <code>modConfig.AssertStagingFolder()</code>; fail fast on errors. <br>2) Read stable preflight view: ensure <code>PREFLIGHT_TABLE_NAME</code> is present and recently refreshed by <code>modPQController</code>. <br>3) Filter rows accepted for batching: include only rows passing gating rules from <code>modPreflight</code> (no fatal tags), allow operator-specified filters. <br>4) Chunk rows: compute batch boundaries using <code>BATCH_SIZE</code> and <code>BatchStrategy</code> (contiguous vs business-partitioned). <br>5) For each chunk: <code>ExportTableRangeToCSV</code> -> compute checksum -> atomic rename -> <code>AppendBatchRecord</code> -> <code>ArchiveBatch</code> (if archive policy requires). <br>6) Post-run manifest: write manifest_<jobId>.json listing files, checksums, row counts; place manifest in archive and record manifest checksum. <br>7) Emit telemetry and return <code>BatchCreationResult</code> to UI. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Chunking strategies & heuristics</strong><br>1) <strong>Contiguous chunking</strong> — simplest approach: split DataBodyRange into contiguous blocks of <code>BATCH_SIZE</code>. Use for maximum performance and simplest resume semantics. <br>2) <strong>Business-key partitioned chunking</strong> — partition by a business column (e.g., region, employerId) while maintaining per-batch <code>BATCH_SIZE</code> soft cap to keep payloads balanced by business owner. Use when business constraints prefer grouped rows. <br>3) <strong>Hybrid strategy</strong> — combine partitioning by a coarse key and contiguous within partitions to produce stable, human-meaningful file ranges. <br>4) <strong>Edge handling</strong> — when row count < <code>BATCH_SIZE</code>, produce a single batch. For final small tail batches, optionally merge with previous batch when policy allows. <br>5) <strong>Chunk metadata</strong> — each chunk must record startRow, endRow, rowCount, selectable filters applied, and a deterministic seed for file-name creation. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Export contract: RFC4180 compliance & robust CSV guarantees</strong><br>1) <strong>Header & ordering</strong> — export header row exactly once at top; header column order must be deterministic and documented; prefer canonical header order produced by PQ or <code>PREFLIGHT_TABLE_NAME</code>. <br>2) <strong>Field quoting & escaping</strong> — follow RFC4180: double-quote fields with embedded commas, CR, LF, or quotes; escape embedded quotes by doubling them; optionally quote all text fields for maximum safety. <br>3) <strong>Embedded newlines</strong> — treat multi-line cell values by quoting the field entirely; ensure ADODB.Stream or the streaming writer writes proper CRLF sequences inside quoted fields. <br>4) <strong>Numeric and date serialization</strong> — do not rely on Excel's cell display formatting; use canonical serialization rules (e.g., dates in <code>yyyy-mm-dd</code> or <code>DEFAULT_DATE_FORMAT</code> from modConfig, numeric values trimmed of thousands separators). <br>5) <strong>Encoding</strong> — default to UTF-8 with or without BOM depending on <code>USE_UTF8</code> and portal requirement; provide fallback to ANSI if explicitly required by portal, but log <code>encoding.fallback</code> telemetry. <br>6) <strong>Line endings</strong> — choose CRLF by default for portal compatibility; allow LF-only override via configuration. <br>7) <strong>Atomic write & rename</strong> — write to <code>outFile.tmp</code> then <code>Name</code> to <code>outFile</code> after checksum verification; if rename fails, delete temp file and return <code>IMP_BATCH_001</code>. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Atomic-write pattern & temp file lifecycle</strong><br>1) <strong>Write to temp file</strong> — create <code>outFile.tmp</code> in the same folder to allow atomic rename (rename within same volume is atomic). <br>2) <strong>Flush & fsync semantics</strong> — when ADODB.Stream or Windows file APIs are used, ensure buffers flushed fully and write operations have completed before computing checksum (where possible). <br>3) <strong>Checksum after close</strong> — compute SHA256 on the closed temp file to ensure deterministic digest. <br>4) <strong>Rename to final</strong> — perform <code>Name outFile.tmp As outFile</code> and confirm existence. <br>5) <strong>Failure handling</strong> — on any exception during write or checksum, delete <code>outFile.tmp</code> and record <code>IMP_BATCH_001</code> with stack context. <br>6) <strong>Orphan temp cleanup</strong> — on module initialization or Resume flows, detect stale <code>*.tmp</code> files older than TTL (configurable) and remove them after logging cleanup. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>File naming rules & best practices</strong><br>1) <strong>Deterministic, non-PII naming</strong> — <code>jobId_batchIdx_start-end_configHash.csv</code> or similar safe naming template to support traceability while avoiding PII. <br>2) <strong>Timestamping</strong> — append a monotonic run timestamp (ISO8601 compact) when <code>OVERWRITE_BATCHES = False</code> to avoid accidental collisions across runs. <br>3) <strong>Sanitization</strong> — remove or hash any free-text label included in filenames to prevent PII leakage. <br>4) <strong>Name length & OS limits</strong> — ensure filename length remains within OS limits; use hashed suffix when human label would exceed safe lengths. <br>5) <strong>Manifest link</strong> — each generated file must be listed in manifest_<jobId> with fileName, relativePath, checksum, rowCount, and createdTs. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Batches ledger (schema & append semantics)</strong><br>1) <strong>Recommended ledger columns</strong> — <code>batchId</code>, <code>jobId</code>, <code>batchIdx</code>, <code>filePath</code>, <code>rowCount</code>, <code>rowRange</code>, <code>checksum</code>, <code>createdTs</code>, <code>status</code>, <code>operatorId</code>, <code>resumeToken</code>, <code>errorDetail</code>, <code>approvalsRef</code>, <code>archivePath</code>, <code>purgeAfterTs</code>. <br>2) <strong>Idempotent append semantics</strong> — <code>AppendBatchRecord()</code> must detect existing rows with <code>jobId+batchIdx+filePath</code>. <br>3) <strong>Conflict detection</strong> — when an existing row exists with the same identifiers but different checksum, return <code>batch_conflict</code> with both checksums and do not overwrite without explicit operator approval. <br>4) <strong>Atomic ledger update</strong> — perform table row append in a single atomic operation (ListObject.InsertRow or Range.Resize + Value assignment with error handling). <br>5) <strong>Audit fields</strong> — ledger rows should include <code>configHash</code> and <code>pqVersion</code> to support auditing and golden-parity analysis. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Checksum & integrity verification rules</strong><br>1) <strong>Algorithm</strong> — use SHA256 and record algorithm name and hex digest. <br>2) <strong>When to compute</strong> — compute checksum after the final rename to ensure digest matches final artifact on disk. <br>3) <strong>Post-archive verification</strong> — recompute checksum after archive move and validate it matches recorded checksum; if mismatch, set status <code>corruption_detected</code> and preserve both copies for forensic analysis. <br>4) <strong>Dual checksums</strong> — when compression used, compute both compressed and uncompressed checksums and record both. <br>5) <strong>Checksum storage</strong> — store only hex digests in ledger and manifest; avoid storing raw file contents in logs. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Archive behavior, retention & purge policy</strong><br>1) <strong>Archive location & ACLs</strong> — STAGING_ARCHIVE_FOLDER\<jobId>\, create per-job folder and enforce ACL recommendations from modConfig; log <code>archive.created</code> telemetry. <br>2) <strong>Retention</strong> — obey <code>ARCHIVE_RETENTION_DAYS</code> from modConfig and set <code>purgeAfterTs</code> in ledger rows for scheduled purge jobs. <br>3) <strong>Purge safety</strong> — do not purge artifacts with <code>investigationFlag</code> or <code>approvalRef</code>; require manual override to remove. <br>4) <strong>Evidence retention</strong> — when <code>evidenceRefRequired</code> is True, copy artifacts to protected evidence store before purge and keep a manifest of checksums for chain-of-custody. <br>5) <strong>Archive encryption</strong> — if <code>UseEncryptedArchive</code> True, call <code>modUtilities.GetSecretFromStore</code> to obtain encryption keys and encrypt files before writing to archive; never store keys in modBatchProcessing. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Resume & idempotency semantics</strong><br>1) <strong>Inspect ledger</strong> — <code>ResumeBatches(jobId)</code> enumerates ledger where <code>status</code> not Completed and attempts to determine action per batch row: retry export, skip if file exists and checksum matches, or mark conflict if checksum differs. <br>2) <strong>Retry policy</strong> — adopt exponential backoff with jitter for transient errors (I/O, network shares); cap retries to a configurable max attempts and store attempts count in ledger. <br>3) <strong>Resume tokens</strong> — use <code>resumeToken</code> in ledger to allow reentrant resume semantics; tokens should be monotonic and include batch metadata for verification. <br>4) <strong>Recreate mode</strong> — typed operator confirmation required for <code>--recreate</code> flows; prior completed batches are marked Archived and new batches created with distinct filenames and <code>recreatedFrom</code> metadata. <br>5) <strong>Concurrent run avoidance</strong> — prevent concurrent CreateBatches for same jobId using a module-level mutex or sheet-backed lock; competing requests should be rejected with <code>ERR_CONFLICT</code> and recommended to call Resume or queue. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Worker offload & CreateJobDescriptor pattern</strong><br>1) <strong>When to offload</strong> — recommended for extremely large exports or when host Excel cannot handle memory/timeout constraints. <br>2) <strong>Descriptor contents</strong> — minimal safe payload: <code>jobId</code>, chunk spec (start,end,columns), <code>CONFIG_HASH</code>, <code>PQ_VERSION</code>, and <code>workerRunId</code>. Exclude PII and secrets; include secret names only. <br>3) <strong>Worker responsibilities</strong> — digest payload, fetch configuration if necessary, perform CSV write and checksum, upload artifact to shared staging UNC or object store, and return manifest to master for ledger append. <br>4) <strong>Checkpointing</strong> — workers must periodically write progress heartbeats to a central job status artifact so master can resume or detect stuck workers. <br>5) <strong>Security</strong> — protect job descriptor in transit; require worker to verify <code>CONFIG_HASH</code> and refuse to run if mismatch unless operator explicitly overrides with signed approval. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Failure modes, diagnostics & recovery</strong><br>1) <strong>Disk full during write</strong> — detect write exception, delete temp file, set batch status <code>Failed</code> with <code>IMP_BATCH_001</code>, log disk usage, and provide remediation: free space or use alternate staging path. <br>2) <strong>Permission denied</strong> — detect permission error on write or rename, set <code>IMP_BATCH_002</code>, and surface remediation: check ACLs, run as different account, or choose alternate UNC path. <br>3) <strong>Temp file orphaned</strong> — remove stale <code>*.tmp</code> older than TTL during resume or module startup and log cleanup. <br>4) <strong>Checksum mismatch after archive move</strong> — mark <code>corruption_detected</code>, keep both files for analysis, escalate to forensic workflow, and do not purge corrupt artifacts. <br>5) <strong>Portal rejection</strong> — mark batch <code>RejectedByPortal</code>, log portal error codes and return details in <code>errorDetail</code> for <code>AppendBatchRecord</code>; create corrective small batches for resubmission. <br>6) <strong>Partial ledger committed</strong> — guard ledger writes so that file creation and ledger append order is correct: finalize file then append ledger; on crash between both steps, resume flow must reconcile by deleting orphan files older than TTL or appending missing ledger rows after recomputing checksums. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Telemetry & observable events</strong><br>Emit structured telemetry rows for key events with <code>configHash</code> and <code>jobId</code> included: <br>1) <code>batch.create.start{jobId,configHash,operatorId,expectedBatches,rows}</code>. <br>2) <code>batch.file.written{filePath,bytesWritten,checksum,elapsedMs,batchIdx,jobId}</code>. <br>3) <code>batch.append.ok{batchId,jobId,filePath,checksum}</code>. <br>4) <code>batch.append.conflict{jobId,batchIdx,filePath,existingChecksum,attemptedChecksum}</code>. <br>5) <code>batch.create.failed{jobId,batchIdx,errorCode,errorDetail}</code>. <br>6) <code>batch.archive.completed{jobId,batchId,archivePath,checksum}</code>. <br>7) <code>batch.resume.start{jobId,resumeCandidateCount}</code>. <br>Telemetry must not include raw PII; when evidence is required, include <code>evidenceRef</code> pointer to secure archive rather than values. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Security & privacy constraints</strong><br>1) <strong>PII handling</strong> — redact PII in all logs and telemetry. If PII retention is regulatory required, record <code>evidenceRef</code> and store full artifacts in a protected archive with strict ACLs and encryption. <br>2) <strong>No secrets in code</strong> — never store keys in modBatchProcessing; use <code>modUtilities.GetSecretFromStore()</code> to retrieve encryption keys and other secrets at runtime. <br>3) <strong>Least privilege</strong> — recommend minimal ACLs on STAGING_FOLDER and archive; document suggested operator groups and rights in runbook and use OS-level ACLs for enforcement. <br>4) <strong>Approval controls</strong> — destructive operations (overwrite/recreate) require typed confirmation and two-person approval for regulated workflows; record approvals in <code>approvalsRef</code> on ledger rows. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Performance & memory considerations</strong><br>1) <strong>Streaming writes</strong> — stream rows to ADODB.Stream or buffered file handle rather than building full CSV in memory for large batches. <br>2) <strong>Buffer size tuning</strong> — use a configurable buffer (4KB–64KB) and flush per buffer to balance memory and I/O overhead. <br>3) <strong>Chunked hashing</strong> — compute checksums by reading files in chunks (e.g., 64KB) to avoid high memory usage. <br>4) <strong>Parallelism</strong> — allow parallel export workers for independent chunks if host and I/O subsystem allow; protect ledger append with concurrency controls. <br>5) <strong>I/O affinity</strong> — for network storage use per-run temp folders local to worker and then atomic move to UNC to reduce network latency and partial file problems. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Testing matrix & QA</strong><br>1) <strong>Unit tests</strong> — RFC4180 escaping rules (embedded commas, quotes, newlines), encoding variants (UTF-8 BOM/no BOM, ANSI), filename sanitization, ledger append idempotency, checksum computations. <br>2) <strong>Integration tests</strong> — full end-to-end from <code>PREFLIGHT_TABLE_NAME</code> through <code>CreateBatches</code> to manifest and archive; golden-file checksum parity for canonical fixtures and <code>CONFIG_HASH</code> values. <br>3) <strong>Resume tests</strong> — simulate crash mid-run: confirm resume recreates missing batches without duplicating completed ones. <br>4) <strong>Chaos tests</strong> — disk full, permission denied, intermittent UNC unavailability, network flakiness for worker offload. <br>5) <strong>CI gating</strong> — any changes to CSV semantics or config keys that affect outputs must run canonical fixture suite and require golden-file acceptance or documented migration_manifest.json with approvals. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Integration points with other modules</strong><br>1) <strong>modConfig</strong> — read <code>STAGING_FOLDER</code>, <code>STAGING_ARCHIVE_FOLDER</code>, <code>BATCH_SIZE</code>, <code>USE_UTF8</code>, <code>REFRESH_TIMEOUT_MS</code>, <code>OVERWRITE_BATCHES</code>, <code>ARCHIVE_RETENTION_DAYS</code>, <code>CONFIG_HASH</code>, and <code>PQ_VERSION</code> via <code>GetConfig()</code>; never hard-code these values. <br>2) <strong>modUtilities</strong> — use <code>WriteUtf8FileAtomic</code>, <code>ComputeFileChecksum</code>, <code>LogAction</code>, <code>Retry</code>, <code>EnsureTableExists</code>, and other helper primitives; do not reimplement robust streaming/hashing primitives. <br>3) <strong>modPQController</strong> — ensure PQ produced <code>PREFLIGHT_TABLE_NAME</code> view; use <code>REFRESH_TIMEOUT_MS</code> when coordinating PQ refresh. <br>4) <strong>modPreflight</strong> — rely on preflight tags to determine which rows are included; preserve <code>dupGroupId</code> and other preflight metadata in batch manifest to support downstream reconciliation. <br>5) <strong>modErrorParser</strong> — when portal returns rejection reports, modErrorParser drives triage and small-batch corrections produced by modBatchProcessing. <br>6) <strong>frmOperatorUI</strong> — typed confirmations, progress, cancellation tokens, and resume UI flows integrate directly with modBatchProcessing. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Operator UI interactions & human-in-loop safeguards</strong><br>1) <strong>Typed confirmations</strong> — when <code>OVERWRITE_BATCHES=True</code> or <code>--recreate</code> flows are invoked, require typed literal (e.g., <code>DELETE-AND-RECREATE</code>) to proceed. <br>2) <strong>Progress & cancel</strong> — UI sets <code>CancelRequested</code> boolean that batch processing checks at chunk boundaries and aborts cleanly, marking remaining batches <code>Cancelled</code>. <br>3) <strong>Interactive resume</strong> — UI displays Resume candidates with existing checksums and operator actions: UseExisting / Recreate / DeleteFromDisk. <br>4) <strong>Conflict resolution UI</strong> — when <code>AppendBatchRecord</code> returns <code>batch_conflict</code>, UI must present existing checksum and attempted checksum, provide options and require approvals for overwrite. <br>5) <strong>Approval capture</strong> — UI must capture approver <code>operatorId</code> and optionally produce signed approval objects for compliance and store approvalsRef in ledger. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Runbook (concise operational steps)</strong><br>1) Validate config: run <code>modConfig.ValidateConfig()</code> and fix any <code>IMP_CFG_*</code> errors before starting. <br>2) Ensure staging: run <code>modConfig.AssertStagingFolder()</code> and verify ACLs for operator/service account. <br>3) PQ refresh: call <code>modPQController.RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> and confirm <code>PREFLIGHT_TABLE_NAME</code> is up-to-date. <br>4) Preflight: review preflight summary and resolve flagged rows. <br>5) Create batches: run <code>CreateBatches(jobId)</code> and confirm manifest_<jobId> in archive; if required, obtain approvals for <code>--recreate</code>. <br>6) Upload: follow portal SOP to upload manifest and files; retain manifest checksum in ledger. <br>7) Portal reconciliation: when portal errors returned, run <code>modErrorParser</code> and produce corrective small batches. <br>8) Post-run: review telemetry, store <code>ForensicPack</code> if required, and apply retention/purge processes per policy. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Conceptual Power Query guidance related to batch exports</strong><br>1) <strong>What PQ should do</strong> — canonical column normalization, whitespace/case normalization, small lookup table joins, and parse success indicators (e.g., <code>ParseSuccessDate</code>) so VBA can make deterministic decisions during CSV export. <br>2) <strong>What PQ should not do</strong> — streaming exports, heavy per-row approvals, file I/O, encryption, and host-specific flows belong in VBA modules. <br>3) <strong>Header stability</strong> — PQ must produce stable header order (documented in <code>PREFLIGHT_TABLE_NAME</code> contract) to allow deterministic CSV generation and checksum parity. <br>4) <strong>Parameters & parity</strong> — store PQ parameters in <code>Settings</code> sheet read by modConfig and include <code>PQ_VERSION</code> in <code>CONFIG_HASH</code> to drive CI gating for parity. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance for batches</strong><br>1) <strong>Key dimensions to model</strong> — JobId, ConfigHash, PQVersion, OperatorId, BatchId, Status, CreatedTs, RowCount, ChecksumVerified. <br>2) <strong>Operational measures to expose</strong> — <code>PreflightFailureRate</code>, <code>BatchSuccessRate</code>, <code>AvgBatchCreateTimeMs</code>, <code>AvgBatchSize</code>, <code>BatchChecksumParityRate</code>, and <code>ArchiveRetentionUtilization</code>. <br>3) <strong>Representative DAX (conceptual)</strong> — <code>BatchSuccessRate = DIVIDE(CALCULATE(COUNTROWS(Batches), Batches[Status]=&quot;Completed&quot;), COUNTROWS(Batches), 0)</code>. <br>4) <strong>Slicing by ConfigHash</strong> — always include <code>ConfigHash</code> as a slicer to quickly detect behavioral changes post config or PQ updates. <br>5) <strong>Use migration_manifest for root-cause</strong> — join <code>migration_manifest</code> data to explain diff in measures across ConfigHash changes. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Testing examples & narrative scenarios</strong><br>Example 1 — Normal small job:<br>1) JobId <code>job-20260220-01</code>, BATCH_SIZE=500, total rows=1,200 -> CreateBatches produces 3 files with deterministic names, checksums recorded, manifest created and archived, all ledger rows set to Completed. <br>2) Operator uploads per portal SOP and records upload receipt in <code>Batches</code> ledger row <code>uploadReceipt</code>. <br>Example 2 — Interrupted run with resume:<br>1) Job begins and two of three batches Completed; process crashes before third finalization. <br>2) On restart <code>ResumeBatches</code> inspects ledger: sees two Completed with matching files -> skips them, recreates third batch, appends ledger row and finalizes manifest. <br>Example 3 — Portal rejection and fixup:<br>1) Portal returns CSV with errors; <code>modErrorParser</code> maps errors to source rows; operator filters failing rows and uses CreateBatches to produce small corrective batch(s) for reupload. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Forensics & audit pack contents</strong><br>1) <strong>ForensicPack contents</strong> — <code>ImportLog</code> rows filtered by <code>jobId</code>, <code>Batches</code> ledger snapshot, manifest_<jobId>, archived artifacts checksums, evidenceRef pointers, approvalsRef and operator metadata, and computed <code>CONFIG_HASH</code> and <code>PQ_VERSION</code>. <br>2) <strong>Signing</strong> — compute HMAC signature of compressed ForensicPack with a key from secure store and include signature manifest so external auditors can verify integrity. <br>3) <strong>Retention</strong> — keep ForensicPack in secure evidence store per regulatory retention; purge only per documented retention policy and two-person approvals. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Common pitfalls & mitigations</strong><br>1) Pitfall: building full CSV string in memory -> Out-of-memory and host timeouts. <br>Mitigation: stream to ADODB.Stream and use chunked flush. <br>2) Pitfall: writing directly to final filename -> partial files visible to portal. <br>Mitigation: always write to temp and atomic rename. <br>3) Pitfall: inconsistent header order between PQ and VBA -> checksum mismatches. <br>Mitigation: freeze header contract in <code>PREFLIGHT_TABLE_NAME</code> and document in README; include <code>PQ_VERSION</code> in <code>CONFIG_HASH</code>. <br>4) Pitfall: trusting mapped drives in scheduled tasks -> UNC path failures when scheduled as service account. <br>Mitigation: enforce UNC paths in config validation and log <code>config.warn</code> when mapped drives are detected. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Change-control, CI gating & migration manifest policy</strong><br>1) <strong>CI gating</strong> — any change to modBatchProcessing that affects CSV serialization (header order, date format, encoding, quoting rules) or modConfig keys that influence output must trigger canonical fixture suite in CI and golden-file checksum verification. <br>2) <strong>migration_manifest.json</strong> — required for semantic changes; must include <code>oldConfigHash</code>, <code>newConfigHash</code>, <code>changedKeys</code>, <code>justification</code>, <code>testResults</code>, and two-person approval signatures. <br>3) <strong>Rollback</strong> — preserve previous release artifacts and <code>CONFIG_HASH</code>; CI artifacts support quick rollback to previous known-good artifacts if new release causes regressions. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Developer checklist before commit</strong><br>1) Run unit tests for RFC4180 rules, encoding, and checksum correctness. <br>2) Run integration E2E with canonical fixtures and verify artifact checksum parity for current <code>CONFIG_HASH</code>. <br>3) Confirm <code>AssertStagingFolder()</code> behavior under operator/service account and ACLs. <br>4) Update <code>migration_manifest.json</code> and obtain required approvals for any breaking changes. <br>5) Add or update runbook and README entries if operational behaviors or required operator actions changed. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Extensibility & hooks for future integrations</strong><br>1) <strong>Upload adapter</strong> — implement a pluggable UploadAdapter interface so uploading artifacts can be performed by SFTP, HTTP POST, portal SDK, or manual UI without changing file creation logic. <br>2) <strong>Event hooks</strong> — provide <code>OnBatchCreated</code>, <code>OnBatchArchived</code>, and <code>OnBatchFailed</code> hooks so monitoring or replication services can subscribe to events. <br>3) <strong>Compression & checksum duality</strong> — allow optional gzip compression and record both compressed and uncompressed checksums when enabled. <br>4) <strong>Pluggable secret providers</strong> — rely on <code>modUtilities</code> abstraction to allow different secret backends (Windows Credential Manager, Azure Key Vault) to be used by environment. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Appendix — error code catalog (batch-related)</strong><br>1) <code>IMP_BATCH_001</code> — file write failed (disk full / IO error). <br>2) <code>IMP_BATCH_002</code> — permission denied to staging/archive folder. <br>3) <code>batch_conflict</code> — ledger contains entry for same jobId+batchIdx but checksum mismatch. <br>4) <code>IMP_BATCH_003</code> — atomic rename failed (target exists or permission). <br>5) <code>IMP_BATCH_004</code> — checksum mismatch after archive move (possible corruption). <br>6) <code>IMP_BATCH_005</code> — worker descriptor mismatch on resume (CONFIG_HASH mismatch). <br>Each code surfaces a concise UI message, a triage hint, remediation steps, and a logged <code>ImportLog</code> row with <code>jobId</code>, stack context, and <code>configHash</code>. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Final verification checklist (runtime invariants)</strong><br>1) <code>modConfig.ValidateConfig()</code> returns empty collection before batch creation. <br>2) <code>modConfig.AssertStagingFolder()</code> returns True and staging path is writable. <br>3) Export writes to temp file and final rename only occurs after successful checksum calculation. <br>4) Ledger <code>AppendBatchRecord()</code> validates checksum parity and returns <code>batch_conflict</code> if mismatch. <br>5) Resume flows avoid duplicate completed batches and recover only missing or failed batches. <br>6) All telemetry rows include <code>jobId</code> and <code>configHash</code> for traceability and forensic reconstruction. </td></tr><tr><td data-label="modBatchProcessing — Per-function technical breakdown (VBA)"> <strong>Closing implementation guidance</strong><br>Implement modBatchProcessing as a small-surface-area, well-tested module that delegates streaming, atomic file writes, hashing, and secret retrieval to modUtilities; integrate tightly with modConfig for environment values and PQ-version parity; enforce typed confirmations and approval capture in frmOperatorUI for destructive actions; instrument detailed telemetry while scrubbing PII; and gate any changes that affect serialized outputs with CI golden-file checks and migration manifests to preserve reproducibility and auditability. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><div class="table-caption" id="Table7" data-table="YJKN_0017_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modErrorParser — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modErrorParser — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Executive summary & mission statement</strong><br>modErrorParser is the authoritative VBA module responsible for deterministic ingestion, robust parsing, canonical normalization, trustworthy matching, audit-preserving annotation, secure archival, and operator-friendly triage of portal-provided error reports (hereafter "portal CSVs").<br>Its core mission is to transform an external portal’s error export into a set of reproducible, auditable actions and artifacts that tie back to the source <code>tblRawImport</code> records while preserving chain-of-custody, minimizing PII leakage in telemetry, and enabling easy manual triage for unmatched or ambiguous rows.<br>Key outcomes: reliable matching of portal rows to source rows, append-only portal annotation history on source rows, deterministic archive + checksum of the original portal file, a clear <code>UnmatchedPortalErrors</code> artifact for human review, and structured telemetry suitable for downstream DAX/Power BI reporting and CI golden-parity gating. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>High-level responsibilities & invariants</strong><br>1) Ingest portal CSVs reliably and compute a stable <code>archiveChecksum</code> before any mutation of source data.<br>2) Detect portal format and map portal columns to canonical internal fields deterministically.<br>3) Match portal rows to source rows using a prioritized, deterministic policy (OriginalRow → PrimaryKey → CompositeKey → Conservative fuzzy fallback).<br>4) Annotate source rows append-only, preserve full history, and include <code>portalFileRef</code> and <code>archiveChecksum</code> in every annotation.<br>5) Produce <code>UnmatchedPortalErrors</code> and <code>AmbiguousMatches</code> artifacts for operator triage; never silently discard data.<br>6) Archive raw portal file atomically into <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal\&lt;timestamp&gt;\</code> with SHA256 checksum and ledger entry; detect duplicates before reprocessing.<br>7) Emit telemetry rows to <code>ImportLog</code> and <code>Telemetry</code> with <code>configHash</code>, <code>jobId</code>, and <code>correlationId</code> while redacting PII in telemetry (use hashed identifiers or evidenceRefs).<br>8) Be idempotent: repeated parse of the same archive checksum should not produce duplicate annotations unless operator explicitly requests reprocess. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Public API (conceptual function signatures & behavior)</strong><br>1) <code>ParsePortalErrors(filePath As String, Optional jobId As String, Optional matchPolicy As Dictionary) As ParseResult</code> — main entrypoint; performs archive, parse, match, annotate and returns structured <code>ParseResult</code> containing <code>matchedCount</code>, <code>unmatchedCount</code>, <code>ambiguousCount</code>, <code>archiveRef</code>, and <code>errors[]</code>.<br>2) <code>DetectPortalFormat(headerRow As Variant) As String</code> — classify known formats or return <code>UnknownFormat</code> with expected header template; uses exact-match registry followed by alias-based heuristics.<br>3) <code>MapPortalColumns(formatName As String) As Scripting.Dictionary</code> — returns canonical->portal column mapping for robust extraction; supports pluggable mapping configs.<br>4) <code>TokenizeCSV(filePath As String, Optional chunkSize As Long) As Generator</code> — robust tokenizer that yields portal row dictionaries or parse-error records; supports streaming for large files.<br>5) <code>MatchPortalRow(portalRow As Scripting.Dictionary, matchPolicy As Scripting.Dictionary) As MatchResult</code> — attempts deterministic matching and returns <code>MatchResult</code> with <code>matchType</code>, <code>sourceRowRef</code>, <code>matchedKeys[]</code>, <code>confidence</code> and <code>reason</code>.<br>6) <code>AnnotateSourceRow(sourceRowRef As Variant, portalRow As Scripting.Dictionary, archiveRef As ArchiveRef, operatorId As String)</code> — append-only write to <code>PortalErrors</code> history column with structured annotation and <code>remediationHint</code> for operator UI.<br>7) <code>ArchivePortalFile(filePath As String, jobId As String) As ArchiveRef</code> — copy+atomic-rename with SHA256 checksum; returns <code>{archivePath,checksum,archivedTs}</code>.<br>8) <code>GenerateUnmatchedArtifact(unmatchedRows As Collection, jobId As String) As String</code> — create stable <code>UnmatchedPortalErrors_&lt;jobId&gt;.xlsx</code> or workbook sheet and returns artifactRef.<br>9) <code>RegisterPortalFormat(formatName As String, headerPattern As Variant, mappingConfig As Scripting.Dictionary)</code> — plugin registration to avoid code edits when adding new portal export formats. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Inputs, outputs & side-effects (clear contract)</strong><br><strong>Inputs:</strong> portal CSV file path; optional <code>jobId</code>; optional <code>matchPolicy</code> override; <code>GetConfig()</code> snapshot for <code>STAGING_ARCHIVE_FOLDER</code>, <code>ARCHIVE_RETENTION_DAYS</code>, <code>UseEncryptedArchive</code>, and <code>configHash</code>; operator identity from <code>frmOperatorUI</code> when actions are UI-driven.<br><strong>Outputs / Side-effects:</strong> archived portal file with checksum; <code>PortalErrors</code> annotations appended to source table rows; <code>UnmatchedPortalErrors</code> artifact; <code>ImportLog</code> telemetry rows (<code>portal.parse.started</code>, <code>portal.parse.completed</code>, <code>portal.annotation.write</code>, <code>portal.parse.error</code>); ledger entry in <code>Batches</code>/<code>EvidenceLedger</code> for chain-of-custody; optional encrypted archive stored when <code>UseEncryptedArchive</code> enabled. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Determinism & idempotency rules</strong><br>1) Compute <code>archiveChecksum</code> from raw bytes first; if identical checksum archived previously, report <code>IMP_PORTAL_DUPLICATE</code> and avoid re-annotating unless <code>--reprocess</code> is explicitly requested via UI and logged.<br>2) Each annotation is identified by the triple <code>{archiveChecksum, portalRowIndex, portalErrorCode}</code>; before writing a new annotation, verify triple does not already exist in the source row's <code>PortalErrors</code> history to avoid duplicates.<br>3) <code>ComputeConfigHash()</code> value from <code>modConfig</code> must be included in all telemetry rows to enable deterministic grouping of runs under the same configuration. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Portal format detection & mapping</strong><br>1) <strong>Format registry</strong> — maintain an internal <code>PortalFormats</code> registry: each entry contains <code>formatName</code>, <code>headerPattern</code> (literal or regex with alias sets), <code>mappingConfig</code> (maps portal header to canonical fields), and <code>exampleRows</code> for CI tests.<br>2) <strong>DetectPortalFormat</strong> algorithm:<br>1) exact-case-insensitive header set match vs registry entries; if found return <code>formatName</code>.<br>2) otherwise, alias-map normalization (trim, lower, remove non-alpha chars) and fuzzy header matching (minimum required canonical fields present) to select best registry entry.<br>3) if no match and minimal keys absent, return <code>UnknownFormat</code> and include expected header template for operator/UI copy-paste.<br>3) <strong>Mapping config</strong> — mapping maps portal column name variants to canonical fields: <code>OriginalRow</code>, <code>PortalNIK</code>, <code>PortalName</code>, <code>PortalTglLahir</code>, <code>PortalErrorCode</code>, <code>PortalMessage</code>, <code>PortalRowIndex</code>. Mappings should accept multiple aliases per canonical field. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Robust CSV tokenization & parsing engine</strong><br>1) <strong>Primary approach</strong> — attempt <code>Workbooks.OpenText</code> with explicit parameters (delimiter, text qualifier, code page) when host supports it; compute raw byte checksum before call so checksum is independent from decoding errors.<br>2) <strong>Fallback approach</strong> — ADODB.Stream-based reader or custom RFC4180 tokenizer that: reads raw bytes, handles BOM detection, splits into lines preserving quoted newlines, tokenizes respecting double-quote escaping (<code>&quot;&quot;</code>), and yields rows as arrays or dictionaries.<br>3) <strong>Encoding fallback</strong> — attempt UTF-8, then Windows-1252 / ANSI, then try heuristics (BOM, common byte patterns); always compute checksum on raw bytes prior to decoding to ensure archive robustness.<br>4) <strong>Error recovery</strong> — rows with parsing issues are emitted as <code>ParseError</code> records with <code>rawText</code>, <code>rowIndex</code>, and <code>reason</code> and are saved into <code>UnparsedPortal_&lt;jobId&gt;</code> artifact for operator triage; parsing must not abort the entire run unless header-level failures occur. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Matching policy — prioritized, conservative, auditable</strong><br>Match priority (exact ordering):<br>1) <strong>OriginalRow index</strong> — portal-provided row index referencing a previously exported source snapshot row; only used if the portal export contract includes <code>OriginalRow</code> and the referenced snapshot checksum matches or a clear mapping exists; exact 1:1 preferred.<br>2) <strong>Primary Key exact match</strong> — normalized <code>NIK</code> (or organization-specific primary key) exact equality after canonical normalization rules (strip punctuation, preserve leading zeros).<br>3) <strong>Composite key exact match</strong> — <code>NIK + TglLahir</code>, or <code>NIK + Nama</code>, or other validated composite; both components normalized and matched exactly.<br>4) <strong>Deterministic candidate pre-filter</strong> — when large alias maps exist, use token-set pre-filtering to limit candidates to <code>MAX_CANDIDATES</code> to avoid O(N²) comparisons; seedScore computed by exact-token overlap count.<br>5) <strong>Conservative fuzzy match (last resort)</strong> — compute component similarity metrics (normalized levenshtein, token Jaccard, trigram overlap) but require conservative thresholds (e.g., combinedScore >= 0.92) and always mark such matches <code>FuzzyMatch</code> with <code>matchConfidence</code> and push borderline cases to <code>UnmatchedPortalErrors</code>. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Normalization rules used during matching</strong><br>1) <strong>NIK normalization</strong> — remove non-digit characters, preserve leading zeros, validate length (e.g., 16 digits typical), and tag <code>NIK_NORMALIZED</code> for matching; invalid NIKs result in <code>NIK_INVALID</code> tag.<br>2) <strong>Name normalization</strong> — unicode normalize to NFKC, remove diacritics when configured, remove punctuation except hyphen, collapse spaces, uppercase for canonical comparisons, and remove honorifics (configurable stoplist).<br>3) <strong>Date normalization</strong> — run <code>NormalizeDateText()</code> that attempts explicit locale-aware parse; ambiguous dates (e.g., <code>01/02/03</code> without locale) are not guessed — instead return <code>AMBIGUOUS_DATE</code> tag and push to <code>UnmatchedPortalErrors</code> unless operator provides <code>SourceLocale</code> in <code>matchPolicy</code>.<br>4) <strong>Phone/address normalization</strong> — when included in composite keys, apply country-aware formatting (E.164-like digits for phone) if <code>sourceCountry</code> is known; otherwise treat as auxiliary fields only. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>MatchResult structure & semantics</strong><br><code>MatchResult</code> must include: <code>matchType</code> (ExactIndex, ExactKey, Composite, FuzzyMatch, Ambiguous, Unmatched), <code>sourceRowRef</code> (if unique), <code>matchedKeys[]</code> (list of normalized keys used), <code>confidence</code> (0.0-1.0 for fuzzy), and <code>reason</code> (short phrase describing result).<br>Operator-facing behaviors based on <code>matchType</code>:<br>1) <code>ExactIndex</code> or <code>ExactKey</code> — automatically annotate and mark matched.<br>2) <code>Composite</code> — automatically annotate but highlight in UI when composite used for auditing.<br>3) <code>FuzzyMatch</code> — annotate but mark for review in <code>UnmatchedPortalErrors</code> or <code>AmbiguousMatches</code> unless <code>matchConfidence</code> exceeds <code>AutoAcceptThreshold</code> in config.<br>4) <code>Ambiguous</code> or <code>Unmatched</code> — do not annotate source rows; add rows to <code>UnmatchedPortalErrors</code> with <code>suggestedAction</code>. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Annotation schema & append-only storage</strong><br>1) <strong>Annotation payload (structured)</strong> — when writing to a source row <code>PortalErrors</code> field, store structured JSON-like data encoded safely for Excel (e.g., compact JSON or semicolon-delimited key-values) with fields: <code>portalFileRef</code>, <code>archiveChecksum</code>, <code>portalRowIndex</code>, <code>portalErrorCode</code>, <code>portalErrorMessage</code>, <code>matchType</code>, <code>matchedKeys</code>, <code>matchConfidence</code>, <code>annotatedTs</code>, <code>annotatedBy</code>, <code>remediationHint</code>, <code>evidenceRef</code>.<br>2) <strong>Append-only semantics</strong> — never overwrite existing history; append new annotations with <code>annotatedTs</code> and an incrementing <code>eventId</code>. Provide <code>visibleFlag</code> for UI collapsing older entries but preserve full history for auditors.<br>3) <strong>Remediation hint</strong> — compute a short, PII-safe <code>remediationHint</code> such as <code>Fix NIK format; reupload small batch</code> or <code>Provide OriginalRow in future export</code> to speed operator actions. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Unmatched/ambiguous artifact design</strong><br>1) <strong>Artifact contents</strong> — <code>UnmatchedPortalErrors_&lt;jobId&gt;</code> must contain: <code>portalRowIndex</code>, <code>portalRawData</code> (redacted minimally for PII governance unless operator requests full view), <code>reason</code>, <code>suggestedAction</code>, <code>candidateMatches</code> (if ambiguous), <code>archiveRef</code> link, and <code>parseError</code> (if row-level parse failed).<br>2) <strong>Operator actions suggested</strong> — <code>Request corrected portal export</code>, <code>Manual map to source row</code>, <code>Provide OriginalRow</code>, <code>Fix source NIK and reprocess small batch</code>. Each suggested action is accompanied by a short operator script or macro to perform the action (e.g., <code>CreateBatches</code> helper snippet or UI button).<br>3) <strong>Artifact lifecycle</strong> — artifact is versioned (e.g., <code>_v1</code>, <code>_v2</code>), stored under <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal_artifacts\</code> and tagged in <code>Batches</code> ledger and <code>ImportLog</code>. If <code>--overwrite</code> flag provided, a new artifact will replace previous with audit entry of replaced artifact. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Archival, checksums & chain-of-custody</strong><br>1) <strong>Compute checksum first</strong> — compute SHA256 on raw bytes; store checksum in <code>archiveChecksum</code> field and include it in every telemetry and annotation row so that evidence maps to annotations deterministically.<br>2) <strong>Atomic archive write</strong> — write to <code>archiveTemp = archivePath &amp; &quot;.tmp&quot;</code>, flush stream, then <code>Name archiveTemp as archivePath</code> to achieve atomicity; on failure, delete <code>.tmp</code> and return <code>IMP_BATCH_001</code> with remediation. <br>3) <strong>Ledger entry</strong> — add a row to <code>Batches</code>/<code>EvidenceLedger</code> for each archived portal file with <code>{archivePath, checksum, originalFileName, fileSize, archivedTs, jobId, operatorId, retentionDays}</code> to support later purge or custody transfer. <br>4) <strong>Duplicate detection</strong> — before parsing, check <code>EvidenceLedger</code> for matching checksum; if found, log <code>IMP_PORTAL_DUPLICATE</code> and return the existing <code>archiveRef</code> unless operator requests reprocess. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Security, encryption & PII handling</strong><br>1) <strong>No raw PII in telemetry</strong> — convert PII to stable hashed identifiers in telemetry (e.g., <code>sha256(NIK)</code>) or reference <code>evidenceRef</code> that maps to encrypted archive accessible only to authorized operators; never include raw names or NIK in <code>ImportLog</code> rows. <br>2) <strong>Encrypted archive option</strong> — if <code>UseEncryptedArchive</code> enabled in <code>GetConfig()</code>, call <code>modUtilities.GetSecretFromStore(&quot;archiveKey&quot;)</code> to fetch encryption key (never store keys in code), encrypt bytes with AES-GCM or equivalent streaming cipher, compute checksum of the encrypted artifact and store both plaintext-checksum and encrypted-checksum in <code>EvidenceLedger</code> for chain-of-custody. <br>3) <strong>ACL recommendation</strong> — after archive, set folder ACLs to read-only for <code>stagingAclSuggestedGroup</code> (if host fs supports it) and write <code>archive.acl.set{archivePath}</code> telemetry row; give operator instructions to validate ACLs for scheduled runs. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Observability & telemetry events</strong><br>Emit structured telemetry rows to <code>ImportLog</code> and optional <code>Telemetry</code> table for BI:<br>1) <code>portal.parse.started{fileName,checksum,rowsCount,jobId,configHash}</code> when parse begins.<br>2) <code>portal.parse.progress{rowsProcessed,totalRows,elapsedMs,jobId}</code> periodically for UI progress.<br>3) <code>portal.parse.completed{matchedCount,unmatchedCount,ambiguousCount,durationMs,archiveRef,jobId}</code> on success.<br>4) <code>portal.parse.error{errorCode,detail,jobId}</code> on fatal failures.<br>5) <code>portal.annotation.write{sourceRowRef,portalRowIndex,portalErrorCode,annotatedTs,jobId}</code> for each annotation persisted.<br>Telemetry policy: never include PII values directly; include <code>configHash</code> and <code>archiveChecksum</code> to support downstream reconciliation. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Failure modes & recovery strategies</strong><br>1) <strong>Header mismatch / missing keys (<code>IMP_PORTAL_001</code>)</strong> — abort parse early; write <code>ImportLog</code> entry with expected header template; operator should request corrected portal export or register a new portal format via <code>RegisterPortalFormat</code>.<br>2) <strong>Malformed CSV rows (<code>IMP_PORTAL_003</code>)</strong> — collect as <code>ParseError</code> records and write <code>UnparsedPortal_&lt;jobId&gt;</code> artifact; proceed with parsable rows so partial progress is not lost. <br>3) <strong>Archive write failure (<code>IMP_BATCH_001</code>)</strong> — do not annotate source tables; abort parse and return structured error with remediation steps (check disk space, ACLs, alternate staging path) and perform cleanup of temporary files. <br>4) <strong>Partial-run interruption</strong> — if process crashes mid-annotation, on re-run detect <code>archiveChecksum</code> presence and compare annotations to expected triple set to avoid duplication; produce a <code>portal.parse.partial</code> reconciliation row and a <code>portal.reconcile</code> artifact enumerating line ranges already annotated. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Operator UI flows & interaction patterns</strong><br>1) <strong>Upload & Parse</strong> — operator uses <code>frmOperatorUI</code> to select portal file -> UI shows confirmation -> <code>ParsePortalErrors(filePath, jobId)</code> called -> progress modal with <code>Cancel</code> option (sets <code>CancelRequested</code>) and periodic <code>portal.parse.progress</code> updates.<br>2) <strong>Review unmatched</strong> — after completion, UI shows <code>UnmatchedPortalErrors</code> sheet with quick action buttons: <code>Request Portal Rerun</code>, <code>Manual Map</code>, <code>Create Correction Batch</code> and includes <code>suggestedAction</code> for each row.<br>3) <strong>Ambiguity resolution</strong> — UI shows candidate matches with component breakdown (NIK match, Name similarity, Date proximity) and buttons <code>Select candidate</code> or <code>Reject all</code>; selection triggers <code>AnnotateSourceRow()</code> and logs <code>portal.manual.resolve{portalRowIndex,chosenSourceRow,operatorId}</code>. <br>4) <strong>Reprocess flow</strong> — explicit typed confirmation required in UI for <code>--reprocess</code> operations; all reprocess actions emit audit with <code>operatorId</code> and are recorded in <code>ImportLog</code>. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Testing matrix & QA strategy (exhaustive)</strong><br><strong>Unit tests</strong> (per-rule):<br>1) Header normalization and alias mapping — feed sample headers and assert <code>DetectPortalFormat()</code> resolution and <code>MapPortalColumns()</code> correctness.<br>2) NIK normalization — leading zeros, punctuation stripping, invalid-length detection produce expected normalized forms or <code>NIK_INVALID</code> tag.<br>3) Date normalization — locale-specific parses return canonical ISO dates; ambiguous examples produce <code>AMBIGUOUS_DATE</code> tags.<br>4) Tokenizer robustness — quoted newlines, embedded double-quotes, and odd line endings parse to expected row arrays or <code>ParseError</code> entries. <br><strong>Integration tests (E2E)</strong>:<br>1) Parse canonical portal exports for each supported format; verify archives created, <code>archiveChecksum</code> recorded, no duplicate annotations on re-run without <code>--reprocess</code>, and <code>UnmatchedPortalErrors</code> content correct for known ambiguous cases.<br>2) Partial failure simulation: throw disk-full during archive and assert no annotations were written and <code>IMP_BATCH_001</code> logged with cleanup. <br><strong>Chaos tests</strong>:<br>1) Malformed CSV with extremely long rows or binary blobs — ensure the parser produces <code>UnparsedPortal</code> artifact and does not crash the host. <br><strong>Security tests</strong>:<br>1) Confirm telemetry contains no raw PII by scanning emitted logs for NIK-like patterns when processing PII-rich fixture files. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Performance & scaling guidance</strong><br>1) For large portal files (> 100k rows), use streaming tokenizer with configurable <code>PARSER_CHUNK_SIZE</code> and emit <code>portal.parse.progress</code> every chunk; avoid loading entire file into memory.<br>2) Pre-filter candidate source rows using token-set indices (e.g., inverted index on normalized NIK or tokens) to reduce expensive similarity computations; cap <code>MAX_CANDIDATES</code> (e.g., 200) to bound CPU cost.<br>3) For heavy workloads, provide <code>CreateJobDescriptor(&quot;ParsePortal&quot;, {filePath, archiveRef, configHash})</code> to offload to worker pool using <code>GetWorkerConfigSubset()</code> for safe config serialization. <br>4) Bulk-write optimizations: aggregate annotation writes into an array and batch-commit to the <code>ListObject</code> using single <code>DataBodyRange.Value</code> assignment to minimize COM round trips. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>CI/CD & golden-parity requirements</strong><br>1) Any change to header alias maps, mapping rules, or fuzzy thresholds must be accompanied by portal fixture updates and golden-file checksums in CI to prevent silent regressions.<br>2) <code>ComputeConfigHash()</code> must include <code>FEATURE_FLAGS.DisableFuzzyPortalMatch</code>, <code>PQ_VERSION</code> (if PQ is used in pre-normalization), and other keys that can change matching behavior; CI must run canonical parsing fixtures for any <code>CONFIG_HASH</code> change and require two-person approval for changes affecting production mappings. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Integration with other modules</strong><br>1) <strong>modConfig</strong> — read <code>STAGING_ARCHIVE_FOLDER</code>, <code>ARCHIVE_RETENTION_DAYS</code>, <code>UseEncryptedArchive</code>, <code>configHash</code>, and <code>PQ_VERSION</code> for telemetry and retention; call <code>AssertStagingFolder()</code> prior to any archive writes.<br>2) <strong>modUtilities</strong> — use <code>WriteUtf8FileAtomic</code>, <code>ComputeFileChecksum</code>, <code>Retry</code>/<code>Backoff</code> wrappers, <code>LogAction</code> for telemetry, and <code>GetSecretFromStore</code> for archive encryption keys; do not reimplement crypto primitives in modErrorParser. <br>3) <strong>modBatchProcessing</strong> — produce <code>suggestedAction</code> outputs and <code>rowRange</code> hints that can be consumed by <code>CreateBatches</code> to create small correction batches for portal re-submission. <br>4) <strong>modPQController / PQ</strong> — if portal exports are normalized by PQ (e.g., placed in a watched folder and PQ produces <code>Portal_Preflight</code>), modErrorParser should operate on a snapshot CSV to preserve deterministic checksum semantics and include <code>PQ_VERSION</code> in <code>CONFIG_HASH</code>. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Conceptual Power Query (PQ) guidance for portal workflows</strong><br>1) <strong>When to use PQ:</strong><br>1) PQ is ideal for deterministic, set-based column-level normalization: trimming, control-character stripping, lower-casing headers, small lookup joins, and producing a normalized preview table for operators used in triage. <br>2) Use PQ to produce a <code>Portal_Sample</code> preflight that flags header and parse issues and to automatically normalize obvious variations of header names, reducing operator friction for common portal formats. <br>2) <strong>When not to use PQ:</strong><br>1) PQ should not be used for archive checksum computation, file moves, encryption, streaming parsing, or any step that requires guaranteed atomic file copy semantics — those remain in VBA to ensure deterministic archive checksums independent of PQ host behavior. <br>3) <strong>Integration pattern:</strong><br>1) If portal exports are placed in a shared folder, PQ can be used to provide a quick preview, but the authoritative parse must use the raw CSV snapshot produced by Excel/VBA to compute checksum and perform archival operations. <br>2) Ensure <code>PQ_VERSION</code> is part of <code>CONFIG_HASH</code> so that changes in PQ normalization are visible and tested in CI. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance for portal reconciliation</strong><br>1) <strong>Dimensions to include:</strong> <code>JobID</code>, <code>ConfigHash</code>, <code>PortalSource</code>, <code>ArchiveChecksum</code>, <code>OperatorId</code>, <code>ParseDate</code>, <code>MatchType</code>, <code>PortalErrorCode</code>, <code>ResolutionState</code> (Unmatched / Ambiguous / Resolved / Annotated).<br>2) <strong>Key measures:</strong><br>1) <code>PortalMatchRate = DIVIDE(SUM(PortalMetrics[MatchedCount]), SUM(PortalMetrics[TotalCount]), 0)</code><br>2) <code>PortalAmbiguousRate = DIVIDE(SUM(PortalMetrics[AmbiguousCount]), SUM(PortalMetrics[TotalCount]), 0)</code><br>3) <code>AvgParseTimeMs = AVERAGE(PortalMetrics[ParseDurationMs])</code><br>3) <code>AvgAnnotationLatency = AVERAGE(PortalAnnotations[annotatedTs] - PortalMetrics[archiveTs])</code><br>3) <strong>Alerts & SLOs:</strong> set alerts for <code>PortalMatchRate</code> falling below expected thresholds (e.g., 95%) and track <code>PortalDuplicateRate</code> to detect unexpected re-uploads. <br>4) <strong>Audit reports:</strong> slice by <code>ConfigHash</code> and <code>PQVersion</code> to diagnose regressions after config or PQ changes; maintain <code>migration_manifest</code> mapping to explain deliberate config updates. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Operational runbook & immediate remediation steps</strong><br>1) <strong>If parse aborts with <code>IMP_PORTAL_001</code> (missing header):</strong> present expected header template to portal support and provide <code>archiveRef</code> for their debug; do not proceed until a corrected portal export is supplied. <br>2) <strong>If archive write fails (<code>IMP_BATCH_001</code>):</strong> check <code>STAGING_ARCHIVE_FOLDER</code> availability, disk space, and ACLs; attempt <code>AssertStagingFolder()</code> and re-run; if scheduled job, ensure service account UNC access and not a mapped drive. <br>3) <strong>If many ambiguous rows appear:</strong> temporarily disable fuzzy match in <code>matchPolicy</code> and request portal to include <code>OriginalRow</code> or stable primary key columns in future exports. <br>4) <strong>If duplicate portal file detected:</strong> verify the existing <code>archiveRef</code> and annotation history; if operator intends to reprocess after manual correction, ensure <code>--reprocess</code> invoked and audit the action. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Error code catalog (recommended)</strong><br>1) <code>IMP_PORTAL_001</code> — portal CSV missing required header or expected keys; remediation: request canonical export or register new portal format.<br>2) <code>IMP_PORTAL_002</code> — header unparseable due to BOM/encoding anomalies; remediation: open file in binary-safe editor and re-export with UTF-8 BOM or Windows-1252 as required.<br>3) <code>IMP_PORTAL_003</code> — CSV parse errors (malformed quotes, inconsistent field counts); remediation: provide <code>UnparsedPortal</code> artifact and request corrected export; perform partial parse if safe rows exist.<br>4) <code>IMP_PORTAL_DUPLICATE</code> — portal file already processed (archive checksum match); remediation: review existing annotations and use <code>--reprocess</code> only when necessary and with typed confirmation.<br>5) <code>IMP_BATCH_001</code> — archive write failed (disk space or permission); remediation: free disk space, fix ACLs, or change staging folder. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Developer best practices & implementation notes</strong><br>1) <strong>Small, testable functions</strong> — break parser into <code>DetectPortalFormat</code>, <code>TokenizeCSV</code>, <code>NormalizeRow</code>, <code>MatchPortalRow</code>, <code>AnnotateSourceRow</code>, and <code>ArchivePortalFile</code> so each piece is unit-testable.<br>2) <strong>Avoid COM per-row writes</strong> — collect annotation payloads in arrays and commit in bulk to ListObject to minimize COM overhead and host slowness.<br>3) <strong>Compute checksum before decode</strong> — always compute archive SHA256 on raw bytes before any decoding so checksum does not depend on host code page behavior.<br>4) <strong>Use modUtilities primitives</strong> — do not reimplement atomic UTF-8 writes or crypto — call <code>modUtilities.WriteUtf8FileAtomic</code>, <code>ComputeFileChecksum</code>, and <code>Retry</code> wrappers for robust IO. <br>5) <strong>CI fixtures</strong> — store canonical portal fixtures and expected <code>archiveChecksum</code> values in <code>tests/portal-fixtures/</code> and verify parity in CI when parser or mapping configs change. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Extensibility & plugin hooks</strong><br>1) <strong>Portal format registry</strong> — support <code>RegisterPortalFormat()</code> so new portal vendors are supported by adding metadata and fixture tests (no code changes required to core parser logic).<br>2) <strong>MatchPolicy overrides</strong> — allow operator UI to pass <code>matchPolicy</code> such as <code>{preferOriginalRow:True, allowFuzzyMatch:False, compositeKeys:[NIK,TglLahir]}</code> for specific jobs or one-off runs.<br>3) <strong>OnParseComplete webhook</strong> — optional <code>onParseComplete(url)</code> callback that posts <code>{archiveRef,summary}</code> for downstream automation (ensure PII-free payloads).<br>4) <strong>Worker offload</strong> — integrate <code>CreateJobDescriptor()</code> so very large portal files can be processed by workers with <code>GetWorkerConfigSubset()</code> to minimize PII in serialized payloads. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Preflight & PQ conceptual patterns for portal imports</strong><br>1) <strong>Use PQ for preview & header normalization</strong> — PQ is excellent at deterministic column-level normalization and small mapping joins; use PQ to provide operator preview and early header normalization suggestions (e.g., map <code>NoNIK</code> -> <code>NIK</code>).<br>2) <strong>Keep final authoritative parse in VBA</strong> — because VBA controls raw file bytes, atomic archive semantics, checksums, encryption, and ACL adjustments, always perform final parse/annotation in VBA after PQ preview. <br>3) <strong>PQ <-> VBA handoff pattern</strong> — <code>ReloadConfig()</code> updates <code>Settings</code> sheet, PQ uses <code>Settings</code> for parameterized normalization, then <code>modErrorParser.ParsePortalErrors()</code> uses raw snapshot for authoritative archive and annotation. <br>4) <strong>Record <code>PQ_VERSION</code> in <code>CONFIG_HASH</code></strong> — when PQ is used for pre-normalization, include <code>PQ_VERSION</code> in <code>ComputeConfigHash()</code> so PQ changes are visible in telemetry and CI. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX examples & recommended reports</strong><br>1) <strong>Operational dashboard slices</strong> — provide slicers for <code>ConfigHash</code>, <code>PortalSource</code>, and <code>JobID</code> to diagnose regressions by configuration change.<br>2) <strong>Important measures</strong>:<br>1) <code>PortalMatchRate = DIVIDE(SUM(PortalMetrics[MatchedCount]), SUM(PortalMetrics[TotalCount]), 0)</code><br>2) <code>AmbiguousRate = DIVIDE(SUM(PortalMetrics[AmbiguousCount]), SUM(PortalMetrics[TotalCount]), 0)</code><br>3) <code>AvgAnnotationLatency = AVERAGE(PortalAnnotations[AnnotatedTs] - PortalMetrics[ArchiveTs])</code><br>3) <code>PortalDuplicateRate = DIVIDE(SUM(PortalMetrics[DuplicateDetected]), SUM(PortalMetrics[TotalCount]), 0)</code><br>3) Use <code>ConfigHash</code> as the primary dimension to detect when behavior changed after a config or PQ update. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Operational checklists & runbook snippets</strong><br>1) <strong>Before a run:</strong> verify <code>STAGING_ARCHIVE_FOLDER</code> ACLs, confirm <code>RAW_TABLE_NAME</code>/<code>PREFLIGHT_TABLE_NAME</code> exist, confirm <code>CONFIG_HASH</code> in UI. <br>2) <strong>During parse:</strong> monitor <code>portal.parse.progress</code> telemetry and cancel cooperative parsing if UI <code>CancelRequested</code> toggled; do not leave <code>.tmp</code> archive files. <br>3) <strong>After parse:</strong> review <code>UnmatchedPortalErrors</code>, perform triage actions, and if corrections are required, generate correction batches with <code>CreateBatches</code> and note <code>archiveRef</code> in <code>Batches</code> ledger for chain-of-custody. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Acceptance criteria & final verification</strong><br>1) Parse a set of canonical portal fixture files and verify computed <code>archiveChecksum</code> matches stored golden checksums.<br>2) Re-running <code>ParsePortalErrors()</code> on the same file without <code>--reprocess</code> should return <code>IMP_PORTAL_DUPLICATE</code> and not create duplicate annotations.<br>3) All telemetry rows generated include <code>configHash</code> and <code>jobId</code>, and telemetry contains no raw PII values.<br>4) <code>UnmatchedPortalErrors</code> artifact provides actionable remediation hints and evidenceRef for every unmatched or ambiguous portal row. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Common pitfalls and mitigations</strong><br>1) <strong>Pitfall:</strong> assuming portal exports include <code>OriginalRow</code> — mitigation: always support fallback matching by normalized primary key and composite keys, and insist on <code>OriginalRow</code> in portal contract for high-assurance integrations.<br>2) <strong>Pitfall:</strong> performing archive checksum after decoding text — mitigation: compute checksum on raw bytes before any decoding to ensure stable artifact checksums across hosts and code pages.<br>3) <strong>Pitfall:</strong> writing annotations before successful archive — mitigation: archive first, verify checksum, then annotate; if archive fails, do not mutate source tables. <br>4) <strong>Pitfall:</strong> exposing PII in telemetry — mitigation: enforce telemetry redaction rules and use evidenceRefs and hashed identifiers only. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Developer checklist before commit</strong><br>1) Add or update portal fixtures in <code>tests/portal-fixtures/</code> and include expected <code>archiveChecksum</code> for CI golden tests.<br>2) Add unit tests for each new header alias and mapping case to <code>DetectPortalFormat()</code> and <code>MapPortalColumns()</code> invocation paths.<br>3) Validate that <code>ParsePortalErrors()</code> emits <code>portal.parse.completed</code> telemetry with expected counts and that telemetry contains <code>configHash</code> and <code>archiveChecksum</code> but no raw PII. <br>4) Update <code>migration_manifest.json</code> for mapping or parsing-behavior changes and secure two-person sign-off for prod-impacting changes. </td></tr><tr><td data-label="modErrorParser — Per-function technical breakdown (VBA)"> <strong>Closing operational note</strong><br>modErrorParser must be treated as a high-assurance component: it produces annotations that affect downstream remediations, re-uploads, and audit evidence. Implement it with conservative default policies (favor operator-in-the-loop for ambiguous/fuzzy matches), compute immutable archive checksums before any mutation, and gate any changes that affect parsing/matching with CI golden-file tests and documented approval flows. </td></tr></tbody></table></div><div class="row-count">Rows: 34</div></div><div class="table-caption" id="Table8" data-table="YJKN_0017_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modUtilities — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modUtilities — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Executive summary & intent</strong><br>modUtilities is the foundational runtime utilities module for the IMPORT DATA pipeline. It provides low-level, host-aware, and highly-tested primitives that every other module depends on: structured logging, atomic UTF-8 writes, robust checksum computation, table/ListObject helpers, retry/backoff orchestration, secret-store adapters, CSV parsing helpers, safe I/O patterns, and host compatibility shims. The module's design goals are safety, determinism, low dependencies, clear structured error returns (no uncaught exceptions), and strong telemetry so every operational action is auditable and reproducible. modUtilities must not contain business logic; it only offers primitives and adapter hooks. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Scope & responsibility (single-sentence contract)</strong><br>Provide deterministic, atomic, and observable low-level primitives for filesystem I/O, logging, checksum, secret retrieval, table management, and retry logic that are portable across supported Excel hosts and safe for production automation. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Public API (conceptual function list and contract summary)</strong><br>1) <code>LogAction(action As String, details As Dictionary, Optional severity As String = &quot;INFO&quot;) As Variant</code> — append structured audit / telemetry row to ImportLog or fallback to safe stash file; returns <code>{success,stashPath?,error?}</code>.<br>2) <code>WriteUtf8FileAtomic(path As String, content As String, Optional UseBom As Boolean = True) As Variant</code> — guaranteed atomic write to path; returns <code>{success,path,checksum}</code> or structured error.<br>3) <code>ComputeFileChecksum(path As String, Optional algorithm As String = &quot;SHA256&quot;) As Variant</code> — buffered checksum; returns <code>{algorithm,hex}</code> or error.<br>4) <code>EnsureTableExists(sheetName As String, headerArray() As String, tableName As String, Optional allowHeaderFix As Boolean=False) As Variant</code> — idempotent ListObject creation/validation; returns <code>{success,tblRef,error}</code>.<br>5) <code>FindListColumnIndex(tbl As ListObject, columnName As String) As Long</code> — normalized lookup; returns 1-based index or -1.<br>6) <code>Retry(actionFunc As String, attempts As Long, initialBackoffMs As Long, Optional maxBackoffMs As Long, Optional jitterPct As Double) As Variant</code> — retry wrapper with exponential backoff and jitter; returns last action result.<br>7) <code>GetSecretFromStore(secretName As String) As Variant</code> — secure secret retrieval via provider adapters; returns <code>{ok,value}</code> or <code>{ok=False,error}</code>.<br>8) <code>SafeOpenCsv(path As String, Optional params As Dictionary) As Variant</code> — robust CSV parse with modes <code>strict/relaxed/raw</code>; returns parsed output or an <code>UnparsedArtifact</code> for manual triage.<br>9) <code>CleanupTempArtifacts(ageHours As Long)</code> — remove stale temp artifacts older than threshold; returns summary. <br>10) <code>EnsureDiskSpace(path As String, requiredBytes As Currency) As Variant</code> — checks free space and returns <code>{ok,freeBytes}</code> or error. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Design principles & guarantees</strong><br>1) <strong>Atomicity first</strong> — all external writes must be atomic (temporary file + rename) to avoid partial reads by downstream consumers. <br>2) <strong>Prefer structured returns to exceptions</strong> — functions return structured result objects with <code>success</code> booleans and error payloads so caller modules can triage and decide action. <br>3) <strong>Idempotency where appropriate</strong> — operations that can be retried must be idempotent or require an <code>idempotencyKey</code>. <br>4) <strong>Host-aware fallbacks</strong> — use high-performance platform APIs when available (ADODB.Stream, CryptoAPI) and pure-VBA fallbacks otherwise, logging detection of fallbacks. <br>5) <strong>Observability & minimal PII in logs</strong> — log hashes or evidenceRefs rather than raw PII, and offer a documented path to archive raw evidence into encrypted storage for regulated runs. <br>6) <strong>No business logic</strong> — modUtilities must not interpret domain fields; it only performs safe primitives. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Structured error objects & recommended fields</strong><br>Every error return must include the following fields: <code>success:Boolean</code>, <code>errorCode:String</code>, <code>field(Optional):String</code>, <code>desc:String</code>, <code>detail(Optional):String</code>, <code>remediation:String</code>, <code>traceId(Optional):String</code>. Example codes used by other modules: <code>IMP_BATCH_001</code> (file write failed), <code>IMP_CFG_001</code> (staging folder), <code>IMP_UTIL_001</code> (checksum failure), <code>IMP_PORTAL_001</code> (CSV parse mismatch). </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>LogAction — detailed behavior & patterns</strong><br><strong>Purpose & semantics:</strong> structured telemetry and audit log anchor for the pipeline; must be append-only and include correlation fields.<br><strong>Payload fields to maintain:</strong> <code>Timestamp, JobID, CorrelationID, Action, Severity, Message, OperatorID, MachineName, ConfigHash, PayloadHash, EvidenceRef</code>.<br><strong>Idempotency handling:</strong> callers MAY include an <code>idempotencyKey</code> inside <code>details</code>; <code>LogAction</code> will consult an in-memory idempotency cache for the current session and optionally consult a persisted idempotency ledger (small table) to prevent duplicate log rows for retried operations; when duplication is detected, <code>LogAction</code> returns <code>{success:True,skipped=True,reason:&quot;duplicate&quot;}</code>. <br><strong>Concurrency & cross-process:</strong> protect in-memory append with <code>LogMutex</code> for same-process concurrency; for multi-process scenarios write stash JSON files in <code>STAGING_FOLDER\log_stash\</code> and provide background drain when workbook is active. <br><strong>Failure fallback:</strong> if the <code>ImportLog</code> table is locked or unavailable, persist log rows as encrypted JSON files named <code>&lt;jobId&gt;-&lt;ts&gt;-log.json</code> in <code>STAGING_FOLDER\log_stash\</code> and return <code>{success:False,stashPath:...}</code>; provide <code>DrainStashedLogs()</code> utility invoked by operator UI to ingest back into ImportLog and log <code>stash.drain</code> events. <br><strong>Retention & sampling:</strong> support <code>DiagnosticsSamplingRate</code> config; when noisy events exceed sampling thresholds aggregate and emit summary metrics rather than per-row logs to avoid telemetry explosion. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>WriteUtf8FileAtomic — contract & implementation considerations</strong><br><strong>Atomic semantics required:</strong> always write to <code>target.tmp</code> in the same folder, flush and close, then <code>Name</code> (rename) to <code>target</code> to achieve atomic visibility. <br><strong>Temp file naming policy:</strong> include PID/uid and random token <code>&lt;base&gt;.tmp.&lt;pid&gt;.&lt;rand&gt;</code> to avoid collisions across concurrent writers. <br><strong>Encoding & BOM:</strong> default to UTF-8 with optional BOM (<code>UseBom=True</code>); make this configurable via <code>GetConfig()[&quot;USE_UTF8&quot;]</code> and <code>GetConfig()[&quot;CSV_BOM_POLICY&quot;]</code>. <br><strong>Preferred write path:</strong> use ADODB.Stream when COM is available for reliable byte writes; fallback to <code>Open For Binary</code> buffered writes with explicit UTF-8 encoding routine when ADODB unavailable. <br><strong>Cross-volume rename fallback:</strong> rename must fail if source and target are on different volumes; detect and, if needed, copy then verify checksum then delete source; log <code>io.crossVolumeRename</code> for audit. <br><strong>Checksum & final return:</strong> after successful rename compute <code>ComputeFileChecksum(finalPath)</code> and return <code>{success:True,path:finalPath,checksum:&quot;sha256:...&quot;}</code>; if checksum computation fails, treat as non-fatal but return detail in response so callers may decide to retry. <br><strong>Crash resilience & cleanup:</strong> on startup run <code>CleanupTempArtifacts()</code> to remove orphan <code>.tmp.*</code> files older than safe threshold; ensure temp files have restricted ACLs when possible. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>ComputeFileChecksum — strategy & fallbacks</strong><br><strong>Preferred algorithm:</strong> SHA-256 for deterministic golden-parity checks in CI; algorithm configurable but CI asserts SHA-256 parity for canonical fixtures. <br><strong>Performance:</strong> read file in buffered chunks (e.g., 64 KB or 128 KB) and update digest incrementally; avoid loading entire file into memory. <br><strong>Crypto providers:</strong> on Windows prefer platform crypto via <code>Crypt32</code>/<code>BCrypt</code> COM or native provider; if unavailable, use a pure-VBA SHA256 implementation as fallback and log <code>util.crypto.fallback</code> when used. <br><strong>Return shape:</strong> <code>{success:True,algorithm:&quot;SHA256&quot;,hex:&quot;...&quot;}</code> or <code>{success:False,errorCode:&quot;IMP_UTIL_001&quot;,desc:&quot;...&quot;,remediation:&quot;...&quot;}</code>. <br><strong>Large file considerations:</strong> for extremely large files optionally support chunked partial checksumming and a manifest of chunk checksums when worker offload is used; provide <code>ComputeFileChecksumAsync</code> via <code>CreateJobDescriptor</code> offload pattern for heavy workloads. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>EnsureTableExists — semantics & safe behaviors</strong><br><strong>Behavior:</strong> validate or create a ListObject with exact header parity; do not silently reorder columns; provide <code>allowHeaderFix</code> flag to enable automatic header normalization when explicitly requested.<br><strong>Validation rules:</strong> case-insensitive trimmed header comparison; whitespace and control-char cleaned for comparison but returned names must match <code>headerArray</code>. If mismatch occurs return <code>{success:False,errorCode:&quot;IMP_PF_001&quot;,expected:headerArray,found:found}</code>. <br><strong>Creation flow:</strong> create worksheet if missing, insert header row, create ListObject named <code>tableName</code>, set initial column formatting to <code>Text</code> for all columns, set <code>Table.ShowTotals = False</code> and apply a neutral table style configured in <code>GetConfig()</code>. <br><strong>Atomicity & events:</strong> during creation set <code>Application.EnableEvents=False</code> and <code>ScreenUpdating=False</code>; call creation within error-handled block and restore state on exit; in case of partial creation revert and return structured error. <br><strong>Concurrency & multi-user:</strong> Excel ListObjects are workbook-scoped; concurrent edits from multiple instances may cause race conditions — use a simple advisory lock pattern implemented as <code>ThisWorkbook.Names(&quot;TableCreateLock&quot;)</code> with timestamp; if lock is active, wait with exponential backoff or return <code>IMP_UTIL_002</code> advising operator to retry later. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>FindListColumnIndex — normalization & edge cases</strong><br><strong>Normalization:</strong> compare trimmed, lowercased column names with punctuation normalization (remove control-chars). <br><strong>Duplicate column names:</strong> return first match and log <code>util.warn.duplicateColumn</code> when duplicates exist; provide <code>FindAllListColumnIndexes(tbl, columnName)</code> variant to return all matches when callers need to triage duplicates. <br><strong>Return contract:</strong> integer 1-based index or <code>-1</code> on missing; do not raise exceptions for missing columns. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Safe CSV parsing (SafeOpenCsv) — robust parsing & triage artifacts</strong><br><strong>Modes:</strong> <code>strict</code> — RFC4180 compliant, abort on malformed rows and return <code>IMP_PORTAL_001</code>; <code>relaxed</code> — best-effort parse marking problematic rows with <code>ParseError</code> fields; <code>raw</code> — import file as single-column evidence for manual inspection.<br><strong>Parsing engine:</strong> prefer <code>Workbooks.OpenText</code> for typical portal CSVs when available; for complicated quoting or embedded newlines implement a streaming tokenizer that handles quoted fields, escaped quotes (<code>&quot;&quot;</code>), and embedded CRLF sequences. <br><strong>Large-file handling:</strong> stream parse in chunks and flush parsed rows to a temporary ListObject to avoid memory/timeouts; check <code>CancelRequested</code> between chunks to support UI cancellation. <br><strong>Header mapping flexibility:</strong> detect expected column headers using fuzzy-normalization (trim, collapse spaces, common synonyms mapping table) but only when <code>params.AllowHeaderCorrection</code> is True; when correction performed log <code>csv.header.autoFix</code> with explicit <code>before</code> and <code>after</code> mapping. <br><strong>Archival & chain-of-custody:</strong> upon successful parse move original CSV to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal\&lt;origfilename&gt;</code> and compute checksum; record archive entry for audits and optionally encrypt archive per <code>GetConfig()</code> policy. <br><strong>Unmatched / Unparsed artifacts:</strong> when parse fails create <code>UnparsedPortal</code> artifact in <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\unparsed\</code> with <code>parseDiagnostics.json</code> and return its path for manual triage. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Retry wrapper — usage & safety rules</strong><br><strong>Signature & defaults:</strong> <code>Retry(action, attempts=3, initialBackoffMs=250, maxBackoffMs=5000, jitterPct=0.25)</code>. <br><strong>Action constraints:</strong> action must be idempotent or accept an <code>idempotencyKey</code>; <code>Retry</code> will not make a non-idempotent action magically safe — it logs a warning if action declares <code>nonIdempotent</code> in metadata. <br><strong>Backoff schedule:</strong> exponential doubling with jitter applied uniformly within ± jitterPct; use <code>DoEvents</code> and <code>Sleep</code> between retries to yield host. <br><strong>Logging & observability:</strong> each attempt emits <code>retry.attempt{action,attempt,backoffMs}</code> to ImportLog; on success emit <code>retry.success{attempt}</code>; on failure after exhaustion emit <code>retry.failed{attempts,action}</code>. <br><strong>Cancellation:</strong> if <code>CancelRequested</code> is set, <code>Retry</code> returns immediately with <code>{success:False,error:&quot;Cancelled&quot;}</code>. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>GetSecretFromStore — provider pattern & security</strong><br><strong>Design:</strong> adapter pattern to support multiple secret providers: <code>WindowsCredentialManager</code>, <code>DPAPILocalStore</code>, <code>AzureKeyVaultAdapter</code>, <code>LocalDevSheetAdapter</code>. <br><strong>Contract:</strong> always return <code>{ok:True,value:&quot;...&quot;}</code> or <code>{ok:False,errorCode,desc,remediation}</code>; never log the secret value — only log <code>secretNameHash</code> and provider name. <br><strong>Production rules:</strong> in <code>GetConfig()</code>, if <code>SecretProvider</code> is not configured and host is production, <code>GetSecretFromStore</code> should fail with <code>{ok:False,errorCode:&quot;IMP_SEC_001&quot;,desc:&quot;No secret provider configured&quot;,remediation:&quot;Configure provider via secure runbook&quot;}</code>. <br><strong>Operator consent & auditing:</strong> when a new provider is used require operator confirmation in UI (typed consent) and log <code>secret.access.granted{secretNameHash,provider,operatorId}</code>. <br><strong>Local dev fallback:</strong> allow <code>LocalDevSheetAdapter</code> only when <code>GetConfig()[&quot;AllowLocalSecrets&quot;]</code> is True and host is interactive; otherwise fail fast. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Safe I/O primitives & filesystem helpers</strong><br><strong>EnsureDiskSpace(path, requiredBytes)</strong> — check free bytes on target filesystem and return <code>{ok:True,freeBytes}</code> or <code>{ok:False,errorCode:&quot;IMP_IO_001&quot;,desc:&quot;Insufficient disk space&quot;,remediation:&quot;Free up X bytes or choose alternate staging folder&quot;}</code>. <br><strong>Atomic rename semantics:</strong> prefer same-volume <code>Name</code> for atomicity; on cross-volume fallback copy->verify->delete with logged <code>io.crossVolumeRename</code> event. <br><strong>Temp file management:</strong> create temp folder <code>STAGING_FOLDER\tmp\&lt;jobId&gt;\</code> and name files with <code>&lt;timestamp&gt;.&lt;pid&gt;.&lt;random&gt;.tmp</code>; <code>CleanupTempArtifacts(ageHours)</code> removes temps older than threshold and reports removed list. <br><strong>Permission detection & remediation mapping:</strong> translate common <code>Err.Number</code> values into friendly <code>errorCode</code> and <code>remediation</code> messages (e.g., permission denied → <code>IMP_BATCH_001</code>, path not found → <code>IMP_IO_002</code>). </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Host compatibility & feature detection</strong><br><strong>Host detection:</strong> detect <code>Application.OperatingSystem</code> and <code>Application.Version</code> to set <code>HostCapabilities</code> map returned by <code>GetConfig()</code> and used by higher-level modules. <br><strong>Feature matrix & fallbacks:</strong><br>1) Windows Excel desktop — full features (ADODB, CryptoAPI, FSO) expected; use preferred fast paths.<br>2) Mac Excel — ADODB and COM limited; use pure-VBA stream & crypto fallbacks; log <code>HostCompatibility.warn</code> when fallbacks used.<br>3) Excel Online — no local file I/O; <code>WriteUtf8FileAtomic</code> and <code>ComputeFileChecksum</code> must raise <code>IMP_HOST_001</code> instructing operator to offload heavy I/O to worker or use cloud-hosted endpoint; provide <code>CreateJobDescriptor</code> integration guidance. <br><strong>Worker offload pattern:</strong> when host lacks features, <code>modUtilities</code> offers <code>GetWorkerConfigSubset()</code> to produce a safe, PII-free config block for worker scheduling and a <code>CreateJobDescriptor</code> hook so heavy I/O and checksumming happen on worker nodes. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Observability, telemetry & payload hygiene</strong><br><strong>ImportLog recommended schema:</strong> <code>Timestamp, JobID, CorrelationID, Action, Severity, Message, OperatorID, Machine, ConfigHash, PayloadHash, EvidenceRef</code>. <br><strong>Payload hashing policy:</strong> compute <code>payloadHash = SHA256(detailsJSON)</code> and store the hash in ImportLog; full <code>detailsJSON</code> may only live in encrypted evidence archive when regulation requires. <br><strong>Sampling & aggregations:</strong> for high-cardinality events (per-row validations), sample raw logs and emit aggregated statistics <code>preflight.summary{rowsProcessed,rowsFlagged,topErrorTypes}</code> rather than per-row logs unless operator enables full diagnostics. <br><strong>Alert-friendly formatting:</strong> ensure <code>LogAction</code> error messages begin with <code>errorCode:&lt;code&gt;</code> for automated alert parsing (pager/ingest systems). </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Performance notes & patterns</strong><br>1) <strong>Streaming over buffering</strong> — stream files in 64KB–256KB chunks to avoid memory pressure. <br>2) <strong>Use native APIs when available</strong> — ADODB.Stream for writes, CryptoAPI for checksum. <br>3) <strong>Offload heavy ops</strong> — provide <code>CreateJobDescriptor</code> hook for offloading large exports/checksums to workers; worker uses <code>GetWorkerConfigSubset()</code> for minimal safe payload. <br>4) <strong>Batch log writes</strong> — when logging high volumes, buffer logs to intermediate file and append in batches to ImportLog to avoid UI locks. <br>5) <strong>Avoid tight polling</strong> — use exponential backoff and jitter for retrying IO or PQ refresh polling to reduce load on shared resources. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Security & privacy controls</strong><br>1) <strong>No secrets in module</strong> — modUtilities must not store secret values in code or logs. <br>2) <strong>Secret access audit</strong> — every secret retrieval writes <code>secret.access{secretNameHash,provider,operatorId,ts}</code> to ImportLog (no secret value). <br>3) <strong>Encrypted archive</strong> — provide <code>WriteEncryptedArchive(path, content, encryptionKeyRef)</code> which wraps <code>WriteUtf8FileAtomic</code> and encrypts payload with key from <code>GetSecretFromStore</code>; this function returns <code>{success,evidenceRef}</code> and ensures ACLs applied to archive folder. <br>4) <strong>PII minimization</strong> — logs store hashed identifiers; <code>evidenceRef</code> points to encrypted evidence if retention required. <br>5) <strong>Least privilege</strong> — recommend ACL hardening for <code>STAGING_FOLDER</code> and require operator sign-off when making it world-readable. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Testing matrix & QA requirements</strong><br><strong>Unit tests:</strong><br>1) <code>WriteUtf8FileAtomic</code> correctness: small file, large file, BOM/no-BOM, simulate crash mid-write and ensure final filename absent and tmp removed by cleanup.<br>2) <code>ComputeFileChecksum</code> parity: known fixtures produce expected SHA256 values; fallback route matches reference pure-VBA implementation.<br>3) <code>Retry</code> behavior: simulate action that fails N-1 times and succeeds on Nth attempt, assert backoff timings and logs.<br>4) <code>LogAction</code> append & stash: simulate locked ImportLog and ensure stash file created and <code>DrainStashedLogs()</code> drains correctly.<br><strong>Integration tests:</strong><br>1) E2E batch export using <code>modBatchProcessing</code> that calls <code>WriteUtf8FileAtomic</code> and <code>ComputeFileChecksum</code> ends with golden-file checksum match.<br>2) Portal CSV parse and archive: <code>SafeOpenCsv</code> processes sample portal variations, archives original, and returns parsed rows matching expectation. <br><strong>Chaos tests:</strong><br>1) Disk full mid-export: ensure <code>EnsureDiskSpace</code> pre-check detects insufficient space and pipeline fails fast with <code>IMP_IO_001</code> rather than producing partial files.<br>2) Kill process during temp write: restart and run <code>CleanupTempArtifacts()</code> to remove orphan files; ledger shows incomplete batch with <code>status:Failed</code>. <br><strong>Host regression tests:</strong> validate behavior on Windows Desktop, Mac Excel, and a simulated Online environment to confirm graceful degradation and telemetry of fallback usage. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>CI gating & golden parity</strong><br>1) <strong>Checksum determinism</strong> — CI must validate that <code>WriteUtf8FileAtomic</code> output bytes are identical across test runners for canonical fixtures; any change in encoding or BOM must be captured as a <code>migration_manifest</code> change. <br>2) <strong>Behavioral contract tests</strong> — modifying defaults (e.g., <code>UseBom</code> default) requires CI run of canonical fixture suite and two-person approval before production release. <br>3) <strong>Static analysis</strong> — lint rules disallow direct filesystem path literals outside modConfig and modUtilities to centralize change scope. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Operational runbook snippets (actionable)</strong><br>1) <strong>Permission denied writing batch</strong> — run <code>AssertStagingFolder()</code>; if <code>IMP_BATCH_001</code>, confirm ACL for operator/service account and re-run <code>CreateBatches</code> with <code>--resume</code> after cleaning temp files. <br>2) <strong>Log append failed</strong> — run <code>DrainStashedLogs()</code> from UI; if stashed files exist, inspect and re-ingest; consider <code>ImportLog</code> compaction if ledger size impacts performance. <br>3) <strong>Checksum mismatch on archive</strong> — recompute checksum locally with <code>ComputeFileChecksum</code> and compare to <code>Batches.checksum</code>; if mismatch, mark batch <code>Conflict</code> and initiate forensic pack (include <code>preflight</code> evidence). </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Inter-module integration patterns & recommended usage</strong><br>1) <strong>modBatchProcessing</strong> — call <code>AssertStagingFolder()</code> safety check, then <code>WriteUtf8FileAtomic()</code> for each batch, then <code>ComputeFileChecksum()</code> and append <code>Batches</code> row via <code>LogAction</code> and ledger helpers. <br>2) <strong>modPreflight</strong> — emit aggregated preflight statistics via <code>LogAction</code> (sampled) rather than raw per-row logs; use <code>SafeOpenCsv</code> for portal CSV in ingestion flows. <br>3) <strong>modErrorParser</strong> — rely on <code>SafeOpenCsv</code> and <code>EnsureTableExists</code> to create <code>UnmatchedPortalErrors</code> artifact and archive original portal file with <code>WriteEncryptedArchive</code> when regulation requires. <br>4) <strong>modPQController</strong> — use <code>GetConfig()[&quot;REFRESH_TIMEOUT_MS&quot;]</code> from <code>modConfig</code> and <code>Retry</code> around PQ refresh polling loops; modUtilities provides <code>Retry</code> and <code>LogAction</code> to capture PQ refresh progress. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Conceptual guidance: when to use modUtilities vs PQ</strong><br>1) <strong>Use PQ</strong> for deterministic set-based, foldable, column-level normalization and joins that can be pushed to source (server-side folding). <br>2) <strong>Use VBA + modUtilities</strong> for streaming exports, robust CSV encoding, atomic filesystem operations, secret retrievals, job scheduling, and anything requiring COM or file system access. <br>3) <strong>Parameter exchange</strong> — use a <code>Settings</code> ListObject created via <code>EnsureTableExists</code> to let PQ read parameters provided by modUtilities/<code>GetConfig()</code> after <code>ReloadConfig()</code> is invoked. <br>4) <strong>Evidence & checksum</strong> — use <code>modUtilities.WriteUtf8FileAtomic</code> and <code>ComputeFileChecksum</code> to produce deterministic artifacts for golden parity tests; PQ cannot produce trustworthy filesystem artifacts. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & telemetry integration (how modUtilities supports reporting)</strong><br>1) <strong>Instrumentation dimension</strong> — ensure every ImportLog row includes <code>ConfigHash</code> and <code>JobID</code> to allow joining telemetry tables in Power BI. <br>2) <strong>Key measures to build:</strong><br>1) <code>PreflightFailureRate = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0)</code><br>2) <code>BatchSuccessRate = DIVIDE(CALCULATE(COUNTROWS(Batches), Batches[Status]=&quot;Completed&quot;), COUNTROWS(Batches), 0)</code><br>3) <code>AvgChecksumVerificationTime = AVERAGEX(Batches, Batches[ChecksumComputeMs])</code><br>3) <code>LogErrorRateByConfig = DIVIDE(CALCULATE(COUNTROWS(ImportLog),ImportLog[Severity]=&quot;ERROR&quot;), COUNTROWS(ImportLog),0)</code><br>3) <strong>Golden-parity investigations:</strong> use <code>ConfigHash</code> as primary slicer and <code>FileChecksum</code> as validation field in reports; when checksum diverges across runs, join on <code>ConfigHash</code> to identify which config change corresponded to divergence. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Detailed examples & narratives (operator-facing scenarios)</strong><br>Example 1 — successful batch export flow:<br>1) Operator runs <code>CreateBatches</code>. <br>2) <code>CreateBatches</code> calls <code>AssertStagingFolder()</code> -> returns True. <br>3) For each chunk, <code>WriteUtf8FileAtomic</code> writes <code>batch001.tmp.&lt;pid&gt;</code>, renames to <code>batch001.csv</code>, computes SHA256, returns <code>{success,checksum}</code>. <br>4) <code>CreateBatches</code> appends <code>Batches</code> ledger row including <code>checksum</code> and calls <code>LogAction(&quot;batch.created&quot;, {...})</code>. <br>5) <code>ImportLog</code> contains <code>configHash</code> and <code>jobId</code> to trace the run. <br>Example 2 — disk full simulation:<br>1) <code>EnsureDiskSpace</code> detects insufficient free bytes prior to export and returns <code>{ok:False,errorCode:&quot;IMP_IO_001&quot;,remediation:&quot;Free up X bytes or change staging&quot;}</code>. <br>2) UI surfaces explicit remediation steps; operation aborts cleanly with no partial final files produced. <br>Example 3 — portal CSV with malformed rows:<br>1) <code>SafeOpenCsv(..., params.Mode=&quot;relaxed&quot;)</code> parses and flags problematic rows with <code>ParseError</code> tags and writes original CSV to <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\portal\</code>. <br>2) <code>modErrorParser</code> uses fuzzy-key mapping to annotate source rows and <code>LogAction</code> records <code>portal.parse.completed{matchedCount,unmatchedCount}</code>. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Retention, archive & purge policy helpers</strong><br>1) <strong>Archive flow:</strong> use <code>WriteEncryptedArchive</code> to store artifacts under <code>STAGING_ARCHIVE_FOLDER\&lt;jobId&gt;\</code> with computed <code>checksum</code> and <code>evidenceRef</code> recorded in ledger. <br>2) <strong>Purge policy:</strong> <code>PurgeExpiredArtifacts(retentionDays, DryRun)</code> returns candidates older than retention and optionally removes after moving to secure quarantine; always compute and store <code>preDeleteManifest</code> with <code>checksums</code> and <code>operatorId</code> for chain-of-custody. <br>3) <strong>Legal hold:</strong> support <code>HoldArtifact(evidenceRef, reason)</code> that marks artifact immune to purge and emits <code>archive.hold{evidenceRef,reason,operatorId}</code> to ImportLog. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Common failure codes & immediate remediation</strong><br>1) <code>IMP_BATCH_001</code> — file write failed (permission, disk full). Remediation: fix ACLs, free disk space, or change <code>STAGING_FOLDER</code>. <br>2) <code>IMP_UTIL_001</code> — checksum computation failed. Remediation: re-run compute or offload to worker. <br>3) <code>IMP_PF_001</code> — table header mismatch. Remediation: restore expected header or update config table names and rerun <code>ValidateConfig()</code>. <br>4) <code>IMP_PORTAL_001</code> — portal CSV missing expected header. Remediation: request corrected portal export and archive original for triage. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Developer checklist before committing changes to modUtilities</strong><br>1) Add or update unit tests for any changed function and ensure coverage for error branches. <br>2) Run canonical fixture E2E to validate checksum parity and encoding across developer machine and CI. <br>3) Run chaos tests: simulated disk full, simulate killing process mid-write, simulate locked ImportLog. <br>4) Update <code>migration_manifest.json</code> if default encoding, BOM policy, temp naming or atomic semantics change. <br>5) Document host fallbacks and verify fallback telemetry is emitted during tests. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Extensibility & adapter hooks</strong><br>1) <strong>Secret provider registration</strong> — <code>RegisterSecretProvider(name, providerObject)</code> allows pluggable secret store implementations while ensuring consistent telemetry and auditing. <br>2) <strong>Checksum provider interface</strong> — <code>RegisterChecksumProvider(name, providerFunc)</code> to allow hardware or native accelerated checksums in specialized environments. <br>3) <strong>Log sink adapters</strong> — <code>RegisterLogSink(name, sinkFunc)</code> enables optional secondary log sinks (HTTP telemetry endpoint or DB) while preserving workbook <code>ImportLog</code> as canonical sink. <br>4) <strong>Worker offload contract</strong> — <code>GetWorkerConfigSubset()</code> serializes safe config for workers and <code>ComputeFileChecksumAsync</code> handshake provides result manifest consumption semantics. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Acceptance criteria for modUtilities release</strong><br>1) All unit tests pass and code coverage meets project standard. <br>2) CI canonical fixture suite shows byte-identical CSV artifacts for golden fixtures across runners. <br>3) Host compatibility tests executed for Windows/Mac/Online and reported fallbacks in telemetry are acceptable. <br>4) <code>migration_manifest.json</code> present for any change affecting serialized outputs. <br>5) Documentation updated: README, operator runbook, and developer changelog entry. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Runbook quick actions for operators (concise)</strong><br>1) Fix permission denied: run <code>AssertStagingFolder()</code>; if <code>IMP_BATCH_001</code>, grant write ACL or use alternate UNC path and re-run <code>CreateBatches</code> with <code>--resume</code>. <br>2) Recover from interrupted export: run <code>CleanupTempArtifacts()</code> then inspect <code>Batches</code> ledger for last completed batch index; re-run <code>CreateBatches</code> from next offset. <br>3) Drain logs: run <code>DrainStashedLogs()</code> from UI if <code>LogAction</code> returned <code>stashPath</code>. <br>4) For golden-parity failures: compare <code>Batches.checksum</code> with computed checksum from <code>ComputeFileChecksum()</code> and escalate with <code>migration_manifest</code> if config changed. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Maintenance & lifecycle notes</strong><br>1) Periodic audits: schedule golden-parity smoke tests whenever <code>modUtilities</code> or <code>modConfig</code> change. <br>2) Deprecation policy: deprecate features for two release cycles and emit <code>config.warn</code> telemetry. <br>3) Retention policy enforcement: run scheduled purge jobs honoring <code>ARCHIVE_RETENTION_DAYS</code> and legal holds. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Final verification checklist (runtime invariants)</strong><br>1) <code>WriteUtf8FileAtomic</code> must never leave a final named file partially written; presence of <code>.tmp.*</code> indicates incomplete work and should be removed by <code>CleanupTempArtifacts</code>. <br>2) <code>ComputeFileChecksum</code> must return identical SHA256 for canonical fixtures across CI environments unless documented in <code>migration_manifest</code>. <br>3) <code>LogAction</code> must either append to ImportLog or create a stash artifact and log the stash path; no silent log loss allowed. <br>4) <code>GetSecretFromStore</code> must never return secret values in logs and always log only <code>secretNameHash</code> with provider name. </td></tr><tr><td data-label="modUtilities — Per-function technical breakdown (VBA)"> <strong>Closing guidance for implementers</strong><br>Implement modUtilities as a compact, well-documented module with explicit, testable fallbacks. Favor structured error objects over exceptions, ensure atomic file semantics and checksum determinism, and embed telemetry hooks for every significant action. Keep the module dependency-light so it is easy to test and reuse; when host features are missing, fail fast with clear remediation and provide worker offload hooks rather than attempting risky local workarounds. </td></tr></tbody></table></div><div class="row-count">Rows: 34</div></div><div class="table-caption" id="Table9" data-table="YJKN_0017_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **frmOperatorUI — Per-function technical breakdown (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>frmOperatorUI — Per-function technical breakdown (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Executive summary & intent</strong><br>frmOperatorUI is the operator-facing orchestration surface for the IMPORT DATA pipeline. Its primary goals are: present a compact, deterministic control surface for the end-to-end workflow; enforce human-in-the-loop safety checks for destructive operations; capture operator metadata and create auditable telemetry; orchestrate background work without blocking the host UI; provide clear remediation guidance for failures; and act as the single place operators interact with day-to-day. The form is intentionally thin — all heavy-lift logic belongs in modules (modConfig, modPQController, modPreflight, modBatchProcessing, modErrorParser, modUtilities). UI code must not duplicate business logic or file I/O responsibilities. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>High-level responsibilities & contract</strong><br>1) Present operator-driven flows: LoadFile → RunPreflight → CreateBatches → Upload/Monitor → ParsePortalErrors → Finalize, with deterministic state transitions and audit logging.<br>2) Capture and persist <code>operatorId</code>, <code>operatorRole</code>, <code>operatorTs</code>, <code>correlationId</code>, and attach these to every <code>ImportLog</code> and <code>Batches</code> ledger entry produced from UI actions.<br>3) Require explicit typed confirmations for destructive operations (e.g., <code>OVERWRITE_BATCHES</code>) and capture approval metadata (who, when) for two-person approvals.<br>4) Coordinate PQ refreshes via modPQController with <code>REFRESH_TIMEOUT_MS</code> and ensure PQ/VBA version parity warnings are surfaced when mismatches exist.<br>5) Offload heavy tasks to background workers or implement cooperative-yield patterns to avoid UI thread blocking; provide progress, checkpoints, and cancellation semantics.<br>6) Surface machine-readable error codes and human remediation hints; link to archived evidence via <code>evidenceRef</code> instead of showing raw PII in the UI by default. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Primary UI elements & behavior contract</strong><br>1) Job header area: show <code>jobId</code>, <code>configHash</code>, <code>operatorId</code>, <code>jobState</code>, <code>createdTs</code>, and small "summary" counts for last run (rows processed, batches created).<br>2) Action toolbar: LoadFile, RunPreflight, CreateBatches, Upload, ParsePortalErrors, Finalize; each button executes a single atomic workflow step and logs <code>ui.action</code> telemetry on click.<br>3) JobDetail pane: read-only audit list filtered to <code>jobId</code> showing recent <code>ImportLog</code> rows and links to <code>evidenceRef</code> for artifacts.<br>4) Progress & status area: step progress, per-batch incremental status, elapsed/estimated time, and "Cancel" control; provide per-step "Show diagnostics" expansion to inspect machine-level details without exposing raw PII.<br>5) Confirmation modal: typed-entry pattern for destructive operations and two-person approval capture for inline mutative actions; log <code>ui.confirmation</code> without storing typed phrase text. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Public methods & conceptual signatures</strong><br>1) InitializeUI() — initialize controls, bind to <code>GetConfig()</code> snapshot, display last job summary, and ensure <code>IsOperationRunning=False</code>.<br>2) CreateNewJob(operatorId, optionalMetadata) — generate <code>jobId</code>, set <code>jobState=&quot;Created&quot;</code>, populate JobDetail, and emit <code>ui.action{createJob}</code>.<br>3) LoadFile(filePath) — validate headers via modPreflight.HeaderValidation, populate <code>RAW_TABLE_NAME</code>, write <code>ui.action{loadFile}</code>, and show preview up to <code>MAX_PREVIEW_ROWS</code>.<br>4) RunPreflight(jobId, opts) — orchestrate PQ refreshes (if enabled), call modPreflight.RunPreflight in a worker or cooperative-yield pattern, display preflight summary modal, and write <code>preflight.summary</code> telemetry.<br>5) CreateBatches(jobId, options) — run typed confirmations, call <code>AssertStagingFolder()</code>, call modBatchProcessing.CreateBatches with streaming progress, and record <code>Batches</code> ledger updates with <code>configHash</code> and <code>operatorId</code>.<br>6) ParsePortalErrors(jobId, portalFilePath) — archive portal CSV via atomic write, compute checksum, call modErrorParser.ParsePortalErrors, and present triage modal for <code>UnmatchedPortalErrors</code> with suggested corrective actions.<br>7) FinalizeJob(jobId) — ensure artifacts are archived per <code>ARCHIVE_RETENTION_DAYS</code> policy, emit <code>ui.action{finalizeJob}</code>, and record final audit lines in <code>ImportLog</code>. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Operator flows — load-to-finalize (step-by-step)</strong><br>1) LoadFile flow:<br>1) Prompt operator for file selection via secure FileDialog; perform header validation via <code>modPreflight.HeaderValidation</code>; on header mismatch show expected header template and "Fix & Retry" guidance.<br>2) On success, load data to <code>RAW_TABLE_NAME</code> ListObject and log <code>ui.action{loadFile, jobId}</code>. Display a preview limited to <code>MAX_PREVIEW_ROWS</code> with redaction of PII by default and a <code>ShowPII</code> toggle guarded by typed confirmation.<br>2) RunPreflight flow:<br>1) Disable conflicting controls and set <code>IsOperationRunning=True</code>; capture <code>operatorId</code> and <code>operatorTs</code>; initialize <code>CancelToken=False</code> and show progress modal.<br>2) Optionally refresh targeted PQ queries via <code>modPQController.RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> respecting <code>REFRESH_TIMEOUT_MS</code> and provide PQ diagnostics to the operator on failure. <br>3) Execute <code>modPreflight.RunPreflight</code> using a background worker or cooperative-yield; update UI with per-chunk progress (e.g., per 500 rows) and periodic <code>ui.checkpoint</code> telemetry.<br>4) On completion, display the PreflightSummary modal with counts, top error types, and direct link to a filtered Preflight sheet for remediation. Log <code>preflight.summary</code> and create an evidence snapshot if required by policy.<br>3) CreateBatches flow:<br>1) Show batch segmentation preview; if <code>OVERWRITE_BATCHES=True</code>, require exact typed confirmation string and optionally a second approver for production runs.<br>2) Call <code>AssertStagingFolder()</code> and on success begin <code>modBatchProcessing.CreateBatches</code> in a worker; stream per-batch status, compute and display checksums for each produced file, and write <code>Batches</code> ledger rows with <code>filePath</code>, <code>checksum</code>, <code>rowCount</code>, <code>jobId</code>, and <code>operatorId</code>.<br>3) Support cancellation: when <code>CancelRequested=True</code>, worker finishes current chunk, closes temp streams, marks partial items <code>Cancelled</code> and writes <code>ui.action{cancelRequested}</code> with state. <br>4) Upload & Monitor flow (optional):<br>1) For automated uploads, invoke <code>UploadAdapter.UploadBatch(filePath, metadata)</code> and show per-file upload progress; on transient failures use <code>modUtilities.Retry</code> wrapper and show retry count in UI.<br>2) On upload success persist portal receipts and checksums in <code>Batches</code> ledger and emit <code>ui.action{uploadCompleted}</code>. <br>5) ParsePortalErrors flow:<br>1) Archive the portal CSV atomically to <code>STAGING_ARCHIVE_FOLDER</code> and compute <code>sha256</code> checksum using <code>modUtilities.ComputeFileChecksum</code>.<br>2) Call <code>modErrorParser.ParsePortalErrors()</code> and present triage modal for <code>UnmatchedPortalErrors</code> with direct actions: export filtered rows as small batch, or open raw Preflight rows for manual correction.<br>3) For ambiguous matches, show <code>AMBIGUOUS_MATCH</code> groupings and offer operator-driven mapping with temporary <code>PortalErrorResolution</code> entries. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Concurrency model & background worker patterns</strong><br>1) <strong>Two execution styles supported:</strong> external worker offload (CreateJobDescriptor + scheduling) and cooperative-yield worker pattern inside the workbook. Choose external offload for very large datasets; prefer cooperative yield for small-to-medium jobs where quick operator feedback is beneficial.<br>2) <strong>Cooperative-yield pattern</strong>: break work into deterministic chunks (e.g., 500 rows), call <code>DoEvents</code>, update progress UI, check <code>CancelToken</code>, and yield periodically to keep UI responsive.<br>3) <strong>Worker descriptor</strong>: when offloading, serialize <code>GetWorkerConfigSubset()</code> and job payload into <code>CreateJobDescriptor</code> including <code>jobId</code>, <code>correlationId</code>, <code>configHash</code>, and minimal non-PII inputs for the worker; provide a <code>statusCallback</code> URL or polling manifest. <br>4) <strong>Mutex & state</strong>: set <code>IsOperationRunning=True</code> while a job is active and disable buttons that would conflict; allow safe read-only operations (view <code>ImportLog</code>) during runs. <br>5) <strong>Progress granularity</strong>: emit <code>ui.checkpoint{step,rowsProcessed,elapsedMs,jobId}</code> at consistent intervals to enable robust recovery and off-line diagnostics. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Cancellation & abort semantics</strong><br>1) <strong>CancelToken</strong> — global boolean <code>CancelRequested</code> the worker checks at chunk boundaries; UI sets this flag when operator clicks Cancel. <br>2) <strong>Graceful abort</strong> — worker completes current chunk, writes partial artifacts safely (compute before/after checksums), marks partial batches <code>Cancelled</code> or <code>Failed</code>, performs temp-file cleanup, and emits <code>ui.action{cancelRequested}</code> followed by <code>ui.action{jobAborted}</code>. <br>3) <strong>Forced abort</strong> — "Force Abort" is a destructive, double-confirmation operation that immediately terminates workers and may leave partial artifacts; allow only for emergency and log <code>ui.action{forceAbort,operatorId,reason}</code>. <br>4) <strong>Recovery</strong> — when a run aborts, display a remediation checklist and "Resume" options where resume uses <code>jobId</code> and <code>Batches</code> ledger to continue from last Completed batch, unless <code>--recreate</code> is specified. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Typed confirmation & two-person approval patterns</strong><br>1) <strong>Typed-confirmation</strong> — destructive flows require exact textual confirmation (e.g., <code>OVERWRITE_BATCHES CONFIRM</code>) in the modal; once matched enable the destructive button. Log <code>ui.confirmation{action,operatorId,typedConfirmed=True,jobId}</code> but do not store the typed phrase text in logs for privacy. <br>2) <strong>Two-person approval</strong> — for inline mutative applies (future feature) or production <code>OVERWRITE_BATCHES</code>, require a second approver to sign in and provide <code>approverId</code> and <code>approvalNote</code> recorded in <code>ApplyDescriptor</code> with <code>approvalsRef</code> in <code>ImportLog</code>. <br>3) <strong>Approval TTL</strong> — approvals used to authorize an inline apply expire after configurable TTL (e.g., 12 hours) to reduce risk of stale approvals being used later. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Operator metadata & audit contract</strong><br>1) Capture <code>operatorId</code> on form load via domain identity when available or prompt the operator to supply a validated identifier; bind <code>operatorId</code> to every <code>ui.action</code> and <code>Batches</code> row.<br>2) Emit <code>ui.action{action,operatorId,jobId,correlationId,configHash,ts}</code> entries via <code>modUtilities.LogAction</code> for every operator interaction that triggers backend work. <br>3) Two-person approvals: store <code>approverId</code>, <code>approvedTs</code>, <code>approvalNote</code>, and <code>approvalsRef</code> in <code>ImportLog</code> and the <code>ApplyDescriptor</code>. <br>4) For regulated flows require <code>evidenceRef</code> linking to encrypted evidence store for runs requiring full data retention and include <code>operatorConsent</code> flags where necessary. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Error handling, diagnostics & remediation UX</strong><br>1) <strong>Dual view:</strong> concise one-line operator-friendly error + expandable diagnostics carrying machine codes, stack trace, <code>evidenceRef</code>, and <code>configHash</code>. <br>2) <strong>Mapping</strong> — every machine error code (e.g., <code>PQ_ERR_001</code>, <code>IMP_PF_001</code>, <code>IMP_BATCH_001</code>) maps to concise UI message, triage hint, and runbook step. <br>3) <strong>Retry affordances</strong> — transient failures surfaced with a Retry button that uses <code>modUtilities.Retry</code> with exponential backoff; log each retry attempt. <br>4) <strong>Evidence</strong> — full error payload archived with checksum and <code>evidenceRef</code>; do not show PII in UI unless operator enables <code>ShowPII</code> with typed confirmation. <br>5) <strong>Bulk diagnostics export</strong> — provide "Export diagnostics" that bundles <code>ImportLog</code> rows, <code>Batches</code> ledger, <code>PREFLIGHT</code> snapshot, and <code>CONFIG_HASH</code> into a deterministic archive used for support escalations. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Progress & checkpoint telemetry</strong><br>1) Emit <code>ui.checkpoint</code> rows at consistent intervals: start, every N rows (configurable e.g., 500), after each batch, on cancel, on completion. Each checkpoint includes <code>step</code>, <code>rowsProcessed</code>, <code>elapsedMs</code>, <code>estimatedRemainingMs</code>, <code>jobId</code>, and <code>configHash</code>.<br>2) On completion emit <code>ui.action{completed,jobId,elapsedMs,summaryCounts,configHash}</code> with a linked <code>validationReportRef</code> if regulation requires evidence retention. <br>3) Emit <code>ui.warn</code> rows for clamped or auto-corrected values (e.g., clamped <code>REFRESH_TIMEOUT_MS</code>) and include both original and clamped values for traceability. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Accessibility & internationalization</strong><br>1) Keyboard accessibility: provide accelerator keys for primary actions, tab-order correctness, and focus outlines for keyboard navigation. <br>2) Screen reader: ensure every control has a clear label and the job progression uses semantic labels to communicate state transitions. <br>3) Locale-aware UI: read <code>uiLocale</code> from <code>GetConfig()</code> and use <code>DEFAULT_DATE_FORMAT</code> for display; allow operator to override <code>uiLocale</code> via Settings which triggers <code>ReloadConfig()</code> and targeted PQ refresh if necessary. <br>4) High-contrast and scaling: ensure layout adapts to large fonts and high-contrast modes. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Security & privacy mandates for UI</strong><br>1) Do not persist secrets in UI memory; retrieve via <code>modUtilities.GetSecretFromStore()</code> and promptly release. <br>2) PII redaction: preview, preflight lists and diagnostics redact PII columns by default; explicit "Show PII" toggle must log <code>ui.action{showPii}</code> and require typed confirmation. <br>3) Evidence storage: when <code>UseEncryptedArchive=True</code> ensure UI initiates encryption workflow via <code>modUtilities</code> and show only <code>evidenceRef</code> in UI; do not render archived data inline. <br>4) Auditability: every operator action and approval is recorded with <code>operatorId</code>, <code>ts</code>, and <code>configHash</code> to meet chain-of-custody requirements. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Integration contracts with other modules</strong><br>1) <strong>modConfig</strong> — frmOperatorUI reads <code>GetConfig()</code> on InitializeUI(), shows <code>configHash</code>, and calls <code>ReloadConfig()</code> when operator updates runtime settings; UI must not hard-code keys or paths. <br>2) <strong>modPQController</strong> — UI passes <code>REFRESH_TIMEOUT_MS</code> and desired query list to <code>RefreshQueries()</code> and displays PQ errors returned with <code>QueryName</code> and <code>ErrorLocation</code>. <br>3) <strong>modPreflight</strong> — UI calls <code>RunPreflight()</code> and consumes preflight <code>Checks</code> tags and <code>remediationHint</code> for presentation in the Preflight modal. <br>4) <strong>modBatchProcessing</strong> — UI calls <code>CreateBatches()</code> and relies on <code>Batches</code> ledger for status; expects <code>filePath</code>, <code>checksum</code>, <code>rowRange</code>, <code>status</code> fields populated. <br>5) <strong>modErrorParser</strong> — UI passes portal CSV path to <code>ParsePortalErrors()</code> and displays <code>UnmatchedPortalErrors</code> with triage actions. <br>6) <strong>modUtilities</strong> — UI uses <code>LogAction</code>, <code>WriteUtf8FileAtomic</code>, <code>ComputeFileChecksum</code>, and <code>Retry</code> helper functions for stable behavior. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Conceptual PQ guidance for UI interactions</strong><br>1) <strong>Parameterization</strong> — expose essential PQ parameters (e.g., <code>SourceLocale</code>, <code>DateOrder</code>, <code>TrimWhitespace</code>) through a Settings dialog that writes <code>Settings</code> sheet and calls <code>ReloadConfig()</code> followed by targeted PQ refresh for <code>PQ_Raw</code> and <code>PQ_Preflight</code>.<br>2) <strong>Targeted refresh</strong> — prefer <code>RefreshQueries([&quot;PQ_Raw&quot;,&quot;PQ_Preflight&quot;])</code> prior to <code>RunPreflight</code> instead of <code>RefreshAll</code> to reduce load and keep UX responsive; surface parse success/failure aggregates in the Preflight modal. <br>3) <strong>Parse diagnostics</strong> — when PQ supplies <code>ParseSuccess</code> boolean and <code>ParseErrorReason</code> columns, show aggregated counters and representative sample rows rather than raw M error stacks; provide "Show PQ debug" toggle for advanced operators. <br>4) <strong>PQ / UI parity</strong> — when <code>PQ_VERSION</code> in config differs from embedded query version, present a blocking warning requiring typed acknowledgement and link to <code>migration_manifest.json</code> documenting the change. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Conceptual DAX & reporting guidance for UI telemetry</strong><br>1) <strong>Dimension inclusion</strong> — ensure telemetry includes <code>JobId</code>, <code>ConfigHash</code>, <code>OperatorId</code>, <code>PQVersion</code>, <code>JobState</code>, and <code>CreatedTs</code> so Power BI models can slice by configuration and operator. <br>2) <strong>Suggested measures</strong> — <code>PreflightFailureRate = DIVIDE(SUM(Preflight[RowsFlagged]), SUM(Preflight[RowsProcessed]), 0)</code><br>3) <code>BatchSuccessRate = DIVIDE(CALCULATE(COUNTROWS(Batches), Batches[Status]=&quot;Completed&quot;), COUNTROWS(Batches), 0)</code><br>4) <code>AvgBatchCreateTimeByConfig = AVERAGEX(FILTER(Batches, Batches[ConfigHash]=SelectedConfig), Batches[CreateDurationMs])</code><br>5) <strong>Event timeline</strong> — Power BI Job Timeline visual showing state transitions (Created → Preflight → CreateBatches → Upload → Finalize) with <code>ConfigHash</code> annotated helps detect regressions after config changes. <br>6) <strong>Golden-parity checks</strong> — in reporting, flag jobs where <code>ConfigHash</code> changed between expected and actual values and link to <code>migration_manifest</code> entries for review. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Testing matrix & QA for frmOperatorUI</strong><br>1) <strong>Unit tests</strong> — control enable/disable logic, typed confirmation gating, <code>CancelRequested</code> toggling, JobDetail binding, and telemetry emission validations. <br>2) <strong>Integration tests</strong> — E2E flows using canonical fixtures: LoadFile → PQ refresh → RunPreflight → CreateBatches → Upload simulation → ParsePortalErrors; assert <code>ImportLog</code> and <code>Batches</code> rows contain expected <code>operatorId</code>, <code>configHash</code>, checksums, and evidenceRefs. <br>3) <strong>Chaos tests</strong> — simulate PQ timeouts, disk-full during export, transient network failures during upload, and mid-run cancellation; verify UI handles each case gracefully and <code>ImportLog</code> contains actionable diagnostics. <br>4) <strong>Accessibility tests</strong> — keyboard-only navigation suites, screen reader label verification, and large-font/contrast tests. <br>5) <strong>Security tests</strong> — verify no secrets in UI memory or logs, <code>ShowPII</code> toggle requires explicit confirmation and is logged, typed-confirmations do not get stored verbatim. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Acceptance criteria for UI features</strong><br>1) All long-running operations must run off the UI thread or use cooperative yields to keep the host responsive. <br>2) Each UI-driven action must emit a <code>ui.action</code> telemetry row with <code>operatorId</code> and <code>configHash</code>. <br>3) Typed confirmations must block destructive flows and require exact-match typed entry; two-person approvals are recorded when required. <br>4) Cancellation must stop work at defined safe checkpoints and leave ledger state consistent. <br>5) Preflight PQ parity warnings block runs until acknowledged and linked <code>migration_manifest</code> documentation is visible. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Operational runbook excerpts (UI focus)</strong><br>1) <strong>Start-of-day check</strong> — open workbook -> InitializeUI() -> ValidateConfig() -> AssertStagingFolder() -> verify JobDetail pane shows previous job results and <code>configHash</code>. <br>2) <strong>Standard run</strong> — LoadFile -> RunPreflight -> fix flagged rows -> Re-run preflight -> CreateBatches -> Upload -> ParsePortalErrors -> Fix portal failures -> Finalize & archive. <br>3) <strong>On staging permission failure</strong> — abort CreateBatches, run <code>AssertStagingFolder()</code> from UI, check ACLs, optionally choose alternate UNC path, and re-run CreateBatches with <code>--recreate</code> if necessary. <br>4) <strong>On PQ refresh timeout</strong> — use "Retry Refresh" option, inspect PQ debug output, and capture <code>jobId</code> and <code>configHash</code> for PQ owner support. <br>5) <strong>On disk full during export</strong> — stop the operation, free space or change staging folder, delete <code>*.tmp</code> files in <code>STAGING_FOLDER</code>, then re-run CreateBatches with resume semantics. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Common failure modes & recommended mitigations</strong><br>1) <strong>Staging folder inaccessible</strong> — detect using <code>AssertStagingFolder()</code> -> <code>IMP_CFG_001</code>; mitigation: fix ACLs, use UNC path, or request admin action; log <code>config.assert.fail</code> and abort. <br>2) <strong>PQ parse errors</strong> — PQ errors surfaced with <code>PQ_ERR_*</code>; mitigation: show sample failing rows, allow operator to edit <code>Settings</code> PQ parameters or contact PQ owner; block downstream RunPreflight until resolved for regulated runs. <br>3) <strong>Large runs causing UI hangs</strong> — ensure offload to worker or use cooperative yield; for repeated hangs, recommend scheduling worker job via <code>CreateJobDescriptor</code>. <br>4) <strong>Partial export / incomplete writes</strong> — atomic temp-file strategy in modBatchProcessing prevents incomplete final names; UI must instruct operator to delete <code>.tmp</code> files found in staging before re-run. <br>5) <strong>Unmatched portal errors</strong> — present <code>UnmatchedPortalErrors</code> artifact and advise operator to attach archived portal CSV and <code>jobId</code> to portal support ticket. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Extensibility & plugin points in UI</strong><br>1) <strong>UploadAdapter plugin</strong> — register adapters implementing <code>UploadBatch(filePath, metadata) -&gt; {success,receipt}</code> supporting manual, HTTP token, or SFTP protocols; UI enumerates available adapters and allows operator to pick. <br>2) <strong>Preflight hooks</strong> — support <code>RegisterPreflightHook(hookName, handler)</code> for domain-specific validation steps executed after core preflight; show hook results in Preflight modal. <br>3) <strong>OnConfigChange subscription</strong> — support <code>RegisterOnConfigChange(handler)</code> so UI refreshes bound values when <code>ReloadConfig()</code> updates <code>Settings</code>. <br>4) <strong>Worker orchestration</strong> — allow exporting <code>CreateJobDescriptor</code> for external schedulers using <code>GetWorkerConfigSubset()</code> to pass a minimal, non-PII config payload to workers. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Telemetry & observability produced by UI</strong><br>1) <code>ui.action{action,operatorId,jobId,correlationId,configHash,ts}</code> — every operator action. <br>2) <code>ui.checkpoint{step,rowsProcessed,elapsedMs,estimatedRemainingMs,jobId}</code> — periodic checkpoints. <br>3) <code>ui.error{action,errorCode,detail,jobId,evidenceRef}</code> — surfaced errors. <br>4) <code>ui.confirmation{action,operatorId,typedConfirmed,jobId}</code> — typed confirmations (do not include typed text). <br>5) <code>ui.reloadConfig{previousHash,newHash,changedKeys,operatorId}</code> — when operator updates settings. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Developer checklist before shipping UI changes</strong><br>1) Confirm all environment inputs are read via <code>GetConfig()</code> and not hard-coded. <br>2) Ensure <code>ui.action</code> telemetry emitted for every operator action and <code>configHash</code> flows into ledger rows. <br>3) Run unit tests for typed confirmations, cancellation semantics, and JobDetail bindings. <br>4) Execute E2E canonical fixture tests to validate <code>Batches</code> checksums and golden-file parity where <code>CONFIG_HASH</code> changes. <br>5) Update runbook and <code>migration_manifest.json</code> if flows or typed confirmations change. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Privacy, compliance & retention behaviors in UI</strong><br>1) Default redaction for PII in all previews and logs; <code>ShowPII</code> requires typed confirmation and is auditable.<br>2) Evidence artifacts are archived to <code>STAGING_ARCHIVE_FOLDER</code> and encrypted when <code>UseEncryptedArchive=True</code>; UI shows <code>evidenceRef</code> and does not render archived content inline. <br>3) Implement retention purge UI action that lists artifacts older than <code>ARCHIVE_RETENTION_DAYS</code> and requires operator permission to delete; deletions recorded with <code>ui.action{purgeArtifacts}</code>. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Accessibility & localization operational notes</strong><br>1) Strings should be sourced from <code>Strings</code> sheet keyed by <code>uiLocale</code> in <code>GetConfig()</code>; <code>InitializeUI()</code> reads locale and binds strings to controls. <br>2) Keep keyboard shortcuts discoverable in Help pane and configurable per-operator. <br>3) Ensure all status modals are navigable via keyboard and have accessible focus management to prevent keyboard traps. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Operational metrics to monitor (UI-specific)</strong><br>1) <code>UI_Avg_Preflight_Time</code> — track median preflight duration by <code>ConfigHash</code>. <br>2) <code>UI_CancelRate</code> — fraction of jobs cancelled mid-run; monitor by operator and <code>ConfigHash</code>. <br>3) <code>UI_TypedConfirmFailures</code> — occurrences where typed confirmation was attempted but not matched; useful to measure operator friction. <br>4) <code>UI_PQRefreshTimeoutRate</code> — PQ refresh timeouts per <code>PQ_VERSION</code>. <br>5) <code>OperatorThroughput</code> — successful jobs per operator per day; used for capacity planning and training. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Runbook quick actions accessible from UI</strong><br>1) "Fix headers" helper — open <code>Strings</code> header template and highlight missing columns; provide a one-click "copy expected header" action.<br>2) "Open Staging Folder" — show path and an "Open in Explorer" action (guarded by host detection and ACL checks). <br>3) "Export Diagnostics" — create deterministic diagnostics bundle with <code>ImportLog</code>, <code>Batches</code> ledger, <code>PREFLIGHT</code> snapshot and <code>CONFIG_HASH</code> for upload to support. <br>4) "Resume job" — resume a cancelled job by reading <code>Batches</code> ledger and continuing from last Completed batch if resume semantics allowed. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Common pitfalls & developer mitigations</strong><br>1) <strong>Pitfall:</strong> performing heavy I/O on UI thread. <br>Mitigation: force cooperative-yield pattern or worker offload; CI smoke test that runs UI flows under simulated large input and check responsiveness. <br>2) <strong>Pitfall:</strong> leaking secrets via logs or retaining secrets in memory longer than needed. <br>Mitigation: centralize secret access via <code>modUtilities.GetSecretFromStore()</code> and scan telemetry for sensitive patterns during pre-release QA. <br>3) <strong>Pitfall:</strong> inconsistent typed-confirmation logic leading to accidental overwrites. <br>Mitigation: centralize typed-confirmation component and unit test exact-match scenarios including case sensitivity and whitespace. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Acceptance test scenarios (concise)</strong><br>1) Normal small dataset: LoadFile -> RunPreflight -> CreateBatches -> Upload simulation -> ParsePortalErrors -> Finalize; verify <code>ImportLog</code> rows, <code>Batches</code> ledger, and checksums match expected golden artifacts for the current <code>CONFIG_HASH</code>.<br>2) Large dataset cancellation: start CreateBatches on large file, request Cancel mid-run, verify <code>CancelRequested</code> honored, partial batches marked <code>Cancelled</code>, and no partial final files left in <code>STAGING_FOLDER</code>.<br>3) PQ version mismatch: modify <code>PQ_VERSION</code> in <code>Settings</code> and ensure UI blocks runs until acknowledged and migration manifest is presented. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Extensibility notes for future features</strong><br>1) Add "review queue" integration: push Review tasks for rows in <code>Review</code> band to a reviewer UI that links back to JobDetail and stores <code>reviewDecision</code> metadata. <br>2) Integrate role-based access control (RBAC) so operator actions like <code>Force Abort</code> or <code>Purge</code> require elevated roles visible in UI and enforced by <code>modUtilities</code> ACL checks. <br>3) Provide an optional "Operator training mode" that simulates pipeline steps (no writes) and records training telemetry without affecting ledger state. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Developer handoff checklist for frmOperatorUI</strong><br>1) Document all UI strings in <code>Strings</code> sheet and include translation keys for supported locales. <br>2) Provide a test fixture workbook with sample <code>RAW_TABLE_NAME</code>, <code>PREFLIGHT_TABLE_NAME</code>, and <code>BATCHES_TABLE_NAME</code> populated for QA teams. <br>3) Include unit and integration tests for typed-confirmation, cancel semantics, and telemetry emission. <br>4) Create <code>migration_manifest.json</code> entries for behavior changes affecting outputs and add CI gating for golden-file parity. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Final runtime verification checklist</strong><br>1) <code>GetConfig()</code> is the single source of runtime values and <code>configHash</code> is surfaced in JobDetail and telemetry. <br>2) All heavy operations run off UI thread or with cooperative yields; UI remains responsive under test loads. <br>3) Typed confirmations and two-person approvals prevent destructive operations without recorded approvals. <br>4) PII is redacted by default and <code>ShowPII</code> requires typed confirmation and is logged. <br>5) All operator actions produce <code>ui.action</code> telemetry rows with <code>operatorId</code>, <code>jobId</code>, <code>configHash</code> and <code>correlationId</code> for traceability. </td></tr><tr><td data-label="frmOperatorUI — Per-function technical breakdown (VBA)"> <strong>Closing guidance</strong><br>Implement frmOperatorUI as a thin orchestration layer focused on safety, observability, and ergonomics. Keep business logic in modules, use <code>GetConfig()</code> for all environment values, enforce typed confirmations and two-person approvals where necessary, and make cancellation and offload behaviors deterministic. Design the UI to produce consistent telemetry and evidence references so every run is auditable, reproducible, and diagnosable. </td></tr></tbody></table></div><div class="row-count">Rows: 33</div></div><div class="table-caption" id="Table10" data-table="YJKN_0017_10" style="margin-top:2mm;margin-left:3mm;"><strong>Table 10</strong></div>
<div class="table-wrapper" data-table-id="table-10"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **CSV**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>CSV</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th class="tv-col" role="button" aria-label="Sort by **XML**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>XML</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="CSV"> <strong>When best</strong><br>Flat/tabular data (rows × columns), spreadsheets, analytics, bulk import/export — when compactness and speed matter.                                                                                                  </td><td data-label="XML"> <strong>When best</strong><br>Hierarchical or document-centric data, messages with metadata, requiring validation, namespaces, transforms, or document-level security.                                                                                                                                                                                                                              </td></tr><tr><td data-label="CSV"> <strong>Key advantages</strong><br>- Simple to read/produce with basic tools.<br>- Compact & fast for large tables.<br>- Native spreadsheet support (Excel/Sheets).<br>- Streaming-friendly (row-by-row processing).<br>- Minimal tooling overhead. </td><td data-label="XML"> <strong>Key advantages</strong><br>- Natural representation of nested/complex structures.<br>- Self-describing elements/attributes for embedded metadata.<br>- Strong schema & validation support (XSD/DTD).<br>- Namespaces to avoid name collisions.<br>- Powerful transformation/query tools (XSLT, XPath, XQuery).<br>- Standards for signatures/encryption; widely used in document protocols. </td></tr><tr><td data-label="CSV"> <strong>Pitfalls / limits</strong><br>- No standardized metadata or data types (everything is text).<br>- Dialect issues (quoting/escape/delimiter differences).<br>- Poor fit for nested data.<br>- Locale/encoding ambiguities.                   </td><td data-label="XML"> <strong>Pitfalls / limits</strong><br>- Verbose → larger files.<br>- Slower to parse and heavier memory use.<br>- More complex tooling and learning curve.<br>- Can be overkill for simple tabular exports.                                                                                                                                                                                         </td></tr><tr><td data-label="CSV"> <strong>Choose when</strong><br>- You need speed, small size, and straightforward spreadsheet compatibility for flat datasets.                                                                                                                      </td><td data-label="XML"> <strong>Choose when</strong><br>- You need nested structure, strict validation, namespaces, advanced transforms, or document-level security/interoperability.                                                                                                                                                                                                                                       </td></tr><tr><td data-label="CSV"> <strong>Alternatives / complements</strong><br>- <strong>JSON</strong> for hierarchical data in web APIs (easier for developers).<br>- <strong>Parquet / Avro / ORC</strong> for typed, columnar analytics at scale.                                                          </td><td data-label="XML"> <strong>Alternatives / complements</strong><br>- <strong>JSON</strong> often replaces XML for many API uses.<br>- Use binary formats (Parquet/Avro) when analytics performance/space matters; use XML when schema, namespaces, or XML-specific security/standards are required.                                                                                                                                  </td></tr></tbody></table></div><div class="row-count">Rows: 5</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>