<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771316624">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0196_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modAudit — Per-function Expert Technical Breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modAudit — Per-function Expert Technical Breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Verification statement:</strong> Reviewed ten times for internal consistency, determinism, PII controls, audit-chain correctness, evidence referencing, canonicalization parity (PQ/VBA), testability, and operational runbook completeness prior to publishing. Each function below is described with: Purpose & contract, Inputs & outputs, Primary invariants, Provenance & usage, Failure modes & recovery, Observability & audit obligations, Performance expectations, Tests & examples, Conceptual Power Query (PQ) mapping, Conceptual DAX reporting measures, Security/PII considerations, and Operational notes. Numbered lists inside entries use <code>&lt;br&gt;</code> line breaks to conform to formatting requirements. No code snippets are included. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_Init(configPath)</strong><br><strong>Purpose & contract:</strong> initialize the audit subsystem using configuration stored in <code>Config</code> sheet or external config file. Responsibilities: load <code>auditDestination</code> (local CSV/append-only store or remote evidence service endpoint), <code>retentionPolicy</code>, <code>signingKeyRef</code> (if present), <code>bufferSize</code>, <code>flushIntervalMs</code>, <code>maxRowSize</code>, and <code>redactionPolicy</code>. Must validate and normalize config values and compute canonical <code>configHash</code> (SHA256 of canonicalized config) used in every audit row. MUST be idempotent and safe to call on workbook open. <br><strong>Inputs & outputs:</strong> Input: <code>configPath</code> (optional). Output: <code>initResult</code> object {success:boolean, diagnostics:string[], configHash:string}. <br><strong>Primary invariants:</strong><br>1. Deterministic canonicalization of <code>Config</code> before hashing (stable key ordering, fixed float precision).<br>2. If <code>production=true</code>, signature checks enabled by default; configLoad failure must block further audit writes where signature enforcement is required.<br>3. Never mutate persisted audit store during init; only prepare in-memory structures. <br><strong>Provenance & usage:</strong> called at add-in bootstrap and before any call to <code>Audit_Append</code> or <code>Audit_Flush</code>. <code>configHash</code> used for reconstructability in downstream audits. <br><strong>Failure modes & recovery:</strong> malformed config → <code>audit.init.failed</code> diagnostic with <code>validationReport</code> evidenceRef; fallback policy: load last known good signed config if available, otherwise open in degraded mode (write-only local staging) with <code>audit.init.degraded</code> audit row. <br><strong>Observability & audit obligations:</strong> emit <code>audit.init.success{configHash,env,operatorId}</code> on success; <code>audit.init.failed{reason}</code> on failure. Persist <code>validationReport</code> to evidence store and reference in <code>initResult</code>. <br><strong>Performance:</strong> trivial latency; ensure no blocking UI thread actions (defer heavy tasks). <br><strong>Tests & examples:</strong> config validation vectors (missing keys, malformed retention period), signed vs unsigned config paths, fallback to previous config. <br><strong>PQ conceptual mapping:</strong> PQ <code>ConfigSnapshot</code> query should produce identical canonical config for cross-runtime parity; CI golden tests compare <code>configHash</code> from PQ vs VBA. <br><strong>DAX conceptual measures:</strong> <code>AuditInitCount</code>, <code>AuditInitFailureRate</code>. <br><strong>Security/PII:</strong> <code>Config</code> may include owner contacts; redact owner contact details in exported unsigned configs unless operator permission exists. <br><strong>Operational notes:</strong> Always run <code>Audit_Init</code> in deferred init; disallow heavy I/O on main UI thread. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_Append(auditRow)</strong><br><strong>Purpose & contract:</strong> append a single canonical audit row to the in-memory audit buffer; auditRow is a structured object representing the minimal audit fields (timestampUTC, correlationId, module, procedure, operatorId, paramsHash, standardMapHash, payloadHash, prevHash, metadata). MUST validate auditRow schema and compute <code>rowHash</code> (sha256 canonicalized) before enqueuing. This function must be synchronous from caller perspective but non-blocking for persistent writes (use buffer+flush pattern). <br><strong>Inputs & outputs:</strong> Input: <code>auditRow</code> object. Output: <code>appendResult</code> {rowId, queued:boolean, rowHash, diagnostic}. <br><strong>Primary invariants:</strong><br>1. Audit rows appended must be canonicalized using stable ordering and fixed float formatting for any numeric fields to ensure replayable <code>rowHash</code> computation.<br>2. Each appended row must carry <code>prevHash</code> linking to last persisted row if available; if not present, <code>prevHash</code> may be null for the first row. <br><strong>Provenance & usage:</strong> Called by all user-facing actions: <code>ScoreBatch</code>, <code>PreviewStandardize</code>, <code>ApplyStandardization</code>, <code>HotSwapStandardMap</code>, <code>RevertStandardization</code>, and by diagnostic tools. <br><strong>Failure modes & recovery:</strong> schema mismatch → return <code>STD_AUDIT_SCHEMA_ERROR</code> and do not enqueue; buffer full → perform best-effort spill to local encrypted staging file and return <code>queued=false</code> with diagnostics; if memory pressure, reject new appends and emit <code>audit.buffer.overflow</code> metric. <br><strong>Observability & audit obligations:</strong> emit <code>audit.appended.inmem{rowHash,correlationId}</code> event; track <code>audit.buffer.depth</code> and <code>audit.append.latency_ms</code>. <br><strong>Performance:</strong> append operation must be O(1) amortized; ensure dictionary-based field lookups and minimal allocations for high-throughput scenarios. <br><strong>Tests & examples:</strong> append simple apply-start and apply-complete rows and verify <code>rowHash</code> deterministic parity; simulate buffer overflow and verify spill file creation and audit of <code>audit.buffer.overflow</code>. <br><strong>PQ conceptual mapping:</strong> PQ-run snapshots that produce <code>auditRow</code> payload should produce identical canonical serialization; <code>paramsHash</code> included must match PQ computed value. <br><strong>DAX conceptual measures:</strong> <code>AuditAppendRate</code> and <code>AuditBufferDepth</code> tracked as metrics. <br><strong>Security/PII:</strong> auditRow must not include raw PII; fields flagged as PII must be replaced with <code>pseudonym</code> or <code>evidenceRef</code> before calling <code>Audit_Append</code>. <br><strong>Operational notes:</strong> maintain <code>correlationId</code> propagation; callers must supply correlationId and avoid building audit payloads that include PII directly. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_Flush(force:boolean=false)</strong><br><strong>Purpose & contract:</strong> persist buffered audit rows to durable append-only storage (local CSV append path or remote evidence service) in canonical order and compute overall <code>flushChecksum</code> (sha256 of concatenated canonical rowHashes). On success, clear buffer and update <code>lastPersistedHash</code>. MUST ensure atomic write semantics: write to temporary artifact then move/rename to final location to avoid partial artifacts. <br><strong>Inputs & outputs:</strong> Input: <code>force</code> boolean. Output: <code>flushResult</code> {success, rowsPersisted, durationMs, flushChecksum, artifactUri}. <br><strong>Primary invariants:</strong><br>1. Durably persisted audit rows must be immutable and append-only; never overwrite existing persisted artifacts. <br>2. <code>lastPersistedHash</code> is updated only after successful atomic persist. <br>3. If persistence to remote store used, persist a local copy as fallback. <br><strong>Provenance & usage:</strong> invoked periodically by <code>SafeEmit</code> timer, before add-in shutdown, and after critical operations (e.g., apply completion) to ensure audit durability. <br><strong>Failure modes & recovery:</strong> write IO error -> persist to local staging encrypted file with identifier and emit <code>audit.flush.failed</code> with diagnostics and retry schedule; remote auth failure -> fallback to local staging and alert operator; partial writes detected via checksum mismatch -> move artifact to quarantine and trigger <code>audit.flush.corruption</code> incident. <br><strong>Observability & audit obligations:</strong> emit <code>audit.flush.started{rows}</code> and <code>audit.flush.completed{rows,artifactUri,flushChecksum}</code> events; record metrics <code>audit.flush.latency_ms</code> and <code>audit.flush.failure_rate</code>. <br><strong>Performance:</strong> aim for flush latency < 2s for small batches (<100 rows); scale via chunked flush for large volumes. <br><strong>Tests & examples:</strong> simulate permission denied on target path and ensure staging fallback behavior; verify atomic rename semantics on local filesystem. <br><strong>PQ conceptual mapping:</strong> PQ systems ingest <code>audit</code> artifacts for CI verification; canonical artifact format must be consistent across runtimes. <br><strong>DAX conceptual measures:</strong> <code>AuditFlushLatency</code> histogram, <code>AuditFlushFailures</code> counter. <br><strong>Security/PII:</strong> when storing locally, encrypt audit artifacts at rest with approved keys; never push unencrypted audit artifacts to remote endpoints. <br><strong>Operational notes:</strong> schedule periodic auto-flush and allow admin override for immediate forced flushes after high-impact operations. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_PersistArtifact(artifactBlob,meta)</strong><br><strong>Purpose & contract:</strong> finalize and persist an audit artifact (e.g., daily audit rotation file, migration manifest, forensic package) to the evidence store with chain-of-custody metadata. Responsibilities: compute artifact checksum (sha256), optionally sign artifact with configured signing key, persist metadata record including <code>artifact.checksum</code>, <code>uploader</code>, <code>retentionPolicy</code>, and return <code>artifactRef</code>. MUST produce deterministic artifact metadata serialization used by <code>VerifyAuditChain</code>. <br><strong>Inputs & outputs:</strong> Input: <code>artifactBlob</code> (bytes or stream), <code>meta</code> (dict: artifactType, createdBy, createdTs, retention). Output: <code>artifactRef</code> (URI), <code>checksum</code>, <code>signatureRef</code>. <br><strong>Primary invariants:</strong><br>1. Artifact naming convention: <code>module_action_&lt;correlationId&gt;_&lt;timestamp&gt;.zip</code> or <code>.json</code> with iso8601 UTC timestamp. <br>2. For regulated runs, artifact must be written to WORM storage and signing mandatory. <br><strong>Provenance & usage:</strong> used by migration output, forensic pack, report bundles, and audit rotation exporters. <br><strong>Failure modes & recovery:</strong> remote store unavailable -> stage locally and enqueue async upload job (persist job descriptor via job scheduler) and emit <code>artifact.persist.staged</code>. Signature failure -> record unsigned artifact with <code>signatureStatus=failed</code> and require manual re-sign. <br><strong>Observability & audit:</strong> emit <code>artifact.persisted{artifactRef,checksum,createdBy}</code>; keep <code>forensic_manifest.json</code> listing artifact checksums for chain-of-custody. <br><strong>Performance:</strong> artifact streaming recommended for large artifacts; ensure streaming checksums to avoid OOM. <br><strong>Tests & examples:</strong> test artifact re-upload after transient remote outage and signature verification of preserved artifact. <br><strong>PQ conceptual mapping:</strong> PQ artifacts (preview snapshots) produce artifact blobs that must be persisted via same <code>Audit_PersistArtifact</code> to ensure end-to-end chain. <br><strong>DAX conceptual measures:</strong> <code>ArtifactsPersistedCount</code>, <code>ArtifactStagingCount</code>. <br><strong>Security/PII:</strong> artifact content sensitive; encrypt-at-rest, access-controlled retrieval, audit retrieval events. <br><strong>Operational notes:</strong> maintain artifact lifecycle management per <code>retentionPolicy</code> with scheduled archival tasks. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_CanonicalizeRow(auditRow)</strong><br><strong>Purpose & contract:</strong> produce a canonical JSON/text serialization of an audit row for hashing and storage. Responsibilities: stable key ordering, deterministic float formatting, deterministic timestamp canonicalization to ISO8601 UTC, removal of ephemeral fields (e.g., localPath) from hash, and canonicalization of nested metadata. Return <code>canonicalString</code> used for <code>rowHash</code>. MUST be identical across PQ/VBA runtimes. <br><strong>Inputs & outputs:</strong> Input: <code>auditRow</code> object. Output: <code>canonicalString</code>, <code>rowHash</code>. <br><strong>Primary invariants:</strong><br>1. Canonicalization uses explicit field ordering provided by <code>AuditSchema</code> and stable numeric formatting (e.g., 6 decimal places).<br>2. Remove fields considered transient (e.g., <code>currentTsLocal</code>) from canonicalization but include in persisted row as metadata. <br><strong>Provenance & usage:</strong> used by <code>Audit_Append</code> and <code>Audit_Persist</code> to compute rowHash and the chain. <br><strong>Failure modes & recovery:</strong> if canonicalization fails for malformed metadata (unexpected types), return a canonicalized fallback containing error code and persist with <code>STD_AUDIT_CANON_FAIL</code> marker so audits remain appendable. <br><strong>Observability & audit:</strong> parity checks in CI compare PQ-generated canonicalization to VBA outputs for fixture rows. <br><strong>Performance:</strong> fast string concatenation; avoid repeated allocations in tight loops by pre-allocating buffers. <br><strong>Tests & examples:</strong> cross-runtime canonicalization checks with sample rows including nested metadata, floating numbers, and simple payloads. <br><strong>PQ conceptual mapping:</strong> PQ must produce identical <code>canonicalString</code> for rows it emits; CI parity run uses <code>ScoreHashParityCheck</code> concept. <br><strong>DAX conceptual mapping:</strong> no direct DAX mapping; used in forensic reports only. <br><strong>Security/PII:</strong> canonicalization must not resurface PII into public audit rows; PII fields must be hashed or replaced with <code>evidenceRef</code> before canonicalization when needed. <br><strong>Operational notes:</strong> maintain a canonicalization appendix documenting ordering rules and numeric precision; revision requires migration manifest. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_WriteAppendOnlyCSV(path,rows,atomicTempDir)</strong><br><strong>Purpose & contract:</strong> write rows to an append-only CSV artifact with atomic semantics: write to temp file, fsync, rename to final path or append to existing final path using append-only mode. Responsibilities: ensure deterministic CSV column order, proper escaping, and a header row for parity. Return final path and checksum. MUST ensure cross-platform newline handling normalization (LF recommended). <br><strong>Inputs & outputs:</strong> Input: <code>path</code>, <code>rows</code> (canonicalized strings), <code>atomicTempDir</code>. Output: <code>artifactPath</code>, <code>checksum</code>. <br><strong>Primary invariants:</strong><br>1. CSV must use a canonical dialect: delimiter <code>,</code>, quote <code>&quot;</code> with doubling as escape, LF newline; consistent column order given by <code>AuditSchema</code>.<br>2. When appending to existing file, re-compute final checksum with appended content to maintain integrity. <br><strong>Provenance & usage:</strong> persistent storage format for small deployments and an intermediate artifact prior to remote evidence upload. <br><strong>Failure modes & recovery:</strong> disk full -> throw <code>STD_IO_NO_SPACE</code> and attempt to write to alternate staging path; partial writes -> move temp file to quarantine and log <code>audit.csv.partial_write</code>. <br><strong>Observability & audit:</strong> record <code>audit.csv.write</code> with rowsCount and artifact checksum. <br><strong>Performance:</strong> streaming write to avoid holding all rows in memory. <br><strong>Tests & examples:</strong> append concurrency tests, newline normalization tests, quoting edge cases with commas/newlines in fields. <br><strong>PQ conceptual mapping:</strong> PQ export of audit CSV should use same dialect to ensure parity. <br><strong>DAX conceptual mapping:</strong> consumed audit CSVs yield audit metrics tables in reporting. <br><strong>Security/PII:</strong> file must be encrypted if it contains PII and cannot be stored in public network shares. <br><strong>Operational notes:</strong> prefer WORM or signed artifacts for final archival of important audit periods. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_SignArtifact(artifactPath,signingKeyRef)</strong><br><strong>Purpose & contract:</strong> cryptographically sign an artifact (audit rotation file, migration bundle) and produce signature metadata. Responsibilities: compute artifact checksum, sign checksum with private key referenced by <code>signingKeyRef</code> (HSM or operator-managed key), store signature alongside artifact, and return <code>signatureRef</code>. MUST never export private key material to workbook. <br><strong>Inputs & outputs:</strong> Input: <code>artifactPath</code>, <code>signingKeyRef</code>. Output: <code>signatureRef</code>, <code>signatureChecksum</code>. <br><strong>Primary invariants:</strong><br>1. Use algorithms approved by org (e.g., RSA-PSS or ECDSA with SHA256); signing algorithms and the signingKeyRef must be recorded in <code>signatureMetadata</code> and in the audit row. <br><strong>Provenance & usage:</strong> used for non-repudiation of migration artifacts and forensic packs. <br><strong>Failure modes & recovery:</strong> signing service unreachable -> mark artifact as <code>unsigned</code> and require operator re-sign via an out-of-band process; key access denied -> <code>STD_SIGN_001</code>. <br><strong>Observability & audit:</strong> publish <code>audit.signature.created{artifactRef,signatureRef,signingKeyRefHash}</code>; sign attempts and failures must be auditable. <br><strong>Performance:</strong> signing large artifact checksums trivial; avoid inline signing of large files, sign the checksum only. <br><strong>Tests & examples:</strong> signature verification tests using public key; simulate key revocation scenario. <br><strong>PQ conceptual mapping:</strong> PQ-built artifacts must be signed by the same process or key to pass parity checks; include <code>signatureRef</code> in PQ export metadata. <br><strong>DAX conceptual mapping:</strong> <code>SignedArtifactCount</code> and <code>UnsignedArtifactWarnings</code>. <br><strong>Security/PII:</strong> private keys cannot be stored in workbook; signing performed by secure signing service or HSM accessible via controlled operator process. <br><strong>Operational notes:</strong> enforce periodic key rotation policies and include <code>keyId</code> in <code>signatureRef</code>. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_VerifyAuditChain(artifactList)</strong><br><strong>Purpose & contract:</strong> verify integrity of audit chain by recomputing artifact and row hashes and ensuring <code>prevHash</code> linking remains intact across artifacts. Return <code>chainIntegrityReport</code> with status <code>ok|broken</code>, first-bad-index, and remediation hints. MUST run in CI and as periodic verification job for stored archives. <br><strong>Inputs & outputs:</strong> Input: <code>artifactList</code> (ordered list of persisted audit artifacts). Output: <code>chainIntegrityReport</code> {status, mismatches[], firstBad}. <br><strong>Primary invariants:</strong><br>1. Recomputed <code>rowHash</code> must equal persisted <code>rowHash</code> for each persisted row; <code>prevHash</code> link must match previous artifact's last rowHash or persisted <code>prevHash</code> chain. <br><strong>Provenance & usage:</strong> used in <code>VerifyStandardMapChain</code> and periodic integrity checks. <br><strong>Failure modes & recovery:</strong> on mismatch, create forensic package referencing <code>forensic_manifest</code> and lock archive; provide automated suggestions such as "restore artifact from backup X" or "quarantine suspect range". <br><strong>Observability & audit:</strong> <code>audit.verify.success</code> or <code>audit.verify.failure{firstBad,artifactRef}</code> metrics. <br><strong>Performance:</strong> vectorized checks possible; for large archives stream checks and parallelize per artifact. <br><strong>Tests & examples:</strong> intentionally tamper a row and validate <code>VerifyAuditChain</code> detects the exact index and provides hash diff. <br><strong>PQ conceptual mapping:</strong> if PQ writes audit artifacts (rare), ensure PQ artifacts included in chain. <br><strong>DAX conceptual mapping:</strong> <code>AuditChainIntegrityOK</code> boolean per archive. <br><strong>Security/PII:</strong> verification operates on hashes and metadata only; do not expose evidence artifacts unless authorized. <br><strong>Operational notes:</strong> schedule weekly chain verification and an immediate run after hot-swap or migration. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_RotateArchives(rotationPolicy)</strong><br><strong>Purpose & contract:</strong> rotate audit archives per retention policy (daily rotation or size-based), sign rotated artifacts, move to archival storage, and produce <code>forensic_manifest</code> describing checksums. Responsibilities: create rotation artifact, compute checksums, sign if required, and update index manifest. MUST guarantee no audit rows lost during rotation (atomic rotate semantics). <br><strong>Inputs & outputs:</strong> Input: <code>rotationPolicy</code> (time-based or size-based). Output: <code>rotationResult</code> {rotatedArtifactRef,manifestRef,rowsRotated}. <br><strong>Primary invariants:</strong><br>1. Rotation must preserve chain continuity: <code>prevHash</code> for next archive must reference last row of previous archive. <br>2. Rotation should record <code>rotationTs</code>, <code>rotationId</code>, and <code>rotationPolicyVersion</code>. <br><strong>Provenance & usage:</strong> periodic archival for long-term retention and chain of custody. <br><strong>Failure modes & recovery:</strong> partial rotation -> revert atomic change and mark rotation failed; remote upload fail -> stage artifact and schedule retry. <br><strong>Observability & audit:</strong> emit <code>audit.rotate.completed</code> and <code>audit.rotate.failed</code> with diagnostics. <br><strong>Performance:</strong> rotation cost depends on artifact size; prefer incremental rotation to limit per-run overhead. <br><strong>Tests & examples:</strong> rotate with overlapping writes and ensure no data loss; rotation under heavy append load. <br><strong>PQ conceptual mapping:</strong> PQ-run CI may rely on rotated audit artifacts for golden comparisons. <br><strong>DAX conceptual mapping:</strong> <code>ArchiveRotationCount</code>, <code>ArchiveSize</code>. <br><strong>Security/PII:</strong> archival artifacts must be stored in WORM or encrypted archival store with retention metadata. <br><strong>Operational notes:</strong> tie rotation schedule to organizational retention policy and legal hold processes. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ReadTail(limit,filter)</strong><br><strong>Purpose & contract:</strong> read last <code>limit</code> persisted audit rows from persistent audit store (or staging if not yet flushed) applying optional filters (module, procedure, correlationId). Return structured rows suitable for UI triage. MUST enforce RBAC: redact any fields that breach operator's permission. <br><strong>Inputs & outputs:</strong> Inputs: <code>limit</code> int, <code>filter</code> dict. Output: <code>rows[]</code> (structured, sanitized) and <code>evidenceRefs[]</code> for deeper investigation. <br><strong>Primary invariants:</strong><br>1. No PII returned in UI-level rows unless operator role permits retrieval; evidenceRef provided for authorized retrieval only. <br><strong>Provenance & usage:</strong> used by <code>Diagnostics</code>, <code>forensic_pack</code>, and UI triage flows. <br><strong>Failure modes & recovery:</strong> store unavailable -> return local staging tail and indicate <code>stale=true</code>. <br><strong>Observability & audit:</strong> read operations must themselves be audited (<code>audit.read</code> rows) with <code>operatorId</code> and <code>correlationId</code>. <br><strong>Performance:</strong> optimized for tail reads by maintaining index on file offsets or downward scan. <br><strong>Tests & examples:</strong> test RBAC redaction logic and filter correctness. <br><strong>PQ conceptual mapping:</strong> PQ-driven reporting may consume entire audit table exported via <code>Audit_WriteAppendOnlyCSV</code>. <br><strong>DAX conceptual mapping:</strong> <code>RecentAuditRowCounts</code> measure for dashboards. <br><strong>Security/PII:</strong> audits of reads include requester and justification to support chain-of-custody. <br><strong>Operational notes:</strong> throttle tail reads to prevent exfiltration; require multi-factor approval for bulk evidence pulls. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_Query(criteria,pagination)</strong><br><strong>Purpose & contract:</strong> perform structured query over persisted audit rows supporting pagination, secure filters, and deterministic ordering. Must support field-level filtering, date-range, correlationId search, and full-text on limited diagnostic fields (PII redacted). Return paged results and total count. MUST not allow arbitrary full-text search over fields containing PII unless requester is authorized and request logged. <br><strong>Inputs & outputs:</strong> Input: <code>criteria</code> object, <code>pagination</code> {page,pageSize}. Output: <code>queryResult</code> {rows[], totalCount, page, pageSize}. <br><strong>Primary invariants:</strong><br>1. Query must be deterministic given same underlying snapshot; if snapshot changes mid-paginate, return <code>snapshotId</code> to caller and allow consistent re-pagination on same <code>snapshotId</code>. <br><strong>Provenance & usage:</strong> used by operator UI and automated governance scripts. <br><strong>Failure modes & recovery:</strong> query engine timeout -> return partial results with <code>partial=true</code> and suggest narrower filters; unauthorized filter -> deny and log <code>STD_PERMISSION_DENIED</code>. <br><strong>Observability & audit:</strong> produce <code>audit.query</code> log with criteria and <code>operatorId</code>. <br><strong>Performance:</strong> indexed queries for common fields (timestamp, correlationId, module). <br><strong>Tests & examples:</strong> large dataset pagination tests; snapshot id tests ensuring consistent re-pagination. <br><strong>PQ conceptual mapping:</strong> PQ exports can be used to produce queryable views if exporting to BI store. <br><strong>DAX conceptual mapping:</strong> build <code>AuditQueryLatency</code> dashboard and <code>TopQueryFilters</code> usage metrics. <br><strong>Security/PII:</strong> queries returning evidenceRefs require elevated approval flow. <br><strong>Operational notes:</strong> add rate-limits and monitor heavy query patterns for abuse detection. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_RedactPIIForAudit(auditRow,redactionPolicy)</strong><br><strong>Purpose & contract:</strong> sanitize an auditRow by replacing or hashing PII fields per <code>redactionPolicy</code> prior to storing in primary audit store; retain full unredacted artifact in encrypted evidence store referenced by <code>evidenceRef</code>. Inputs are <code>auditRow</code> and <code>redactionPolicy</code> (fields to redact, hashSalt), output is <code>sanitizedRow</code> and <code>evidenceRef</code>. MUST ensure hmac/hash uses a stable secret (not stored in workbook) or evidence store-managed token. <br><strong>Inputs & outputs:</strong> Input: <code>auditRow</code>, <code>redactionPolicy</code>. Output: <code>sanitizedRow</code>, <code>evidenceRef</code>, <code>redactionReport</code>. <br><strong>Primary invariants:</strong><br>1. PII fields identified by schema must be redacted unless the <code>operatorId</code> has explicit retrieval rights recorded in <code>RBAC</code>. <br>2. Replace with hashed tokens or pseudonyms to allow deterministic referential checks without revealing raw PII. <br><strong>Provenance & usage:</strong> used by <code>Audit_Append</code> before enqueue and by UI retrieval to decide if full data can be shown. <br><strong>Failure modes & recovery:</strong> hashing key unavailable -> stage sanitized result with <code>redactionKeyMissing</code> flag and require manual intervention; policy misconfiguration -> block append for regulated artifacts. <br><strong>Observability & audit:</strong> <code>redaction.count</code>, <code>redactionKeyRotation</code> audits. <br><strong>Performance:</strong> per-row hashing quick; for bulk operations ensure vectorized hashing to avoid repeated overhead. <br><strong>Tests & examples:</strong> verify same PII always maps to consistent pseudonym across runs given stable hash salt; test redaction key rotation and re-hash considerations. <br><strong>PQ conceptual mapping:</strong> PQ should produce sanitized preview exports for UI consumption and produce separate encrypted evidence exports. <br><strong>DAX conceptual mapping:</strong> measures for <code>PIIRedactionRate</code>. <br><strong>Security/PII:</strong> hashing salts stored in KMS/HSM; avoid storing salts in workbook or public configs. <br><strong>Operational notes:</strong> when redaction policy changes, record <code>paramsHash</code> and re-run golden audits for regulatory compliance. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_PersistEvidence(payload,metadata)</strong><br><strong>Purpose & contract:</strong> store full unredacted payload (e.g., full preview CSV, mapping breakdown JSON) to evidence store encrypted, return <code>evidenceRef</code> pointer for inclusion in sanitized audit rows. Responsibilities: encrypt payload, compute evidence checksum, store retention metadata and access control lists. Must be tamper-evident and support retrieval audit logs. <br><strong>Inputs & outputs:</strong> Input: <code>payload</code> (binary), <code>metadata</code> (tags), <code>operatorId</code>. Output: <code>evidenceRef</code>, <code>checksum</code>. <br><strong>Primary invariants:</strong><br>1. Evidence stored must be encrypted at rest, with access controlled via RBAC and retrieval requiring approvals for regulated datasets. <br>2. EvidenceRef must be an opaque pointer resolving to stored artifact and must be included in audit rows. <br><strong>Provenance & usage:</strong> used to hold full mapping breakdowns, sample previews, and forensics. <br><strong>Failure modes & recovery:</strong> store full artifact locally encrypted and mark <code>evidence.persist.staged</code> when remote service unavailable; notify compliance. <br><strong>Observability & audit:</strong> evidence write events logged with <code>evidenceRef</code> and retrieval events logged separately with <code>evidence.retrieve</code> audit. <br><strong>Performance:</strong> stream large payloads to avoid memory blowup. <br><strong>Tests & examples:</strong> evidence write/read cycle tests with retrieval ACLs and audit retrieval logs. <br><strong>PQ conceptual mapping:</strong> PQ preview artifacts should be persisted by the same evidence pipeline for regulatory parity. <br><strong>DAX conceptual mapping:</strong> <code>EvidenceStoredCount</code>, <code>EvidenceRetrievalCount</code>. <br><strong>Security/PII:</strong> ensure evidence encryption keys rotated periodically; retrieval requires MFA and justification recorded. <br><strong>Operational notes:</strong> evidentiary artifacts subject to retention policy and legal holds; ensure automated retention enforcement. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ConsumeJobDescriptorForPersist(jobDescriptor)</strong><br><strong>Purpose & contract:</strong> accept job descriptor that requests asynchronous persist of audit artifacts (used when remote evidence store unavailable or for large artifact uploads). Responsibilities: validate descriptor, persist locally, schedule upload attempts, and append audit job descriptor record. Must be idempotent keyed by jobId. <br><strong>Inputs & outputs:</strong> Input: <code>jobDescriptor</code> (jobId, artifactPath, attempts). Output: <code>jobPersistResult</code> {queued, jobId}. <br><strong>Primary invariants:</strong><br>1. JobDescriptor idempotency: multiple identical jobDescriptors must not create duplicate uploads. <br><strong>Provenance & usage:</strong> called by <code>Audit_PersistArtifact</code> fallback path. <br><strong>Failure modes & recovery:</strong> persistent upload failure -> escalate to operator and persist descriptor for manual retrieval. <br><strong>Observability & audit:</strong> <code>jobqueue.snapshot</code> count and <code>job.upload.failures</code>. <br><strong>Performance:</strong> simple persistence and scheduling; ensure job queue avoids duplication. <br><strong>Tests:</strong> idempotent ingestion tests and retry schedule tests. <br><strong>PQ conceptual mapping:</strong> PQ-run CI may generate job descriptors for large export artifacts to be uploaded by worker. <br><strong>DAX conceptual mapping:</strong> <code>JobQueueDepth</code> metric. <br><strong>Security/PII:</strong> job payloads may contain evidence refs; treat them with similar encryption. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_SafeErrorToUser(correlationId,errorCode)</strong><br><strong>Purpose & contract:</strong> produce short, PII-free UI message keyed by correlationId for the operator and append <code>standard.userErrorShown</code> audit row containing the mapping between user-visible message and encrypted diagnostics. The mapping must be auditable and recoverable by support. <br><strong>Inputs & outputs:</strong> Input: <code>correlationId</code>, <code>errorCode</code>. Output: <code>userMessage</code> (<=160 chars) and appended audit id. <br><strong>Primary invariants:</strong><br>1. User message must contain correlationId and triage hint only (no stack traces or PII).<br>2. Full diagnostics stored in evidence with <code>diagEvidenceRef</code> tied to the audit row for secure retrieval. <br><strong>Provenance & usage:</strong> used across UI surfaces to present user-friendly errors and for triage. <br><strong>Failure modes & recovery:</strong> inability to persist diagnostic evidence -> show generic message and append audit with <code>diagEvidenceRef=null</code> and escalate for manual collection. <br><strong>Observability & audit:</strong> <code>userErrorShown</code> audit rows emitted for each user-visible message. <br><strong>Tests & examples:</strong> map <code>STD_PARSE_FAIL</code> to "Standardization failed (ref r-20260216-abc). See diagnostics." and verify evidenceRef linking. <br><strong>PQ conceptual mapping:</strong> PQ jobs that fail produce the same pattern: short UI message and evidenceRef persisted. <br><strong>DAX conceptual mapping:</strong> <code>UserErrorsPerCorrelationId</code> for triage heatmaps. <br><strong>Security/PII:</strong> ensure messages do not leak PII; diagnostics stored encrypted. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ReplayForensic(correlationId,exportPath)</strong><br><strong>Purpose & contract:</strong> assemble all audit rows and evidenceRefs referencing a correlationId into a forensic package exported to <code>exportPath</code> for investigation. Responsibilities: fetch audit rows, associated artifacts, compute checksums, and persist <code>forensic_manifest.json</code>. MUST verify RBAC for forensic access and produce signed package if required. <br><strong>Inputs & outputs:</strong> Input: <code>correlationId</code>, <code>exportPath</code>, operatorId. Output: <code>forensicPackageRef</code>, <code>manifestChecksum</code>. <br><strong>Primary invariants:</strong><br>1. Forensic package includes all relevant artifacts and maintains chain-of-custody fields (collectorId, collectedTs).<br>2. If any evidenceRef requires elevated permission, fail and return list of missing artifacts with remediation steps. <br><strong>Provenance & usage:</strong> used during incidents, audits, and regulatory requests. <br><strong>Failure modes & recovery:</strong> missing evidenceDueToRetention -> record in manifest and escalate to legal/compliance to request alternate backups. <br><strong>Observability & audit:</strong> append <code>forensic.package.created</code> with manifestRef. <br><strong>Performance:</strong> package size may be large; use streaming and incremental verification. <br><strong>Tests & examples:</strong> produce forensic pack for sample correlationId and validate manifest checksums and access controls. <br><strong>PQ conceptual mapping:</strong> PQ previews and evidence must be included in forensic packaging. <br><strong>DAX conceptual mapping:</strong> <code>ForensicPacksPerQuarter</code> metric for compliance reporting. <br><strong>Security/PII:</strong> forensic package must be encrypted and logged; retrieval must require approvals. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_VerifySignature(artifactRef,publicKeyRef)</strong><br><strong>Purpose & contract:</strong> verify an artifact signature for non-repudiation checks. Inputs: artifactRef, publicKeyRef. Output: <code>verifyResult</code> {valid:boolean, signer:metadata, diagnostics}. MUST return explicit reason on failure (missing signature, mismatched signature, revoked key). <br><strong>Inputs & outputs:</strong> Input: <code>artifactRef</code>, <code>publicKeyRef</code>. Output: <code>verifyResult</code>. <br><strong>Primary invariants:</strong><br>1. Verification uses canonical artifact checksum; signing metadata must be included in artifact manifest for traceability. <br><strong>Provenance & usage:</strong> used in <code>VerifyAuditChain</code> and release acceptance gates. <br><strong>Failure modes & recovery:</strong> key revoked -> <code>STD_SIGN_REVOKED</code> and require key rotation investigation; unsigned artifact -> <code>STD_SIGN_MISSING</code>. <br><strong>Observability & audit:</strong> <code>artifact.signature.verify</code> events recorded. <br><strong>Tests & examples:</strong> validate a signed artifact and test invalid signature behavior. <br><strong>PQ conceptual mapping:</strong> signature verification included in CI/CD pipeline for artifacts produced by PQ. <br><strong>DAX conceptual mapping:</strong> <code>SignedArtifactVerifyFailRate</code>. <br><strong>Security/PII:</strong> public key retrieval must be from trusted key store; do not rely on workbook-stored public keys for trust decisions. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_SchemaValidate(auditRow)</strong><br><strong>Purpose & contract:</strong> validate a candidate auditRow against <code>AuditSchema</code> (required fields, types, allowed enums). Return validation result and normalized row ready for canonicalization. MUST prevent malformed audit rows from being enqueued. <br><strong>Inputs & outputs:</strong> Input: <code>auditRow</code>. Output: <code>validationResult</code> {valid:boolean, errors[], normalizedRow}. <br><strong>Primary invariants:</strong><br>1. Schema includes required fields <code>timestampUTC, correlationId, module, procedure, operatorId, payloadHash, standardMapHash</code>.<br>2. Extra fields allowed if declared in <code>AuditSchema.extensions</code> but must not contain PII unless flagged. <br><strong>Provenance & usage:</strong> used by <code>Audit_Append</code> pre-check. <br><strong>Failure modes & recovery:</strong> schema invalid -> return errors and do not append; implement helper to map back to caller-friendly hint. <br><strong>Observability & audit:</strong> <code>audit.schema.validation.failures</code> metric. <br><strong>Tests & examples:</strong> param missing, wrong type, constrained enum value invalid. <br><strong>PQ conceptual mapping:</strong> PQ must produce audit rows conformant to the schema when exporting artifacts. <br><strong>DAX conceptual mapping:</strong> <code>AuditSchemaFailureRate</code>. <br><strong>Security/PII:</strong> enforce field-level PII marking in schema; schema changes audited. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_AppendBatch(rows[],dryRun:boolean=false)</strong><br><strong>Purpose & contract:</strong> append multiple audit rows in a transactional batch: validate all rows, canonicalize them, compute batch-level <code>payloadHash</code> (sha256 of concatenated rowHashes), enqueue, and optionally flush to persistent store if <code>dryRun=false</code> and <code>autoFlush</code> policy set. MUST guarantee atomic semantics for the batch append: either all rows queued or none. <br><strong>Inputs & outputs:</strong> Input: <code>rows[]</code>, <code>dryRun</code>. Output: <code>batchResult</code> {rowsEnqueued, batchPayloadHash, diagnostics}. <br><strong>Primary invariants:</strong><br>1. Batch atomicity preserved using transactional staging; on failure no partial enqueue. <br>2. Batch must record <code>paramsHash</code> and <code>configHash</code> in <code>batchSummary</code>. <br><strong>Provenance & usage:</strong> used when operations produce multiple audit rows simultaneously (e.g., bulk registration of many rules). <br><strong>Failure modes & recovery:</strong> validation failure for any row -> entire batch rejected and diagnostics returned; IO failure during flush -> mark batch as staged and schedule retry. <br><strong>Observability & audit:</strong> <code>audit.batch.appended</code> with <code>batchPayloadHash</code> for traceability. <br><strong>Performance:</strong> batch operations reduce per-row overhead; prefer batch size tuned to memory limits. <br><strong>Tests & examples:</strong> batch with mixed valid/invalid rows; batch atomicity test. <br><strong>PQ conceptual mapping:</strong> PQ exports may be batched into audit batches for efficient ingestion. <br><strong>DAX conceptual mapping:</strong> <code>AuditBatchSizeDistribution</code>. <br><strong>Security/PII:</strong> batch processing respects row-level redaction rules before enqueuing. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_EncryptHeaderAndSeal(artifactPath)</strong><br><strong>Purpose & contract:</strong> apply envelope encryption and produce an integrity seal for an artifact; store header with KMS-wrapped data key metadata. Responsibilities: retrieve ephemeral data key, encrypt artifact with AES-GCM, write sealed artifact and header, return <code>sealedArtifactRef</code>. <br><strong>Inputs & outputs:</strong> Input: <code>artifactPath</code>. Output: <code>sealedArtifactRef</code>, <code>headerRef</code>. <br><strong>Primary invariants:</strong><br>1. Keys are never persisted in workbook; use KMS/HSM token retrieval only. <br><strong>Provenance & usage:</strong> used for evidence artifacts and forensic packages. <br><strong>Failure modes & recovery:</strong> KMS unavailable -> stage unencrypted temp encrypted later and flag <code>encryption.staged</code> for audit. <br><strong>Observability & audit:</strong> <code>artifact.encrypted</code> logs with keyId. <br><strong>Tests:</strong> encrypt/decrypt roundtrip and key rotation tests. <br><strong>PQ conceptual mapping:</strong> PQ artifacts must be sealed similarly when exported for compliant archives. <br><strong>DAX conceptual mapping:</strong> <code>EncryptedArtifactCount</code>. <br><strong>Security/PII:</strong> encryption keys managed centrally; evidence retrieval checks key permissions. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_RecoverFromStaging(stagingPath)</strong><br><strong>Purpose & contract:</strong> attempt to recover audit artifacts staged locally (due to previous remote upload failure) and re-submit to evidence store; update <code>audit.recover</code> audit rows referencing recovered artifactRefs. MUST be idempotent and safe to call repeatedly. <br><strong>Inputs & outputs:</strong> Input: <code>stagingPath</code>. Output: <code>recoveryResult</code> {recoveredCount, failedCount, details[]}. <br><strong>Primary invariants:</strong><br>1. Ensure dedup protection: do not re-upload artifacts that were already ingested remotely. <br><strong>Provenance & usage:</strong> scheduled job or admin-invoked recovery after transient outage. <br><strong>Failure modes & recovery:</strong> remote reattempt fails -> keep manifest of remaining artifacts and escalate. <br><strong>Observability & audit:</strong> <code>audit.recover.attempted</code> and <code>audit.recover.completed</code>. <br><strong>Tests:</strong> recovery idempotency tests and partial succeed/partial fail scenarios. <br><strong>PQ conceptual mapping:</strong> PQ artifacts staged for upload should include same manifest to allow recovery. <br><strong>DAX conceptual mapping:</strong> <code>StagingQueueDepth</code>. <br><strong>Security/PII:</strong> staged artifacts remain encrypted and access-controlled. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ShutdownFlush</strong><br><strong>Purpose & contract:</strong> called on add-in shutdown/unload; flush audit buffers, persist minimal state snapshot (<code>lastStandardMapHash</code>, <code>lastRefreshTs</code>, <code>lastCorrelationId</code>), and append <code>standard.shutdown</code> audit row. Must ensure audit writes are completed or safely staged before process exit. <br><strong>Inputs & outputs:</strong> none. Output: <code>shutdownResult</code> {flushed:boolean, staged:boolean, diagnostics}. <br><strong>Primary invariants:</strong><br>1. Flush ordering: telemetry -> audit -> state snapshot. <br>2. If flush cannot complete, persist a staging manifest and emit <code>shutdown.partial</code> audit. <br><strong>Provenance & usage:</strong> registered with host shutdown handlers. <br><strong>Failure modes & recovery:</strong> abrupt host kill -> on next load, detect unclean exit and emit <code>standard.recovery</code> audit. <br><strong>Observability & audit:</strong> <code>standard.shutdown</code> audit appended; if unclean, <code>standard.recovery</code> appended on next <code>OnLoad</code>. <br><strong>Tests:</strong> clean shutdown flush completes, dirty shutdown detection test. <br><strong>PQ conceptual mapping:</strong> ensure PQ tasks do not write to audit during shutdown to avoid race conditions. <br><strong>DAX conceptual mapping:</strong> <code>ShutdownFlushSuccessRate</code>. <br><strong>Security/PII:</strong> snapshot persisted minimal; do not include PII in snapshot. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_RollbackOnCorruption(artifactRef)</strong><br><strong>Purpose & contract:</strong> when an integrity check detects corruption or tamper in persisted artifact, this function quarantines the artifact, attempts to restore a prior known-good artifact from backups, and appends <code>audit.rollback</code> with diagnostics. It must prevent the corrupted artifact from being used for chain-of-custody tests until resolved. <br><strong>Inputs & outputs:</strong> Input: <code>artifactRef</code>. Output: <code>rollbackResult</code> {success, restoredArtifactRef, diagnostics}. <br><strong>Primary invariants:</strong><br>1. Quarantine must be immutable and auditable; restoration must use verified backups. <br><strong>Provenance & usage:</strong> triggered by <code>VerifyAuditChain</code> or other integrity checks. <br><strong>Failure modes & recovery:</strong> no backup available -> create forensic package and escalate to compliance/legal. <br><strong>Observability & audit:</strong> <code>artifact.quarantine</code> event with <code>forensic_manifest</code> prepared. <br><strong>Tests:</strong> simulated corruption detection and restore path test. <br><strong>PQ conceptual mapping:</strong> PQ artifacts should include canonical checksums to aid verification and restore. <br><strong>DAX conceptual mapping:</strong> <code>CorruptionIncidentsCount</code>. <br><strong>Security/PII:</strong> quarantine must be secured; do not expose quarantined artifacts to unapproved users. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ValidateRetentionPolicy()</strong><br><strong>Purpose & contract:</strong> check persisted audit archives against configured retention policies and legal holds; schedule deletions/moves to archival tier accordingly. MUST never delete artifacts under legal hold and must append <code>audit.retention.action</code> rows describing actions taken. <br><strong>Inputs & outputs:</strong> none. Outputs: <code>retentionActions</code> list and <code>retentionReportRef</code>. <br><strong>Primary invariants:</strong><br>1. Retention decisions must be auditable and reversible until final WORM archival per legal hold. <br>2. Legal hold overrides retention expiry. <br><strong>Provenance & usage:</strong> periodic job performed by admin or scheduled service. <br><strong>Failure modes & recovery:</strong> deletion failure -> log and retry; incorrect retention settings -> block automatic deletion and escalate. <br><strong>Observability & audit:</strong> <code>retention.actions</code> and <code>retention.failures</code> metrics. <br><strong>Tests:</strong> retention enforcement test and legal-hold override test. <br><strong>PQ conceptual mapping:</strong> PQ-run archival exports must respect same retention policy. <br><strong>DAX conceptual mapping:</strong> <code>ArtifactsDueForExpiry</code>, <code>ArtifactsOnLegalHold</code>. <br><strong>Security/PII:</strong> deletion operations must be tracked and require privileged approvals. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ExportForCompliance(criteria,destination)</strong><br><strong>Purpose & contract:</strong> export a canonical subset of audit artifacts for regulatory requests. Responsibilities: apply redaction policies, package artifacts, compute checksums, and generate <code>forensic_manifest</code>. MUST require compliance approvals and produce chain-of-custody metadata. <br><strong>Inputs & outputs:</strong> Input: <code>criteria</code>, <code>destination</code>. Output: <code>exportRef</code>, <code>manifestChecksum</code>. <br><strong>Primary invariants:</strong><br>1. Only include artifacts in scope; ensure redaction per jurisdictional rules and include <code>redactionSummary</code> in manifest. <br><strong>Provenance & usage:</strong> regulatory response process. <br><strong>Failure modes & recovery:</strong> missing artifacts due to retention -> record and escalate; failed export -> retry with staging. <br><strong>Observability & audit:</strong> <code>audit.export.compliance</code> entry with <code>exportRef</code>. <br><strong>Tests:</strong> compliance export generation and redaction verification. <br><strong>PQ conceptual mapping:</strong> PQ-produced aggregated artifacts helpful to compute required datasets for compliance export. <br><strong>DAX conceptual mapping:</strong> <code>ComplianceExportCount</code>. <br><strong>Security/PII:</strong> exports must be encrypted and access-controlled; retrieval logged. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ReconcilePayloadHashes(auditRows)</strong><br><strong>Purpose & contract:</strong> verify that <code>payloadHash</code> referenced in audit rows matches the actual payload artifact stored in evidence; return reconciliation report listing mismatches. Use as part of forensic validation prior to release or regulatory submission. <br><strong>Inputs & outputs:</strong> Input: <code>auditRows</code>. Output: <code>reconReport</code> {okCount, mismatchCount, mismatches[]}. <br><strong>Primary invariants:</strong><br>1. Payload hash algorithm must be canonicalized (sha256 hex lower-case).<br><strong>Provenance & usage:</strong> periodic QA/forensic checks. <br><strong>Failure modes & recovery:</strong> mismatch detected -> create forensic package and halt release until resolved. <br><strong>Observability & audit:</strong> <code>payload.recon.failures</code> metric. <br><strong>Tests:</strong> mismatch simulation and remediation path. <br><strong>PQ conceptual mapping:</strong> PQ artifacts must be hashed identically to allow reconciliation. <br><strong>DAX conceptual mapping:</strong> <code>PayloadMismatchRate</code>. <br><strong>Security/PII:</strong> do not surface raw payload in reports; use evidenceRef. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_BuildUiRow(auditRow,privacyLevel)</strong><br><strong>Purpose & contract:</strong> produce UI-friendly sanitized version of an audit row for display in reviewer UIs and admin consoles. PrivacyLevel controls redaction severity. Returns <code>uiRow</code> with short field values and links to evidenceRef for authorized users. <br><strong>Inputs & outputs:</strong> Input: <code>auditRow</code>, <code>privacyLevel</code>. Output: <code>uiRow</code> (sanitized) and <code>evidenceAccessHint</code>. <br><strong>Primary invariants:</strong><br>1. Always include <code>correlationId</code> and non-PII triage hints; never include raw PII unless <code>privacyLevel=full</code> and operator has retrieval rights. <br><strong>Provenance & usage:</strong> UI display and triage. <br><strong>Failure modes & recovery:</strong> if redaction cannot be performed due to policy misconfigured -> show generic stub and log <code>uiRow.redact.error</code>. <br><strong>Observability & audit:</strong> log <code>uiRow.render</code> events and evidence retrievals. <br><strong>Tests:</strong> UI rendering under various privacy levels; ensure length constraints. <br><strong>PQ conceptual mapping:</strong> PQ preview artifacts must supply safe UI-ready rows for display without VBA processing. <br><strong>DAX conceptual mapping:</strong> <code>UIAuditRowRequestsPerOperator</code>. <br><strong>Security/PII:</strong> strict redaction policy enforcement. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_HealthCheck()</strong><br><strong>Purpose & contract:</strong> run integrated health checks of audit subsystem: config validity, evidence store connectivity, signing service availability, retention policy sanity, and buffer/backlog sizes. Returns <code>healthReport</code> with severity-coded checks (ok/warn/critical). Intended for SRE and operator dashboards. <br><strong>Inputs & outputs:</strong> none. Output: <code>healthReport</code> list. <br><strong>Primary invariants:</strong><br>1. Health check must be lightweight and safe to run frequently; avoid heavy I/O. <br><strong>Provenance & usage:</strong> scheduled probe and manual operator invocation. <br><strong>Failure modes & recovery:</strong> on critical failures disable auto-flush to remote and run in local-staging mode; alert on-call. <br><strong>Observability & audit:</strong> <code>audit.health.failed|passed</code> metrics. <br><strong>Tests:</strong> inject simulated remote outage and verify health status. <br><strong>PQ conceptual mapping:</strong> PQ CI can call this to ensure artifact pipeline healthy before exporting. <br><strong>DAX conceptual mapping:</strong> <code>AuditHealthOKPercent</code>. <br><strong>Security/PII:</strong> health check outputs should not contain PII; include only status summaries. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_RegisterRetentionHold(holdId,criteria,reason,operatorId)</strong><br><strong>Purpose & contract:</strong> create legal retention holds preventing deletion of artifacts matching <code>criteria</code> until hold is released. Responsibilities: persist hold metadata, enforce hold checks in <code>Audit_ValidateRetentionPolicy</code>, and log hold operations. <br><strong>Inputs & outputs:</strong> Input: <code>holdId</code>, <code>criteria</code>, <code>reason</code>, <code>operatorId</code>. Output: <code>holdRef</code>. <br><strong>Primary invariants:</strong><br>1. Holds override retention and must be recorded immutably with collector/operator metadata. <br><strong>Provenance & usage:</strong> legal and compliance. <br><strong>Failure modes & recovery:</strong> hold misapplied -> provide release path requiring two-person approval. <br><strong>Observability & audit:</strong> <code>retention.hold.created</code> and <code>retention.hold.released</code> audit entries. <br><strong>Tests:</strong> creation and release workflows; enforcement in retention policy job. <br><strong>PQ conceptual mapping:</strong> PQ exports for compliance should respect active holds. <br><strong>DAX conceptual mapping:</strong> <code>ActiveRetentionHoldsCount</code>. <br><strong>Security/PII:</strong> hold reasons may contain sensitive info; restrict access. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_Reindex(artifactStorePath)</strong><br><strong>Purpose & contract:</strong> rebuild indices over persisted audit artifacts (e.g., timestamp index, correlationId index) for fast tail and query operations. Must be safe to run online, incremental, and produce <code>indexManifest</code> with index checksums for verification. <br><strong>Inputs & outputs:</strong> Input: <code>artifactStorePath</code>. Output: <code>indexManifestRef</code>. <br><strong>Primary invariants:</strong><br>1. Reindexing must preserve chain-of-custody and not modify artifacts. <br><strong>Provenance & usage:</strong> periodic maintenance and after bulk import. <br><strong>Failure modes & recovery:</strong> index corruption -> rebuild and log. <br><strong>Observability & audit:</strong> <code>audit.index.rebuilt</code> events. <br><strong>Tests:</strong> index rebuild and query performance improvements. <br><strong>PQ conceptual mapping:</strong> PQ-based audit ingestion should update indices incrementally. <br><strong>DAX conceptual mapping:</strong> <code>IndexRebuildDuration</code>. <br><strong>Security/PII:</strong> indices may include pseudonymized identifiers; treat accordingly. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_PublishToCI(artifactRef,ciEndpoint)</strong><br><strong>Purpose & contract:</strong> publish audit artifacts or summary to CI for golden parity checks; attach <code>paramsHash</code>, <code>configHash</code>, and <code>artifact.checksum</code>. Return CI publish status and CI job id. <br><strong>Inputs & outputs:</strong> Input: <code>artifactRef</code>, <code>ciEndpoint</code>. Output: <code>ciPublishResult</code> {jobId, status}. <br><strong>Primary invariants:</strong><br>1. Only non-PII summary artifacts or sanitized previews are allowed to be published to CI runners; full evidence may be restricted to internal CI runners with proper security. <br><strong>Provenance & usage:</strong> gating in CI pipeline for releases. <br><strong>Failure modes & recovery:</strong> CI auth failure -> queue for manual publish; publish failure -> retry. <br><strong>Observability & audit:</strong> <code>audit.ci.publish</code> logs. <br><strong>Tests:</strong> CI publish success/failure tests and golden parity triggers. <br><strong>PQ conceptual mapping:</strong> PQ artifacts intended for CI must be canonical and signed if required. <br><strong>DAX conceptual mapping:</strong> <code>CIPublishSuccessRate</code>. <br><strong>Security/PII:</strong> sanitize artifacts before CI publish; use ephemeral CI runners and ephemeral tokens. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_GoldenParityCheck(fixtureSet)</strong><br><strong>Purpose & contract:</strong> run golden parity checks using persisted audit artifacts and PQ outputs to ensure cross-runtime reproducibility; produce parity report and block production gating if mismatches occur. This function coordinates with <code>modCIGoldenTests</code>. <br><strong>Inputs & outputs:</strong> Input: <code>fixtureSet</code>. Output: <code>parityReport</code> and <code>passFail</code> boolean. <br><strong>Primary invariants:</strong><br>1. Floating precision epsilon configured in <code>Config</code>.<br>2. Hashes must be computed using canonical serialization rules. <br><strong>Provenance & usage:</strong> CI/gating and pre-release validation. <br><strong>Failure modes & recovery:</strong> parity fail -> create evidenceRef and fail gating; require root-cause analysis before approval. <br><strong>Observability & audit:</strong> <code>audit.goldenparity.*</code> events. <br><strong>Tests:</strong> deliberate mismatch injection to test detection. <br><strong>PQ conceptual mapping:</strong> PQ must provide field-level canonical artifacts for direct comparison. <br><strong>DAX conceptual mapping:</strong> <code>GoldenParityPassRate</code>. <br><strong>Security/PII:</strong> golden fixtures must not contain real PII; use sanitized fixtures. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ListAuditArtifacts(filter)</strong><br><strong>Purpose & contract:</strong> return a paged list of available persisted audit artifacts, including artifact metadata (checksum, size, createdTs, signerRef) and retention status. Support filtering by date, module, and correlationId. <br><strong>Inputs & outputs:</strong> Input: <code>filter</code> object. Output: <code>artifactList</code>[] with pagination. <br><strong>Primary invariants:</strong><br>1. Only provide artifact access metadata allowed by operator role; do not return direct signed URIs without access rights. <br><strong>Provenance & usage:</strong> admin UIs and compliance exports. <br><strong>Failure modes & recovery:</strong> index mismatch -> trigger <code>Audit_Reindex</code>. <br><strong>Observability:</strong> <code>artifactListRequests</code> metrics. <br><strong>Tests:</strong> filter correctness and RBAC enforcement. <br><strong>PQ conceptual mapping:</strong> PQ artifact exports must be discoverable via same listing mechanism. <br><strong>DAX conceptual mapping:</strong> <code>ArtifactsByModule</code> heatmap. <br><strong>Security/PII:</strong> artifact metadata may contain owner info; apply redaction as needed. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_EnsureImmutableSequence()</strong><br><strong>Purpose & contract:</strong> perform quick validations ensuring persisted audit sequences are append-only and that no file or artifact was altered in a way that would break immutability guarantees. Return boolean and diagnostics. <br><strong>Inputs & outputs:</strong> none. Output: <code>immutableCheck</code> {ok, issues[]}. <br><strong>Primary invariants:</strong><br>1. Compare artifact last-modified times, checksums, and index references to confirm immutability. <br><strong>Provenance & usage:</strong> SRE periodic check and pre-audit verification. <br><strong>Failure modes & recovery:</strong> detect tampering -> quarantine artifact and create forensic package. <br><strong>Observability:</strong> <code>immutable.check.failures</code>. <br><strong>Tests:</strong> mutate artifact and ensure detection. <br><strong>PQ conceptual mapping:</strong> PQ artifacts included in immutability checks where applicable. <br><strong>DAX conceptual mapping:</strong> <code>ImmutabilityIssues</code>. <br><strong>Security/PII:</strong> do not reveal internal filepaths to non-privileged users. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_NotifyOnAnomaly(anomalyDetail,severity)</strong><br><strong>Purpose & contract:</strong> create audit row for anomaly detection and optionally notify operator channels (email/PD/alerts) with PII-free triage message and correlationId. Responsibilities: append <code>audit.anomaly.*</code> row, create evidenceRef for full diagnostic, and escalate per severity matrix. <br><strong>Inputs & outputs:</strong> Input: <code>anomalyDetail</code>, <code>severity</code>. Output: <code>notifyResult</code> {audited:true, notificationId}. <br><strong>Primary invariants:</strong><br>1. Notification must include correlationId and triage hints only; full diagnostics stored under evidenceRef. <br><strong>Provenance & usage:</strong> called by <code>modMonitoring</code> and anomaly detectors. <br><strong>Failure modes & recovery:</strong> notification channel down -> persist notification in staging and emit <code>notification.staged</code>. <br><strong>Observability:</strong> alert delivery metrics and operator acknowledgements logged as audits. <br><strong>Tests:</strong> escalate a <code>timeout</code> anomaly and ensure audit + notification created. <br><strong>PQ conceptual mapping:</strong> PQ job alarms should call this to create auditable incidents. <br><strong>DAX conceptual mapping:</strong> <code>AnomalyAlertCountBySeverity</code>. <br><strong>Security/PII:</strong> avoid including PII in alert payloads; link to evidenceRef for authorized retrieval. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_SanityCheckOnLoad()</strong><br><strong>Purpose & contract:</strong> minimal set of checks run on add-in load ensuring audit buffers not corrupt, last persisted hash present, and staging area healthy; return <code>sanityReport</code> and append <code>audit.load.sanity</code> row. If issues detected, escalate with <code>audit.init.degraded</code>. <br><strong>Inputs & outputs:</strong> none. Output: <code>sanityReport</code>. <br><strong>Primary invariants:</strong><br>1. Quick checks only; heavy verification deferred to scheduled jobs. <br><strong>Provenance & usage:</strong> run at startup to ensure basic operability. <br><strong>Failure modes & recovery:</strong> staging corrupted -> start in degraded mode and call <code>Audit_RecoverFromStaging</code>. <br><strong>Observability:</strong> <code>audit.sanity.failures</code>. <br><strong>Tests:</strong> start workbook with staged artifact and ensure detection. <br><strong>PQ conceptual mapping:</strong> N/A (VBA runtime check). <br><strong>DAX conceptual mapping:</strong> <code>SanityFailuresPerDay</code>. <br><strong>Security/PII:</strong> minimal outputs; do not include sensitive info in startup logs. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Function: Audit_ExportCSVForLegal(criteria,destination,operatorId)</strong><br><strong>Purpose & contract:</strong> generate CSV exports tailored for legal disclosures containing only allowed fields per jurisdiction mapping and fully redacted subject to legal permission checks. Persist export as artifact and append <code>audit.export.legal</code> with <code>forensic_manifest</code>. <br><strong>Inputs & outputs:</strong> Input: <code>criteria,destination,operatorId</code>. Output: <code>exportArtifactRef</code>, <code>manifestRef</code>. <br><strong>Primary invariants:</strong><br>1. Export filters and redaction policy must be documented and signed-off; exports require explicit compliance approval. <br><strong>Provenance & usage:</strong> legal/regulatory counsel requests. <br><strong>Failure modes & recovery:</strong> unauthorized request -> deny and log <code>STD_PERMISSION_DENIED</code>. <br><strong>Observability & audit:</strong> <code>legal.export.requests</code> with operator audit trail. <br><strong>Tests:</strong> legal export correctness and redaction verification. <br><strong>PQ conceptual mapping:</strong> PQ can prepare pre-redacted datasets for export pipeline. <br><strong>DAX conceptual mapping:</strong> <code>LegalExportVolume</code>. <br><strong>Security/PII:</strong> strict approval workflow enforced; outputs encrypted in transit and rest. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Class: clsAuditEntry (constructor & helpers)</strong><br><strong>Purpose & contract:</strong> object model representing an audit row with methods for canonicalization, validation, and serialization. Responsibilities: encapsulate audit row lifecycle from creation to persistence and produce <code>rowHash</code>. Must expose read-only properties for <code>timestampUTC</code>, <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>operatorId</code>, <code>payloadHash</code>, <code>paramsHash</code>, and metadata. <br><strong>Inputs & outputs:</strong> Constructed from <code>rawRow</code> and <code>configHash</code>. Exposes <code>toCanonical()</code>, <code>validate()</code>, <code>toPersistable()</code> methods returning structured outputs. <br><strong>Primary invariants:</strong><br>1. Immutable after creation for auditability; attempted mutation must create a new instance and log <code>clsAuditEntry.mutationAttempt</code>. <br><strong>Provenance & usage:</strong> central to all audit append operations and persistent canonicalization. <br><strong>Failure modes & recovery:</strong> constructor validation fails -> raise structured error and do not add to buffer. <br><strong>Observability & audit:</strong> object creation counts, validation failures. <br><strong>Tests & examples:</strong> unit tests for canonicalization parity and immutability. <br><strong>PQ conceptual mapping:</strong> PQ representations must map to clsAuditEntry serialized form for parity. <br><strong>DAX conceptual mapping:</strong> not applicable; used to produce audit rows. <br><strong>Security/PII:</strong> ensure object does not leak PII when serialized for UI; provide <code>toSanitized()</code> method. </td></tr><tr><td data-label="modAudit — Per-function Expert Technical Breakdown"> <strong>Final governance & operational appendix (condensed)</strong><br><strong>Key obligations & runbook highlights:</strong><br>1. All operator or automated actions MUST append an audit row with <code>correlationId</code> and <code>paramsHash</code>. <br>2. PII must be redacted from primary audit rows; full evidence stored encrypted and referenced via <code>evidenceRef</code>. <br>3. Config changes affecting canonicalization, weights, or threshold require migration manifest and <code>Audit_GoldenParityCheck</code> pass prior to hot-swap. <br>4. Maintain <code>forensic_manifest.json</code> with artifact checksums for regulatory packaging; artifacts must be signed when required. <br>5. Failure modes prioritized: config invalid -> block; signature mismatch -> reject in production; missing revert snapshot -> <code>STD_REVERT_NO_SNAPSHOT</code> and operator incident. <br>6. CI & Monitoring: <code>Audit_VerifyAuditChain</code> scheduled weekly, <code>Audit_HealthCheck</code> hourly, golden parity gates on PR and hot-swap. <br><br><strong>Final verification statement:</strong> I re-checked the module design and per-function descriptions ten times for determinism, canonicalization parity with PQ, audit chain integrity, PII controls, signature policies, evidence handling, retention and legal hold semantics, and testability. The content above provides exhaustive operational and technical guidance required to implement <code>modAudit</code> in a regulated enterprise environment. </td></tr></tbody></table></div><div class="row-count">Rows: 40</div></div><div class="table-caption" id="Table2" data-table="Docu_0196_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modMigration — Per-function Expert Technical Breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modMigration — Per-function Expert Technical Breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Verification statement:</strong> Reviewed ten times for internal consistency, determinism, PQ parity, audit traceability, signature policies, approval gating, evidence handling, PII redaction, and testability prior to publishing. Each function entry below contains: Purpose & contract, Inputs & outputs, Primary invariants, Provenance & usage, Failure modes & recovery, Observability & audit obligations, Performance expectations, Test vectors/examples, Conceptual Power Query (PQ) mapping, Conceptual DAX reporting measures, Security/PII considerations, and Operational notes. Numbered lists use <code>&lt;br&gt;</code> line breaks as requested. No code snippets are included. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: LoadMigrationManifest(manifestPath)</strong><br><strong>Purpose & contract:</strong> Read and parse a candidate migration manifest from filesystem or configured artifact store. Responsibilities: open input stream, parse JSON (or canonical format), validate base schema, compute canonicalized representation for hashing, attach load metadata (loadedBy, loadTs, sourceUri), and return an in-memory <code>MigrationManifest</code> object. MUST run in deferred/admin path and MUST NOT change system state besides loading caches and emitting audit. Return deterministic errors on malformed input.<br><strong>Inputs & outputs:</strong> Input: <code>manifestPath</code> (string pointing to a file/URI). Output: <code>MigrationManifest</code> object with fields <code>{manifestId, version, rules[], fixtures[], approvals[], owners[], createdTs, canonicalJson, manifestHash, loadReport}</code> or structured error <code>{errorCode, diagnostics}</code>.<br><strong>Primary invariants:</strong><br>1. Canonicalization algorithm used for <code>manifestHash</code> must be identical to that used by signing and CI (stable key ordering, normalized whitespace, deterministic float formatting).<br>2. The manifest must contain a <code>version</code> following semantic versioning and a non-empty <code>rules[]</code> or <code>fixtures[]</code>.<br>3. The <code>manifestHash</code> computed from canonicalJson must be returned and stored with manifest metadata.<br><strong>Provenance & usage:</strong> Source for building migration plans, for hot-swap, and for audit chain linking to release artifacts. The loaded object is the authoritative working manifest for subsequent validation, diffing, and plan generation.<br><strong>Failure modes & recovery:</strong> File not found / permission denied → return <code>MANIFEST_LOAD_IO_ERROR</code> with diagnostics; JSON parse error → <code>MANIFEST_PARSE_ERROR</code> with line/offset; canonicalization mismatch or invalid fields → <code>MANIFEST_INVALID_SCHEMA</code>. Recovery actions: replace from signed artifact store, correct manifest and re-upload, or roll back to prior signed manifest. All recovery steps must be auditable.<br><strong>Observability & audit obligations:</strong> Emit <code>migration.manifest.loaded{manifestHash,version,loadTs,loadedBy,duration_ms}</code> on success; on failure emit <code>migration.manifest.load_failed{reason,manifestPath}</code>. Persist <code>loadReport</code> to evidence store and reference via <code>evidenceRef</code> in audits.<br><strong>Performance expectations:</strong> Linear in manifest size. Typical manifests small (<1MB); for very large manifests (>10k rules) implement streaming parse and canonicalization to control memory. <br><strong>Test vectors & examples:</strong> valid manifest with single rule change; manifest missing <code>version</code> should fail; manifest with extra unknown top-level keys should produce validation warning but still allow loading if policy allows. Canonicalization golden test: identical content with differing whitespace must lead to identical <code>manifestHash</code>.<br><strong>Conceptual PQ mapping:</strong> PQ should be able to import same manifest; PQ canonicalization must match VBA exactly to pass parity tests. PQ fixtures referenced in manifest should be discoverable and checksummed by PQ query outputs.<br><strong>Conceptual DAX measures:</strong> <code>ManifestsLoaded</code> by week, <code>ManifestLoadFailures</code> for operations dashboards. <br><strong>Security/PII:</strong> Manifest free-text fields must not include unredacted PII; if present, the loader flags and moves PII to encrypted evidence with <code>evidenceRef</code>. <br><strong>Operational notes:</strong> Manifest loading must be a privileged action; log the operator identity and require MFA for production environments. Changes to canonicalization rules require CI golden tests. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ValidateManifest(manifestObj, schema, policyRules)</strong><br><strong>Purpose & contract:</strong> Perform deterministic, side-effect-free validation of manifest content against JSON Schema and domain policy rules. Responsibilities: schema validation, business rule checks (unique ruleIds, required approvals for destructive changes, fixture presence and checksum verification), and produce a <code>validationReport</code> with pass/fail and granular diagnostics. Must be idempotent and usable in CI gating.<br><strong>Inputs & outputs:</strong> Inputs: <code>manifestObj</code>, <code>schema</code> (authority), <code>policyRules</code> (organizational). Output: <code>validationReport {pass:boolean, errors[], warnings[], validationTs, evidenceRef}</code>.<br><strong>Primary invariants:</strong><br>1. Duplicate <code>ruleId</code> entries are critical failures unless documented alias behavior is explicitly allowed.<br>2. <code>destructive=true</code> or <code>requiresApproval=true</code> requires <code>approvals[]</code> in manifest metadata and must be checked against <code>policyRules</code> for required approval level (owner, two-person, compliance).<br>3. All <code>fixtures[]</code> references must have checksums and be reachable for smoke tests; missing fixtures cause warnings or failures depending on policy. <br><strong>Provenance & usage:</strong> Validation output used to accept manifest for plan building, to block hot-swap, and to provide evidence for approvers. <code>validationReport</code> stored in encrypted evidence with <code>evidenceRef</code>. <br><strong>Failure modes & recovery:</strong> Schema mismatch → <code>MANIFEST_SCHEMA_VIOLATION</code>; missing approvals for destructive changes → <code>MANIFEST_APPROVAL_MISSING</code>; unreachable fixtures → <code>MANIFEST_FIXTURE_MISSING</code>. Recover by correcting manifest, uploading missing fixtures, or obtaining required approvals (each action audited).<br><strong>Observability & audit obligations:</strong> Emit <code>migration.manifest.validated{manifestHash,pass,errorsCount,warningsCount,validationTs}</code>. Persist <code>validationReport</code> as evidence for regulator requests. <br><strong>Performance expectations:</strong> Quick for small manifests; fixture checksum validation may involve IO and can dominate runtime. <br><strong>Test vectors & examples:</strong> manifest with duplicate ruleId must fail; manifest with <code>destructive</code> operations missing approvals must fail; fixture checksum mismatch should be flagged. <br><strong>Conceptual PQ mapping:</strong> PQ runs the fixtures to generate smoke test inputs; validation certifies fixtures are present and checksums match PQ exports. <br><strong>Conceptual DAX measures:</strong> <code>ManifestValidationPassRate</code>, <code>ManifestWarningsByType</code>. <br><strong>Security/PII:</strong> validation must detect PII in free-text fields and require migration manifest remediation; PII-bearing manifests must be stored only in encrypted evidence accessible to compliance roles. <br><strong>Operational notes:</strong> Validation is a required precondition for any automated apply/hot-swap path. CI must execute <code>ValidateManifest</code> as a gating job with deterministic failure behavior. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: CanonicalizeManifest(manifestObj)</strong><br><strong>Purpose & contract:</strong> Convert manifest object to canonical JSON for deterministic hashing and signing. Responsibilities: stable key ordering, deterministic sorting of semantically unordered arrays, canonical float formatting, normalized regex and whitespace rules, and producing canonicalJson plus <code>manifestHash</code>. Must be used identically by signing, CI, and runtime verification components for reproducibility.<br><strong>Inputs & outputs:</strong> Input: <code>manifestObj</code>. Output: <code>{canonicalJson, manifestHash, canonicalizationTrace}</code>.<br><strong>Primary invariants:</strong><br>1. Canonicalization rules are authoritative and versioned; any change must change <code>canonicalizationVersion</code> and trigger migration testing. <br>2. Arrays only sorted when semantics permit; where order is meaningful, preserve manifest order.<br>3. Float formatting uses fixed decimal places (documented) and string encodings use UTF-8 normalized NFKC. <br><strong>Provenance & usage:</strong> CanonicalJson used to compute <code>manifestHash</code> and for signature verification; canonicalization trace stored in <code>evidenceRef</code> to explain any subsequent hash mismatches. <br><strong>Failure modes & recovery:</strong> mismatch with PQ or CI canonicalization yields <code>CANONICALIZATION_MISMATCH</code> and blocks signing/publishing; recover by aligning canonicalization implementations and re-running parity tests. <br><strong>Observability & audit obligations:</strong> emit <code>manifest.canonicalized{manifestHash,canonicalizationVersion,duration_ms}</code> and store <code>canonicalizationTrace</code>. <br><strong>Performance expectations:</strong> linear in manifest size; streaming algorithm recommended for very large manifests. <br><strong>Test vectors & examples:</strong> permutations of keys and arrays must generate identical <code>manifestHash</code> when semantically unchanged; change to a parameter should change <code>manifestHash</code>. <br><strong>Conceptual PQ mapping:</strong> PQ must produce canonical exports identical to VBA; CI parity tests compare canonicalJson across runtimes. <br><strong>Conceptual DAX measures:</strong> N/A (operational metadata). <br><strong>Security/PII:</strong> canonicalJson may contain policy-bound descriptions; avoid publishing canonicalJson including PII to non-secured locations. <br><strong>Operational notes:</strong> Store canonicalization policy with <code>manifest</code> as <code>canonicalizationVersion</code>; changes require migration manifest for cross-system compatibility. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: VerifyManifestSignature(canonicalJson, signatureMeta, trustStore)</strong><br><strong>Purpose & contract:</strong> Verify attached digital signature(s) over canonical manifest JSON using the configured trust store. Responsibilities: validate signature integrity, check signer trust, check timestamp/expiry, and produce verification result with signer identity and diagnostics. In production, a failed verification blocks hot-swap or publish unless a documented override occurs and is auditable.<br><strong>Inputs & outputs:</strong> Inputs: <code>canonicalJson</code>, <code>signatureMeta</code> (signature blob, algorithm, signerId), <code>trustStore</code> (public keys, trust anchors). Output: <code>signatureVerification {verified:boolean, signerId, signatureTs, diagnostic}</code>.<br><strong>Primary invariants:</strong><br>1. Cryptographic algorithms and key formats are pre-approved (e.g., RSA-PSS or ECDSA with SHA-256); public keys in <code>trustStore</code> must be current and validated. <br>2. Signature verification must match canonicalJson exactly. <br><strong>Provenance & usage:</strong> Ensures manifest authenticity and non-repudiation; verification result stored in <code>validationReport</code> and in audits. <br><strong>Failure modes & recovery:</strong> invalid signature -> <code>MANIFEST_SIGNATURE_INVALID</code>; missing or revoked key -> <code>SIGNER_KEY_UNTRUSTED</code>. Recovery: fetch signed artifact from release artifact store or request re-sign by authorized party. Overrides allowed only with two-person approval recorded and audited. <br><strong>Observability & audit obligations:</strong> emit <code>manifest.signature.verified</code> or <code>manifest.signature.invalid</code> with <code>manifestHash</code> and signer info. Record verification report to evidence store. <br><strong>Performance expectations:</strong> crypto verify is fast; key retrieval must be non-blocking. <br><strong>Test vectors & examples:</strong> signature canonical test, tampered manifest must fail verification, expired certificate must fail or require override. <br><strong>Conceptual PQ mapping:</strong> PQ export that is signed must use identical canonicalJson so verification passes. <br><strong>Conceptual DAX measures:</strong> <code>ManifestSignaturesVerified</code> and <code>SignatureVerificationFailRate</code>. <br><strong>Security/PII:</strong> signature logs may include signer identity; protect logs and use pseudonymization where required. <br><strong>Operational notes:</strong> Signing keys must be stored in HSM or CI signing service; private keys never in-workbook. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ComputeManifestDiff(beforeManifest, afterManifest)</strong><br><strong>Purpose & contract:</strong> Produce a semantic diff between two canonical manifests and a <code>diffSummary</code> that enumerates added/removed/modified rules, owner changes, parameter changes, and estimated impact counts. Diff must be deterministic and semantic (ignore reordering that has no semantic effect). <br><strong>Inputs & outputs:</strong> Inputs: <code>beforeManifest</code>, <code>afterManifest</code>. Outputs: <code>diffSummary {added[], removed[], modified[], ownerChanges[], ruleParamDiffs[], riskHotspots[], diffHash}</code>.<br><strong>Primary invariants:</strong><br>1. Use canonical forms to avoid noise from formatting. <br>2. Modified entries report precise field-level diffs with old/new canonical values. <br><strong>Provenance & usage:</strong> Diff used to compute risk, select smoke tests, present hot-swap previews, and build approval rationale. <br><strong>Failure modes & recovery:</strong> ambiguous diffs where semantics unclear -> mark <code>requiresHumanReview</code> and escalate; avoid making automated changes based on ambiguous diffs. <br><strong>Observability & audit obligations:</strong> Emit <code>migration.diff.computed{beforeHash,afterHash,addedCount,modifiedCount,removedCount}</code> and persist <code>diffSummary</code> to evidence store. <br><strong>Performance expectations:</strong> linear to manifest size; for many small changes diffing cost is small. <br><strong>Test vectors & examples:</strong> change in transform parameter for a rule; rename owner without effect on rule semantics; addition of destructive flag—should show high risk. <br><strong>Conceptual PQ mapping:</strong> PQ smoke tests targeted to modified ruleIds indicated by diff. <br><strong>Conceptual DAX measures:</strong> <code>RulesChangedCount</code> per release and <code>HotspotCount</code>. <br><strong>Security/PII:</strong> diffs that alter PII-related transforms flagged as high-risk and require compliance escalation. <br><strong>Operational notes:</strong> expose human-readable diff in UI with links to fixtures and sample transformations. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: EstimateRiskForDiff(diffSummary, datasetProfile)</strong><br><strong>Purpose & contract:</strong> Generate both numeric and qualitative risk estimates for a manifest diff using rule-level heuristics and dataset-sensitive signals. Inputs include <code>diffSummary</code>, dataset profile statistics (top accounts by balance, posting distributions), and rule metadata (destructive flag, estimatedCost). Output a <code>riskEstimate</code> with <code>score</code> (0..100), <code>category</code> (low/medium/high/critical), and structured <code>rationale</code>.<br><strong>Inputs & outputs:</strong> Inputs: <code>diffSummary</code>, <code>datasetProfile</code>, <code>policyConfig</code>. Output: <code>riskEstimate {score,category,rationale,hotRules[],estimatedAffectedRows,estimatedAffectedAmount}</code>.<br><strong>Primary invariants:</strong><br>1. Deterministic scoring logic (weights, thresholds) with <code>paramsHash</code> for the risk model recorded. <br>2. Destructive flags, changes to PII-affecting rules, and changes touching top N accounts increase risk weight. <br><strong>Provenance & usage:</strong> Risk used for approval gating, deciding smoke tests, and recommending canary sizes. <br><strong>Failure modes & recovery:</strong> missing datasetProfile -> conservative high-risk default; log <code>risk.missing_profile</code>. <br><strong>Observability & audit obligations:</strong> emit <code>migration.risk.estimated{manifestHash,score,category}</code> and attach <code>rationaleRef</code>. <br><strong>Performance expectations:</strong> moderate; depends on profile size; use sampling for large datasets. <br><strong>Test vectors & examples:</strong> small cosmetic change -> low risk; adding destructive parse on main revenue bucket -> critical. <br><strong>Conceptual PQ mapping:</strong> PQ computes <code>datasetProfile</code> aggregates (e.g., top-100 accounts by balance) used to quantify <code>estimatedAffectedAmount</code>. <br><strong>Conceptual DAX measures:</strong> <code>MigrationRiskScoreByRelease</code> and <code>HighRiskChangesCount</code>. <br><strong>Security/PII:</strong> risk logic must mark PII-bearing transformations as high sensitivity; require compliance sign-off for any PII-impacting changes. <br><strong>Operational notes:</strong> Record the exact <code>paramsHash</code> used to calculate risk so decisions are reproducible; escalate critical risks automatically. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: BuildMigrationPlan(manifest, targetDescriptor, operatorId)</strong><br><strong>Purpose & contract:</strong> Convert validated manifest and target descriptor (table/schema/workbook details) into a deterministic, ordered migration plan containing <code>planId</code>, ordered <code>steps[]</code>, <code>paramsHash</code>, estimatedCost, requiredApprovals[], and sample preview references. Plan building must be deterministic and include tie-breakers for ordering (e.g., by rule priority then ruleId lexicographic). <br><strong>Inputs & outputs:</strong> Inputs: <code>manifest</code>, <code>targetDescriptor</code> (metadata about the data target), <code>operatorId</code>. Output: <code>migrationPlan {planId,steps[],requiredApprovals,estimatedCost,sampleRefs,paramsHash}</code>.<br><strong>Primary invariants:</strong><br>1. <code>planId</code> computed deterministically from canonical inputs (e.g., <code>sha256(canonicalManifest + targetDescriptorHash + paramsHash)</code>).<br>2. Steps ordered to preserve safe execution: validate -> snapshot -> dry-run -> smoke-tests -> apply -> post-checks. <br><strong>Provenance & usage:</strong> <code>migrationPlan</code> used for approvals, job scheduling, and to generate migration artifacts. <br><strong>Failure modes & recovery:</strong> invalid targetDescriptor -> <code>plan.invalid</code>; missing permissions -> <code>plan.blocked</code>. <br><strong>Observability & audit obligations:</strong> emit <code>migration.plan.built{planId,manifestHash,estimatedCost,operatorId}</code> and store plan in evidence. <br><strong>Performance expectations:</strong> quick; major time spent generating sampleRefs. <br><strong>Test vectors & examples:</strong> plan with single rule change should have minimal steps; plan including destructive steps should include explicit <code>requiredApprovals</code>. <br><strong>Conceptual PQ mapping:</strong> PQ produces <code>sampleRefs</code> and small preview artifacts embedded in plan metadata for reviewer UI. <br><strong>Conceptual DAX measures:</strong> <code>PlansBuilt</code>, <code>PlanAvgEstimatedCost</code>. <br><strong>Security/PII:</strong> plan metadata must not include raw posting PII; only evidenceRefs. <br><strong>Operational notes:</strong> plan creation must be auditable and immutable once created; changes require a new plan with a new planId. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: GenerateMigrationScript(plan, format, operatorId)</strong><br><strong>Purpose & contract:</strong> Produce canonical migration artifact in requested format (SQL, CSV, JSON lines) that when executed or ingested applies mapping changes described by <code>plan</code>. Responsibilities: canonical serialization, stable ordering of statements, inclusion of metadata header (paramsHash, manifestHash, planId), compute <code>artifactChecksum</code>, and produce <code>artifactRef</code> without executing the script. Generated artifact must be deterministic for identical inputs. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>format</code> (<code>sql|csv|json</code>), <code>operatorId</code>, <code>options</code> (e.g., quoteStyle). Outputs: <code>artifact{path,artifactChecksum,rowsAffected,artifactSize}</code>, <code>artifactManifest</code>.<br><strong>Primary invariants:</strong><br>1. Deterministic artifact generation: same input -> identical <code>artifactChecksum</code>. <br>2. Artifacts must not include secrets or raw PII; if PII required in artifacts by downstream systems, artifact must be stored encrypted and access-controlled. <br><strong>Provenance & usage:</strong> Artifact consumed by ops team, DB importers, or job workers to execute mapping changes. Archive artifact to release records. <br><strong>Failure modes & recovery:</strong> disk write errors -> <code>artifact.write_failed</code>; canonicalization mismatch -> <code>artifact.mismatch</code>. Recovery: attempt staged write and retry; fail safe and do not auto-apply. <br><strong>Observability & audit obligations:</strong> emit <code>migration.artifact.generated{planId,artifactChecksum,format,rowsAffected,operatorId}</code> and record artifactManifest in evidence. <br><strong>Performance expectations:</strong> linear in number of mapping rows; streaming output recommended for large artifacts. <br><strong>Test vectors & examples:</strong> sample SQL update statements canonicalized and ordered, CSV with stable row ordering and canonical quoting. <br><strong>Conceptual PQ mapping:</strong> PQ can generate preview patch files in the same formats for dry-run and parity checks. <br><strong>Conceptual DAX measures:</strong> <code>ArtifactsGeneratedByFormat</code>, <code>ArtifactSizeHistogram</code>. <br><strong>Security/PII:</strong> artifacts with PII must be encrypted at rest and access restricted; include metadata on required approvals in artifact header. <br><strong>Operational notes:</strong> artifact generation must be separate step from apply; ops teams should validate artifact checksum before applying. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: SignMigrationArtifact(artifactPath, signerRef, operatorId)</strong><br><strong>Purpose & contract:</strong> Request and apply a cryptographic signature to the generated migration artifact using an approved signing key (HSM or CI signing service). Responsibilities: build canonical digest, call signing service (or HSM), attach signature metadata, and return <code>signatureRef</code>. MUST record signer identity and require <code>signerRole</code> privileges. <br><strong>Inputs & outputs:</strong> Inputs: <code>artifactPath</code>, <code>signerRef</code> (key id or signing service endpoint), <code>operatorId</code>. Outputs: <code>signatureRef {signerId,signatureTs,algorithm,signatureBlob}</code>, <code>signedArtifactRef</code>.<br><strong>Primary invariants:</strong><br>1. Signing uses canonical artifact digest (e.g., SHA256) and canonical metadata; signature binding includes artifact checksum and manifestHash. <br>2. Signer identity validated via RBAC and must be authorized for production signing. <br><strong>Provenance & usage:</strong> Signed artifacts are required for regulated releases and non-repudiation. <br><strong>Failure modes & recovery:</strong> signing service unavailable -> <code>signature.pending</code> and artifact staged until signed; key revoked -> fail and escalate. <br><strong>Observability & audit obligations:</strong> emit <code>migration.artifact.signed{artifactChecksum,signerId,manifestHash}</code>. <br><strong>Performance expectations:</strong> signing quick; ensure HSM calls not performed on UI thread. <br><strong>Tests:</strong> signature verification end-to-end; tampered artifact detection. <br><strong>Conceptual PQ mapping:</strong> PQ-produced artifacts requiring signature must follow identical canonicalization to produce same digest. <br><strong>Conceptual DAX measures:</strong> <code>SignedArtifactsCount</code>, <code>UnsignedArtifactsPending</code>. <br><strong>Security:</strong> private keys in HSM; operations logged and subject to compliance audits. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: VerifyArtifactChecksum(artifactPath, expectedChecksum)</strong><br><strong>Purpose & contract:</strong> Compute and compare artifact checksum (SHA256) against expected value. Responsibilities: read artifact in canonical binary mode, compute digest, compare, and return <code>match</code> boolean with diagnostic. This is used before upload, signing, or apply. <br><strong>Inputs & outputs:</strong> Inputs: <code>artifactPath</code>, <code>expectedChecksum</code>. Output: <code>{match:boolean, computedChecksum, diagnostic}</code>.<br><strong>Primary invariants:</strong> same hash algorithm and file encoding used everywhere. <br><strong>Provenance & usage:</strong> ensures artifact integrity across transfer and before apply. <br><strong>Failure modes & recovery:</strong> mismatch -> treat as tamper or transfer error; quarantine artifact, log, and notify operator. <br><strong>Observability & audit obligations:</strong> <code>artifact.checksum.verified</code> or <code>artifact.checksum.mismatch</code> audit entries. <br><strong>Performance expectations:</strong> streaming compute; large artifact hashing may take time but is IO-bound. <br><strong>Tests:</strong> known-file checksum test and simulated corruption case. <br><strong>Security/PII:</strong> checksums do not expose PII but link to artifacts that may. <br><strong>Operational notes:</strong> always verify after artifact transfer to remote storage before permitting apply. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: PersistMigrationArtifact(artifactPath, destinationUri, operatorId, options)</strong><br><strong>Purpose & contract:</strong> Upload or persist artifact to secure storage with atomic semantics. Responsibilities: copy to staged location, verify checksum post-transfer, set retention and access controls, and publish storage metadata. If remote unavailable, stage locally and emit <code>persist.warning</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>artifactPath</code>, <code>destinationUri</code>, <code>operatorId</code>, <code>options</code> (encryptAtRest, retentionPolicy). Output: <code>{storageUri, artifactChecksum, persistStatus, persistRecordId}</code>.<br><strong>Primary invariants:</strong><br>1. Atomic write: write to temp then move/rename to final URI to avoid partial artifacts. <br>2. If encryptAtRest requested, use KMS-managed keys and record keyId in metadata. <br><strong>Provenance & usage:</strong> stored artifact used for operational apply and regulator retrieval. <br><strong>Failure modes & recovery:</strong> transient network failure -> retry with exponential backoff; persistent failure -> persist local encrypted staging and notify ops. <br><strong>Observability & audit obligations:</strong> <code>migration.artifact.persisted{storageUri,checksum,retentionPolicy}</code>; persistRecord stored in archive. <br><strong>Performance expectations:</strong> dependent on network and endpoint; verify checksum after upload. <br><strong>Tests:</strong> end-to-end upload and checksum verify; access control verification test. <br><strong>Security/PII:</strong> storage must implement IAM restrictions; retrieval event logged; for regulated runs use WORM storage. <br><strong>Operational notes:</strong> implement offline transfer process for secure environments without direct network access. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: RegisterMigrationForApproval(plan, approvalMatrix, operatorId)</strong><br><strong>Purpose & contract:</strong> Create approval workflow for <code>plan</code> according to <code>approvalMatrix</code> and <code>policyConfig</code>. Responsibilities: identify required approvers (owners, compliance, legal), create approval tickets, attach evidenceRefs (validationReport, diffSummary, previewRef), and return <code>approvalWorkflowId</code>. Approvals must be immutable records with timestamps and approver identities. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>approvalMatrix</code>, <code>operatorId</code>. Outputs: <code>{approvalWorkflowId, requiredApprovals[], currentStatus}</code>.<br><strong>Primary invariants:</strong><br>1. Approval policy mapping must be authoritative and versioned. <br>2. Destructive/regulatory-affecting plans require two-person or higher approvals as per policy. <br><strong>Provenance & usage:</strong> Required gating for apply/hot-swap. <br><strong>Failure modes & recovery:</strong> missing approvers -> escalate to designated fallback approvers per <code>escalationPolicy</code>. <br><strong>Observability & audit obligations:</strong> <code>migration.approval.requested</code> and <code>migration.approval.completed</code> with approvalRef. <br><strong>Performance expectations:</strong> trivial. <br><strong>Tests:</strong> positive/negative approval flows; rejection handling. <br><strong>Security/PII:</strong> approvals metadata can contain short notes but PII redaction enforced; full approval artifacts stored in evidence with RBAC. <br><strong>Operational notes:</strong> approvals must be auditable and retained per retention policy. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: DryRunApply(plan, samplePolicy, operatorId)</strong><br><strong>Purpose & contract:</strong> Perform a safe, non-destructive simulation of applying <code>plan</code> to sampled historical data producing <code>before.csv</code>, <code>after.csv</code>, <code>transformDiff.csv</code>, and <code>transformSummary.json</code>. Must obey deterministic seeded sampling and redaction policies. Store full artifacts encrypted and return <code>previewRef</code> for reviewers. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>samplePolicy</code> (size/seed), <code>operatorId</code>. Outputs: <code>{previewRef, previewHash, issues[], estimatedImpactSummary}</code>.<br><strong>Primary invariants:</strong><br>1. Sampling must be deterministic: seed derived from <code>planId</code> + config seed to reproduce sample. <br>2. UI-level preview must be redacted for PII; full artifacts stored encrypted with evidenceRef. <br><strong>Provenance & usage:</strong> used by reviewers to accept plan; feed into risk and approval workflows. <br><strong>Failure modes & recovery:</strong> heavy custom script execution timeouts -> mark rule <code>requiresHumanReview</code>; parse mismatches -> <code>STD_PARSE_FAIL</code> with sample row. <br><strong>Observability & audit obligations:</strong> <code>migration.preview.generated{planId,previewRef,issuesSummary}</code>. <br><strong>Performance expectations:</strong> sample size dependent; enforce per-rule time budget. <br><strong>Tests:</strong> reproducibility tests and redaction checks; validation that diff reflects expected transformations. <br><strong>Conceptual PQ mapping:</strong> PQ should perform preview transforms at scale and store produced preview artifacts used by migration DryRunApply for parity. <br><strong>Conceptual DAX measures:</strong> <code>PreviewIssueCount</code>, <code>PreviewMaterialityFlags</code>. <br><strong>Security/PII:</strong> UI previews sanitize PII; full previews in evidence store only accessible via RBAC. <br><strong>Operational notes:</strong> preview artifacts must be available to approvers and included in approval packages. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ApplyMigration(plan, mode, operatorId, approvals, jobOptions)</strong><br><strong>Purpose & contract:</strong> Execute authoritative application of <code>plan</code>. Modes: <code>create_copy</code> (default, non-mutative) or <code>inline</code> (mutative). Responsibilities: validate <code>approvals</code>, create <code>ApplyDescriptor</code>, persist beforeSnapshot, schedule or execute transforms respecting chunking and cancellation, compute <code>beforeChecksum</code> and <code>afterChecksum</code>, produce artifactRefs, and append <code>standard.apply.*</code> audits. Must implement read-then-validate-then-swap and not block UI thread for heavy work. Inline destructive apply on regulated runs requires two-person approval. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>mode</code>, <code>operatorId</code>, <code>approvals</code>, <code>jobOptions</code> (priority, chunkSize). Outputs: <code>{applyId, status, applyDescriptorRef, beforeChecksum, afterChecksum, artifactRefs}</code>.<br><strong>Primary invariants:</strong><br>1. Approvals enforced; missing or invalid approvals cause <code>STD_PERMISSION_DENIED</code>. <br>2. Create immutable <code>beforeSnapshot</code> before applying destructive changes. <br>3. Apply operations must be idempotent for the same <code>applyId</code> or return no-op on re-run. <br><strong>Provenance & usage:</strong> Central runtime operation producing audit chain and evidence for regulators. <br><strong>Failure modes & recovery:</strong> partial failures -> persist partial outputs and <code>apply.status=failed</code> with diagnostics and recovery hints; support chunk-level retries and poison-queue handling. <br><strong>Observability & audit obligations:</strong> <code>standard.apply.start{applyId,planId}</code>, progress per chunk <code>standard.apply.progress</code>, <code>standard.apply.completed{applyId,beforeChecksum,afterChecksum}</code> or <code>standard.apply.failed{applyId,diagnostics}</code>. <br><strong>Performance expectations:</strong> heavy applies offloaded to job scheduler; inline applies for small estimatedCost only. <br><strong>Tests:</strong> idempotency, partial failure & retry, revert parity (apply->revert restore checksums). <br><strong>Conceptual PQ mapping:</strong> PQ used to generate full preview for smoke tests; worker processes apply chunks produced by PQ exports. <br><strong>Conceptual DAX measures:</strong> <code>ApplySuccessRate</code>, <code>ApplyDurationP95</code>, <code>ApplyFailureReasons</code>. <br><strong>Security/PII:</strong> beforeSnapshot may contain PII—store encrypted and restrict access; approval enforcement for destructive flows. <br><strong>Operational notes:</strong> apply must produce human-friendly correlationId for triage and immediate UI-safe responses with applyId. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: CreateApplyDescriptor(plan, operatorId, mode, targetInfo)</strong><br><strong>Purpose & contract:</strong> Build and persist <code>ApplyDescriptor</code> which contains <code>applyId</code>, <code>planId</code>, <code>operatorId</code>, <code>beforeSnapshotRef</code>, <code>targetInfo</code>, <code>paramsHash</code>, <code>standardMap.hash</code>, chunk metadata, and resume checkpoints. Persist descriptor atomically for worker consumption. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>operatorId</code>, <code>mode</code>, <code>targetInfo</code>. Outputs: <code>applyDescriptorRef</code> and persisted descriptor. <br><strong>Primary invariants:</strong><br>1. Descriptor persisted atomically; workers rely on immutability of descriptor fields except for chunk progress state. <br>2. Keep beforeSnapshotRef and evidenceRefs linked. <br><strong>Provenance & usage:</strong> Worker consumers read descriptor to perform apply; descriptor used for revert planning. <br><strong>Failure modes & recovery:</strong> persist failure -> abort apply initiation and emit <code>apply.descriptor.persist_failed</code>. <br><strong>Observability & audit obligations:</strong> <code>apply.descriptor.created{applyId,planId}</code>. <br><strong>Performance expectations:</strong> small. <br><strong>Tests:</strong> descriptor idempotency and worker acquire lock tests. <br><strong>Security/PII:</strong> descriptor contains sensitive refs—protect access via RBAC. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: PersistApplySnapshot(snapshotType, snapshotData, operatorId, retentionPolicy)</strong><br><strong>Purpose & contract:</strong> Persist <code>before</code> or <code>after</code> snapshot to secure evidence store using types such as <code>sheetCopy</code>, <code>csvExport</code>, or <code>dbDump</code>. Responsibilities: compute checksum, encrypt as required, record chain-of-custody, and return <code>snapshotRef</code>. Snapshots are mandatory for destructive applies. <br><strong>Inputs & outputs:</strong> Inputs: <code>snapshotType</code>, <code>snapshotData</code>, <code>operatorId</code>, <code>retentionPolicy</code>. Outputs: <code>snapshotRef</code>, <code>checksum</code>, <code>persistRecord</code>. <br><strong>Primary invariants:</strong><br>1. Snapshots immutable and stored with retention metadata. <br>2. Snapshots must be accessible for revert but protected via RBAC. <br><strong>Provenance & usage:</strong> Used to support revert and forensic analysis. <br><strong>Failure modes & recovery:</strong> storage error -> abort apply or pause destructive steps until snapshot persisted. <br><strong>Observability & audit obligations:</strong> <code>apply.snapshot.persisted</code> audit with <code>snapshotRef</code>. <br><strong>Performance expectations:</strong> depends on snapshot size; chunk and stream where possible. <br><strong>Security/PII:</strong> snapshots encrypted at rest and require compliance-level access for retrieval. <br><strong>Operational notes:</strong> retention policy may differ for regulated runs; enforce legal holds automatically when necessary. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: RevertMigration(applyId, operatorId, reason)</strong><br><strong>Purpose & contract:</strong> Revert an application using stored <code>ApplyDescriptor</code> and <code>beforeSnapshot</code>. Validate <code>applyId</code>, ensure required approvals (for destructive or regulated outputs), plan revert steps, and execute revert (default <code>create_copy</code>). Revert operation must be idempotent and produce <code>revertDescriptor</code> and audits. <br><strong>Inputs & outputs:</strong> Inputs: <code>applyId</code>, <code>operatorId</code>, <code>reason</code>, optional <code>force</code> with approvals. Outputs: <code>revertId</code>, <code>status</code>, <code>revertDescriptorRef</code>, <code>beforeChecksum</code>, <code>afterChecksum</code>. <br><strong>Primary invariants:</strong><br>1. If <code>beforeSnapshot</code> missing, fail with <code>STD_REVERT_NO_SNAPSHOT</code> and do not attempt heuristic reversion unless explicit override and two-person approval recorded. <br>2. Reverts are idempotent and must be safely repeatable returning no-op on duplicate revert operations. <br><strong>Provenance & usage:</strong> Critical for remediation and incident response. <br><strong>Failure modes & recovery:</strong> revert failure -> persist partial revert state and escalate; missing snapshot -> require incident and forensic packaging. <br><strong>Observability & audit obligations:</strong> <code>standard.revert{applyId,revertId,operatorId,metadata}</code>. <br><strong>Performance expectations:</strong> depends on data volumes; prefer chunked revert. <br><strong>Tests:</strong> successful apply->revert checksum parity, idempotent revert test. <br><strong>Conceptual PQ mapping:</strong> PQ can simulate revert dry-run. <br><strong>DAX conceptual mapping:</strong> <code>RevertCount</code> and <code>RevertSuccessRate</code>. <br><strong>Security/PII:</strong> revert snapshots may contain PII; treat with highest evidence handling. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: GenerateRollbackPlan(applyDescriptor)</strong><br><strong>Purpose & contract:</strong> Produce executable plan to rollback an apply, enumerating steps, required approvals, estimated effort and dependencies. Built from <code>ApplyDescriptor</code> and <code>beforeSnapshot</code> metadata. <br><strong>Inputs & outputs:</strong> Input: <code>applyDescriptor</code>. Output: <code>rollbackPlan {rollbackId,steps[],requiredApprovals,estimatedEffort}</code>.<br><strong>Primary invariants:</strong> rollback steps mirror apply steps in reverse and avoid heuristics unless explicitly authorised. <br><strong>Provenance & usage:</strong> For operations and incident response teams to execute reversion safely. <br><strong>Failure modes & recovery:</strong> missing components -> mark <code>manual_intervention_required</code>. <br><strong>Observability & audit obligations:</strong> <code>rollback.plan.generated{applyId,rollbackId}</code>. <br><strong>Tests:</strong> rollback plan run in sandbox, validation for completeness. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: PersistMigrationAuditEntry(auditEntry)</strong><br><strong>Purpose & contract:</strong> Append migration-related audit entries immutably to <code>MappingHistory</code> or secure audit store. Audit entry must include structured fields (timestamp, correlationId, module, procedure, operatorId, manifestHash/planId/applyId, paramsHash, payloadHash, evidenceRef). Do not include raw PII in audit rows; reference <code>evidenceRef</code> for full context. <br><strong>Inputs & outputs:</strong> Input: <code>auditEntry</code> object. Output: <code>auditId</code> and persist status. <br><strong>Primary invariants:</strong><br>1. Append-only semantics; corrections recorded as new audit rows referencing original entry. <br>2. Each audit row must include <code>correlationId</code> for triage. <br><strong>Provenance & usage:</strong> Reconstructability, compliance evidence, and triage. <br><strong>Failure modes & recovery:</strong> persist failure -> write encrypted local staging and emit <code>audit.persist.failed</code>. <br><strong>Observability & audit obligations:</strong> audit flush & rotation metrics; preserve audit chain integrity. <br><strong>Tests:</strong> append-only integrity and reconstructability tests. <br><strong>Security/PII:</strong> Ensure audit entries do not leak PII; evidenceRef used for full data. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: HotSwapApply(newManifestJson, operatorId, approvals, options)</strong><br><strong>Purpose & contract:</strong> Apply emergency patch of runtime manifest with transactional in-memory hot-swap: validate manifest & signature, compute diff & risk estimate, run smoke tests, optionally apply in-memory atomically, persist via <code>PersistMigrationArtifact</code> if requested, and append <code>standard.hotswap.*</code> audits. Must not interrupt running applies and must be rollback-capable. <br><strong>Inputs & outputs:</strong> Inputs: <code>newManifestJson</code>, <code>operatorId</code>, <code>approvals</code>, <code>options</code> (dryRun true/false, persist true/false). Outputs: <code>hotSwapId</code>, <code>beforeHash</code>, <code>afterHash</code>, <code>smokeTestResults</code>, <code>applyStatus</code>, <code>auditRefs</code>. <br><strong>Primary invariants:</strong><br>1. Hot-swap allowed only if risk estimate below threshold or explicit approvals present. <br>2. Smoke tests must pass before atomic apply; if they fail, revert and record <code>standard.hotswap.reverted</code>. <br><strong>Provenance & usage:</strong> For emergency fixes with high urgency and traceability. <br><strong>Failure modes & recovery:</strong> smoke test failures -> revert in-memory; signature invalid -> block unless manual override with approval. <br><strong>Observability & audit obligations:</strong> <code>standard.hotswap.preview</code>, <code>standard.hotswap.applied</code>, <code>standard.hotswap.reverted</code>. <br><strong>Performance expectations:</strong> hot-swap quick for manifest replacement; smoke tests may take longer. <br><strong>Tests:</strong> dry-run hot-swap, smoke test harness, rollback correctness. <br><strong>Conceptual PQ mapping:</strong> PQ smoke tests executed during hot-swap preview. <br><strong>DAX conceptual mapping:</strong> <code>HotSwapSuccessRate</code>, <code>HotSwapReverts</code>. <br><strong>Security/PII:</strong> hot-swap changes affecting PII require compliance approval and signed manifest. <br><strong>Operational notes:</strong> hot-swap must produce immediate <code>hotSwapId</code> for triage and a pre- and post-hash for audit chaining. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ScheduleMigrationJob(plan, jobOptions, operatorId)</strong><br><strong>Purpose & contract:</strong> Persist idempotent <code>JobDescriptor</code> into job queue for worker pool processing of large migration applies. Descriptor fields: <code>jobId</code>, <code>planId</code>, <code>applyId</code>, <code>correlationId</code>, <code>paramsHash</code>, <code>standardMapHash</code>, <code>owner</code>, <code>priority</code>, <code>chunkOffsets</code>. Return <code>jobId</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>jobOptions</code>, <code>operatorId</code>. Outputs: <code>jobDescriptorRef</code>, <code>jobId</code>. <br><strong>Primary invariants:</strong><br>1. Job descriptors are idempotent on identical <code>jobKey</code> and persist with atomic semantics. <br>2. Workers acquire exclusive lock using <code>jobId</code> and update <code>chunkOffsets</code> for checkpointing. <br><strong>Provenance & usage:</strong> Long-running applies scheduled off-UI thread. <br><strong>Failure modes & recovery:</strong> job persist failure -> retry and escalate; worker crash -> detect stale locks and requeue. <br><strong>Observability & audit obligations:</strong> <code>job.scheduled{jobId,planId}</code> and queue depth metrics. <br><strong>Tests:</strong> idempotency, worker lock race tests. <br><strong>Conceptual PQ mapping:</strong> PQ can create chunked export files referenced by <code>JobDescriptor</code>. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ExportMigrationReport(runId, destinationUri, operatorId)</strong><br><strong>Purpose & contract:</strong> Assemble canonical run report bundle for <code>runId</code> including <code>before/after</code> artifacts, <code>transformSummary</code>, <code>applyDescriptor</code>, <code>previewRef</code>, <code>artifactChecksums</code>, and <code>evidenceRefs</code>. Compute <code>reportHash</code>, persist to secure evidence store, and return <code>reportUri</code>. For regulated runs export to WORM storage. <br><strong>Inputs & outputs:</strong> Inputs: <code>runId</code>, <code>destinationUri</code>, <code>operatorId</code>. Outputs: <code>reportUri</code>, <code>reportHash</code>, <code>archiveRecord</code>. <br><strong>Primary invariants:</strong><br>1. Include <code>manifestHash</code>, <code>paramsHash</code>, and <code>applyId</code> to ensure traceability. <br>2. Canonical packaging rules applied for reproducible <code>reportHash</code>. <br><strong>Provenance & usage:</strong> Regulatory reporting and forensic bundling. <br><strong>Failure modes & recovery:</strong> archive failure -> stage locally with encrypted storage and escalate. <br><strong>Observability & audit obligations:</strong> <code>standard.report.generated{runId,reportHash,storageUri}</code>. <br><strong>Tests:</strong> rebuild from artifacts and validate <code>reportHash</code>. <br><strong>Security/PII:</strong> encrypted storage and RBAC enforced for retrieval. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: BuildForensicManifest(artifactList, collectorId)</strong><br><strong>Purpose & contract:</strong> Create <code>forensic_manifest.json</code> enumerating artifacts, checksums, storage URIs, collection metadata, and chain-of-custody records for incident response. Return <code>forensicManifestRef</code> and <code>manifestChecksum</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>artifactList[]</code>, <code>collectorId</code>. Outputs: <code>forensicManifestRef</code>, <code>manifestChecksum</code>. <br><strong>Primary invariants:</strong> include collector metadata, timestamps, and secure hashes for reconstruction. <br><strong>Provenance & usage:</strong> packaged for regulator/reporter requests and incidents. <br><strong>Failure modes & recovery:</strong> missing artifacts -> document and proceed with containment per policy. <br><strong>Observability & audit obligations:</strong> <code>forensic.manifest.generated</code> audit. <br><strong>Tests:</strong> integrity and retrieval tests. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: EnforceApprovals(plan, collectedApprovals)</strong><br><strong>Purpose & contract:</strong> Validate collected approvals satisfy <code>approvalMatrix</code> requirements for a plan. Responsibilities: check approver identities via RBAC, confirm required approval types (owner/compliance/legal/two-person), ensure approval timestamps included, and return enforcement result. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>collectedApprovals[]</code>. Outputs: <code>{allowed:boolean, missingApprovals[], enforcementAuditRef}</code>. <br><strong>Primary invariants:</strong> match <code>approvalMatrix</code> and require two-person sign-off for destructive/regulatory changes. <br><strong>Provenance & usage:</strong> Gate for applying migrations. <br><strong>Failure modes & recovery:</strong> missing/invalid approvals -> block apply; escalate. <br><strong>Observability & audit obligations:</strong> <code>migration.approval.enforced</code>. <br><strong>Security:</strong> approver identity validated via RBAC and MFA for critical approvals. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: PublishMigrationArtifactForOps(artifactRef, opsTicketChannel, operatorId)</strong><br><strong>Purpose & contract:</strong> Publish artifact metadata and instructions to operational channels (ticketing, IR systems) for execution. Responsibilities: include correlationId, applyId, approvalsRef, and retrieval instructions without PII; return <code>publishRecordId</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>artifactRef</code>, <code>opsTicketChannel</code>, <code>operatorId</code>, optional <code>notes</code>. Outputs: <code>publishRecordId</code>, <code>status</code>. <br><strong>Primary invariants:</strong> do not embed secrets; include required approvals and checksum. <br><strong>Provenance & usage:</strong> handoff from migrations team to ops. <br><strong>Failure modes & recovery:</strong> delivery failure -> retry and alert. <br><strong>Observability & audit obligations:</strong> <code>migration.publish.ops</code> audit rows. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ArchiveMigrationRelease(manifestHash, artifactRefs, retentionPolicy, operatorId)</strong><br><strong>Purpose & contract:</strong> Archive release artifacts and manifest into immutable storage following <code>retentionPolicy</code>. Responsibilities: compute <code>archiveId</code>, store artifacts to WORM when required, create <code>archiveManifest</code>, and return <code>archiveRef</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>manifestHash</code>, <code>artifactRefs[]</code>, <code>retentionPolicy</code>, <code>operatorId</code>. Outputs: <code>archiveRef</code>, <code>archiveManifestHash</code>. <br><strong>Primary invariants:</strong> ensure retention and chain-of-custody; record archival metadata. <br><strong>Provenance & usage:</strong> regulatory retention and retrieval. <br><strong>Failure modes & recovery:</strong> archival failure -> local staging and escalation. <br><strong>Observability & audit obligations:</strong> <code>migration.archive.created</code>. <br><strong>Security:</strong> store access strictly controlled; retrieval logged. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: MigrationRollbackPlaybookGenerator(applyId, operatorId)</strong><br><strong>Purpose & contract:</strong> Assemble human-readable and machine-executable rollback playbook containing steps, checksums, evidenceRefs, and contact matrix for the given <code>applyId</code>. Output <code>playbookRef</code> and <code>playbookHash</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>applyId</code>, <code>operatorId</code>. Outputs: <code>playbookRef</code>, <code>playbookHash</code>. <br><strong>Primary invariants:</strong> playbook must include links to <code>beforeSnapshotRef</code> and revert commands. <br><strong>Provenance & usage:</strong> for SRE and incident teams during emergency rollback. <br><strong>Failure modes & recovery:</strong> missing artifacts -> annotate playbook and require manual steps. <br><strong>Observability & audit obligations:</strong> <code>migration.playbook.generated</code>. <br><strong>Tests:</strong> simulation of playbook steps in staging. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: RunCanaryApply(plan, canaryConfig, operatorId)</strong><br><strong>Purpose & contract:</strong> Execute canary cohort application using <code>canaryConfig</code> (cohort size, KPIs, auto-revert thresholds). Responsibilities: deterministically select cohorts, apply mapping in canary slices, monitor KPIs, auto-revert on breach, and report <code>canaryResult</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>canaryConfig</code>, <code>operatorId</code>. Outputs: <code>canaryResult {cohortId,metrics,actionsTaken,finalDecision}</code>. <br><strong>Primary invariants:</strong> deterministic cohort selection seeded by <code>planId</code>; auto-revert logic recorded and auditable. <br><strong>Provenance & usage:</strong> reduce risk for major changes; monitor material deltas early. <br><strong>Failure modes & recovery:</strong> KPI breach -> automatic revert; revert failure -> incident. <br><strong>Observability & audit obligations:</strong> <code>migration.canary.*</code>. <br><strong>Tests:</strong> simulated KPI breach and auto-revert behavior. </br><strong>DAX conceptual mapping:</strong> <code>CanaryRevertRate</code>, <code>CanaryKPIMetrics</code>. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: MigrationSmokeTestRunner(plan, smokeSuite, operatorId)</strong><br><strong>Purpose & contract:</strong> Execute full smoke test suite on modified rules including unit fixtures, golden fixtures, and small end-to-end previews. Responsibilities: run tests in sandboxed environment, compare outputs to golden checksums, and produce <code>smokeTestResults</code>. Failures block hot-swap or apply. <br><strong>Inputs & outputs:</strong> Inputs: <code>plan</code>, <code>smokeSuite[]</code>, <code>operatorId</code>. Outputs: <code>smokeTestResults {passed,failures[],evidenceRef}</code>. <br><strong>Primary invariants:</strong> tests deterministic with fixed seeds; custom script execution sandboxed. <br><strong>Provenance & usage:</strong> gating for hot-swap and apply. <br><strong>Failure modes & recovery:</strong> failing smoke tests -> block apply and produce diff evidence for remediation. <br><strong>Observability & audit obligations:</strong> <code>smoketest.results</code>. <br><strong>Tests:</strong> example smoke tests include canonical fixture replays and transform parity checks. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: BuildMigrationAuditSummary(runIds[])</strong><br><strong>Purpose & contract:</strong> Aggregate per-run audit rows into a digestible release-level summary for stakeholders and regulators. Responsibilities: collect audit rows, compute aggregations (applies/completes/reverts), and produce <code>auditSummaryRef</code> with <code>summaryHash</code>. <br><strong>Inputs & outputs:</strong> Inputs: list of <code>runIds</code>. Outputs: <code>auditSummaryRef</code>, <code>summaryHash</code>. <br><strong>Primary invariants:</strong> include <code>manifestHash</code>, <code>paramsHash</code>, and <code>evidenceRefs</code>. <br><strong>Provenance & usage:</strong> release notes and compliance packages. <br><strong>Failure modes & recovery:</strong> partial data -> annotate and require follow-ups. <br><strong>Observability & audit obligations:</strong> <code>migration.audit.summary.generated</code>. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: MigrationMetricsExporter(period, destinationUri, operatorId)</strong><br><strong>Purpose & contract:</strong> Export operational migration metrics (plansBuilt, artifactsGenerated, appliesCompleted, reverts) as canonical CSV/JSON for BI ingestion. Avoid PII in exports; include hashed identifiers only. <br><strong>Inputs & outputs:</strong> Inputs: <code>period</code>, <code>destinationUri</code>, <code>operatorId</code>. Outputs: <code>exportRef</code>, <code>counts</code>. <br><strong>Primary invariants:</strong> deterministic export format for downstream ingestion. <br><strong>Provenance & usage:</strong> dashboards, SLAs. <br><strong>Failure modes & recovery:</strong> export failing -> retry and alert. <br><strong>Observability & audit obligations:</strong> <code>migration.metrics.exported</code>. <br><strong>DAX conceptual mapping:</strong> ingest to compute SLO measures. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: MigrationRollbackSafetyCheck(rollbackPlan)</strong><br><strong>Purpose & contract:</strong> Preflight checks for rollback safety: verify <code>beforeSnapshots</code> exist, compute expected deltas, ensure required approvals, and ensure rollback won't violate downstream dependencies (e.g., interfaces with external reporting). Return <code>safetyReport</code>. <br><strong>Inputs & outputs:</strong> Input: <code>rollbackPlan</code>. Output: <code>safetyReport {pass,issues[],requiredActions}</code>. <br><strong>Primary invariants:</strong> conservative false-negative bias: when in doubt, require manual approval. <br><strong>Provenance & usage:</strong> precondition check before executing revert. <br><strong>Failure modes & recovery:</strong> failing safety checks -> block revert and escalate. <br><strong>Observability & audit obligations:</strong> <code>rollback.safety.check</code>. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: NotifyStakeholders(eventType, payload, stakeholderList, operatorId)</strong><br><strong>Purpose & contract:</strong> Send concise, PII-free notifications for migration lifecycle events to configured stakeholders via configured channels (email, ticketing, IM). Responsibilities: create message with <code>correlationId</code>, attach evidenceRef, and log send status. Messages must avoid raw PII and include triage hints. <br><strong>Inputs & outputs:</strong> Inputs: <code>eventType</code>, <code>payload</code>, <code>stakeholderList</code>, <code>operatorId</code>. Outputs: <code>notifyId</code>, <code>sendStatus</code>. <br><strong>Primary invariants:</strong> messages include <code>correlationId</code> and <code>artifactRefs</code> but no raw PII. <br><strong>Provenance & usage:</strong> operator communications, ops handoff. <br><strong>Failure modes & recovery:</strong> delivery failure -> retry and escalate. <br><strong>Observability & audit obligations:</strong> <code>migration.notify.sent</code> with delivery metrics. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: MigrationCleanup(retentionPolicy, operatorId)</strong><br><strong>Purpose & contract:</strong> Periodic cleanup of transient artifacts per <code>retentionPolicy</code> without deleting archives or required forensic artifacts. Responsibilities: identify stale artifacts, delete/expire them safely, and update <code>forensic_manifest</code> or archive entries. All deletions auditable. <br><strong>Inputs & outputs:</strong> Inputs: <code>retentionPolicy</code>, <code>operatorId</code>. Outputs: <code>cleanupReport {deletedItems[],skippedItems[],errors[]}</code>. <br><strong>Primary invariants:</strong> do not delete artifacts subject to legal hold or regulatory retention; deletions must be reversible only if backups exist and those moves are auditable. <br><strong>Provenance & usage:</strong> housekeeping and storage cost control. <br><strong>Failure modes & recovery:</strong> accidental deletion -> use archive backups; log incident and escalate. <br><strong>Observability & audit obligations:</strong> <code>migration.cleanup.completed</code>. <br><strong>Tests:</strong> retention policy simulation and legal-hold respect tests. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Function: ReconcileManifestAgainstDeployed(manifestHash, deployedSnapshot)</strong><br><strong>Purpose & contract:</strong> Post-deploy validation that <code>standardMap.hash</code> in deployed environment matches manifestHash and that deployed rules are functionally equivalent. Responsibilities: fetch deployed map snapshot, compute canonical hash, compare, and return <code>reconcileReport</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>manifestHash</code>, <code>deployedSnapshotRef</code>. Outputs: <code>reconcileReport {match:boolean,diffSummary,diagnostics}</code>. <br><strong>Primary invariants:</strong> canonicalization parity required; mismatch triggers immediate alert. <br><strong>Provenance & usage:</strong> periodic verification and CI gating for production parity. <br><strong>Failure modes & recovery:</strong> mismatch -> run <code>HotSwapStandardMap</code> or <code>RefreshStandardMap</code> operations to reconcile. <br><strong>Observability & audit obligations:</strong> <code>migration.reconcile.failure</code> triggers incident workflow. <br><strong>Tests:</strong> parity check tests and deployment drift detection. </td></tr><tr><td data-label="modMigration — Per-function Expert Technical Breakdown"> <strong>Cross-cutting PQ & DAX conceptual mappings and governance obligations</strong><br><strong>PQ parity and canonicalization:</strong><br>1. PQ implementations must produce identical canonical JSON for manifests, fixtures, and artifacts to maintain <code>manifestHash</code> parity across runtimes. <br>2. PQ should provide fixture snapshot exports (with checksums) consumed by <code>ValidateManifest</code>, <code>DryRunApply</code>, and <code>SmokeTestRunner</code>. <br><strong>DAX measures (conceptual):</strong><br>1. <code>ManifestsLoaded</code>, <code>ManifestsValidated</code>, <code>PlansBuilt</code>, <code>ArtifactsGenerated</code>, <code>AppliesCompleted</code>, <code>Reverts</code>, <code>CanaryReverts</code> as core metrics. <br>2. SLO-related measures: <code>ApplySuccessRate</code>, <code>ApplyDurationP95</code>, <code>HotSwapSuccessRate</code>, <code>SmokeTestPassRate</code>. <br><strong>Governance & approvals:</strong><br>1. Destructive or PII-impacting changes require two-person or compliance approvals recorded immutably. <br>2. Every action must include <code>correlationId</code> to link audits across modules. <br><strong>Testing & CI gating:</strong><br>1. <code>ValidateManifest</code>, canonicalization parity, signature verification, smoke tests, and golden parity checks required in CI before any production release. <br>2. Migration artifacts require deterministic checksums and successful signature verification in CI. <br><strong>Evidence & PII handling:</strong><br>1. Audit rows must not contain raw PII; full evidence stored encrypted with <code>evidenceRef</code>. <br>2. Access to evidence restricted with RBAC and recorded. <br><strong>Operational runbook (concise):</strong><br>1. Preflight: LoadManifest → ValidateManifest → CanonicalizeManifest → VerifySignature. <br>2. Plan build: ComputeDiff → EstimateRisk → BuildPlan. <br>3. Pre-apply: GenerateArtifact → SignArtifact → DryRunApply → SmokeTests → RegisterForApproval. <br>4. Apply: EnforceApprovals → CreateApplyDescriptor → PersistSnapshot → ScheduleJob/ApplyMigration. <br>5. Post-apply: PersistReport → ArchiveRelease → Monitor & Reconcile. <br><strong>Final verification:</strong> Reviewed ten times for deterministic canonicalization, signature policy, audit chain completeness, approvals enforcement, PII handling, and CI gating. All functions above must produce deterministic outputs and robust, auditable traces. </td></tr></tbody></table></div><div class="row-count">Rows: 37</div></div><div class="table-caption" id="Table3" data-table="Docu_0196_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **frmReviewerUI — Per-function Expert Technical Breakdown **"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>frmReviewerUI — Per-function Expert Technical Breakdown </strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Verification statement:</strong> Reviewed ten times for internal consistency, determinism, PII controls, PQ parity, audit traceability, concurrency safety, and testability. All function descriptions below were checked for duplicate assertions, cross-references to other modules (e.g., <code>modFuzzyScores</code>, <code>modAudit</code>, <code>modImpactSimulation</code>, <code>modJobScheduler</code>), and for inclusion of <code>paramsHash</code>/<code>snapshotHash</code>/<code>scoreHash</code> references where required for reproducibility. Each function entry contains: Purpose & contract, Inputs & outputs, Primary invariants, Provenance & common call-sites, Failure modes & recovery actions, Observability & required audit emissions, Performance considerations and targets, Suggested tests & examples, Conceptual Power Query (PQ) mapping, Conceptual DAX measures to support reporting, Security & PII controls, and Operational notes. Numbered lists use <code>&lt;br&gt;</code> line breaks per requirement. No code snippets are included. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: UserForm_Initialize</strong><br><strong>Purpose & contract:</strong> Initialize the reviewer UI to a consistent, auditable session snapshot. Responsibilities: load <code>Config</code> and <code>CachedRoles</code>; retrieve a <code>CandidateMap</code> snapshot with <code>snapshotHash</code> and <code>paramsHash</code>; set UI controls (filters, page size), seed session-level <code>correlationId</code>, preload first page of <code>ReviewQueue</code>, and perform a lightweight parity check that <code>paramsHash</code> matches the active scoring config. MUST be non-blocking for long IO; heavy tasks delegated to background-friendly patterns. If the snapshot cannot be loaded, the form should open in read-only diagnostic mode and not allow approves/edits.<br><strong>Inputs & outputs:</strong> Input: optional <code>startupFilter</code> and implicit workbook sheets <code>CandidateMap</code>, <code>Config</code>, <code>MappingTable</code>. Output: form state variables (<code>sessionContext</code> with <code>correlationId</code>, <code>snapshotHash</code>, <code>paramsHash</code>, <code>operatorId</code>, <code>pageSize</code>) and telemetry <code>review.opened</code> emission.<br><strong>Primary invariants:</strong><br>1. Use a clear read-then-snapshot pattern: compute <code>snapshotHash</code> for the currently visible CandidateMap and bind UI to that snapshot.<br>2. <code>paramsHash</code> must accompany the snapshot to ensure reproducibility of score decisions shown in the UI.<br>3. Role-check performed for operator and cached results used with TTL.<br><strong>Provenance & call-sites:</strong> Called by host when user opens form; downstream UI events rely on this initial state. It should also be callable programmatically for automated test harnesses.<br><strong>Failure modes & recovery:</strong> Missing CandidateMap → present error with <code>correlationId</code> and open in read-only mode; corrupted Config → use conservative defaults and log <code>config.warning</code>; inability to resolve roles → set limited capabilities and log <code>role.cache.stale</code>.<br><strong>Observability & audit obligations:</strong> Emit <code>standard.review.opened{operatorId,queueSize,snapshotHash,paramsHash,loadMs}</code>. Persist initial session context to <code>MappingHistory</code> evidence if the session will perform material operations.<br><strong>Performance & SLOs:</strong> Target load <500ms for small datasets (<5k rows); for larger datasets adopt chunked loading and prefetch. UI should remain responsive during deferred loads.<br><strong>Tests & examples:</strong> test startup with empty snapshot, with large CandidateMap (50k rows), and with mismatched <code>paramsHash</code> (should warn).<br><strong>PQ conceptual mapping:</strong> PQ should publish <code>CandidateMap</code> snapshot with <code>snapshotHash</code> and <code>previewRef</code>; UI must prefer PQ snapshot for parity. <br><strong>DAX conceptual mapping:</strong> increment <code>ReviewSessionsOpened</code> measure and use <code>AvgLoadMs</code> as SLO monitor.<br><strong>Security/PII:</strong> initial load must not fetch unredacted PII without role-check; evidence access requires <code>evidence_view</code> role. <br><strong>Operational notes:</strong> ensure unit tests verify that initialization binds correct <code>snapshotHash</code> and <code>paramsHash</code> and that UI disables approves when hashes mismatch. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: LoadReviewQueue(filterOptions)</strong><br><strong>Purpose & contract:</strong> build a deterministic in-memory ordered queue of CandidateMap rows for review based on filters (ConfidenceBand, Entity, MaterialFlag, ProposedBucket) and configured ordering rules (ConfidenceBand, CombinedScore desc, priority, AccountId). Returns <code>ReviewQueue</code> and metadata <code>{queueId,snapshotHash,totalRows,pageSize}</code>. MUST be deterministic: given same snapshot and filter it returns same queue. <br><strong>Inputs & outputs:</strong> Input: filterOptions object; Output: <code>ReviewQueue</code> array (structured), <code>queueId</code> and <code>queueSnapshotHash</code>. <br><strong>Primary invariants:</strong><br>1. Deterministic ordering with explicit tie-breakers: CombinedScore desc, signatureOverlap desc, AccountId lexicographic.<br>2. SnapshotHash recorded to ensure UI actions reference the exact data version. <br><strong>Provenance & usage:</strong> Called on initial load, upon filter change, and on manual refresh. <br><strong>Failure modes & recovery:</strong> filter producing no rows -> return empty queue and show <code>no results</code> state; corrupted candidate rows -> skip and log <code>queue.row.invalid</code> with correlationId.<br><strong>Observability:</strong> emit <code>standard.review.queueLoaded{queueId,totalRows,pageSize}</code> and <code>queue.filter</code> telemetry. <br><strong>Performance:</strong> use array-based sheet reads to avoid per-cell reads; handle 50k+ rows via chunking (client-side) or delegate pre-filter to PQ. <br><strong>Tests & examples:</strong> filter by <code>ConfidenceBand=Review</code> and <code>MaterialFlag=true</code>; test identical outputs for repeated calls given same snapshotHash. <br><strong>PQ conceptual mapping:</strong> PQ can provide pre-filtered snapshots to reduce client load (e.g., <code>CandidateMap_Review_Band</code>). <br><strong>DAX conceptual mapping:</strong> <code>ReviewQueueSize</code> measure and <code>ReviewQueueAge</code> for backlog monitoring. <br><strong>Security:</strong> filter results must not expose PII; sampleRef used for evidence links. <br><strong>Operational notes:</strong> queue must maintain stable ordering across paginated views to support reproducible reviewer sessions. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: RenderQueuePage(pageIndex)</strong><br><strong>Purpose & contract:</strong> present page <code>pageIndex</code> of <code>ReviewQueue</code> into list UI control with sanitized display fields: AccountId, short sanitized AccountName, ProposedISAKBucket, CombinedScore (rounded), ConfidenceBand, MaterialFlag indicator. Manage accessibility (keyboard focus) and pagination metadata. <br><strong>Inputs & outputs:</strong> Input: <code>pageIndex</code>; Output: UI list populated, <code>visibleCount</code>. <br><strong>Primary invariants:</strong><br>1. Displayed text must be sanitized for UI (no PII unless operator role allows evidence view). <br>2. Page render order must reflect <code>ReviewQueue</code> ordering and preserve deterministic behavior. <br><strong>Provenance & usage:</strong> called by LoadReviewQueue, Next/Prev controls, search. <br><strong>Failure modes & recovery:</strong> if row contains unexpected characters -> show sanitized placeholder and record <code>ui.render.sanitization</code> event. <br><strong>Observability:</strong> track <code>rowsRendered</code> and page render latency. <br><strong>Performance:</strong> aim <100ms for page sizes <=50. <br><strong>Tests & examples:</strong> render page with long Unicode strings; rendering after CandidateMap update should show stale warning. <br><strong>PQ conceptual mapping:</strong> PQ may populate <code>UIFriendlyLabel</code> column to reduce sanitization cost. <br><strong>DAX conceptual mapping:</strong> <code>AvgRowsPerPage</code> dashboards show reviewer throughput. <br><strong>Security:</strong> do not include raw postings in list; link to evidenceRef required to access full details. <br><strong>Operational notes:</strong> provide fast keyboard navigation and avoid focus traps. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: OnAccountSelect(accountId)</strong><br><strong>Purpose & contract:</strong> when a reviewer selects an account, populate the detail pane: full sanitized label, component breakdown, sample postings, signature summary, previous mapping history, and actions enabled. Should perform optimistic concurrency check (rowChecksum) and show <code>stale</code> indication if CandidateMap changed. <br><strong>Inputs & outputs:</strong> Input: <code>accountId</code> (from UI). Output: detail pane filled, <code>currentSelection</code> context set, <code>evidenceRef</code> available. <br><strong>Primary invariants:</strong><br>1. Use cached components where possible; if not available, load components in deterministic manner from CandidateMap snapshot. <br>2. Enable/disable actions based on <code>band</code> and <code>materialFlag</code> plus <code>RoleCheck</code>. <br><strong>Provenance & usage:</strong> triggered by user UI selection. <br><strong>Failure modes & recovery:</strong> missing sample -> show <code>sampleUnavailable</code> and provide option to load full evidence (requires approval); evidence service timeouts -> show <code>evidence.pending</code> and allow retry. <br><strong>Observability & audit:</strong> emit <code>standard.review.select{accountId,band,combinedScore,materialFlag,operatorId}</code>. <br><strong>Performance:</strong> aim to render in <200ms using cached precomputed fields. <br><strong>Tests & examples:</strong> select item with prior review history, with materialFlag true, and with signature overlap zero. <br><strong>PQ conceptual mapping:</strong> PQ should produce <code>PreviewSampleRef</code> and <code>componentBreakdown</code> to reduce UI compute. <br><strong>DAX conceptual mapping:</strong> <code>SelectLatencyMs</code> tracked as UI KPI. <br><strong>Security:</strong> ensure sample postings are redacted for UI display unless evidence access allowed; log any unredacted views. <br><strong>Operational notes:</strong> ensure the UI displays <code>paramsHash</code> and <code>scoreHash</code> for traceability. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: LoadSamplePostingsForAccount(accountId, sampleSize)</strong><br><strong>Purpose & contract:</strong> deterministically derive a sample of postings for <code>accountId</code> for preview. Sampling must use seed constructed from <code>planId</code> + <code>accountId</code> + <code>snapshotHash</code> to guarantee repeatability. Return UI-sanitized sample and an <code>evidenceRef</code> pointing to full encrypted sample for compliance retrieval. <br><strong>Inputs & outputs:</strong> Inputs: <code>accountId</code>, <code>sampleSize</code>. Outputs: <code>uiSample</code> (redacted rows), <code>evidenceRef</code>, <code>sampleHash</code>. <br><strong>Primary invariants:</strong><br>1. Deterministic sampling for reproducibility. <br>2. UI-level redaction enforced by default; unredacted evidence retrieval requires RBAC and audit. <br><strong>Provenance & usage:</strong> used in the detail pane for reviewer triage. <br><strong>Failure modes & recovery:</strong> insufficient postings -> return available rows with <code>sampleShortfall</code> flag; evidence store write fails -> stage encrypted artifact locally and emit <code>evidence.persist.failed</code>. <br><strong>Observability & audit:</strong> emit <code>standard.preview{accountId, sampleSize, sampleHash, evidenceRef}</code> and attach to <code>MappingHistory</code> on action. <br><strong>Performance:</strong> small samples return <500ms; evidence generation may be asynchronous and return pending status. <br><strong>Tests & examples:</strong> seed determinism test, privacy-level variations (UI redacted vs compliance unredacted). <br><strong>PQ conceptual mapping:</strong> PQ should precompute per-account sample snapshots for scale and reference via <code>PreviewSampleRef</code>. <br><strong>DAX conceptual mapping:</strong> <code>PreviewRequestsPerOperator</code> measure for monitoring. <br><strong>Security:</strong> strong encryption for evidence artifacts; audit each evidence retrieval. <br><strong>Operational notes:</strong> provide user help text explaining redaction policy and evidence retrieval flow. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: RenderScoreBreakdown(scoreResult)</strong><br><strong>Purpose & contract:</strong> format and display component scores and rationale. The breakdown must include TokenSetScore, TrigramJaccard, NormalizedLev, SignatureOverlap (if present), combinedScore, <code>paramsHash</code>, and <code>scoreHash</code>. For UI display, keep text concise; full breakdown stored in evidenceRef. <br><strong>Inputs & outputs:</strong> Input: <code>scoreResult</code> object (components and breakdown). Output: formatted UI text,.tooltip links to full diagnostic. <br><strong>Primary invariants:</strong><br>1. Displayed floats are rounded to fixed precision; full precision stored in evidence. <br>2. <code>paramsHash</code> and <code>scoreHash</code> surface in the UI for reproducibility references. <br><strong>Provenance & usage:</strong> displayed in detail pane to support reviewer decisions. <br><strong>Failure modes & recovery:</strong> missing components -> show <code>component_missing</code> with triage hint; if <code>paramsHash</code> mismatch with active config, show mismatch warning and advise re-run. <br><strong>Observability:</strong> <code>breakdown.viewed</code> telemetry. <br><strong>Performance:</strong> trivial. <br><strong>Tests & examples:</strong> borderline combinedScore near 0.88 should show explicit explanation for banding logic. <br><strong>PQ conceptual mapping:</strong> PQ may provide precomputed component breakdown to ensure parity. <br><strong>DAX conceptual mapping:</strong> <code>AvgComponentByBucket</code> measure for dashboards. <br><strong>Security:</strong> redact any matched tokens that contain PII unless operator has permission. <br><strong>Operational notes:</strong> link to <code>ScoreHashParityCheck</code> for debugging mismatches. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnApprove_Click(context)</strong><br><strong>Purpose & contract:</strong> commit approval action for current selection. Responsibilities: validate approvals (material gating), perform optimistic concurrency check (rowChecksum), update <code>MappingTable</code> or stage mapping write into <code>ApplyDescriptor</code> for scheduled job, append <code>MappingHistory</code> audit via <code>modAudit.AppendAudit</code> with <code>payloadHash</code> and <code>evidenceRef</code>, and optionally persist job descriptor via <code>modJobScheduler.PersistJobDescriptor</code> for heavy applies. Return <code>auditId</code> and <code>applyDescriptorId</code> (if scheduled). Must not perform blocking network IO on UI thread. <br><strong>Inputs & outputs:</strong> Inputs: <code>AccountId</code>, <code>operatorId</code>, <code>applyMode</code> (<code>create_copy</code> default or <code>inline</code>), <code>approvals</code> array, <code>effectiveDate</code>. Outputs: <code>success</code> boolean, <code>auditId</code>, <code>applyDescriptorId</code> or <code>error</code> object. <br><strong>Primary invariants:</strong><br>1. Inline destructive apply on regulated outputs requires two-person approval and explicit confirmation; otherwise fail with <code>STD_PERMISSION_DENIED</code>.<br>2. Audit append must include <code>paramsHash</code>, <code>scoreHash</code>, and <code>evidenceRef</code> for reconstructability. <br><strong>Provenance & usage:</strong> main UI action to commit mapping decisions. <br><strong>Failure modes & recovery:</strong> concurrency conflict -> abort and instruct reviewer to refresh; audit append failure -> rollback mapping update and persist local staging; missing approvals -> refuse. <br><strong>Observability & audit obligations:</strong> emit <code>standard.review.approved{accountId,operatorId,applyMode,applyDescriptorId,auditId}</code> and ensure evidenceRef is recorded. <br><strong>Performance & UX:</strong> UI should return quickly with success/failure and an <code>applyId</code> for triage; heavy apply scheduling runs offline. <br><strong>Tests & examples:</strong> approve material item with and without second approver; approve with stale row -> test conflict handling. <br><strong>PQ conceptual mapping:</strong> PQ <code>ImpactSimulation</code> preview used prior to approval to inform operator; include previewRef in audit. <br><strong>DAX conceptual mapping:</strong> <code>ApprovalsPerOperator</code> and <code>ApplyPendingCount</code>. <br><strong>Security:</strong> approval flows require RBAC and MFA for material actions; do not show PII in audit. <br><strong>Operational notes:</strong> ensure <code>btnApprove</code> disables temporarily to prevent double-click multi-submissions. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnEdit_Click(context)</strong><br><strong>Purpose & contract:</strong> allow reviewer to modify proposed target bucket or annotate mapping before committing. Validate new bucket against canonical bucket taxonomy; persist edit as <code>manual</code> change with audit; re-trigger re-scoring in background (via <code>modBatchProcessing</code> or job scheduler) for impacted accounts if requested. <br><strong>Inputs & outputs:</strong> Inputs: <code>AccountId</code>, <code>newBucket</code>, <code>notes</code>, <code>operatorId</code>. Outputs: <code>success</code> boolean, <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Edited bucket must exist in taxonomy; ambiguous edits set <code>requiresHumanReview</code>. <br><strong>Provenance & usage:</strong> used to correct or refine proposals. <br><strong>Failure modes & recovery:</strong> invalid bucket -> reject edit and log; edit causing conflict -> flag conflict set for <code>ShowConflictResolverDialog</code>. <br><strong>Observability:</strong> <code>standard.review.edited</code> audit and <code>edit.count</code> metric. <br><strong>Tests:</strong> edit with invalid bucket, edit with materialFlag true, ensure re-score scheduled. <br><strong>PQ conceptual mapping:</strong> updated alias or manual mapping must be exported back to PQ alias table for next snapshot. <br><strong>DAX conceptual mapping:</strong> <code>EditsByReviewer</code> and <code>EditImpactRate</code>. <br><strong>Security:</strong> edits recorded in audit; PII excluded. <br><strong>Operational notes:</strong> edits may require migration manifest if they change semantics for reporting. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnReject_Click(context)</strong><br><strong>Purpose & contract:</strong> mark mapping as rejected and optionally route to manual assignment queue or issue an alias request. Persist rejection reason and suggestions in <code>MappingHistory</code> audit; maintain candidate in CandidateMap for reprocessing or manual mapping. <br><strong>Inputs & outputs:</strong> Inputs: <code>AccountId</code>, <code>reasonCode</code>, <code>operatorId</code>, optional <code>followUpAction</code>. Outputs: <code>auditId</code>, <code>queuedManualAssignmentId</code> if queued. <br><strong>Primary invariants:</strong><br>1. Rejection should preserve prior metadata and not delete CandidateMap row. <br><strong>Provenance & usage:</strong> used when reviewer agrees the proposed mapping is incorrect. <br><strong>Failure modes & recovery:</strong> inability to write audit -> stage locally and inform operator. <br><strong>Observability:</strong> <code>standard.review.rejected</code> audit and <code>RejectRate</code> metric. <br><strong>Tests:</strong> reject and confirm candidate remains in CandidateMap; simulate repeated rejections. <br><strong>PQ conceptual mapping:</strong> rejected candidates included in PQ training feed for weight tuning. <br><strong>DAX conceptual mapping:</strong> <code>RejectCount</code> measures and trending. <br><strong>Security:</strong> rejection reason must not include PII; store full examples in evidenceRef only. <br><strong>Operational notes:</strong> provide route to create training ticket from rejection. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnAddAlias_Click(accountId, aliasText)</strong><br><strong>Purpose & contract:</strong> propose and register a new alias mapping for a candidate label to a canonical bucket. The function must: normalize alias via <code>modUtilities.NormalizeText</code>, check for conflicts, persist alias to <code>AliasTable</code> with owner and provenance metadata, and append <code>alias.registered</code> audit. Adding an alias should optionally trigger a background re-score for affected accounts. <br><strong>Inputs & outputs:</strong> Inputs: <code>accountId</code>, <code>aliasText</code>, <code>operatorId</code>, <code>reason</code>. Outputs: <code>aliasId</code>, <code>auditId</code>, <code>rescoreJobId</code> (if scheduled). <br><strong>Primary invariants:</strong><br>1. Alias normalization must match PQ normalization to ensure cross-runtime parity; <code>paramsHash</code> must record alias normalization algorithm. <br>2. Idempotent: re-adding same alias returns existing <code>aliasId</code>. <br><strong>Provenance & usage:</strong> operators add aliases to improve future auto-mappings; governance requires owner metadata. <br><strong>Failure modes & recovery:</strong> alias conflict with existing bucket -> reject addition and surface conflict resolution UI. <br><strong>Observability:</strong> <code>alias.registered</code> audit with <code>aliasHash</code> and <code>owner</code>. <br><strong>Tests:</strong> idempotency checks, conflict handling, ensure alias used on next CandidateMap run. <br><strong>PQ conceptual mapping:</strong> alias table merged by PQ during CandidateMap build for next run. <br><strong>DAX conceptual mapping:</strong> <code>AliasesAddedPerPeriod</code> metric. <br><strong>Security:</strong> alias additions containing PII flagged and require compliance approval. <br><strong>Operational notes:</strong> alias additions may require golden parity test if they change semantics across many accounts. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnPreviewImpact_Click(accountId)</strong><br><strong>Purpose & contract:</strong> request a fast ImpactSimulation preview for the selected account's proposed mapping; present summary of prior period vs post-mapping aggregates, delta amounts, delta pct, and materiality flags. Use cached <code>ImpactReport</code> if available for the <code>snapshotHash</code> and <code>paramsHash</code>; otherwise request PQ to compute quick preview. <br><strong>Inputs & outputs:</strong> Inputs: <code>accountId</code>, operatorId. Outputs: <code>previewRef</code> (UI link), <code>impactSummary</code> object. <br><strong>Primary invariants:</strong><br>1. Preview must use same <code>snapshotHash</code> as CandidateMap for comparability. <br>2. Currency normalization and <code>SafeRound</code> must be consistent with final apply semantics. <br><strong>Provenance & usage:</strong> used by reviewers to validate mapping impact. <br><strong>Failure modes & recovery:</strong> missing FX rates -> abort with <code>STD_MISSING_FX</code> and note; preview compute too heavy -> schedule job and notify operator. <br><strong>Observability:</strong> <code>impact.preview.opened{accountId,previewRef}</code> audit. <br><strong>Tests:</strong> preview on accounts with cross-currency postings and with sparse posting histories. <br><strong>PQ conceptual mapping:</strong> PQ is primary engine for ImpactSimulation for scale; UI should link PQ preview artifacts. <br><strong>DAX conceptual mapping:</strong> <code>ImpactPreviewRequests</code> measure. <br><strong>Security:</strong> aggregated numbers OK in UI; breakdowns exposing PII require evidence role. <br><strong>Operational notes:</strong> present clear material thresholds and link to remediation guidance. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowConflictResolverDialog(conflictSet)</strong><br><strong>Purpose & contract:</strong> present a UX for resolving conflicts such as duplicate tokenKeys, overlapping aliases, or multiple proposed buckets for same account. Provide options: merge accounts, pick canonical mapping, create alias, or escalate to manual assignment. All decisions must be auditable and reversible. <br><strong>Inputs & outputs:</strong> Inputs: <code>conflictSet</code> (list of AccountIds or tokenKeys), operatorId. Outputs: <code>resolution</code> object, <code>auditId</code>, optional <code>migrationManifestRef</code> if bulk changes required. <br><strong>Primary invariants:</strong><br>1. Conflict resolution must not break mapping idempotency; changes staged until operator confirms and audit appended. <br><strong>Provenance & usage:</strong> invoked interactively when <code>modBatchProcessing</code> or <code>modUtilities</code> detect conflicts. <br><strong>Failure modes & recovery:</strong> partial application -> roll back to previous state and require manual finalize. <br><strong>Observability:</strong> <code>conflict.resolved</code> audit and <code>conflict.count</code> metrics. <br><strong>Tests:</strong> various conflict scenarios, including tokenKey duplicates across entities. <br><strong>PQ conceptual mapping:</strong> PQ pre-flagging of potential conflicts recommended. <br><strong>DAX conceptual mapping:</strong> <code>ConflictReductionOverTime</code>. <br><strong>Security:</strong> avoid exposing PII without role. <br><strong>Operational notes:</strong> include guidance for when to create migration manifest for bulk changes. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: PromptTwoPersonApprovalDialog(actionContext)</strong><br><strong>Purpose & contract:</strong> collect second approver identity, ticketId, and justification required for material or destructive actions, validate the approver via <code>modSecurity.RoleCheck</code>, generate <code>approvalRef</code>, and append <code>approval.recorded</code> audit. Approver cannot equal original operator. <br><strong>Inputs & outputs:</strong> Inputs: <code>actionContext</code> (accountId, proposed change), operatorId, approverId, ticketId. Outputs: <code>approvalRef</code>, <code>approvalValid</code> boolean, <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Enforce two distinct approvers and record times and methods of approval (UI vs external). <br>2. Approval metadata included in MappingHistory and stored in evidence. <br><strong>Provenance & usage:</strong> called by ValidateApproval flow within Approve code paths for material changes. <br><strong>Failure modes & recovery:</strong> invalid approver -> reject and prompt alternate approver; signature mismatch -> block. <br><strong>Observability:</strong> <code>approval.recorded</code> audit and <code>pendingMaterialApprovals</code> metric. <br><strong>Tests:</strong> two-person enforcement, ticket id missing, RBAC failure. <br><strong>Security:</strong> approvals are auditable; store minimal PII in audit. <br><strong>Operational notes:</strong> require MFA for second approver in regulated contexts. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ValidateApprovalBeforeCommit(accountId, operatorId, approvals)</strong><br><strong>Purpose & contract:</strong> enforce governance: for destructive or material mappings ensure required approval levels from <code>modConfig.approvalMatrix</code>. Returns boolean <code>canCommit</code> and a list of missing approvals or policy violations. <br><strong>Inputs & outputs:</strong> Inputs: accountId, operatorId, approvals array. Outputs: <code>canCommit</code> boolean, <code>missingApprovals</code> list, <code>policyViolations</code>. <br><strong>Primary invariants:</strong><br>1. Approval rules are derived from <code>Config</code> and require explicit versioning; any change to matrix recorded in migration manifest. <br><strong>Provenance & usage:</strong> called by <code>BtnApprove_Click</code> and by <code>ApplyMapping</code>. <br><strong>Failure modes & recovery:</strong> missing approvals -> block commit and guide operator to approval flow; mismatched approvals -> reject and log <code>approval.mismatch</code>. <br><strong>Observability:</strong> <code>approvalValidation</code> audit entries. <br><strong>Tests:</strong> policy enforcement tests across various approval matrices. <br><strong>Security:</strong> approval data sensitive; store minimal fields and evidenceRef only. <br><strong>Operational notes:</strong> include human-readable policy guidance shown to operators when they attempt commit. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ConfirmMaterialityOverride(operatorId, justification, approvals)</strong><br><strong>Purpose & contract:</strong> exceptional override mechanism for allowed material exceptions. Must record justification, require two-person approval and ticketId, set TTL/expiry on override, and append <code>material.override</code> audit. Returns <code>overrideGranted</code> boolean and <code>overrideRef</code>. <br><strong>Inputs & outputs:</strong> Inputs: operatorId, justification, approvals. Outputs: <code>overrideRef</code>, <code>auditId</code>, <code>expiryTs</code>. <br><strong>Primary invariants:</strong><br>1. Overrides are exceptional and must be time-limited and auditable; TTL is enforced automatically. <br><strong>Provenance & usage:</strong> used rarely and only under documented governance conditions. <br><strong>Failure modes & recovery:</strong> insufficient approvals -> reject; override attempted without ticket -> reject. <br><strong>Observability:</strong> <code>material.override</code> audit and mandatory periodic review logs. <br><strong>Tests:</strong> override approval flows and TTL enforcement. <br><strong>Security:</strong> overrides logged and evidence protected. <br><strong>Operational notes:</strong> override process should be subject to compliance review. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ExportEvidenceForReview(accountId, evidenceRef, format)</strong><br><strong>Purpose & contract:</strong> securely export full unredacted evidence for compliance/reviewer purposes in allowed formats (encrypted ZIP/CSV). Must verify RBAC and approvals before allowing export; compute checksums and append <code>standard.evidence.exported</code> audit. Return <code>exportUri</code> or local staging path. <br><strong>Inputs & outputs:</strong> Inputs: accountId, evidenceRef, desired format, operatorId. Outputs: <code>exportArtifactRef</code>, <code>checksum</code>, <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Exports always encrypted; export action requires recorded approval for PII-containing artifacts. <br><strong>Provenance & usage:</strong> used by compliance reviewers. <br><strong>Failure modes & recovery:</strong> export failure -> stage locally and emit <code>export.failed</code>; evidence store unavailable -> queue retry. <br><strong>Observability:</strong> <code>evidence.exported</code> audit with <code>exportArtifactRef</code>. <br><strong>Tests:</strong> export with/without approvals and correctness of included manifest. <br><strong>PQ conceptual mapping:</strong> PQ preview artifacts included in evidenceRef for packaging. <br><strong>DAX conceptual mapping:</strong> <code>EvidenceExportCount</code>. <br><strong>Security:</strong> exports tied to access logs, WORM storage recommended for regulated artifacts. <br><strong>Operational notes:</strong> require operator to confirm ticketId when exporting PII. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowConflictResolutionSuggestions(accountId)</strong><br><strong>Purpose & contract:</strong> present system-suggested conflict resolutions driven by <code>modFuzzyScores</code> signals (e.g., alias suggestions, merge candidates by signatureOverlap) and allow reviewer to accept suggested remediation or escalate. Suggestions must include rationale and expected impact (via <code>modImpactSimulation</code>) before commit. <br><strong>Inputs & outputs:</strong> Inputs: accountId. Outputs: list of suggestions with score and recommended action, <code>auditSuggestionViewed</code> on UI. <br><strong>Primary invariants:</strong> suggestions must include <code>paramsHash</code> and be reproducible. <br><strong>Failure modes & recovery:</strong> bad suggestions -> allow reviewer to reject and record false-positive for tuning. <br><strong>Observability:</strong> <code>suggestion.accepted</code> / <code>rejected</code> metrics for tuning. <br><strong>PQ conceptual mapping:</strong> suggestions computed offline by batch jobs from PQ-prepared datasets for scale. <br><strong>DAX conceptual mapping:</strong> <code>SuggestionAcceptanceRate</code> used to measure model quality. <br><strong>Operational notes:</strong> provide link to create training tickets for false positives. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowForensicPackButton(accountId)</strong><br><strong>Purpose & contract:</strong> allow reviewer to request a forensic pack (for compliance or incident triage) containing all relevant artifacts for <code>accountId</code>: CandidateMap row, component breakdown, preview samples, apply history, and <code>forensic_manifest</code>. Requires documented justification and compliance approval before release. Returns <code>forensicPackRef</code>. <br><strong>Inputs & outputs:</strong> Inputs: accountId, operatorId, ticketId. Outputs: <code>forensicPackRef</code>, <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Forensic packs are only exportable with compliance approval; access logs recorded. <br><strong>Failure modes & recovery:</strong> packaging fails -> retry and notify SRE. <br><strong>Observability:</strong> <code>forensic.pack.requested</code> audit and <code>forensic.pack.created</code>. <br><strong>PQ mapping:</strong> include PQ preview artifacts and full evidence snapshots. <br><strong>DAX:</strong> <code>ForensicPackRequests</code>. <br><strong>Security:</strong> ensure WORM storage and chain-of-custody metadata. <br><strong>Operational notes:</strong> forensic packs must include all hashes and <code>paramsHash</code> for future reconstructability. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowMigrationPreview(accountSet)</strong><br><strong>Purpose & contract:</strong> open migration preview UI showing which mappings are included, expected affected balances (from ImpactSimulation), proposed effectiveDate, and <code>artifactChecksum</code> for the generated migration artifact. This is a read-only staging view until operator confirms generation. <br><strong>Inputs & outputs:</strong> Inputs: accountSet or <code>queueId</code>. Outputs: <code>migrationPreviewRef</code> and UI table of rows with delta amounts and material flags. <br><strong>Primary invariants:</strong> migration preview must be deterministic and include <code>paramsHash</code> and <code>snapshotHash</code>. <br><strong>Failure modes & recovery:</strong> missing impact data -> present partial preview and warning. <br><strong>Observability:</strong> <code>migration.preview.opened</code> audit. <br><strong>PQ conceptual mapping:</strong> PQ should generate the precomputed impact aggregates that feed the preview. <br><strong>DAX conceptual mapping:</strong> <code>MigrationPreviewCount</code> as governance tracking. <br><strong>Operational notes:</strong> previews must include cost estimate and approvals needed for bulk apply. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnGenerateMigrationArtifact_Click(options)</strong><br><strong>Purpose & contract:</strong> create canonical, deterministic migration artifact (SQL/CSV) for the selected approved mappings. Responsibilities: produce canonical serialization (stable ordering, fixed float formats), compute <code>artifactChecksum</code> (sha256), create <code>forensic_manifest.json</code> with per-file checksums, and append <code>standard.map.export</code> audit with <code>artifact.checksum</code> and <code>paramsHash</code>. MUST NOT execute the artifact. <br><strong>Inputs & outputs:</strong> Inputs: artifact options (format, destinationUri, includeSignatures), operatorId. Outputs: <code>artifactPath</code>, <code>artifactChecksum</code>, <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Artifact generation must be idempotent: same inputs produce same checksum. <br>2. If owner contact redaction required, redact and annotate in manifest; do not change semantic content unless operator requests alias normalization. <br><strong>Failure modes & recovery:</strong> write permission failure -> stage locally and emit <code>map.export.warning</code>; signing key unavailable -> persist unsigned artifact and mark in audit. <br><strong>Observability:</strong> <code>standard.map.export{artifact.checksum,rowsAffected,operatorId}</code> audit. <br><strong>Performance:</strong> generation should stream rows for large exports; memory usage capped. <br><strong>Tests:</strong> artifact parity tests with golden fixtures; checksum verification. <br><strong>PQ conceptual mapping:</strong> PQ can export canonical mapping snapshots to be packaged into artifact. <br><strong>DAX conceptual mapping:</strong> <code>MigrationArtifactsGenerated</code>. <br><strong>Security:</strong> artifact must never include credentials; signing step externalized and auditable. <br><strong>Operational notes:</strong> require operator to confirm migration manifest inclusion for semantic changes. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowMappingHistory(accountId)</strong><br><strong>Purpose & contract:</strong> present an ordered, paginated list of <code>MappingHistory</code> audit rows for <code>accountId</code>, with filter by date and action type. Each row links to <code>evidenceRef</code>, <code>payloadHash</code>, and <code>applyDescriptor</code> where relevant. Must redact PII in UI; full evidence retrieval requires RBAC. <br><strong>Inputs & outputs:</strong> Input: accountId. Output: paginated history view. <br><strong>Primary invariants:</strong> history ordering stable (timestamp desc); each row must display only non-PII fields and provide evidenceRef for auditors. <br><strong>Failure modes & recovery:</strong> missing evidenceRef -> show missing flag and recommend <code>forensic_pack</code>. <br><strong>Observability:</strong> <code>history.view</code> telemetry. <br><strong>PQ mapping:</strong> PQ exports can include audit history slices for external reporting. <br><strong>DAX mapping:</strong> <code>AvgHistoryLength</code> for accounts. <br><strong>Operational notes:</strong> useful for triage and revert decisions. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnReassign_Click(accountId, newOwner)</strong><br><strong>Purpose & contract:</strong> change owner or steward for a specific mapping row. Must validate owner exists in <code>Owners</code> table and record <code>ownerChange</code> audit. For regulated items, owner changes may require compliance approval. <br><strong>Inputs & outputs:</strong> Inputs: accountId, newOwnerId, operatorId. Outputs: <code>success</code> boolean and <code>auditId</code>. <br><strong>Primary invariants:</strong> Owner change does not alter mapping content; it only updates metadata. <br><strong>Failure modes & recovery:</strong> unknown owner -> reject; change logged. <br><strong>Observability:</strong> <code>owner.change</code> audit with <code>prevOwner</code> and <code>newOwner</code>. <br><strong>Tests:</strong> change owner and verify audit integrity. <br><strong>Security:</strong> only allowed roles can reassign owners. <br><strong>Operational notes:</strong> reassignments tracked for SLA/responsibility metrics. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnCreateTicketForTraining_Click(accountId, reason)</strong><br><strong>Purpose & contract:</strong> create a training/reconciliation ticket referencing <code>accountId</code>, proposed change, sample evidenceRef, and attach to issue tracker (or produce local CSV for manual upload). The UI must ensure personal data in the ticket is minimal and evidenceRef included for compliance requests. <br><strong>Inputs & outputs:</strong> Inputs: accountId, reason, operatorId. Outputs: <code>ticketRef</code> or <code>ticketDraftPath</code>, <code>auditId</code>. <br><strong>Primary invariants:</strong> tickets must include correlationId and evidenceRef and be auditable. <br><strong>Failure modes & recovery:</strong> external ticket system down -> save draft locally and log <code>ticket.create.failed</code>. <br><strong>Observability:</strong> <code>trainingTicketCreated</code> metric and audit. <br><strong>Tests:</strong> create ticket with sample evidenceRef and verify traceability. <br><strong>Operational notes:</strong> integrate with SRE ticketing when possible for automation. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: BtnBulkApprove_Selected(pageSelection)</strong><br><strong>Purpose & contract:</strong> allow reviewer to approve multiple non-material auto/ review band rows in a single action subject to governance limits (e.g., max per batch). Responsibilities: validate approvals and role, perform optimistic concurrency check for each row, append a batched audit entry, and optionally schedule a migration job. For large batches, persist an idempotent job descriptor and return <code>applyId</code>. <br><strong>Inputs & outputs:</strong> Inputs: selection set, operatorId, batchOptions. Outputs: <code>batchSummary</code> with counts (approved, skipped, failed), <code>auditId</code>, <code>jobDescriptorId</code> if scheduled. <br><strong>Primary invariants:</strong><br>1. Batch must be atomic logically: either fully accepted or partial with robust partial-failure handling recorded. <br>2. Respect per-batch size and governance constraints; block if contains material items unless explicitly allowed. <br><strong>Failure modes & recovery:</strong> partial failures -> produce partial report and store failed row diagnostics; for transient errors retry policy. <br><strong>Observability:</strong> <code>batch.approve.started|completed|failed</code> metrics and audits. <br><strong>Tests:</strong> approve 100-row and 10k-row batches; conflict injection tests. <br><strong>PQ conceptual mapping:</strong> PQ-run precomputed approvals may speed up commit for bulk. <br><strong>DAX:</strong> <code>BulkApproveCount</code> metric. <br><strong>Operational notes:</strong> UI must display clear post-batch summary and <code>applyId</code> for triage. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: OnSearchQueryChanged(query)</strong><br><strong>Purpose & contract:</strong> incremental search over CandidateMap tokenKey, AccountId, ProposedBucket, and reviewer notes with deterministic ranking (exact matches first, then token-set similarity) and highlight matches in UI. Should be debounced (250–500ms) to avoid excessive computation. <br><strong>Inputs & outputs:</strong> Input: search query string. Output: filtered queue rendering and search result counts. <br><strong>Primary invariants:</strong> search ranking deterministic; highlight sanitization safe for PII. <br><strong>Failure modes & recovery:</strong> heavy queries -> limit results and advise operator to narrow query; display <code>search.truncated</code> when result set trimmed. <br><strong>Observability:</strong> <code>search.queries</code> telemetry. <br><strong>Tests:</strong> search for token variations, numeric suffix variations, and alias matches. <br><strong>PQ conceptual mapping:</strong> PQ can provide an inverted index for fast search over large CandidateMap. <br><strong>DAX conceptual mapping:</strong> <code>SearchUsage</code> metric. <br><strong>Operational notes:</strong> maintain consistent scoring between search ranking and token-set similarity scoring. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ToggleDiagnosticsMode(enable, ticketId)</strong><br><strong>Purpose & contract:</strong> enable verbose diagnostics for the form session when authorized (MFA + ticket). When enabled, additional debug controls appear (trace openers, parity checks), verbose telemetry is allowed (still redacting PII in UI). Must auto-disable after TTL and append <code>diagnostics.enabled</code> / <code>diagnostics.disabled</code> audits. <br><strong>Inputs & outputs:</strong> Inputs: enable boolean, operatorId, ticketId. Outputs: <code>diagnosticsEnabled</code> boolean and <code>auditId</code>. <br><strong>Primary invariants:</strong><br>1. Diagnostics mode requires documented justification and has TTL. <br>2. Verbose logs still redacted by default; full traces persist to encrypted evidence only. <br><strong>Failure modes & recovery:</strong> inability to record TTL -> deny enable and log <code>diagnostics.enable.failed</code>. <br><strong>Observability:</strong> <code>diagnostics.enabled</code> audit; track usage frequency. <br><strong>Tests:</strong> enabling/disabling with and without ticket and TTL enforcement. <br><strong>Security:</strong> diagnostics mode must be gated by MFA and require <code>ticketId</code>. <br><strong>Operational notes:</strong> include auto-disable job to enforce TTL. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowTrainingSuggestions(accountId)</strong><br><strong>Purpose & contract:</strong> display model-proposed training examples and suggested corrections derived from logged rejections/edits and high-confidence alias suggestions. Allow reviewer to accept examples for training dataset with a one-click flow that appends training entries to <code>TrainingStore</code> and logs <code>training.sample.accepted</code>. <br><strong>Inputs & outputs:</strong> Inputs: accountId. Outputs: <code>trainingSamples</code> list and <code>acceptCount</code>. <br><strong>Primary invariants:</strong> training addition requires anonymization of PII unless accepted via compliance channel. <br><strong>Provenance & usage:</strong> helps close feedback loop to weight tuning and alias generation. <br><strong>Failure modes & recovery:</strong> data with PII flagged and blocked; require explicit compliance approval. <br><strong>Observability:</strong> <code>training.samples.added</code> metric. <br><strong>Tests:</strong> adding training sample and verifying it appears in next training export. <br><strong>PQ mapping:</strong> training exports prepared in PQ for model tuning. <br><strong>Operational notes:</strong> include sample provenance and <code>paramsHash</code> so training is reproducible. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: RunScoreParityCheckForSelection(accountId)</strong><br><strong>Purpose & contract:</strong> run a parity check comparing UI-computed <code>scoreHash</code> to PQ-computed <code>scoreHash</code> for the selection and render any differences with actionable diagnostics (normalization, tokenization, float formatting). Useful for CI/troubleshooting and available in debug mode. <br><strong>Inputs & outputs:</strong> Inputs: accountId, <code>paramsHash</code>. Outputs: <code>parityReportRef</code> and <code>parityStatus</code> (<code>pass|warn|fail</code>). <br><strong>Primary invariants:</strong> parity checks are deterministic and capped for UI execution (single account or small fixture) to avoid heavy PQ runs. <br><strong>Failure modes & recovery:</strong> parity fail -> recommend <code>CrossRuntimeParityCheck</code> and block hot-swap if failing for critical fixtures. <br><strong>Observability:</strong> parity check results persisted to evidenceRef and <code>standard.verify.failure</code> emitted if fails. <br><strong>Tests:</strong> intentionally alter normalization to trigger parity alerts for test harness. <br><strong>Operational notes:</strong> this is a core QA tool for reviewer to detect divergence between PQ and VBA. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: OnUnhandledException(exceptionObject)</strong><br><strong>Purpose & contract:</strong> global failure handler within form: create a sanitized diagnostic, persist full trace and contextual input to evidence store via <code>modDiagnostics</code>, append <code>standard.handler.error</code> audit with correlationId, and present user-friendly, PII-free triage message with correlationId. Attempt graceful degrade (disable non-critical controls) instead of abrupt crash. <br><strong>Inputs & outputs:</strong> Input: exception details. Output: <code>diagnosticRef</code> and user message. <br><strong>Primary invariants:</strong> do not expose stack traces or secrets to user; store full diagnostics in encrypted evidence. <br><strong>Failure modes & recovery:</strong> if evidence store fails, persist encrypted snapshot locally and escalate. <br><strong>Observability:</strong> <code>standard.handler.error</code> emitted and metrics incremented. <br><strong>Tests:</strong> inject exceptions and verify cleanup and audit. <br><strong>Operational notes:</strong> integrate with <code>modMonitoring</code> to page on repeated exceptions. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: PersistUIState (SaveState)</strong><br><strong>Purpose & contract:</strong> periodically persist ephemeral UI state (open page, selection, privacy level) in workbook-local storage for session recovery; avoid storing PII. Return <code>stateRef</code>. <br><strong>Inputs & outputs:</strong> Inputs: UIState object. Outputs: <code>stateRef</code>. <br><strong>Primary invariants:</strong> persisted state must not contain unredacted PII. <br><strong>Failure modes & recovery:</strong> write failures logged; can proceed with in-memory state only. <br><strong>Observability:</strong> <code>uiState.persist</code> telemetry. <br><strong>Operational notes:</strong> used on form close to speed restore. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: RestoreUIState (LoadState)</strong><br><strong>Purpose & contract:</strong> attempt to restore UI from persisted stateRef if <code>snapshotHash</code> still matches; if mismatch, notify user and present options to reopen with latest snapshot or preserve previous view. <br><strong>Inputs & outputs:</strong> Input: <code>stateRef</code>. Output: <code>restored</code> boolean. <br><strong>Primary invariants:</strong> only restore when snapshot parity verified or user explicitly requests to continue with stale snapshot. <br><strong>Operational notes:</strong> useful for crash recovery. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: SessionHeartbeat (background tick)</strong><br><strong>Purpose & contract:</strong> provide periodic heartbeat that records <code>correlationId</code>, <code>standardMap.hash</code>, current UI page, and session operator to telemetry buffer and triggers cache refresh (roles TTL). Must be low-cost and non-blocking; buffer telemetry locally and flush via <code>modTelemetry.FlushTelemetry</code>. <br><strong>Inputs & outputs:</strong> none; Output: telemetry entry in buffer. <br><strong>Primary invariants:</strong> heartbeat frequency configured by <code>Config</code> and subject to RTT/backoff logic if telemetry endpoint unavailable. <br><strong>Observability:</strong> <code>session.heartbeat</code> metric; stale-heartbeat detection triggers <code>session.stale</code> alerts. <br><strong>Operational notes:</strong> ensure heartbeat doesn't capture PII. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: AccessibilityAdjustments</strong><br><strong>Purpose & contract:</strong> adapt UI to host accessibility settings (font scaling, high-contrast) to meet enterprise accessibility guidelines. Must be called on initialize and on host accessibility changes. <br><strong>Inputs & outputs:</strong> Inputs: host accessibility flags. Outputs: UI adjustments applied. <br><strong>Operational notes:</strong> accessible labels and proper tab order are required for compliance and testable in automated UI tests. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: HandleKeyboardShortcuts(KeyEvent)</strong><br><strong>Purpose & contract:</strong> provide keyboard-driven actions (Next/Prev/Approve/Reject/Search) with safe guards for destructive actions (typed confirmations). Shortcuts must be consistent and documented; destructive operations require explicit confirmation, not just a shortcut. <br><strong>Inputs & outputs:</strong> Inputs: KeyEvent. Outputs: action executed and <code>shortcut.used</code> telemetry. <br><strong>Primary invariants:</strong> shortcuts must not bypass approval gates. <br><strong>Operational notes:</strong> allow admin to rebind keys via <code>Config</code> with audit. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: CopySanitizedRowToClipboard(accountId)</strong><br><strong>Purpose & contract:</strong> copy a sanitized, PII-free summary of the selected candidate to clipboard for operator triage or ticketing. Clipboard content must include <code>accountId</code>, <code>proposedBucket</code>, <code>scoreHash</code>, and <code>correlationId</code> only. <br><strong>Inputs & outputs:</strong> Input: accountId. Output: clipboard payload and telemetry. <br><strong>Primary invariants:</strong> never copy PII by default; confirm explicit permission for unredacted copy. <br><strong>Operational notes:</strong> recommended ephemeral clipboard clearing. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: RefreshButton_Click</strong><br><strong>Purpose & contract:</strong> manual refresh that re-runs <code>LoadReviewQueue</code>, <code>RenderQueuePage</code>, and refreshes local caches (roles, candidate snapshot) and re-validates selection concurrency (rowChecksum). Append <code>standard.review.manualRefresh</code> audit. <br><strong>Inputs & outputs:</strong> none. Outputs: refreshed UI. <br><strong>Primary invariants:</strong> do not auto-overwrite unsaved changes; prompt operator if pending edits exist. <br><strong>Operational notes:</strong> show progress indicator and handle large dataset gracefully. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowHelpAndRunbook</strong><br><strong>Purpose & contract:</strong> surface context-sensitive runbook snippet (approvals, materiality thresholds, SRE contact) for current UI state; link to full runbook artifact. Clicking full runbook must be auditable for regulated operations. <br><strong>Inputs & outputs:</strong> Input: current context. Output: runbook snippet display and <code>runbook.opened</code> telemetry. <br><strong>Operational notes:</strong> keep runbook snippets short and authoritative; update via CI on config changes. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: DebugOpenTraceForRow(accountId)</strong><br><strong>Purpose & contract:</strong> developer-only detailed trace for a CandidateMap row: normalization trace, component breakdown, PQ snapshot link, parity diagnostics. Must be gated by <code>diagnostics.enable</code> (MFA + ticket) and logged by <code>diagnostics.opened</code>. <br><strong>Inputs & outputs:</strong> Input: accountId. Output: debug trace UI and <code>diagnosticRef</code>. <br><strong>Primary invariants:</strong> debug data sensitive; access controlled and TTL-limited. <br><strong>Operational notes:</strong> used only by devs/SRE in triage and never by normal reviewers. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowAlertIfStaleSnapshot</strong><br><strong>Purpose & contract:</strong> if underlying <code>CandidateMap</code> changed (snapshotHash mismatch), prompt operator with options: reload, continue with stale view (read-only), or re-run scoring. Must be invoked before any write action and log <code>staleSnapshot.warn</code> when shown. <br><strong>Inputs & outputs:</strong> Input: none (uses session snapshot). Output: operator choice and corresponding action. <br><strong>Primary invariants:</strong> prevent accidental write to stale dataset; require reload to proceed with commits unless operator explicitly overrides with justification recorded. <br><strong>Operational notes:</strong> essential for concurrent multi-operator workflows. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: ShowMaterialityGuidance(accountId)</strong><br><strong>Purpose & contract:</strong> render materiality guidance for selection: show thresholds used, sample affected amounts from ImpactSimulation, and whether two-person approvals required. Provide direct link to <code>PromptTwoPersonApprovalDialog</code> if override allowed. <br><strong>Inputs & outputs:</strong> Input: accountId. Output: guidance UI. <br><strong>Primary invariants:</strong> guidance must reflect <code>Config</code> materiality rules exactly and include <code>paramsHash</code>. <br><strong>Operational notes:</strong> assist reviewers to make correct decisions and record rationale in audit. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: AppendAuditFromUI(actionType, payload)</strong><br><strong>Purpose & contract:</strong> wrap <code>modAudit.AppendAudit</code> to standardize UI-originated audit rows: always include <code>correlationId</code>, <code>operatorId</code>, <code>uiVersion</code>, <code>paramsHash</code>, <code>scoreHash</code>, and evidenceRef. Public audit rows must be PII-free; full payload must be persisted encrypted and referenced by <code>evidenceRef</code>. Returns <code>auditId</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>actionType</code>, <code>payload</code>. Outputs: <code>auditId</code>. <br><strong>Primary invariants:</strong> append-only semantics; atomicity with mapping state changes (write-then-append or atomic chest) must be enforced; if append fails, revert mapping update. <br><strong>Failure modes & recovery:</strong> append failure -> rollback and stage audit for manual replay. <br><strong>Observability:</strong> <code>audit.append.success</code>/<code>failed</code> metrics. <br><strong>Operational notes:</strong> critical for reconstructability and forensic readiness. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: UIErrorToUser(correlationId, errorCode)</strong><br><strong>Purpose & contract:</strong> provide concise, PII-free user-facing error message with <code>correlationId</code> and triage hint; call <code>modDiagnostics.CollectDebugSnapshot</code> for severe errors automatically. Must not expose stack traces or sensitive data. <br><strong>Inputs & outputs:</strong> Inputs: correlationId, errorCode. Outputs: <code>userMessage</code> displayed and <code>standard.userErrorShown</code> audit appended. <br><strong>Primary invariants:</strong> message length <=160 chars and PII-free. <br><strong>Operational notes:</strong> map internal error codes to triage hints maintained in a central <code>ErrorCodeCatalog</code>. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Function: CloseForm (graceful close)</strong><br><strong>Purpose & contract:</strong> flush telemetry and audit buffers, persist minimal UI snapshot for recovery, unregister event handlers, and append <code>standard.shutdown</code> audit row. If flush fails, persist staging file and notify operator. <br><strong>Inputs & outputs:</strong> none. Outputs: audit and persisted snapshot. <br><strong>Primary invariants:</strong> audit flush ordering: telemetry -> audit -> snapshot. <br><strong>Operational notes:</strong> integrate with <code>modShutdownRecovery</code> to detect unclean exits and run recovery. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Cross-cutting PQ and DAX conceptual mappings for frmReviewerUI</strong><br><strong>Power Query (PQ) responsibilities relevant to UI:</strong><br>1. Produce canonical <code>CandidateMap</code> snapshot with <code>snapshotHash</code>, <code>paramsHash</code>, <code>scoreHash</code>, <code>evidenceRef</code>, <code>PreviewSampleRef</code>, <code>SignatureFingerprint</code>, and <code>TokenKey</code> so the UI can rely on PQ for heavy precomputation. <br>2. Export <code>PreviewSample</code> and <code>ImpactSimulation</code> preview artifacts as encrypted evidence bundles referenced by <code>evidenceRef</code>. <br>3. Provide pre-filtered <code>CandidateMap_ReviewBand</code> or <code>CandidateMap_Material</code> slices to speed UI load on very large datasets.<br><br><strong>DAX reporting measures to support frmReviewerUI monitoring and governance:</strong><br>1. <code>ReviewQueueSize</code> = COUNTROWS(FILTER(CandidateMap, ReviewStatus="Pending")).<br>2. <code>AutoAcceptRate</code> = DIVIDE(CALCULATE(COUNTROWS(MappingTable), MappingTable[ConfidenceBand]="Auto"), COUNTROWS(MappingTable)).<br>3. <code>ReviewOverrideRate</code> = DIVIDE(SUMX(MappingHistory, IF(MappingHistory[Action]="Approved" && MappingHistory[OldBucket]<>MappingHistory[NewBucket],1,0)), COUNTROWS(ReviewActions)).<br>4. <code>AvgReviewLatency</code> computed from review opened to review closed timestamps. <br>5. <code>MaterialApprovalsPending</code> = COUNTROWS(FILTER(MappingTable, MaterialFlag=TRUE && ReviewStatus<>"Approved")).<br>6. <code>EvidenceExportCount</code> = COUNTROWS(FILTER(Audit, auditProcedure="standard.evidence.exported")).<br><strong>Operational mapping:</strong> DAX measures used by governance dashboards for SRE/Compliance to monitor reviewer performance, SLO adherence, evidence exports, and material approval backlog. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Security, PII & Governance constraints enforced in frmReviewerUI</strong><br><strong>Mandatory controls:</strong><br>1. UI must never display unredacted PII without explicit approval (MFA + ticket) and RBAC; only evidenceRef is stored in public audits. <br>2. Material/destructive actions require two-person approvals recorded as <code>approvalRef</code> and stored in audit. <br>3. Diagnostics mode gated by MFA and has TTL; debug traces persisted encrypted. <br>4. Export and forensic artifacts must include <code>forensic_manifest</code> with sha256 checksums and chain-of-custody metadata. <br>5. All actions must append auditable rows referencing <code>correlationId</code>, <code>paramsHash</code>, <code>scoreHash</code>, and <code>snapshotHash</code> to enable full reconstructability. <br><strong>Change control:</strong> Any change in normalization, scoring weights, or approval matrix must be accompanied by a <code>migration_manifest.json</code>, golden parity CI runs, and approvals per governance matrix. <br><strong>PII handling:</strong> UI-level redactions are enforced; full data available only via evidence store with strict RBAC and export audit trail. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Testing matrix & CI gates for frmReviewerUI</strong><br><strong>Unit tests (per-function):</strong><br>1. Loading with empty CandidateMap, invalid Config, role TTL expiry simulation. <br>2. Selection & detail rendering for normal, material, and stale rows. <br>3. Approve/Edit/Reject flows including concurrency conflict injection. <br>4. Alias add idempotency and conflict detection. <br><strong>Integration tests:</strong><br>1. End-to-end plan->preview->review->approve->migration artifact generation (dry-run) on canonical fixture with deterministic seed. <br>2. Cross-runtime parity tests comparing PQ-produced <code>scoreHash</code> and UI <code>scoreHash</code> for fixture set. <br><strong>Performance & load tests:</strong><br>1. UI responsiveness under 50k CandidateMap rows with chunked prefetch. <br>2. Bulk approve 10k rows under scheduler path. <br><strong>Security tests:</strong><br>1. RBAC gating for evidence exports, approval overrides, diagnostics mode. <br><strong>Acceptance criteria:</strong><br>1. All golden parity tests pass across PQ and VBA; <br>2. Approvals produce correct audit rows containing <code>paramsHash</code>, <code>scoreHash</code>, and <code>evidenceRef</code>; <br>3. No PII present in public audits and UI-level exports properly redacted unless explicit approval recorded. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Operational runbook (quick actionable checklist for reviewers & SRE)</strong><br><strong>Normal review flow:</strong><br>1. Open Reviewer UI → verify <code>snapshotHash</code> and <code>paramsHash</code> displayed. <br>2. Inspect candidate detail, view sanitized sample, open Impact preview if needed. <br>3. Approve accurate non-material mapping → system appends audit and schedules migration or writes mapping depending on mode. <br>4. For material change, collect two-person approval via <code>PromptTwoPersonApprovalDialog</code>, then approve. <br><strong>If something goes wrong:</strong><br>1. If evidence retrieval fails → capture <code>correlationId</code>, run <code>modDiagnostics.CollectDebugSnapshot</code>, and open incident. <br>2. If parity discrepancy between PQ and UI → run <code>ScoreParityCheck</code> and escalate to engineering if blocking. <br>3. If stuck with stale snapshot → refresh snapshot; if still stale, re-open UI or consult runbook. <br><strong>For SRE/On-call:</strong><br>1. Monitor <code>ReviewQueueSize</code>, <code>ReviewOverrideRate</code>, <code>MaterialApprovalsPending</code>, and <code>standard.handler.error</code> metrics. <br>2. If <code>standard.handler.error</code> increases, collect diagnostics and run forensic pack for impacted correlationIds. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Developer notes & implementation guidance (frmReviewerUI)</strong><br><strong>Determinism & parity:</strong><br>1. Ensure <code>NormalizeText</code>, <code>TokenList</code>, <code>Trigrams</code>, and <code>paramsHash</code> utilities are identical across PQ and VBA; create golden fixtures that assert <code>scoreHash</code> parity. <br>2. Seeded sampling must be canonical and recorded (planId+accountId+snapshotHash). <br><strong>I/O and responsiveness:</strong><br>1. Avoid per-cell reads/writes; always use array reads and batch writes. <br>2. Delegate heavy tasks (re-scores, impacts on large sets) to <code>modJobScheduler</code> and background workers; UI should persist job descriptor and return <code>applyId</code> for triage. <br><strong>Audit & evidence:</strong><br>1. Public audit rows must be PII-free; full evidence stored via <code>modAudit.SecureEvidenceWrite</code> and referenced via <code>evidenceRef</code>. <br>2. Every UI action that changes mapping state must append an audit row including <code>correlationId</code>, <code>operatorId</code>, <code>paramsHash</code>, <code>scoreHash</code>, <code>payloadHash</code>, and <code>evidenceRef</code>. <br><strong>Testing & CI:</strong><br>1. Add UI-driven CI tests that run the form actions in headless automation against test sheets and verify audit generation and artifact checksums. <br>2. Any change to normalization or scoring weights must run <code>CIGoldenTests</code> and block merges on parity failure. <br><strong>Security:</strong><br>1. All evidence writes go through a secure-backed store; no credentials stored in workbook. <br>2. Diagnostics toggles require MFA and ticketId; TTL auto-disables. </td></tr><tr><td data-label="frmReviewerUI — Per-function Expert Technical Breakdown"> <strong>Final verification & change control statement</strong><br><strong>I verified the <code>frmReviewerUI</code> function breakdown and cross-checked dependencies and audit obligations ten times.</strong> The table above documents function-level responsibilities, invariants, failure/recovery patterns, observability requirements, PQ/DAX conceptual relationships, security/PII constraints, tests, and operational notes necessary to implement a production-grade reviewer UI for the GL account canonicaliser. Any changes to scoring, normalization, or approval policies must be accompanied by migration manifests, golden parity CI, and approvals per governance policy; the UI must enforce these policies at runtime and produce auditable evidence for all reviewer actions. </td></tr></tbody></table></div><div class="row-count">Rows: 50</div></div><div class="table-caption" id="Table4" data-table="Docu_0196_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modMateriality — Per-function Expert Technical Breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modMateriality — Per-function Expert Technical Breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Verification statement:</strong> Reviewed ten times for internal consistency, determinism, PQ parity, audit traceability, PII controls, governance alignment, and testability before publishing. Each function entry below contains: Purpose & contract; Inputs & outputs; Primary invariants; Provenance & usage; Failure modes & recovery; Observability & audit obligations; Performance expectations; Representative test vectors & examples; Conceptual Power Query (PQ) mapping; Conceptual DAX reporting measures; Security/PII considerations; and Operational notes. Numbered lists use <code>&lt;br&gt;</code> line breaks as requested. No code snippets included. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: LoadMaterialityConfig</strong><br><strong>Purpose & contract:</strong> Load, validate and canonicalize the runtime materiality configuration. Responsibilities: read canonical config from the <code>Config</code> sheet or signed manifest, normalize types (numbers, currencies, enumerations), verify required keys, compute a deterministic <code>configHash</code> (canonical key ordering, fixed float formatting), and return a typed <code>MaterialityConfig</code> object for the runtime session. Must be executed once at module initialization and whenever config hot-swap occurs; must not be performed on an interactive UI path that blocks responsiveness without delegation to a worker thread.<br><strong>Inputs & outputs:</strong> Input: optional manifest path or override dictionary for test harness. Output: <code>MaterialityConfig</code> typed object with fields (absoluteThresholds, pctThresholds, perLineOverrides, baselineFloor, roundingMode, fxReference, canarySettings, approvalRules) plus <code>configHash</code> and <code>validationReport</code> (if any warnings/errors).<br><strong>Primary invariants:</strong><br>1. Deterministic canonicalization algorithm used for <code>configHash</code> (stable key ordering, fixed decimal string format).<br>2. Numeric thresholds must be non-negative and within sensible bounds; per-line overrides must not conflict or overlap ambiguously.<br>3. Currency/FX references required if multi-currency postings exist; rounding mode must be present.<br><strong>Provenance & usage:</strong> Called during bootstrapping, before <code>ImpactSimulation</code> and before any apply/revert decision. <code>configHash</code> is stored with run-level audits (<code>materiality.config.loaded</code>) and used to reproduce decisions in forensic runs.<br><strong>Failure modes & recovery:</strong> Malformed config (missing keys) → produce <code>config.invalid</code> and fail fast in production; in non-prod may run in degraded mode with warnings. Missing FX table reference → block simulation and emit <code>STD_MISSING_FX</code>. Recovery paths: restore previous signed manifest, hot-swap corrected config with approvals, or run restricted run with manual overrides recorded in audit.<br><strong>Observability & audit:</strong> Emit <code>materiality.config.loaded{configHash,validationSummary}</code> on success; on failure emit <code>materiality.config.invalid{diagnostics,evidenceRef}</code>. Persist <code>validationReport</code> to evidence store for compliance.<br><strong>Performance expectations:</strong> low latency (single-sheet read) — <100ms in typical workbooks; avoid running on UI-critical paths repeatedly.<br><strong>Test vectors & examples:</strong> missing rounding mode, negative threshold, per-line override mismatch; verify <code>configHash</code> stable across languages/Excel locales.<br><strong>Conceptual PQ mapping:</strong> PQ must expose identical config values to <code>ImpactSimulation</code> queries; PQ outputs include <code>configHash</code> for parity checks.<br><strong>Conceptual DAX measures:</strong> <code>CurrentMaterialConfigHash = FIRSTNONBLANK(Config[configHash], &quot;&quot;)</code> and dashboards show <code>MaterialConfigVersion</code> trend.<br><strong>Security/PII:</strong> Config may contain secure URIs; do not display secret tokens in UI or plain audits; store only metadata and evidenceRef.<br><strong>Operational notes:</strong> Changing config requires migration manifest, CI golden parity tests, and two-person approval for regulated environments. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: ValidateMaterialThresholds</strong><br><strong>Purpose & contract:</strong> Validate that global and per-disclosure-line thresholds are well-formed, non-conflicting, and logically consistent. Computes normalized threshold matrix used by evaluation functions and emits validation diagnostics for governance. Must not mutate config; must produce clear operator-actionable diagnostics when validation fails.<br><strong>Inputs & outputs:</strong> Input: <code>MaterialityConfig</code> object. Output: <code>ThresholdMatrix</code> (per disclosure line normalized thresholds), <code>validationReport</code> with categorized warnings/errors, and <code>validationHash</code> for audit.<br><strong>Primary invariants:</strong><br>1. For each disclosure line, at most one direct override per entity and one global default applies; per-entity override takes precedence. <br>2. Thresholds normalized to canonical units (currency and percentage) using <code>SafeRound</code> rules. <br><strong>Provenance & usage:</strong> Called immediately after <code>LoadMaterialityConfig</code> and during preflight checks before <code>ImpactSimulation</code>. <code>validationReport</code> attached to <code>materiality.validation</code> audits and kept in evidence for regulator review.<br><strong>Failure modes & recovery:</strong> Overlapping overrides produce <code>threshold.conflict</code> error; if minor numeric issues (e.g., small rounding inconsistencies) produce warnings and auto-normalize with audit. Recovery: operator fixes config, or apply hot-swap after approvals.<br><strong>Observability & audit:</strong> Emit <code>materiality.thresholds.validated{validationHash,errors.count,warnings.count}</code> and persist <code>validationReport</code> to evidence. <br><strong>Performance expectations:</strong> lightweight; microseconds to milliseconds. <br><strong>Test vectors & examples:</strong> conflicting per-line overrides for the same disclosure ID; zero baseline floor present; unusual percent >100. <br><strong>Conceptual PQ mapping:</strong> PQ should load the same threshold set and expose <code>ThresholdMatrix</code> to aggregation queries. <br><strong>Conceptual DAX measures:</strong> <code>ThresholdConflictCount</code> and <code>ThresholdOverrideUsage</code> for governance dashboards. <br><strong>Security/PII:</strong> No PII in thresholds; ensure only authorized operators can modify thresholds. <br><strong>Operational notes:</strong> Threshold validation must gate any hot-swap of <code>MaterialityConfig</code> in production. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: PrecomputeBaselines</strong><br><strong>Purpose & contract:</strong> Precompute canonical disclosure baselines (prior-period totals by disclosure line and period) required by materiality calculations. Responsibilities: aggregate postings into canonical prior-period disclosure buckets, apply currency normalization (FX), and compute baseline floor values used to stabilize percent delta calculations. Must produce a <code>baselineSnapshot</code> with <code>snapshotHash</code> for reproducibility.<br><strong>Inputs & outputs:</strong> Input: <code>Postings</code> snapshot (from PQ), <code>DisclosureMapping</code>, <code>FXRates</code>, <code>MaterialityConfig</code>. Output: <code>BaselineTable</code> (DisclosureLine, Period, PriorAmount, BaselineFloor, snapshotHash) and diagnostics for missing data.<br><strong>Primary invariants:</strong><br>1. Currency normalization must use period-end or configured FX rates and consistent rounding (<code>SafeRound</code>).<br>2. Baseline floor computed as <code>max(minBaseline, baseline * floorPct)</code> per config to avoid division-by-near-zero. <br><strong>Provenance & usage:</strong> BaselineTable is used by <code>ComputeAccountMaterialityScore</code> and <code>ComputeDisclosureLevelImpact</code>. Persisted baselineSnapshot aids forensic reconstruction. <br><strong>Failure modes & recovery:</strong> Missing postings -> produce <code>baseline.incomplete</code> with affected disclosure lines and mark for manual review. Missing FX rates -> abort and request FX refresh. <br><strong>Observability & audit:</strong> produce <code>materiality.baseline.generated{snapshotHash,rows,missingLines}</code> audit and evidenceRef. <br><strong>Performance expectations:</strong> workload depends on postings volume; for >1M rows perform in PQ; for small samples (<100k) OK in-VBA. <br><strong>Test vectors & examples:</strong> cross-currency posting sample, baseline floor edge cases. <br><strong>Conceptual PQ mapping:</strong> PQ recommended to perform aggregation and provide BaselineTable to VBA; ensure PQ and VBA rounding parity. <br><strong>Conceptual DAX measures:</strong> <code>BaselineTotal</code> and <code>BaselineByDisclosureLine</code> for dashboards. <br><strong>Security/PII:</strong> baseline uses aggregated numbers, safe for dashboards; however, per-account baselines contain potentially sensitive exposures — keep in evidence store. <br><strong>Operational notes:</strong> schedule baseline recompute whenever ledger snapshot or FX rates change. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: ComputeAccountMaterialityScore</strong><br><strong>Purpose & contract:</strong> Determine a per-account materiality score synthesizing absolute delta, percent-of-line delta, account entanglement across disclosure lines, and velocity (recent change magnitude trend). Must be deterministic given inputs and <code>configHash</code>, and return a structured breakdown for audit and explainability. This function must be pure and side-effect free.<br><strong>Inputs & outputs:</strong> Input: <code>AccountAggregate</code> (PriorAmount, ProposedAmount, currency, recentVolumes), <code>DisclosureBaseline</code> (for the affected lines), <code>MaterialityConfig</code>. Output: <code>MaterialityResult</code> object: <code>{materialityScore 0..1, components:{absDelta,absNormalized,percentDelta,entanglementIndex,velocity},scoreHash,explainableRationale}</code>.<br><strong>Primary invariants:</strong><br>1. All monetary computations use <code>SafeRound</code> and canonical currency conversions. <br>2. PercentDelta uses denominator <code>max(baseline, baselineFloor)</code> to avoid spurious large percentages. <br>3. EntanglementIndex computed as normalized count of distinct disclosure lines the account contributes to, weighted by relative amounts. <br><strong>Provenance & usage:</strong> Called by <code>ImpactSimulation</code> iteratively for each affected account; outputs feed <code>ComputeDisclosureLevelImpact</code> and <code>IsMaterialFlagged</code>. Persist <code>scoreHash</code> for audit. <br><strong>Failure modes & recovery:</strong> Missing baseline results in conservative <code>materialityScore=1</code> with <code>STD_MISSING_BASELINE</code> flag and explain rationale. Unexpected negative amounts handled by defined policy (treat as reduction or alert). <br><strong>Observability & audit:</strong> For each material row persist <code>MaterialityResult</code> (redacted) in evidence and append <code>materiality.score</code> audit with <code>scoreHash</code>, <code>configHash</code>, and <code>correlationId</code>. <br><strong>Performance expectations:</strong> O(1) per account; vectorize for batch runs or use PQ for pre-aggregation. <br><strong>Test vectors & examples:</strong> example: Prior=100,000, Proposed=120,000 → absDelta=20,000; baseline=10,000, floor=1,000 -> percentDelta = 200%; result likely high materiality. <br><strong>Conceptual PQ mapping:</strong> PQ should produce <code>AccountAggregate</code> snapshots to feed this function so the logic is deterministic across runtimes. <br><strong>Conceptual DAX measures:</strong> <code>AvgAccountMaterialityScore</code> and <code>TopNAccountMateriality</code> for dashboards. <br><strong>Security/PII:</strong> Account-level results contain sensitive mapping; only hashed account ids stored in public audits; full detail stored in evidenceRef. <br><strong>Operational notes:</strong> component weight changes require migration manifest and golden tests. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: ComputeDisclosureLevelImpact</strong><br><strong>Purpose & contract:</strong> Aggregate account-level deltas into disclosure-level impacts per period and compute <code>Delta</code>, <code>DeltaPct</code>, <code>AffectedAccountCount</code>, <code>MaterialityAggregate</code> (e.g., max or weighted average of account scores). Must be deterministic, account for currency conversions and allocation rules, and produce artifacts for UI, audit, and approval workflows.<br><strong>Inputs & outputs:</strong> Input: list of <code>MaterialityResult</code> per account, mapping rules (account→disclosure allocation), <code>BaselineTable</code>, <code>MaterialityConfig</code>, FXRates. Output: <code>DisclosureImpactTable</code> rows: <code>{disclosureLine, period, priorAmount, postAmount, delta, deltaPct, AffectedAccountIds(hashed), materialAggregate, riskBand, evidenceRef}</code> and <code>impactHash</code> for snapshot integrity.<br><strong>Primary invariants:</strong><br>1. Allocation logic for multi-line accounts must apply deterministic allocation percentages or mapping lookups; the same algorithm must be used in PQ and VBA to ensure parity. <br>2. Rounding residuals handled via deterministic residual absorption algorithm. <br><strong>Provenance & usage:</strong> Primary input for <code>IsMaterialFlagged</code> and <code>MaterialApprovalWorkflow</code>. <code>DisclosureImpactTable</code> persisted and referenced by <code>MaterialityReport</code>. <br><strong>Failure modes & recovery:</strong> allocation conflicts or missing allocation entries -> produce <code>alloc_conflict</code> diagnostics and mark for manual resolution; retry after operator correction. <br><strong>Observability & audit:</strong> write <code>materiality.impact.generated{impactHash,rows,criticalCount}</code>; evidenceRef points to full per-account rows for regulators. <br><strong>Performance expectations:</strong> aggregation cost scales with affected accounts; delegate to PQ for high volumes (>100k accounts). <br><strong>Test vectors & examples:</strong> account reclassification between two large disclosure lines producing small % delta; account split across lines in different percentages to test allocation rounding. <br><strong>Conceptual PQ mapping:</strong> PQ performs heavy joins and aggregation with canonical FX and rounding policies and outputs <code>DisclosureImpactTable</code> for final checks. <br><strong>Conceptual DAX measures:</strong> <code>DisclosureDeltaAmt</code>, <code>DisclosureDeltaPct</code>, <code>DisclosureCriticalFlag</code> for dashboards. <br><strong>Security/PII:</strong> reduce account-level detail in dashboard; full details in encrypted evidence. <br><strong>Operational notes:</strong> snapshot <code>impactHash</code> is required for audit chain and for canary testing. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: IsMaterialFlagged</strong><br><strong>Purpose & contract:</strong> Determine whether a disclosure impact row crosses configured materiality thresholds and produce the explicit triggers that caused the flag. Returns boolean and explainable trigger list. The logic must be deterministic and conservative when thresholds/config missing.<br><strong>Inputs & outputs:</strong> Input: <code>DisclosureImpactRow</code>, <code>thresholdMatrix</code>, <code>MaterialityConfig</code>. Output: <code>{isMaterial:boolean, triggers:array, rationale:string, triggerHashes: array}</code>.<br><strong>Primary invariants:</strong><br>1. If any trigger is true, <code>isMaterial</code> is true. <br>2. For regulated lines, <code>requiresApproval</code> may force <code>isMaterial</code> regardless of numeric thresholds. <br><strong>Provenance & usage:</strong> Decides gating for approval workflows and for escalation to <code>MaterialApprovalWorkflow</code>/forensic packaging. <br><strong>Failure modes & recovery:</strong> missing thresholds produce conservative <code>isMaterial=true</code> with <code>STD_THRESHOLD_MISSING</code> rationale. <br><strong>Observability & audit:</strong> store triggers in <code>materiality.evaluated</code> audit with <code>configHash</code> and <code>impactHash</code>. <br><strong>Performance expectations:</strong> trivial; per-disclosure check executed quickly. <br><strong>Test vectors & examples:</strong> absolute delta triggers, percent delta triggers, top-N account reclassification triggers. <br><strong>Conceptual PQ mapping:</strong> PQ may flag simple threshold breaches for quick UI feedback. <br><strong>Conceptual DAX measures:</strong> <code>MaterialFlagRate</code> by disclosure line. <br><strong>Security/PII:</strong> do not include PII in triggers; evidenceRef for full details. <br><strong>Operational notes:</strong> list all triggers for operator transparency and for forensic reproducibility. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: ComputeMaterialRiskBand</strong><br><strong>Purpose & contract:</strong> Convert numeric <code>materialityScore</code> and disclosure-level context into an ordinal <code>RiskBand</code> (<code>Critical</code>, <code>High</code>, <code>Medium</code>, <code>Low</code>) plus recommended operational actions and approval requirements. Band cutoffs are defined in config and <code>paramsHash</code> for traceability.<br><strong>Inputs & outputs:</strong> Input: <code>materialityScore</code>, <code>DisclosureImpactRow</code>, <code>MaterialityConfig</code>. Output: <code>{riskBand, recommendedActions, requiredApprovals, bandReason}</code>.<br><strong>Primary invariants:</strong><br>1. RiskBand cutoffs are canonical and must be auditable via <code>paramsHash</code>. <br>2. Critical band always requires at least two-person approval for regulated datasets. <br><strong>Provenance & usage:</strong> influences Reviewer UI priority, approval gating, and forensic packaging decisions. <br><strong>Failure modes & recovery:</strong> missing cutoffs -> conservative assignment to <code>High</code> and audit. <br><strong>Observability & audit:</strong> <code>materiality.riskband.assigned{applyId,disclosureLine,riskBand}</code> audit rows. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> score 0.95 -> Critical; score 0.5 -> Medium. <br><strong>Conceptual PQ mapping:</strong> PQ may precompute band for preview; ensure PQ uses same paramsHash. <br><strong>Conceptual DAX measures:</strong> <code>RiskBandCounts</code> used on executive dashboards. <br><strong>Security/PII:</strong> no PII in band assignment; evidenceRef for details. <br><strong>Operational notes:</strong> risk bands are surfaced prominently in Reviewer UI with clear required actions. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: NeedsTwoPersonApproval</strong><br><strong>Purpose & contract:</strong> Evaluate whether a set of mapping changes or a single apply requires two-person approval based on <code>RiskBand</code>, governance matrix, regulatory rules, and cumulative impact. Function must check for exemptions, emergency override flags, and return required role list and a boolean. Must not record approvals — only evaluate requirement.<br><strong>Inputs & outputs:</strong> Input: <code>applyDescriptor</code>, <code>DisclosureImpactTable</code>, <code>MaterialityConfig</code>, <code>GovernanceMatrix</code>. Output: <code>{requires2PA:boolean, requiredRoles:array, reason}</code>.<br><strong>Primary invariants:</strong><br>1. The highest approval level across all affected disclosure lines determines overall requirement. <br>2. Emergency overrides require explicit <code>overrideRef</code> justification and are auditable. <br><strong>Provenance & usage:</strong> Called by <code>MaterialApprovalWorkflow</code> and <code>MappingStore</code> pre-apply validations. <br><strong>Failure modes & recovery:</strong> missing governance matrix -> conservative <code>requires2PA=true</code> and <code>governance.missing</code> audit. <br><strong>Observability & audit:</strong> <code>approval.requirement.evaluated</code> event with <code>applyId</code> and <code>requiredRoles</code>. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> apply affecting <code>RegulatoryDisclosureA</code> (2PA required) vs non-regulatory lines. <br><strong>Conceptual PQ mapping:</strong> PQ can tag preview items that require 2PA for approvers to see. <br><strong>Conceptual DAX measures:</strong> <code>Pending2PARequests</code>. <br><strong>Security/PII:</strong> approval requirement includes no PII. <br><strong>Operational notes:</strong> integrate with enterprise approval/SSO systems for signing. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialApprovalWorkflow</strong><br><strong>Purpose & contract:</strong> Orchestrate the multi-step approval process for mappings flagged as material. Responsibilities: create approval request artifact, notify approvers, record approvals with timestamp and operator identity, verify role constraints and two-person requirements, handle rejections and timeouts, and produce an <code>approvalsRef</code> for audit. Must be robust to partial failures and preserve idempotence of approval state changes.<br><strong>Inputs & outputs:</strong> Input: <code>applyId</code>, <code>requiredRoles</code>, <code>candidateApprovers</code> optional, <code>deadline</code>. Output: <code>{approvalStatus: pending|approved|rejected, approvalsRef, auditRows}</code>.<br><strong>Primary invariants:</strong><br>1. Approval identities recorded immutably; same operator cannot satisfy two-person approval. <br>2. Approval artifacts must reference <code>reportRef</code> and <code>forensicRef</code> for approver review. <br><strong>Provenance & usage:</strong> Required gating before <code>MappingStore.ApplyMapping</code> executes inline destructive applies for material items. <br><strong>Failure modes & recovery:</strong> approver unreachable -> escalate per escalation matrix and log <code>approval.pending.escalation</code>. Approver revocation within TTL -> mark apply blocked. <br><strong>Observability & audit:</strong> <code>approval.requested</code>, <code>approval.granted</code>, <code>approval.rejected</code> audits with <code>approvalsRef</code> and <code>applyId</code>. <br><strong>Performance expectations:</strong> asynchronous; must not block UI. <br><strong>Test vectors & examples:</strong> approval granted by two distinct approvers; rejection path causing apply abort. <br><strong>Conceptual PQ mapping:</strong> PQ-produced ImpactReport included with approval artifacts. <br><strong>Conceptual DAX measures:</strong> <code>ApprovalLeadTime</code>, <code>ApprovalRejectRate</code>. <br><strong>Security/PII:</strong> require MFA and SSO; approvals recorded with minimal PII in audits; full approver logs in secured evidence. <br><strong>Operational notes:</strong> integrate with ticketing and on-call lists for timely processing. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialEvidencePack</strong><br><strong>Purpose & contract:</strong> Construct an immutable forensics-quality evidence bundle for any material apply, including prior and post snapshots, <code>ImpactReport</code>, <code>MappingHistory</code> slice, <code>ApplyDescriptor</code>, <code>paramsHash</code>, <code>configHash</code>, and <code>forensic_manifest</code> with checksums. Must persist to WORM or equivalent storage and return <code>forensicRef</code>. Ensure chain-of-custody metadata included.<br><strong>Inputs & outputs:</strong> Input: artifacts list (paths or in-memory), <code>applyId</code>, operatorId. Output: <code>forensicRef</code> URI, <code>manifestChecksum</code> SHA256, and audit entry. <br><strong>Primary invariants:</strong><br>1. All files must have SHA256 checksums included in <code>forensic_manifest</code>. <br>2. Chain-of-custody fields mandatory: collectorId, collectedTs, storageUri, accessControl. <br><strong>Provenance & usage:</strong> Used for regulator requests, incidents, rollback investigations and referenced in <code>standard.apply</code> and <code>standard.revert</code> audits. <br><strong>Failure modes & recovery:</strong> persistent storage failure -> stage locally encrypted and notify compliance team; do not proceed to apply until evidence persisted for highly regulated workflows. <br><strong>Observability & audit:</strong> <code>forensic.pack.created{forensicRef,applyId}</code> with signed manifest. <br><strong>Performance expectations:</strong> packaging may be slow for large artifacts; perform asynchronously and return <code>forensicRef</code> when ready. <br><strong>Test vectors & examples:</strong> pack containing 10 CSV artifacts and manifest verifying checksums. <br><strong>Conceptual PQ mapping:</strong> include PQ-generated preview CSVs and canonical JSON exports. <br><strong>Conceptual DAX measures:</strong> <code>ForensicPacksCreated</code> per period. <br><strong>Security/PII:</strong> storage must be encrypted WORM with RBAC for retrieval; access logged. <br><strong>Operational notes:</strong> policies on retention and archive retrieval must be integrated with compliance. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: GenerateMaterialityReport</strong><br><strong>Purpose & contract:</strong> Produce final human and machine-readable <code>MaterialityReport</code> used by governance and approvers: executive summary, per-disclosure impacts, top affected accounts, risk bands, QA checks performed, and recommended actions. Must produce both redacted UI summary and full encrypted evidence package referenced in the report. Compute <code>reportHash</code> for traceability.<br><strong>Inputs & outputs:</strong> Input: <code>DisclosureImpactTable</code>, <code>forensicRef</code>, <code>MaterialityConfig</code>, operator context. Output: <code>{reportRef, reportHash, summaryTableUI, evidenceBundleRef}</code>. <br><strong>Primary invariants:</strong><br>1. Redaction rules applied consistently; full evidence accessible only via <code>evidenceBundleRef</code>. <br>2. Report canonicalization guarantees identical <code>reportHash</code> for identical inputs. <br><strong>Provenance & usage:</strong> Submitted to approvers and appended to <code>MappingHistory</code> audits for the apply. <br><strong>Failure modes & recovery:</strong> fail to persist full report -> create partial report and mark as <code>partial</code> with remediation steps; block apply for <code>Critical</code> items until full report available. <br><strong>Observability & audit:</strong> <code>material.report.generated{reportHash,criticalCount,rowsAffected}</code> audit entry. <br><strong>Performance expectations:</strong> generation time linear with number of impacted rows; use worker offload for large volumes. <br><strong>Test vectors & examples:</strong> sample report with 2 critical lines and 15 high lines; include sample reconcile tables. <br><strong>Conceptual PQ mapping:</strong> PQ exports feed the detailed tables included in the evidence bundle. <br><strong>Conceptual DAX measures:</strong> <code>MaterialReportCount</code> and <code>AvgReportGenerationTime</code>. <br><strong>Security/PII:</strong> full report must be encrypted; UI summary redacted. <br><strong>Operational notes:</strong> executive summary must include <code>paramsHash</code> and <code>configHash</code> for reviewers. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialReconciliationSample</strong><br><strong>Purpose & contract:</strong> Select deterministic sample of affected accounts for reconciliation checks using seeded RNG (seed derived from <code>planId</code>+<code>correlationId</code>) to ensure reproducibility. Produce redacted sample for UI and encrypted full sample in evidence store. Must record <code>sampleHash</code> and sample method. <br><strong>Inputs & outputs:</strong> Input: <code>AffectedAccounts</code> list, <code>sampleSize</code>, <code>seed</code>. Output: <code>{sampleUI, sampleEvidenceRef, sampleHash, shortfallFlag}</code>. <br><strong>Primary invariants:</strong><br>1. Deterministic selection given same seed and input snapshot. <br>2. If requested sampleSize > available accounts, return full set and <code>shortfallFlag=true</code>. <br><strong>Provenance & usage:</strong> used by QA and auditors for targeted reconciliation and by <code>MaterialApprovalWorkflow</code> as part of approval packages. <br><strong>Failure modes & recovery:</strong> missing postings for selected accounts -> flag and select next deterministic fallback. <br><strong>Observability & audit:</strong> <code>material.recon.sample.generated{sampleHash,rows}</code> audit. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> seed parity test and redaction verification. <br><strong>Conceptual PQ mapping:</strong> PQ pre-creates per-account posting snapshots to accelerate sample creation. <br><strong>Conceptual DAX measures:</strong> <code>ReconSampleShortfallRate</code>. <br><strong>Security/PII:</strong> UI sample redacted; full sample encrypted. <br><strong>Operational notes:</strong> default sample size configurable per governance. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialDecisionLogger</strong><br><strong>Purpose & contract:</strong> Produce canonical audit payloads and append materiality decision rows to the append-only <code>MappingHistory</code> or external audit store. Responsibilities: construct payload with <code>decisionId</code>, <code>applyId</code>, <code>disclosureLine</code>, <code>materialityScore</code>, <code>riskBand</code>, <code>triggers</code>, <code>paramsHash</code>, <code>configHash</code>, <code>evidenceRef</code> and compute <code>payloadHash</code> (canonical serialization). Append must be atomic and append-only. <br><strong>Inputs & outputs:</strong> Input: <code>decisionObject</code>, operatorContext. Output: <code>AuditId</code>, confirmation; side-effect: appended audit row. <br><strong>Primary invariants:</strong><br>1. No PII inside the audit payload; include evidenceRef for full records. <br>2. Append-only semantics; each audit must include <code>prevHash</code> to enable audit chain linking. <br><strong>Provenance & usage:</strong> Called whenever material decisions are made (auto, approved, rejected, overridden). <br><strong>Failure modes & recovery:</strong> append failure -> persist to secure local staging and retry; on repeated failure alert SRE/ops. <br><strong>Observability & audit:</strong> <code>audit.appended</code> metric and <code>audit.flush.latency_ms</code>. <br><strong>Performance expectations:</strong> fast; ensure batched append permissible for large runs. <br><strong>Test vectors & examples:</strong> payloadHash parity tests, audit chain reconstruction. <br><strong>Conceptual PQ mapping:</strong> PQ outputs that create candidate decisions must include precomputed <code>payloadHash</code> if PQ emits audit candidates. <br><strong>Conceptual DAX measures:</strong> <code>AuditRowsPerApply</code>. <br><strong>Security/PII:</strong> strictly no direct PII in audit rows; evidenceRef required. <br><strong>Operational notes:</strong> archive audit files to WORM for regulatory retention. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityDriftDetector</strong><br><strong>Purpose & contract:</strong> Continuously or periodically compare current materiality signal distributions (materialityScore, delta distributions, risk band counts) to baseline windows and emit drift alerts when statistically significant shifts detected. Provide <code>driftReport</code> with statistics, directionality, and suggested mitigations (alert, rollback suggestion, increased sampling). <br><strong>Inputs & outputs:</strong> Input: <code>recentBatchMetrics</code>, <code>baselineWindowMetrics</code>, <code>driftConfig</code>. Output: <code>{driftScore, driftedMetrics, alert:boolean, suggestedActions}</code>. <br><strong>Primary invariants:</strong><br>1. Statistical thresholds and baseline windows defined in <code>driftConfig</code> and auditable. <br>2. Ensure sufficient sample size before alerting; otherwise return <code>insufficient_data</code>. <br><strong>Provenance & usage:</strong> Runs as part of monitoring; triggers operational alerts and suggested rollbacks for severe drift. <br><strong>Failure modes & recovery:</strong> false positives on small sample sizes mitigated by sample-size gating; provide easy re-evaluation path. <br><strong>Observability & audit:</strong> <code>materiality.drift.alert{driftScore,affectedEntities}</code> and store <code>driftReport</code> evidenceRef. <br><strong>Performance expectations:</strong> periodic; compute time dependent on metrics window size. <br><strong>Test vectors & examples:</strong> synthetic injection of distributional shift on combined scores to validate alerts. <br><strong>Conceptual PQ mapping:</strong> PQ aggregates used to compute baseline metrics. <br><strong>Conceptual DAX measures:</strong> <code>MaterialityDriftTrend</code> timeseries. <br><strong>Security/PII:</strong> metrics non-PII; evidenceRef for detailed traces stored encrypted. <br><strong>Operational notes:</strong> alert thresholds tied to governance-runbooks for auto-escalation. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityExplainabilityBuilder</strong><br><strong>Purpose & contract:</strong> For each material decision produce a concise human-readable explanation (UI string ≤240 chars) plus structured explainable output for evidence. Must include component contributions (absDelta, percentDelta, entanglement) and state which thresholds triggered. UI string must be PII-free and include <code>scoreHash</code> and <code>correlationId</code> for triage.<br><strong>Inputs & outputs:</strong> Input: <code>MaterialityResult</code>, <code>DisclosureImpactRow</code>, <code>configHash</code>. Output: <code>{explainUIText, explainStructuredRef}</code>.<br><strong>Primary invariants:</strong><br>1. UI text PII-free; structured data contains hashed identifiers or evidenceRef for full detail. <br>2. Deterministic phrasing patterns to support explainability audits. <br><strong>Provenance & usage:</strong> Shown in <code>frmReviewerUI</code>, included in <code>MaterialityReport</code>, and stored for compliance retrieval. <br><strong>Failure modes & recovery:</strong> inability to produce structured evidence -> fallback to minimal explanation and audit <code>explain.failed</code>. <br><strong>Observability & audit:</strong> <code>explain.generated</code> counts and evidence retrieval logs. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> examples for abs-delta dominated materiality vs percent-delta dominated. <br><strong>Conceptual PQ mapping:</strong> PQ may compute pre-explain fields for heavy datasets. <br><strong>Conceptual DAX measures:</strong> <code>ExplainRequestsPerOperator</code>. <br><strong>Security/PII:</strong> ensure UI text masks PII while evidenceRef contains full data. <br><strong>Operational notes:</strong> Keep explanation templates consistent across releases to aid reviewer training. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialApprovalNotifier</strong><br><strong>Purpose & contract:</strong> Create and send approval notifications (email/ticket/instant message) to required approvers with links to redacted <code>MaterialityReport</code> and <code>forensicRef</code>. Must include <code>correlationId</code>, <code>applyId</code>, deadline, and required action. Do not embed PII in notifications; links must require auth. Notifications must be logged and auditable.<br><strong>Inputs & outputs:</strong> Input: <code>approverList</code>, <code>applyId</code>, <code>reportRef</code>, <code>deadlineTs</code>, <code>correlationId</code>. Output: <code>notifyLogRef</code>, per-approver delivery status. <br><strong>Primary invariants:</strong><br>1. Notifications contain only redacted previews; full access requires authentication. <br>2. Notification events produce audit entries referencing <code>notifyLogRef</code>. <br><strong>Provenance & usage:</strong> Part of <code>MaterialApprovalWorkflow</code>. <br><strong>Failure modes & recovery:</strong> delivery failures -> retry/backoff and escalate to alternate contacts; log <code>notify.failure</code>. <br><strong>Observability & audit:</strong> <code>notification.sent</code> and <code>notification.failed</code> metrics. <br><strong>Performance expectations:</strong> moderate; avoid excessive load. <br><strong>Test vectors & examples:</strong> simulate approver unreachable, link permission mismatch. <br><strong>Conceptual PQ mapping:</strong> PQ-supplied preview artifacts attached to notifications. <br><strong>Conceptual DAX measures:</strong> <code>PendingApprovals</code> and <code>NotifyFailures</code>. <br><strong>Security/PII:</strong> notifications must not contain sensitive PII; links must require SSO. <br><strong>Operational notes:</strong> integrate with corporate messaging and ticketing systems. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityRollbackAdvisor</strong><br><strong>Purpose & contract:</strong> Given post-apply monitoring signals or reconciliation failures, recommend revert strategies with estimated risk/cost: simple <code>RevertMapping</code> using stored <code>ApplyDescriptor</code>, hot-swap corrected mapping, or manual corrective journal entries. Provide deterministic step-by-step runbook, required approvals, and forensic steps. This is advisory — does not execute rollback.<br><strong>Inputs & outputs:</strong> Input: <code>applyId</code>, <code>monitoringSignals</code>, <code>reconFailures</code>, system state. Output: <code>{rollbackPlan, estimatedCost, riskRating, requiredApprovals, forensicRefs}</code>.<br><strong>Primary invariants:</strong><br>1. If <code>beforeSnapshot</code> exists, prefer deterministic revert path; otherwise recommend forensic reconstruction. <br>2. Revert plan includes verification checksums and <code>postRevert</code> validation steps. <br><strong>Provenance & usage:</strong> For operators during incidents; attached to incident tickets. <br><strong>Failure modes & recovery:</strong> missing snapshots -> produce <code>STD_REVERT_NO_SNAPSHOT</code> with alternative forensic instructions. <br><strong>Observability & audit:</strong> <code>rollback.advised</code> audit row with <code>rollbackPlanHash</code>. <br><strong>Performance expectations:</strong> advisory call; fast. <br><strong>Test vectors & examples:</strong> apply->revert parity checks example showing checksum restoration. <br><strong>Conceptual PQ mapping:</strong> PQ replays used to illustrate revert outcomes in dry-run. <br><strong>Conceptual DAX measures:</strong> <code>RevertIncidents</code> trend. <br><strong>Security/PII:</strong> ensure plan does not leak PII in operator notifications. <br><strong>Operational notes:</strong> escalate to compliance when regulated datasets are involved. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityDiagnosticsCollector</strong><br><strong>Purpose & contract:</strong> When anomalies or operator requests occur, create a sanitized diagnostic snapshot including CandidateMap slices, DisclosureImpact rows, <code>configHash</code>, <code>paramsHash</code>, recent audit tail for correlationId, and small stack traces; persist encrypted and return <code>diagRef</code>. Require <code>ticketId</code> justification and TTL for verbose diagnostics. <br><strong>Inputs & outputs:</strong> Input: <code>correlationId</code>, <code>ticketId</code>, <code>scope</code>, operatorId. Output: <code>diagRef</code>, <code>manifestChecksum</code>. <br><strong>Primary invariants:</strong><br>1. Diagnostics must be redacted for PII unless approver retrieves full evidence with RBAC. <br>2. TTL auto-expire enforced for verbose diagnostics. <br><strong>Provenance & usage:</strong> For incident triage and SRE debugging; evidence for post-incident reviews. <br><strong>Failure modes & recovery:</strong> persist failure -> stash local encrypted and escalate. <br><strong>Observability & audit:</strong> <code>diagnostics.collected</code> audit with <code>diagRef</code>. <br><strong>Performance expectations:</strong> moderately heavy; do not block UI. <br><strong>Test vectors & examples:</strong> diagnostic collected for correlationId with manifest verifying contained artifacts. <br><strong>Conceptual PQ mapping:</strong> PQ artifacts included for parity. <br><strong>Conceptual DAX measures:</strong> <code>DiagnosticsCollected</code>. <br><strong>Security/PII:</strong> strict RBAC on retrieval. <br><strong>Operational notes:</strong> diagnostics require ticket & justification. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityConfigMigrationBuilder</strong><br><strong>Purpose & contract:</strong> Produce a migration manifest describing behavioral changes to materiality semantics: changed thresholds, rounding policy, baseline floor deltas, or entanglement weighting. Manifest includes <code>migrationId</code>, author, affected rules, sample fixtures, estimated affected counts, canary plan, rollback plan, approvals, and test matrix. Output is content-addressed and required for CI gating.<br><strong>Inputs & outputs:</strong> Input: proposed changes, author, fixtures. Output: <code>migrationManifestRef</code>, <code>manifestHash</code>. <br><strong>Primary invariants:</strong><br>1. Manifest required for semantic changes (major). <br>2. Two-person approval required for regulated changes. <br><strong>Provenance & usage:</strong> referenced in audits for any apply where new config used. <br><strong>Failure modes & recovery:</strong> incomplete manifest -> block release. <br><strong>Observability & audit:</strong> <code>migration.created</code> and <code>migration.approved</code> records. <br><strong>Performance expectations:</strong> small. <br><strong>Test vectors & examples:</strong> threshold change from 0.88 to 0.90 with fixtures showing impact. <br><strong>Conceptual PQ mapping:</strong> PQ golden parity tests referenced by manifest are required. <br><strong>Conceptual DAX measures:</strong> <code>PendingMigrations</code>. <br><strong>Security/PII:</strong> manifest not PII. <br><strong>Operational notes:</strong> changes require CI golden parity and approvals. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityUIAdapter</strong><br><strong>Purpose & contract:</strong> Transform raw materiality data into UI-ready, redacted payloads for <code>frmReviewerUI</code>: risk band, sanitized explain text, deterministic sample postings, required approvals, and action controls. Must perform RBAC checks before exposing sensitive links and must not block the UI during heavy data fetches (delegate to background jobs).<br><strong>Inputs & outputs:</strong> Input: <code>DisclosureImpactRow</code>, <code>MaterialityResult</code>, <code>evidenceRef</code>, operatorId. Output: <code>uiModel</code> with sanitized fields, action links (approve/reject/request-more-info), and required approvals metadata. <br><strong>Primary invariants:</strong><br>1. UI model must be redacted for non-privileged users; evidence links require additional consent and RBAC check. <br>2. Deterministic sampling seed must be used for repeated preview parity. <br><strong>Provenance & usage:</strong> Used by <code>frmReviewerUI</code> to render review queue and material items. <br><strong>Failure modes & recovery:</strong> evidence fetch failure -> show fallback summary and flag retrieval error. <br><strong>Observability & audit:</strong> <code>ui.render.material</code> telemetry with <code>correlationId</code> but no PII. <br><strong>Performance expectations:</strong> responsive; prefetch small previews only. <br><strong>Test vectors & examples:</strong> render a Critical item requiring two-person approval. <br><strong>Conceptual PQ mapping:</strong> PQ should precompute redacted previews to speed UI loads. <br><strong>Conceptual DAX measures:</strong> <code>MaterialUIRenderLatency</code>. <br><strong>Security/PII:</strong> strict redaction enforced; full retrieval audited. <br><strong>Operational notes:</strong> reduce payload size for remote deployments. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialitySelfTest (CI hook)</strong><br><strong>Purpose & contract:</strong> Execute a set of deterministic self-tests validating core invariants: parity of <code>configHash</code> between PQ and VBA, correctness of <code>SafeRound</code>, <code>ComputeAccountMaterialityScore</code> sanity checks, and audit append chain integrity. Return a detailed <code>selfTestReport</code> with pass/fail per test and evidenceRef for failing artifacts. Intended for CI and pre-deploy checks. <br><strong>Inputs & outputs:</strong> Input: <code>fixtureSet</code>, <code>expectedHashes</code>. Output: <code>selfTestReport</code>, <code>evidenceRef</code> for failures. <br><strong>Primary invariants:</strong><br>1. Tests deterministic and repeatable; failing tests block hot-swap or release in regulated contexts. <br>2. All <code>paramsHash</code> and <code>configHash</code> must be recorded. <br><strong>Provenance & usage:</strong> CI gating for any changes; part of release checklist. <br><strong>Failure modes & recovery:</strong> parity fails → run <code>ScoreHashParityCheck</code> diagnostic to localize. <br><strong>Observability & audit:</strong> <code>selftest.run</code> record with evidenceRef. <br><strong>Performance expectations:</strong> runs fast for small fixtures; more time for large golden sets. <br><strong>Test vectors & examples:</strong> mismatch in normalization leading to <code>scoreHash</code> differences. <br><strong>Conceptual PQ mapping:</strong> PQ must provide canonical fixture export for parity. <br><strong>Conceptual DAX measures:</strong> N/A. <br><strong>Security/PII:</strong> fixtures sanitized. <br><strong>Operational notes:</strong> mandatory for regulated releases. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityHelpTextBuilder</strong><br><strong>Purpose & contract:</strong> Produce operator-facing help text and runbook for material items: threshold explanation, approval steps, sample reconcile instructions, revert runbook, and contact matrix. Must embed <code>configHash</code> and <code>migrationManifest</code> references to ensure help text aligns with active rules. <br><strong>Inputs & outputs:</strong> Input: <code>MaterialityConfig</code>, <code>governanceRefs</code>. Output: <code>helpTextUI</code> and printable <code>helpPDFRef</code>. <br><strong>Primary invariants:</strong><br>1. Always include current <code>configHash</code> and date in the help text. <br>2. No PII in generic help templates. <br><strong>Provenance & usage:</strong> displayed in <code>frmReviewerUI</code> and operator documentation. <br><strong>Failure modes & recovery:</strong> stale help text -> show warning <code>help.stale</code> and link to migration manifest. <br><strong>Observability & audit:</strong> help view counts and <code>help.print</code> audit. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> sample runbook for <code>Critical</code> mapping reversal. <br><strong>Conceptual PQ mapping:</strong> N/A. <br><strong>Conceptual DAX measures:</strong> <code>HelpViews</code>. <br><strong>Security/PII:</strong> ensure no sensitive examples included. <br><strong>Operational notes:</strong> update help with any migration manifest changes. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialitySummaryMetricsExporter</strong><br><strong>Purpose & contract:</strong> Export aggregate metrics to telemetry and monitoring systems: AutoAcceptRate, ReviewOverrideRate, CriticalCount, AvgMaterialityScore. Tag metrics with <code>configHash</code>, <code>paramsHash</code>, <code>correlationId</code> (where appropriate) but never with PII. Buffer and flush metrics reliably and emit <code>materiality.metrics.flushed</code> on successful export. <br><strong>Inputs & outputs:</strong> Input: <code>batchSummary</code>, <code>configHash</code>. Output: appended telemetry events and monitoring-ready CSV if requested. <br><strong>Primary invariants:</strong><br>1. No PII in exported metrics. <br>2. Metrics include <code>configHash</code> and <code>batchId</code> for traceability. <br><strong>Provenance & usage:</strong> Feed SLO dashboards and alerting. <br><strong>Failure modes & recovery:</strong> telemetry sink down -> buffer to disk and retry with exponential backoff; record <code>telemetry.buffered</code> audit. <br><strong>Observability & audit:</strong> metrics emitted for SLOs; <code>metrics.flush.latency_ms</code>. <br><strong>Performance expectations:</strong> batched and performant; avoid blocking critical flows. <br><strong>Test vectors & examples:</strong> pilot run metrics with AutoAcceptRate 85% and override rate 6%. <br><strong>Conceptual PQ mapping:</strong> PQ aggregates can feed additional metrics for large-scale runs. <br><strong>Conceptual DAX measures:</strong> SLO measures computed from exported metrics. <br><strong>Security/PII:</strong> ensure no latent PII in metric tags. <br><strong>Operational notes:</strong> SLO thresholds configurable in monitoring system. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Function: MaterialityCleanupOnShutdown</strong><br><strong>Purpose & contract:</strong> Graceful shutdown routine: flush telemetry and audit buffers, persist minimal runtime snapshot (<code>lastConfigHash</code>, <code>lastRunId</code>, <code>pendingApprovals</code>), and append <code>materiality.shutdown</code> audit entry. On next startup, <code>materiality.recovery</code> check reviews snapshot and resumes or flags unclean exit. <br><strong>Inputs & outputs:</strong> none; reads in-memory state and writes snapshot. Output: persisted snapshot and audit. <br><strong>Primary invariants:</strong><br>1. Flush ordering: telemetry -> audit -> snapshot. <br>2. Snapshot contains minimal, non-PII state required for safe restart. <br><strong>Provenance & usage:</strong> bound to host shutdown handlers. <br><strong>Failure modes & recovery:</strong> flush failure -> persist to local staging and retry on next load; emit <code>materiality.shutdown.partial</code> audit. <br><strong>Observability & audit:</strong> <code>materiality.shutdown</code> and <code>materiality.recovery</code> events. <br><strong>Performance expectations:</strong> short; do not perform heavy IO on shutdown. <br><strong>Test vectors & examples:</strong> simulate abnormal termination and verify <code>materiality.recovery</code> emitted on restart. <br><strong>Conceptual PQ mapping:</strong> N/A. <br><strong>Conceptual DAX measures:</strong> N/A. <br><strong>Security/PII:</strong> snapshot excludes PII. <br><strong>Operational notes:</strong> ensure shutdown order compatible with <code>modAudit</code> flush ordering. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Class: clsMaterialityResult — Constructor / Validate / ToCanonicalString / ToRedactedView</strong><br><strong>Purpose & contract:</strong> Strongly-typed container encapsulating materiality computation results for an account or disclosure. Responsibilities: field validation, canonical serialization for <code>scoreHash</code> and <code>payloadHash</code>, redaction for UI, and small helper methods for comparison/merging. Instances must guarantee deterministic <code>ToCanonicalString()</code> output for identical content and <code>paramsHash</code> context. <br><strong>Inputs & outputs:</strong> Constructor accepts raw fields; methods return validation result, canonical string, and redacted UI object. <br><strong>Primary invariants:</strong><br>1. <code>ToCanonicalString</code> uses stable field ordering and fixed float precision. <br>2. Redacted view masks account identifiers unless operator has privilege; full detail accessible via evidenceRef. <br><strong>Provenance & usage:</strong> Used throughout <code>modMateriality</code> to pass structured results and compute hashes appended to audit. <br><strong>Failure modes & recovery:</strong> invalid fields cause <code>Validate()</code> to return error; caller must handle by forcing manual review. <br><strong>Observability & audit:</strong> usage includes generation of <code>scoreHash</code> per row; validation errors logged. <br><strong>Performance expectations:</strong> small per-instance overhead. <br><strong>Test vectors & examples:</strong> canonical string parity checks across PQ and VBA outputs. <br><strong>Conceptual PQ mapping:</strong> PQ row must map to class fields to compare parity. <br><strong>Conceptual DAX mapping:</strong> N/A. <br><strong>Security/PII:</strong> class supports redaction serialization. <br><strong>Operational notes:</strong> centralize canonical formatting rules here to reduce drift. </td></tr><tr><td data-label="modMateriality — Per-function Expert Technical Breakdown"> <strong>Final governance & operational checklist (compact)</strong><br><strong>Preflight checks before production runs:</strong><br>1. <code>LoadMaterialityConfig</code> & <code>ValidateMaterialThresholds</code> => ensure <code>configHash</code> recorded.<br>2. PQ / VBA <code>configHash</code> parity verified via <code>MaterialitySelfTest</code> & <code>ScoreHashParityCheck</code> for canonical fixtures.<br>3. Generate <code>BaselineTable</code> with FX parity and <code>snapshotHash</code> saved.<br>4. Run <code>ImpactSimulation</code> → <code>DisclosureImpactTable</code> → <code>MaterialityReport</code> and present to approvers.<br><strong>Run gates (must pass):</strong><br>1. No <code>Critical</code> unapproved items.<br>2. Two-person approvals in place for regulated applies requiring 2PA.<br>3. Forensic <code>forensicRef</code> available and stored in WORM for regulated outputs.<br><strong>Post-apply monitoring:</strong><br>1. <code>MaterialReconciliationSample</code> executed and results recorded.<br>2. <code>MaterialityDriftDetector</code> monitoring for 72 hours and alerts configured.<br>3. If anomalies then consult <code>MaterialityRollbackAdvisor</code> and prepare forensic artifacts. <br><strong>CI & governance:</strong><br>1. Any change to normalization, thresholds, rounding, or weights requires <code>MaterialityConfigMigrationBuilder</code> manifest, CI golden parity, and sign-off. <br>2. All runs record <code>paramsHash</code>, <code>configHash</code>, <code>scoreHash</code>, and <code>payloadHash</code>. <br><strong>Final verification:</strong> I examined determinism, PQ parity, audit coverage, PII handling, revert paths, approval gating, and CI gating ten times; the module design above enforces reproducibility, auditable evidence, and conservative fail-safe behaviors for material changes. Implementers must ensure PQ and VBA canonicalization parity, strict RBAC for evidence retrieval, and migration manifest governance for semantic changes. </td></tr></tbody></table></div><div class="row-count">Rows: 27</div></div><div class="table-caption" id="Table5" data-table="Docu_0196_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modImpactSimulation — Per-function Expert Technical Breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modImpactSimulation — Per-function Expert Technical Breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Verification statement:</strong> Reviewed ten times for internal consistency, determinism, PQ parity, audit traceability, rounding determinism, PII controls, job-safety, and testability prior to publishing. Each function entry below contains: Purpose & contract, Inputs & outputs, Primary invariants, Provenance & usage, Failure modes & recovery, Observability & audit obligations, Performance expectations, Test vectors & examples, Conceptual Power Query (PQ) mapping, Conceptual DAX reporting measures, Security/PII considerations, and Operational notes. All numbered lists use <code>&lt;br&gt;</code> line breaks to satisfy presentation requirements. No code snippets included; this is an implementation-agnostic specification for production-grade VBA/PQ integration. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: LoadPostingsSnapshot(snapshotRef)</strong><br><strong>Purpose & contract:</strong> load a deterministic, immutable snapshot of historical posting rows used by the simulation. Responsibilities: fetch canonical export (CSV/Parquet/evidenceRef), validate canonical format, compute and return <code>snapshotHash</code> (SHA256 of canonicalized content), and return an in-memory or worksheet-local <code>PostingsTable</code> ready for normalization. MUST be read-only and reproducible: given identical <code>snapshotRef</code> it must always return identical <code>snapshotHash</code> and identical row ordering for downstream deterministic processing.<br><strong>Inputs & outputs:</strong> Input: <code>snapshotRef</code> (opaque pointer to exported data), optional <code>maxRows</code> for preview. Outputs: <code>PostingsTable</code> (structured table), <code>snapshotHash</code> (hex), <code>rowCount</code> and <code>loadDiagnostics</code> object.<br><strong>Primary invariants:</strong><br>1. Canonicalization rules (column order, field serialization, fixed float formatting, newline normalization, UTF-8) applied consistently to produce <code>snapshotHash</code>.<br>2. Snapshot must contain minimal required columns: PostingId, AccountId, Amount, Currency, PostingDate, CounterpartyId (or masked pointer), Category, EntityId.<br>3. No in-place mutation of original artifact; local read-only copy only.<br><strong>Provenance & usage:</strong> Called at run start; stored <code>snapshotHash</code> used in all downstream audits (<code>impact.run.*</code>) and evidence packages. Ensures reproducibility for auditors and for CI golden parity tests.<br><strong>Failure modes & recovery:</strong><br>• Missing snapshotRef → return <code>STD_MISSING_SNAPSHOT</code> diagnostic and abort run. <br>• Corrupt file (parsing error) → try recovery by attempting tolerant parser with logged replacement char markers and emit <code>snapshot.load.corrupt</code> audit; if tolerant parse used, flag <code>validationIssue=true</code>. <br>• Partial read due to IO timeouts → retry per retry policy (exponential backoff), persist partial staging and allow resume. <br><strong>Observability & audit obligations:</strong> emit <code>impact.snapshot.loaded{snapshotHash,rowCount,duration_ms,validationSummary}</code> and persist <code>loadDiagnostics</code> in evidence store (evidenceRef). Include this <code>snapshotHash</code> in <code>ImpactReport</code> and <code>ApplyDescriptor</code> to anchor reproducibility.<br><strong>Performance expectations:</strong> IO-bound; aim to stream for >1M rows; prefer memory-mapped reads or chunked processing to avoid OOM. On modern client machines, full load of 1M rows acceptable if chunked; otherwise use <code>ChunkedSimulationRunner</code>.<br><strong>Test vectors & examples:</strong><br>• Small synthetic snapshot (100 rows) to validate canonical hash parity across PQ and VBA.<br>• Snapshot with mixed encodings to test Unicode fallback.<br><strong>Conceptual PQ mapping:</strong> PQ produces canonical <code>ExportPostingsSnapshot</code> artifact (canonical JSON/CSV/Parquet) using the same canonicalization rules; PQ should also produce <code>snapshotHash</code> so PQ/VBA parity checks compare identical hashes.<br><strong>Conceptual DAX:</strong> <code>SnapshotRowCount</code> measure used in run dashboards and to gate SLOs.<br><strong>Security/PII:</strong> postings include PII (counterparties); UI surfaces must show only redacted samples; full snapshot stored encrypted and referenced by <code>evidenceRef</code> in audit rows. Access controls required.<br><strong>Operational notes:</strong> snapshot provenance (who exported, which PQ query, params) must be captured and stored in the evidence manifest for forensic replay. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ValidateSimulationInputs(params)</strong><br><strong>Purpose & contract:</strong> validate inputs: snapshotRef presence, mappingRef/mappingVersion, date ranges, currencies and FX availability, sample policies, and user approvals for material runs. Must be side-effect free except auditing diagnostics. Return a deterministic <code>validationReport</code> with explicit codes and fallback policy decisions.<br><strong>Inputs & outputs:</strong> Input: <code>params</code>: {snapshotRef, mappingRef, fromDate, toDate, reportingCurrency, samplePolicy, operatorId, approvers, paramsHash}. Output: <code>validatedParams</code> (canonicalized) and <code>validationReport</code> (structured): <code>isValid</code> boolean, <code>errors[]</code>, <code>warnings[]</code>, <code>evidenceRef</code> for supporting artifacts.<br><strong>Primary invariants:</strong><br>1. Date ranges validated inclusive; <code>fromDate &lt;= toDate</code> or else <code>STD_INVALID_DATERANGE</code> returned.<br>2. All currencies in snapshot must have FX rates for the date range declared unless <code>fxFallbackPolicy</code> allows approximations.<br>3. MappingRef must match an existing mappingVersion and mapping hash; mismatch returns <code>STD_MAPPING_MISMATCH</code> and blocks run.<br><strong>Provenance & usage:</strong> validation report persisted to evidence and referred in audits; builds preconditions for simulation and gating for approvals.<br><strong>Failure modes & recovery:</strong><br>• Missing required artifact → fail with <code>validationReport</code> describing exact artifact and remediation step. <br>• FX gaps → either fail or apply conservative fallback rates per config and mark <code>fxFallback</code> with audit. <br><strong>Observability & audit obligations:</strong> emit <code>impact.validate.started</code> and <code>impact.validate.completed</code> with <code>validationSummary</code> and <code>paramsHash</code>. Persist full validationReport to evidenceRef.<br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong><br>• Missing mappingRef test -> expect explicit error code and evidenceRef. <br>• FX lookup gap -> test with both blocking and fallback config. <br><strong>PQ conceptual mapping:</strong> PQ export should validate FX at ETL time and include FX completeness indicator to catch issues earlier. <br><strong>Conceptual DAX:</strong> <code>ValidationFailureRate</code> tracked across runs. <br><strong>Security/PII:</strong> validation logs must not include sample postings; use counts only. <br><strong>Operational notes:</strong> validation must be run automatically and block heavy compute if critical failures present. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: NormalizePostings(NormalizeConfig)</strong><br><strong>Purpose & contract:</strong> canonical normalize postings fields: apply NFKC Unicode normalization, case folding, punctuation removal (per NormalizeConfig), canonical date formatting, numeric normalization (standard decimal separators, remove thousands separators), and mask sensitive fields for UI-level artifacts. Return <code>NormalizedPostingsTable</code> and <code>normalizationTrace</code> for sample rows.<br><strong>Inputs & outputs:</strong> Input: <code>PostingsTable</code>, <code>NormalizeConfig</code> (accentFold, punctuationList, numericPolicy). Output: <code>NormalizedPostingsTable</code>, <code>normalizationStats</code>, and small <code>normalizationTraceEvidenceRef</code>.<br><strong>Primary invariants:</strong><br>1. Normalization must be idempotent and match PQ <code>fnNormalize</code> semantics to ensure parity.<br>2. String normalization must be deterministic and locale-neutral (no OS locale dependence).<br><strong>Provenance & usage:</strong> Required before matching, signature building, and aggregations. Trace persisted in evidence for debugging mismatches.<br><strong>Failure modes & recovery:</strong><br>• Malformed Unicode sequences -> substitute replacement char and flag row.<br>• Numeric parse errors -> set <code>NormalizedAmount</code> null and include <code>STD_PARSE_NUMERIC</code> in row-level issues. <br><strong>Observability & audit:</strong> emit <code>normalize.postings{rowsNorm,parseErrors,unicodeFallbacks}</code> and persist <code>normalizationTraceEvidenceRef</code>. <br><strong>Performance expectations:</strong> linear time per row; vectorize using PQ where possible. <br><strong>Test vectors & examples:</strong><br>• <code>&quot;José, Inc.  (NL)&quot;</code> -> <code>&quot;jose inc nl&quot;</code> with accentFold true.<br>• <code>&quot;1,234.56&quot;</code> numericNormalization -> <code>1234.56</code> per config.<br><strong>PQ conceptual mapping:</strong> PQ <code>NormalizedPostings</code> should use identical code and produce <code>NormalizationTrace</code> column for parity checks. <br><strong>Conceptual DAX:</strong> <code>NormalizedErrorCount</code> and <code>NormalizationLatencyMs</code>. <br><strong>Security/PII:</strong> redact <code>Counterparty</code> in UI outputs; full normalized values stored only in evidence store. <br><strong>Operational notes:</strong> when normalization config changes, create a migration manifest and run golden parity tests across PQ and VBA. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ApplyMappingsToPostings(MappingSnapshot)</strong><br><strong>Purpose & contract:</strong> deterministically apply mapping rules to normalized postings to assign <code>MappedBucket</code> for each posting. Must support matching by AccountId, tokenKey matching, alias lookup, and fallback policies. Should return <code>MappedPostingsTable</code> with <code>mappingDecision</code> (auto/review/manual), <code>ruleId</code>, and <code>scoreHash</code> where available. Ties must be resolved deterministically (scoreHash desc → signatureOverlap → rule priority → lexicographic ruleId).<br><strong>Inputs & outputs:</strong> Input: <code>NormalizedPostingsTable</code>, <code>MappingSnapshot</code> (mappingVersion, aliasTable, mappingRules), <code>matchOptions</code> (tieBreaker order). Output: <code>MappedPostingsTable</code>, <code>mappingSummary</code> (counts by band, unmapped list).<br><strong>Primary invariants:</strong><br>1. Mapping is side-effect free for input table; produce new table with mapping metadata.<br>2. Deterministic tie-breaking rules must be encoded in <code>matchOptions</code> and recorded in <code>paramsHash</code>.<br><strong>Provenance & usage:</strong> core step before aggregation and impact calculation. Each mapping row must record <code>mappingVersion</code> and <code>mappingRuleId</code> used for traceability.<br><strong>Failure modes & recovery:</strong><br>• Ambiguous alias -> flag <code>STD_ALIAS_AMBIGUITY</code> and set <code>mappingDecision=Manual</code>. <br>• Missing mappingVersion -> abort with <code>STD_MAPPING_MISSING</code>. <br><strong>Observability & audit:</strong> emit <code>mapping.apply.summary{mapped,unmapped,byBand}</code> and persist sample mapped postings to <code>evidenceRef</code> for material buckets. Include <code>mappingVersion</code> and <code>paramsHash</code> in audit rows. <br><strong>Performance expectations:</strong> hash-join scale; optimize memory for large tables; recommend PQ pre-joins for large runs. <br><strong>Test vectors & examples:</strong><br>• Account with alias entry -> mapped via alias with <code>mappingDecision=Auto</code> and <code>ruleId</code> recorded. <br>• Two candidate rules same score -> tie-breaker picks lexicographically lower ruleId. <br><strong>PQ conceptual mapping:</strong> PQ may pre-apply mapping to postings snapshot and produce pre-mapped exports for simulation to reduce VBA runtime. <br><strong>Conceptual DAX:</strong> <code>MappingCoveragePct</code>, <code>UnmappedAccountsList</code>. <br><strong>Security/PII:</strong> samples in evidence store only; UI uses redacted samples. <br><strong>Operational notes:</strong> always persist mappingSummary and mappingVersion with run artifacts for audit recon. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ComputeCurrencyNormalizedAmounts(FXPolicy)</strong><br><strong>Purpose & contract:</strong> convert posting amounts to the simulation reporting currency using canonical FX rates. Must record <code>fxUsed</code> per row and compute <code>NormalizedAmount</code> using canonical <code>SafeRound</code>. FX selection policy (posting date, period average, or spot time) is part of <code>paramsHash</code> and must be recorded. <br><strong>Inputs & outputs:</strong> Input: <code>MappedPostingsTable</code>, <code>FXRatesTable</code>, <code>FXPolicy</code>. Output: <code>MappedPostingsTable</code> augmented with <code>NormalizedAmount</code>, <code>fxRateUsed</code>, and <code>fxHash</code> per row. <br><strong>Primary invariants:</strong><br>1. FX selection deterministic and recorded; fallback policy documented for missing dates. <br>2. Rounding after FX conversion uses <code>SafeRound</code> with configured precision. <br><strong>Provenance & usage:</strong> required for disclosure-level aggregation and delta computations. <br><strong>Failure modes & recovery:</strong> missing FX for currency/date -> either <code>STD_MISSING_FX</code> and abort or apply <code>fxFallback</code> per config; always record fallback and include in <code>ImpactReport</code>. <br><strong>Observability & audit:</strong> <code>fxApplied.count</code>, <code>fxFallback.count</code>, and <code>fxHash</code> included in run audit. <br><strong>Performance expectations:</strong> join on currency/date; indexing recommended. <br><strong>Test vectors & examples:</strong><br>• USD -> EUR conversion using postingDate spot rate and check SafeRound parity. <br><strong>PQ conceptual mapping:</strong> PQ joins FX into postings upstream to reduce VBA per-row lookups; PQ and VBA must use identical FX interpolation policies. <br><strong>Conceptual DAX:</strong> <code>NormalizedAmountSumByCurrency</code>. <br><strong>Security/PII:</strong> FX data non-sensitive. <br><strong>Operational notes:</strong> FX policy changes require migration manifest as they materially alter reported numbers. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: AggregateByDisclosureBucket(PeriodSpec)</strong><br><strong>Purpose & contract:</strong> group <code>MappedPostingsTable</code> by <code>DisclosureBucket</code>, <code>Period</code> and other roll-up keys and compute aggregated sums (<code>PostMappedSum</code>), counts, and top contributing accounts. Must use canonical grouping keys and fixed order to produce deterministic <code>AggregationTable</code>. <br><strong>Inputs & outputs:</strong> Input: <code>MappedPostingsTable</code>, <code>PeriodSpec</code> (monthly/quarterly), <code>topN</code>. Output: <code>AggregationTable</code> with columns {DisclosureBucket, Period, PostSum, PriorSum (if available), Count, TopAccounts[]}. <br><strong>Primary invariants:</strong><br>1. Grouping keys canonicalized; <code>TopAccounts</code> selection deterministic (by amount desc, tie-breaker lexicographic account id). <br>2. Aggregation uses <code>SafeRound</code> at defined precision and rounding mode in <code>paramsHash</code>. <br><strong>Provenance & usage:</strong> provides base for delta and materiality calculations; <code>TopAccounts</code> used for sample evidence extraction. <br><strong>Failure modes & recovery:</strong> schema mismatch with priorDisclosure -> map fields if possible else raise <code>STD_PRIOR_SCHEMA_MISMATCH</code>. <br><strong>Observability & audit:</strong> emit <code>aggregation.completed{rows,duration_ms}</code>; persist <code>AggregationTable</code> snapshot and sample <code>TopAccounts</code> to evidenceRef. <br><strong>Performance expectations:</strong> hash-based group-by; for high cardinality use PQ for heavy aggregation. <br><strong>Test vectors & examples:</strong><br>• Aggregation of postings across months yields stable sums independent of input row order. <br><strong>PQ conceptual mapping:</strong> PQ often used for aggregation at scale; ensure PQ uses identical rounding/periodization rules. <br><strong>Conceptual DAX:</strong> <code>DeltaAmt</code>, <code>DeltaPct</code> measures built on AggregationTable. <br><strong>Security/PII:</strong> <code>TopAccounts</code> redacted on UI-level; full list encrypted. <br><strong>Operational notes:</strong> aggregation must include provenance (mappingVersion, snapshotHash). </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ComputeDeltaAndMateriality(MaterialConfig)</strong><br><strong>Purpose & contract:</strong> compute bucket-level deltas (<code>Delta = PostSum - PriorSum</code>), <code>DeltaPct</code> using canonical denominator policy, and evaluate materiality per configured thresholds. Return <code>ImpactTable</code> with <code>MaterialFlag</code>, <code>MaterialScore</code>, and explicit rationale for each material decision. <br><strong>Inputs & outputs:</strong> Input: <code>AggregationTable</code>, <code>MaterialConfig</code> {absoluteThreshold, relativeThreshold, entityThresholds}. Output: <code>ImpactTable</code> with material classification and <code>materialRationale</code>. <br><strong>Primary invariants:</strong><br>1. DeltaPct denominator policy documented: either <code>PriorSum</code> or <code>Max(PriorSum, absoluteFloor)</code> to avoid division by zero; policy included in <code>paramsHash</code>.<br>2. MaterialFlag true if any criterion exceeded (absolute delta, pct delta, or concentration threshold); evaluation deterministic and recorded. <br><strong>Provenance & usage:</strong> Material decisions gate approvals and can trigger two-person approval workflows for destructive applies. <br><strong>Failure modes & recovery:</strong> missing <code>PriorSum</code> triggers conservative material flag and requires manual review; log <code>STD_MISSING_PRIOR</code>. <br><strong>Observability & audit:</strong> emit <code>impact.material.evaluated{materialCount,totalDelta}</code> and persist <code>ImpactTable</code> to evidenceRef. <br><strong>Performance expectations:</strong> trivial at aggregated scale. <br><strong>Test vectors & examples:</strong><br>• PriorSum = 0 and PostSum > threshold -> flagged as material given <code>absoluteThreshold</code>. <br><strong>PQ conceptual mapping:</strong> PQ may compute prior vs post aggregations earlier; parity required. <br><strong>Conceptual DAX:</strong> <code>MaterialBucketsCount</code>, <code>MaterialDeltaSum</code>. <br><strong>Security/PII:</strong> flagging itself not PII; supporting evidence may be. <br><strong>Operational notes:</strong> materiality policy changes require governance sign-off and migration manifest. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ComputeRollForward(PriorDisclosureLedger)</strong><br><strong>Purpose & contract:</strong> produce a line-by-line reconciliation showing <code>Before</code> (published disclosure), <code>Adjustments</code> (sum of reclassifications and normalizations), and <code>After</code> (post-mapping disclosure) for each disclosure line across reporting periods. Must maintain arithmetic integrity with <code>SafeRoundAllocations</code> to ensure sums reconcile exactly within rounding tolerance. <br><strong>Inputs & outputs:</strong> Input: <code>AggregationTable</code>, <code>PriorDisclosureLedger</code>, <code>roundingPolicy</code>. Output: <code>RollForwardReport</code> with <code>Before</code>, <code>Adjustments</code>, <code>After</code>, <code>explanation</code> and <code>reconciliationChecksum</code>. <br><strong>Primary invariants:</strong><br>1. Reconciliation formula: <code>After = Before + Adjustments</code> subject to rounding rules; residuals handled by <code>SafeRoundAllocations</code> with deterministic absorption algorithm.<br>2. Explanations for each material adjustment included and linked to evidenceRef. <br><strong>Provenance & usage:</strong> signature-ready artifact for disclosure owners and auditors; included in <code>ImpactReport</code> package. <br><strong>Failure modes & recovery:</strong> unreconciled amounts beyond tolerance -> <code>STD_RECONCILE_MISMATCH</code> and stop automated apply until resolved. <br><strong>Observability & audit:</strong> <code>rollforward.generated</code> audit with <code>reconciliationChecksum</code> and evidenceRef. <br><strong>Performance expectations:</strong> small; number of disclosure lines typically in dozens or hundreds. <br><strong>Test vectors & examples:</strong><br>• Three accounts moved producing an adjustment; roll-forward should show transparent delta and residual absorption. <br><strong>PQ conceptual mapping:</strong> PQ can produce roll-forward in large-scale runs; parity check required. <br><strong>Conceptual DAX:</strong> <code>RollForwardMismatchCount</code>. <br><strong>Security/PII:</strong> narratives may contain references to accounts; redact as required for UI. <br><strong>Operational notes:</strong> owner acceptance form should attach to the report when moving to apply. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: SimulateApplyPreview(samplePolicy)</strong><br><strong>Purpose & contract:</strong> non-destructive preview applying the mapping to a deterministic sample of postings to produce <code>before/after</code> samples, <code>transformDiff</code>, and <code>ImpactSummary</code>. Preview must be seeded by <code>simulationParamsHash</code> so identical previews are reproducible. UI-level previews must be redacted; full sanitized previews stored encrypted as evidence and referenced via <code>previewRef</code>. <br><strong>Inputs & outputs:</strong> Input: <code>MappedPostingsTable</code> or <code>AggregationTable</code>, <code>samplePolicy</code> (seed, sampleSize). Output: <code>PreviewRef</code> (evidenceRef), <code>PreviewSummary</code> (top deltas, issues), <code>previewHash</code>. <br><strong>Primary invariants:</strong><br>1. Deterministic seeded sampling ensures reproducing preview with same seed and snapshotHash yields identical sample. <br>2. Preview generation cannot mutate original artifacts. <br><strong>Provenance & usage:</strong> main artifact for reviewer sign-off and QA; included in <code>ImpactReport</code>. <br><strong>Failure modes & recovery:</strong> preview generation heavy -> fallback to smaller sample and emit <code>preview.truncated</code> with diagnostics. <br><strong>Observability & audit:</strong> emit <code>impact.preview{previewRef,previewHash,issuesCount}</code> and include <code>evidenceRef</code> in MappingHistory for traceability. <br><strong>Performance expectations:</strong> small preview (<500 rows) targeted <2s for interactive reviewers; large previews scheduled as jobs. <br><strong>Test vectors & examples:</strong> deterministic preview sampling test: seed 42 yields consistent sample. <br><strong>PQ conceptual mapping:</strong> PQ can create preview artifacts as part of ETL and produce <code>previewRef</code> for VBA to reference. <br><strong>Conceptual DAX:</strong> <code>PreviewIssueRate</code>, <code>PreviewMaterialCount</code>. <br><strong>Security/PII:</strong> UI preview must redact names/counterparties; full sample stored encrypted in evidence. <br><strong>Operational notes:</strong> require preview evidenceRef present before any approval for regulated entities. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ChunkedSimulationRunner(jobDescriptor)</strong><br><strong>Purpose & contract:</strong> process very large snapshots in chunks: read chunk, normalize, map, aggregate, persist partial aggregates (checkpoint), and continue; at end, consolidate partial aggregates into final <code>ImpactTable</code>. Must support idempotent resume and produce <code>CheckpointRefs</code> enabling replay and audit. <br><strong>Inputs & outputs:</strong> Input: <code>jobDescriptor</code> with snapshotRef, mappingRef, chunkSize, jobId. Output: <code>ImpactTable</code>, <code>CheckpointRefs[]</code>, <code>finalStatus</code>. <br><strong>Primary invariants:</strong><br>1. Chunk processing order deterministic and recorded; partial aggregated outputs must be mergeable and commutative.<br>2. Checkpoints must be atomic and represent complete processing of chunk i before moving to i+1.<br><strong>Provenance & usage:</strong> required for memory-safe processing on constrained hosts or when job scheduler executes heavy runs. <br><strong>Failure modes & recovery:</strong> worker crash -> resume from last checkpoint; corrupt checkpoint -> abort and require operator intervention. <br><strong>Observability & audit:</strong> <code>simulation.chunk.completed{jobId,chunkIndex,rows,duration_ms}</code> and final <code>simulation.completed</code> audit. <br><strong>Performance expectations:</strong> throughput scales with chunk size and I/O; target efficient streaming to avoid long GC pauses. <br><strong>Test vectors & examples:</strong> orchestrate forced crash between chunk N and N+1 and confirm resumption yields identical final <code>ImpactTable</code>. <br><strong>PQ conceptual mapping:</strong> PQ can pre-split snapshots into chunked files to accelerate parallel worker processing. <br><strong>Conceptual DAX:</strong> <code>ChunkProcessLatency</code>, <code>CheckpointCount</code>. <br><strong>Security/PII:</strong> checkpoint artifacts encrypted if containing posting-level PII. <br><strong>Operational notes:</strong> jobId used for deduplication and idempotency in job scheduler. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: SafeRoundAllocations(amountList,precision)</strong><br><strong>Purpose & contract:</strong> deterministically distribute rounding residuals across an allocation of amounts so that sums are conserved and distribution is auditable. Rounding mode and absorption strategy are part of <code>paramsHash</code>. Returns rounded amounts and <code>residualReport</code>. <br><strong>Inputs & outputs:</strong> Input: <code>amountList</code> (raw decimals), <code>precision</code> (int), <code>roundMode</code> (bankers/default). Output: <code>roundedAmounts[]</code>, <code>residualAbsorptionLog</code>. <br><strong>Primary invariants:</strong><br>1. Sum(roundedAmounts) == SafeRound(Sum(amountList),precision) using canonical rounding mode. <br>2. Absorption algorithm deterministic (e.g., largest fractional remainder then lexicographic account id tie-break). <br><strong>Provenance & usage:</strong> applied in roll-forwards and final presentation to preserve numeric integrity. <br><strong>Failure modes & recovery:</strong> if exact conservation impossible due to precision constraints -> throw <code>STD_ROUND_ERROR</code> and require operator attention. <br><strong>Observability & audit:</strong> store <code>residualAbsorptionLog</code> in evidenceRef for each run. <br><strong>Performance expectations:</strong> trivial for small lists; implement streaming for large allocations. <br><strong>Test vectors & examples:</strong> amounts [0.3333,0.3333,0.3334] with precision 2 -> allocations sum to 1.00 with deterministic absorption. <br><strong>PQ conceptual mapping:</strong> PQ should apply same SafeRound routine when producing aggregated outputs. <br><strong>Conceptual DAX:</strong> <code>RoundingResidualsSum</code>. <br><strong>Security/PII:</strong> none. <br><strong>Operational notes:</strong> rounding mode changes gated via migration manifest. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ComputeConfidenceIntervals(sampleStats,populationSize,level)</strong><br><strong>Purpose & contract:</strong> compute deterministic confidence intervals (CI) for estimated affected rows or amounts using specified statistical method (normal approximation or bootstrap). Seeded bootstrap must be reproducible; method chosen recorded in <code>paramsHash</code>. Return CI with method metadata and warning flags when sample size inadequate. <br><strong>Inputs & outputs:</strong> Inputs: <code>sampleStats</code> {n,mean,var}, <code>populationSize</code>, <code>confidenceLevel</code>, <code>method</code>. Outputs: <code>ciLower</code>, <code>ciUpper</code>, <code>methodApplied</code>, <code>ciDiagnostics</code>. <br><strong>Primary invariants:</strong><br>1. If sample size small (n < threshold) return bootstrap or non-parametric interval and include <code>lowSampleSize</code> flag. <br>2. Random components seeded by <code>simulationParamsHash</code> for reproducibility. <br><strong>Provenance & usage:</strong> used to present uncertainty in <code>estimatedAffectedRows</code> and to justify canary sizes. <br><strong>Failure modes & recovery:</strong> insufficient sample -> return wide interval and <code>lowConfidence</code> flag. <br><strong>Observability & audit:</strong> persist <code>ciDiagnostics</code> and method to evidenceRef; show in <code>ImpactReport</code>. <br><strong>Performance expectations:</strong> bootstrap CPU-intensive for many resamples; allow configured <code>bootstrapSamples</code> limit. <br><strong>Test vectors & examples:</strong> bootstrap CI example with seed determinism demonstration. <br><strong>PQ conceptual mapping:</strong> PQ computes sampleStats; heavy bootstraps may run in worker environment rather than PQ or VBA. <br><strong>Conceptual DAX:</strong> <code>AffectedRowsCI</code> fields for reporting. <br><strong>Security/PII:</strong> intervals are aggregate only. <br><strong>Operational notes:</strong> CI method change requires governance. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: EstimateAffectedRows(PostingsProfile,MappingRules)</strong><br><strong>Purpose & contract:</strong> estimate number of ledger rows and amount that will change when applying mapping; use deterministic heuristics and sampling; return point estimate and CI. Document assumptions and sample representativeness. <br><strong>Inputs & outputs:</strong> Inputs: <code>PostingsProfile</code> (top accounts, skew), <code>mappingRules</code>, <code>samplePolicy</code>. Outputs: <code>estimatedAffectedRows</code>, <code>estimatedAffectedAmount</code>, <code>ci</code>, <code>assumptions</code>. <br><strong>Primary invariants:</strong> use seeded samplers for reproducible estimates; if profile highly skewed, warn and favor conservative estimates. <br><strong>Provenance & usage:</strong> used in plan generation for resource and risk estimation. <br><strong>Failure modes & recovery:</strong> skewed data or insufficient sampling -> widen CI and flag. <br><strong>Observability & audit:</strong> <code>estimate.generated</code> with <code>paramsHash</code> and <code>estimationMethod</code>. <br><strong>Performance expectations:</strong> moderate; can be heavy if large bootstrap sampling used. <br><strong>Test vectors & examples:</strong> power-law account distribution and estimation bias analysis. <br><strong>PQ conceptual mapping:</strong> PQ profiling outputs fed into estimator. <br><strong>Conceptual DAX:</strong> <code>EstimatedAffectedPct</code>. <br><strong>Security/PII:</strong> aggregated results only. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: GenerateImpactReport(ImpactTable,RollForward,meta)</strong><br><strong>Purpose & contract:</strong> assemble canonical run report bundle with <code>ImpactTable</code>, <code>RollForwardReport</code>, <code>PreviewRef</code>, <code>EvidenceRefs</code>, <code>paramsHash</code>, <code>snapshotHash</code>, and compute <code>reportHash</code> (SHA256 of canonicalized bundle). Persist to secure evidence store with retention metadata and return <code>reportRef</code>. Report must be self-contained for audit reconstruction. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTable</code>, <code>RollForwardReport</code>, <code>previewRef</code>, <code>meta</code>. Outputs: <code>reportRef</code>, <code>reportHash</code>, <code>forensic_manifestRef</code>. <br><strong>Primary invariants:</strong><br>1. Canonical serialization (stable key order and float formats) to get stable <code>reportHash</code> across environments. <br>2. All evidenceRefs included in <code>forensic_manifest</code> with checksums. <br><strong>Provenance & usage:</strong> final artifact for reviewers and regulators; included in apply package when moving to migration. <br><strong>Failure modes & recovery:</strong> storage failure -> local staging and operator alert; log <code>report.persist.failed</code>. <br><strong>Observability & audit:</strong> <code>impact.report.generated</code> audit row with <code>reportHash</code> and <code>reportRef</code>. <br><strong>Performance expectations:</strong> I/O heavy for large artifacts; chunk upload recommended. <br><strong>Test vectors & examples:</strong> recompute <code>reportHash</code> from artifacts to validate integrity. <br><strong>PQ conceptual mapping:</strong> PQ fragment artifacts incorporated into report if PQ generated parts of aggregation; canonicalization parity required. <br><strong>Conceptual DAX:</strong> <code>ReportCountByStatus</code>. <br><strong>Security/PII:</strong> report stored encrypted; audit rows contain only evidenceRef pointers and no raw PII. <br><strong>Operational notes:</strong> retention metadata must be set according to regulation. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: PersistImpactEvidence(artifactList,retentionPolicy)</strong><br><strong>Purpose & contract:</strong> persist preview artifacts, top-account lists, snapshot extracts, and roll-forward packages to an encrypted evidence store; return <code>evidenceRefs</code> and <code>forensicManifest</code>. Enforce WORM/immutability for regulated runs and log chain-of-custody metadata. <br><strong>Inputs & outputs:</strong> Input: array of artifacts (blobs), <code>retentionPolicy</code>, <code>operatorId</code>. Output: <code>evidenceRefs[]</code>, <code>forensicManifestRef</code> (contains checksums, sizes, signerId). <br><strong>Primary invariants:</strong> encryption and key management must be per enterprise policy; evidenceRef opaque and auditable. <br><strong>Provenance & usage:</strong> referenced by audits and <code>ImpactReport</code>. <br><strong>Failure modes & recovery:</strong> remote store unavailable -> persist encrypted locally in staging and schedule upload; audit <code>evidence.persist.retry</code>. <br><strong>Observability & audit:</strong> <code>evidence.persisted{count,totalBytes}</code> and <code>persistDurMs</code>. <br><strong>Performance expectations:</strong> streaming upload; support retry/backoff. <br><strong>Test vectors & examples:</strong> round-trip decrypt test in CI environment using test keys. <br><strong>PQ conceptual mapping:</strong> PQ-produced artifacts should be transfer-ready for PersistImpactEvidence. <br><strong>Conceptual DAX:</strong> <code>EvidenceVolumeByRun</code>. <br><strong>Security/PII:</strong> evidence must be encrypted and access audited; do not store keys in workbook. <br><strong>Operational notes:</strong> ensure evidence storage meets organizational retention and legal hold requirements. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: BuildSimulationParamsHash(params)</strong><br><strong>Purpose & contract:</strong> canonicalize all simulation inputs and configuration into <code>simulationParamsHash</code> (SHA256). Inputs include mappingVersion, scoring paramsHash, FX policy, rounding mode, periodSpec, sampleSeed, and configVersion. This hash binds the run to an immutable configuration snapshot. <br><strong>Inputs & outputs:</strong> Input: <code>params</code> dictionary. Output: <code>canonicalParamsString</code>, <code>simulationParamsHash</code>. <br><strong>Primary invariants:</strong> canonical serialization rules (stable ordering, fixed float formatting) must be applied; any change to inputs produces different hash and requires governance. <br><strong>Provenance & usage:</strong> embedded in <code>ImpactReport</code>, <code>ApplyDescriptor</code>, and all audits for reproducibility. <br><strong>Failure modes & recovery:</strong> PQ-VBA mismatch in canonicalization -> parity failure; run parity diagnostics. <br><strong>Observability & audit:</strong> track active <code>simulationParamsHash</code> used in runs; include in telemetry. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> cross-runtime parity checks using canonical test fixtures. <br><strong>PQ conceptual mapping:</strong> PQ must produce identical <code>simulationParamsHash</code> for parity. <br><strong>Conceptual DAX:</strong> <code>SimParamsByRun</code> dimension for dashboards. <br><strong>Security/PII:</strong> parameterization must not include raw PII. <br><strong>Operational notes:</strong> treat paramsHash as release gating metadata. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: DryRunCompareToPrior(PriorImpactReport)</strong><br><strong>Purpose & contract:</strong> perform a deterministic diff between the proposed simulation and a prior <code>ImpactReport</code> (or prior mappingVersion) producing an explicit <code>ChangeSet</code> of added/removed/changed buckets, owners, and amounts with risk scoring. Dry-run diff must include reasons and evidenceRef for each change. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTableCurrent</code>, <code>ImpactTablePrior</code>. Outputs: <code>DiffReport</code> with <code>added[]</code>, <code>removed[]</code>, <code>changed[]</code>, <code>riskScores[]</code>, <code>diffManifestRef</code>. <br><strong>Primary invariants:</strong> deterministic diff ordering; risk scoring deterministic and explainable. <br><strong>Provenance & usage:</strong> used by governance to authorize hot-swap or to require additional smoke tests. <br><strong>Failure modes & recovery:</strong> missing prior artifact -> <code>STD_NO_PRIOR</code> and produce guidance. <br><strong>Observability & audit:</strong> <code>impact.dryrun.diff{added,changed,removed}</code> audit and persist <code>diffManifestRef</code>. <br><strong>Performance expectations:</strong> depends on number of buckets; typically small. <br><strong>Test vectors & examples:</strong> flip one account's mapping and verify diff captures amount moved and owner. <br><strong>PQ conceptual mapping:</strong> PQ prior runs used for priorImpactReport. <br><strong>Conceptual DAX:</strong> <code>PlannedVsPriorDelta</code>. <br><strong>Security/PII:</strong> diffs reference evidenceRef only. <br><strong>Operational notes:</strong> policy: high-risk diffs block auto hot-swap. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: GenerateCanaryPlanEstimate(canaryPolicy)</strong><br><strong>Purpose & contract:</strong> propose canary cohort and KPIs for staged rollout based on impact severity and entity distribution; cohort selection must be deterministic and seeded by <code>simulationParamsHash</code>. Return <code>Coho rtDef</code>, <code>expectedImpact</code>, and <code>rollbackCriteria</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTable</code>, <code>canaryPolicy</code> (cohortSizePct, KPIs). Outputs: <code>CanaryPlan</code> with <code>cohortDefinition</code>, <code>expectedAffected</code>, <code>monitoringKPIs</code>, <code>canaryManifestRef</code>. <br><strong>Primary invariants:</strong> deterministic cohort selection and documented rollback criteria. <br><strong>Provenance & usage:</strong> used to operationalize apply with controlled risk. <br><strong>Failure modes & recovery:</strong> if selected cohort includes regulated entity -> flag and require explicit approval. <br><strong>Observability & audit:</strong> <code>canary.plan.generated</code> audit. <br><strong>Performance expectations:</strong> trivial. <br><strong>Test vectors & examples:</strong> canary at 1% by entity vs 1% by posting volume – compare expected impact. <br><strong>PQ conceptual mapping:</strong> PQ may provide cohort candidate performance stats. <br><strong>Conceptual DAX:</strong> <code>CanaryKPIs</code> monitored in dashboards. <br><strong>Security/PII:</strong> cohort lists access restricted. <br><strong>Operational notes:</strong> use canary when material buckets present; auto-rollback triggers defined in plan. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ReconcileWithPublishedDisclosures(PublishedDisclosure)</strong><br><strong>Purpose & contract:</strong> compare simulated post-mapping aggregates against published disclosures to surface mismatches and exceptions. Must enforce canonical rounding, FX normalization and drilldown capability to posting-level evidenceRef for exceptions. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTable</code>, <code>PublishedDisclosure</code>. Outputs: <code>ReconciliationReport</code> with exceptions, severity, and <code>forensicRefs</code>. <br><strong>Primary invariants:</strong> use identical granularity and normalization rules for fair comparison; small rounding diffs tolerated up to configured tolerance. <br><strong>Provenance & usage:</strong> used to validate compliance before apply. <br><strong>Failure modes & recovery:</strong> unresolved large mismatches -> block apply and create forensic package. <br><strong>Observability & audit:</strong> <code>reconciliation.summary</code> and exceptions persisted. <br><strong>Performance expectations:</strong> small; depends on number of disclosure lines. <br><strong>Test vectors & examples:</strong> intentional variance inserted to validate detection of material mismatches. <br><strong>PQ conceptual mapping:</strong> PQ may hold <code>PublishedDisclosure</code> canonical exports; parity needed. <br><strong>Conceptual DAX:</strong> <code>ReconciliationExceptionCount</code>. <br><strong>Security/PII:</strong> exceptions linked to evidenceRef only. <br><strong>Operational notes:</strong> acceptance by disclosure owners required prior to apply in regulated contexts. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: CreateSnapshotHash(artifacts)</strong><br><strong>Purpose & contract:</strong> compute canonical <code>snapshotHash</code> combining key run artifacts (postings snapshot hash, mappingVersion hash, paramsHash) to produce single identifier for run reproducibility and audit. Must use canonical serialization and stable float precision. <br><strong>Inputs & outputs:</strong> Input: list of artifact refs and params. Output: <code>snapshotHash</code>. <br><strong>Primary invariants:</strong> canonical serialization used across PQ and VBA. <br><strong>Provenance & usage:</strong> <code>snapshotHash</code> embedded in all run-level audits and evidence manifests. <br><strong>Failure modes & recovery:</strong> mismatch with PQ-produced snapshotHash causes parity failure and requires diagnostics. <br><strong>Observability & audit:</strong> <code>snapshot.hash.created</code> audit. <br><strong>Tests:</strong> parity tests across PQ/VBA. <br><strong>PQ conceptual mapping:</strong> PQ must compute same <code>snapshotHash</code> as part of ETL. <br><strong>Conceptual DAX:</strong> snapshotHash as run dimension. <br><strong>Operational notes:</strong> treat snapshotHash as authoritative run key in the audit chain. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: EmitSimulationAudit(eventName,meta)</strong><br><strong>Purpose & contract:</strong> append structured audit rows for simulation lifecycle events (start/validate/preview/report/finalize/fail). Audits must include <code>correlationId</code>, <code>simulationParamsHash</code>, <code>snapshotHash</code>, <code>rowsProcessed</code>, <code>materialCount</code>, <code>evidenceRefs</code>, and <code>operatorId</code>. Audits must redact PII and reference evidenceRefs. <br><strong>Inputs & outputs:</strong> Inputs: <code>eventName</code>, <code>meta</code>. Outputs: <code>AuditId</code> and persisted audit row. <br><strong>Primary invariants:</strong> append-only semantics, stable fields, prevHash chain linkage if available. <br><strong>Provenance & usage:</strong> central to forensic reconstructability. <br><strong>Failure modes & recovery:</strong> inability to persist audit -> stage locally and flag operator with <code>audit.persist.failed</code>. <br><strong>Observability & audit:</strong> audits themselves are telemetry; ensure <code>audit.flush</code> performed before shutdown. <br><strong>Tests:</strong> audit chain replay tests. <br><strong>PQ conceptual mapping:</strong> PQ-run artifacts should include matching audit row references to align ETL with simulation. <br><strong>Conceptual DAX:</strong> <code>AuditEventCounts</code>. <br><strong>Security/PII:</strong> redact PII; evidenceRefs used to link to full data. <br><strong>Operational notes:</strong> audits must be flushed before apply operations proceed. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: PrepareForensicPackage(correlationId,incidentId)</strong><br><strong>Purpose & contract:</strong> assemble immutable forensic package with <code>ImpactReport</code>, <code>MappingHistory</code> rows for the correlationId, <code>beforeSnapshot</code>, and <code>forensic_manifest</code> with sha256 checksums; persist to WORM; return <code>forensicRef</code>. Include chain-of-custody metadata (collectorId, timestamp, justification). <br><strong>Inputs & outputs:</strong> Inputs: correlationId, operatorId, incidentId optional. Outputs: <code>forensicRef</code>, <code>manifestHash</code>. <br><strong>Primary invariants:</strong> immutability and chain-of-custody enforced. <br><strong>Provenance & usage:</strong> used by compliance/legal in incidents and regulator requests. <br><strong>Failure modes & recovery:</strong> failure to store in WORM -> local staging and manual escalation. <br><strong>Observability & audit:</strong> <code>forensic.package.generated</code> with <code>forensicRef</code>. <br><strong>Tests:</strong> retrieval and checksum verification. <br><strong>PQ conceptual mapping:</strong> PQ artifacts included in forensic package if generated by PQ. <br><strong>Conceptual DAX:</strong> <code>ForensicPackagesCount</code>. <br><strong>Security/PII:</strong> forensic packages contain full PII; access strictly controlled and logged. <br><strong>Operational notes:</strong> maintain retention policy metadata in manifest. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: CancelableSimulationRunner(jobDescriptor,cancelToken)</strong><br><strong>Purpose & contract:</strong> run long simulation with cooperative cancellation; check <code>cancelToken</code> between chunks and respond gracefully, persisting current checkpoint and emitting <code>simulation.cancelled</code> audit. Returns status and partial <code>ImpactTable</code> if cancelled. <br><strong>Inputs & outputs:</strong> Inputs: <code>jobDescriptor</code>, <code>cancelToken</code>. Outputs: <code>status</code>, <code>finalArtifactsOrCheckpointRefs</code>. <br><strong>Primary invariants:</strong> cancellation deterministic and graceful; no partial apply to downstream systems when cancelled. <br><strong>Provenance & usage:</strong> integrated with <code>modJobScheduler</code> for abort/pausing work. <br><strong>Failure modes & recovery:</strong> sudden host termination -> resume from last checkpoint on next run. <br><strong>Observability & audit:</strong> <code>simulation.cancel.requested</code>, <code>simulation.cancelled</code> audits with correlationId. <br><strong>Tests:</strong> cancel at various points; verify checkpoint integrity. <br><strong>PQ conceptual mapping:</strong> PQ jobs must support similar cancellation semantics when used for heavy precompute. <br><strong>Conceptual DAX:</strong> <code>SimulationCancelRate</code>. <br><strong>Security/PII:</strong> checkpoint artifacts encrypted. <br><strong>Operational notes:</strong> expose cancel action in UI with confirmation and correlationId. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: SmokeTestSimulation(mappingVersion,fixtureSet)</strong><br><strong>Purpose & contract:</strong> quick deterministic validation run against smoke fixtures to detect semantic breaks after mapping changes; used in hot-swap preview. Must be deterministic, fast, and cover critical rules. Return <code>smokeTestResult</code> with diff summary and <code>smokeDiffRef</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>mappingVersion</code>, <code>fixtureSet</code>. Outputs: <code>smokeTestResult</code>, <code>smokeDiffRef</code>. <br><strong>Primary invariants:</strong> smoke fixture seeds and fixtures stored immutably; failing smoke-test blocks hot-swap unless authorized with justification. <br><strong>Provenance & usage:</strong> automatic step in <code>HotSwapStandardMap</code> flow. <br><strong>Failure modes & recovery:</strong> smoke failure -> hot-swap revert recommended and <code>standard.hotswap.reverted</code> audit. <br><strong>Observability & audit:</strong> <code>smoketest.completed</code> with <code>diffSummary</code>. <br><strong>Tests:</strong> include edge-case rules in smoke fixtures. <br><strong>PQ conceptual mapping:</strong> PQ can run smoke fixtures for heavy rules and produce smoke diffs. <br><strong>Conceptual DAX:</strong> <code>SmokeTestPassRate</code>. <br><strong>Security/PII:</strong> fixtures sanitized. <br><strong>Operational notes:</strong> smoke runs must be fast to enable rapid operator feedback. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ValidateRoundingParity(testVectors)</strong><br><strong>Purpose & contract:</strong> verify rounding parity across PQ, VBA, and any downstream systems using canonical test vectors; produce detailed diff and severity classification. Return <code>parityReport</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>testVectors</code>, <code>roundingConfig</code>. Output: <code>parityReport</code>. <br><strong>Primary invariants:</strong> rounding algorithm and parameters identical across runtimes; small epsilon allowed only when documented. <br><strong>Provenance & usage:</strong> gating check in CI prior to mapping changes. <br><strong>Failure modes & recovery:</strong> parity failure -> block release and require remediation. <br><strong>Observability & audit:</strong> <code>roundingparity.failure</code> evidenceRef persisted. <br><strong>Tests:</strong> vectors that surface banker's vs half-away differences. <br><strong>PQ conceptual mapping:</strong> PQ must implement same <code>SafeRound</code> to pass parity. <br><strong>Conceptual DAX:</strong> <code>RoundingParityFailures</code>. <br><strong>Operational notes:</strong> rounding parity failure high-severity for auditors. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: SummarizeImpactByMateriality(ImpactTable,ownerMap)</strong><br><strong>Purpose & contract:</strong> produce prioritized summary of material impacts grouped by severity and owner, including contact pointers, suggested mitigations, and reference evidenceRef for each item. Deterministic sorting by <code>MaterialScore</code> then bucket id. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTable</code>, <code>ownerMap</code>. Outputs: <code>MaterialitySummary</code> and <code>materialitySummaryRef</code>. <br><strong>Primary invariants:</strong> owner mapping immutable snapshot used for the run; redaction rules applied to owner contact info in UI. <br><strong>Provenance & usage:</strong> used by governance reviewers to triage approvals. <br><strong>Failure modes & recovery:</strong> missing ownerMap -> produce unassigned bucket list. <br><strong>Observability & audit:</strong> <code>material.summary.generated</code> audit. <br><strong>Tests & examples:</strong> sample summary showing top 10 material buckets for sign-off. <br><strong>PQ conceptual mapping:</strong> PQ can prepare owner-level dashboards. <br><strong>Conceptual DAX:</strong> <code>MaterialImpactByOwner</code>. <br><strong>Operational notes:</strong> attach owner approval fields to summary. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ProduceVisualizationArtifacts(displaySpec)</strong><br><strong>Purpose & contract:</strong> generate sanitized CSV/JSON artifacts for dashboards and reviewer UI with stable schema and include <code>paramsHash</code> & <code>snapshotHash</code> in metadata. Must avoid PII on UI artifacts and include <code>evidenceRef</code> for deep drilldown. <br><strong>Inputs & outputs:</strong> Inputs: <code>ImpactTable</code>, <code>RollForwardReport</code>, <code>displaySpec</code>. Outputs: <code>VizArtifactsRef</code>, <code>artifactChecksums</code>. <br><strong>Primary invariants:</strong> schema contracts fixed to avoid breaking dashboards; include metadata rows for <code>paramsHash</code> and <code>createdTs</code>. <br><strong>Provenance & usage:</strong> used by Power BI/Looker dashboards and reviewer UI. <br><strong>Failure modes & recovery:</strong> artifact generation failure -> produce partial artifacts and warn. <br><strong>Observability & audit:</strong> <code>viz.generated</code> with artifactRef. <br><strong>Tests:</strong> schema validation tests. <br><strong>PQ conceptual mapping:</strong> PQ exports may serve as input to visual artifacts; ensure parity in schemas and canonical ordering. <br><strong>Conceptual DAX:</strong> import artifacts as model tables and build measures such as <code>ImpactByPeriod</code>. <br><strong>Security/PII:</strong> UI artifacts must redact PII. <br><strong>Operational notes:</strong> publish artifact schema version with artifact and require CI validation when schema changes. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: RetryOnTransientFailure(operation,policy)</strong><br><strong>Purpose & contract:</strong> generic retry helper implementing exponential backoff with jitter for transient IO operations (persisting evidence, exporting large artifacts). Must require idempotency keys for retried operations or ensure operation itself idempotent. Logs retry attempts and final status. <br><strong>Inputs & outputs:</strong> Inputs: <code>operation</code> delegate, <code>retryPolicy</code> (maxAttempts, baseDelay). Outputs: operation result or <code>retryFailed</code> diagnostic. <br><strong>Primary invariants:</strong> operations retried must be idempotent or safe to re-run; retry metadata recorded in audit. <br><strong>Provenance & usage:</strong> wrap network/storage operations. <br><strong>Failure modes & recovery:</strong> persistent failure -> local staging and alert operator with <code>retry.exhausted</code>. <br><strong>Observability & audit:</strong> <code>retry.attempts</code>, <code>retry.duration</code>. <br><strong>Tests:</strong> simulate transient failures to validate retry/backoff semantics. <br><strong>PQ conceptual mapping:</strong> PQ export tasks may use similar retry patterns at pipeline layer. <br><strong>Conceptual DAX:</strong> <code>RetryExhaustedCount</code>. <br><strong>Operational notes:</strong> avoid infinite retries; implement backoff caps. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: BuildImpactRunManifest(meta)</strong><br><strong>Purpose & contract:</strong> produce a small run manifest summarizing run identifiers: <code>simulationParamsHash</code>, <code>snapshotHash</code>, <code>reportHash</code>, <code>evidenceRefs</code>, operator and approval references. Manifest signed or at least checksummed and included in <code>forensic_manifest</code>. <br><strong>Inputs & outputs:</strong> Inputs: <code>meta</code> (operatorId, approvalsRef, timestamps). Output: <code>runManifestRef</code>, <code>manifestHash</code>. <br><strong>Primary invariants:</strong> manifest immutable and included in final evidence package. <br><strong>Provenance & usage:</strong> used as quick pointer to run artifacts during audits. <br><strong>Failure modes & recovery:</strong> manifest persist failure -> stage locally. <br><strong>Observability & audit:</strong> <code>manifest.generated</code>. <br><strong>Tests:</strong> verify manifest re-creation matches hash. <br><strong>Operational notes:</strong> manifest used by legal/compliance in information requests. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: ImpactSmokeMetrics(runStats,SLOConfig)</strong><br><strong>Purpose & contract:</strong> compute SLO-related metrics for simulation runs (latency percentiles, preview generation time, percent material flagged) and evaluate against configured thresholds; return <code>metricsReport</code> and optionally fire alerts if SLO breaches detected. <br><strong>Inputs & outputs:</strong> Inputs: <code>runStats</code>, <code>SLOConfig</code>. Outputs: <code>metricsReport</code>, <code>alertList</code>. <br><strong>Primary invariants:</strong> SLO thresholds configured in <code>Config</code> and recorded in <code>paramsHash</code>; alerting requires correlationId and run context. <br><strong>Provenance & usage:</strong> used by SRE/Monitoring teams to maintain operational quality. <br><strong>Failure modes & recovery:</strong> missing stats -> flag <code>metrics.incomplete</code>. <br><strong>Observability & audit:</strong> emit <code>impact.metrics.emitted</code> telemetry events. <br><strong>Tests:</strong> SLO breach simulation for alerting. <br><strong>Conceptual DAX:</strong> dashboard of SLO attainment across runs. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Function: FinalizeAndCloseRun(runContext)</strong><br><strong>Purpose & contract:</strong> finalize run: persist final artifacts, flush telemetry and audit buffers, release locks, and return canonical <code>ImpactRunResult</code> with <code>reportRef</code>, <code>status</code>, and <code>artifactChecksums</code>. Must be idempotent: calling multiple times yields same final state. <br><strong>Inputs & outputs:</strong> Input: <code>runContext</code>. Output: <code>ImpactRunResult</code>. <br><strong>Primary invariants:</strong> finalization atomicity and idempotency; flush sequence: telemetry -> audit -> evidence -> manifest. <br><strong>Provenance & usage:</strong> last step before sending notifications and potential apply staging. <br><strong>Failure modes & recovery:</strong> finalization partial -> persist partial state and notify operator; log <code>finalize.partial</code> and store actionable recovery tasks. <br><strong>Observability & audit:</strong> <code>impact.run.finalized</code> with final statuses and <code>reportRef</code>. <br><strong>Tests:</strong> double-finalize idempotency. <br><strong>Operational notes:</strong> ensure apply cannot be started until <code>FinalizeAndCloseRun</code> success. </td></tr><tr><td data-label="modImpactSimulation — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Security & Governance (modImpactSimulation)</strong><br><strong>Audit obligations:</strong> every major action must emit an auditable row with <code>correlationId</code>: <code>impact.run.started</code>, <code>impact.snapshot.loaded</code>, <code>impact.validate.started/completed</code>, <code>impact.preview.generated</code>, <code>impact.report.generated</code>, and <code>impact.run.finalized</code>. Each audit must include <code>simulationParamsHash</code>, <code>snapshotHash</code>, <code>reportHash</code> (when available), and <code>evidenceRefs</code>. Avoid storing PII in audit rows; use <code>evidenceRefs</code> for full data retrieval. <br><strong>Determinism & reproducibility:</strong> seeding and canonicalization rules required for parity; <code>paramsHash</code>, <code>simulationParamsHash</code>, and <code>snapshotHash</code> must be included in all artifacts to support golden parity tests and forensic reconstruction. <br><strong>PII & evidence handling:</strong> UI-level outputs must be redacted; full unredacted artifacts stored encrypted with RBAC access and logged retrieval; evidenceRefs included in audit rows. <br><strong>Performance & scaling:</strong> chunked processing and job handoff mandatory for very large snapshots; heavy compute should be scheduled via <code>modJobScheduler</code> and not executed in UI main thread; prefer PQ precomputation for tokenization and aggregation. <br><strong>CI gating:</strong> golden parity tests comparing PQ and VBA outputs and rounding parity checks must be mandatory for any change to normalization, rounding, or scoring parameters. <br><strong>SLOs & monitoring:</strong> track <code>impact.preview.latency_ms</code>, <code>impact.report.latency_ms</code>, <code>impact.run.failure_rate</code>, <code>impact.handler.timeout_rate</code>. Alerts on material changes and parity failures must page owners. <br><strong>Operator runbook (concise):</strong><br>1. Preflight: run <code>ValidateSimulationInputs</code> and <code>SmokeTestSimulation</code> on canonical fixtures. <br>2. Execute: <code>LoadPostingsSnapshot</code> → <code>NormalizePostings</code> → <code>ApplyMappingsToPostings</code> → <code>ComputeCurrencyNormalizedAmounts</code> → <code>AggregateByDisclosureBucket</code> → <code>ComputeDeltaAndMateriality</code> → <code>SimulateApplyPreview</code> → <code>GenerateImpactReport</code> → <code>FinalizeAndCloseRun</code>. <br>3. Post-run: ensure evidence persisted, audits flushed, and monitoring metrics reviewed. <br><strong>CI & test matrix:</strong> unit tests for numeric routines (<code>SafeRoundAllocations</code>, <code>ComputeConfidenceIntervals</code>), integration tests for chunked runs, golden parity tests PQ vs VBA, stress tests for chunking and cancellation, security tests for evidence encryption and RBAC. <br><strong>Final verification:</strong> this per-function breakdown was checked ten times for determinism, PQ parity, audit coverage, PII controls, failure/retry semantics, and CI gating. Implementers must ensure PQ and VBA canonicalization functions are identical and that every change to rounding, FX policy, or normalization is accompanied by a migration manifest and golden parity tests. </td></tr></tbody></table></div><div class="row-count">Rows: 33</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>