<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771304656">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0179_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by REG_Audit — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">REG_Audit — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_REG_AUDIT (documented in OWNERS.md, included in release manifests and deployment notes).<br><strong>Public API:</strong> EmitAuditEvent, AppendAuditRow, AppendChainedAuditRow, ReadAuditTail, StreamAuditTail, QueryAuditRows, RotateAuditFiles, SignAuditRotation, VerifyAuditChain, CompactAuditTail, FlushAuditBuffer, ExportAuditBundle, ImportAuditBundle, AuditPrune, AuditRestoreFromBackup, AuditRetentionEnforce, EvidenceStorePut, EvidenceStoreGet, EvidenceStoreSeal, SerializeAuditState, RestoreAuditState, AuditReplayRun, AuditTailSnapshot, AuditTailReplay, AuditTailCheckpoint, AuditTailVerifyChecksum. <br><strong>Audits emitted by REG_Audit:</strong> audit.startup, audit.emit.attempt, audit.emit.completed, audit.append.chained, audit.rotate.started, audit.rotate.completed, audit.rotate.failure, audit.rotate.signing.started, audit.rotate.signing.completed, audit.verify.chain.start, audit.verify.chain.pass, audit.verify.chain.fail, audit.export.attempt, audit.export.completed, audit.prune.started, audit.prune.completed, audit.restore.attempt, audit.restore.completed. Every audit row emitted by REG_Audit also includes correlationId, module=REG_Audit, procedure, paramsHash, and resultHash where applicable. <br><strong>Purpose and intended use:</strong> provide a robust, append-only, auditable, provable audit ledger for add-ins and workers that touch regulated or sensitive data; ensure immutability in practice (append-only), tamper-evidence (chained hashes and signatures), durability (atomic persistence and rotation), and forensic replayability. Serve as the canonical source of operator actions, system transitions, and critical configuration changes consumed by compliance, SIEM, and incident response tooling. <br><strong>Non-goals / constraints:</strong> REG_Audit does not attempt to be a blockchain: it provides append-only, chained audit rows with rotation and signing rather than distributed consensus. REG_Audit does not store raw PII in top-level audit rows; large or sensitive payloads are stored encrypted in the EvidenceStore with evidenceRef links. Fast-path emits should be non-blocking for UI threads; heavy IO operations (rotation, signing, export) run on worker threads or scheduled jobs. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. <strong>Append-only invariant:</strong> once an audit row is accepted and persisted in a committed rotation, it shall never be altered in-place; only rotation with new signed batch appends is permitted. <br>2. <strong>Chained integrity:</strong> every audit row includes prevHash chaining within the active tail; rotation seals batches with a rotation header containing first/last hashes and a rotationChecksum. <br>3. <strong>Tamper-evidence:</strong> audit rotations are signed with the release manifest key and rotation manifest contains signatures; VerifyAuditChain must detect any modification. <br>4. <strong>Crash-safety:</strong> writes to audit_tail use AtomicWrite semantics: either the old tail remains visible or the new appended tail is fully visible. <br>5. <strong>UI thread safety:</strong> EmitAuditEvent and AppendAuditRow are non-blocking in UI contexts; they queue buffered audit rows and return synchronously; flush operations are asynchronous or scheduled. <br>6. <strong>Retention & archival invariants:</strong> retention rules must be enforced deterministically and verifiably; warm/cold rotations are moved to designated archives with proofs. <br>7. <strong>Performance SLOs:</strong> median EmitAuditEvent latency <5ms for in-memory enqueue; flush latency for background persistence <200ms on local filesystem; rotation signing throughput scaled to expected audit rates in CI. <br><strong>CI / acceptance gates:</strong> golden parity for chain construction, cross-language hash vectors, rotation signing tests, audit-emit performance tests, forbidden API static checks (no direct workbook writes in OnLoad). </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Global concepts & primitives used by functions:</strong><br><strong>AuditRow canonical shape (logical):</strong> <code>{timestamp, correlationId, module, procedure, operatorId?, paramsHash, payloadRef?, prevHash, rowHash, rotationId?, level, severity?, metadata}</code>.<br><strong>RowHash derivation:</strong> rowHash = SHA256( canonicalSerialize(rowWithoutRowHash) ) where canonicalSerialize uses deterministic field ordering (ASCII-order field names), UTF-8, and normalized numeric formatting.<br><strong>Chaining:</strong> prevHash = last rowHash of previous persisted row in active tail.<br><strong>Rotation header:</strong> <code>{rotationId, firstRowHash, lastRowHash, rowCount, rotationTs, rotationChecksum, rotationSignature?}</code>.<br><strong>EvidenceRef:</strong> pointer to encrypted evidence store artifact (e.g., evidence://hot/<module>/<correlationId>/<blobId>) where sanitized full params or large payloads reside.<br><strong>Tail state:</strong> in-memory queue <code>audit_buffer[]</code>, checkpointed tail file <code>audit_tail.csv</code> (append-only), rotated sealed batches <code>audit_rotation_&lt;ts&gt;.json</code>, and signature store <code>audit_rotation_signatures.json</code>.<br><strong>Security primitives:</strong> use RSA/ECDSA for rotation signatures (release manifest key), HMAC_SHA256 for evidenceRef validation, and optional hardware key (HSM) for production signing. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>EmitAuditEvent(event, level=&quot;INFO&quot;, operatorId=null, immediate=false)</code> — ingestion entrypoint</strong><br><strong>Purpose & contract:</strong> lightweight API for modules and UI handlers to emit auditable events. Must be non-blocking for UI flows when <code>immediate=false</code>. Each call enqueues a normalized audit row into <code>audit_buffer</code> and returns a descriptor <code>{queued=true, tempId}</code>. If <code>immediate=true</code> the call attempts synchronous persistence but may still return without waiting for remote rotation/signing. <br><strong>Parameters & return:</strong> <code>event</code> (structured map with <code>module</code>, <code>procedure</code>, <code>params</code> (optional), <code>metadata</code>), <code>level</code> in {"DEBUG","INFO","WARN","ERROR","CRITICAL"}, <code>operatorId</code> optional, <code>immediate</code> boolean. Returns <code>{queued, tempId, queuedAt}</code> or on immediate persist <code>{success, rowHash, durationMs}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Emitted rows must have canonical timestamp in ISO8601 UTC. <br>2. Top-level audit row must not contain raw PII; if <code>params</code> contain sensitive data, module must call EvidenceStorePut and replace <code>params</code> with <code>paramsHash</code> and <code>evidenceRef</code>. <br>3. EmitAuditEvent must compute paramsHash deterministically and include it in audit row. <br><strong>Algorithm & implementation notes:</strong><br>1. Canonicalize <code>event</code> to deterministic JSON (sorted keys, normalized numbers). <br>2. If <code>params</code> size > threshold or flagged sensitive -> EvidenceStorePut -> obtain evidenceRef. <br>3. Compute <code>paramsHash</code> = SHA256(canonicalParams) and drop raw <code>params</code> from row. <br>4. Create <code>row = {timestamp, correlationId (from context), module, procedure, operatorId, paramsHash, evidenceRef?, prevHash=null, rowHash=null}</code>. <br>5. prevHash filled by tail appender; enqueue to <code>audit_buffer</code>. <br><strong>Edge cases & invalid inputs:</strong><br>1. Missing <code>module</code>/<code>procedure</code> -> reject with error UTIL_AUDIT_INVALID_SCHEMA. <br>2. Large <code>params</code> but EvidenceStore disabled -> reject with UTIL_EVIDENCE_DISABLED. <br>3. Non-serializable <code>params</code> -> emit util.audit.emit.invalid_input and return structured failure. <br><strong>Observability & audit fields:</strong> emits <code>audit.emit.attempt(correlationId, module, procedure, paramsHash)</code> and <code>audit.emit.completed(correlationId, rowTempId, queued)</code>; if immediate persist -> <code>audit.emit.persisted(correlationId, rowHash, durationMs)</code>. <br><strong>Examples & narratives:</strong><br>1. UI control click: DQ_Ribbon handler calls EmitAuditEvent({module:"DQ_Ribbon", procedure:"profile.run", params:{table="Sheet1!A1:D100"}}, level="INFO", operatorId="alice") which enqueues row and returns tempId enabling caller to display a non-blocking confirmation. <br><strong>Tests & CI vectors:</strong> property tests for paramsHash parity; security tests ensuring PII not present; throughput tests for enqueue latency under synthetic load. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>AppendAuditRow(serializedRow)</code> — low-level append with chaining</strong><br><strong>Purpose & contract:</strong> accept a fully prepared canonical audit row (with <code>rowHash</code> computed or computed by the function) and append atomically to the current tail file, ensuring <code>prevHash</code> consistency and atomic persistence. Intended for background workers that flush <code>audit_buffer</code>. <br><strong>Parameters & return:</strong> <code>serializedRow</code> (canonical JSON string excluding <code>rowHash</code> or including it), optional <code>expectedPrevHash</code> for optimistic concurrency. Returns <code>{success, rowHash, persistedAt}</code> or error <code>{success:false, errorCode, diagnostics}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. If <code>expectedPrevHash</code> provided, and current tail lastHash != expectedPrevHash -> fail with UTIL_AUDIT_CONCURRENT_APPEND to avoid forked tails. <br>2. Append must be atomic; use AtomicWrite semantics for tail persistence. <br><strong>Algorithm & implementation notes:</strong><br>1. Lock tail append path using local file lock (advisory) or process-level append queue to avoid races. <br>2. Read last persisted rowHash (tail state file). <br>3. Set <code>serializedRow.prevHash = lastRowHash</code>. <br>4. Compute <code>rowHash = SHA256(serializedRow)</code> and set <code>serializedRow.rowHash = rowHash</code>. <br>5. Append to <code>audit_tail.csv</code> (append line) using AtomicWrite on a temporary tail file followed by replace to avoid partial tail visibility; alternative optimized path: open tail in append mode with O_APPEND and fsync. <br>6. Update in-memory tail state <code>lastRowHash</code> and checkpoint. <br><strong>Edge cases & invalid inputs:</strong><br>1. Disk full -> return UTIL_ATOMIC_WRITE_ENOSPC with diagnostics and keep the audit_buffer intact for retry. <br>2. Partial write detected -> run tail verification and attempt recovery from temp files using AtomicWriteRepair. <br><strong>Observability & audit fields:</strong> emits <code>audit.append.attempt(correlationId, tempId)</code> and <code>audit.append.completed(correlationId, rowHash, durationMs)</code>. <br><strong>Examples & narratives:</strong> background flush thread gathers N rows, calls AppendAuditRow for each in strict order to ensure deterministic chaining. <br><strong>Tests & CI vectors:</strong> concurrency tests simulating multiple flushers; disk-failure injection tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>AppendChainedAuditRow(payload, module, procedure, operatorId=null, level=&quot;INFO&quot;)</code> — convenience full path</strong><br><strong>Purpose & contract:</strong> higher-level helper that constructs canonical row, handles EvidenceStore interactions if needed, and appends with chaining in a single call (used by workers). Returns <code>{success, rowHash}</code>. <br><strong>Parameters & return:</strong> <code>payload</code> (structured), <code>module</code>, <code>procedure</code>, <code>operatorId</code>, <code>level</code>. Returns <code>{success, rowHash, persistedAt}</code> or error. <br><strong>Primary invariants (must/shall):</strong> identical to AppendAuditRow regarding chaining, PII policy. <br><strong>Algorithm & implementation notes:</strong> combines EmitAuditEvent and AppendAuditRow flow; used in worker flows where synchronous durability for emitted row is desired before proceeding. <br><strong>Edge cases & invalid inputs:</strong> same as EmitAuditEvent and AppendAuditRow. <br><strong>Observability & audit fields:</strong> emits <code>audit.append.chained(correlationId, module, procedure, rowHash)</code> on success. <br><strong>Examples & narratives:</strong> job scheduler persists jobDescriptor and emits AppendChainedAuditRow({jobId, paramsHash,...}, module="CORE_JobScheduler", procedure="job.persist"). This ensures the job persist is immediately auditable and chained for later forensic reconstruction. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>ReadAuditTail(fromHash=null, limit=1000, includePayloadRefs=false)</code> — read/query tail</strong><br><strong>Purpose & contract:</strong> read sequential audit rows from the tail starting after <code>fromHash</code> (if null, from head of tail) returning up to <code>limit</code> rows. Does not load encrypted evidence payloads unless <code>includePayloadRefs=true</code> and caller has proper authorization. Return stable page with <code>nextCursor</code> (lastRowHash). <br><strong>Parameters & return:</strong> <code>fromHash</code> (string), <code>limit</code> (int), <code>includePayloadRefs</code> (bool). Returns <code>{rows:[...], nextCursor, lastHash, count}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Results must reflect a stable snapshot at read start; if rotation occurs during read, the function ensures consistent ordering across rotation boundary by reading sealed rotations first then active tail. <br><strong>Algorithm & implementation notes:</strong><br>1. If <code>fromHash</code> lies in older rotation, locate rotation file and stream rows from that rotation and subsequent rotations up to active tail. <br>2. For active tail, read from <code>audit_tail.csv</code> starting after <code>fromHash</code>. <br>3. If <code>includePayloadRefs</code> true, include <code>paramsHash</code> and <code>evidenceRef</code> but do not retrieve evidence payloads. Evidence payloads fetched separately with EvidenceStoreGet (requires authorization). <br><strong>Edge cases & invalid inputs:</strong><br>1. <code>fromHash</code> unknown -> return UTIL_AUDIT_CURSOR_INVALID. <br>2. Limit excessive -> cap to configured max and annotate response. <br><strong>Observability & audit fields:</strong> emits <code>audit.query(correlationId, fromHash, limit, returnedCount)</code>. <br><strong>Examples & narratives:</strong> forensic tool calls ReadAuditTail(fromHash=r-...-checkpoint, limit=10000) to stream audit rows for a full run. <br><strong>Tests & CI vectors:</strong> cross-rotation reads, cursor parity tests, ordering invariants tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>StreamAuditTail(streamHandler, startFrom=null, filter=null)</code> — real-time tail streaming</strong><br><strong>Purpose & contract:</strong> subscribe to tail events in near-real-time (long-poll/stream); deliver new rows to <code>streamHandler</code> callback in canonical order. Suitable for monitoring, live dashboards, and SIEM ingestion. <br><strong>Parameters & return:</strong> <code>streamHandler</code> (callable accepting row objects), <code>startFrom</code> optional cursor, <code>filter</code> optional (module/procedure/level). Returns subscription object <code>{subscriptionId, resumedCursor}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Stream must deliver rows in strict tail order; no duplicates except in resume-after-fail scenarios where idempotent consumer must de-duplicate using rowHash. <br>2. Stream must support at-least-once delivery semantics; exactly-once is only achievable with consumer checkpoints and de-duplication. <br><strong>Algorithm & implementation notes:</strong><br>1. Provide SSE/WebSocket or persistent HTTP stream for host processes; on reconnection use <code>startFrom</code> cursor to resume. <br>2. Buffer tail reads and push to handlers; maintain backpressure limits and reject slow consumers after threshold with audit and metrics. <br><strong>Edge cases & invalid inputs:</strong> consumer not acknowledging checkpoints -> throttle or disconnect. <br><strong>Observability & audit fields:</strong> <code>audit.stream.subscribe(correlationId, subscriptionId, filter)</code>, <code>audit.stream.deliver(correlationId, subscriptionId, rowHash)</code>. <br><strong>Examples & narratives:</strong> SIEM connector uses StreamAuditTail(filter={module:"REG_Export"}) to ingest export.attempt/completed events for further correlation. <br><strong>Tests & CI vectors:</strong> stream reconnection and resume tests; backpressure handling tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>RotateAuditFiles(rotationPolicy, signerKeyRef=null, archiveDestination=null)</code> — rotate & seal</strong><br><strong>Purpose & contract:</strong> compact active tail into a sealed rotation file according to <code>rotationPolicy</code> (size-based, time-based, or hybrid), compute rotationChecksum, sign rotation with <code>signerKeyRef</code> if provided, and move sealed rotation to archiveDestination depending on retention stage. Rotation must be atomic and produce a <code>rotationManifest</code> referencing rotationId and signature. <br><strong>Parameters & return:</strong> <code>rotationPolicy</code> object, optional <code>signerKeyRef</code> (HSM or key reference), <code>archiveDestination</code> path. Returns <code>{rotationId, firstRowHash, lastRowHash, rowCount, rotationChecksum, signatureRef, archivePath}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Rotation must preserve chaining: the sealed rotation's firstRowHash must match the persisted prevHash in the first row recorded. <br>2. Rotation signing must use release manifest key in regulated contexts; signature must be appended to rotationManifest and stored in signature store. <br>3. Rotation operation must be idempotent when retried; detect already-rotated windows via rotationId collision detection and return existing rotation metadata rather than creating duplicates. <br><strong>Algorithm & implementation notes:</strong><br>1. Determine rotation window using policy (e.g., all rows older than <code>now - retentionHotWindow</code> or when <code>audit_tail.size &gt; maxTailSize</code>). <br>2. Atomically snapshot active tail up to rotation cutpoint into tempRotationFile. <br>3. Compute rotationChecksum = SHA256(concat(rowHashes)) or SHA256(tempRotationFile) and produce rotationManifest including first/last row hashes and rowCount. <br>4. If <code>signerKeyRef</code> present, sign rotationManifest (timestamped) producing rotationSignature. Store signature in <code>audit_rotation_signatures.json</code> and attach signatureRef. <br>5. Move tempRotationFile -> finalRotationPath and atomically truncate active tail (keeping rows after cutpoint). <br>6. Emit audit.rotate.started and audit.rotate.completed with rotation metadata. <br><strong>Cross-platform concerns & fallbacks:</strong><br>1. On filesystems with weak rename semantics, use two-phase commit with rotation state file and emit audit.rotate.degraded. <br>2. When HSM unavailable, fallback to encrypted signerKeyRef in local keystore with appropriate audit and operator approval for regulated environments. <br><strong>Recovery & runbook:</strong><br>1. On rotation failure after partial move, use rotation temp artifacts to either complete move or roll back. <br>2. Recompute rotationChecksum and compare with partial artifacts; if mismatch, mark rotation as suspect and quarantine. <br><strong>Observability & audit fields:</strong> <code>audit.rotate.started(correlationId, rotationId, firstRowHash, lastRowHash)</code> and <code>audit.rotate.completed(correlationId, rotationId, rotationChecksum, signatureRef, archivePath)</code>. <br><strong>Examples & narratives:</strong> nightly rotation consolidates that day's audit rows into <code>audit_rotation_2026-01-17.json</code> signed with release manifest key and pushed to warm archive. <br><strong>Tests & CI vectors:</strong> simulate concurrent rotations; cross-filesystem rename injection tests; signature validation suites. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>SignAuditRotation(rotationId, signerKeyRef)</code> — detached signature flow</strong><br><strong>Purpose & contract:</strong> create a detached cryptographic signature over the rotationManifest for <code>rotationId</code> using <code>signerKeyRef</code>. Signature stored separately and referenced from rotation manifest; supports key-rolling processes. <br><strong>Parameters & return:</strong> <code>rotationId</code>, <code>signerKeyRef</code>. Returns <code>{signatureRef, algorithm, signerId, signedAt}</code> or error. <br><strong>Primary invariants (must/shall):</strong><br>1. Signature must include canonical rotationManifest bytes and signer metadata. <br>2. Signature keys are managed by release manifest process and key rotation requires two-person approval for production. <br><strong>Algorithm & implementation notes:</strong><br>1. Retrieve rotationManifest for rotationId; canonicalize manifest; produce signature = Sign(manifest, signerKeyRef) and create signatureRef record with signature metadata and signer fingerprint. <br>2. Store signatureRef in <code>audit_rotation_signatures.json</code> and append an audit row <code>audit.rotate.signing.completed</code>. <br><strong>Edge cases & invalid inputs:</strong> missing rotationManifest -> UTIL_AUDIT_ROTATION_MISSING. <br><strong>Observability & audit fields:</strong> <code>audit.rotate.signing.started(correlationId, rotationId, signerId)</code> and <code>audit.rotate.signing.completed(correlationId, rotationId, signatureRef)</code>. <br><strong>Examples & narratives:</strong> CI pipeline signs rotation artifacts for canary release using ephemeral signing key and stores signatureRef in release manifest for traceability. <br><strong>Tests & CI vectors:</strong> signature verify golden vectors; key-rotation acceptance tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>VerifyAuditChain(earliestRotation=null, latestRotation=null)</code> — chain verification</strong><br><strong>Purpose & contract:</strong> deterministic verification procedure that validates every rotation between <code>earliestRotation</code> and <code>latestRotation</code> (or all rotations if null) for chaining integrity, rowHash correctness, rotationChecksum correctness, and signature validity. Returns a comprehensive verification report. <br><strong>Parameters & return:</strong> <code>earliestRotation</code> optional, <code>latestRotation</code> optional. Returns <code>{verified:true/false, report:{rotationChecks:[...], errors:[...], sampleRows:[...], verifiedAt}}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. VerifyAuditChain must be deterministic and idempotent; running it twice on same artifact set yields same report. <br>2. Any mismatch in rowHash, prevHash chaining, rotationChecksum, or signature must be surfaced with exact artifact paths and diagnostics. <br><strong>Algorithm & implementation notes:</strong><br>1. Iterate sealed rotations in chronological order; for each rotation: verify that concatenated row hashes compute to rotationChecksum, verify rows' rowHash fields recompute correctly, verify firstRowHash of rotation matches prevHash linkage from prior rotation lastRowHash, verify signature using stored signer public keys (release manifest). <br>2. For active tail, verify sequential rowHash/prevHash invariants. <br>3. Produce sparse sampleRows with canonicalSerialized rows for fast debug. <br><strong>Edge cases & invalid inputs:</strong><br>1. Missing signer public keys -> fail with UTIL_VERIFY_MISSING_KEYS and optionally mark rotation as unverifiable until key available. <br>2. Partially corrupted rotation files -> include byte-offset diagnostics. <br><strong>Observability & audit fields:</strong> emits <code>audit.verify.chain.start(correlationId)</code> and either <code>audit.verify.chain.pass(correlationId, checkedRotations)</code> or <code>audit.verify.chain.fail(correlationId, errors)</code>. <br><strong>Examples & narratives:</strong> pre-release CI runs VerifyAuditChain over all rotations produced during smoke runs to ensure no accidental tampering before canary rollout. <br><strong>Tests & CI vectors:</strong> mutation tests where single byte flipped in rotation file should cause verify to fail and CI to block the merge. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>CompactAuditTail(compactionPolicy)</code> — compress & compact active tail</strong><br><strong>Purpose & contract:</strong> reduce the active tail footprint by compacting older audit rows into more compact representations for storage while preserving full forensic replayability via evidenceRefs and rotation indexes. Must be reversible (i.e., compacted representation + evidence store allows full reconstruction). <br><strong>Parameters & return:</strong> <code>compactionPolicy</code> (ageThreshold, compressAlgo, chunkSize). Returns <code>{compactedRows, spaceSaved, compactManifestRef}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Compaction never removes data required to reconstruct full original audit rows; only compresses or externalizes large payloads to EvidenceStore. <br>2. Compaction steps must be idempotent and produce a compactManifest referencing original rowHashes. <br><strong>Algorithm & implementation notes:</strong><br>1. Select candidate rows older than <code>ageThreshold</code>. <br>2. For each row: move <code>evidenceRef</code> payloads to long-term EvidenceStore if not already moved; replace payload references with evidence fingerprints and compacted metadata (e.g., <code>compactedRef</code>). <br>3. Batch rows into compressed chunks using <code>compressAlgo</code> and store chunk artifacts in archive, creating <code>compactManifest</code> describing mapping from rowHashes -> chunkId + offset. <br>4. Atomically replace row block in tail with a compact pointer (preserving chaining with synthetic rowHash computed deterministically from compactManifest). <br><strong>Edge cases & invalid inputs:</strong> corruption in compacted chunk -> rollback compaction for affected chunk and mark for operator review. <br><strong>Observability & audit fields:</strong> <code>audit.compact.started(correlationId, candidateCount)</code>, <code>audit.compact.completed(correlationId, compactManifestRef, spaceSaved)</code>. <br><strong>Examples & narratives:</strong> compaction run converts six months of routine INFO-level audit rows into compressed monthly bundles while preserving high-severity rows intact. <br><strong>Tests & CI vectors:</strong> round-trip reconstruction tests; compactManifest integrity tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>FlushAuditBuffer(force=false, maxBatch=1000)</code> — immediate persistence of buffered rows</strong><br><strong>Purpose & contract:</strong> push <code>audit_buffer</code> rows to durable tail storage synchronously (used in graceful shutdown, critical checkpoints). When <code>force=false</code> the function may batch and defer non-blocking semantics. Returns <code>{flushedCount, elapsedMs}</code> or error on failure. <br><strong>Parameters & return:</strong> <code>force</code> bool, <code>maxBatch</code> int. <br><strong>Primary invariants (must/shall):</strong> flush must preserve order of rows during persistence. <br><strong>Algorithm & implementation notes:</strong><br>1. Acquire flush lock to avoid concurrent flushes. <br>2. Drain up to <code>maxBatch</code> rows from <code>audit_buffer</code>, call AppendAuditRow sequentially. <br>3. On partial failure, requeue remaining rows and return failure with diagnostics. <br><strong>Edge cases & invalid inputs:</strong> disk full -> flush returns ENOSPC with flushedCount and remainingCount. <br><strong>Observability & audit fields:</strong> <code>audit.flush.started(correlationId, batchSize)</code>, <code>audit.flush.completed(correlationId, flushedCount, elapsedMs)</code>. <br><strong>Examples & narratives:</strong> On Add-in shutdown hook, call FlushAuditBuffer(force=true, maxBatch=10000) to ensure ephemeral UI emits are persisted. <br><strong>Tests & CI vectors:</strong> shutdown flush tests, partial failure retry tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>ExportAuditBundle(rotationIds[], destination, options={compress:true, includeEvidence:false})</code> — atomic export of audit artifacts</strong><br><strong>Purpose & contract:</strong> produce an auditable export bundle containing specified rotation files, optional active tail snapshot, and optional evidence artifacts; export must be atomic and accompanied by bundleChecksum. Used for regulatory submissions and forensic transfers. <br><strong>Parameters & return:</strong> <code>rotationIds</code> array, <code>destination</code> (local path or remote URI), <code>options</code>. Returns <code>{bundlePath, bundleChecksum, artifactCount, exportedEvidenceCount}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Export must be atomic: either the bundle is fully written and checksum verified or not visible to consumers. <br>2. When including evidence and the evidence store is encrypted, ensure proper key references included and operator access controls enforced. <br><strong>Algorithm & implementation notes:</strong><br>1. Collect requested rotation files and optionally active tail snapshot. <br>2. If <code>includeEvidence</code>, fetch evidence payloads (authorized) and include them in a sealed <code>evidence/</code> directory, ensuring PII policies are observed; otherwise include evidenceRefs only. <br>3. Generate <code>bundleManifest.json</code> with file list, checksums, rotationManifests, and include signed exportMetadata if operator authorized. <br>4. Write to temporary bundle file and move to <code>destination</code> atomically using AtomicWrite semantics; compute SHA256 checksum and optionally sign bundleManifest. <br><strong>Cross-system concerns & fallbacks:</strong> when remote URI is network mount with weak guarantees, write to local staging then attempt staged upload; emit audit.export.degraded when fallback used. <br><strong>Observability & audit fields:</strong> <code>audit.export.attempt(correlationId, rotations, destination)</code> and <code>audit.export.completed(correlationId, bundlePath, bundleChecksum)</code>. <br><strong>Examples & narratives:</strong> regulator-requested export for quarter-end includes rotations for the quarter and evidence for specific correlationIds; bundle signed by release manifest key and uploaded via secure channel. <br><strong>Tests & CI vectors:</strong> export integrity tests, staged upload fallback tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>ImportAuditBundle(bundlePath, verifyOnly=true, acceptPolicy=null)</code> — import and verify exported bundles</strong><br><strong>Purpose & contract:</strong> ingest an exported audit bundle into a verification or ingest environment. When <code>verifyOnly=true</code> perform integrity and signature checks without installing into local archive. When <code>verifyOnly=false</code>, install inspected rotations and optionally evidence. Returns verification report and installed artifact refs if accepted. <br><strong>Parameters & return:</strong> <code>bundlePath</code>, <code>verifyOnly</code>, <code>acceptPolicy</code>. Returns <code>{verified, report, installedRefs}</code>. <br><strong>Primary invariants (must/shall):</strong> do not ingest bundles that fail signature or checksum checks unless operator override and documented acceptance policy present. <br><strong>Algorithm & implementation notes:</strong><br>1. Validate bundleChecksum and compare with <code>bundleManifest.json</code>. <br>2. Validate rotationManifests and signatures. <br>3. If <code>verifyOnly=false</code> and policy allows, install rotation files into local archive ensuring no chain collisions; if collisions detected, require operator manual resolution. <br><strong>Observability & audit fields:</strong> <code>audit.import.attempt(correlationId, bundlePath)</code> and <code>audit.import.completed(correlationId, installedRefs)</code>. <br><strong>Examples & narratives:</strong> security team imports third-party bundle for cross-organization audit verification; VerifyAuditChain run post-import. <br><strong>Tests & CI vectors:</strong> tampered bundle detection tests; signature verification negative tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>EvidenceStorePut(plaintextPayload, metadata, sensitivityLevel, retentionPolicy)</code> — encrypted evidence storage</strong><br><strong>Purpose & contract:</strong> store large or sensitive parameters and payloads outside top-level audit rows, returning an <code>evidenceRef</code> pointer and <code>payloadHash</code>. Evidence store encrypts payloads with tenant keys and stores metadata separately. EvidenceStore is access-controlled and audited. <br><strong>Parameters & return:</strong> <code>plaintextPayload</code> (bytes), <code>metadata</code> (json), <code>sensitivityLevel</code> (enum LOW/MEDIUM/HIGH/PII), <code>retentionPolicy</code>. Returns <code>{evidenceRef, payloadHash, storagePath}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Evidence payloads for PII must be encrypted at rest with keys rotated per policy and stored in the hot evidence store with tight ACLs. <br>2. <code>payloadHash</code> = SHA256(plaintextPayload) used to detect duplicates and for verification during export/import. <br><strong>Algorithm & implementation notes:</strong><br>1. Sanitize <code>metadata</code> (strip PII if necessary), compute payloadHash and evidenceFingerprint. <br>2. Encrypt payload using tenant key or HSM-wrapped KEK, store encrypted blob in evidence store path (hot/warm according to sensitivity). <br>3. Generate <code>evidenceRef = evidence://&lt;tier&gt;/&lt;module&gt;/&lt;correlationId&gt;/&lt;blobId&gt;</code> and return. <br><strong>Edge cases & invalid inputs:</strong> insufficient authorization -> UTIL_EVIDENCE_ACCESS_DENIED. <br><strong>Observability & audit fields:</strong> <code>util.rng.seeded</code> may appear in evidence flows when RNG state saved; emit <code>util.evidence.put(correlationId, evidenceRef, payloadHash)</code>. <br><strong>Examples & narratives:</strong> when EmitAuditEvent receives <code>params</code> containing full SQL text or PII, call EvidenceStorePut and replace params with paramsHash/evidenceRef in the audit row. <br><strong>Tests & CI vectors:</strong> evidence round-trip encryption/decryption tests; retention lifecycle tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>EvidenceStoreGet(evidenceRef, authorizeToken)</code> — retrieve evidence payload</strong><br><strong>Purpose & contract:</strong> fetch an encrypted evidence blob, verify authorization, and return decrypted payload in memory or stream to caller. Strict access controls and audit emission are required. <br><strong>Parameters & return:</strong> <code>evidenceRef</code>, <code>authorizeToken</code> (or operator context). Returns <code>{payload, payloadHash, metadata}</code> or error. <br><strong>Primary invariants (must/shall):</strong> access must be logged with <code>evidence.access</code> audit row showing operatorId and reason. Evidence payloads should not be returned to UI without PII masking unless operator authorized. <br><strong>Edge cases & invalid inputs:</strong> stale key -> attempt KEK rotation path or fail with UTIL_EVIDENCE_KEY_MISSING. <br><strong>Observability & audit fields:</strong> <code>audit.evidence.access(correlationId, evidenceRef, operatorId, reason)</code> emitted for every retrieval. <br><strong>Examples & narratives:</strong> Forensic investigator retrieves serialized RNG state using EvidenceStoreGet(evidenceRef) to perform deterministic replay. <br><strong>Tests & CI vectors:</strong> access control tests; encrypted key rotation tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>AuditPrune(policy)</code> — controlled deletion according to retention</strong><br><strong>Purpose & contract:</strong> evaluate retention policy and safely delete expired audit artifacts and evidence in compliance with retention windows (hot/warm/cold) while preserving forensic proofs (e.g., proof-of-delete records). Prune must be verifiable and produce <code>forensic_manifest.json</code> entries listing deleted artifacts and proofs. <br><strong>Parameters & return:</strong> <code>policy</code> object with retention windows and exclusions. Returns <code>{prunedArtifacts, proofOfDeleteRef, errors}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Deletions for regulated data must be performed only after the appropriate retention window and with required approvals; two-person approval required for regulated PII. <br>2. Proof-of-delete must include prior artifact checksum, operator approvals, and deletion timestamp, and be appended into secure deletion ledger. <br><strong>Algorithm & implementation notes:</strong><br>1. Evaluate candidate artifacts older than policy thresholds and not excluded by retention exceptions. <br>2. For each artifact, generate proof-of-delete record including artifactChecksum, artifactPath, and deletion metadata; optionally sign the proof using rotation signing key. <br>3. Remove artifact from store and move proof-of-delete to warm/cold archive with restricted ACLs. <br>4. Emit <code>audit.prune.completed</code> with counts and proofRef. <br><strong>Edge cases & invalid inputs:</strong> legal hold overrides -> skip prune and log <code>audit.prune.skipped</code>. <br><strong>Observability & audit fields:</strong> <code>audit.prune.started(correlationId, candidateCount)</code> and <code>audit.prune.completed(correlationId, prunedCount, proofRef)</code>. <br><strong>Examples & narratives:</strong> monthly prune run removes audit rotations older than 7 years except those marked by legal hold. <br><strong>Tests & CI vectors:</strong> legal hold tests; proof-of-delete signature checks. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>AuditRestoreFromBackup(backupManifest, restorePolicy)</code> — full forensic restore</strong><br><strong>Purpose & contract:</strong> restore audit rotations and evidence from backup archives into the live archive for forensic replay and investigation. Restore must be auditable and must not overwrite existing rotations unless operator explicitly allows. <br><strong>Parameters & return:</strong> <code>backupManifest</code>, <code>restorePolicy</code>. Returns <code>{restoredRefs, conflicts, report}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Restored artifacts must be verified against checksums and rotation signatures before being accepted. <br>2. On conflict (rotationId exists), create a parallel namespace and preserve both artifacts for forensic comparison. <br><strong>Algorithm & implementation notes:</strong><br>1. Validate backupManifest checksums and signatures. <br>2. Copy rotation files and evidence blobs into restore staging area and run VerifyAuditChain for the restored rotation set. <br>3. On success, import into live archive with new manifest entries and append <code>audit.restore.completed</code>. <br><strong>Edge cases & invalid inputs:</strong> corrupted backup -> abort restore and emit <code>audit.restore.failure</code>. <br><strong>Observability & audit fields:</strong> <code>audit.restore.attempt(correlationId, backupManifestRef)</code> and <code>audit.restore.completed(correlationId, restoredRefs)</code>. <br><strong>Examples & narratives:</strong> SRE restores a suspected-misbehaving rotation into staging for analysis without altering live archive. <br><strong>Tests & CI vectors:</strong> restore integrity tests; conflict resolution tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong><code>AuditReplayRun(correlationId, evidenceRefs[], options={dryRun:true, preserveOutputs:true})</code> — deterministic replay</strong><br><strong>Purpose & contract:</strong> reconstruct sequence of audit-triggered operations for a given <code>correlationId</code> by loading audit rows, fetching evidence payloads as required, restoring RNG states, and replaying deterministic modules (SafeRound, MatchMerge tie-breakers) to reproduce artifacts. Intended for forensic verification. <br><strong>Parameters & return:</strong> <code>correlationId</code>, <code>evidenceRefs</code>, <code>options</code>. Returns <code>{replaySuccess, differences:[...], outputs:[artifactRefs], proofRef}</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Replay must be deterministic given same audit rows, evidence payloads, and RNG serialized states; any divergence must be recorded with precise diff diagnostics. <br>2. Replay must not perform side-effects on production artifacts unless <code>preserveOutputs=false</code> and operator explicitly authorizes. <br><strong>Algorithm & implementation notes:</strong><br>1. Read audit rows for correlationId using ReadAuditTail; fetch EvidenceStore payloads; restore RNG states via DeterministicRNG.restore_state for seeded runs; run pipeline modules in deterministic order using canonical inputs. <br>2. Compute output artifact checksums and compare with original artifactChecksum recorded in audit rows. <br>3. Produce <code>replayReport</code> containing step-by-step hashes and divergence points if any. <br><strong>Edge cases & invalid inputs:</strong> missing evidence or missing RNG state -> replayFail with specific missing artifacts list. <br><strong>Observability & audit fields:</strong> <code>audit.replay.started(correlationId, runId)</code>, <code>audit.replay.completed(correlationId, runId, replaySuccess)</code>. <br><strong>Examples & narratives:</strong> Compliance team requests deterministic replay of <code>r-20260117-xyz</code> allocation run to validate allocation tie-break decisions; replay produces identical artifact checksums and is attached to the compliance package. <br><strong>Tests & CI vectors:</strong> deterministic replay regression tests; missing-evidence negative tests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (concepts & mapping)</strong><br><strong>Audit schema (canonical):</strong> timestamp, correlationId, module, procedure, operatorId (optional), paramsHash, evidenceRef (optional), prevHash, rowHash, rotationId (optional), severity, level, metadata object (duration_ms, attempts, artifactChecksum, tempPathList). Top-level audit rows must not contain raw PII. Evidence store must be referenced via evidenceRef with encrypted payloads. <br><strong>Key audit events produced by REG_Audit:</strong> audit.startup, audit.emit.attempt/completed, audit.append.chained, audit.flush.started/completed, audit.rotate.started/completed/failure, audit.rotate.signing.started/completed, audit.verify.chain.start/pass/fail, audit.export.attempt/completed, audit.import.attempt/completed, audit.compact.started/completed, audit.prune.started/completed, audit.restore.attempt/completed, audit.replay.started/completed. <br><strong>Representative ErrorCodes:</strong> AUDIT_APPEND_CONFLICT, AUDIT_TAIL_CORRUPT, AUDIT_ROTATE_SIGNATURE_MISSING, AUDIT_VERIFY_FAILED, AUDIT_EXPORT_ENOSPC, AUDIT_IMPORT_SIGNATURE_MISMATCH, EVIDENCE_ACCESS_DENIED, EVIDENCE_KEY_MISSING, AUDIT_PRUNE_LEGAL_HOLD, AUDIT_REPLAY_MISSING_EVIDENCE. Each error code maps to operator guidance used by REG_Error.SafeErrorToUser. <br><strong>Metric names and semantics:</strong> reg.audit.emit.latency_ms, reg.audit.append.rate, reg.audit.rotate.count, reg.audit.verify.fail_rate, reg.audit.export.latency_ms. Metrics buffered locally and uploaded by CORE_Telemetry in audited batches; utility functions must not perform remote exports in the fast path. <br><strong>Evidence policy:</strong> top-level audit rows store <code>paramsHash</code> only; full params stored encrypted in EvidenceStore and referenced by evidenceRef. PII must never appear in top-level audit fields or UI. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-language golden governance</strong><br><strong>Unit tests (must include):</strong><br>1. Append & chaining unit tests verifying rowHash/prevHash properties across single and batch appends.<br>2. Rotation tests: size/time-based rotations, signature generation, signature verification, rotation manifest parity. <br>3. ReadAuditTail cursor & resume tests covering rotation boundaries.<br>4. EvidenceStore encryption/decryption and access control tests.<br>5. Export/Import bundle integrity tests and signed bundle verification.<br>6. Prune & proof-of-delete tests including legal-hold overrides.<br><strong>Integration tests:</strong><br>1. End-to-end add-in flow: UI EmitAuditEvent -> background flush -> rotation -> sign -> VerifyAuditChain success. <br>2. Recovery scenarios: partial rotation, disk full, corrupted rotation files leading to expected alarms. <br>3. Deterministic replay: produce a pipeline artifact and verify replay produces identical artifact checksums. <br><strong>Property tests:</strong><br>1. Immutable chain property under random concurrent append scheduling. <br>2. Idempotence of rotation and signing operations under retry. <br><strong>CI golden gating:</strong><br>1. Golden vectors for rowHash computations and rotation signatures must match cross-language implementations (VBA/JS/Python/C#). <br>2. Static analyzer checks: forbid blocking IO in UI handlers, forbid inclusion of PII in top-level audit rows. <br><strong>Performance tests:</strong><br>1. EmitAuditEvent throughput and latency under stress. <br>2. Rotation signing throughput and signature verification latency. <br>3. Export bundling and staged upload overhead. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always call EmitAuditEvent for user actions, control clicks, and critical transitions. <br>2. Use AppendChainedAuditRow when a module requires immediate durable row persisted before proceeding. <br>3. Do not include raw PII in audit rows; use EvidenceStorePut and include evidenceRef. <br>4. Seed deterministic RNGs for operator-visible sampling and persist RNG state via EvidenceStore when needed for replay. <br><strong>Forbidden practices:</strong><br>1. Do not write audit rows directly to rotation files bypassing AppendAuditRow/RotateAuditFiles; static analyzer rejects such writes. <br>2. Do not serialize secrets or credentials into audit params; EvidenceStore only accepts sanitized payloads. <br>3. Do not skip signature verification in verifier workflows; failure to verify must abort import or flag as suspect. <br><strong>Code-review checklist:</strong> ensure audit emissions cover persistence flows, evidenceRef used for large/sensitive params, rotation signing hooks present, VerifyAuditChain tested in pipeline, and legal-hold exceptions are enforced at prune time. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable steps)</strong><br><strong>Audit tail corruption detection:</strong><br>1. Alert fires: audit.verify.chain.fail or <code>audit.append.verification_failed</code> observed in monitoring.<br>2. Immediately set audit reads to read-only and emit <code>audit.containment.action</code> with correlationId.<br>3. Collect <code>audit_tail.csv</code>, rotation files around failure window, <code>audit_rotation_signatures.json</code>, release manifest, and jobDescriptor files; compute checksums and produce <code>forensic_manifest.json</code>.<br>4. Run VerifyAuditChain in isolated forensic environment; attempt recovery using temp rotation artifacts if available. <br><strong>Atomic export ENOSPC runbook:</strong><br>1. Audit audit.export.failure with ENOSPC; inspect destination mount and df -h; identify available space and mount type. <br>2. If policy allows, stage export to local same-volume staging path and retry; compute and verify bundleChecksum. <br>3. If staging not possible, escalate to SRE with <code>forensic_manifest.json</code> and audit_tail. <br><strong>Signature mismatch triage:</strong><br>1. Identify rotationId and signerId from audit.rotate.signing.completed rows; fetch rotationManifest and signature. <br>2. Verify public key for signerId from release manifest; if missing, retrieve key material from key repository. <br>3. If signature still fails, isolate rotation and mark suspect; begin incident response with full forensic artefacts. <br><strong>Non-deterministic replay complaint triage:</strong><br>1. Pull audit.replay.* and util.rng.state_serialized audits; fetch serialized RNG state from EvidenceStore. <br>2. Replay in isolated environment using same evidence and RNG state; attach replay report to incident. <br><strong>Retention & prune disputes:</strong><br>1. If audit artifact was pruned unexpectedly, fetch proof-of-delete and review legal hold status and operator approvals in proof metadata. <br>2. If missing proof or malformed proof, escalate to compliance and SRE. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples (multiple scenarios)</strong><br><strong>Scenario 1 — Regulated end-of-period signature & submission (complete trace):</strong><br>1. Operator triggers <code>FinalizeQuarter</code> from REG_Ribbon; ribbon handler emits <code>EmitAuditEvent({module:&quot;REG_Ribbon&quot;,procedure:&quot;finalizeQuarter&quot;,params:{quarter:&quot;Q4-2025&quot;}}, operatorId=&quot;bob&quot;)</code> which returns tempId and queued status. <br>2. JobScheduler persists jobDescriptor using AppendChainedAuditRow({jobId, paramsHash,...}, module="CORE_JobScheduler", procedure="job.persist") ensuring the job persistence row is durably chained to audit tail. <br>3. Worker processes ledger, generates artifacts, calls AppendChainedAuditRow for <code>allocation.complete</code> including artifactChecksum and evidenceRef for the ledger snapshot. <br>4. Background rotation job picks up sealed rotations and calls RotateAuditFiles with <code>signerKeyRef</code> pointing to release manifest signing key. Rotation signed and moved to warm archive; audit.rotate.completed row emitted with signatureRef. <br>5. ExportAuditBundle invoked to assemble rotations for quarter-end submission; atomic export produces bundle and audit.export.completed emitted. <br>6. Release pipeline includes VerifyAuditChain in CI before regulatory submission; VerifyAuditChain passes and signatures validated. <br>7. Audit artifacts and export bundle are packaged in regulatory submission with <code>forensic_manifest.json</code> containing rotation checksums and signatureRefs. <br><strong>Narrative takeaways:</strong> full cryptographic chain from UI action → chained audit rows → rotation → signature → export produces a reproducible, verifiable regulatory package. <br><strong>Scenario 2 — PQ template injection forensic trace:</strong><br>1. PQ_Ribbon preview executes and calls EmitAuditEvent({module:"PQ_Ribbon", procedure:"pq_preview", params:{templateId:"t-123"}}, operatorId="carol"). <br>2. When operator injects template, PQ_Injector uses AppendChainedAuditRow to persist the injection event and persists the M artifact in AtomicWrite storage; audit includes artifactChecksum and evidenceRef linking to the M text. <br>3. If PQ template marked <code>requiresHighPrecision</code>, the injector delegates final numeric transforms to worker which uses SafeRound and persists final query/formula as audited artifact; audit rows include evidenceRef and deterministic RNG state if sampling occurred during preview. <br>4. Export and signature flows ensure injected templates used in regulated contexts are accounted for in release manifest. <br><strong>Narrative takeaways:</strong> ensure artifact checksums and evidenceRefs are included in audit rows so injections and template usage are traceable. <br><strong>Scenario 3 — DQ_Remediation deterministic replay:</strong><br>1. DQ_Rules identifies remediation proposals and calls AppendChainedAuditRow for <code>dq_proposal</code> including a paramsHash and evidenceRef containing sample before/after rows and RNG serialized state used for sampling. <br>2. If operator accepts proposal, DQ_Apply persists the reversible plan using AppendChainedAuditRow and AtomicWrite. <br>3. If operator disputes results, AuditReplayRun reconstructs the exact tie-break ordering and SafeRoundResiduals behavior using persisted RNG state and evidence snapshots; replay produces identical artifact checksums proving deterministic behavior. <br><strong>Narrative takeaways:</strong> deterministic RNG and persisted evidence are essential for resolving disputes. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — how REG_Audit principles map to PQ workflows (detailed conceptual mapping)</strong><br><strong>Context:</strong> PQ (Power Query M) environments vary in runtime behavior and lack direct strong guarantees for file-system atomicity and cryptographic signing; REG_Audit cannot run inside M but must be orchestrated by host add-ins and helpers. <br><strong>Patterns and recommendations:</strong><br>1. <strong>Audit emission for PQ actions:</strong> PQ_Ribbon or PQ_Injector must call EmitAuditEvent for preview, inject, refresh, and export steps. Where PQ cannot call host directly, parameterize M templates to return <code>previewSeed</code> and <code>previewChecksum</code> which host then captures and appends an audit row with EvidenceStorePut for large previews. <br>2. <strong>AtomicWrite mapping for PQ exports & injections:</strong> PQ templates produce artifacts that the host helper (signed XLAM or worker) persists via AtomicWrite to guarantee consumers never observe partial templates. The host then emits an AppendChainedAuditRow with artifactChecksum and evidenceRef. <br>3. <strong>DeterministicRNG mapping for PQ preview sampling:</strong> seed computed by the host (SeedFromCorrelation) passed into M templates as parameter; preview audit rows record the seed and mChecksum. For heavy sampling, perform sampling in worker using DeterministicRNG and persist RNG state via EvidenceStore; store evidenceRef in the audit. <br>4. <strong>Signature & export:</strong> Final export bundles for PQ templates (M + diagnostics) must be produced by the host helper and exported using ExportAuditBundle, signed, and then optionally injected into workbook with validated artifactChecksum matching audit. <br><strong>Operator narrative (PQ injection example):</strong><br>1. Operator previews template; PQ_Ribbon records preview audit with seed & mChecksum. <br>2. Operator injects; host helper persists M artifact atomically and emits audit containing artifactChecksum; workbook injection uses the same artifact to ensure audit parity. <br><strong>Governance note:</strong> for regulated templates require signed template manifests and host-side AtomicWrite for authoritative injection. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping REG_Audit to DAX & semantic model design (detailed conceptual mapping)</strong><br><strong>Context:</strong> DAX runs in analysis/visualization layer and cannot perform durable side-effects or sign artifacts. Audit responsibility remains with ETL/worker layer. <br><strong>Patterns & recommended practices:</strong><br>1. <strong>Push authoritative state to ETL:</strong> any rounding, allocation, or reconciliation decisions that must be auditable should be done in ETL and persisted as audited artifacts (with artifactChecksum) referenced by model. DAX can read these artifacts and show <code>RunMetadata</code> info for provenance. <br>2. <strong>Model metadata linkage:</strong> ETL writes a <code>RunMetadata</code> table atomically with fields <code>correlationId</code>, <code>artifactChecksum</code>, <code>rotationId</code>, <code>runTs</code>; DAX reports use that table to show dataset provenance to users. <br>3. <strong>Deterministic sampling surfaced via model:</strong> ETL persists sample selection decisions and RNG seed used; DAX can surface selection fraction and sample seed for operator reference. <br>4. <strong>DAX reconciliation indicators:</strong> ETL produces reconciliation artifacts and appends <code>audit.reconciliation.completed</code> into REG_Audit; model surfaces reconciliation status by comparing <code>RunMetadata.artifactChecksum</code> to expected checksum recorded in model. <br><strong>Narrative example (DAX interplay with REG_Audit):</strong><br>1. Worker writes reconciled table and persists audit rotation + artifactChecksum. <br>2. Model <code>RunMetadata</code> includes artifactChecksum and correlationId; DAX measure <code>IsReconciled</code> compares current artifactChecksum with expectedChecksum and provides visual validation. <br><strong>Governance guidance:</strong> do not perform irreversible allocation logic in DAX; DAX is a read-only surface for provenance and verification. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded)</strong><br><strong>Minimum forensic artifacts to collect for an incident:</strong><br>1. <code>audit_tail.csv</code> and <code>audit_rotation_*.json</code> covering time window for correlationId. <br>2. <code>audit_rotation_signatures.json</code> and release manifest with signing keys/fingerprints. <br>3. <code>jobDescriptor.json</code> persisted via AppendChainedAuditRow with jobId and paramsHash. <br>4. Evidence blobs referenced by evidenceRefs (serialized RNG state, SafeRound inputs, canonical decimals). <br>5. <code>forensic_manifest.json</code> enumerating artifact URIs and checksums. <br>6. Trace logs from CORE_Bootstrap and add-in loader. <br><strong>Evidence storage & retention patterns:</strong><br>1. Hot evidence store: <code>\\evidence\hot\&lt;module&gt;\&lt;correlationId&gt;\</code> for 30 days; access controlled and audited. <br>2. Warm archive: secure archive for 7 years with restricted access and rotation signing. <br>3. Cold archive: per regulatory requirement (e.g., 10+ years) with chain-of-custody metadata. <br><strong>Retention cadence:</strong> monthly verification job emits <code>audit.housekeeping</code> and rotates evidence per retention rules; proofs-of-delete stored in secure archive with signed manifests. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before REG_Audit release (detailed)</strong><br>1. OWNERS.md lists owners and approvers. <br>2. API stability documented and versioned; backward compatibility tests passing. <br>3. Audit emit hooks in all modules validated in integration tests. <br>4. Cross-language golden vectors for rowHash and rotation signatures passing. <br>5. EvidenceStore encryption, key rotation, and access controls tested. <br>6. VerifyAuditChain acceptance tests and negative tamper detection tests. <br>7. CI static checks enforce forbidden patterns (no blocking IO on UI). <br><strong>Blocking conditions:</strong> missing audit emits on persistence flows, failed golden parity, missing signing key in release manifest, or legal-hold liveness failures. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & scripts (explicit, conceptual)</strong><br><strong>Unit tests:</strong><br>1. RowHash parity and canonical serialization tests across languages. <br>2. Append concurrency tests with advisory locks and O_APPEND modes. <br>3. EvidenceStore encryption/decryption and key rotation tests. <br>4. Rotation signing and signature verification tests (positive & negative). <br><strong>Integration tests:</strong><br>1. End-to-end UI -> EmitAuditEvent -> background flush -> rotation -> sign -> VerifyAuditChain. <br>2. Export/Import bundle roundtrip within CI environment. <br><strong>Property tests:</strong><br>1. Chain immutability under random insert/delete fault injections. <br>2. Deterministic replay property for sampled flows. <br><strong>Performance tests:</strong><br>1. EmitAuditEvent throughput under 10k rps synthetic load. <br>2. Rotation signing throughput with RSA/ECDSA keys. <br><strong>CI gating:</strong> all unit, integration, golden, and property tests must pass; any signature or hash mismatches block merges. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (concise and prescriptive)</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-abc</code> — collects <code>audit_tail.csv</code>, rotations, serialized RNG states, and <code>forensic_manifest.json</code>. <br>2. <code>audit rotate --now --signer &lt;keyRef&gt;</code> — perform on-demand rotation and signing. <br>3. <code>audit verify --range &lt;startRotation&gt;-&lt;endRotation&gt;</code> — run VerifyAuditChain for rotation range and produce verification report. <br>4. <code>audit export --rotations r1,r2 --dest /tmp/export.tar.gz</code> — atomic export of specified rotations. <br>5. <code>audit replay --correlation r-... --dry-run</code> — deterministic replay for forensics. <br><strong>When to call SRE:</strong> after two <code>AUDIT_EXPORT_ENOSPC</code> retries for critical exports, or when VerifyAuditChain reports signature verification failures for regulated rotations. Provide <code>forensic_manifest.json</code> and <code>audit_tail</code> in SRE ticket. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Final governance & mandatory constraints (firm):</strong><br>1. No artifact consumed by other processes may be produced without an audit append (EmitAuditEvent/AppendChainedAuditRow). <br>2. Always persist paramsHash and evidenceRef for large/sensitive data; raw PII must never appear in top-level audit rows. <br>3. Use AtomicWrite for all audit-tier artifacts to avoid partial-read exposure. <br>4. Seed deterministic RNGs from correlationId for operator-visible sampling; persist RNG state when exact replayability is required. <br>5. Rotation signatures must use release manifest keys in regulated contexts; key rotation requires two-person approval. <br>6. CI must run VerifyAuditChain on smoke rotations before canary rollout. <br><strong>Checked:</strong> cross-cutting invariants, audit coverage, deterministic chain from UI → jobDescriptor → worker → audit rotations and signature; verified conceptual compliance and internal consistency. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive)</strong><br><strong>Fields required for REG_Audit rows:</strong> timestamp, correlationId, module, procedure, operatorId (optional), paramsHash, evidenceRef (optional), prevHash, rowHash, rotationId (optional), configHash, ribbonMapHash (where relevant), metadata object (duration_ms, attempts, artifactChecksum, tempPathList). <br><strong>Policy note:</strong> top-level audit rows must not include PII; sanitized full params stored encrypted in EvidenceStore and referenced by evidenceRef. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded)</strong><br><strong>Failure mode: partial tail write visible to readers</strong><br>1. Likely cause: naive append without fsync or direct in-place writes. <br>2. Mitigation: use AtomicWrite semantics or O_APPEND + fsync patterns; implement tail verification on startup and rotate suspect tails into quarantine. <br><strong>Failure mode: missing signatures on rotations</strong><br>1. Likely cause: signerKeyRef unavailable or HSM offline. <br>2. Mitigation: have emergency offline signing procedure with multi-person approvals; mark rotation as <code>unsigned</code> and quarantine until signature restored. <br><strong>Failure mode: non-deterministic replay outcomes</strong><br>1. Likely cause: RNG seed not persisted or evidence missing. <br>2. Mitigation: require DeterministicRNG seed persisted via EvidenceStore when sampling is operator-visible. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit)</strong><br>1. PR must include unit & integration tests for changes. <br>2. Any change to rotation format or hash algorithm requires migration manifest and owner approvals. <br>3. Key management changes require SRE & security sign-off and CI golden re-signing. <br>4. Audit emission must be present for all persistence changes. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix D — Incident reconstruction example (ordered forensic steps)</strong><br><strong>Scenario:</strong> operator reports "Mismatch between exported artifact checksum and audit record for run <code>r-20260112-455</code>".<br><strong>Forensic reconstruction steps:</strong><br>1. Retrieve <code>audit.append</code> and <code>audit.export.completed</code> rows for correlationId; extract artifactChecksum and rotationId. <br>2. Pull rotation file containing the <code>allocation.complete</code> row and compute rowHash; compare with recorded rowHash. <br>3. Fetch EvidenceStore blobs referenced by evidenceRef (operator must authorize). <br>4. Run AuditReplayRun with evidence payloads and serialized RNG states; compute artifact checksum and compare with original export artifactChecksum. <br>5. If mismatch persists, inspect <code>audit.atomic_write.verification_failed</code> rows and temp artifact files for corruption evidence. <br>6. Produce <code>forensic_manifest.json</code> containing artifact paths and checksums and escalate to compliance if regulated. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ & DAX quick checklists for template authors and report builders</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> in template metadata and record preview seed in preview audit. <br>2. Mark <code>requiresHighPrecision</code> when template depends on canonical rounding; offload final numeric aggregation to worker SafeRound. <br>3. Parameterize seed for preview and persist seed in preview audit. <br>4. Use EvidenceStore for large payloads referenced in audit rows. <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> table for artifact provenance and <code>artifactChecksum</code>. <br>2. Avoid allocation logic in DAX; use ETL persisted artifacts for allocation and rounding. <br>3. Use hashed stable keys for deterministic sampling filters surfaced by ETL. </td></tr><tr><td data-label="REG_Audit — Per-function Expert Technical Breakdown"> <strong>Final operational constraint (must not be bypassed):</strong><br>All processes that produce artifacts consumed by other processes must: persist job descriptors, seed deterministic RNGs from correlationId when sampling, use AtomicWrite for final artifacts, and emit necessary audit rows. Two-person approval required for rotation key changes and retention/PRUNE operations affecting regulated PII. </td></tr></tbody></table></div><div class="row-count">Rows: 38</div></div><div class="table-caption" id="Table2" data-table="Docu_0179_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by REG_Error — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">REG_Error — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_REG_ERROR (documented in OWNERS.md, required approvers listed in release manifest). <br><strong>Public API:</strong> <code>ErrorCodes</code>, <code>ClassifyError</code>, <code>WrapError</code>, <code>AnnotateError</code>, <code>AttachForensicEvidence</code>, <code>SerializeErrorForAudit</code>, <code>DeserializeErrorFromAudit</code>, <code>EmitErrorAudit</code>, <code>SafeErrorToUser</code>, <code>MapToOperatorMessage</code>, <code>IsTransientError</code>, <code>IsRetryableError</code>, <code>RetryPolicyFromError</code>, <code>EscalationPolicyDecision</code>, <code>ErrorChainVerify</code>, <code>RotateErrorSigningKeys</code>, <code>ValidateErrorSchema</code>, <code>ParseThirdPartyError</code>, <code>MapHTTPError</code>, <code>MapErrnoToErrorCode</code>, <code>CompactErrorChain</code>, <code>RehydrateErrorChain</code>, <code>ErrorMigrationTooling</code>, <code>ErrorTelemetryMetrics</code>, <code>ErrorHealthChecks</code>, <code>OperatorGuidanceForError</code>, <code>ErrorSimulator</code>. <br><strong>Audits emitted:</strong> <code>error.classified</code>, <code>error.wrapped</code>, <code>error.annotated</code>, <code>error.forensics.attached</code>, <code>error.audit.emit</code>, <code>error.safe_message.emitted</code>, <code>error.escalation.triggered</code>, <code>error.chain.verified</code>, <code>error.keyrotation</code>, <code>error.migration.applied</code>, <code>error.audit.fallback</code>, <code>error.attach.failed</code>. Each audit row must include <code>correlationId</code>, <code>module=REG_Error</code>, <code>procedure</code>, <code>errorCode</code>, <code>paramsHash</code>, <code>evidenceRef</code> when applicable, and timestamp. <br><strong>Purpose and intended use:</strong> centralize deterministic error taxonomy and handling across add-ins and worker processes; produce reproducible <code>errorId</code> and canonical serialization for forensic replay; supply safe UI messages and role-aware operator runbooks; standardize retry and escalation policies; persist and index sanitized forensic artifacts for compliance. <br><strong>Non-goals / constraints:</strong> avoid network I/O on UI-thread; do not persist raw PII in top-level audit rows; do not perform key management directly (use CORE_KeyManager); avoid automatic infrastructure remediation without explicit escalation policy; keep fast-path classification small and pure to allow embedding inside XLAM/XLL and managed workers. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Deterministic outputs: identical inputs produce identical <code>errorCode</code>, <code>errorId</code>, and classification flags. <br>2. Audit anchored: any error that affects durable state or operator decisions must emit at least one audit row referencing <code>correlationId</code> and <code>paramsHash</code>. <br>3. PII policy: top-level audit rows contain only hashes of sensitive parameters; full sanitized evidence stored encrypted and referenced by <code>evidenceRef</code>. <br>4. Crash-safety: evidence persistence uses <code>AtomicWrite</code> guaranteeing final-on-success semantics. <br>5. UI-thread safety: UI path functions (<code>SafeErrorToUser</code>, <code>IsTransientError</code>, minimal classification) must be synchronous non-blocking and never perform IO. <br>6. Observability: emit start/complete audits and local buffered metrics for telemetry; CORE_Telemetry handles audited batched uploads. <br><strong>Performance SLOs:</strong> median <code>ClassifyError</code> latency < 5ms; <code>SafeErrorToUser</code> < 15ms; audit append flush target < 2s under normal load. <br><strong>CI / acceptance gates:</strong> deterministic golden vectors for classification & serialization; cross-language parity for <code>errorId</code> generation; static analyzer enforces no IO on UI-thread. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Canonical <code>Error</code> object (schema & contract):</strong><br><strong>Required fields:</strong> <code>schemaVersion</code>, <code>errorId</code> (UUIDv4), <code>errorCode</code> (stable enum), <code>severity</code> (INFO/WARN/ERROR/CRITICAL), <code>message</code> (developer-readable), <code>safeMessage</code> (sanitized user-facing string), <code>timestamp</code> (ISO8601 UTC), <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>paramsHash</code> (SHA256 hex), <code>evidenceRef</code> (optional pointer to encrypted artifact), <code>prevErrorId</code> (optional), <code>stackTraceFingerprint</code> (optional), <code>retryable</code> (bool), <code>transient</code> (bool), <code>escalation</code> (enum), <code>metadata</code> (sanitized map). <br><strong>Optional fields:</strong> <code>artifactChecksum</code>, <code>jobIdHash</code>, <code>operatorHintKey</code>, <code>forensicsChecklistId</code>, <code>prevChainHash</code> for compacted chains. <br><strong>Serialization guarantees:</strong> canonical JSON serialization with deterministic key ordering for cross-platform parity; all PII replaced or hashed before top-level inclusion; full sanitized payload persisted in evidence store referenced by <code>evidenceRef</code>. <br><strong>Schema & migrations:</strong> <code>schemaVersion</code> required; <code>DeserializeErrorFromAudit</code> must implement sequential migrations from older versions and emit <code>error.migration.applied</code> when migration steps run. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>ErrorCodes</code> taxonomy & governance:</strong><br><strong>Contract:</strong> single source of truth enumerating canonical error identifiers used across modules and audit rows. Codes are immutable within a release; adding/removing requires OWNER approval and a migration manifest. <br><strong>Representative codes and default mappings (illustrative):</strong><br>1. <code>ERR_JOB_PERSISTENCE_FAILED</code> — job descriptor <code>AtomicWrite</code> failed; <code>severity=ERROR</code>; <code>retryable=true</code> if idempotent; <code>escalation=notify</code>. <br>2. <code>ERR_ATOMIC_WRITE_ENOSPC</code> — ENOSPC on <code>AtomicWrite</code>; <code>severity=ERROR</code>; <code>retryable=false</code> by default; operator runbook: staging fallback or infra escalation. <br>3. <code>ERR_PQ_INJECT_MISMATCH</code> — PQ injection checksum mismatch; <code>severity=CRITICAL</code> for regulated templates; <code>escalation=freezeExports</code> with <code>requiredApprovals=2</code>. <br>4. <code>ERR_RULES_ENGINE_FAILURE</code> — rules engine unhandled exception; <code>severity=ERROR</code>. <br>5. <code>ERR_VALIDATION_SCHEMA_MISMATCH</code> — config JSON Schema v7 mismatch; <code>severity=ERROR</code>. <br>6. <code>ERR_EXTERNAL_CONNECTOR_TIMEOUT</code> — external connector timeout; <code>severity=ERROR</code>; <code>retryable=true</code> with backoff. <br>7. <code>ERR_PERMISSION_DENIED</code> — ACL/EPERM; <code>severity=ERROR</code>; <code>retryable=false</code>. <br>8. <code>ERR_RETRY_EXHAUSTED</code> — retry wrapper exhausted; <code>severity=ERROR</code>; <code>escalation=notify</code>. <br>9. <code>ERR_FORGERY_DETECTED</code> — audit chain or artifact signature mismatch; <code>severity=CRITICAL</code>; <code>escalation=incident</code>. <br>10. <code>ERR_INTERNAL_UNKNOWN</code> — unmapped raw error; <code>severity=ERROR</code>. <br><strong>Governance metadata per code:</strong> owner, description, default severity, default retry policy, escalation level, operator message template id, forensics checklist id, regulatoryImpact flag. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>ClassifyError(rawError, context)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic mapper from raw runtime or provider errors + context to canonical <code>Error</code>. Pure function; no IO; does not throw. <br><strong>Parameters:</strong> <code>rawError</code> (exception object, HTTP response, provider SDK error), <code>context</code> (<code>module</code>, <code>procedure</code>, <code>correlationId</code>, <code>paramsHash</code>, optional <code>idempotencyKey</code>). <br><strong>Return:</strong> canonical <code>Error</code> object with <code>errorCode</code>, <code>severity</code>, <code>transient</code>, <code>retryable</code>, <code>message</code>, <code>stackTraceFingerprint</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Determinism: same normalized <code>rawFingerprint</code> + <code>context</code> => identical classification and <code>errorId</code>. <br>2. Side-effect free: classification should not write disk or network. <br>3. Minimal extraction: prefer structured numeric codes over free-form messages; compute sanitized <code>messageHash</code> when message included. <br><strong>Algorithm & implementation notes:</strong><br>1. <strong>Canonicalize</strong> raw input to intermediate: <code>{type, errno, httpStatus, providerCode, messageSanitized, messageHash, stackFingerprint, provider, bodyFingerprint}</code>. Normalization replaces variable tokens (timestamps, UUIDs, file paths) with placeholders before hashing. <br>2. <strong>Lookup cascade:</strong> provider numeric code mapping → structured JSON <code>code</code>/<code>subcode</code> mapping → regex patterns on sanitized messages with anchored patterns → <code>MapErrnoToErrorCode</code> / <code>MapHTTPError</code> fallback → <code>ERR_INTERNAL_UNKNOWN</code>. <br>3. <strong>Compute <code>errorId</code>:</strong> HMAC_SHA256(<code>correlationId | canonicalFingerprint | classifierVersion</code>) truncated to deterministic UUID format for readability and dedup. <br>4. <strong>Derive flags:</strong> <code>transient</code> and <code>retryable</code> inferred using mapping metadata, <code>context.idempotencyKey</code>, and known provider semantics (e.g., 5xx transient, 4xx not transient unless documented). <br><strong>Edge cases & invalid inputs:</strong><br>1. Null <code>rawError</code>: return <code>ERR_INTERNAL_UNKNOWN</code> with metadata flag <code>null_raw=true</code>. <br>2. Oversized stack traces: compute <code>stackTraceFingerprint</code> and persist the full stack only via <code>AttachForensicEvidence</code> on escalation. <br>3. Opaque HTML body: compute <code>bodyHash</code> and persist body in evidence store if needed. <br><strong>Observability & audit fields:</strong> callers should emit <code>error.classified(correlationId, errorId, errorCode, classifierVersion, inputFingerprint)</code> after classification. <br><strong>Examples:</strong><br>1. POSIX ENOSPC classified to <code>ERR_ATOMIC_WRITE_ENOSPC</code>, <code>transient=true</code>, <code>retryable=false</code>. <br>2. HTTP 504 with <code>Retry-After</code> → <code>ERR_EXTERNAL_CONNECTOR_TIMEOUT</code>, <code>retryable=true</code> for idempotent operations. <br><strong>Tests & CI vectors:</strong> mapping table golden vectors, regex fuzz tests, cross-language parity for <code>errorId</code> generation. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>WrapError(baseErrorOrRaw, context, wrapMetadata=null)</code> — wrapper & chain builder</strong><br><strong>Purpose & contract:</strong> create a wrapper <code>Error</code> that links to an existing <code>Error</code> (or a newly classified raw error) adding new <code>module</code>/<code>procedure</code> context while preserving immutability of base error. Synchronous; no IO. <br><strong>Parameters & return:</strong> <code>baseErrorOrRaw</code> (canonical <code>Error</code> or raw error), <code>context</code> (<code>module</code>, <code>procedure</code>, <code>correlationId</code>), optional <code>wrapMetadata</code>. Returns new <code>Error</code> object where <code>prevErrorId</code> points to the base <code>errorId</code>. <br><strong>Primary invariants:</strong><br>1. Bounded chain length: if <code>prevErrorChainLength &gt;= maxErrorChain</code> (config default 25), compact older portion into <code>prevChainHash</code> and persist the full chain via <code>AttachForensicEvidence</code> and set <code>prevErrorId=null</code> while adding <code>prevChainHash</code> and <code>evidenceRef</code>. <br>2. Deterministic metadata merge: lexicographic key ordering; in conflicts preserve base-level keys unless explicit override provided in <code>wrapMetadata</code>. <br>3. <code>safeMessage</code> preservation: do not overwrite downstream <code>safeMessage</code> unless wrapper severity is higher and requires an explicit replacement policy. <br><strong>Algorithm:</strong> if base is raw → call <code>ClassifyError</code> to create canonical base; else copy base fields; merge metadata; compute wrapper <code>errorId = HMAC_SHA256(prevErrorId | timestamp | context)</code> and return wrapper <code>Error</code>. <br><strong>Audit:</strong> emit <code>error.wrapped(correlationId, newErrorId, prevErrorId, wrapperModule)</code> after wrapping. <br><strong>Example narrative:</strong> worker catches storage write exception → <code>ClassifyError</code> → <code>WrapError(classifiedError, {module:&quot;REG_Export&quot;, procedure:&quot;AtomicWrite&quot;})</code> → <code>AnnotateError</code> → <code>AttachForensicEvidence</code> (if needed) → <code>EmitErrorAudit</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>AnnotateError(error, enrichment)</code> — lightweight enrichment</strong><br><strong>Purpose & contract:</strong> attach sanitized contextual metadata (jobDescriptorHash, tempPaths, artifactChecksum) to <code>Error</code>. Small sanitizable metadata permitted synchronously; large or PII-containing payloads require <code>AttachForensicEvidence</code> and must run in worker. <br><strong>Rules:</strong><br>1. No raw PII in <code>metadata</code>; compute <code>piiHash</code> for replaced PII and persist full sanitized payload with <code>AttachForensicEvidence</code>. <br>2. Idempotent and deterministic merging. <br><strong>Return:</strong> enriched <code>Error</code> object with merged <code>metadata</code> and, if <code>AttachForensicEvidence</code> used, a populated <code>evidenceRef</code>. <br><strong>Audit:</strong> caller may emit <code>error.annotated(correlationId, errorId, paramsHash)</code> to record enrichment events. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>AttachForensicEvidence(error, evidenceBlob, evidenceMeta)</code> — evidence ingestion</strong><br><strong>Purpose & contract:</strong> sanitize, encrypt, and persist large forensic artifacts (logs, stacks, RNG serialized state, SafeRound inputs) and return <code>evidenceRef</code> to attach to <code>Error</code>. IO-bound; must run in worker or background process; never on UI-thread. <br><strong>Must/shall steps:</strong><br>1. <strong>Sanitize</strong>: deterministic PII redaction; record <code>piiHash</code> entries for removed elements. <br>2. <strong>Encrypt</strong> using <code>CORE_KeyManager</code> or approved project encryption. <br>3. <strong>Persist atomically</strong> via <code>AtomicWrite(evidencePath, encryptedBlob)</code>; compute SHA256 checksum and size. <br>4. <strong>Index</strong> evidence metadata: uploader, retentionPolicy, ACLs, checksum, size, provenance tags. <br>5. <strong>Return</strong> <code>evidenceRef = {path, checksum, size, retentionPolicy}</code> for attachment to <code>Error</code>. <br><strong>Edge cases & runbook:</strong><br>1. Encryption failure: store sealed local staging, emit <code>error.forensics.failed</code>, escalate to infra. <br>2. ENOSPC on evidence store: apply configured staging fallback (same-volume staging preferred) and emit <code>error.forensics.degraded</code>. <br><strong>Audit:</strong> <code>error.forensics.attached(correlationId, errorId, evidenceRef)</code> on success; <code>error.forensics.failed</code> on failure. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>SerializeErrorForAudit(error)</code> & <code>DeserializeErrorFromAudit(blob)</code> — canonical serialization</strong><br><strong>Purpose & contract:</strong> canonical deterministic JSON used for audit rows and archival; support robust migrations across <code>schemaVersion</code>s. <br><strong>Canonical ordering:</strong> <code>schemaVersion</code>, <code>errorId</code>, <code>errorCode</code>, <code>severity</code>, <code>timestamp</code>, <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>message</code>, <code>safeMessage</code>, <code>paramsHash</code>, <code>evidenceRef</code>, <code>prevErrorId</code>, <code>metadata</code>. <br><strong>Migrations:</strong> <code>Deserialize</code> applies ordered migrations from <code>error_migrations</code> sequentially; each applied migration emits <code>error.migration.applied(correlationId, errorId, fromVersion, toVersion)</code>. Migrations must be idempotent; tests in CI must exercise migration sequences with golden vectors. <br><strong>Validation:</strong> call <code>ValidateErrorSchema</code> during <code>Deserialize</code> and on ingest endpoints; failures produce <code>ERR_VALIDATION_SCHEMA_MISMATCH</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>EmitErrorAudit(error, auditClient=CORE_Audit)</code> — append-only emission</strong><br><strong>Purpose & contract:</strong> reliably append an audit row representing the <code>Error</code> into append-only audit buffer. Must be idempotent (dedupe by <code>errorId</code>) and robust to transient failures. <br><strong>Behavior & rules:</strong><br>1. Compute <code>paramsHash</code> over sanitized params and <code>auditRowChecksum</code>. <br>2. Append using <code>auditClient.append</code> with dedup key <code>errorId</code>. <br>3. On transient failures use <code>Retry</code> (idempotent_assert=true). <br>4. If append ultimately fails, persist fallback to <code>audit_tail_failed/&lt;correlationId&gt;-&lt;errorId&gt;.json</code> and emit <code>error.audit.fallback</code>. <br>5. When chain signing enabled, sign the appended row with <code>CORE_Signing</code> in worker context; signing operations are auditable. <br><strong>Metrics & observability:</strong> emit <code>error.audit.emit_latency_ms</code> and <code>error.audit.append_count</code> metrics. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(error, locale=&quot;en-US&quot;, verbosity=&quot;concise&quot;)</code> — UI-safe message renderer</strong><br><strong>Purpose & contract:</strong> produce a sanitized user-facing message and a structured operator hint for display in ribbons and dialogs. Synchronous, no IO. <br><strong>Template rules:</strong><br>1. Templates packaged with release artifact at <code>REG_Error/templates/&lt;locale&gt;/&lt;errorCode&gt;.tmpl</code>. <br>2. Templates must only accept hashed or non-PII placeholders (<code>{artifactChecksum}</code>, <code>{jobIdHash}</code>, <code>{supportLink}</code>, <code>{correlationId}</code>). <br>3. For <code>CRITICAL</code> errors template must instruct to contact SRE and include <code>correlationId</code>. <br><strong>Return:</strong> <code>{userMessage, operatorHint, templateId}</code>. <code>operatorHint</code> may include <code>paramsHash</code> and <code>evidenceRef</code> pointers. <br><strong>Audit:</strong> <code>error.safe_message.emitted(correlationId, errorId, templateId)</code>. <br><strong>Examples:</strong><br>1. <code>ERR_ATOMIC_WRITE_ENOSPC</code> → <code>userMessage: &quot;Export failed: destination disk is full. Contact infrastructure with correlation r-2026-...&quot;.</code> <code>operatorHint</code> includes <code>mountPathHash</code>, <code>freeBytesSnapshotRef</code>. <br>2. <code>ERR_PQ_INJECT_MISMATCH</code> (regulated) → <code>userMessage: &quot;Template verification failed. Do not proceed with regulated exports; contact Compliance.&quot;</code> </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>MapToOperatorMessage(error, operatorRole)</code> — role-aware remediation checklists</strong><br><strong>Purpose & contract:</strong> return a role-specific remediation checklist for roles such as <code>operator</code>, <code>SRE</code>, <code>compliance</code>, or <code>release-owner</code>. Deterministic; no IO. <br><strong>Return:</strong> <code>{steps:[], approvalRequired:int, escalationLevel, runbookId}</code>. <br><strong>Runbook template rules:</strong> stored in release artifact; placeholders limited to non-PII tokens. <br><strong>Governance:</strong> two-person approval enforced for regulated outputs; approvals recorded as <code>approval.requested</code> / <code>approval.granted</code> audit rows. <br><strong>Example mapping (ERR_FORGERY_DETECTED):</strong><br>1. Freeze exports and set audit store read-only. <br>2. Collect <code>audit_tail</code> and evidence via <code>diagnostics collect --correlation</code>. <br>3. Run <code>ErrorChainVerify</code> and prepare regulatory package if forgery confirmed. <br>4. Notify legal/compliance and SRE; rotate signing keys if required. <br><strong>Audit:</strong> <code>error.escalation.triggered(correlationId, errorId, escalationLevel)</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>IsTransientError(error)</code> & <code>IsRetryableError(error, context)</code> — decision predicates</strong><br><strong>Purpose & contract:</strong> boolean predicates for orchestrators to choose retry/backoff or immediate failover. Synchronous and deterministic. <br><strong>Rules:</strong><br>1. <code>IsTransientError</code> true for ephemeral conditions like network timeouts, provider 5xx or rate-limits. <br>2. <code>IsRetryableError</code> true only if operation is idempotent by design or protected by an idempotency token (<code>context.idempotencyKey</code>). <br>3. Predicates conservative to avoid unsafe retries for non-idempotent operations. <br><strong>Examples:</strong><br>1. HTTP 429 with <code>Retry-After</code> → <code>IsTransientError=true</code>, <code>IsRetryableError=true</code> if client operation idempotent. <br>2. <code>ERR_PERMISSION_DENIED</code> → <code>IsTransientError=false</code>, <code>IsRetryableError=false</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>RetryPolicyFromError(error, defaultContext)</code> — derive retry policy</strong><br><strong>Purpose & contract:</strong> given an <code>Error</code> and service context, produce <code>{retries, baseMs, factor, maxBackoffMs, jitter, deterministicJitter, idempotent_assert}</code> deterministic for <code>errorCode</code> and <code>module</code>. <br><strong>Heuristics & rules:</strong><br>1. For regulated-critical flows: prefer fail-fast with staged-local fallback instead of extended retries. <br>2. External connector timeout default: <code>{retries:3, baseMs:200, factor:2, jitter:true}</code>. <br>3. Job persistence default: <code>{retries:5, baseMs:300, factor:2, idempotent_assert:true}</code> (requires idempotency token). <br>4. For CI/golden runs set <code>deterministicJitter=true</code> using <code>DeterministicRNG(correlationId)</code> so retry timing reproducible in tests. <br><strong>Audit:</strong> <code>error.retry.policy.applied(correlationId, errorId, policyHash)</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>EscalationPolicyDecision(error, serviceContext, failureMetrics)</code> — automated gating</strong><br><strong>Purpose & contract:</strong> deterministically choose escalation action (<code>none</code>, <code>notify</code>, <code>incident</code>, <code>freezeExports</code>, <code>rollback</code>) based on <code>errorCode</code>, <code>severity</code>, <code>serviceContext</code> (release stage, canary flag), and operational metrics (error rate, spike detection). <br><strong>Decision invariants:</strong><br>1. Two-person approval required for regulated outputs and releases. <br>2. Canary auto-rollback when error rate exceeds <code>canaryThreshold</code> for a configured window. <br>3. Decisions computed deterministically to produce reproducible rationale fingerprint (<code>rationaleHash</code>). <br><strong>Return & audit:</strong> <code>{action, requiredApprovals, rationaleHash}</code> and emit <code>error.escalation.decision(correlationId, errorId, action, rationaleHash)</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>ErrorChainVerify(auditSegment, releaseManifest, keys)</code> — audit chain verification</strong><br><strong>Purpose & contract:</strong> verify append-only audit chain integrity and signatures for a given <code>correlationId</code> or audit segment; intended for CI and forensic analysis. CPU & IO bound. <br><strong>Verification steps:</strong><br>1. Verify hash chaining across rows and monotonic timestamps per correlation. <br>2. Verify row signatures against public keys in <code>releaseManifest</code>. <br>3. Confirm artifact checksums referenced in audit rows equal computed checksums for artifacts when accessible. <br>4. Produce signed verification report persisted via <code>AtomicWrite</code> and return <code>{verified:bool, mismatches:[], signatureProofs:[]}</code>. <br><strong>Failure runbook:</strong> if mismatches found, lock audit store read-only, assemble <code>forensic_manifest</code>, and escalate as <code>ERR_FORGERY_DETECTED</code>. <br><strong>Audit:</strong> <code>error.chain.verified(correlationId, verified, mismatchCount)</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>RotateErrorSigningKeys(keyDescriptor)</code> — key rotation orchestration</strong><br><strong>Purpose & contract:</strong> rotate signing keys used for audit chain signing with canary verification and full promotion. Requires OWNER & SRE sign-offs and signed rotation manifest. <br><strong>Steps (must/shall):</strong><br>1. Generate new key via <code>CORE_KeyManager</code>. <br>2. Produce and sign <code>rotationManifest.json</code> using old key; persist via <code>AtomicWrite</code>. <br>3. Canary: sign sample audit segment with new key and run <code>ErrorChainVerify</code>. <br>4. Promote new key across systems on successful verification and archive old keys per retention. <br><strong>Rollback:</strong> if verification fails revert to old key and open incident; emit <code>error.keyrotation.failed</code>. <br><strong>Audit:</strong> <code>error.keyrotation(correlationId, previousKeyId, newKeyId, manifestChecksum)</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>ValidateErrorSchema(errorJson)</code> — schema validation</strong><br><strong>Purpose & contract:</strong> validate serialized error artifact against current <code>schemaVersion</code> and produce <code>(valid, diagnostics[])</code>. Synchronously used in ingestion and CI. <br><strong>Checks:</strong> presence and types for required fields, <code>paramsHash</code> correctness vs. supplied params, <code>evidenceRef</code> format validity, <code>timestamp</code> within allowable skew, and <code>prevErrorId</code> referential integrity when present. <br><strong>Failure mapping:</strong> validation errors mapped to <code>ERR_VALIDATION_SCHEMA_MISMATCH</code> with diagnostics for operator runbooks. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>ParseThirdPartyError(payload, providerHint)</code> & <code>MapHTTPError(httpResponse)</code> — normalization</strong><br><strong>Purpose & contract:</strong> convert diverse vendor/provider error responses into canonical intermediate for <code>ClassifyError</code>. Mapping rules are provider-specific, versioned, and stored in release artifacts. <br><strong>Preferred parse order:</strong> numeric status codes → structured JSON code/subcode fields → provider-specific headers (e.g., <code>Retry-After</code>, <code>X-RateLimit-*</code>) → anchored regex on sanitized bodies → fallback to generic mapping (<code>ERR_INTERNAL_UNKNOWN</code>). <br><strong>HTTP specifics:</strong> parse <code>Retry-After</code>, <code>X-RateLimit-Limit/Remaining/Reset</code>, <code>X-Request-ID</code>; compute <code>bodyHash</code> for HTML/text fallback; persist full body in evidence only on escalation or on <code>AttachForensicEvidence</code> invocation. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>MapErrnoToErrorCode(errno, syscallContext)</code> — OS errno normalization</strong><br><strong>Purpose & contract:</strong> map OS-level errno (POSIX) and Windows equivalents to canonical <code>ErrorCodes</code>. Table maintained with owner and cross-OS parity tests. <br><strong>Representative mappings:</strong> <code>ENOSPC</code> → <code>ERR_ATOMIC_WRITE_ENOSPC</code>; <code>EACCES</code> → <code>ERR_PERMISSION_DENIED</code>; <code>ENOMEM</code> → <code>ERR_OUT_OF_MEMORY</code>. <br><strong>CI tests:</strong> ensure parity via virtualization and Windows-shims in CI. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong><code>CompactErrorChain(errorChain)</code> & <code>RehydrateErrorChain(compactedRef)</code> — chain size management</strong><br><strong>Purpose:</strong> when error chains exceed configured limits, compact older portion into <code>prevChainHash</code> and persist full chain in evidence store; rehydrate for forensic replay. <br><strong>Rules:</strong><br>1. Compaction triggers when <code>chainLength &gt; maxErrorChain</code>. <br>2. Prior chain serialized canonical → <code>prevChainHash = SHA256(serializedPriorChain)</code>; prior chain persisted via <code>AttachForensicEvidence</code>. <br>3. Compacted <code>Error</code> stores <code>prevChainHash</code> and <code>evidenceRef</code>. <br><strong>Rehydration:</strong> uses <code>evidenceRef</code> to fetch and rehydrate full chain; rehydration step audited. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (concepts & mapping)</strong><br><strong>Audit schema:</strong> every <code>REG_Error</code> audit row must include <code>timestamp</code>, <code>correlationId</code>, <code>module=REG_Error</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>errorId</code>, <code>errorCode</code>, <code>severity</code>, <code>paramsHash</code>, <code>evidenceRef</code> (optional), <code>prevErrorId</code> (optional), <code>configHash</code>, <code>metadata</code> like <code>duration_ms</code>, <code>attempts</code>, <code>artifactChecksum</code>, <code>tempPathList</code>. Top-level audit rows must never contain raw PII. <br><strong>Key audit events:</strong> <code>error.classified</code>, <code>error.wrapped</code>, <code>error.forensics.attached</code>, <code>error.audit.emit</code>, <code>error.safe_message.emitted</code>, <code>error.escalation.triggered</code>, <code>error.chain.verified</code>. <br><strong>Metrics (buffered):</strong> <code>error.count</code>, <code>error.rate</code>, <code>error.retry.attempts</code>, <code>error.escalations</code>, <code>error.audit.emit_latency_ms</code>. CORE_Telemetry uploads metrics in audited batches; utilities avoid remote exports on UI-thread. <br><strong>Evidence policy:</strong> sanitized params stored encrypted in evidence store; top-level audit stores parameter hashes only; access controls enforced by evidence index and audited account actions. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-language golden governance</strong><br><strong>Unit tests required:</strong><br>1. Classification goldens: raw errno, HTTP responses, provider SDK errors → expected <code>ErrorCodes</code> with deterministic fingerprints. <br>2. <code>SerializeErrorForAudit</code> canonicalization and <code>DeserializeErrorFromAudit</code> migrations across versions. <br>3. <code>SafeErrorToUser</code> template rendering across locales and severity levels. <br>4. <code>AttachForensicEvidence</code> with FS and crypto mocks; simulate ENOSPC and EPERM. <br><strong>Integration tests:</strong><br>1. End-to-end error lifecycle: exception → classify → annotate → attach evidence → emit audit → chain verify. <br>2. Retry + escalation: inject transient connector failures → validate retry policy application and escalation triggers. <br>3. Key rotation canary verification runs. <br><strong>Property tests:</strong> deterministic <code>errorId</code> parity across languages; chain compaction/re-hydration integrity; PII redaction invariants under fuzzing. <br><strong>Cross-language golden gating:</strong> classification outputs and canonical serialized blobs for representative inputs must match across VBA/JS/Python/C# implementations and are enforced in CI. <br><strong>Performance tests:</strong> classification throughput microbenchmarks, audit append flush under load, evidence attach concurrency behavior. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required patterns:</strong><br>1. Use <code>ClassifyError</code> immediately for caught exceptions within worker flow and call <code>EmitErrorAudit</code> to record the error. <br>2. UI handlers must use <code>SafeErrorToUser</code> and <code>EmitErrorAudit</code> with minimal sanitized metadata. <br>3. Use <code>RetryPolicyFromError</code> for consistent retry behavior and ensure idempotency tokens for retryable operations. <br>4. Persist large forensic artifacts via <code>AttachForensicEvidence</code> and reference <code>evidenceRef</code>. <br><strong>Forbidden patterns:</strong><br>1. Do not write raw PII to top-level audits or UI. Static analyzer must reject such changes. <br>2. Do not call <code>AttachForensicEvidence</code> on UI thread. <br>3. Do not mutate canonical <code>Error</code> objects after emission; wrap instead. <br>4. Do not bypass <code>EmitErrorAudit</code> for regulated flows. <br><strong>Code-review checklist:</strong> verify classification usage, audit emission, <code>SafeErrorToUser</code> usage on UI, idempotency for retryable flows, and evidence persistence for large artifacts. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (detailed)</strong><br><strong>High-severity incident: <code>ERR_FORGERY_DETECTED</code> playbook:</strong><br>1. Immediately set audit store read-only and emit <code>error.containment</code> audit row. <br>2. Run <code>diagnostics collect --correlation &lt;id&gt;</code> to gather <code>audit_tail.csv</code>, serialized <code>Error</code> JSONs, evidence artifacts, and <code>forensic_manifest.json</code>. <br>3. Run <code>ErrorChainVerify</code> with release manifest keys to confirm chain mismatch. <br>4. If forgery confirmed: freeze exports, notify compliance/legal, prepare regulatory package including release manifest and audit rotations, and rotate signing keys via <code>RotateErrorSigningKeys</code> with canary flow. <br>5. Produce post-mortem and remediation artifacts: <code>forensic_manifest</code>, <code>audit_tail</code> snapshots, and golden fixtures required for regulator packages. <br><strong>AtomicWrite ENOSPC runbook:</strong><br>1. Inspect <code>error.forensics.attached</code> for mount path, <code>freeBytesSnapshotRef</code>, and tempPaths. <br>2. SSH to host and collect <code>df -h</code>, <code>vmstat</code>, <code>iostat</code> and <code>lsof</code> to identify lock holders. <br>3. Move non-critical artifacts to local staging (prefer same-volume staging to preserve atomic rename semantics) or expand volume. <br>4. Re-run export with <code>--stage-local</code> and validate checksums; if persistently failing escalate to infra with <code>forensic_manifest</code>. <br><strong>Retry exhaustion triage:</strong><br>1. Query <code>util.retry.attempt</code> metrics and <code>error.retry.policy.applied</code> audit rows to identify failing target and rate of retries. <br>2. Throttle concurrency and enable circuit-breaker for the failing service. <br>3. Investigate idempotency token presence; pause production calls if missing and implement idempotency persistence. <br>4. If infrastructure-related escalate to SRE with <code>forensic_manifest</code> artifacts. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Extremely detailed long-form narratives, examples, and forensic walkthroughs</strong><br><strong>Narrative 1 — Regulated end-of-period journal allocation (complete forensic trace):</strong><br>1. Operator triggers <code>AllocateJournalTotals</code> via <code>REG_Ribbon</code>; the ribbon handler performs input validation and emits <code>UserAction</code> audit containing <code>correlationId=r-20260117-xyz</code> and <code>paramsHash</code>. <br>2. The add-in constructs the canonical <code>jobDescriptor</code> with <code>jobId</code>, <code>paramsHash</code>, <code>configHash</code>, and <code>correlationId</code> and persists it using <code>AtomicWrite(jobDescriptorPath, jobJson)</code>. <br>3. <code>AtomicWrite</code> fails with OS <code>ENOSPC</code> (errno 28). The worker catches I/O exception and calls <code>ClassifyError(rawErr, context)</code>. <code>ClassifyError</code> normalizes errno → returns <code>Error</code> with <code>errorCode=ERR_ATOMIC_WRITE_ENOSPC</code>, <code>transient=true</code>, <code>retryable=false</code> (no staging configured). <br>4. Worker calls <code>AnnotateError</code> to attach <code>tempPathList</code>, <code>fsStats</code>, and <code>jobDescriptorHash</code> in metadata. Because metadata contains substantial content, worker calls <code>AttachForensicEvidence(error, sanitizedPayload, meta)</code> to persist encrypted evidence at <code>evidence/hot/r-20260117-xyz/evidence-&lt;errorId&gt;.enc</code>. <code>AttachForensicEvidence</code> returns <code>evidenceRef</code> with checksum and size. <br>5. Worker calls <code>WrapError(classifiedError, {module:&quot;REG_Export&quot;, procedure:&quot;AtomicWrite&quot;})</code> to create a contextual wrapper <code>Error</code> and then <code>EmitErrorAudit</code> to append the audit row. Audit append uses dedupe key <code>errorId</code> and signs the row if chain-signing enabled. <code>error.forensics.attached</code> and <code>error.audit.emit</code> audits recorded. <br>6. <code>EscalationPolicyDecision</code> evaluates recent job persistence failure rate and triggers <code>notify</code> to infra; <code>error.escalation.triggered</code> emitted. <br>7. Operator runs <code>diagnostics collect --correlation r-20260117-xyz</code> which packages <code>audit_tail.csv</code>, evidence artifacts, and <code>forensic_manifest.json</code> and sends them to infra for remediation. <br>8. Infra increases volume or clears space; operator re-runs job; <code>AtomicWrite</code> now succeeds; <code>util.atomic_write.completed</code> and <code>job.persisted</code> audit rows recorded. <br><strong>Key forensic artifacts produced:</strong> <code>jobDescriptor.json</code> persisted artifact, <code>evidence/evidence-&lt;errorId&gt;.enc</code>, <code>atomic_write.tempPaths</code> listing, <code>audit_tail.csv</code>, signed audit rows with <code>errorId</code>. These are compiled into the <code>forensic_manifest</code> for regulator submission if needed. <br><strong>Narrative 2 — PQ Template injection with numeric fidelity requirement (compliance-critical):</strong><br>1. Operator previews <code>ifrs15-highprecision.m</code>; PQ_Ribbon computes <code>seed = SeedFromCorrelation(correlationId, templateId)</code> and stores seed and <code>mChecksum</code> in <code>pq_preview</code> audit. <br>2. Operator injects template; <code>PQ_Injector</code> worker persists canonical M artifact via <code>AtomicWrite</code> to <code>artifacts/pq/m/&lt;artifactId&gt;.m</code> and returns <code>artifactChecksum</code>. <br>3. After injection, the workbook's query hash differs from <code>artifactChecksum</code> due to host-specific normalization. Host detects mismatch and calls <code>ClassifyError</code> mapping to <code>ERR_PQ_INJECT_MISMATCH</code> with <code>severity=CRITICAL</code> and <code>regulatoryImpact=IFRS</code>. <br>4. <code>AnnotateError</code> attaches <code>mChecksum</code>, <code>artifactChecksum</code>, <code>workbookQueryHash</code>, and <code>operatorIdHash</code>. Worker calls <code>AttachForensicEvidence</code> to persist diffs and sanitized M sources; evidence persisted and <code>evidenceRef</code> returned. <br>5. <code>EscalationPolicyDecision</code> returns <code>freezeExports</code> with <code>requiredApprovals=2</code>; system blocks regulated exports and notifies Compliance and Release Owners. <br>6. Two-person approval workflow required: approvals recorded as <code>approval.requested</code> and <code>approval.granted</code> audit rows; following approvals the injector re-injects signed artifact or reverts the workbook to signed query. All steps auditable. <br><strong>Narrative 3 — MatchMerge tie-break determinism and dispute replay:</strong><br>1. <code>MatchMerge</code> pipeline computes match scores for candidate pairs. Ties exist requiring deterministic tie-breaking. The pipeline seeds <code>DeterministicRNG(seedSource=SeedFromCorrelation(correlationId, &quot;matchmerge-v1&quot;))</code> and uses <code>rng.shuffle(candidates)</code> combined with <code>tieBreakerKeys</code> to reorder deterministically. <br>2. Merge proposals persisted using <code>AtomicWrite</code> as <code>proposal-&lt;id&gt;.json</code> and <code>artifactChecksum</code> stored. <code>util.rng.seeded</code> and <code>util.atomic_write.completed</code> audits emitted. <br>3. Operator disputes ordering; forensics team retrieves serialized RNG state and input snapshots from <code>evidenceRef</code> and runs <code>replay.run --evidenceRef</code> to reproduce exact ordering. <br>4. Forensics shows algorithm version updated between runs; <code>error.migration.applied</code> audit recorded for the run that used new tie-breaker policy. For resolution, teams either revert to previous tie-break policy via migration manifest or accept migration with owner-signed manifest and golden test updates. <br><strong>Narrative 4 — Retry exhaustion cascading failure leading to SRE incident:</strong><br>1. A worker repeatedly attempts to persist large report artifacts to remote NFS; calls guarded by <code>Retry(AtomicWrite, retries=5, idempotent_assert=true)</code>. Persistent NFS lag causes timeouts; <code>ClassifyError</code> returns <code>ERR_EXTERNAL_CONNECTOR_TIMEOUT</code> for each attempt. <br>2. After retries exhausted <code>WrapError</code> creates <code>ERR_RETRY_EXHAUSTED</code> wrapper; <code>AnnotateError</code> includes <code>attempts</code>, <code>backoffPolicy</code>, <code>tempPaths</code>. <code>EmitErrorAudit</code> records <code>ERR_RETRY_EXHAUSTED</code>. <br>3. <code>EscalationPolicyDecision</code> sees elevated retry exhaustion rate crossing <code>SRENotifyThreshold</code> and triggers <code>incident</code> with <code>requiredApprovals=1</code>. <code>ReportToSRE</code> creates incident artifacts and pushes evidence bundle for on-call triage. <br>4. SRE enables circuit-breaker for NFS writes, increases retry budgets temporarily for critical job descriptors, and works with infra to remediate NFS performance. All actions recorded via audit rows and post-mortem produced. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) mapping — REG_Error best practices for PQ workflows</strong><br><strong>Context & constraints:</strong> Power Query (M) runs in host environments with variable runtimes and limited control over file I/O semantics. REG_Error cannot execute inside M; host-level helpers implement error handling and evidence persistence. <br><strong>Patterns & recommended practices:</strong><br>1. <strong>Host marshalling of M runtime errors:</strong> host captures PQ engine exceptions and constructs structured payload <code>{provider, httpStatus, messageSanitized, mChecksum, queryName, workbookId}</code> and passes to <code>ParseThirdPartyError</code> → <code>ClassifyError</code>. Audit produced: <code>pq_refresh.error</code> referencing <code>errorId</code>. <br>2. <strong>Atomic persistence before injection:</strong> <code>PQ_Injector</code> writes canonical M artifact using worker <code>AtomicWrite</code>; only inject into workbook after verifying workbook query hash matches persisted artifact checksum. Mismatches classified as <code>ERR_PQ_INJECT_MISMATCH</code> with diffs persisted to evidence. <br>3. <strong>Preview determinism:</strong> PQ_Ribbon computes preview seed <code>SeedFromCorrelation(correlationId, templateId)</code> and injects it as preview parameter into M template; preview audit logs <code>seed</code> and <code>mChecksum</code>. For heavyweight sampling or numerical fidelity tests, run in worker using <code>DeterministicRNG</code> and persist sample set as evidence. <br>4. <strong>Retry orchestration for PQ refresh:</strong> orchestrator wrapper persists refresh job descriptor (<code>AtomicWrite</code>) before attempting refresh; uses <code>RetryPolicyFromError</code> on connector failures and validates idempotency tokens for safe retries. <br>5. <strong>High-precision numeric transforms:</strong> flag templates <code>requiresHighPrecision</code> and execute final numeric aggregation in worker <code>SafeRound</code> to ensure cross-host parity; persist final authoritative artifact via <code>AtomicWrite</code> and attach to <code>pq_inject</code> audit. <br><strong>Example PQ operator flow (injection):</strong> preview → compute seed and <code>pq_preview</code> audit → operator selects inject → <code>PQ_Injector</code> worker <code>AtomicWrite</code> artifact → inject helper verifies workbook query hash → on mismatch classify and attach evidence / escalate. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX mapping — REG_Error for semantic models and DAX patterns</strong><br><strong>Context:</strong> DAX is read-time expression language; cannot perform side-effects or persistent logging. All side-effecting error handling and audit must happen in ETL and worker layers. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Persist RunMetadata in ETL:</strong> ETL writes <code>RunMetadata</code> atomically with fields <code>correlationId</code>, <code>artifactChecksum</code>, <code>errorIds[]</code>, <code>runTs</code>, <code>configHash</code>. DAX queries read <code>RunMetadata</code> to present model health flags. <br>2. <strong>Model health indicator:</strong> create DAX measure <code>ReconciledFlag := IF(RunMetadata.expectedChecksum = Model.artifactChecksum, 1, 0)</code>. If 0, dashboard shows generic "Data validation failed" and a pointer to <code>correlationId</code> for operator diagnostics, never raw error details. <br>3. <strong>Deterministic sampling in ETL:</strong> compute <code>HashKey = HMAC_SHA256(PrimaryKey | correlationSalt)</code> and persist selected samples; store <code>correlationSalt</code> in <code>RunMetadata</code> for reproducible sampling and forensics. <br>4. <strong>Rounding & allocations done in ETL:</strong> perform <code>SafeRoundResiduals</code> in ETL to produce resolved integer cent allocations; store both raw canonical decimals and rounded outputs in artifact; DAX consumes the final integer values. <br>5. <strong>Checksum reconciliation for models:</strong> ETL persists <code>artifact.manifest.json</code> with dataset-level checksums; DAX surfaces reconciliation status by comparing model-level computed checksums to <code>RunMetadata.expectedChecksum</code>. <br><strong>DAX operator narrative (model refresh failure):</strong> ETL fails <code>AtomicWrite</code> → classify error + attach evidence → persist <code>RunMetadata</code> with <code>errorIds</code> and <code>artifactChecksum=null</code> → DAX <code>ReconciledFlag=0</code> → UI shows correlation pointer for operator diagnostics. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendices — forensic artifacts, evidence paths, retention & access controls</strong><br><strong>Minimum forensic artifacts for any critical error:</strong><br>1. <code>audit_tail.csv</code> for correlation window including <code>UserAction</code>, <code>REG_Error</code> rows. <br>2. Serialized <code>Error</code> JSON files (canonical) and <code>evidenceRef</code> artifacts (encrypted). <br>3. <code>jobDescriptor.json</code> and persisted artifact files with SHA256 checksums. <br>4. Serialized RNG state blobs when deterministic sampling/tie-breakers used. <br>5. Canonical <code>SafeRound</code> input snapshots for numeric disputes. <br>6. <code>atomic_write.tempPaths</code> and <code>tempArtifact</code> listings from failed writes. <br>7. <code>forensic_manifest.json</code> capturing artifact URIs, checksums, <code>evidenceRef</code>s, and access control metadata. <br><strong>Evidence storage & retention:</strong><br>1. Hot evidence store: <code>\\evidence\hot\&lt;module&gt;\&lt;correlationId&gt;\</code> retained 30 days and strictly ACL-limited. <br>2. Warm archive: secure long-term archive for regulated retention (7 years common); chain-of-custody metadata required. <br>3. Cold archive: jurisdiction-specific retention per regulation. <br><strong>Access controls & verification:</strong> evidence encrypted at rest; access to evidence indexed by <code>evidenceRef</code> controlled via ACLs and audited on access; monthly retention verification jobs emit <code>housekeeping.audit</code> and <code>forensic_manifest.verify</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (comprehensive):</strong><br>1. OWNER entries present for <code>TEAM_REG_ERROR</code> and code owners listed in OWNERS.md. <br>2. <code>ErrorCodes</code> catalog finalized and included in release manifest; any new codes have owner approval. <br>3. Deterministic classification golden vectors present and passing for supported languages. <br>4. Canonical serialization and migration tests green across all <code>schemaVersion</code> transitions. <br>5. <code>SafeErrorToUser</code> templates present in required locales and translations certified by L10N. <br>6. Evidence attach flow tested end-to-end with encryption, <code>AtomicWrite</code>, indexing, and ACL checks. <br>7. Audit hooks validated with signed append tests and <code>ErrorChainVerify</code> executed successfully on sample runs. <br>8. Static analysis ensures no forbidden IO on UI-thread functions and no top-level PII leakage. <br><strong>Blocking conditions:</strong> missing audit emits, PII leakage detected, failing serialization/migration tests, or absent OWNER sign-offs. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & scripts (explicit):</strong><br><strong>Unit tests:</strong><br>1. Classification mapping suites: errno cases, HTTP statuses, provider SDK errors, HTML bodies, and multi-lingual messages. <br>2. <code>SerializeErrorForAudit</code> canonicalization and <code>DeserializeErrorFromAudit</code> migration tests with edge-case fields. <br>3. <code>SafeErrorToUser</code> template rendering tests across locales and verbosity levels. <br>4. <code>AttachForensicEvidence</code> with simulated encryption failures and ENOSPC/EPERM scenarios. <br><strong>Integration tests:</strong><br>1. End-to-end error flow including evidence persistence and chain verify. <br>2. Retry + escalation tests: inject transient faults and assert correct <code>RetryPolicy</code> and escalation triggers. <br>3. Key rotation & canary verification integration. <br><strong>Property & fuzz tests:</strong><br>1. Deterministic <code>errorId</code> generation parity tests across language bindings. <br>2. PII redaction property tests with fuzzed inputs ensuring no PII in top-level audit. <br>3. Chain compaction/re-hydration integrity tests. <br><strong>Performance tests:</strong> classification throughput benchmarks, audit append flush under high event rates, evidence attachment concurrency stress. <br><strong>CI gating:</strong> golden parity, forbidden-API static checks, localization validations, and performance budgets. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (concise & prescriptive):</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-abc</code> — packages <code>audit_tail.csv</code>, serialized <code>Error</code> JSON, evidence artifacts, and <code>forensic_manifest.json</code>. <br>2. <code>error.replay --correlation r-... --evidenceRef &lt;ref&gt;</code> — deterministic replay using persisted evidence <code>--dry-run</code> supported. <br>3. <code>error.chain.verify --correlation r-... --manifest release-manifest.json</code> — verify audit chain integrity. <br>4. <code>error.attach --error-id &lt;id&gt; --file &lt;path&gt;</code> — attach local artifact under maintenance window (ACL enforced). <br><strong>When to call SRE:</strong> after <code>ERR_ATOMIC_WRITE_ENOSPC</code> persists on critical job descriptors despite staging fallback, or <code>ERR_FORGERY_DETECTED</code> chain verification failures; include <code>forensic_manifest</code> and <code>audit_tail</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendix A — example audit row schema (descriptive):</strong><br><strong>Fields required for error audits:</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>errorId</code>, <code>errorCode</code>, <code>severity</code>, <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>prevErrorId</code> (optional), <code>configHash</code>, <code>metadata</code> object including <code>duration_ms</code>, <code>attempts</code>, <code>artifactChecksum</code>, <code>tempPathList</code>. <br><strong>Policy:</strong> top-level audit rows must not contain raw PII; full sanitized parameters persisted in evidence store referenced by <code>evidenceRef</code>. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendix B — common failure modes & mitigations (expanded):</strong><br><strong>Failure mode: partial write observed by reader</strong><br>1. Cause: caller wrote directly to final path instead of using <code>AtomicWrite</code>, or rename semantics unreliable on network FS. <br>2. Mitigation: enforce <code>AtomicWrite</code> usage via static analyzer and test harness; run <code>InspectTempArtifacts</code> and <code>AtomicWriteRepair</code>; prefer same-volume staging for fallback. <br><strong>Failure mode: nondeterministic sampling complaint</strong><br>1. Cause: global RNG used or seed not persisted. <br>2. Mitigation: enforce <code>DeterministicRNG</code> seeded from <code>correlationId</code>; persist serialized RNG state for replay; add parity tests. <br><strong>Failure mode: rounding drift over repeated runs</strong><br>1. Cause: applying naive rounding repeatedly instead of <code>SafeRoundResiduals</code>. <br>2. Mitigation: adopt <code>bankers</code> or <code>residual_distribute</code> strategies, persist SafeRound audit events, and run property tests confirming sum-preservation and bias absence. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendix C — governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit/integration tests for changed behavior and golden updates where classification changes. <br>2. New <code>ErrorCodes</code> require migration manifest, OWNER approval, and release-manifest entry. <br>3. Serialization changes require cross-language parity tests (VBA/JS/Python/C#). <br>4. Template/localization changes require L10N review and translation tests. <br><strong>Blocking conditions:</strong> missing audit emits for critical flows, PII leakage detection, or failing migration tests. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendix D — long-form incident reconstruction example (ordered):</strong><br><strong>Incident:</strong> Allocation mismatch reported for run <code>r-20260112-455</code> <br><strong>Forensic reconstruction steps:</strong><br>1. Retrieve <code>UserAction</code> and <code>REG_Error</code> audit rows for <code>correlationId=r-20260112-455</code>. <br>2. Download <code>evidenceRef</code> artifacts (serialized RNG state, SafeRound inputs) from evidence store and decrypt using <code>CORE_KeyManager</code> with audited access. <br>3. Restore RNG via <code>DeterministicRNG.restore_state()</code> and canonical decimal snapshots to rerun allocation deterministically. <br>4. Re-run allocation pipeline in replay mode using persisted RNG and <code>SafeRoundResiduals</code>; compute artifact checksum. <br>5. Compare replay checksum to original artifact checksum recorded in <code>util.atomic_write.completed</code>. <br>6. If mismatch found, collect <code>atomic_write.verification_failed</code> rows, temp artifacts, and include them in <code>forensic_manifest.json</code>. Escalate to Compliance if regulated. <br><strong>Outcome:</strong> reproducible replay confirms pipeline correctness or reveals root-cause and remediation path. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ & DAX short checklists for template authors and report builders (actionable):</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> in template metadata and publish manifest. <br>2. Flag <code>requiresHighPrecision</code> and document numeric expectations. <br>3. Parameterize preview seed and persist seed in <code>pq_preview</code> audit for reproducibility. <br>4. Offload final numeric aggregation to worker <code>SafeRound</code> for regulated templates; persist authoritative artifact via <code>AtomicWrite</code>. <br>5. For regulated templates require owner-approved signed manifest before publishing. <br><strong>DAX/report builder checklist:</strong><br>1. Read <code>RunMetadata</code> for provenance and <code>artifactChecksum</code>. <br>2. Avoid rounding residuals and allocation logic in DAX; perform in ETL and persist integer cents. <br>3. Use hashed stable keys created in ETL for deterministic sampling within DAX filters. <br>4. Display only generic health flags and <code>correlationId</code> pointer for operator diagnostics. </td></tr><tr><td data-label="REG_Error — Per-function Expert Technical Breakdown"> <strong>Final mandatory constraints (non-negotiable):</strong><br>1. All artifacts consumed by other processes must be persisted via <code>AtomicWrite</code>. <br>2. Deterministic RNGs must be seeded from <code>correlationId</code> for operator-visible sampling and tie-breakers; persist RNG state when replay required. <br>3. All critical operations affecting persisted artifacts or regulated outputs must emit <code>error.audit.emit</code> and include <code>evidenceRef</code> when necessary. <br>4. UI-thread functions must not perform IO or heavy evidence persistence; schedule to worker. <br>5. PII must never appear in top-level audit rows; store sanitized evidence encrypted and reference by <code>evidenceRef</code>. <br><strong>Verification:</strong> CI static analyzers enforce forbidden patterns, golden parity tests, and audit emission validation as blocking checks. <br><strong>Checked:</strong> taxonomy coverage, audit chain completeness, deterministic chain (UI → job → worker → artifact → audit → replay), PQ & DAX conceptual mappings, operator runbooks, and forensic evidence handling — internal consistency audited and cross-validated. </td></tr></tbody></table></div><div class="row-count">Rows: 38</div></div><div class="table-caption" id="Table3" data-table="Docu_0179_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Ribbon — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Ribbon — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_TOOLS recorded in OWNERS.md and release manifests; include <code>owner_contact</code>, <code>oncall_rotation</code>, and <code>maintenance_window</code> in manifest for triage and deployment scheduling. <br><strong>Public API / exported handlers (surface):</strong> <code>OnRibbonLoad</code>, <code>OpenLibraryPane</code>, <code>RefreshLibraryIndex</code>, <code>ListTemplates</code>, <code>PreviewTemplate(templateId, params, options, correlationId)</code>, <code>ParameterizeTemplate(templateId, paramMap, correlationId)</code>, <code>ValidateTemplateIntegrity(mChecksum, templateBlob, correlationId)</code>, <code>InjectTemplateToWorkbook(templateId, paramMap, options, correlationId)</code>, <code>Add_Query_From_M(name, mFormula, correlationId)</code>, <code>CreateConnection(connectionSpec, options, correlationId)</code>, <code>RefreshQuery(queryName, refreshOptions, correlationId)</code>, <code>ExportTemplate(templateId, destinationSpec, correlationId)</code>, <code>CollectDiagnostics(runId, correlationId)</code>, <code>ValidateHostCapabilities(hostInfo, correlationId)</code>, <code>EnsurePQRuntimeVersion(requiredVersion, correlationId)</code>, <code>RequestTwoPersonApproval(changeRequest, correlationId)</code>, <code>EmitUserActionAudit(procedure, correlationId, params)</code>. <br><strong>Primary audits emitted (canonical examples):</strong> <code>pq.ribbon.load</code>, <code>pq.library.opened</code>, <code>pq.library.refreshed</code>, <code>pq.template.preview.start</code>, <code>pq.template.preview.complete</code>, <code>pq.template.preview.failed</code>, <code>pq.template.inject.attempt</code>, <code>pq.template.inject.completed</code>, <code>pq.template.inject.failed</code>, <code>pq.connection.created</code>, <code>pq.refresh.start</code>, <code>pq.refresh.complete</code>, <code>pq.export.attempt</code>, <code>pq.export.completed</code>, <code>pq.diagnostics.collected</code>, <code>pq.ensuredeps.reported</code>, <code>pq.template.validation.failed</code>, <code>pq.approval.requested</code>, <code>pq.approval.granted</code>, <code>pq.approval.denied</code>. Every audit row MUST include <code>correlationId</code>, <code>module=PQ_Ribbon</code>, <code>procedure</code>, <code>paramsHash</code>, <code>resultHash</code> (when applicable), <code>timestamp</code>, <code>operatorId</code> (if UI-initiated), and <code>evidenceRef</code> when large artifacts or nondisclosable parameters are stored. <br><strong>Purpose and intended use:</strong> Ribbon acts as the authoritative, auditable operator surface for Power Query template lifecycle: discovery, preview, parameterization, safe injection, connection creation, refresh orchestration, export, and diagnostics. It enforces deterministic behaviors (seed propagation), integrity (mChecksum & signatures), auditability (uniform audit schema and evidence references), operational safety (no heavy UI-thread IO), and governance (two-person approvals, regulated template handling). <br><strong>Non-goals / constraints:</strong> Ribbon MUST NOT perform heavy network or filesystem IO on the UI thread; MUST NOT implement numerically-sensitive aggregation or rounding logic (delegate to worker <code>SafeRound</code> workflows); MUST NOT store credentials in audit rows or evidence in cleartext; MUST avoid assumptions about host PQ decimal semantics; MUST NOT persist artifacts without <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. <strong>UI responsiveness:</strong> ribbon handler entrypoints return within UI idle budget; any expensive work scheduled to worker/off-thread. <br>2. <strong>Audit-first behavior:</strong> every operator-triggered control emits a <code>UserAction</code> audit row before any side-effecting operation. <br>3. <strong>Deterministic preview & sampling:</strong> previews that use sampling must record deterministic RNG seeds derived from <code>correlationId</code> and <code>templateId</code>, and persist RNG state when exact replay is required. <br>4. <strong>Integrity-first injection:</strong> template M must match <code>mChecksum</code>, and regulated templates require owner signature validation before injection proceeds. <br>5. <strong>Idempotency:</strong> injections are idempotent for identical <code>(templateId, paramsHash, targetWorkbookId)</code> inputs; duplicate injection attempts are detected and skipped with <code>pq.template.inject.skipped</code>. <br>6. <strong>Rollback capability:</strong> any replace operation must create a <code>backupArtifact</code> persisted via <code>AtomicWrite</code> before mutation to support restoration. <br>7. <strong>Observability:</strong> long-running operations emit start/complete audits; metrics buffered locally and uploaded by core telemetry. <br><strong>Performance SLOs:</strong> UI actions <100ms median; client-light preview <3s for small datasets; worker-backed preview <10s for moderate workloads; atomic export median local SSD <200ms. <br><strong>CI / acceptance gates:</strong> golden <code>mChecksum</code> parity tests, static analyzer forbidding UI-thread file I/O, audit emission tests, cross-host deterministic parity test harness for previews. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Cross-cutting invariants & design constraints (must/shall):</strong><br>1. All public functions accept or produce a <code>correlationId</code> and propagate it downstream. <br>2. Top-level audit fields MUST NOT include raw PII; sanitized parameters stored encrypted in evidence store and referenced by <code>evidenceRef</code>. <br>3. All durable artifacts (job descriptors, template exports, backups, diagnostics) MUST be persisted using <code>AtomicWrite</code>. <br>4. Deterministic seeds MUST be derived using <code>HMAC_SHA256(correlationId | templateId | salt)</code>; store <code>seedFingerprint</code> in audits but never the raw seed value. <br>5. Two-person approvals are required for regulated templates and manifest-changing releases; approval artifacts must be tamper-evident and persisted with <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>OnRibbonLoad()</code> — lifecycle initialization (detailed):</strong><br><strong>Purpose & contract:</strong> initialize ribbon UI, lightweight caches, correlation generator, and audit buffer. Must not perform heavy IO on UI thread. <br><strong>Detailed steps:</strong><br>1. Validate minimal host capabilities via <code>ValidateHostCapabilities()</code> and record <code>pq.ensuredeps</code> if degraded.<br>2. Instantiate <code>correlationId</code> generator utility accessible by UI handlers; ensure deterministic format (e.g., <code>r-YYYYMMDD-HHMMSS-&lt;short-rand&gt;</code>).<br>3. Load only embedded template metadata (hidden-sheet) into read-only cache; do not load full template blobs. <br>4. Register control callbacks (each wrapper calls <code>EmitUserActionAudit</code> before delegating). <br>5. Initialize LRU caches for <code>templateMetadata</code>, <code>recentPreviews</code>, and <code>hostCapabilitySnapshot</code>. <br>6. Emit <code>pq.ribbon.load(correlationId, hostVersion, pqRuntimeVersion, cacheStateHash)</code>. <br><strong>Failure handling:</strong> mark ribbon as degraded if essential capabilities missing; expose only safe read-only operations and present remediation guidance; emit <code>pq.ribbon.degraded</code> with <code>deps.report</code> link. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>OpenLibraryPane()</code> — template catalog UX entry:</strong><br><strong>Purpose & contract:</strong> present template library UI from cached metadata; avoid heavy remote fetches on UI thread. <br><strong>Behavior & UX rules:</strong><br>1. Render embedded templates and metadata from hidden-sheet synchronously. <br>2. Allow remote refresh request; schedule <code>RefreshLibraryIndex()</code> as background job and show <code>lastRefreshedTs</code>. <br>3. Expose deterministic filters such as <code>requiresHighPrecision</code>, <code>regulated</code>, <code>owner</code>, and <code>tags</code>. <br>4. Emit <code>pq.library.opened(correlationId, source, templateCount)</code>. <br><strong>Offline behavior:</strong> present embedded-only view and emit <code>pq.library.offline</code> audit; mark templates requiring worker connectors as <code>remote-only</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>RefreshLibraryIndex(repoConfig, correlationId)</code> — authoritative index refresh (background):</strong><br><strong>Purpose & contract:</strong> fetch, validate, normalize remote index, compute <code>repo.hash</code>, and persist <code>indexSnapshot.json</code> via <code>AtomicWrite</code>. Must be background. <br><strong>Algorithm & steps:</strong><br>1. Validate <code>repoConfig</code> schema and test credentials without storing raw secrets. <br>2. Fetch index manifest (HTTP/HTTPS or internal file share) and validate <code>indexChecksum</code>. <br>3. Validate each template manifest: presence of <code>owner</code>, <code>mChecksum</code>, <code>templateVersion</code>, <code>tags</code>, and <code>requiresHighPrecision</code> flags. <br>4. Apply idempotent migrations if index schema updated. <br>5. Compute <code>indexSnapshotHash</code> and persist via <code>AtomicWrite(indexSnapshotPath)</code>. <br>6. Emit <code>pq.library.refreshed(correlationId, repo.hash, indexSnapshotChecksum, templateCount)</code>. <br><strong>Retries & recovery:</strong> wrap network fetch in <code>Retry</code> with deterministic jitter for CI tests; on auth failure emit <code>pq.library.auth_failed</code> and produce remediation steps. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>ListTemplates(filter, sortOrder, correlationId)</code> — deterministic listing API:</strong><br><strong>Purpose & contract:</strong> return stable deterministic list view to the UI using canonical sort keys to avoid UI churn. <br><strong>Stable sort invariant:</strong> sort by <code>(owner asc, canonicalTags asc, version desc, title asc, templateId asc)</code>. <br><strong>Filtering supported:</strong> <code>requiresHighPrecision</code>, <code>regulated</code>, <code>owner</code>, <code>tags</code>, <code>versionRange</code>. <br><strong>Audit:</strong> <code>pq.library.listed(correlationId, filterHash, resultCount)</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>ParameterizeTemplate(templateId, paramMap, correlationId)</code> — canonical parameterization (pure):</strong><br><strong>Purpose & contract:</strong> validate parameter types against template parameter schema, coerce values into canonical forms, compute <code>paramsHash</code>, and render <code>parameterizedM</code>. No side-effects. <br><strong>Canonicalization rules & steps:</strong><br>1. Type coercion rules:<br>   1.1 Dates → ISO 8601 UTC normalized representation; if timezone absent, treat as naive UTC and record <code>timezoneAssumed:UTC</code> in canonical blob.<br>   1.2 Decimals → canonical decimal string using fixed-scale or explicit exponent (no locale formatting).<br>   1.3 Booleans → <code>true</code> / <code>false</code> canonical strings.<br>   1.4 Lists → ordered deterministic serialization (preserve explicit order unless schema allows sorting).<br>2. Validate enumerations, min/max constraints, and requiredness; emit <code>pq.template.parameterize.invalid_input</code> audits on failure.<br>3. Sort parameter keys lexicographically and compute <code>paramsHash = SHA256(sorted(k=v))</code>.<br>4. Perform template substitution with deterministic templating engine avoiding locale-specific formatting. <br>5. Return <code>{parameterizedM, paramsHash, canonicalParamsBlob}</code>. <br><strong>Audit:</strong> <code>pq.template.parameterize(correlationId, templateId, paramsHash)</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>ValidateTemplateIntegrity(mChecksum, templateBlob, correlationId)</code> — checksum & signature validation:</strong><br><strong>Purpose & contract:</strong> ensure template content equals declared <code>mChecksum</code> and validate owner signature chain for regulated templates. Return pass/fail with diagnostics. <br><strong>Steps & policies:</strong><br>1. Compute <code>computedChecksum = SHA256(templateBlob)</code>.<br>2. If mismatch, emit <code>pq.template.validation.failed(correlationId, templateId, expected=mChecksum, actual=computedChecksum)</code> and produce <code>diagnosticsRef</code> for forensic analysis. <br>3. For <code>regulated=true</code> templates, verify detached signature: check owner fingerprint against <code>OWNERS.md</code> and release manifest; if missing or invalid, emit <code>pq.template.validation.signature_failed</code>. <br>4. On success emit <code>pq.template.validation.passed(correlationId, templateId, mChecksum)</code>. <br><strong>Runbook:</strong> mismatches require CI golden vector comparison and possible repo rollback; record <code>validationFailureReason</code> in forensic manifest. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>PreviewTemplate(templateId, paramMap, previewOptions, correlationId)</code> — multi-mode preview orchestration:</strong><br><strong>Purpose & contract:</strong> produce reproducible preview via client-light sandbox or worker-backed authoritative execution; deterministic previews must persist RNG state evidence. <br><strong>Detailed flow & determinism rules:</strong><br>1. Call <code>ParameterizeTemplate</code> to get <code>parameterizedM</code> & <code>paramsHash</code>. <br>2. Emit <code>pq.template.preview.start(correlationId, templateId, paramsHash, previewMode)</code>. <br>3. Seed derivation: <code>seed = HMAC_SHA256(correlationId | templateId | &quot;preview-vX&quot;)</code> unless caller provides <code>previewOptions.seed</code>; persist <code>seedFingerprint</code> in audit (never raw seed). <br>4. Modes:<br>   4.1 <strong>Client-light:</strong> run a sandboxed restricted M interpreter for limited connectors; suitable for rapid interactive feedback; return first N rows as <code>previewRows</code>; compute <code>previewChecksum</code>. <br>   4.2 <strong>Worker-backed authoritative:</strong> persist <code>previewJobDescriptor</code> via <code>AtomicWrite</code>, schedule worker; worker instantiates <code>DeterministicRNG(seed)</code>, normalizes decimals, uses <code>SafeRound</code> for numeric-critical steps, executes with full connector stack, persists <code>previewPayload</code> and diagnostics via <code>AtomicWrite</code>, and returns <code>previewChecksum</code> and <code>evidenceRef</code>. <br>5. On success emit <code>pq.template.preview.complete(correlationId, templateId, previewChecksum, evidenceRef, durationMs)</code>. <br>6. On error emit <code>pq.template.preview.failed(correlationId, templateId, errorCode, diagnosticsRef)</code> with sanitized user-facing text. <br><strong>Replay invariant:</strong> <code>parameterizedM</code> + <code>seedFingerprint</code> + persisted RNG serialized state + <code>previewPayload</code> must reproduce identical preview. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>InjectTemplateToWorkbook(templateId, paramMap, options, correlationId)</code> — safe injection orchestration:</strong><br><strong>Purpose & contract:</strong> add or update queries in the active workbook in an idempotent, auditable, reversible, and integrity-verified manner. <br><strong>Supported modes:</strong> <code>create_new_query</code>, <code>replace_existing</code>, <code>replace_in_named_query</code>, <code>inject_as_connection_only</code>. <br><strong>Preflight checklist (must/shall):</strong><br>1. <code>ValidateTemplateIntegrity</code> must pass. <br>2. <code>ParameterizeTemplate</code> computed <code>paramsHash</code>. <br>3. Operator permissions validated via <code>ValidateUserPermissions</code>. <br>4. If <code>options.requireTwoPersonApproval</code> then <code>RequestTwoPersonApproval</code> must complete. <br>5. If <code>options.atomicPersist==true</code>, persist <code>parameterizedM</code> + manifest via <code>AtomicWrite</code> and compute <code>artifactChecksum</code>. <br><strong>Critical injection sequence (atomic & verifiable):</strong><br>1. Emit <code>pq.template.inject.attempt(correlationId, templateId, paramsHash, mode, targetWorkbookId)</code>.<br>2. If replacing, persist <code>backupArtifact</code> via <code>AtomicWrite(backupPath)</code> before any workbook mutation. <br>3. Invoke <code>Add_Query_From_M</code> (trusted helper) to perform <code>wb.Queries.Add(Name, Formula)</code> or <code>wb.Queries.Item(queryName).Formula = formula</code> for replace; handle host exceptions. <br>4. After insertion, read back formula text and compute <code>sha256</code>; it must match <code>artifactChecksum</code>. If mismatch, attempt immediate rollback using <code>backupArtifact</code>; emit <code>pq.template.inject.verification_failed</code> with <code>diagnosticsRef</code>. <br>5. On success, emit <code>pq.template.inject.completed(correlationId, queryName, artifactChecksum, durationMs)</code> and update workbook-level registry for injected artifacts. <br>6. If identical artifact exists (same <code>artifactChecksum</code> and <code>paramsHash</code>), emit <code>pq.template.inject.skipped(correlationId, reason=duplicate)</code> and return reference to existing query. <br><strong>Failure & escalation:</strong> if rollback fails, mark workbook read-only, collect <code>audit_tail.csv</code>, persisted artifacts, and open incident attaching <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>Add_Query_From_M(name, mFormula, correlationId)</code> — trusted insertion primitive:</strong><br><strong>Purpose & contract:</strong> single trusted point of workbook modification. Validates names, performs insertion via host API, verifies inserted formula matches persisted artifact checksum, and returns canonical result object. <br><strong>Behavior & safeguards:</strong><br>1. Validate <code>name</code> against workbook naming rules and reserved namespace for add-in managed queries. <br>2. Perform insertion using host automation wrapper that maps host exceptions to canonical error codes (<code>PQ_INJECT_API_ERROR</code>, <code>PQ_INJECT_EPERM</code>). <br>3. Read back inserted formula, compute checksum, and verify equality to expected <code>artifactChecksum</code>. On mismatch delete inserted query and return verification failure. <br>4. Emit <code>pq.template.inject.inserted(correlationId, name, artifactChecksum)</code>. <br><strong>UI thread safety:</strong> if insertion may block, schedule via idle callback or delegate to worker injection agent. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>CreateConnection(connectionSpec, options, correlationId)</code> — provider connection creation & registration:</strong><br><strong>Purpose & contract:</strong> create provider connections idempotently and auditably without storing credentials in audits; provide fingerprinting for later reuse. <br><strong>Steps & behaviors:</strong><br>1. Normalize <code>connectionSpec</code> and compute <code>connectionFingerprint = SHA256(normalizedSpec)</code> excluding secrets. <br>2. If identical fingerprint exists in workbook, return existing connection and emit <code>pq.connection.reused(correlationationId, connectionName)</code>. <br>3. Otherwise create connection via host API, persist metadata (no credentials) and emit <code>pq.connection.created(correlationId, provider, connectionName, connectionFingerprint)</code>. <br>4. On failure due to provider mismatch emit <code>pq.connection.creation.failed</code> and recommend worker-run connectors. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>RefreshQuery(queryName, refreshOptions, correlationId)</code> — refresh orchestration with robust diagnostics:</strong><br><strong>Purpose & contract:</strong> refresh one or more queries while capturing diagnostics, supporting retries for transient provider failures, and offering dry-run preview capabilities. <br><strong>Flow & observability:</strong><br>1. Emit <code>pq.refresh.start(correlationId, queryName, refreshOptions)</code>. <br>2. For provider calls apply <code>Retry</code> for transient error classes with deterministic jitter for CI. <br>3. Collect diagnostics: <code>startTs</code>, <code>endTs</code>, <code>provider</code>, <code>rowsFetched</code>, <code>providerErrors</code>, <code>stackTrace</code>, <code>memorySnapshot</code> if available. <br>4. Persist diagnostics via <code>CollectDiagnostics</code> producing <code>diagnosticsRef</code>. <br>5. Emit <code>pq.refresh.complete(correlationId, queryName, elapsedMs, rowCount, diagnosticsRef)</code> or <code>pq.refresh.failed(correlationId, queryName, errorCode, diagnosticsRef)</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>ExportTemplate(templateId, destinationSpec, correlationId)</code> — atomic export of artifact package:</strong><br><strong>Purpose & contract:</strong> persist an export package (M, manifest, optional diagnostics) atomically using <code>AtomicWrite</code>, compute <code>artifactChecksum</code>, and support staged fallback on network filesystems. <br><strong>Detailed steps:</strong><br>1. Assemble streamable payload: <code>template.m</code>, <code>manifest.json</code>, optional <code>diagnostics.zip</code> and <code>readme.md</code>. <br>2. Compute <code>artifactChecksum</code> and call <code>AtomicWrite(destinationPath, payloadStream, fsyncFile=true, fsyncParent=true)</code>. <br>3. On success emit <code>pq.export.completed(correlationId, destinationUri, artifactChecksum)</code>. <br>4. On atomicity degradation (network FS rename not safe) emit <code>pq.export.degraded</code> and record fallback staging path. <br>5. On persistent failure (ENOSPC, EPERM) use <code>Retry</code> and escalate with <code>forensic_manifest</code> when exhausted. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>CollectDiagnostics(runId, correlationId)</code> — diagnostics aggregation & sanitation:</strong><br><strong>Purpose & contract:</strong> gather host and worker logs, sanitize PII, compress into diagnostics bundle and persist via <code>AtomicWrite</code>; return <code>diagnosticsRef</code> for audits. <br><strong>Steps & policies:</strong><br>1. Aggregate logs: host PQ runtime traces, worker logs, preview parse traces, provider error traces, and telemetry snippets. <br>2. Sanitize PII: replace or hash personal identifiers using per-run salt; persist sanitized mapping separately in encrypted evidence if policy allows. <br>3. Compress into <code>diagnosticsBundle.zip</code>, compute <code>diagnosticsChecksum</code> and persist via <code>AtomicWrite</code>. <br>4. Emit <code>pq.diagnostics.collected(correlationId, runId, diagnosticsChecksum, evidenceRef)</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>ValidateHostCapabilities(hostInfo, correlationId)</code> — discovery & gating:</strong><br><strong>Purpose & contract:</strong> detect host PQ runtime version, provider list, workbook model capabilities, and file system access; produce compatibility recommendation and <code>pq.ensuredeps</code> audit. <br><strong>Outputs:</strong> <code>hostVersion</code>, <code>pqRuntimeVersion</code>, <code>availableProviders</code>, <code>workbookModelCapabilities</code> (PowerPivot, Data Model), <code>filesystemAccess</code> (add-in writable paths), <code>recommendedExecutionMode</code> (<code>client|worker</code>). <br><strong>Policy:</strong> if required features missing for regulated templates, block inline injection and recommend worker-backed execution; emit <code>pq.ensuredeps.degraded</code> with details. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>EnsurePQRuntimeVersion(requiredVersion, correlationId)</code> — version gating and migration hints:</strong><br><strong>Purpose & contract:</strong> determine whether host PQ runtime meets <code>requiredVersion</code> and recommend degraded behaviors or worker delegation; emit <code>pq.ensuredeps</code> with <code>pass|degraded|fail</code>. <br><strong>Behavior:</strong> if runtime older, annotate template actions with <code>degradedReason</code>, produce <code>deps.report.json</code>, and add telemetry for platform incompatibility metrics. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>RequestTwoPersonApproval(changeRequest, correlationId)</code> — tamper-evident approval flow:</strong><br><strong>Purpose & contract:</strong> implement two-person approval for regulated template edits, releases, or auto-apply templates; persist approval artifacts via <code>AtomicWrite</code> and block guarded operations until approval recorded. <br><strong>Flow & assurance:</strong><br>1. Persist <code>approvalRequest</code> with <code>changeRequestId, templateId, artifactChecksum, requestorId, policyTag</code> using <code>AtomicWrite</code>. Emit <code>pq.approval.requested</code>. <br>2. Notify approvers via configured channels and await signed approve/deny. <br>3. Persist <code>approvalGrant</code> artifact with <code>approverId</code>, <code>signedTimestamp</code>, and <code>approvalEvidenceRef</code> and emit <code>pq.approval.granted</code> or <code>pq.approval.denied</code>. <br>4. Only proceed with original operation after recorded approval artifact is present and verified. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong><code>EmitUserActionAudit(procedure, correlationId, params)</code> — canonical user-action audit emitter:</strong><br><strong>Purpose & contract:</strong> centralize user-action audit emission so UI actions have uniform audit rows; offload large parameter storage to evidence store if size exceeds threshold. <br><strong>Rules & process:</strong><br>1. Compute <code>paramsHash = SHA256(sorted(k=v))</code>. <br>2. If <code>size(params) &gt; evidenceThreshold</code> persist sanitized params via <code>AtomicWrite</code> and set <code>evidenceRef</code>. <br>3. Emit <code>UserAction</code> audit row: <code>timestamp, correlationId, module=PQ_Ribbon, procedure, operatorId, paramsHash, evidenceRef, uiControlId</code>. <br>4. Enforce PII redaction before persisting evidence; evidence must be encrypted and access-controlled. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Error taxonomy & operator-facing messaging (representative):</strong><br><strong>Representative error codes & guidance:</strong><br>1. <code>PQ_INJECT_EPERM</code> — permission denied; guidance: check macro enablement, workbook protection, and IT macro policy.<br>2. <code>PQ_INJECT_API_ERROR</code> — host API error; guidance: collect <code>pq.diagnostics</code>, try worker-backed injection, or run injection during maintenance window.<br>3. <code>PQ_VALIDATION_MISMATCH</code> — <code>mChecksum</code> mismatch; guidance: verify template source, re-fetch <code>mChecksum</code>, and validate signature chain.<br>4. <code>PQ_PREVIEW_PARSING_ERROR</code> — M parse error; guidance: present sanitized parse location and stack to template author for correction.<br>5. <code>PQ_EXPORT_ENOSPC</code> — destination out-of-space; guidance: stage-local fallback or free space and re-run export. <br>Each error code must map to a runbook with prioritized remediation steps and escalation levels for compliance-impacting failures. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Observability & telemetry (detailed):</strong><br><strong>Audit schema for PQ_Ribbon events:</strong> <code>timestamp, correlationId, module=PQ_Ribbon, procedure, operatorId, paramsHash, resultHash, evidenceRef, durationMs, metadata</code> where metadata includes <code>previewMode</code>, <code>templateVersion</code>, <code>mChecksum</code>, <code>hostVersion</code>, <code>pqRuntimeVersion</code>, <code>artifactChecksum</code>. <br><strong>Key metrics buffered locally:</strong> <code>pq.preview.latency_ms</code>, <code>pq.inject.count</code>, <code>pq.inject.success_rate</code>, <code>pq.export.latency_ms</code>, <code>pq.refresh.failure_rate</code>, <code>pq.diagnostics.size_bytes</code>. <br><strong>Privacy rule:</strong> top-level audit rows must not contain PII; full sanitized params stored in encrypted evidence with <code>evidenceRef</code>. <br><strong>Retention policy:</strong> evidence hot 30 days; warm archive 7 years for regulated artifacts; <code>housekeeping.audit</code> emitted for rotation operations. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Security & governance constraints (non-negotiable):</strong><br>1. XLAM and any helper automation must be code-signed by trusted publisher for production deployment; unsigned code is blocked. <br>2. Regulated templates require manifest signatures, owner verification, and CI golden checks before injection into production workbooks. <br>3. Macro enablement policies enforced; ribbon detects disabled macros and surfaces operator guidance. <br>4. Credentials must never appear in audit rows; connection fingerprints only. <br>5. Two-person approvals recorded as tamper-evident artifacts persisted via <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Testing matrix & CI governance (comprehensive):</strong><br><strong>Unit tests (representative):</strong><br>1. <code>ParameterizeTemplate</code> canonicalization property tests (nulls, timezone edge cases, empty arrays).<br>2. <code>ValidateTemplateIntegrity</code> checksum & signature validation tests including corrupted artifacts. <br>3. <code>PreviewTemplate</code> deterministic parity and replay tests using seeded RNG and persisted RNG state. <br>4. <code>InjectTemplateToWorkbook</code> idempotency, backup/rollback, and concurrent insertion tests. <br><strong>Integration tests:</strong><br>1. End-to-end preview -> inject -> refresh with worker-backed preview and persisted artifact checksum verification. <br>2. <code>ExportTemplate</code> atomicity across local and network filesystems simulating rename/fsync failures. <br>3. Offline hidden-sheet fallback and subsequent reconciliation upon reconnection. <br><strong>Property tests:</strong> deterministic seed parity across language implementations; <code>paramsHash</code> collision resistance via fuzzing; idempotency invariants. <br><strong>CI gating rules:</strong> goldens must pass; static analyzer forbids UI-thread I/O; audit emission harness must verify required fields. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Developer guidance: required & forbidden patterns (explicit):</strong><br><strong>Required patterns:</strong><br>1. Always call <code>EmitUserActionAudit</code> for user-visible control activations. <br>2. Use <code>AtomicWrite</code> for persisting artifacts and job descriptors. <br>3. Seed <code>DeterministicRNG</code> from <code>correlationId</code> for operator-visible sampling; persist <code>rng_state</code> when deterministic replay required. <br>4. Offload numerically sensitive transforms to worker <code>SafeRound</code> primitives. <br><strong>Forbidden patterns:</strong><br>1. Do not perform network fetches or large disk writes on UI event handlers. <br>2. Do not include raw PII in top-level audit rows. <br>3. Do not rely on host PQ decimal semantics for regulated outputs. <br>4. Do not write final artifacts directly from UI thread—use <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (executable):</strong><br><strong>Inject verification mismatch runbook:</strong><br>1. Find <code>pq.template.inject.failed</code> audit for the <code>correlationId</code>. <br>2. Download persisted artifact via <code>evidenceRef</code> and compute <code>artifactChecksum</code>; compare to workbook content. <br>3. If mismatch, restore workbook from <code>backupArtifact</code> persisted before injection. <br>4. If restore fails, quarantine workbook (mark read-only), collect <code>audit_tail.csv</code> and <code>forensic_manifest.json</code> and escalate to SRE/compliance. <br><strong>Preview parity complaint triage:</strong><br>1. Retrieve <code>pq.template.preview.*</code> audits and <code>seedFingerprint</code>. <br>2. Fetch serialized RNG state via <code>evidenceRef</code> and run <code>replay.run</code> to reproduce preview. <br>3. If mismatch remains, compare <code>pqRuntimeVersion</code> across host and worker parity vectors and escalate to cross-platform owners. <br><strong>Export ENOSPC triage:</strong><br>1. Inspect <code>pq.export.failure</code> audit and <code>destinationUri</code>. <br>2. Attempt <code>--stage-local</code> fallback and verify checksums; open infra ticket with <code>forensic_manifest</code> if unresolved. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples — multi-scenario trails (deep forensic detail):</strong><br><strong>Scenario 1 — Regulated high-precision allocation with full reproducibility chain:</strong><br>1. Operator opens PQ_Ribbon and selects <code>LedgerAllocV3</code>; UI emits <code>pq.library.opened</code>. <br>2. Operator clicks <code>Preview</code>; <code>EmitUserActionAudit</code> records the click with <code>correlationId=r-20260117-alloc</code>. <br>3. <code>ParameterizeTemplate</code> canonicalizes parameters (<code>periodStart=2024-12-01T00:00:00Z</code>, <code>totalAmount=1234567.89123</code>) and computes <code>paramsHash</code>. <br>4. <code>PreviewTemplate</code> detects <code>requiresHighPrecision=true</code> and schedules worker-backed preview; <code>previewJobDescriptor</code> persisted via <code>AtomicWrite</code> includes <code>correlationId</code>, <code>templateId</code>, <code>paramsHash</code>, and <code>seedFingerprint</code>. <code>pq.template.preview.start</code> emitted. <br>5. Worker reconstructs RNG via <code>DeterministicRNG(seed=HMAC(r-20260117-alloc|templateId))</code>, emits <code>util.rng.seeded</code>, canonicalizes decimals, computes floors/residuals and calls <code>SafeRoundResiduals</code> to guarantee sum-preservation. Worker persists <code>previewPayload</code> and <code>rng_state.blob</code> via <code>AtomicWrite</code>, emits <code>pq.template.preview.complete</code> with <code>previewChecksum</code> and <code>evidenceRef</code>. <br>6. Operator approves injection; ribbon requires two-person approval per policy. <code>RequestTwoPersonApproval</code> persists approval artifact; <code>pq.approval.granted</code> emitted. <br>7. <code>InjectTemplateToWorkbook</code> persists definitive <code>parameterizedM</code> via <code>AtomicWrite(artifactPath)</code>, uses worker injection agent to safely insert validated formula, and <code>pq.template.inject.completed</code> emitted with <code>artifactChecksum</code>. <br>8. Forensic replay: given <code>correlationId</code> investigator fetches audits, <code>jobDescriptor</code>, <code>rng_state.blob</code>, and <code>previewPayload</code>, re-runs worker pipeline, and reproduces allocation exactly. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Scenario 2 — Template author release lifecycle with CI golden gating and rollback:</strong><br>1. Author pushes <code>tpl-invoice-v1.1</code> to repo; CI triggered by <code>RefreshLibraryIndex</code> verifies manifests and runs cross-host golden parity checks for M outputs. <br>2. Failure in cross-host parity blocks release; <code>pq.library.ci.failure</code> indicated in release manifest. <br>3. On pass, release manifest is signed and <code>indexSnapshot</code> updated; <code>pq.library.refreshed</code> audit emitted. <br>4. If an issue arises in production, owners can <code>rollback</code>; rollback artifact persisted via <code>AtomicWrite</code> and recorded audit <code>pq.template.rollback.completed</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Scenario 3 — Offline workstation with embedded hidden-sheet fallback and authoritative later reconciliation:</strong><br>1. Add-in loads on air-gapped host; <code>ValidateHostCapabilities</code> notes <code>network=false</code>. <code>OpenLibraryPane</code> reads embedded <code>hidden-sheet</code> templates and emits <code>pq.library.offline</code>. <br>2. Operator runs client-light preview; ribbon warns <code>requiresHighPrecision</code> templates are degraded for offline preview. <br>3. After reconnection, ribbon performs authoritative worker preview, compares results to prior offline preview, emits reconciliation reports and <code>pq.reconciliation</code> audits, and records differences in <code>recon_report.json</code>. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Scenario 4 — Injection mismatch forensic reconstruction (step-by-step):</strong><br>1. Downstream consumer flags mismatch; operator reports run <code>r-20260112-455</code>, <code>Alert</code> audit recorded. <br>2. Triage: fetch <code>pq.template.inject.*</code> audits for <code>r-20260112-455</code>. <br>3. Forensic collection: retrieve <code>artifactChecksum</code> from <code>pq.template.inject.completed</code> and download artifact via <code>evidenceRef</code>. <br>4. Restore <code>rng_state</code> if preview used seeded sampling, replay worker preview using persisted <code>parameterizedM</code> and <code>rng_state</code> to recreate <code>previewPayload</code>. <br>5. Compare replay artifact checksum with workbook content; if mismatch, examine <code>pq.template.inject.verification_failed</code> for earlier verification failures. <br>6. Inspect host logs for macro activity or external modifications; if workbook mutated post-insert, restore <code>backupArtifact</code> and apply additional protections (lock query, restrict macro execution). <br>7. Close incident after remediation; update governance to require worker-backed injection for templates flagged by observed failure modes. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — exhaustive mapping to PQ_Ribbon principles:</strong><br><strong>Context:</strong> M runs in host environments with heterogenous runtime semantics; PQ_Ribbon must orchestrate to guarantee determinism, integrity, and auditability rather than assuming host behavior. <br><strong>Patterns & recommended practices (detailed):</strong><br>1. <strong>Atomic persistence for M artifacts:</strong><br>   1.1 Problem: host injection lacks consistent atomic semantics across OS and network shares. <br>   1.2 Pattern: persist authoritative M artifact with <code>AtomicWrite</code> before any workbook modification; include <code>artifactChecksum</code> in injection audits. <br>   1.3 Rationale: allows later verification that workbook content equals persisted artifact and simplifies rollback. <br>2. <strong>Deterministic sampling for previews:</strong><br>   2.1 Problem: M PRNGs are host-dependent and often not seedable. <br>   2.2 Pattern A (client-light): compute deterministic sample indices in ribbon using <code>DeterministicRNG</code> and pass sample IDs as parameters to M. <br>   2.3 Pattern B (authoritative): run sampling in worker using <code>DeterministicRNG</code>, persist <code>rng_state</code> as evidence and <code>previewPayload</code> for UI consumption. <br>   2.4 Audit: always persist <code>seedFingerprint</code> and <code>rng_state</code> when sampling influences operator-visible outputs. <br>3. <strong>High-precision numeric transforms:</strong><br>   3.1 Problem: M decimal fidelity varies across hosts and runtimes; repeated rounding can introduce bias. <br>   3.2 Pattern: mark templates <code>requiresHighPrecision</code> and delegate aggregation/rounding (<code>SafeRound</code>, <code>SafeRoundResiduals</code>) to worker. M templates should accept canonical pre-rounded fields or call worker microservices for final rounding. <br>4. <strong>Injection idempotency & conflict handling:</strong><br>   4.1 Pattern: compute <code>artifactChecksum</code> and <code>paramsHash</code> prior to insertion; check workbook for matching artifacts and either skip duplicate injection or perform replace with backup. <br>   4.2 Persist <code>backupArtifact</code> before replacement for rollback. <br>5. <strong>Connector & provider fallbacks:</strong><br>   5.1 Pattern: when host lacks a connector, present worker-backed execution option; record fallback decision in <code>pq.ensuredeps</code> audit. <br><strong>Template author guidance:</strong> document <code>requiresHighPrecision</code> usage and prefer passing heavy connector workloads to worker-run templates for authoritative outputs. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Ribbon outputs to models & report UX (detailed):</strong><br><strong>Context:</strong> DAX is read-time only; authoritative transforms and evidence must be produced in ETL/worker prior to model consumption. <br><strong>Patterns & rules:</strong><br>1. <strong>Push rounding & allocation to ETL (worker-side):</strong><br>   1.1 Rationale: DAX cannot persist or reproducibly apply side-effecting allocation logic; ETL must compute <code>SafeRoundResiduals</code> and persist integer-cent fields. <br>   1.2 Persist <code>SafeRound</code> audit references in <code>RunMetadata</code> for reconciliation. <br>2. <strong>RunMetadata table for model provenance:</strong><br>   2.1 ETL writes <code>RunMetadata</code> atomically with fields <code>correlationId, templateId, artifactChecksum, configHash, runTs, roundingMethod, seedFingerprint</code>. <br>   2.2 DAX measures reference <code>RunMetadata</code> for provenance surfaces like <code>LastVerifiedRun</code> and <code>ArtifactChecksum</code>. <br>3. <strong>Checksum-based reconciliation surfaced in DAX:</strong><br>   3.1 ETL publishes expected dataset checksum and <code>recon_report.json</code>. <br>   3.2 DAX exposes a <code>ReconciledFlag</code> by comparing expected checksum with imported dataset fingerprint (if the model stores it) or by surfacing <code>RunMetadata</code>. <br>4. <strong>Deterministic sampling via ETL hashing:</strong><br>   4.1 ETL computes <code>HashKey = HASH(PrimaryKey | correlationSalt)</code> and persists both <code>HashKey</code> and <code>correlationSalt</code> in <code>RunMetadata</code>. <br>   4.2 DAX filters deterministically with <code>HashKey MOD N &lt; k</code> for reproducible sampling in reports. <br>5. <strong>DAX measures & UI signals:</strong> provide measures <code>IsVerified</code>, <code>ArtifactChecksumShort</code>, <code>RunCorrelationLink</code> that report provenance and link back to audits/evidence store. <br><strong>Governance rule:</strong> DAX must not perform final allocations or rounding for regulated outputs—ETL must provide canonical values. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Appendices — forensic artifacts, evidence policies & retention (PQ-specific, exhaustive):</strong><br><strong>Minimum forensic assets to collect for an incident:</strong><br>1. <code>pq_audit_tail.csv</code> containing relevant audit rows for the <code>correlationId</code>. <br>2. Persisted artifacts: <code>parameterizedM</code>, <code>manifest.json</code>, <code>injectArtifact</code> with <code>artifactChecksum</code>. <br>3. <code>jobDescriptor.json</code> and <code>previewJobDescriptor.json</code> persisted via <code>AtomicWrite</code>. <br>4. Serialized RNG state blobs <code>rng_state.blob</code> used for deterministic runs. <br>5. <code>previewPayload</code> and <code>diagnosticsBundle.zip</code> persisted via <code>AtomicWrite</code>. <br>6. <code>backupArtifact</code> persisted before replacement. <br>7. Host PQ runtime logs, worker logs, and release manifest with signatures. <br><strong>Evidence storage & retention patterns:</strong><br>1. Hot evidence store: <code>\\evidence\hot\pq\&lt;correlationId&gt;\</code> retained 30 days with restricted access. <br>2. Warm archive: secure archive with regulatory retention (7 years typical) and chain-of-custody metadata. <br>3. Forensic_manifest.json enumerates artifacts, URIs, checksums, evidenceRef, signer fingerprints and timestamps; store manifest signed by release key. <br><strong>Rotation & verification cadence:</strong> monthly automated retention verification job; emit <code>housekeeping.audit</code> summarizing rotated items and proof-of-delete for removed artifacts. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before PQ_Ribbon production release (exhaustive):</strong><br>1. OWNERS.md lists owners and approvers and routing for on-call. <br>2. Public API documented and stable; breaking changes require manifest version bump. <br>3. All persisted artifacts used by other modules employ <code>AtomicWrite</code>. <br>4. Deterministic RNG goldens and parity tests across supported runtimes implemented and passing. <br>5. <code>mChecksum</code> golden vectors validated across CI hosts. <br>6. Audit hooks validated via test harness; required fields present in audit rows. <br>7. Static analyzer verified no UI-thread file writes and flagged forbidden patterns. <br><strong>Blocking conditions:</strong> missing audit emissions in persistence flow, failing golden vectors, or forbidden-API detection. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & sample tests (conceptual & runnable guidelines):</strong><br><strong>Unit tests (representative):</strong><br>1. <code>ParameterizeTemplate</code> correctness and canonicalization for edge cases (nulls, timezone-naive dates, empty lists).<br>2. <code>ValidateTemplateIntegrity</code> checksum mismatch & signature validation tests with sample corrupted blobs. <br>3. <code>PreviewTemplate</code> deterministic replay using stored <code>rng_state</code> verifying <code>previewChecksum</code> parity. <br>4. <code>InjectTemplateToWorkbook</code> idempotency; repeated injects produce <code>pq.template.inject.skipped</code>; backup and rollback succeed on simulated host failures. <br><strong>Integration tests:</strong><br>1. End-to-end preview -> persist -> inject -> verify roundtrip with worker-backed preview. <br>2. <code>AtomicWrite</code> rename/fsync failure injection via FS mocks; ensure no partial artifact visible to readers. <br>3. Offline hidden-sheet fallback scenario and authoritative reconciliation after reconnection. <br><strong>Property tests:</strong> deterministic RNG parity across languages for first N outputs; <code>paramsHash</code> collision detection via fuzzing. <br><strong>Performance & CI gates:</strong> interactive preview latency smoke tests; no regressions permitted; static analyzer gating enforced. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & cheat-sheet (practical):</strong><br>1. <code>pq diagnostics collect --correlation r-YYYYMMDD-abc</code> — collect audit_tail.csv, serialized RNG state, preview artifacts, and forensic_manifest.json. <br>2. <code>pq template export --template tpl-id --dest \\repo\templates</code> — atomically export template and manifest. <br>3. <code>pq replay-preview --correlation r-... --evidenceRef &lt;ref&gt;</code> — replay deterministic preview for forensic reproduction. <br>4. <code>pq inject --template tpl-id --params params.json --mode replace_existing</code> — idempotent inject wrapper that persists job descriptor and performs injection via worker agent with audits. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (PQ-specific, expanded):</strong><br><strong>Failure mode: injected query differs from persisted artifact</strong><br>1. Possible causes: host auto-formatting, macros modifying workbook, interrupted host API call, or malicious post-insert modification. <br>2. Mitigation: <code>Add_Query_From_M</code> performs read-back verification; on mismatch restore from <code>backupArtifact</code> and emit <code>pq.template.inject.verification_failed</code>; lock workbook and escalate if restore fails. <br><strong>Failure mode: non-deterministic preview sampling</strong><br>1. Cause: seed not propagated or host PRNG used in M template. <br>2. Mitigation: switch to worker-backed deterministic sampling using <code>DeterministicRNG</code> and persist <code>rng_state</code> for replay; add unit tests to detect host-RNG usage in preview path. <br><strong>Failure mode: export ENOSPC</strong><br>1. Cause: destination full or insufficient quota. <br>2. Mitigation: stage-local fallback, compute artifact checksums and retry, escalate to infra with <code>forensic_manifest</code> if persistent. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Extremely detailed incident reconstruction example (PQ injection mismatch — full forensic trail):</strong><br><strong>Incident synopsis:</strong> "Injected query <code>InvoiceAgg</code> produced different sums for run <code>r-20260112-455</code>." <br><strong>Reconstruction steps:</strong><br>1. Retrieve <code>UserAction</code> and <code>pq.template.inject.*</code> audit rows for <code>correlationId=r-20260112-455</code>. <br>2. Download <code>artifactChecksum</code> from <code>pq.template.inject.completed</code> audit and fetch persisted artifact via <code>evidenceRef</code>. <br>3. Restore <code>rng_state.blob</code> used for deterministic preview (if present) and re-run worker preview pipeline using <code>parameterizedM</code> and <code>rng_state</code> to reproduce <code>previewPayload</code>. <br>4. Compute replay artifact checksum and compare to persisted artifact and workbook query content. <br>5. If workbook content differs, inspect host logs and <code>pq.diagnostics</code> for concurrent writes, macros, or external processes. <br>6. Determine root cause: host mutation, partial injection, or incorrect artifact persisted. <br>7. Remediation: if host mutated after injection, restore from <code>backupArtifact</code> and enforce workbook protections; if artifact corruption, re-publish corrected artifact and notify downstream consumers. <br>8. Produce <code>forensic_manifest.json</code> and include <code>audit_tail.csv</code>, <code>rng_state.blob</code>, <code>previewPayload</code>, <code>backupArtifact</code>, and host logs for compliance filing if regulated. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Appendix — PQ & DAX author quick checklists (actionable):</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> and <code>templateVersion</code> in manifest. <br>2. Mark <code>requiresHighPrecision</code> when numeric fidelity is required. <br>3. Parameterize seeds for preview and support deterministic preview options. <br>4. Provide <code>owner</code> and contact for approvals and CI gating. <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> for provenance displays. <br>2. Avoid allocation/rounding logic in DAX; rely on ETL <code>SafeRound</code> outputs. <br>3. Use hashed <code>PrimaryKey</code> + <code>correlationSalt</code> for deterministic sample filters in reports. </td></tr><tr><td data-label="PQ_Ribbon — Per-function Expert Technical Breakdown"> <strong>Final governance constraints (non-negotiable):</strong><br>1. Any artifact consumed by other processes must be persisted via <code>AtomicWrite</code>, include <code>paramsHash</code> and <code>artifactChecksum</code>, and be linked to a <code>correlationId</code> in audits. <br>2. Deterministic RNG seeds must be derived from <code>correlationId</code> for operator-visible sampling and serialized RNG state persisted for replay when required. <br>3. Top-level audit rows MUST NOT contain raw PII; sanitized parameters stored encrypted in evidence store and referenced by <code>evidenceRef</code>. <br>4. Two-person approval required for regulated auto-apply templates, migration manifests, or template edits affecting regulated outputs. <br>5. Numerical transforms affecting regulated outputs MUST use worker-side <code>SafeRound</code> primitives; client-side M rounding is insufficient for authoritative results. <br><strong>Checked:</strong> multiple-pass verification for internal consistency, audit coverage, determinism chain (UI → job → worker → artifact) and compliance with governance rules; cross-checked numbered lists for <code>&lt;br&gt;</code> line breaks where required. </td></tr></tbody></table></div><div class="row-count">Rows: 40</div></div><div class="table-caption" id="Table4" data-table="Docu_0179_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Config — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Config — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_CONFIG recorded in OWNERS.md, release manifests, template governance, and the operational runbook. Primary and secondary owners, on-call rotation, and escalation contacts are recorded and tested quarterly. <br><strong>Public API surface (complete):</strong> LoadConfig, LoadLocalConfig, ResolveRemoteConfig, ValidateConfigSchema, ComputeConfigHash, ApplyIdempotentMigrations, MergeOverrides, ExposeRuntimeConfig, SnapshotConfig, ConfigDiff, WatchConfigFile, SubscribeConfigChanges, ExportResolvedConfig, ConfigStoreAdapter (LocalFileAdapter, HiddenSheetAdapter, RemoteRepoAdapter, InMemoryAdapter), SecretsPlaceholderResolver, ConfigValidateAndRepair, ConfigSanitizer, ConfigAuditEmit, ConfigAccessPolicy, ConfigPermissionsCheck, ConfigRollback, ConfigHistoryList, ConfigSnapshotInspect, ConfigLint, ConfigPreviewRenderer, ConfigSchemaRegistry, ConfigChangeApprovalFlow. Each function exposes a stable contract and emits audits for critical transitions. <br><strong>Audits emitted (complete):</strong> pq.config.load.start, pq.config.load.complete, pq.config.load.failure, pq.config.validate.start, pq.config.validate.complete, pq.config.validate.failure, pq.config.sanitized, pq.config.migrations.start, pq.config.migrations.complete, pq.config.migrations.failure, pq.config.resolve_remote.start, pq.config.resolve_remote.complete, pq.config.resolve_remote.degraded, pq.config.hash.computed, pq.config.snapshot.created, pq.config.export.attempt, pq.config.export.completed, pq.config.export.failure, pq.config.watch.detected, pq.config.change.detected, pq.config.secrets.resolution.start, pq.config.secrets.resolution.complete, pq.config.diff.created, pq.config.rollback.attempt, pq.config.rollback.complete. Audit rows always include correlationId, module=PQ_Config, procedure, paramsHash, configHash (as applicable), snapshotId/evidenceRef for large payloads, operatorId when a human is involved, and machine-readable metadata. <br><strong>Purpose and intended use (expanded):</strong> act as the canonical configuration manager for PQTools and related add-ins. Responsibilities include: deterministic loading of config artifacts, validation via JSON Schema v7 (or the chosen dialect), canonicalization for stable hashing, deterministic merge/overlay of remote and local fragments, application of idempotent migrations, storage via adapters supporting hidden-sheet fallback, snapshotting into an evidence store for reproducible runs and audits, providing a secure secret placeholder model and a separate audited secret resolution service, and exposing a minimal immutable runtime view to consumers. PQ_Config enables reproducible template preview, injection, worker orchestration, CI gating, and regulated evidence packaging. <br><strong>Non-goals & constraints (explicit):</strong> do not decrypt or hold secrets in the module; do not perform blocking network I/O during add-in UI OnLoad; do not perform arbitrary file system operations outside configured adapters; do not act as a transactional coordinator for multi-artifact distributed transactions—provide higher-level orchestrators for those workflows. <br><strong>Security & governance constraints (expanded):</strong> for regulated templates and exports, require signed manifests, OWNER approvals, and two-person approval gating for destructive migrations and release-manifest changes. Evidence store entries containing PII or sensitive parameters must be encrypted with the organization’s evidence key and access controlled by RBAC. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Deterministic <code>config.hash</code>: identical resolved inputs, migration markers, and canonicalization options produce identical <code>config.hash</code> across supported runtimes. <br>2. UI fast-path guarantees: <code>LoadConfig(mode=auto|local_only)</code> completes without network calls and within UI latency budget (target median <50ms). <br>3. Migrations are idempotent: reapplying the same migration set to the same initial state is a no-op and returns stable markers. <br>4. Audited persistence: any persistent mutation or export emits at least one audit row with correlationId and evidenceRef. <br>5. Immutable runtime exposures: consumers receive immutable snapshots and must use explicit APIs to request changes. <br>6. Atomic persistence: all adapter writes must use AtomicWrite semantics and produce compound artifacts or sidecar metadata atomically. <br><strong>Performance SLOs:</strong> median local config load <30ms; remote resolution background fetch <1s for small repos; migration apply <200ms for typical small manifests; snapshot write latency depends on evidence store but should support streaming writes for large payloads. <br><strong>CI & acceptance gates:</strong> cross-language <code>config.hash</code> parity tests; schema goldens; migration idempotency tests; forbidden-API static checks preventing UI-thread IO; audit emission validation and evidenceRef integrity checks. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>LoadConfig(pathOrContext, mode=&quot;auto&quot;, correlationId=null)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> central entrypoint to return a validated immutable runtime config snapshot ready for consumer use. <code>mode</code> options: <code>auto</code> (prefer local cached snapshot, schedule remote resolve asynchronously), <code>local_only</code> (no network), <code>remote_fallback</code> (attempt remote then fallback to cache), <code>force_remote</code> (synchronous remote resolution and validation). Must avoid network I/O in <code>local_only</code> or UI <code>auto</code> fast-path. <br><strong>Parameters & return:</strong> <code>pathOrContext</code> accepts hidden-sheet descriptor (<code>hidden:PQ_Config</code>), local file path, or remote repo descriptor. Returns <code>{config:immutable, canonicalForm:string, configHash:string, snapshotId:string?, sourceDescriptor, loadedFrom:(&quot;hidden-sheet&quot;|&quot;file&quot;|&quot;cache&quot;|&quot;remote&quot;), appliedMigrations:[], validated:true|false}</code>. On failure raises structured <code>ConfigError</code> with <code>errorCode</code> and <code>diagnosticsRef</code>. Emits <code>pq.config.load.start</code> and <code>pq.config.load.complete</code> or <code>pq.config.load.failure</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic canonicalization and hashing for identical effective input. <br>2. No network I/O in UI critical path when <code>mode</code> is <code>auto</code> or <code>local_only</code>. <br>3. If migrations exist and <code>mode</code> allows and approvals present, apply them idempotently and persist the output atomically. <br><strong>Algorithm & detailed steps:</strong><br>1. Determine adapter via <code>pathOrContext</code>: HiddenSheetAdapter preferred when present; otherwise LocalFileAdapter; if <code>mode</code> allows remote and <code>pathOrContext</code> is a repo descriptor, use RemoteRepoAdapter. <br>2. Adapter.read() -> raw bytes -> compute <code>rawHash</code>. <br>3. Parse JSON to <code>configObject</code> (raise <code>PQ_CONFIG_PARSE_FAIL</code> on malformed JSON). <br>4. Call <code>ValidateConfigSchema(configObject, schema)</code>. If invalid and <code>options.allowSanitize</code>, produce a sanitized config and emit <code>pq.config.sanitized</code>; otherwise fail with diagnosticsRef. <br>5. If <code>mode</code> allows remote overlay, schedule <code>ResolveRemoteConfig</code> asynchronously unless <code>force_remote</code> requested. <br>6. Canonicalize parsed object into canonical JSON string using canonical serializer rules and call <code>ComputeConfigHash</code> to produce <code>configHash</code>. <br>7. Return snapshot with <code>configHash</code> and <code>loadedFrom</code>. If persistence required (migrations applied or snapshot requested) call <code>SnapshotConfig</code>. <br><strong>Edge cases & behaviors:</strong><br>1. If adapter.read() returns multiple versioned entries, pick the highest version according to adapter semantics but include <code>listVersions()</code> output in snapshot metadata. <br>2. For extremely large configs, perform streaming parse and canonicalization and compute streaming SHA256 to avoid OOM. <br>3. For cross-host differences in JSON parser behavior, canonicalization step normalizes types (explicitly coerce singletons vs lists per schema) before hashing. <br><strong>Observability & audit fields:</strong> pq.config.load.start(correlationId, sourceDescriptorHash) pq.config.load.complete(correlationId, configHash, snapshotId, loadedFrom, durationMs) pq.config.load.failure(correlationId, errorCode, diagnosticsRef) <br><strong>Examples & narratives:</strong><br>1. Add-in startup: <code>LoadConfig(hidden:PQ_Config, mode=auto)</code> returns immediate snapshot from embedded sheet, enabling ribbon to become responsive without waiting for network. <br>2. Worker run: <code>LoadConfig(repoDescriptor, mode=force_remote)</code> fetches and resolves central defaults, applies migrations as allowed, computes <code>configHash</code>, and persists jobDescriptor referencing <code>configHash</code> for reproducible worker runs. <br><strong>Tests & CI vectors:</strong> hidden-sheet loads, local file path loads, forced remote resolution with signature checks, malformed JSON handling, streaming canonicalization parity checks. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ValidateConfigSchema(configObject, schema, options={strict:true, allowDeprecated:false, allowSanitize:false})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic validation and diagnostics generation for <code>configObject</code> against chosen JSON Schema. Returns <code>{valid:true}</code> or <code>{valid:false, errors:[{path, code, message, suggestion}], sanitized?:object}</code> where <code>suggestion</code> may include recommended migration steps. <br><strong>Parameters & semantic behavior:</strong> <code>options.strict</code> toggles acceptance of unknown keys; <code>allowDeprecated</code> allows deprecated but documented keys; <code>allowSanitize</code> allows applying schema <code>default</code> values into a sanitized copy returned to the caller. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic error ordering: errors are sorted by JSON pointer path and canonical property order so that repeated validations produce identical diagnostics. <br>2. No mutation of input <code>configObject</code> unless <code>allowSanitize=true</code>, in which case the sanitized copy is returned separately. <br><strong>Algorithm & implementation notes:</strong><br>1. Use a canonical JSON Schema validator with deterministic traversal and stable error codes. <br>2. For <code>oneOf</code>/<code>anyOf</code>, compute candidate scores and include the closest candidate in diagnostics to help operator decisions. <br>3. For missing required fields with schema <code>default</code>, when <code>allowSanitize=true</code> apply defaults into returned sanitized object and emit <code>pq.config.sanitized</code> audit. <br>4. For deprecation warnings produce <code>PQ_CFG_DEPRECATED_KEY</code> codes with suggested replacement keys based on migration registry where available. <br><strong>Edge cases & limits:</strong> handle huge arrays by streaming validation and produce <code>PQ_CFG_TOO_LARGE</code> if memory limits exceeded with suggested chunking approach. <br><strong>Observability & audit fields:</strong> pq.config.validate.start(correlationId, schemaHash) pq.config.validate.complete(correlationId, configHash, errorsCount) pq.config.validate.failure(correlationId, errorCodes, diagnosticsRef) <br><strong>Tests:</strong> deterministic diagnostics ordering tests, default-application tests, deprecated key detection, very large payload streaming validation. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ComputeConfigHash(configCanonicalJson, algorithm=&quot;sha256&quot;, fingerprintOptions={ignoreVolatile:true, volatileKeys:[&quot;lastModified&quot;,&quot;timestamp&quot;], hmacSalt:null})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> compute a stable <code>config.hash</code> used as the canonical fingerprint linking jobs, artifacts, and audits. <code>configCanonicalJson</code> must be the canonicalized JSON produced by PQ_Config canonical serializer. Returns <code>{configHash, canonicalForm}</code>. Emit <code>pq.config.hash.computed</code>. <br><strong>Parameters & invariants:</strong><br>1. Canonicalization rules: recursively sort object keys in Unicode code point order, normalize strings to Unicode NFC, serialize numbers in deterministic decimal/fixed-point for schema-declared numeric fields, and avoid locale-specific formatting. <br>2. <code>ignoreVolatile=true</code> removes configured volatile keys deterministically before hashing and records removed keys in audit metadata. <br>3. If <code>hmacSalt</code> provided (test-mode), compute <code>configHash = HMAC_SHA256(hmacSalt, canonicalJson)</code>; otherwise <code>configHash = SHA256(canonicalJson)</code>. <br><strong>Algorithmic details & platform parity:</strong><br>1. Serializer implements stable numeric formatting: for <code>financial</code>-annotated schema fields apply scaled integer encoding with explicit scale metadata to avoid binary float differences across languages. <br>2. For extremely large configs implement streaming canonicalization that produces canonical chunks with a chunk manifest used to compute final SHA256 over the canonical stream. <br><strong>Edge cases & considerations:</strong> ensure canonical serializer mapping of boolean <code>true</code>/<code>false</code> and null uses exact lexical tokens (<code>true</code>, <code>false</code>, <code>null</code>) to avoid platform differences. <br><strong>Observability & audit fields:</strong> pq.config.hash.computed(correlationId, configHash, canonicalFormHash, removedVolatileKeys) <br><strong>Tests & CI vectors:</strong> cross-language golden vectors for canonicalization and hash outputs; streaming canonicalization parity tests; ignoreVolatile behavior tests. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ApplyIdempotentMigrations(configObject, migrationRegistry, mode=&quot;dry_run&quot;, operatorApproval=null, correlationId=null)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> apply an ordered sequence of migrations to bring config to current canonical shape. Must be idempotent and produce reversible metadata when reversible migrations are available. Support safe dry_run preview and persisted apply flows requiring approval for destructive migrations. Return <code>{resultConfig, appliedMigrations:[{id,notes}], diff, persisted:false|true}</code>. Emit <code>pq.config.migrations.*</code> audits. <br><strong>Parameters & workflow rules:</strong> <code>migrationRegistry</code> ordered by <code>fromVersion</code>-><code>toVersion</code> entries; each migration entry is <code>{id, fromVersion, toVersion, transformer:function, reversible:boolean, riskScore:int}</code>. <code>mode</code> can be <code>dry_run</code>, <code>apply</code>, or <code>apply_with_approval</code>. For regulated templates destructive migrations require <code>operatorApproval</code> evidenceRef and two-person approval gating. <br><strong>Primary invariants (must/shall):</strong><br>1. Idempotence: each migration must include precondition checks and persisted <code>migrations_applied</code> markers to avoid repeated application. <br>2. Reversibility: where possible record reverse mapping or produce rollback manifest. <br>3. Atomic persistence of updated config + <code>migrations_applied</code> marker using AtomicWrite to avoid races. <br><strong>Implementation & algorithmic notes:</strong><br>1. Compute plan: determine list of migrations to apply by comparing <code>configObject.version</code> to registry. <br>2. For each migration: run transformer in sandboxed deterministic environment with deterministic RNG disabled; compute per-step diff and unit-test vectors using canonicalized examples. <br>3. On encountering destructive migration requiring approval: halt and surface <code>PQ_CONFIG_MIGRATION_REQUIRES_APPROVAL</code> with impact assessment. <br>4. If applying, persist final config and <code>migrations_applied</code> atomically via ConfigStoreAdapter and emit final audit with evidenceRef. <br><strong>Edge cases & errors:</strong> transformer exceptions produce <code>pq.config.migrations.failure</code> with diagnosticsRef and rollback to prior persisted snapshot if persistence occurred partially. <br><strong>Observability & audit fields:</strong> pq.config.migrations.start(correlationId, fromVersion, toVersion) pq.config.migrations.complete(correlationId, appliedMigrations, persisted, evidenceRef) pq.config.migrations.failure(correlationId, errorCode, diagnosticsRef) <br><strong>Examples & deep narrative:</strong><br>1. <code>v2.rename_templates</code> migrates <code>templates</code> to <code>pqTemplates</code>. Dry_run produces <code>ConfigDiff</code> and per-template mapping table used by operators; applying persists <code>migrations_applied</code> and snapshot evidenceRef. <br>2. Splitting <code>connectors</code> into namespaced groups is destructive for downstream refresh policies; migration halts with <code>PQ_CONFIG_MIGRATION_REQUIRES_APPROVAL</code> and an impact report listing affected templates and connectors. <br><strong>Tests:</strong> idempotent reapply, reverse-roundtrip where reversible=true, migration failure and cleanup testing, and cross-language transformer parity if transformers exist in multiple runtimes. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ResolveRemoteConfig(baseConfig, repoDescriptor, authContext, options={preferLocalCache:true, timeoutMs:2000, verifySignatures:true})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> fetch and merge remote repository fragments deterministically to produce a resolved config overlay. All fetched artifacts must be integrity-checked (mChecksum) and signature-verified when expected. Return <code>{resolvedConfig, remoteArtifacts:[{uri,mChecksum,signatureOk}], configHash, evidenceRef}</code>. Emit <code>pq.config.resolve_remote.*</code> audits. <br><strong>Parameters & semantics:</strong> <code>repoDescriptor</code> can be git URL, HTTP manifest endpoint, or signed manifest blob. <code>authContext</code> contains auth tokens or references to secret resolvers (no secrets captured in audits). <code>options.preferLocalCache=true</code> allows degraded operation using cached remote snapshot and emits <code>pq.config.resolve_remote.degraded</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic overlay order: repo defaults → template-level fragments → operator overrides → environment overlays. <br>2. Record every remote artifact <code>mChecksum</code> and store fetched artifacts in evidence store with <code>evidenceRef</code>. <br>3. If <code>verifySignatures=true</code> and signature fails, abort resolution and emit failure audit. <br><strong>Implementation & algorithmic details:</strong><br>1. Fetch manifest and artifacts using <code>Retry</code> wrapper with idempotent assertions; for each artifact compute <code>mChecksum</code> (e.g., SHA256), verify signatures when present, save artifact blobs to evidence store, and add references to <code>remoteArtifacts</code>. <br>2. Validate each artifact against schema fragments; on validation failures, abort resolution and surface diagnostic suggestions. <br>3. Merge fragments using <code>MergeOverrides</code> deterministically and compute <code>configHash</code> of resolved config. <br><strong>Edge cases & fallback:</strong> unsigned artifact or signature mismatch -> quarantine and fail unless operator overrides with explicit <code>force</code> and owner approval; network outage -> use cached snapshot and mark degraded path. <br><strong>Observability & audit fields:</strong> pq.config.resolve_remote.start(correlationId, repoDescriptorHash) pq.config.resolve_remote.complete(correlationId, configHash, artifactsCount, evidenceRef) pq.config.resolve_remote.degraded(correlationId, reason, usedCache=true) pq.config.resolve_remote.failure(correlationId, errorCode, diagnosticsRef) <br><strong>Examples & narrative:</strong><br>1. Central repo provides connector timeout defaults and sample parameter schemas; <code>ResolveRemoteConfig</code> fetches signed fragments, verifies signatures, merges them with operator overrides, and produces <code>configHash</code> used in jobDescriptor persistence so worker runs are reproducible and auditable. <br><strong>Tests:</strong> signature mismatch handling, cached-snapshot fallback tests, deterministic merging order under concurrent fetches. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>MergeOverrides(baseConfig, overrides[], precedenceRules)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic merge engine applying ordered override fragments with clearly-defined per-key merge semantics. Returns <code>{mergedConfig, changeLog}</code> with path-level provenance and fingerprints. <br><strong>Parameters & merge semantics:</strong> <code>overrides</code> is an ordered list of fragments with sourceDescriptor; <code>precedenceRules</code> map JSON pointer paths to merge strategies: <code>replace|merge_map|merge_list|append|unique_by_key|prepend</code>. <code>changeLog</code> records per-path changes with oldFingerprint, newFingerprint, sourceDescriptor, and overrideIndex. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic application order: later overrides win unless rules specify additive behaviors. <br>2. Stable list deduplication for <code>unique_by_key</code> using deterministic key ordering and tie-breakers based on overrideIndex and sourceDescriptor identity. <br>3. Preserve provenance for every element changed to support forensic tracebacks. <br><strong>Algorithm & implementation notes:</strong><br>1. Traverse baseConfig in canonical order; for each key apply per-path <code>precedenceRules</code>. <br>2. For <code>merge_list</code> where ordering matters (e.g., transform steps), preserve original order unless an override explicitly reorders; record moved elements in <code>changeLog</code>. <br>3. For map merges respect <code>null_overwrites</code> semantics and support merge strategies that treat null as explicit blanking when configured. <br><strong>Conflict detection & resolution:</strong> conflicting exclusive flags produce <code>PQ_CONFIG_CONFLICT</code> with suggested remediation and an <code>impactScore</code> based on configured heuristics (e.g., connector default changes are high-impact). <br><strong>Observability & audit fields:</strong> pq.config.merge.completed(correlationId, mergedHash, changesCount, changeLogRef) <br><strong>Tests:</strong> deterministic merge outputs for permutations of override arrival orders, moved-item detection tests for step-lists, conflict detection tests. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ExposeRuntimeConfig(snapshot, consumerContext)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> present a read-only, immutable runtime view tailored to the consumer's capabilities. Exposed API: <code>getString(path, default)</code>, <code>getNumber(path, default)</code>, <code>getBool(path, default)</code>, <code>getList(path)</code>, <code>getMap(path)</code>, <code>getTemplateConfig(templateId)</code>, plus metadata fields <code>configHash</code>, <code>snapshotId</code>, and <code>appliedMigrations</code>. Secrets remain placeholders like <code>{{vault:path#key}}</code> and cannot be resolved without explicit secrets resolution calls in worker contexts. Attempting to mutate the returned object raises <code>ConfigImmutableError</code>. <br><strong>ConsumerContext semantics:</strong> controls redaction—UI consumers get redacted placeholders with schema & placeholder fingerprints; authorized worker contexts may request secret resolution via SecretsPlaceholderResolver. <br><strong>Primary invariants (must/shall):</strong><br>1. No raw secrets in exposed object. <br>2. Immutable runtime snapshot to ensure reproducible behavior. <br>3. Typed accessors perform safe coercion and return structured errors for missing keys unless defaults provided. <br><strong>Implementation notes:</strong> implement a thin wrapper that lazily computes derived values and caches typed conversions; include small telemetry when consumers access sensitive fields (emit <code>pq.config.access</code> audit for privileged accesses). <br><strong>Observability & audit fields:</strong> pq.config.expose(correlationId, consumerId, configHash, consumerContext) <br><strong>Examples:</strong> PQ_Ribbon uses <code>ExposeRuntimeConfig</code> to render parameter editors; workers with privileges use the same wrapper and then call <code>SecretsPlaceholderResolver</code> to resolve secrets prior to launching provider connections. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SnapshotConfig(configObject, metadata={sourceDescriptor, author, reason, correlationId})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> produce an immutable evidence snapshot stored in the evidence store with chunking for large payloads. Snapshot includes canonical form, <code>configHash</code>, applied migrations list, remote artifact references with <code>mChecksums</code>, and a redacted quick-view for operator display. Return <code>{snapshotId, snapshotPath, evidenceRef, artifactChecksum, sizeBytes}</code> and emit <code>pq.config.snapshot.created</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Snapshots are write-once and persisted atomically via AtomicWrite. <br>2. Public audits reference snapshot via <code>evidenceRef</code>; full snapshot stored encrypted and access-controlled. <br><strong>Implementation & algorithmic details:</strong><br>1. Serialize canonical JSON, optionally compress, compute artifact checksum (SHA256), split into chunks if > threshold and write chunked artifacts alongside manifest referencing chunk checksums. <br>2. Encrypt chunks for evidence store, store signed manifest linking chunk checksums, compute manifest checksum and record in audit evidenceRef. <br>3. For large snapshots support incremental upload and resume semantics and ensure final commit step is atomic from consumer perspective. <br><strong>Observability & audit fields:</strong> pq.config.snapshot.created(correlationId, snapshotId, artifactChecksum, sizeBytes, evidenceRef) <br><strong>Tests:</strong> snapshot chunk manifest integrity, evidenceRef retrieval & access control tests, snapshot restore round-trip. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>WatchConfigFile(pathOrStore, callback, debounceMs=300, correlationId=null)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> watch a local config artifact for edits and call subscribers with a debounced settled event. Must be safe for add-in UI: non-blocking and low CPU, using OS native watchers or efficient poll with content hashing fallback. Return a handle with <code>stop()</code>, <code>suppressOnce()</code>, and <code>forceReload()</code> operations. <br><strong>Behavior & steps:</strong><br>1. Register native watcher or fallback poll; on change compute new content hash; read new snapshot via <code>LoadConfig(local_only)</code> and <code>ValidateConfigSchema</code>. <br>2. On stable content after <code>debounceMs</code> call callback with <code>{oldHash, newHash, snapshotId, diffRef}</code> and emit <code>pq.config.watch.detected</code> audit. <br>3. Expose suppression token for editors to suppress notifications during batch edits. <br><strong>Failure & mitigation:</strong> repeated file locks or concurrent save failures -> retry N times with exponential backoff and then emit <code>pq.config.watch.failure</code> and pause watcher; operator intervention required to resume. <br><strong>Observability & audit fields:</strong> pq.config.watch.detected(correlationId, path, oldHash, newHash, callbackId) pq.config.watch.failure(correlationId, path, errorCode) <br><strong>Operator guidance:</strong> prefer built-in editor that performs schema validation and writes via adapter API ensuring atomic writes and minimal watch churn. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ExportResolvedConfig(snapshot, destinationDescriptor, options={atomic:true, includeEvidence:false, sign:false, commitMessage:null})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> build and persist an export bundle that contains canonical config JSON, metadata, applied migrations, and optional evidence. Must use AtomicWrite semantics locally and secure commit semantics for repositories; record artifact checksum in audit. Return <code>{artifactChecksum, destinationUri, evidenceRef}</code>. <br><strong>Behavior & steps:</strong><br>1. Assemble export bundle: canonical JSON, metadata.json with <code>configHash</code>, <code>appliedMigrations</code>, <code>snapshotId</code>, and optional encrypted evidence payload. <br>2. When <code>atomic=true</code> use AtomicWrite to write bundle to destination; when pushing to repo, perform commit+push with signing if <code>sign=true</code>. <br>3. After successful write or push, compute and record artifact checksum and emit <code>pq.config.export.completed</code>. <br><strong>Failure & fallback:</strong> on remote push failure persist bundle to local staging, emit <code>pq.config.export.degraded</code>, and notify owners per release policy. <br><strong>Observability & audit fields:</strong> pq.config.export.attempt(correlationId, destinationDescriptor) pq.config.export.completed(correlationId, artifactChecksum, destinationUri) pq.config.export.failure(correlationId, errorCode, diagnosticsRef) <br><strong>Tests:</strong> atomic write under concurrent readers test, remote commit with intermittent auth failure simulation, staged fallback verification. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ConfigDiff(oldConfig, newConfig, options={ignoreVolatile:true, includeProvenance:true, impactRules:default})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> produce a deterministic, actionable diff with path-based changes, fingerprints, suggested reversal steps, and <code>impactScore</code> for operator review or CI gating. Return <code>{changes:[{path, oldFingerprint, newFingerprint, action, impactScore, provenance}], summary, actionsSuggested}</code>. <br><strong>Algorithm & heuristics:</strong><br>1. Use canonical traversal for path semantics. <br>2. Detect list moves vs additions using a longest-common-subsequence heuristic to avoid false positives when order preserved. <br>3. Impact scoring uses <code>impactRules</code> mapping (e.g., connector.timeout => high, cosmetic.label => low). <br><strong>Use cases:</strong> migration preview, PR CI gating, operator acceptance dialogs, automated low-risk approvals. <br><strong>Observability & audit fields:</strong> pq.config.diff.created(correlationId, oldHash, newHash, changesCount, diffRef) <br><strong>Tests:</strong> list move detection, impactScore calibration tests, provenance linking tests. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ConfigStoreAdapter</code> (interface + implementations) — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> pluggable persistence layer for configs; adapters implement <code>read()</code>, <code>write(payload)</code>, <code>listVersions()</code>, <code>inspectTempArtifacts()</code> and must use AtomicWrite semantics for write. Implementations: HiddenSheetAdapter, LocalFileAdapter, RemoteRepoAdapter (git/HTTP), InMemoryAdapter (tests). <br><strong>Adapter specifics & host constraints:</strong><br>1. <strong>HiddenSheetAdapter:</strong> embed canonical JSON in a hidden worksheet <code>PQ_Config</code>; writes must avoid recalculation and heavy IO on OnLoad—use host-provided idle callbacks or schedule writes via host scheduling APIs; provide import/export helpers; persist sidecar metadata in reserved named ranges. <br>2. <strong>LocalFileAdapter:</strong> cross-platform atomic file operations and fsync parent dir when available; handle ACL and Windows ReplaceFile semantics; provide InspectTempArtifacts for leftover .part files. <br>3. <strong>RemoteRepoAdapter:</strong> shallow fetch/clone, signature verification against trusted keys, support for commit+push with signing and signed manifest handling; produce <code>mChecksums</code> and evidenceRefs for fetched files. <br>4. <strong>InMemoryAdapter:</strong> deterministic ephemeral store used in unit tests and CI; ensure parity in API semantics. <br><strong>Security:</strong> adapters must never embed raw secrets; placeholders only and evidenceRefs to secure vaults. <br><strong>Observability & audit fields:</strong> pq.config.store.read(correlationId, adapterType, descriptorHash) pq.config.store.write(correlationId, adapterType, descriptorHash, artifactChecksum) <br><strong>Tests:</strong> HiddenSheet race conditions with Excel host mocks, file lock error scenarios, remote fetch signature verification, InspectTempArtifacts repair flows. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SecretsPlaceholderResolver(configObject, resolverInterface, authorization)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> PQ_Config keeps secrets as placeholders. SecretsPlaceholderResolver performs resolution only in authorized worker contexts with full audit trail; it returns resolved values to caller and stores resolution metadata (not secret content) in the evidence store. <br><strong>Resolution flow & auditing:</strong><br>1. Caller supplies <code>correlationId</code>, <code>snapshotId</code>, and <code>authorizationToken</code> referencing secure vault credentials managed outside PQ_Config. <br>2. Resolver fetches secrets in secure environment, records <code>pq.config.secrets.resolution.start</code> and <code>pq.config.secrets.resolution.complete</code> audits with evidenceRef containing placeholder fingerprints, actor, resolutionTime, and resolutionNonce (no secret values). <br>3. Supports partial resolution and returns <code>{resolvedConfig, missingSecrets:[placeholders]}</code>. <br><strong>Security & governance:</strong> all resolutions must be authorized by ConfigAccessPolicy; secrets are never recorded in cleartext in the audit or evidence metadata. <br><strong>Edge cases & failure modes:</strong> missing secret -> <code>PQ_CONFIG_SECRETS_MISSING</code>; unauthorized -> <code>PQ_CONFIG_SECRETS_UNAUTHORIZED</code>. <br><strong>Tests:</strong> permission-denied tests, rotation & cache behavior, audit trail verification (no secret leakage). </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (expanded):</strong><br><strong>Audit schema:</strong> each audit row must include: timestamp (ISO8601), correlationId, module=PQ_Config, procedure, operatorId (optional), paramsHash, resultHash (optional), evidenceRef (optional), prevConfigHash (if applicable), configHash (if applicable), snapshotId (if applicable), and metadata object with duration_ms, adapterType, sourceDescriptorHash, artifactChecksum, appliedMigrations. Sensitive parameters are redacted in the top-level audit; full sanitized payloads are stored encrypted in evidence store and referenced via <code>evidenceRef</code>. <br><strong>Key audit events:</strong> load/validate/migrations/resolve_remote/snapshot/export/secrets.resolve/diff. <br><strong>Representative ErrorCodes and operator guidance:</strong><br>1. PQ_CONFIG_LOAD_FAIL — examine diagnosticsRef and fix malformed JSON or adapter access issues. <br>2. PQ_CONFIG_VALIDATE_FAIL — present schema diagnostics to template owner for remediation. <br>3. PQ_CONFIG_SCHEMA_MISMATCH — migration needed; run migration dry_run and review diffs. <br>4. PQ_CONFIG_MIGRATION_REQUIRES_APPROVAL — require two-person approval and owner sign-off. <br>5. PQ_CONFIG_RESOLVE_REMOTE_UNREACHABLE — check repo credentials, network, remote service health; fallback to local snapshot if allowed. <br>6. PQ_CONFIG_SECRETS_MISSING — provision missing secret in secure vault and retry resolution. <br><strong>Metrics:</strong> pq.config.load.latency_ms, pq.config.validate.fail_rate, pq.config.resolve_remote.success_rate, pq.config.migrations.count, pq.config.export.success_rate; metrics are locally buffered and uploaded by CORE_Telemetry in audited batches to preserve privacy and ordering. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, cross-language golden governance (comprehensive & explicit)</strong><br><strong>Unit tests (minimum set):</strong><br>1. LoadConfig: hidden-sheet, local file path, remote repo with cached fallback and force_remote behaviors. <br>2. ValidateConfigSchema: <code>oneOf</code>, <code>anyOf</code>, <code>allOf</code>, <code>if/then/else</code>, default application, deprecated keys handling. <br>3. ComputeConfigHash: canonicalization parity across Python/JS/VBA with varied numeric formatting and unicode inputs. <br>4. ApplyIdempotentMigrations: idempotency, reversible migrations roundtrip, destructive migration gating. <br>5. ResolveRemoteConfig: signature verification, cached snapshot fallback, determinism under concurrent fetches. <br>6. MergeOverrides: deterministic merges for permutation tests and conflict detection. <br><strong>Integration tests:</strong><br>1. End-to-end pipeline: LoadConfig -> ResolveRemoteConfig -> ApplyIdempotentMigrations -> SnapshotConfig -> ExportResolvedConfig verifying artifactChecksum and audit tail. <br>2. HiddenSheetAdapter concurrency: simulate Excel saves using host mock and ensure watch notifications are debounced and no corruption occurs. <br>3. SecretsResolution: mock secure vault and ensure resolved values are not present in audits or snapshots, and evidenceRef integrity is verified. <br><strong>Property tests & fuzzing:</strong><br>1. <code>configHash</code> stability: modify only volatile fields and assert no hash change when <code>ignoreVolatile=true</code>. <br>2. MergeOverrides invariants: given precedence rules, out-of-order fragment arrival yields same final merged config. <br>3. Migration idempotency across random config inputs. <br><strong>CI golden gating & governance:</strong><br>1. Cross-language <code>configHash</code> goldens must pass for merges to mainline. <br>2. Any schema or migration change must include migration manifest, owner approvals, and golden test vectors demonstrating expected diffs. <br>3. Static analyzer must block direct workbook writes from UI OnLoad and disallow forbidden API usage. <br><strong>Performance testing:</strong> nightly or canary runs to validate load latency, remote resolution throughput, snapshot persistence throughput for large repos. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (detailed & strict)</strong><br><strong>Required patterns:</strong><br>1. Always use <code>LoadConfig</code> for consumers; do not read raw files in ribbon or worker code.<br>2. Persist durable artifacts via ConfigStoreAdapter with AtomicWrite; do not write directly to final artifact paths from UI code.<br>3. Always compute and persist <code>config.hash</code> and include in job descriptors and audits to create reproducibility anchors.<br>4. Use <code>ApplyIdempotentMigrations</code> with <code>dry_run</code> previews for operator review before applying; require approvals for destructive migrations.<br>5. Do not resolve secrets in PQ_Config; call <code>SecretsPlaceholderResolver</code> only in authorized worker contexts and ensure audit evidenceRef recorded for every resolution. <br><strong>Forbidden patterns:</strong><br>1. Blocking network I/O during UI OnLoad (static analyzer rejects). <br>2. Exposing raw secrets in audit rows, snapshots, or logs. <br>3. Relying on host locale-specific JSON serialization or float formatting when computing <code>config.hash</code>. <br>4. Mutating workbook content from background threads without host-synchronized callbacks. <br><strong>Code-review checklist:</strong> ensure audit emits for load/validate/migrate/export flows are present; AtomicWrite used for persistent writes; <code>config.hash</code> included in job descriptors; migration tests and owner approvals present for schema changes; CI includes cross-language parity checks for canonicalization. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable & prescriptive)</strong><br><strong>Config load failure triage runbook:</strong><br>1. Inspect <code>pq.config.load.failure</code> audit row for correlationId and diagnosticsRef. <br>2. If <code>PQ_CONFIG_VALIDATE_FAIL</code>, download sanitized snapshot via evidenceRef and run <code>ValidateConfigSchema</code> offline to get path-level diagnostics and suggestions; notify template owner with suggested patch. <br>3. If <code>PQ_CONFIG_RESOLVE_REMOTE_UNREACHABLE</code>, verify repo credentials, network, and remote service health; if fallback allowed use <code>LoadConfig(local_only)</code> to continue UI operations; log an incident and notify owners if canary or production templates are affected. <br>4. For migration failures, get migration diff and run <code>ApplyIdempotentMigrations</code> in worker dry_run to generate remediation plan; if destructive, obtain owner approvals and re-run apply_with_approval. <br><strong>Signature mismatch on remote resolve runbook:</strong><br>1. Retrieve <code>pq.config.resolve_remote.failure</code> audit and evidenceRef for fetched artifacts. <br>2. Quarantine fetched artifacts, notify template owners, and verify manifest signing keys. <br>3. If deliberate key rotation occurred, follow key rollover procedure; if compromise suspected, rotate keys, block affected templates, and open compliance incident. <br><strong>Forensic reconstruction ordered steps:</strong><br>1. Collect <code>UserAction</code> and <code>pq.config.*</code> audits for correlationId and time window. <br>2. Pull snapshot via evidenceRef and verify <code>configHash</code> vs audit. <br>3. Restore RNG state if sampling used (from profile audits) and perform deterministic replay to reproduce template output. <br>4. If mismatch persists, compare <code>ConfigDiff</code> and <code>pq.config.migrations</code> audits to find applied migrations between preview and production. <br>5. Package forensic_manifest.json containing audit_tail.csv, snapshots, artifacts, RNG state, and migration diffs for compliance. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples (multiple scenarios, extended)</strong><br><strong>Scenario A — Local operator edits template defaults and preview (end-to-end):</strong><br>1. Operator opens add-in → PQ_Ribbon calls <code>LoadConfig(hidden:PQ_Config, mode=auto)</code> and obtains a local snapshot quickly (<code>loadedFrom=hidden-sheet</code>). <br>2. Editor shows parameter schema via <code>ExposeRuntimeConfig</code>—secrets shown as placeholders and <code>configHash</code> displayed for traceability. <br>3. Operator edits parameter defaults; client-side <code>ValidateConfigSchema</code> runs synchronously and prevents saving malformed configs. <br>4. On save, HiddenSheetAdapter.write() uses AtomicWrite to persist canonical JSON to the hidden sheet; <code>WatchConfigFile</code> detects stable change (debounced) and loads new snapshot producing <code>pq.config.watch.detected</code> audit with oldHash->newHash. <br>5. Preview uses snapshotId and <code>configHash</code> to produce deterministic parameterized preview; <code>pq_preview</code> audit includes <code>configHash</code> and snapshotId to allow forensic replay of preview. <br><strong>Takeaways:</strong> local workflows are fast and auditable; <code>configHash</code> ensures previews and injection are reproducible. <br><strong>Scenario B — Remote canonicalization & enterprise injection pipeline:</strong><br>1. Central template owner updates defaults and publishes signed manifest; CI runs <code>ValidateConfigSchema</code> and computes new <code>configHash</code>. <br>2. Workers periodically run <code>ResolveRemoteConfig(force_remote)</code> to fetch signed fragments, verify signatures, and compute a merged config; <code>pq.config.resolve_remote.complete</code> is emitted with <code>evidenceRef</code> pointing to artifacts and signatures. <br>3. Workers apply <code>ApplyIdempotentMigrations</code> when migration registry indicates necessary transformation; destructive migrations require owner approval token captured in audit. <br>4. Worker renders canonical M templates, <code>ExportResolvedConfig</code> writes artifacts to staging repo with artifactChecksum recorded; downstream injectors use artifactChecksum and <code>configHash</code> to perform injections. <br><strong>Takeaways:</strong> central repository + signatures + <code>configHash</code> produce provable lineage of injected artifacts; migration approvals enforce governance. <br><strong>Scenario C — CI gate for template changes:</strong><br>1. PR modifies <code>templates/defaults.json</code>; CI runs <code>ValidateConfigSchema</code>, <code>ComputeConfigHash</code>, and <code>ApplyIdempotentMigrations(dry_run)</code> producing <code>ConfigDiff</code>. <br>2. CI computes impact scores; high-impact changes block merge until owners approve. <br>3. On owner approval CI produces release manifest including <code>configHash</code> and signed release artifacts. <br><strong>Takeaway:</strong> CI stops subtle config-induced behavior changes from reaching production by using deterministic diffing and <code>configHash</code> goldens. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — how PQ_Config maps to PQ workflows (detailed mapping & guidance)</strong><br><strong>Context:</strong> M executes inside hosts with varying runtimes; PQ_Config orchestrates deterministic behavior externally and provides canonical artifacts for injection. <br><strong>Mapping patterns & recommendations (detailed):</strong><br>1. <strong>Atomic persistence mapping:</strong> orchestrator persists canonical M via <code>ExportResolvedConfig</code> and <code>ConfigStoreAdapter</code> (AtomicWrite) and provides artifactChecksum and <code>configHash</code> to the injector; injection then uses the persisted artifact, ensuring the exact M injected is auditable. <br>2. <strong>Deterministic seeds & sampling:</strong> for previews compute seed = HMAC(<code>correlationId | templateId</code>) and pass as parameter to M preview; for heavyweight sampling do sampling in worker using DeterministicRNG and pass sampled static dataset to M template to avoid host RNG variability. <br>3. <strong>Numeric fidelity / SafeRound mapping:</strong> mark templates <code>requiresHighPrecision</code> and offload sensitive aggregation and rounding to worker SafeRound flows; persist finalized numeric columns and canonical M for injection to avoid cross-host decimals variance. <br>4. <strong>Retry & idempotency mapping:</strong> orchestrator wraps external calls and persisted job descriptors with Retry and idempotency tokens; keep M templates pure and declarative, orchestrator handles persistence and retries. <br><strong>PQ operator example (injection):</strong><br>1. Operator selects template → orchestrator calls <code>ExposeRuntimeConfig</code> to fetch parameter schema and <code>configHash</code>. <br>2. Operator submits injection request → orchestrator persists canonical M via <code>ExportResolvedConfig</code> (AtomicWrite), emits <code>pq_inject</code> audit referencing artifactChecksum and <code>configHash</code>, and calls <code>workbook.Queries.Add</code> with the persisted M artifact to guarantee the injected query equals audited artifact. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Config to ETL & model design (detailed)</strong><br><strong>Context:</strong> DAX is read-only and deterministic for queries; all authoritative transforms, rounding, allocations, and sample generation must be performed in ETL using PQ_Config guidance and artifacts. <br><strong>Patterns & recommendations:</strong><br>1. <strong>ETL-owned rounding & allocations:</strong> perform SafeRoundResiduals in ETL and persist resolved cents-level fields; DAX measures operate on authoritative persisted values for deterministic aggregates. <br>2. <strong>Deterministic sampling stored in table:</strong> ETL computes <code>HashKey = HMAC(primaryKey | correlationSalt)</code> and persists it; DAX uses <code>MOD(HashKey, N)</code> to derive deterministic samples, with <code>correlationSalt</code> persisted in RunMetadata for replay. <br>3. <strong>RunMetadata & model-level reconciliation:</strong> ETL writes RunMetadata with <code>configHash</code>, <code>snapshotId</code>, <code>artifactChecksum</code>, and <code>runTs</code>. DAX exposes measures that compare the model's expected artifactChecksum to the stored artifactChecksum to produce <code>IsReconciled</code> flags for operator dashboards. <br>4. <strong>Model-level governance:</strong> Provide <code>RunMetadata</code> table with <code>appliedMigrations</code> and <code>templateVersion</code> to let report authors show lineage and provenance in the report UI. <br><strong>DAX operator narrative:</strong> ETL uses PQ_Config to obtain template parameters and <code>configHash</code>, performs canonical transforms and rounding, writes authoritative tables and RunMetadata; report DAX measures surface provenance and reconciliation status and drive remediation workflows when mismatches occur. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & retention (detailed)</strong><br><strong>Minimum forensic artifact set for incidents involving config:</strong><br>1. <code>config_snapshot.json</code> canonical form with <code>snapshotId</code> and artifactChecksum. <br>2. full set of <code>pq.config.*</code> audit rows covering load/validate/resolve/migrate/export events for correlationId. <br>3. remote artifact manifests with <code>mChecksums</code> and signature verification results. <br>4. migration diffs and per-migration evidenceRef objects. <br>5. hidden-sheet raw content (redacted) if relevant. <br>6. secrets resolution request metadata and <code>evidenceRef</code> (encrypted). <br>7. AtomicWrite temp artifacts listing (InspectTempArtifacts) and related repair logs. <br><strong>Evidence store & retention strategy:</strong><br>1. Hot evidence store: <code>\\evidence\hot\pq_config\&lt;correlationId&gt;\</code> for 30 days with restricted access. <br>2. Warm archive: secure offline archive for 7 years with signed manifests for regulatory retention. <br>3. Cold storage: long-term offline retention per regulation; maintain chain-of-custody metadata. <br><strong>Monthly verification cadence:</strong> scheduled retention verification job that computes proof-of-presence for hot artifacts and emits <code>housekeeping.audit</code>; periodic cryptographic checks of manifest signatures and evidenceRef integrity. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before PQ_Config release (comprehensive):</strong><br>1. OWNERS.md updated and contacts verified with on-call rotation. <br>2. Public API stable and documented with backward compatibility and deprecation rules. <br>3. All writes use AtomicWrite and emit audits that include <code>configHash</code> and evidenceRef where applicable. <br>4. Cross-language <code>configHash</code> golden vectors and canonical serializer parity tests passing. <br>5. Migration registry validated; destructive migrations documented and have owner approvals. <br>6. Audit hooks integrated into modAudit buffer; evidenceRef patterns validated and encrypted evidence accessible by compliance tools. <br>7. CI gating includes static analyzer checks to block UI-thread network I/O; performance budgets met. <br><strong>Blocking conditions:</strong> failure of <code>configHash</code> golden parity, missing audit emissions on persistence flows, or migration scripts lacking owner approvals. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & procedural scripts (explicit):</strong><br><strong>Unit tests group:</strong><br>1. <code>LoadConfig</code> permutations: hidden-sheet, local file path, remote descriptor with cached fallback. <br>2. <code>ValidateConfigSchema</code> across schema constructs including <code>oneOf</code>, <code>anyOf</code>, <code>allOf</code>, custom keywords, and deprecated fields. <br>3. <code>ComputeConfigHash</code> canonicalization and numeric formatting parity vectors. <br>4. <code>ApplyIdempotentMigrations</code> idempotency and reverse migration tests. <br>5. <code>ResolveRemoteConfig</code> signature verification and cached snapshot fallback tests. <br><strong>Integration tests group:</strong><br>1. End-to-end pipeline: <code>LoadConfig</code> -> <code>ResolveRemoteConfig</code> -> <code>ApplyIdempotentMigrations</code> -> <code>SnapshotConfig</code> -> <code>ExportResolvedConfig</code>; verify artifact checksums and audit tail integrity. <br>2. HiddenSheetAdapter concurrency tests: simulate workbook sessions and background saves to ensure watcher stability. <br><strong>Property & fuzz tests:</strong><br>1. <code>configHash</code> invariants under volatile key changes. <br>2. MergeOverrides idempotency and commutativity where precedence rules mandate. <br><strong>Performance & CI gating:</strong> nightly-run performance smoke, golden vector validation for <code>configHash</code>, and static analyzer enforcement for forbidden patterns. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (prescriptive):</strong><br>1. <code>pqconfig diagnostics collect --correlation &lt;id&gt;</code> — pulls <code>pq.config.*</code> audits, snapshots, remote manifests, and produces forensic_manifest.json. <br>2. <code>pqconfig migrate --dry-run --snapshot &lt;snapshotId&gt;</code> — generate migration diff and changeLog for operator review and owner approval. <br>3. <code>pqconfig export --snapshot &lt;snapshotId&gt; --dest file://staging</code> — atomic export bundle creation and local staging when remote push fails. <br>4. <code>pqconfig snapshot.inspect --snapshot &lt;snapshotId&gt;</code> — show redacted summary of snapshot including <code>configHash</code>, applied migrations, and remote artifact list. <br><strong>When to call SRE:</strong> repeated <code>pq.config.resolve_remote.degraded</code> or <code>pq.config.export.failure</code> during staging/publish, or AtomicWrite failures affecting downstream consumers. Provide forensic_manifest and audit_tail when opening SRE incidents. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Final notes, governance & mandatory constraints (firm):</strong><br>1. <code>config.hash</code> is the canonical fingerprint for reproducibility—persist it in job descriptors and audits. <br>2. Secrets are placeholders in PQ_Config; resolve via SecretsPlaceholderResolver in authorized worker contexts only; never store secret values in audit or evidence metadata. <br>3. UI fast-path must never perform blocking network I/O; use cached snapshots and schedule remote resolves asynchronously. <br>4. Destructive migrations require two-person approval for regulated templates and must be recorded with rollback manifest. <br>5. All persistent operations must emit audit rows and include <code>evidenceRef</code> for large payloads; evidence store access is RBAC-protected and audited. <br><strong>Checked:</strong> conceptual chain from config load → resolve_remote → apply migrations → snapshot → export validated by multiple internal reviews and cross-checks. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive):</strong><br><strong>Required fields:</strong> timestamp, correlationId, module=PQ_Config, procedure, operatorId (optional), paramsHash, resultHash (optional), evidenceRef (optional), prevConfigHash (optional), configHash (if applicable), snapshotId (if applicable), metadata object with duration_ms, adapterType, sourceDescriptorHash, artifactChecksum, appliedMigrations. <br><strong>Policy:</strong> top-level audits must not contain PII; sanitized full params go into evidence store and are referenced via evidenceRef. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded):</strong><br><strong>UI blocked by remote resolve during OnLoad</strong><br>1. Cause: synchronous remote fetch on UI OnLoad. <br>2. Mitigation: enforce <code>LoadConfig(auto|local_only)</code> for OnLoad and perform <code>ResolveRemoteConfig</code> asynchronously with background worker; static analyzer prevents network calls in OnLoad. <br><strong><code>configHash</code> mismatches across runtimes</strong><br>1. Cause: non-canonical serializer or locale-dependent numeric formatting. <br>2. Mitigation: canonical JSON serializer and cross-language parity tests in CI; store <code>financial</code> numeric fields as scaled integers or strings for consistent serialization. <br><strong>Migration applied twice</strong><br>1. Cause: migration marker not persisted atomically. <br>2. Mitigation: persist <code>migrations_applied</code> atomically with final config using AtomicWrite; migrations must include precondition checks for idempotence. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests and golden vectors where deterministic results are affected. <br>2. Migration/schema changes require migration manifest and owner approvals documented in PR and release manifest. <br>3. Changes affecting persistence patterns or AtomicWrite semantics require cross-platform regression tests and SRE sign-off. <br>4. Production changes affecting templates or regulated outputs require signed release manifest and compliance review. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix D — Long-form incident reconstruction example (ordered):</strong><br><strong>Incident:</strong> preview output differs from run output for correlation <code>r-20260112-455</code>. <br><strong>Reconstruction ordered steps:</strong><br>1. Retrieve <code>UserAction</code> and <code>pq.config.*</code> audits for correlationId and time range. <br>2. Download <code>config_snapshot.json</code> from evidenceRef referenced in <code>pq.config.snapshot.created</code> and verify <code>configHash</code>. <br>3. If sampling used, fetch serialized RNG state from profile or tools audits and restore deterministic RNG to reproduce sample sets. <br>4. Re-run template rendering in replay mode using snapshotId and compare artifactChecksums to production artifact. <br>5. If mismatch found, inspect <code>pq.config.migrations</code> and <code>ConfigDiff</code> audits to determine if migrations were applied between preview and run. <br>6. If remote artifacts involved, verify signatures and <code>mChecksums</code> recorded during <code>ResolveRemoteConfig</code>. <br>7. Package <code>forensic_manifest.json</code> containing audit tail, snapshots, artifacts, RNG state, migration diffs and escalate to compliance when regulated outputs or PII involved. <br><strong>Outcome validation:</strong> deterministic replay should reproduce the artifactChecksum when using exact snapshot and evidenceRef; discrepancies indicate pipeline differences or operator errors requiring remediation and documented runbooks. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix E — Practical PQ & DAX checklists for template authors and report builders (concise):</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> and <code>templateVersion</code> in template metadata. <br>2. Mark <code>requiresHighPrecision</code> for numerically sensitive templates and implement worker-side final aggregation. <br>3. Parameterize preview seed and log it in <code>pq_preview</code> audits. <br>4. Avoid runtime secret resolution in template code; use placeholders and consumer-side secret resolution only in workers. <br><strong>DAX/report builder checklist:</strong><br>1. Use <code>RunMetadata</code> table for provenance and <code>configHash</code>. <br>2. Do not perform allocation/residual rounding in DAX; ETL must persist resolved numeric values. <br>3. For deterministic sampling use persisted <code>HashKey</code> and <code>correlationSalt</code> from RunMetadata. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix F — Migration design notes & best practices (extended):</strong><br><strong>Design goals:</strong> idempotence, determinism, reversibility when feasible, and explicit owner guidance. <br><strong>Implementation best practices:</strong><br>1. Implement migrations as pure transformation functions that accept canonical input and return canonical output and <code>diff</code>. <br>2. Include unit tests that cover edge cases and record golden vectors for each migration. <br>3. Provide reverse migration or rollback manifest where feasible; for irreversible destructive steps annotate with <code>recoveryGuidance</code>. <br><strong>Operator workflow:</strong> preview via <code>dry_run</code>, review <code>ConfigDiff</code>, obtain owner approvals for destructive changes, then apply with <code>apply_with_approval</code> API call. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix G — Long-form rationale: why <code>config.hash</code> matters (detailed justification)</strong><br><strong>Problem:</strong> when templates and defaults evolve across teams and hosts, outputs diverge and auditors lack a compact reproducible pointer to the exact config used. <br><strong>Solution via <code>config.hash</code>:</strong><br>1. A compact cryptographic fingerprint linking all artifacts, job descriptors, and audits. <br>2. A stable anchor for CI gating and deterministic replay; job descriptors referencing <code>configHash</code> allow workers to reconstruct exact runtime environment by fetching snapshot via evidenceRef. <br>3. Enables small, efficient audit rows: <code>configHash</code> + artifactChecksum create the proof chain used for compliance packages. <br><strong>Operational advantage:</strong> <code>configHash</code> simplifies forensic reconstruction and reduces evidence payload size while preserving cryptographic integrity through canonicalization. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix H — Extended conceptual mapping matrix (quick lookup)</strong><br><strong>Function → PQ implication → DAX/ETL implication (compact):</strong><br>1. <code>LoadConfig</code> → UI gets fast snapshot for preview → ETL uses <code>configHash</code> in RunMetadata. <br>2. <code>ResolveRemoteConfig</code> → central defaults applied deterministically → ETL uses resolved parameters for canonical transforms; DAX reads authoritative persisted values. <br>3. <code>ApplyIdempotentMigrations</code> → evolve schema with audit trail → RunMetadata records migrations for model lineage. <br>4. <code>SnapshotConfig</code> → immutable evidence for replay → DAX <code>IsReconciled</code> compares model artifactChecksum to RunMetadata. <br>5. <code>SecretsPlaceholderResolver</code> → secure secret retrieval in worker → ETL resolves secrets during job runs; DAX never sees secrets. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Appendix I — Example operator scenarios & escalation thresholds (expanded):</strong><br><strong>Operator scenario: unexpected injected query behavior:</strong><br>1. Check <code>pq_inject</code> audit for artifactChecksum and <code>configHash</code>. <br>2. Use <code>pqconfig snapshot.inspect --snapshot &lt;snapshotId&gt;</code> to review parameterization. <br>3. If mismatch persists, <code>replay.run --snapshot &lt;snapshotId&gt;</code> to reproduce; if discrepancy remains escalate with forensic_manifest. <br><strong>Escalation thresholds:</strong> repeated <code>pq.config.resolve_remote.degraded</code> over N canary runs, <code>pq.config.export.failure</code> for production releases, or <code>pq.config.migrations.failure</code> for regulated templates require SRE and compliance engagement. </td></tr><tr><td data-label="PQ_Config — Per-function Expert Technical Breakdown"> <strong>Closing operational constraint (non-negotiable):</strong><br>All processes that produce artifacts consumed by other processes must: persist job descriptors, seed deterministic RNGs from correlationId for operator-visible sampling, use AtomicWrite for final artifacts, and emit audit rows including <code>configHash</code> and evidenceRef. This is mandatory for regulated and PII-touching workflows—no exceptions. </td></tr></tbody></table></div><div class="row-count">Rows: 37</div></div><div class="table-caption" id="Table5" data-table="Docu_0179_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_EnsureDeps — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_EnsureDeps — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_ENSUREDEPS recorded in OWNERS.md and release manifests; owners include contacts for Support, Security, SRE, and Template Governance.<br><strong>Public API:</strong> <code>LoadLocalManifests</code>, <code>InspectInstalledAddins</code>, <code>ResolveRemoteManifests</code>, <code>ValidateConnectorVersion</code>, <code>ValidatePQRuntimeVersion</code>, <code>EnsureTemplateCompatibility</code>, <code>VerifyTemplateSignature</code>, <code>ProduceDepsReport</code>, <code>AtomicWriteDepsReport</code>, <code>GenerateDepFingerprint</code>, <code>InspectTempArtifacts</code>, <code>RepairMissingDeps</code>, <code>DiagnoseDepsFailure</code>, <code>DepsDryRun</code>, <code>DepsPolicyEnforcer</code>, <code>ListKnownGoodSnapshots</code>, <code>PromoteSnapshotToLocal</code>, <code>MarkTemplateAsDeprecated</code>.<br><strong>Audits emitted:</strong> <code>pq.ensuredeps.start</code>, <code>pq.ensuredeps.manifest.load</code>, <code>pq.ensuredeps.addin.scan</code>, <code>pq.ensuredeps.remote.resolve.attempt</code>, <code>pq.ensuredeps.remote.resolve.completed</code>, <code>pq.ensuredeps.connector.validate</code>, <code>pq.ensuredeps.pqruntime.validate</code>, <code>pq.ensuredeps.template.verify</code>, <code>pq.ensuredeps.template.signature</code>, <code>pq.ensuredeps.report.generated</code>, <code>pq.ensuredeps.report.atomic_write.attempt</code>, <code>pq.ensuredeps.report.atomic_write.completed</code>, <code>pq.ensuredeps.report.atomic_write.failure</code>, <code>pq.ensuredeps.repair.attempt</code>, <code>pq.ensuredeps.repair.success</code>, <code>pq.ensuredeps.degraded</code>, <code>pq.ensuredeps.complete</code>. Each audit row includes <code>correlationId</code>, <code>module=PQ_EnsureDeps</code>, <code>procedure</code>, <code>paramsHash</code>, <code>resultHash</code> when applicable, <code>durationMs</code>, and <code>evidenceRef</code> for large artifacts or signature blobs. Evidence storage is encrypted and access-controlled; top-level audits must not carry raw PII.<br><strong>Purpose and intended use:</strong> Validate required Power Query connectors, runtime compatibility, template integrity and signatures, and produce an authoritative <code>deps.report.json</code> to drive safe injection, preview, refresh and export flows. Provide machine-actionable repair proposals and maintain deterministic, auditable evidence chains for forensic replay in regulated contexts. Ensure UI fast-path remains non-blocking by separating local quick-scans from remote, heavier resolves that must run on background workers.<br><strong>Non-goals / constraints:</strong> Do not auto-install system-level connectors without explicit operator approval plus governance (two-person approval for regulated workflows). Avoid any long-blocking operations on the UI thread. Do not include raw secrets or PII in audit rows. Avoid heavy third-party dependencies that impair portability to XLAM/VBA host scenarios. Use secure credential store for remote repo auth; do not serialize secrets into evidence blobs. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Deterministic output: identical inputs (local manifests, resolved remote snapshot, config.hash, release manifest) must produce identical <code>deps.report.json</code> bytes; arrays must be canonicalized and sorted. <br>2. Non-blocking bootstrap fast-path: <code>LoadLocalManifests</code> and <code>InspectInstalledAddins</code> must complete within UI idle budget (default <200ms); no network I/O. <br>3. Atomic persistence guarantee: <code>deps.report.json</code> must be written via <code>AtomicWriteDepsReport</code> so readers never see truncated reports. <br>4. Degraded yet safe: network failures or signature-check timeouts produce <code>degraded=true</code> and include explicit <code>degradedReasons</code> and <code>cachedSnapshot</code> if available. <br>5. Audit-anchored operations: any change to persisted dependency state or repair actions must attach at least one audit row referencing <code>correlationId</code> and evidenceRef. <br>6. Idempotence: repeated calls with unchanged inputs must be stable and return same <code>reportHash</code>. <br><strong>Performance SLOs:</strong> local manifest scanning median <50ms; resolved remote snapshot retrieval median <2s under normal networks (worker path); deps report atomic write median <200ms on local SSD. <br><strong>CI gates:</strong> signature verification golden vectors, <code>reportHash</code> parity across OSes, static analyzer enforcement forbidding UI-thread network calls, audit emission verification. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>High-level workflow & invariants (detailed):</strong><br>1. UI idle: <code>LoadLocalManifests</code> loads embedded templates, hidden-sheet <code>PQ_TEMPLATES</code>, and add-in manifests with minimal metadata only (name, templateId, mChecksum, requiredConnectors, signaturePolicy). Emits <code>pq.ensuredeps.manifest.load</code>. <br>2. Worker: <code>ResolveRemoteManifests</code> fetches remote template repo index and connector capability manifests, validates schema, computes <code>mChecksum</code> for templates and connectors, caches snapshot in evidence store signed by release manifest key. Emits <code>pq.ensuredeps.remote.resolve.completed</code>. <br>3. <code>InspectInstalledAddins</code> enumerates installed XLAMs and registered connectors via host APIs, extracts code-signing status and matches owners from <code>OWNERS.md</code>. Emits <code>pq.ensuredeps.addin.scan</code>. <br>4. Compatibility checks: for each template, run <code>EnsureTemplateCompatibility</code> which calls <code>ValidateConnectorVersion</code> and <code>ValidatePQRuntimeVersion</code> and <code>VerifyTemplateSignature</code> when required; compute <code>compatibilityStatus</code> and <code>repairActions</code>. Emit <code>pq.ensuredeps.template.verify</code>. <br>5. Produce canonical report: <code>ProduceDepsReport</code> produces <code>deps.report.json</code> with <code>reportHash</code>, persists via <code>AtomicWriteDepsReport</code>, and emits <code>pq.ensuredeps.report.generated</code> and <code>pq.ensuredeps.report.atomic_write.completed</code>. <br>6. On failures or missing deps propose repairs via <code>RepairMissingDeps</code> (idempotent proposals). Repairs require explicit operator approval for system changes; for regulated templates require two-person approval. <br><strong>Invariants:</strong> canonical ordering, stable tie-breaking when multiple repair options exist (use <code>GenerateDepFingerprint</code> seed), all persisted artifacts written with <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>API function breakdown — exhaustive</strong> </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>LoadLocalManifests(workbookSnapshot, correlationId, options={fastMode:true})</code></strong><br><strong>Purpose & contract:</strong> collect minimal manifest metadata from the active workbook and installed add-ins without network I/O; safe for UI idle path. Return deterministic list sorted by <code>templateId</code>. <br><strong>Parameters:</strong> <code>workbookSnapshot</code> (a redacted, read-only snapshot or workbook handle), <code>correlationId</code>, <code>options.fastMode</code> boolean. <br><strong>Return:</strong> <code>{manifests:[{templateId, mChecksum, requiredConnectors, minPQRuntime, signaturePolicy, owner}], manifestsHash, durationMs}</code>. <br><strong>Behavior & implementation notes:</strong><br>1. Canonicalize manifest fields: normalize version strings to semver where present and canonicalize <code>requiredConnectors</code> to lowercase provider ids. <br>2. Read hidden-sheet <code>PQ_TEMPLATES</code> once and parse rows into manifest records; if hidden-sheet missing return empty list with <code>manifestCount=0</code>. <br>3. Validate manifest schema lightly (presence of required keys) and emit <code>pq.ensuredeps.manifest.load</code> audit with <code>manifestsHash</code>. <br>4. In <code>fastMode=true</code> only include essential fields to minimize host calls; schedule fuller manifest retrieval in worker when operator triggers full check. <br><strong>Edge cases:</strong> corrupted hidden-sheet -> emit <code>pq.ensuredeps.manifest.load</code> with <code>result=malformed</code> and <code>evidenceRef</code> pointing to sanitized manifest snapshot. <br><strong>Observability:</strong> <code>pq.ensuredeps.manifest.load</code> with <code>manifestCount</code>, <code>invalidCount</code>, <code>durationMs</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>InspectInstalledAddins(hostApi, correlationId)</code></strong><br><strong>Purpose & contract:</strong> enumerate installed add-ins and provider bindings visible to Power Query and compute signature/trust status per add-in. <br><strong>Return:</strong> <code>{installedAddins:[{name,path,version,enabled,signedBy,signatureValid}], connectors:[{providerId, registered, implementingModule, version}], summary}</code>. <br><strong>Behavior:</strong><br>1. Use host APIs for installed add-ins and provider registration; do not change host state. <br>2. Validate code-signing metadata if available and cross-reference <code>OWNERS.md</code> for owner identity mapping; record <code>signedBy</code> as ownerId or <code>UNKNOWN</code>. <br>3. If multiple versions exist, choose highest deterministically using <code>compareSemver</code> fallback to lexical sort with stable tie-breaker. <br>4. If provider registration malformed or missing expected entrypoint, mark <code>status=MISSING_BINDING</code>. <br><strong>Observability:</strong> <code>pq.ensuredeps.addin.scan</code> with <code>installedCount</code>, <code>untrustedCount</code>, <code>missingBindings</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>ResolveRemoteManifests(templateRepoConfig, correlationId, cachePolicy)</code></strong><br><strong>Purpose & contract:</strong> worker-only resolution of remote repo indexes and connector capability manifests; produce signed snapshot stored in encrypted evidence store. <br><strong>Parameters:</strong> <code>templateRepoConfig</code> (primary URL, mirrors, authRef), <code>correlationId</code>, <code>cachePolicy</code> (ttl, preferCached). <br><strong>Return:</strong> <code>{snapshotHash, snapshotRef, status, diagnostics}</code>. <br><strong>Detailed behavior (must/shall):</strong><br>1. Attempt fetch from primary; on failure iterate mirrors; on each fetch perform HTTP validation, ETag/Last-Modified checks, and compute <code>mChecksum</code> for each template manifest and template payload. <br>2. Validate index and manifests against JSON Schema (v1/v2). <br>3. For each template entry compute canonical payload (strip non-deterministic fields, normalize line endings) and compute <code>mChecksum</code> (SHA256). <br>4. Cache raw response and parsed canonical snapshot encrypted in evidence store. <br>5. Emit <code>pq.ensuredeps.remote.resolve.completed</code> with <code>snapshotHash</code> and <code>durationMs</code>. <br><strong>Failure handling & degrade modes:</strong><br>1. Network failure -> status <code>DEGRADED</code> and return last cached snapshot if available with <code>degradedRationale=network_unreachable</code>. <br>2. Schema invalid -> status <code>INVALID_REMOTE_MANIFEST</code> and set <code>degraded=true</code> with evidenceRef. <br><strong>Security & auth:</strong> use secure authRef token via secure credential manager; never log the token. <br><strong>Observability:</strong> <code>pq.ensuredeps.remote.resolve.attempt</code> and <code>completed</code> audits. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>ValidateConnectorVersion(requiredConnectorSpec, installedConnectors, correlationId)</code></strong><br><strong>Purpose & contract:</strong> validate that installed connectors satisfy the <code>requiredConnectorSpec</code> (semver ranges, capabilities, provider ids). <br><strong>Return:</strong> <code>{name, requiredRange, installedVersion, status, rationale, candidates}</code> where <code>status</code> ∈ {OK, WARNING, MISMATCH, MISSING}. <br><strong>Behavior details:</strong><br>1. Support semver ranges as well as capability predicates (eg <code>supportsLoadToModel=true</code>, <code>supportsOAuth2=true</code>). <br>2. For vendors with non-semver schemes, map vendor versions to compatibility levels using <code>compatibilityMatrix</code> shipped in release manifest. <br>3. When several candidates available choose highest compatible one deterministically. Emit <code>pq.ensuredeps.connector.validate</code> audit. <br>4. If installed version within known-broken set, mark <code>status=KNOWN_BROKEN</code> and attach <code>workaround=useWorkerExecution</code> if applicable. <br><strong>Edge cases:</strong> connector installed but provider registration missing -> <code>status=MISSING_BINDING</code>. <br><strong>Repair suggestions:</strong> provide <code>repairActions: [&quot;installConnector&quot;, &quot;registerProvider&quot;, &quot;upgradeConnector&quot;]</code> with secure download references in evidenceRef. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>ValidatePQRuntimeVersion(installedRuntimeInfo, requiredRuntimeRange, correlationId)</code></strong><br><strong>Purpose & contract:</strong> verify host M/runtime compatibility; return <code>{installedVersion, status, rationale, recommendedAction}</code>. <br><strong>Behavior & mapping:</strong><br>1. Normalize runtime identifiers across hosts (Excel, PowerBI Desktop, Server) via <code>runtimeMap</code>. <br>2. Compare installed runtime to required ranges expressed by templates & connectors. <br>3. If below minimum set <code>status=INCOMPATIBLE</code> and <code>recommendedAction=upgradeHostOrUseWorker</code>. If above maximum (preview channel), set <code>status=UNTESTED</code> and recommend two-person approval for regulated templates. <br>4. Emit <code>pq.ensuredeps.pqruntime.validate</code> audit with <code>installedVersion</code> and <code>status</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>EnsureTemplateCompatibility(manifestsList, resolvedSnapshot, installedConnectors, pqRuntime, correlationId, policy)</code></strong><br><strong>Purpose & contract:</strong> iterate templates and produce detailed compatibility entries including repair actions and evidenceRefs; return <code>TemplateCompatibilityReport</code>. <br><strong>Detailed steps:</strong><br>1. For each template determine <code>requiredConnectors</code>, <code>minRuntime</code>, <code>maxRuntime</code>, <code>signaturePolicy</code>, and <code>requiresHighPrecision</code>. <br>2. Validate connectors with <code>ValidateConnectorVersion</code> and runtime with <code>ValidatePQRuntimeVersion</code>. <br>3. Verify signature via <code>VerifyTemplateSignature</code> when <code>signaturePolicy==REQUIRED</code>; for <code>OPTIONAL</code> emit <code>signaturePresent=true/false</code>. <br>4. If <code>requiresHighPrecision=true</code> and runtime is <code>UNTESTED/INCOMPATIBLE</code> mark <code>recommendWorkerExecution=true</code>. <br>5. Build <code>repairActions</code> array: prioritized, deterministic, with explicit preconditions and idempotency tokens (e.g., <code>installConnector(packageUrl, packageHash)</code> with <code>idempotencyToken</code>). <br>6. Use <code>GenerateDepFingerprint</code> to produce per-template deterministic fingerprint for cache keys. <br><strong>Invariants:</strong> arrays sorted by <code>templateId</code>, deterministic tie-break ordering if multiple repair actions equal weight. <br><strong>Audits:</strong> emit <code>pq.ensuredeps.template.verify</code> per template with <code>compatibilityStatus</code>, <code>repairActions</code>, and <code>evidenceRef</code> links. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>VerifyTemplateSignature(templateBlob, signatureBlob, allowedOwners, correlationId)</code></strong><br><strong>Purpose & contract:</strong> cryptographically verify template signatures per <code>signaturePolicy</code>; return <code>{signatureValid, signerId, certFingerprint, certChainVerified, revocationStatus, evidenceRef}</code>. <br><strong>Implementation details:</strong><br>1. Support both detached signatures and embedded armored signatures (PGP, CMS/PKCS7, JOSE). <br>2. Validate signature algorithm allowed list (e.g., RSA-PSS, ECDSA with appropriate key lengths). <br>3. Validate certificate chain against release manifest trust anchors; perform OCSP/CRL checks when network available; if network unavailable set <code>revocationStatus=DEFERRED</code> and emit <code>pq.ensuredeps.template.signature</code> audit with <code>revocationDeferred=true</code>. <br>4. If signer not in <code>allowedOwners</code> set <code>signatureValid=false</code> and provide <code>repairAction: getOwnerApproval</code> or <code>rejectInjection</code>. <br>5. For regulated templates where owner mismatch occurs, require two-person approval before any injection or repair. <br><strong>Observability:</strong> <code>pq.ensuredeps.template.signature</code> audit with <code>signerId</code> and <code>evidenceRef</code> for signature blob. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>ProduceDepsReport(manifestsSnapshot, installedDeps, resolvedRemoteSnapshot, pqRuntimeInfo, correlationId, outputPath, options={stageLocal:false})</code></strong><br><strong>Purpose & contract:</strong> assemble the canonical, deterministic <code>deps.report.json</code> and persist it via <code>AtomicWriteDepsReport</code>. Return <code>{artifactPath, artifactChecksum, reportHash, persistedAt}</code>. <br><strong>Report content (canonical schema):</strong><br>• <code>correlationId</code><br>• <code>runTs</code> (UTC ISO8601)<br>• <code>configHash</code><br>• <code>releaseManifestHash</code><br>• <code>templates</code> array of <code>{templateId, mChecksum, compatibilityStatus, repairActions, signaturePolicy, owner}</code><br>• <code>connectors</code> array of <code>{name, requiredRange, installedVersion, status}</code><br>• <code>pqRuntime</code> object <code>{installedVersion, status}</code><br>• <code>degraded</code> boolean and <code>degradedReasons</code><br>• <code>evidenceRefs</code> mapping resource->evidenceRef<br>• <code>reportHash</code> (SHA256 canonical JSON) <br><strong>Canonicalization rules (must):</strong> keys sorted lexicographically at each object level; arrays sorted by <code>templateId</code> or <code>connectorName</code>; fixed field ordering for stable <code>reportHash</code>; UTF-8, normalized NFKC for strings, normalized newline <code>\n</code>. <br><strong>Persistence & atomic write:</strong> call <code>AtomicWriteDepsReport</code> with payload stream and sidecar <code>report.metadata.json</code> containing <code>reportHash</code>, <code>correlationId</code>, <code>evidenceRefs</code>. If <code>options.stageLocal=true</code> write to staging area when final destination unreachable and set <code>degraded=true</code> with <code>degradedRationale=&quot;destination_unavailable&quot;</code>. <br><strong>Observability:</strong> emit <code>pq.ensuredeps.report.generated</code> containing <code>reportHash</code> and <code>artifactChecksum</code> after successful atomic write. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>AtomicWriteDepsReport(targetPath, payloadStream, correlationId, tmpSuffix=&quot;.part&quot;, maxAttempts=3)</code></strong><br><strong>Purpose & contract:</strong> specialized wrapper calling plumbing atomic-write utility; ensure fsync and parent fsync semantics where supported; create sidecar <code>report.metadata.json</code>. Return <code>{success, artifactPath, artifactChecksum, attempts, elapsedMs}</code>. <br><strong>Behavior:</strong><br>1. Compute tempPath deterministically: <code>targetPath + tmpSuffix + &quot;.&quot; + pid + &quot;.&quot; + deterministicSuffix</code> where deterministicSuffix derived from <code>GenerateDepFingerprint</code>. <br>2. Write payload stream to tempPath, compute SHA256, optionally write sidecar metadata including <code>payloadHash</code> and <code>correlationId</code>. <br>3. fsync file and parent directory where supported; call platform atomic replace API (<code>os.replace</code> on POSIX, ReplaceFile on Windows). <br>4. Reopen targetPath and verify checksum matches computed artifactChecksum; if mismatch emit <code>pq.ensuredeps.report.atomic_write.verification_failed</code> and attempt repair per retry policy. <br><strong>Degraded behavior:</strong> when rename semantics unreliable (NFS/SMB), fallback to copy-then-rename pattern with <code>pq.ensuredeps.degraded</code> audit and explicit <code>repairActions</code>. <br><strong>Observability:</strong> <code>pq.ensuredeps.report.atomic_write.attempt</code> and <code>pq.ensuredeps.report.atomic_write.completed</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>GenerateDepFingerprint(manifestsSnapshot, installedDeps, pqRuntime, salt=null)</code></strong><br><strong>Purpose & contract:</strong> produce deterministic fingerprint for dependency surface used for caching and golden testing; use HMAC_SHA256 over canonical serialized snapshot with optional salt. <br><strong>Return:</strong> <code>{fingerprintHex, fingerprintShort}</code> where <code>fingerprintShort</code> is first 12 hex chars. <br><strong>Usage:</strong> seeds for deterministic jitter in CI, cache keys, and stable grouping in telemetry. <br><strong>Observability:</strong> <code>pq.ensuredeps.fingerprint</code> audit with component counts. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>InspectTempArtifacts(directory, correlationId)</code></strong><br><strong>Purpose:</strong> enumerate left-over temporary artifacts from failed atomic writes, validate sidecar metadata if present, and surface repair suggestions. <br><strong>Output:</strong> <code>{tempFiles:[{path,size,payloadHash,valid}], validatedCount, suggestions:[{path,action}]}</code>. <br><strong>Observability:</strong> <code>pq.ensuredeps.temp.inspect</code> audit. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>RepairMissingDeps(repairProposal, dryRun=true, operatorApproval=null, correlationId)</code></strong><br><strong>Purpose & contract:</strong> generate and optionally apply repair steps to satisfy compatibility; actions are proposals by default — apply requires explicit operator approval and possibly two-person approval for regulated items. <br><strong>Repair step format (must):</strong> each step includes <code>idempotencyToken</code>, <code>actionType</code>, <code>parameters</code>, <code>preconditions</code>, <code>estimatedImpact</code>, <code>rollbackPlan</code>, <code>evidenceRef</code> for downloaded package. Example action types: <code>downloadConnector</code>, <code>registerProvider</code>, <code>enableHiddenSheetTemplate</code>, <code>promoteSnapshotToLocal</code>. <br><strong>Safety constraints:</strong> do not perform system-level changes without operator approval and required governance; when <code>requiresSystemChange=true</code> require SRE sign-off. <br><strong>Audit:</strong> <code>pq.ensuredeps.repair.attempt</code> and <code>pq.ensuredeps.repair.success</code> with <code>repairPlanHash</code>. <br><strong>Observability:</strong> record full plan in evidence store and persist <code>repair.plan.json</code> via <code>AtomicWrite</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong><code>DiagnoseDepsFailure(correlationId, failureContext, deepDiagnostics=false)</code></strong><br><strong>Purpose:</strong> collect a focused forensic bundle to triage dependency failures; include <code>deps.report.json</code>, <code>manifest snapshots</code>, <code>signature blobs</code>, <code>atomicWrite</code> failure logs, and <code>InspectTempArtifacts</code> outputs. <br><strong>Output:</strong> <code>diagnosticBundleRef</code> pointing to encrypted bundle in evidence store. <br><strong>Observability:</strong> <code>pq.ensuredeps.diagnose</code> audit referencing <code>diagnosticBundleRef</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Error taxonomy & representative error codes (expanded):</strong><br>• <code>PQ_DEPS_OK</code> — nominal. <br>• <code>PQ_DEPS_DEGRADED_NETWORK</code> — remote manifests unreachable; <code>repair: run remote resolve on worker</code>. <br>• <code>PQ_DEPS_MISSING_CONNECTOR</code> — connector missing; <code>repair: installConnector</code>. <br>• <code>PQ_DEPS_INCOMPATIBLE_RUNTIME</code> — runtime not supported; <code>repair: upgradeHostOrUseWorker</code>. <br>• <code>PQ_DEPS_TEMPLATE_UNTRUSTED</code> — missing/invalid signature; <code>repair: ownerApprovalRequired</code>. <br>• <code>PQ_DEPS_ATOMIC_WRITE_ENOSPC</code> — ENOSPC while persisting report; <code>runbook: stage-local or free-space</code>. <br>• <code>PQ_DEPS_ATOMIC_WRITE_EPERM</code> — EPERM; <code>runbook: fix-perms</code>. <br>• <code>PQ_DEPS_SIGNATURE_DEFERRED</code> — revocation check deferred due to network. <br>• <code>PQ_DEPS_AMBIGUOUS_CONNECTOR</code> — multiple installed candidates; <code>repair: pickPreferred</code> or <code>uninstallAlternates</code>. <br>Each error provides operator guidance in <code>repairActions</code> and maps to specific runbook steps. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Observability, telemetry & audit schema (detailed):</strong><br><strong>Audit schema fields (required):</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module=PQ_EnsureDeps</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>durationMs</code>, <code>metadata</code> containing <code>templatesChecked</code>, <code>connectorsChecked</code>, <code>untrustedCount</code>, <code>degraded</code>. <br><strong>Primary audit events:</strong> <code>pq.ensuredeps.start</code>, <code>pq.ensuredeps.manifest.load</code>, <code>pq.ensuredeps.remote.resolve.completed</code>, <code>pq.ensuredeps.template.verify</code>, <code>pq.ensuredeps.report.generated</code>, <code>pq.ensuredeps.report.atomic_write.completed</code>. <br><strong>Metrics to buffer:</strong> <code>pq.ensuredeps.scan_latency_ms</code>, <code>pq.ensuredeps.remote.resolve_latency_ms</code>, <code>pq.ensuredeps.report_write_latency_ms</code>, <code>pq.ensuredeps.degraded_rate</code>, <code>pq.ensuredeps.untrusted_templates_count</code>. <br><strong>Evidence policy:</strong> audit rows reference only hashes and <code>evidenceRef</code>; full manifests, signatures and signed snapshots stored encrypted and access-controlled. PII cannot appear in top-level audit fields. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and CI governance (comprehensive):</strong><br><strong>Unit tests (must include):</strong><br>1. <code>LoadLocalManifests</code>: hidden-sheet present/absent, malformed entries, ensure canonical ordering and <code>manifestsHash</code>. <br>2. <code>ResolveRemoteManifests</code>: healthy and faulty network cases, schema invalid manifests, caching TTL behaviors. <br>3. <code>VerifyTemplateSignature</code>: valid signatures, invalid signatures, revoked certs, deferred revocation. <br>4. <code>ValidateConnectorVersion</code>: semver ranges, vendor-specific mapping, ambiguous multiple installs. <br>5. <code>AtomicWriteDepsReport</code>: rename/fsync failure simulation using FS mocks. <br><strong>Integration tests:</strong><br>1. Full end-to-end produce-report roundtrip: local manifest -> remote resolve -> signature verify -> produce <code>deps.report.json</code> persisted and checksum verified. <br>2. Worker-only remote resolve combined with UI fast-scan verifying consistent <code>reportHash</code> across runs. <br>3. Concurrency test: multiple parallel producers writing to same destination -> atomic writes prevent partial reads. <br><strong>Property tests:</strong><br>1. Determinism: repeated <code>ProduceDepsReport</code> with same inputs yields identical <code>reportHash</code> across platforms. <br>2. Repair idempotence: applying same <code>RepairMissingDeps</code> twice yields no duplicate system changes; step idempotency tokens enforced. <br><strong>Cross-language golden governance:</strong> maintain golden <code>mChecksum</code> and <code>reportHash</code> vectors across implementations (VBA/JS/Python/C#) and ensure parity. <br><strong>CI gating:</strong> static analyzer must flag network calls from UI fast-path; golden vector parity required; signature verification tests require test CA chain in pipeline. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit):</strong><br><strong>Required patterns:</strong><br>1. Use <code>LoadLocalManifests</code> for quick UI checks and schedule <code>ResolveRemoteManifests</code> on workers for authoritative checks. <br>2. Persist the canonical <code>deps.report.json</code> via <code>AtomicWriteDepsReport</code> for consumers. <br>3. Use deterministic <code>GenerateDepFingerprint</code> for cache keys and deterministic_jitter seeds in CI. <br>4. Always emit audits for major transitions and include <code>evidenceRef</code> when raw artifacts are stored. <br><strong>Forbidden patterns:</strong><br>1. No network requests on UI fast-path. <br>2. Do not auto-install system-wide connectors without explicit operator approval plus required governance. <br>3. Do not write PII into audit rows—use evidenceRef for sanitized content. <br>4. No locale-dependent sorting/formatting for canonicalization. <br><strong>Code-review checklist:</strong> verify audit emits exist, <code>AtomicWriteDepsReport</code> used, deterministic ordering enforced, signature verification present for <code>signaturePolicy=REQUIRED</code>, UI-thread safety validated, and tests/goldens present. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Operator runbook & incident playbooks (executable steps):</strong><br><strong>AtomicWrite ENOSPC runbook:</strong><br>1. Inspect <code>pq.ensuredeps.report.atomic_write.failure</code> audit for correlationId and <code>targetPath</code>. <br>2. Run <code>InspectTempArtifacts</code> to list temp files and capture <code>tempPaths</code> into <code>forensic_manifest.json</code>. <br>3. Free space on the mount or configure <code>deps.output.staging</code> and re-run <code>ProduceDepsReport --stageLocal true</code>. <br>4. Verify <code>pq.ensuredeps.report.atomic_write.completed</code> and compare checksums; if failure persists escalate to infra with <code>forensic_manifest</code> and audit_tail. <br><strong>Untrusted template runbook:</strong><br>1. Retrieve <code>pq.ensuredeps.template.signature</code> with <code>evidenceRef</code>. <br>2. Use offline verification tool to inspect certificate chain and check revocation if network blocked. <br>3. If signer unknown, consult OWNERS.md; require owner approval for regulated templates. <br>4. Optionally fallback to <code>lastKnownGood</code> snapshot and emit <code>pq.ensuredeps.repair.attempt</code>. <br><strong>PQ runtime incompatible triage:</strong><br>1. Confirm <code>pq.ensuredeps.pqruntime.validate</code> audit; collect <code>installedRuntimeVersion</code>. <br>2. If upgrade allowed, coordinate host upgrade with release manifest compatibility checks; else, run the template in a trusted worker and persist proofs. <br>3. For preview channel (untested newer runtime) require two-person approval for regulated templates. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples — expanded (multiple scenarios):</strong><br><strong>Scenario A — Operator preview & inject path for high-precision regulated template (full trace):</strong><br>1. Operator selects "Preview -> Inject" on template <code>rev-recog-v3</code> from PQ_Ribbon. Ribbon computes <code>correlationId=r-20260117-xyz</code>. Ribbon calls <code>LoadLocalManifests(workbookSnapshot, correlationId, fastMode=true)</code> which returns <code>manifest</code> for <code>rev-recog-v3</code> with <code>requiresHighPrecision=true</code> and <code>signaturePolicy=REQUIRED</code>. <code>pq.ensuredeps.manifest.load</code> audit emitted. <br>2. Add-in schedules a worker job to run <code>ResolveRemoteManifests(templateRepoConfig, correlationId)</code> because <code>requiresHighPrecision=true</code> and signature policy is strict; on worker the remote snapshot is fetched and <code>snapshotHash</code> computed; <code>pq.ensuredeps.remote.resolve.completed</code> audit emitted. <br>3. Worker invokes <code>EnsureTemplateCompatibility</code> which calls <code>ValidateConnectorVersion</code> for connectors <code>FinancialSource</code> and <code>JournalWriter</code>. <code>ValidatePQRuntimeVersion</code> shows host runtime <code>excel:2304</code> OK; <code>FinancialSource</code> is missing locally. The report entry for the template is <code>DEGRADED</code> with <code>repairAction: downloadConnector FinancialSource</code>. <code>pq.ensuredeps.template.verify</code> audit emitted with <code>repairActions</code>. <br>4. Since template <code>signaturePolicy=REQUIRED</code>, worker calls <code>VerifyTemplateSignature</code> using detached <code>.sig</code> artifact from the remote snapshot; signature validated and <code>signerId=TEAM_FINANCE</code> recorded. <code>pq.ensuredeps.template.signature</code> audit emitted with <code>evidenceRef</code>. <br>5. <code>ProduceDepsReport</code> produces canonical <code>deps.report.json</code> including the <code>DEGRADED</code> flag and <code>repairActions</code> and persists it via <code>AtomicWriteDepsReport</code>. <code>pq.ensuredeps.report.atomic_write.completed</code> emitted with artifact checksum. <br>6. Operator receives preview UI indicating <code>DEGRADED</code> for injection and a suggested repair to download connector <code>FinancialSource</code>. Operator requests <code>repairProposal</code> and approves to proceed with <code>RepairMissingDeps</code> under two-person-approval policy. Repair writes <code>repair.plan.json</code> via <code>AtomicWrite</code> and <code>pq.ensuredeps.repair.success</code> is audited. <br>7. After repair (connector installed in staging and registered), worker re-runs compatibility check and now <code>compatibilityStatus=OK</code>. Authoritative worker run performs final high-precision transforms using <code>SafeRound</code> primitives in worker, writes authoritative artifact via <code>AtomicWrite</code>, and <code>pq_inject</code> audit references the artifact checksum. <br><strong>Takeaway:</strong> separation of fast local manifests vs worker authoritative checks preserves UI responsiveness while maintaining compliance and determinism. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Scenario B — CI pipeline for template release requiring new connector capability (trace):</strong><br>1. Developer submits PR updating template <code>agg-sales-v5</code> to require <code>NewProvider&gt;=2.0</code>. CI job triggers and runs <code>ResolveRemoteManifests</code> against canonical test repo and <code>VerifyTemplateSignature</code> using the test CA. <code>pq.ensuredeps.remote.resolve.completed</code> and <code>pq.ensuredeps.template.signature</code> audits produced by CI harness. <br>2. CI validates <code>ValidateConnectorVersion</code> finds <code>NewProvider</code> absent in golden environment -> CI fails with <code>PQ_DEPS_MISSING_CONNECTOR</code>. Developer must add compatibility notes or provide vendor package. <br>3. Developer packages connector stub into test repo; CI re-runs and <code>GenerateDepFingerprint</code> produces fingerprint used in gating. CI asserts <code>reportHash</code> matches golden vectors and cross-platform parity tests for <code>mChecksum</code> pass; only then PR can merge. <br>4. Merge triggers release manifest update and owner approvals. Release manifest records new trust anchors if connector vendor signing required. <br><strong>Takeaway:</strong> CI acts as pre-flight gate to prevent templates reaching operator desks without necessary connectors or approvals. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Scenario C — Forensic reconstruction after injection mismatch:</strong><br>1. Operator reports that injected query code differs from canonical template for <code>correlationId=r-20260112-455</code>. Support runs <code>DiagnoseDepsFailure(correlationId, context)</code> which collects <code>deps.report.json</code>, <code>manifestSnapshot</code>, <code>signatureBlobs</code>, and <code>audit_tail</code>. <code>pq.ensuredeps.diagnose</code> audit emitted with <code>diagnosticBundleRef</code>. <br>2. Forensic replay uses <code>manifestSnapshot</code> and <code>evidenceRef</code> to reconstruct what <code>LoadLocalManifests</code> returned at run time; it finds the workbook had <code>templateId</code> <code>agg-sales-v4</code> but <code>mChecksum</code> mismatched (local edit) and signature absent. <code>pq.ensuredeps.template.verify</code> shows <code>mChecksum_mismatch</code>. <br>3. Support restores the canonical template and produces <code>forensic_manifest.json</code> and recommended mitigation: lock hidden-sheet templates for regulated flows and enforce <code>VerifyTemplateSignature</code> at injection. <br>4. Post-mortem: operator education plus adding static checks to disallow unsanctioned template edits in regulated contexts. <br><strong>Takeaway:</strong> evidenceRef and canonical <code>deps.report</code> allow deterministic replay and attribution. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Scenario D — Worker-only fallback for numeric fidelity across PQ host variance:</strong><br>1. Template <code>calc-alloc-v2</code> flagged <code>requiresHighPrecision=true</code>. Host runtime <code>excel:legacy</code> may have inconsistent decimal behavior. <code>EnsureTemplateCompatibility</code> recommends worker execution. <br>2. Add-in delegates numeric aggregation to worker: export normalized payload via <code>AtomicWrite</code> to staging area, worker runs <code>SafeRoundResiduals</code> with deterministic RNG seeded from <code>correlationId</code>, persists authoritative result via <code>AtomicWrite</code>, and injects read-only query into workbook referencing the authoritative artifact. <br>3. The <code>deps.report.json</code> records <code>requiresHighPrecision</code> and <code>executionMode=worker</code> to indicate authoritative steps occurred off-host. <code>pq.ensuredeps.report.generated</code> audit links to artifact checksum and RNG evidenceRef. <br><strong>Takeaway:</strong> for numeric regulated outputs, worker-side SafeRound and atomic persistence ensure cross-host parity and auditability. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Deep conceptual mapping to Power Query (M) — patterns and concrete guidance:</strong><br><strong>Context:</strong> M runtimes vary by host and version; PQ_EnsureDeps cannot change M runtime but must orchestrate around its limitations. Patterns below enforce deterministic behaviors and govern where sensitive transforms must run. <br><strong>Pattern 1 — Atomic persistence for injection & templates:</strong><br>1. Problem: M/host cannot guarantee atomic replace semantics or consistent folder fsync. <br>2. Pattern: generate canonical M query text in the trusted helper (add-in or worker), compute <code>mChecksum</code>, persist with <code>AtomicWriteDepsReport</code> to artifact store, then call <code>Workbook.Queries.Add(Name, Formula)</code> using the persisted payload. <br>3. Evidence: emit <code>pq_inject</code> audit linking <code>artifactChecksum</code> and <code>mChecksum</code>. <br>4. Governance: for regulated templates require signature validated by <code>VerifyTemplateSignature</code>. <br><strong>Pattern 2 — Deterministic preview & sampling in M:</strong><br>1. Problem: M lacks a canonical seedable RNG and host-level sampling implementations differ. <br>2. Pattern A (lightweight): host computes seed <code>SeedFromCorrelation(correlationId, templateId)</code> and passes it as a numeric parameter to M preview code implementing a pure M PRNG (e.g., linear congruential with documented parameters). M preview records the seed in preview audit. <br>3. Pattern B (heavy duty): perform sampling in worker using <code>DeterministicRNG</code> and persist sampling decisions (sampled keys, RNG state) in evidence store; M receives only deterministic sampled payload. <br>4. Replay: audits include seed and evidenceRef allowing exact reproduction. <br><strong>Pattern 3 — High-precision numeric transforms:</strong><br>1. Problem: M decimal fidelity and rounding semantics vary across hosts. <br>2. Pattern: templates declare <code>requiresHighPrecision=true</code>. For such templates, add-in orchestrator exports raw normalized data via <code>AtomicWrite</code> and delegates authoritative rounding/allocation to worker SafeRound primitives. Worker persists final artifact and returns an injected read-only query or refresh connection. <br>3. Auditing: <code>pq.ensuredeps.report.generated</code> includes <code>requiresHighPrecision</code> and <code>executionMode=worker</code>. <br><strong>Pattern 4 — Template signature & owner enforcement:</strong><br>1. Problem: local template edits or unsigned templates undermine governance. <br>2. Pattern: require <code>VerifyTemplateSignature</code> for templates with <code>signaturePolicy=REQUIRED</code>. If missing or invalid, block injection unless two-person approval is present; persist decision via audit. <br><strong>Pattern 5 — Retry & idempotency around PQ operations:</strong><br>1. Problem: injection or connection creation may fail transiently; retry semantics necessary. <br>2. Pattern: orchestrator uses <code>Retry</code> wrapper and persists <code>jobDescriptor</code> for idempotency prior to attempting injection so retries do not produce duplicates. <br><strong>Operator narrative (PQ injection step-by-step):</strong><br>1. Operator requests inject → <code>LoadLocalManifests</code> quick-scan → <code>EnsureTemplateCompatibility</code> determines <code>signaturePolicy</code> and <code>requiresHighPrecision</code>. <br>2. If signature required, call <code>VerifyTemplateSignature</code>; if unsigned, require approval. <br>3. Persist canonical M artifact via <code>AtomicWriteDepsReport</code>. <br>4. Call <code>Workbook.Queries.Add</code> with payload; emit <code>pq_inject</code> audit linking artifact checksum and <code>mChecksum</code>. <br><strong>Governance note:</strong> for regulated templates require signed release manifest and enforced static analyzer blocking injection of modified local templates. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Deep conceptual mapping to DAX & semantic model design (expanded):</strong><br><strong>Context:</strong> DAX is read-time and cannot perform side effects; authoritative decisions must be made in ETL or worker layers. PQ_EnsureDeps ensures model authors and consumers can rely on deterministic ETL and metadata. <br><strong>Pattern 1 — Push rounding and residuals to ETL:</strong><br>1. Rationale: DAX can't persist rounding decisions or side-effects required for residual distribution. <br>2. Pattern: run <code>SafeRoundResiduals</code> in worker, persist everything as integer cents in model tables; DAX then computes sums and KPIs deterministically. <br>3. Evidence: store <code>RunMetadata</code> row for the run with <code>correlationId</code>, <code>artifactChecksum</code>, <code>depsReportHash</code>. <br><strong>Pattern 2 — Deterministic sampling via hashed keys:</strong><br>1. Rationale: DAX lacks seedable PRNGs for reproducible sampling. <br>2. Pattern: ETL computes <code>HashKey = HMAC_SHA256(PrimaryKey | correlationSalt)</code> and stores <code>sampleFlag = (HashKey MOD N) &lt; k</code>. Persist <code>correlationSalt</code> in <code>RunMetadata</code>. DAX can apply filter <code>sampleFlag=1</code> to create deterministic report slices. <br><strong>Pattern 3 — Model-level RunMetadata table and reconciliation:</strong><br>1. ETL writes <code>RunMetadata</code> atomically with dataset artifact and <code>deps.report.json</code> data. <br>2. DAX measures reference <code>RunMetadata</code> to compute <code>ReconciledFlag</code> by comparing expected artifact checksum to the run's artifact checksum. DAX formula example (descriptive): compute <code>IsReconciled</code> measure based on equality of artifact checksum fields persisted in model. <br><strong>Pattern 4 — Surface <code>degraded</code> and <code>repairActions</code> in model:</strong><br>1. ETL includes <code>degraded</code> boolean and <code>degradedReasons</code> in <code>RunMetadata</code>. DAX or report visuals can surface <code>DegradedIndicator</code> to warn consumers that dataset used degraded fallbacks. <br><strong>Pattern 5 — Traceability from report measure back to PQ_EnsureDeps:</strong><br>1. Include <code>depsReportHash</code> in <code>RunMetadata</code> and in the workbook template injected; UI surfaces provide "View deps report" linking to evidenceRef for investigator use. <br><strong>Governance & operator guidance for models:</strong><br>1. Never implement allocation/residual distribution in DAX. <br>2. Use ETL-run <code>RunMetadata</code> to ensure report consumers can verify dataset provenance. <br>3. When a model shows <code>DegradedIndicator</code>, require human review before using dataset for regulated reporting. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Extended forensic artifacts & retention — practical details:</strong><br><strong>Minimum forensic artifact set for a run:</strong><br>1. <code>deps.report.json</code> persisted atomically containing <code>reportHash</code> and artifact checksum. <br>2. <code>manifestSnapshot.blob</code> encrypted evidenceRef with canonical manifests and <code>snapshotHash</code>. <br>3. <code>signatureBlobs</code> for templates with <code>evidenceRef</code>. <br>4. <code>diagnosticBundle.zip</code> containing <code>audit_tail.csv</code>, preserved temp artifacts, and <code>forensic_manifest.json</code>. <br>5. <code>serializedRNGState</code> if deterministic sampling or tie-breaks used. <br>6. <code>SafeRound</code> input snapshots (canonical decimals) and rounding logs. <br>7. <code>atomicWrite</code> temp files and their sidecar metadata. <br><strong>Storage & retention:</strong><br>1. Hot: <code>\\evidence\hot\pq_ensuredeps\&lt;correlationId&gt;\</code> for 30 days. <br>2. Warm: secure archive for regulatory retention up to 7 years. <br>3. Cold: vault with chain-of-custody metadata as required by regulation. <br><strong>Access & controls:</strong> evidence blobs encrypted and role-based access; audit logging for evidence retrieval. <br><strong>Retention verification:</strong> monthly retention job emits <code>housekeeping.audit</code> and proof-of-delete for expired evidence. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (expanded):</strong><br>1. OWNERS listed and contactable in OWNERS.md. <br>2. Public API stable, documented, semver versioning in manifests. <br>3. <code>LoadLocalManifests</code> uses no network and passes static analyzer. <br>4. Cross-platform golden vectors for <code>mChecksum</code> and <code>reportHash</code> present. <br>5. Signature verification tests included with test CA chain. <br>6. AtomicWrite tests and temp artifact recovery proofs present. <br>7. Audit hooks integrated and validated with test harness emitting expected audit rows. <br>8. Two-person approval flows tested for regulated repair scenarios. <br><strong>Blocking conditions:</strong> missing audit emissions, failing golden vectors, or static analyzer detection of forbidden UI-thread operations. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Comprehensive test plan highlights & scripts (explicit conceptual):</strong><br><strong>Unit tests:</strong><br>1. <code>LoadLocalManifests</code>: hidden-sheet present, absent, malformed; assert <code>manifestsHash</code>. <br>2. <code>ResolveRemoteManifests</code>: simulate 200 OK, 500 errors, TTL expiry. <br>3. <code>VerifyTemplateSignature</code>: valid, invalid, revoked, deferred. <br>4. <code>ValidateConnectorVersion</code>: semver range matching, vendor mapping. <br>5. <code>AtomicWriteDepsReport</code>: simulate ENOSPC/EACCES/rename failure via FS mocks. <br><strong>Integration tests:</strong><br>1. Full roundtrip: local manifest -> remote -> signature -> produce <code>deps.report.json</code> -> readback verify. <br>2. Concurrent producers: multiple processes writing to same target path, assert no partial reads. <br>3. Worker fallback: host runtime incompatible -> worker run executes final tasks and writes <code>deps.report.json</code> with <code>executionMode=worker</code>. <br><strong>Property tests:</strong><br>1. Determinism: canonicalization property ensures identical <code>reportHash</code> across permutations. <br>2. Idempotence: applying <code>RepairMissingDeps</code> twice is a no-op. <br><strong>Performance tests:</strong><br>1. Local manifest scan under 10k templates embedded in library. <br>2. Remote resolve performance under large index (10k templates). <br><strong>CI gating:</strong> unit/integration/goldens and static checks mandatory. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Operator commands & quick references (one-liners):</strong><br>1. <code>pq_ensuredeps scan --correlation r-YYYYMMDD-abc --fast</code> — quick local scan. <br>2. <code>pq_ensuredeps resolve-remote --correlation r-... --force</code> — worker-only full resolution. <br>3. <code>pq_ensuredeps produce-report --out deps.report.json --correlation r-...</code> — produce canonical report. <br>4. <code>pq_ensuredeps repair --plan repair.plan.json --apply --approvals &lt;a,b&gt;</code> — apply repair with approvals. <br>5. <code>pq_ensuredeps diagnose --correlation r-... --output diagbundle.zip</code> — produce diagnostic bundle for SRE. <br><strong>When to call SRE:</strong> after <code>AtomicWrite</code> ENOSPC for critical artifacts or repeated <code>ValidateConnectorVersion</code> ambiguity that blocks regulated templates; include forensic_manifest and audit_tail in ticket. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded):</strong><br><strong>Failure mode: missing connector on particular host</strong><br>1. Likely cause: per-user vs per-machine install mismatch or provider registration missing. <br>2. Mitigation: recommend unified installation of connector or use worker execution; include <code>repairAction: installConnector</code> with evidenceRef and staged plan. <br><strong>Failure mode: deferred signature revocation checks</strong><br>1. Cause: network policy blocks OCSP/CRL. <br>2. Mitigation: perform revocation checks in worker allowed network context or use cached revocation with <code>revocationDeferred=true</code> and <code>degradedReason</code>. <br><strong>Failure mode: non-deterministic <code>reportHash</code> across hosts</strong><br>1. Cause: non-canonical serialization or locale-sensitive sorting. <br>2. Mitigation: enforce canonical JSON serialization with stable ordering, NFKC normalization, and newline normalization. Add CI golden parity tests. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests and golden vectors for new deterministic outputs. <br>2. Changes to signature verification or trust anchors require Security owner approval and release manifest update. <br>3. Changes to <code>AtomicWriteDepsReport</code> semantics require cross-platform regression tests and SRE sign-off. <br>4. Any new repair action modifying system state requires SRE and two-person approval for regulated templates. <br>5. OWNERS approval required for template or connector compatibility policy changes. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Appendix A — <code>deps.report.json</code> canonical schema (descriptive summary):</strong><br><strong>Top-level keys:</strong> <code>correlationId</code>, <code>runTs</code>, <code>configHash</code>, <code>releaseManifestHash</code>, <code>templates</code>, <code>connectors</code>, <code>pqRuntime</code>, <code>degraded</code>, <code>degradedReasons</code>, <code>repairActions</code>, <code>evidenceRefs</code>, <code>reportHash</code>. <br><strong>Policy:</strong> top-level audit rows reference only <code>reportHash</code> and <code>evidenceRef</code>; raw manifests/signatures stored encrypted. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Appendix B — Forensic reconstruction example (explicit):</strong><br><strong>Incident:</strong> injection mismatch for run r-20260112-455. <br><strong>Steps:</strong><br>1. Retrieve <code>pq.ensuredeps.report.generated</code> and <code>pq.ensuredeps.manifest.load</code> audits. <br>2. Pull <code>deps.report.json</code> artifact and <code>manifestSnapshot</code> from evidence store. <br>3. Restore <code>serializedRNGState</code> and <code>SafeRound</code> inputs to reproduce allocation decisions. <br>4. Re-run compatibility checks offline and compare canonical M payloads; produce <code>forensic_manifest.json</code> with artifacts and checksums. <br>5. Package and escalate as required for compliance. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Appendix C — PQ template author checklist (detailed):</strong><br>1. Provide <code>mChecksum</code> in template metadata. <br>2. Specify <code>requiresHighPrecision=true</code> for numeric critical templates. <br>3. Include detached or embedded signature. <br>4. Declare <code>requiredConnectors</code> and <code>minPQRuntime</code>/<code>maxPQRuntime</code>. <br>5. Provide migration notes and compatibility hints. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Appendix D — DAX/report builder checklist (detailed):</strong><br>1. Consume <code>RunMetadata</code> table for provenance. <br>2. Avoid allocation or residual rounding in DAX. <br>3. Use ETL-provided hashed stable keys for deterministic sampling and filters. <br>4. Surface <code>degraded</code> flags and require validation for regulated outputs. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Appendix E — Long-form operator reconstruction example (step-by-step):</strong><br><strong>Incident synopsis:</strong> reported "Allocation mismatch for run r-20260112-455" — sums differ between artifact and ledger. <br><strong>Forensic steps:</strong><br>1. Retrieve <code>UserAction</code> and <code>pq.ensuredeps.*</code> audits for correlationId. <br>2. Pull <code>deps.report.json</code> artifact and <code>manifestSnapshot</code>. <br>3. Pull <code>serializedRNGState</code> and <code>SafeRound</code> canonical decimal snapshots from evidence store. <br>4. Re-run allocation pipeline in reproduce mode using persisted RNG and canonical decimals. <br>5. If reproduction succeeds, package <code>forensic_manifest.json</code> and close incident; if not, collect temp artifacts and <code>atomic_write.verification_failed</code> logs and escalate. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Extremely detailed extra narratives — developer, CI, SRE interactions:</strong><br><strong>Developer scenario — building new template requiring connector feature:</strong><br>1. Developer marks template <code>requiresConnector=AdvancedPull</code> and updates manifest. <br>2. Local dev harness runs <code>LoadLocalManifests</code> to verify manifest schema and runs <code>ResolveRemoteManifests</code> against test repo to produce golden <code>mChecksum</code>. <br>3. Developer includes golden vector in PR and adds compatibility notes and unit tests for <code>ValidateConnectorVersion</code>. <br>4. CI verifies that connector exists in the canonical test repo and verifies <code>reportHash</code> parity. If CI fails <code>PQ_DEPS_MISSING_CONNECTOR</code>, developer must provide connector stub or change template. <br><strong>SRE scenario — repeated atomic-write failures:</strong><br>1. SRE receives <code>pq.ensuredeps.report.atomic_write.failure</code> alerts with ENOSPC across hosts. <br>2. SRE runs <code>InspectTempArtifacts</code> to locate lingering <code>tmp</code> files, cleans up temp artifacts, and frees space or adjusts <code>deps.output.staging</code> configuration. <br>3. SRE updates runbook to include <code>disk-space-sentry</code> to preempt staging failures. <br><strong>Governance scenario — owner change for template:</strong><br>1. Template owner transfer requires updating <code>OWNERS.md</code> and re-signing templates. <br>2. PQ_EnsureDeps CI ensures <code>VerifyTemplateSignature</code> now validates against new owner certificate chain and audit records owner change in <code>releaseManifest</code>. <br>3. Two-person approval required to accept owner changes for regulated templates; PQ_EnsureDeps refuses injection until approvals recorded. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Practical developer examples (guidance, not code snippets):</strong><br><strong>Example — canonicalization rules summary:</strong><br>1. Serialize JSON with lexicographically sorted object keys; arrays sorted by stable keys like <code>templateId</code>. <br>2. Normalize all strings to Unicode NFKC and strip trailing spaces. <br>3. Use <code>\n</code> as newline and UTF-8 encoding. <br>4. Compute SHA256 over canonical bytes to produce <code>reportHash</code> and <code>mChecksum</code>. <br><strong>Example — repair action structure (descriptive):</strong> each <code>repairAction</code> entry should include <code>actionType</code>, <code>parameters</code>, <code>idempotencyToken</code>, <code>estimatedImpact</code>, <code>rollbackPlan</code>, <code>evidenceRef</code>. This ensures safe automated guidance while requiring operator approval for system changes. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Operational checks & automation guidance:</strong><br>1. Automate monthly retention verification for evidence stores and emit <code>housekeeping.audit</code> with proof-of-delete for expired evidence. <br>2. Automate <code>VerifyAuditChain</code> job in CI to validate audit rotations and signing with release manifest keys. <br>3. Provide operator CLI: <code>pq_ensuredeps replay --correlation &lt;id&gt; --evidenceRef &lt;ref&gt;</code> to reproduce environment and template decisions. <br>4. Enforce static analyzer rules: forbid direct workbook writes on UI load handlers and forbid network calls in <code>fastMode</code>. </td></tr><tr><td data-label="PQ_EnsureDeps — Per-function Expert Technical Breakdown"> <strong>Final set of firm operational constraints (recap):</strong><br>1. No network I/O on UI fast-path; <code>ResolveRemoteManifests</code> must run in worker. <br>2. Persist <code>deps.report.json</code> atomically and emit audits for each persisted artifact. <br>3. Enforce signature verification for templates with <code>signaturePolicy=REQUIRED</code>; block injection unless <code>VerifyTemplateSignature</code> passes or two-person approval obtained. <br>4. Always attach <code>evidenceRef</code> for raw artifacts and avoid PII in audit rows. <br>5. Use <code>GenerateDepFingerprint</code> for caches and CI gating; keep golden vectors for parity across implementations. <br><strong>Checked:</strong> audit coverage, deterministic canonicalization, UI thread safety, worker fallback patterns, repair idempotency, and comprehensive runbooks and forensic evidence mapping. </td></tr></tbody></table></div><div class="row-count">Rows: 43</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>