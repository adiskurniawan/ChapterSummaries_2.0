<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1772308347">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="YJKN_0021_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Using Power Query (PQ) and VBA Together Effectively"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Using Power Query (PQ) and VBA Together Effectively</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Using Power Query (PQ) and VBA Together Effectively"> Power Query (PQ) and VBA serve different but complementary roles in a structured Excel-based payroll and XML generation pipeline. The most stable architecture separates responsibilities clearly: PQ handles extract–transform–validate processes in a declarative, repeatable way, while VBA manages orchestration, execution control, file handling, logging, and user-triggered automation. <br><br>PQ should be used for all structured data work: discovering named ranges, promoting headers, enforcing data types, normalizing formats, logging transformation changes, validating required fields, reconciling joins, and producing clean output tables. Because PQ is deterministic and query-based, every transformation step is visible, reviewable, and reproducible. <br><br>VBA should not replicate transformation logic. Instead, it should focus on macro-level workflow control: running preflight checks, refreshing queries, invoking the Converter workbook, generating XML files, creating run folders, calculating file hashes, writing manifests, handling locks, and stopping execution when blocking errors are detected. <br><br>Clear separation of responsibility reduces bugs, prevents duplicated logic, and improves auditability. If a business rule changes, it should be updated in PQ transformation steps, not scattered across macros. If an execution process changes, it should be adjusted in VBA without touching transformation logic. <br><br><strong>Core Design Principles</strong><br><br>1. <strong>Single Responsibility Model</strong><br>PQ = data transformation and validation. VBA = orchestration, file operations, and controlled execution. Avoid mixing business logic into VBA and avoid performing file system tasks in PQ. <br><br>2. <strong>Fail Early and Transparently</strong><br>PQ should surface structured diagnostics instead of hiding errors. Missing columns, parse failures, and join mismatches must produce diagnostic tables. VBA should block execution when critical diagnostics exist and write clear preflight summaries before export proceeds. <br><br>3. <strong>Auditability by Default</strong><br>Always retain raw values before normalization. If a number or identifier is cleaned or reformatted, log the original value in a change ledger. VBA should generate run-level artifacts such as run logs, manifest files, and checksum hashes for every XML produced. <br><br>4. <strong>Parameterization Over Hardcoding</strong><br>Sheet names, named ranges, period year, period month, converter paths, tolerance thresholds, and lock settings must come from configuration tables. Hard-coded strings create maintenance risk and should be eliminated. <br><br>5. <strong>Deterministic Exports</strong><br>Always implement a dry-run process before generating the final XML. Perform mapping difference checks and schema validation before invoking final SaveAsXML operations. Write XML to a temporary file first, compute hash, then rename to final filename. <br><br>6. <strong>Structured Error Handling</strong><br>Avoid silent error suppression. Replace broad error ignoring with centralized error handlers that capture procedure name, error number, error description, run identifier, and timestamp. <br><br><strong>Recommended Power Query Practices</strong><br><br>Use try–otherwise patterns to capture load failures when reading named ranges or tables. Immediately enforce expected data types after header promotion. Maintain an expected schema table to detect missing or extra columns. Generate conversion error tables when numeric or date parsing fails. Implement normalization as explicit transformation steps while preserving original values. Join payroll to staff data using stable identifiers first, then fallback logic with confidence scoring. Output matched, unmatched, and partially matched datasets for reconciliation. <br><br><strong>Recommended VBA Practices</strong><br><br>Implement a PreflightChecks routine to verify:<br>- Required sheets exist<br>- Converter workbook is present<br>- XML maps exist<br>- Required parameters are set<br>- No concurrent export is running<br><br>Implement locking mechanisms using workbook flags and optional filesystem lock files. Generate a unique run identifier for each export session. Record run start and end timestamps in a structured log. Always create a run folder and write artifacts into it. <br><br><strong>Suggested Operator Workflow</strong><br><br>1. Set reporting period in configuration sheet. <br>2. Refresh PQ and review diagnostics output. <br>3. Resolve all critical issues before proceeding. <br>4. Run VBA dry-run export. <br>5. Review mapping differences and validation summaries. <br>6. Perform final export only after sign-off. <br>7. Verify generated XML and checksum. <br>8. Archive bundle with manifest and logs. <br><br><strong>Do and Do Not Summary</strong><br><br>Do use PQ for transformations and validations. Do use VBA for execution control and artifact management. Do generate logs and change records automatically. Do version control the converter and mapping structure. <br><br>Do not hard-code sheet names, paths, or years. Do not use clipboard-based copy and paste for core logic. Do not automate name-only joins without reconciliation checks. Do not overwrite original data without logging changes. <br><br>When PQ and VBA are structured with this separation of roles, the system becomes easier to maintain, easier to audit, and safer to operate. Transformations remain transparent and testable in PQ, while VBA ensures disciplined execution and controlled file generation. </td></tr></tbody></table></div><div class="row-count">Rows: 1</div></div><div class="table-caption" id="Table2" data-table="YJKN_0021_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by BPMP XML Converter with Power Query &amp; VBA - User Guide"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">BPMP XML Converter with Power Query & VBA - User Guide</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>Executive overview (purpose, scope, audience)</strong><br><strong>Purpose:</strong> This document is the authoritative operator / technical / governance guide for the payroll consolidation workbook used to produce BPMP XML outputs. It documents the end-to-end pipeline that ingests monthly payroll ranges (<code>Payroll_Data_01</code>…<code>Payroll_Data_11</code>), enriches and reconciles those records with a canonical staff table (<code>Staff_Data</code>), validates and normalizes values, maps fields into converter templates, and exports signed canonical XML bundles for upload to downstream tax/benefit systems. The guide covers pipeline architecture, failure modes, hardening recommendations, validation rules, mapping governance, artifact management, manifest and checksum procedures, operator runbooks, incident playbooks, test cases, and audit evidence requirements. It is intended to allow the workbook to be run at production grade inside an operational control framework.<br><br><strong>Scope:</strong> This document addresses the complete pipeline from ingestion through production upload and archival. Scope items include: discovery of named ranges and tables in the workbook; Power Query (M) discovery/combination/enrichment patterns; data typing and normalization; validation layers and remediation pathways; deterministic mapping and XML canonicalization rules; Converter workbook contract management; VBA automation flows and required hardening; locking, manifest, and SHA256 mechanics; bundle assembly and signoff sequencing; runbooks for operators and evidence capture; incident response playbooks; regression and UAT test suites; retention and audit pack generation. Responsibilities are separated explicitly (operator, mapping owner, IT integrator, auditor) and artifacts' schemas are prescribed for each gate in the process.<br><br><strong>Risks (expanded):</strong><br>- <strong>Discovery risk:</strong> Named ranges missing or renamed cause empty PQ outputs. Failure mode: silent empty table or header mis-promotion. Detection: <code>pq_diagnostics</code> absent or reports zero rows for an expected range. Mitigation: parameterized discovery, diagnostics-first pattern, and operator preflight checklist.<br>- <strong>Reconciliation risk:</strong> Reliance on name-only joins causes misattribution. Failure mode: payments assigned to wrong employee when name collisions occur. Mitigation: join priority, composite keys (EmployeeID, NPWP, DOB), robustness scoring, and human-in-the-loop reconciliation for low-confidence matches.<br>- <strong>Parsing risk:</strong> Text-formatted numerics or mixed locale formatting produce silent numeric truncation or incorrect computations. Failure mode: PPh 21 or contribution calculation off by large amounts. Mitigation: explicit numeric parse rules, <code>conversion_errors</code> artifact, and fail-fast if critical currency fields cannot be parsed.<br>- <strong>Template drift risk:</strong> External Converter workbook or XmlMap changes break exports. Failure mode: <code>XmlMap</code> not found, or exported XML structure differs. Mitigation: converter versioning, preflight <code>converter_sha256</code> checks, mapping diffs, and mandatory dual approval for converter changes.<br>- <strong>VBA fragility and concurrency:</strong> Broad <code>On Error Resume Next</code>, clipboard dependence, or lack of locking create data corruption or partial exports. Mitigation: structured error handling, dry-run capability, concurrency locks, atomic write patterns, and run log forensic capture.<br>- <strong>Governance & auditability gaps:</strong> No manifest or checksum makes evidence unverifiable. Mitigation: manifest generation, SHA256 over canonical XML, retention policy, and append-only <code>change_ledger</code> with digest signing.<br><br><strong>Audience:</strong> Payroll operators, HR data stewards, payroll and tax owners, integration/IT personnel, QA/regression engineers, internal auditors, compliance officers, and third-party integrators. Operators focus on runbook and preflight; developers focus on PQ hardening, macro refactor, and manifest automation; auditors use audit-pack and manifest verification procedures. Each role has a short responsibilities list in the appendix of this guide. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>1 — Workbook quick inventory & behavioral summary (expanded)</strong><br><strong>High-level summary:</strong> The workbook comprises: (1) sheet-level data sources used as inputs (Staff and monthly payroll ranges), (2) Power Query transforms combining and enriching payroll ranges into a canonical operator-facing table, and (3) VBA automation used for staging, small interactive filters, and orchestrating export through an external Converter workbook. The pipeline intentionally targets simplicity for small-to-medium runs but requires production hardening to meet audit and control standards. Key touch points: query refresh on sheet activation, filter-triggered staging build into <code>ShBPMPTempData</code> via AdvancedFilter, and <code>CreateXMLFile</code> which populates the Converter and invokes <code>SaveAsXMLData</code> using an XmlMap. The workbook assumes a converter file present at <code>./Converter/BPMP Excel to XML v.3.xlsx</code>. Staging sheet <code>ShBPMPTempData</code> expects header row anchored at A9 with data from A10 onward. Consolidated PQ output should populate <code>BPMP_All</code> for operator inspection and QC.<br><br><strong>1.1 Required sheets / named ranges (operator-visible contract):</strong><br>- <code>Staff_Data</code> — canonical staff master: must be an Excel Table / named range with a header row. Required / preferred columns: <code>EmployeeID</code>(stable internal id), <code>Nama</code>, <code>NamaNorm</code>(precomputed normalization), <code>NPWP</code>(tax id), <code>NIK</code>, <code>DOB</code>, <code>Position</code>, <code>PTKPStatus</code>, <code>StartDate</code>, <code>EndDate</code>, <code>TaxClass</code>, <code>ActiveFlag</code>, <code>LastUpdatedTs</code>. Maintenance: HR must record a change log and last-update timestamp; changes to NPWP / EmployeeID must be versioned and require HR signoff.<br>- <code>Payroll_Data_01</code> … <code>Payroll_Data_11</code> — input ranges/tables for each payroll source or segment. Each must be an Excel Table or named range with first row as header. Baseline headers expected include <code>Nama</code>, <code>Masa Pajak</code>, <code>Gaji</code>, <code>Basis For Calculating BPJS Allowance</code>, <code>Tunjangan JSHK</code>, <code>Tunjangan Asuransi</code>, <code>JKK 0,24%</code>, <code>JKM 0,3%</code>, <code>JHT 3,7%</code>, <code>JHT 2%</code>, <code>JP 2%</code>, <code>JP 1%</code>, <code>BPJSKes 4%</code>, <code>BPJSKes 1%</code>, <code>Jumlah Penghasilan Bruto</code>, <code>Tarif</code>, <code>Gross Up (Y/N)</code>, <code>Take Home Pay</code>, <code>PPh 21</code>, <code>Total BPJSTK</code>, <code>Total BPJSKes</code>. Policy: if required columns are missing pipeline must stop and emit a <code>CheckRequiredColumns</code> failure in <code>pq_diagnostics</code>.<br>- <code>ShBPMPTempData</code> — staging sheet used for AdvancedFilter output. Strict layout: headers at row 9 starting at column A (A9..N9 expected header span), data from row 10 downward. No manual edits below header except via macros. Macros overwrite A10:Q1002 in current implementation; do not edit these addresses without updating macros. The staging sheet is the canonical source used by <code>CreateXMLFile</code> to populate Converter <code>DATA</code> sheet.<br>- <code>BPMP_All</code> — consolidated PQ output intended for operator landing and QA. It should be a protected sheet (read-only for operators) with a query table anchored at A4. The refresh behavior is tied to <code>Worksheet_Activate</code> on that sheet to show current PQ output on navigation.<br><br><strong>1.2 Power Query artifacts: observed behavior and expected outputs (detailed):</strong><br>- <strong>Discovery & combination:</strong> PQ uses <code>Excel.CurrentWorkbook()</code> to enumerate named ranges / tables. Given the original code, discovery is explicit for <code>Payroll_Data_01..11</code>. Recommended improvement is a parameter-driven discovery. The query promotes headers, adds a <code>Source</code> column (derived by removing <code>_Data</code> suffix) and then combines tables. If no ranges are found, PQ errors with an explicit message.<br>- <strong>Normalization:</strong> PQ constructs <code>NamaKey</code> as a lowercased trimmed <code>Nama</code>. This simple normalization is fragile (accents, punctuation, whitespace variants). Improve with a multi-step normalizer: canonical Unicode normalization, punctuation removal, whitespace collapse, and optionally surname-first detection for common local naming conventions.<br>- <strong>Join & enrichment:</strong> An inner join is used to match payroll rows to staff. Current behavior: unmatched rows are dropped. This is unsafe; recommended behavior is to create <code>matched_rows</code>, <code>left_anti</code> (payroll rows not matched to staff), and <code>right_anti</code> (staff not matched to payroll) outputs. <code>left_anti</code> must be persisted to <code>unmatched_payroll.csv</code> for HR action.<br>- <strong>Column dedupe & ordering:</strong> When expanding staff fields into payroll rows, overlapping column names must be removed & staff fields renamed (e.g., <code>Nama_Staff</code>). Final column ordering is enforced to stabilize downstream mapping. Maintain <code>field_spec.json</code> describing column order and types to prevent accidental header reorder from breaking mapping.<br><br><strong>1.3 VBA artifacts observed and behavior (detailed):</strong><br>- <code>Worksheet_Activate</code> refreshes the query table anchored at A4 to provide instant refresh when the operator opens <code>BPMP_All</code>. This is convenient but can be problematic in large datasets; consider adding an explicit button for refresh and enforcing preflight checks before refresh completes.<br>- <code>Worksheet_Change</code> monitors a filter input cell (F2). When F2 changes it disables screen updating, events, and calculation to run an AdvancedFilter from the master table (assumed at A4 current region) into <code>ShBPMPTempData</code>. The macro clears a fixed range (A10:Q1002) and copies values and formats from B4:N4 to B10:N<nFinalRow>. This hard-coded copying may break when table widths change. Replace with dynamic column count detection. Also <code>On Error Resume Next</code> usage reduces observability of failure causes; change to structured error handlers that log errors to <code>run_log</code> and show a clear operator message.<br>- <code>CreateXMLFile</code> opens <code>Converter\BPMP Excel to XML v.3.xlsx</code>, writes staging values starting at B5 into sheet <code>DATA</code>, adjusts converter table rows, finds the XmlMap <code>MmPayrollBulk_Map</code>, and calls <code>SaveAsXMLData</code>. The macro currently hardcodes the year prefix to <code>2026</code>; replace with <code>PeriodYear</code> and <code>PeriodMonth</code> cells and validate. Also introduce <code>dryRun</code> to allow mapping checks without writing XML. The macro expects the Converter file to be present at a relative path; preflight must confirm the file exists and its checksum.<br>- <strong>Utility macros:</strong> <code>Delete_Names</code> removes worksheet-level names <code>CriteriaDatabase</code>, <code>Criteria</code>, <code>_FilterDatabase</code>, <code>Extract</code> created by AdvancedFilter. <code>DeleteNamedRangesWithREF</code> removes workbook-level names referencing <code>#REF!</code>. <code>BreakLinks</code> removes external Excel links. These utilities are useful but dangerous if run indiscriminately; scope them to dry-run preflight checks and require operator confirmation for destructive removal. Add safeguards to restrict deletion to names associated with a specific worksheet or to log removed names to <code>run_log</code> for audit traceability. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>2 — Naming, artifact & storage conventions (operational standard, expanded)</strong><br><strong>Canonical folder layout (operational standard):</strong> The workspace layout standardizes artifact placement and lifecycle. Enforce a machine-readable structure: <code>/workspace/{YYYY}/{KPP}/{period}/{operator_ts}/</code> where <code>period</code> is YYYYMM and <code>operator_ts</code> is <code>YYYYMMDD_HHMMSS</code> to ensure uniqueness. Each run folder must include mandatory subfolders: <code>/raw/</code> (ingested source files), <code>/validation/</code> (PQ diagnostics, validation_report, conversion_errors), <code>/normalizer/</code> (normalizer_preview and change_ledger extracts), <code>/calc_logs/</code> (per-row calculation traces), <code>/xml_canonical/</code>, <code>/xml_pretty/</code>, <code>/bundles/</code>, <code>/archive/</code>, <code>/logs/</code>, <code>/Converter/</code> (copied converter used for the run), and <code>/upload_evidence/</code> (staging and production upload receipts). Operational rules: create these folders at run start via macro or CLI helper; do not allow export unless required folders exist and are writable; log folder creation in <code>preflight_report.json</code> and <code>run_log</code>.<br><br><strong>Naming rules (practical conventions):</strong> Filenames must be machine-parseable and stable for automation. Recommended patterns and rationale:<br>- <code>raw_export_{source}_{period}_{YYYYMMDD_HHMMSS}.xlsx</code> — source snapshots used for diagnostics. Keep original provider filename in metadata but use ASCII machine name for storage.<br>- <code>export_metadata_{period}_{ts}.json</code> — includes <code>source_file</code>, <code>sha256</code>, <code>extracted_by</code>, <code>extraction_ts</code>, and source system id.<br>- <code>pq_diagnostics_{period}_{ts}.csv</code> — PQ discovery & load diagnostics used by operator to triage listings.<br>- <code>validation_report_{period}_{ts}.csv</code> — flattened row-level validation outputs keyed by <code>row_hash</code> and <code>source</code>.<br>- <code>normalizer_preview_{period}_{ts}.csv</code> — suggested deterministic fixes prior to auto-application.<br>- <code>change_ledger_{period}.csv</code> — append-only ledger listing each deterministic change applied with <code>row_hash</code>, <code>field</code>, <code>before</code>, <code>after</code>, <code>rule_id</code>, <code>applied_ts</code>, <code>applied_by</code> (system or operator), and <code>justification</code>. Ledger must be digitally signed daily.<br>- <code>xml_canonical/BPMP_{YYYYMM}_YJKN_canonical.xml</code> and <code>.sha256</code> — canonical artifact and its checksum.<br>- <code>acceptance_bundle_{kpp}_{period}_{YYYYMMDD_HHMMSS}.zip</code> and <code>.sha256</code> — acceptance bundle and its checksum for upload.<br>- <code>manifest.json</code> — machine-readable manifest included in every bundle and archived.<br>- <code>run_log_{run_id}.json</code> — structured run log for forensic triage, containing phase timings and warnings.<br>Rules: avoid spaces and special characters; use lower-case where possible for portability across filesystems; include <code>operator_id</code> and <code>run_id</code> in manifest and run logs for audit linkage.<br><br><strong>Manifest schema (operational recommendation, expanded):</strong> <code>manifest.json</code> must be JSON Schema v7-compliant and include at minimum:<br>- <code>bundle_id</code> (UUID v4), <code>bundle_sha256</code> (hex), <code>period</code> (YYYYMM), <code>kpp</code> (organization code), <code>generated_by</code> (operator id), <code>generated_ts</code> (ISO8601 UTC), <code>run_id</code> (UUID), <code>converter_sha256</code> (hex), <code>converter_version</code> (string), <code>mapping_version</code> (string), <code>files</code> (array), <code>signoffs</code> (array), <code>regression_checks</code> (pass/fail), <code>xsd_summary</code> (object), <code>staging_parse_summary</code> (object), <code>production_upload_response</code> (object or null), <code>notes</code> (string).<br>Each <code>files</code> entry must include <code>{ path, sha256, size_bytes, description, role }</code>. Each <code>signoff</code> must include <code>{ role, approver_id, sso_event_id, ts, comment, evidence_path }</code>. Validate the manifest against <code>manifest.schema.json</code> programmatically before allowing <code>signed</code> status in bundle registry. Keep manifest in both JSON and an optionally-signed binary form when signing keys are available. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>3 — Power Query pipeline: functional & hardening (comprehensive)</strong><br><strong>Design goals for PQ (detailed):</strong> PQ must be a deterministic extract-transform-validate layer producing both primary output (<code>BPMP_All</code>) and diagnostic artifacts (<code>pq_diagnostics</code>, <code>conversion_errors</code>, <code>unmatched_payroll</code>, <code>change_ledger</code>). Goals: deterministic discovery of named ranges, strict schema enforcement, non-destructive normalizer preview, append-only change ledger export, and clear diagnostics for all failures. PQ must never silently drop rows without producing an auditable <code>left_anti</code> record. PQ must not alter raw columns in-place without recording original <code>*_raw</code> fields.<br><br><strong>Implementation patterns (recommended, high detail):</strong><br>- <strong>Parameterize discovery:</strong> Use a parameter table <code>Params[PayrollRanges]</code> with columns <code>expected_name</code>, <code>enabled</code>, <code>source_type</code> and <code>priority</code>. PQ reads this table at runtime and attempts to load each <code>expected_name</code>. Missing entries are logged into <code>pq_diagnostics</code>. This approach avoids hard-coded range lists and allows adding ad-hoc ranges without modifying PQ code.<br>- <strong>Diagnostics-first wrapper:</strong> For each <code>expected_name</code> do a <code>try ... otherwise</code> wrapper that returns <code>{ loaded_table, diag_record }</code>. <code>diag_record</code> must include <code>name</code>, <code>found</code> boolean, <code>row_count</code>, <code>col_count</code>, <code>headers_sample</code> (first N headers), <code>error</code> (null or message). Aggregate diag_records into <code>pq_diagnostics</code> and write to CSV at end of PQ refresh via <code>Table.Export</code> patterns or by exposing to Excel and invoking a macro to persist them to the run folder.<br>- <strong>Header synonyms mapping:</strong> Maintain <code>header_synonyms</code> table mapping common header variants to canonical column names. Apply mapping during load: map header if exact match else attempt fuzzy normalization (trim, lower, collapse whitespace, strip punctuation) and consult synonyms. Any header not mapped is recorded as <code>ERR-HEADER-DRIFT</code> in diagnostics, causing operator attention.<br>- <strong>Schema enforcement & typed casting:</strong> Define <code>expected_schema</code> table listing canonical columns with expected data type, required flag, and tolerated nulls. After combining payroll ranges, run <code>Table.TransformColumnTypes</code> on the combined table. Use <code>try ... otherwise</code> to capture type-conversion failures. For each failed conversion emit a <code>conversion_errors</code> row with <code>row_id</code>, <code>column</code>, <code>original_value</code>, <code>attempted_type</code>, <code>error_message</code>. For required columns failing conversion, mark run as <code>CRITICAL</code> and block export until fixed.<br>- <strong>Normalization & change ledger:</strong> Normalization must be deterministic and auditable. Implement normalizers as pure functions (e.g., <code>normalize_npwp</code>, <code>currency_to_integer</code>, <code>normalize_date</code>) that return both <code>normalized_value</code> and a <code>change_record</code> when <code>normalized_value</code> differs. Accumulate change_records into <code>change_ledger</code> with <code>rule_id</code>, <code>rule_description</code>, <code>confidence</code>, <code>applied_by</code> (<code>system</code> for PQ auto-fix or <code>operator</code> for manual), and timestamp. Do not apply auto-fixes unless mapping owner policy grants permission for specific rule_ids; instead create <code>normalizer_preview</code> for operator acceptance when rules are not auto-approved.<br>- <strong>Robust join strategy:</strong> Attempt joins in order: (<code>EmployeeID</code> -> <code>NPWP</code> exact -> <code>NPWP + DOB</code> -> <code>NPWP fuzzy</code> -> <code>NamaKey</code> with robustness scoring). For each attempted join produce <code>match_summary</code> listing <code>attempted_key</code>, <code>matched_count</code>, <code>left_anti_count</code>, <code>right_anti_count</code>, and <code>sample_mismatches</code>. Prioritize <code>EmployeeID</code> and <code>NPWP</code> exact matches for automated assignment; require manual recon for any name-only match below a confidence threshold. Export left_anti as <code>unmatched_payroll.csv</code> with augmented context and suggested candidate staff matches using phonetic similarity or token overlap ranking.<br>- <strong>Field spec export:</strong> Export <code>field_spec.json</code> documenting final column names, types, required flag, length limits, and transformation notes. Mapping owners use <code>field_spec.json</code> for mapping.csv alignment and regression testing.<br><br><strong>3.1 Failure modes & concrete mitigations (examples):</strong><br>- <strong>Missing named ranges:</strong> Detection: <code>pq_diagnostics</code> shows found=false for expected names. Mitigation: operator recreates named range or updates <code>Params[PayrollRanges]</code>. PQ should provide an auto-recreate helper that, when the underlying sheet contains a table with expected columns, can register a named range automatically but only after operator confirmation recorded in <code>run_log</code>.<br>- <strong>Header drift:</strong> Detection: <code>ERR-HEADER-DRIFT</code> entries in diagnostics. Mitigation: <code>header_synonyms</code> updated with mapping; require mapping owner signoff for new synonyms. For urgent runs, operators may accept mapped synonyms with singed approval recorded in <code>run_log</code> then include mapping change as a tracked manifest change for mapping owners to formalize in the next release.<br>- <strong>Name-only join misassignment:</strong> Detection: low <code>match_confidence</code> score, manual review shows multiple similar candidate names. Mitigation: require manual reconciliation UI (spreadsheet or lightweight userform) where operator chooses accepted mapping; applied change recorded to <code>change_ledger</code> with <code>approver</code> SSO id and <code>evidence_path</code> (screenshot or note). If frequent, prioritize adding <code>EmployeeID</code> or NPWP into payroll source ingestion contract.<br>- <strong>Numeric parse errors:</strong> Detection: <code>conversion_errors</code> shows many rows with locale-specific separators or stray characters. Mitigation: implement <code>currency_to_integer</code> that infers pattern (e.g., presence of commas and decimals) and normalizes; if heuristics cannot decide, mark as <code>ERR-NUM-002</code> and block export for critical columns.<br><br><strong>3.2 Hardening tasks & code hints (non-snippet guidance):</strong><br>- Replace hard-coded <code>Payroll_Data_01..11</code> with a parameter table and a dynamic loader. Add a <code>MaxRows</code> parameter to limit PQ memory consumption for enormous inputs.<br>- Export <code>pq_diagnostics</code> and <code>conversion_errors</code> as CSVs to the run <code>validation</code> folder on every PQ refresh. Add <code>diagnostics_version</code> and <code>pq_version</code> metadata in each file to correlate across runs.<br>- Fail fast when required columns are missing and produce <code>CheckRequiredColumns</code> diagnostics enumerating each missing column and expected type. Mark run as <code>CRITICAL</code> if any required column is missing.<br>- Implement <code>normalizer_preview</code> CSV with grouped suggested fixes and allow operators to generate a sign-off or accept-and-apply action; when applied, append to <code>change_ledger</code> and record signoff evidence (SSO event id) in <code>run_log</code>/manifest.<br>- Create <code>unmatched_payroll.csv</code> and <code>unmatched_staff.csv</code> containing full row context and suggested candidate matches. Provide an operator triage checklist to resolve these in HR or to accept a temporary override recorded in <code>run_log</code>. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>4 — VBA automation: hardening, refactor patterns & controls (expanded)</strong><br><strong>Objectives (expanded):</strong> The VBA layer coordinates user interactions and the final export. Hardening objectives: deterministic exports, explicit error handling and informative run logs, manifest and SHA256 production, concurrency locks preventing simultaneous exports, dry-run capability, atomic file writes, and per-run audit logs enabling post-mortem analysis. Preserve stable public subroutine names to avoid breaking user buttons; implement modern structured internals. Provide a <code>Config</code> module for paths, thresholds, and TTL values so behavior is configurable without code edits.<br><br><strong>4.A Structured error handling and logging (detailed):</strong><br>- Remove <code>On Error Resume Next</code> unless absolutely necessary and localize <code>On Error GoTo ErrHandler</code> to each public procedure. Create central <code>ErrHandler</code> pattern that logs a structured error record with fields: <code>err_number</code>, <code>err_description</code>, <code>procedure</code>, <code>module</code>, <code>stack_trace</code> (if possible), <code>operator_id</code>, <code>workbook_path</code>, <code>run_id</code>, and <code>ts</code>. Append to <code>logs</code> sheet and flush to disk as <code>run_log_{run_id}.json</code>. Surface only a single operator-facing message with <code>run_id</code> and <code>run_log</code> path. Avoid message boxes that require many clicks; use one well-formed modal summarizing next steps.<br>- Implement <code>LogWarning</code> and <code>LogInfo</code> helpers for non-fatal diagnostic additions to <code>run_log</code>. Keep warnings in <code>run_log</code> so auditors can see non-blocking items that nonetheless require attention.<br><br><strong>4.B Avoid hardcoded years and inputs:</strong><br>- Introduce a <code>Config</code> sheet or named cells for <code>PeriodYear</code>, <code>PeriodMonth</code>, <code>ConverterPath</code>, <code>RunFolderTemplate</code>, <code>LockTTLMinutes</code>, <code>OperatorIDCell</code>, and <code>RunIDCell</code>. Macros derive filename conventions from <code>PeriodYear</code> and <code>PeriodMonth</code>. Validate <code>PeriodMonth</code> in range 1..12 and <code>PeriodYear</code> within acceptable operational range (e.g., now-5 .. now+1). If <code>Period*</code> cells are blank, macro should refuse to run and instruct operator to fill them; if fallback is allowed, record fallback reason in <code>run_log</code> and require explicit override for production runs.<br><br><strong>4.C Preflight checks (executable checklist):</strong><br>- Implement <code>PreflightChecks()</code> returning a structured <code>preflight_report</code> object and writing <code>preflight_report.json</code>. Checks include: converter file presence and expected <code>converter_sha256</code> if provided; XmlMap existence inside converter workbook; <code>ShBPMPTempData</code> header present at A9 and at least one data row at A10; disk space check for available bytes greater than threshold; destination folder exists and writable; run folder creation success; <code>DeleteNamedRangesWithREF</code> dry-run shows zero or recorded names to be removed. If any <code>CRITICAL</code> check fails, abort and present <code>preflight_report.json</code> to operator. Persist <code>preflight_report</code> in <code>/validation/</code> folder.<br><br><strong>4.D Concurrency and locking (precise behavior):</strong><br>- Implement atomic locking at both workbook-level and filesystem-level. Workbook-level: create a workbook-scoped name <code>ExportInProgress</code> containing JSON <code>{ operator_id, run_id, ts, expiry_ts }</code> pointing to a harmless cell. File-level: create a <code>.lock</code> file in the run folder containing same metadata and acquire using atomic file create; if <code>.lock</code> already exists, read expiry and owner; if expired, allow takeover only after operator acknowledges takeover and records <code>takeover_reason</code> with SSO evidence. Locks must be cleared in <code>CleanUp</code> or via explicit <code>ForceClearLock</code> admin tool after verifying no concurrent process. Log lock events to <code>run_log</code> with <code>lock_acquired_ts</code>, <code>lock_released_ts</code>, and <code>owner</code>. TTL default 30 minutes, configurable via <code>Config</code>.<br><br><strong>4.E Manifest and canonicalization after export (detailed):</strong><br>- After <code>SaveAsXMLData</code> returns success, compute canonical XML bytes and SHA256. Prefer internal hashing API; fallback to spawning <code>certutil</code> or PowerShell with <code>Get-FileHash</code>. Record <code>xml_sha256</code> in <code>manifest.json</code> and <code>run_log</code>. Record <code>xml_size_bytes</code>, <code>row_count</code>, <code>converter_sha256</code>, <code>converter_version</code>, <code>mapping_version</code>, <code>operator_id</code>, <code>generated_ts</code>, <code>run_id</code>, and <code>machine_id</code>. Write <code>manifest.json</code> first to a temp file, compute its SHA256, then rename atomically to final path to prevent watchers from reading partial manifests. If signing keys are available, sign the manifest and persist a <code>manifest.sig</code> next to <code>manifest.json</code> and record signer metadata in <code>signoffs</code> array inside manifest.<br><br><strong>4.F Dry-run capability and atomic writes (procedural):</strong><br>- <code>CreateXMLFile(dryRun As Boolean)</code> must: (1) run preflight checks, (2) copy staging values to copied Converter <code>DATA</code> sheet, (3) run header mapping diff and mapping checks, (4) perform mapping preview and XSD smoke checks but skip <code>SaveAsXMLData</code> when <code>dryRun = True</code>. When real export is requested, write XML to temporary filename <code>BPMP_{YYYYMM}_YJKN.tmp.xml</code> and ensure the file closes properly before computing SHA256, then rename to final <code>BPMP_{YYYYMM}_YJKN.xml</code> atomically. Write <code>last_successful_export.txt</code> pointer to contain <code>run_id</code>, <code>xml_sha256</code>, <code>xml_size</code> and <code>generated_ts</code> for quick operator reference.<br><br><strong>4.G Run logging and searchability (spec):</strong><br>- <code>run_log_{run_id}.json</code> structure: <code>run_id</code>, <code>operator_id</code>, <code>period</code>, <code>run_folder</code>, <code>phases</code> (object with keys: <code>preflight</code>, <code>staging_copy</code>, <code>mapping_check</code>, <code>xml_export</code>, <code>postflight</code> each with <code>start_ts</code>, <code>end_ts</code>, <code>status</code>, <code>warnings</code>), <code>warnings</code>, <code>errors</code>, <code>artifact_paths</code> (map), <code>signoffs</code>, <code>lock_info</code>, <code>machine_id</code>, <code>notes</code>. Persist run logs to <code>/logs/</code> and also append a summary line to <code>logs</code> sheet in workbook. Provide small lookup UI or macro to filter <code>logs</code> sheet by date, operator, status, and run_id.<br><br><strong>4.H Mapping header checks and diffs (policy):</strong><br>- When the Converter <code>DATA</code> sheet is populated, compute <code>mapping_diff.csv</code> comparing Converter headers vs <code>mapping.csv</code>. Diff classification: <code>blocking</code> (missing required column, type mismatch), <code>warn</code> (optional column missing), <code>info</code> (extra column in converter). Block export for <code>blocking</code> items. For <code>warn</code> items require operator signoff captured in <code>run_log</code> with <code>sso_event_id</code>. Generate <code>mapping_preview</code> showing resolved mapping pairs and sample rows for each mapped column for operator review.<br><br><strong>4.1 Developer checklist for macro refactor (actionable):</strong><br>- Add <code>Option Explicit</code> to all modules.<br>- Create <code>Config</code> module and <code>Config</code> sheet exposing all runtime settings.<br>- Implement <code>ComputeFileSHA256(filepath)</code> with direct API usage if available; otherwise fallback to <code>certutil</code> or <code>powershell</code> command-line. Wrap OS calls in safe <code>WaitForExit</code> and capture return codes.<br>- Implement <code>ValidateStagingShape</code> to verify header position, column count, and required columns before mapping population.<br>- Replace ad-hoc clipboard usage with direct <code>.Value</code> assignments and <code>Range.Value = arr</code> operations to avoid user clipboard interference.<br>- Implement unit tests as documented: dry-run mapping checks, preflight failure scenarios, stale-lock takeover, run_log generation. Keep change log in <code>CHANGELOG.md</code> inside each run folder and reflect workbook version on a <code>Version</code> sheet. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>5 — Validation rules: exhaustive catalog, outputs & remediation (expanded)</strong><br><strong>Validation architecture (detailed):</strong> Validation split into five deterministic layers to simplify triage:<br>- <strong>Layer 1 — Schema validation:</strong> Ensure presence and type of required columns and data shape. Outputs <code>CheckRequiredColumns</code> and <code>field_spec.json</code> mismatches. Block on missing required columns.<br>- <strong>Layer 2 — Field validation:</strong> Per-field checks (NPWP format, numeric bounds, PTKP code validity). Outputs <code>validation_report</code> rows with field-level issues. Severity mapping applied at field rule level.<br>- <strong>Layer 3 — Cross-field validation:</strong> Inter-field consistency checks (component sums equal gross within tolerance, gross-up consistency). Produce <code>calc_qc_report.csv</code> with computed vs provided values and <code>calc_deltas</code> flagged beyond tolerance.<br>- <strong>Layer 4 — Cross-record validation:</strong> Checks across dataset (duplicate NPWP among active employees, employee with conflicting PTKP across months). Produce <code>cross_record_issues.csv</code> with candidate groups for HR investigation.<br>- <strong>Layer 5 — External validation:</strong> XSD validation of final XML, converter checksum verification, and pre/post-file hash checks. Block on critical XSD failures.<br><br><strong>Validation outputs (structured):</strong><br>- <code>validation_report.csv</code> — row-level records including <code>row_hash</code>, <code>source</code>, <code>row_number</code>, <code>nama_raw</code>, <code>nama_norm</code>, <code>npwp_raw</code>, <code>npwp_norm</code>, <code>gaji_raw</code>, <code>gaji_norm</code>, <code>jumlah_penghasilan_bruto</code>, <code>pph21_raw</code>, <code>pph21_norm</code>, <code>total_bpjstk</code>, <code>total_bpjskes</code>, and <code>issues_json</code> (array of issues). This file is the primary entry for triage teams.<br>- <code>validation_summary.json</code> — aggregated counts by <code>severity</code> and <code>issue_code</code>, and top offending columns by count and percent. Provide <code>human_summary</code> for operator quick action list.<br>- <code>conversion_errors.csv</code> — row-level capture of parse failures and raw values to help data engineers implement correct parsers at source stage.<br>- <code>error_heatmap.html</code> — pivoted heatmap visualization showing density of issues by source range and column for focused remediation activities.<br><br><strong>5.1 Representative rule catalog (fuller set):</strong><br>- <code>ERR-PRES-001</code> — Required field missing. Severity: Critical. Action: block export.<br>- <code>ERR-NUM-002</code> — Numeric parsing failed. Severity: Error. Auto-fix only allowed if deterministic pattern recognized and mapping owner approves; otherwise block.<br>- <code>ERR-NPWP-003</code> — NPWP normalization error (after strip non-digits length != 15). Severity: Error. Action: route to HR.<br>- <code>ERR-BPJS-004</code> — BPJS arithmetic mismatch beyond tolerance. Severity: Error/Warning depending on magnitude. Action: reconciliation and calc trace required.<br>- <code>WARN-GROSS-005</code> — Gross-up flag with no solver trace. Severity: Warning. Action: operator evidence required before signoff.<br>- <code>WARN-DUP-006</code> — Duplicate IDs across active records. Severity: Warning / Error based on business risk. Action: HR verification and possible freeze of conflicting records.<br>- <code>ERR-JOIN-007</code> — Payroll row failed staff join. Severity: Error. Action: emit <code>unmatched_payroll.csv</code> and route to HR.<br>- <code>ERR-RANGE-008</code> — Field length truncation risk when mapping to converter schema. Severity: Error. Action: mapping update or converter schema extension.<br>- <code>ERR-XML-009</code> — XSD validation failure. Severity: Critical. Action: block until mapping or data corrected and regression tests pass.<br><br><strong>5.2 Remediation policy by severity (operational):</strong><br>- <strong>Critical:</strong> Block pipeline, create automated ticket including first 200 example rows and <code>pq_diagnostics</code>, notify stakeholders, and require signoff to clear. No manual promotion allowed.<br>- <strong>Error:</strong> Require pre-bundle correction or approved auto-fix with <code>change_ledger</code> entries and operator signoff. If auto-fix applied, include <code>applied_rules</code> in manifest and require mapping owner review post-run.<br>- <strong>Warning:</strong> Allow bundling only after operator acknowledgment with signoff recorded in <code>run_log</code> including <code>sso_event_id</code> and explanation. Warnings must be reviewed in monthly QC cycles.<br>- <strong>Info:</strong> Record-only; included in <code>validation_summary.json</code> for trend analysis.<br><br><strong>5.3 Example row JSON structure (conceptual):</strong><br><code>{ &quot;row_hash&quot;: &quot;...&quot;, &quot;source&quot;: &quot;Payroll_Data_02&quot;, &quot;row_number&quot;: 24, &quot;nama_raw&quot;: &quot;...&quot;, &quot;nama_norm&quot;: &quot;...&quot;, &quot;npwp_raw&quot;: &quot;...&quot;, &quot;npwp_norm&quot;: &quot;...&quot;, &quot;gaji_raw&quot;: &quot;...&quot;, &quot;gaji_norm&quot;: 15000000, &quot;jumlah_penghasilan_bruto&quot;: 15200000, &quot;pph21_raw&quot;: &quot;...&quot;, &quot;pph21_norm&quot;: 200000, &quot;total_bpjstk&quot;: 50000, &quot;total_bpjskes&quot;: 60000, &quot;issues&quot;: [ { &quot;code&quot;:&quot;ERR-NUM-002&quot;, &quot;message&quot;:&quot;Failed to parse Gaji&quot;, &quot;severity&quot;:&quot;Error&quot;, &quot;suggested_fix&quot;:&quot;Remove &#x27;.&#x27; thousands separators or provide raw numeric&quot;, &quot;confidence&quot;:0.95 } ] }</code><br>Retain raw fields (<code>*_raw</code>) for audit and forensic replays; do not drop or overwrite original values. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>6 — Mapping & XML construction controls (expanded)</strong><br><strong>Mapping governance principles (detailed):</strong> Mapping from PQ output to XML nodes is the single most sensitive contract. All mapping definitions must be in <code>mapping.csv</code> under source control with strict versioning and change-control workflows. <code>mapping.csv</code> columns: <code>mapping_version</code>, <code>source_column</code>, <code>destination_xml_node</code>, <code>required</code>(Y/N), <code>type</code>, <code>transform_functions</code>, <code>max_length</code>, <code>notes</code>, <code>author</code>, <code>approved_by</code>, <code>approved_ts</code>. Every mapping change must include test cases and pass golden-file regression before promotion. Maintain <code>mapping_history.csv</code> recording delta between mapping versions and link mapping_version to each run's manifest.<br><br><strong>Transform functions (policy):</strong> All transforms must be deterministic, pure, and unit-tested. Document each transform (name, purpose, input-type, output-type, edge behavior). Allowed transforms examples (names only): <code>normalize_digits</code>, <code>pad_left(15)</code>, <code>currency_to_integer</code>, <code>normalize_date_yyyymmdd</code>, <code>if_empty(default)</code>, <code>concatenate(fields,separator)</code>, <code>npwp_strip_punctuation</code>, <code>name_tokenize_sort</code>, <code>trim_and_collapse_whitespace</code>. Prohibited transforms: those that call external web services at runtime (unless cached and recorded in manifest) or non-deterministic transforms without recorded seed. Transforms requiring external data (e.g., currency rates) must include source and effective timestamp in manifest.<br><br><strong>XmlMap & Converter governance (contractual):</strong> The Converter workbook is a versioned contract with authoritative XmlMap <code>MmPayrollBulk_Map</code>. Operational requirements:<br>- Store approved converter versions in <code>/Converter/archive/</code> with versioned filenames (e.g., <code>BPMP Excel to XML v.3.0.1.xlsx</code>).<br>- For each run copy the approved converter into the run's <code>/Converter/</code> folder and compute <code>converter_sha256</code> saved to manifest.<br>- For mapping changes, mapping owner provides mapping testcases; golden regression suite validates that Converter outputs unchanged XML for reference inputs unless intentional mapping change. Dual approval required for mapping changes affecting node names, multiplicity, or attribute semantics.<br><br><strong>XML production & canonicalization:</strong> Produce two XML artifacts: <code>xml_pretty</code> (formatted for human review, optionally indented) and <code>xml_canonical</code> (deterministic canonicalization to compute <code>xml_sha256</code>). Canonicalization rules: exclusive canonicalization without comments, deterministic namespace declaration ordering, and sorted attributes where permitted by mapping rules. Document canonicalization algorithm in <code>canonicalization_spec.txt</code> and include in run folder. Compute and store <code>xml_canonical.sha256</code> and include in <code>manifest.json</code> and <code>bundle</code> checksums.<br><br><strong>XSD & XPath smoke checks:</strong> Prior to pushing to acceptance bundle run XSD validation (MSXML or <code>xmllint</code>) and produce <code>xsd_errors.log</code> and <code>xsd_summary.json</code>. For critical XSD failures block bundle creation. Additionally run XPath smoke checks for expected sample nodes (e.g., sample NPWP present, total employee count matches expected) and include <code>smoke_check.json</code> results in the bundle. Smoke checks are simple assertions to catch mapping regressions that slip past XSD (which may be permissive). </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>7 — Bundle assembly, signoff & upload (gate-driven blueprint, full)</strong><br><strong>Gate model (expanded):</strong> The process is strictly gate-driven; each gate requires artifacts and approvals. Gate sequence and required artifacts:<br>- <strong>Gate 1 — Export & Freeze:</strong> Place raw exports in <code>/raw/</code>, compute <code>sha256_raw</code>, and record <code>export_metadata.json</code>. If row count > threshold, chunking required; chunk metadata recorded in <code>export_metadata</code>.<br>- <strong>Gate 2 — Validator:</strong> Run PQ & validation layers, produce <code>validation_report.csv</code>, <code>validation_summary.json</code>. Critical items auto-open tickets and block progress. <code>pq_diagnostics</code> and <code>conversion_errors</code> must be attached to ticket if present.<br>- <strong>Gate 3 — Normalization:</strong> Apply auto-fixes only for approved rules; produce <code>normalizer_preview.csv</code> before any auto-application. All changes appended to <code>change_ledger.csv</code>. Manual fixes require ticket and HR signoff with SSO evidence in <code>signoffs</code> array.<br>- <strong>Gate 4 — Reconciliation & QC:</strong> Execute calculation engine dry-run and export <code>calc_qc_report.csv</code>. Sampling rules: default 1% random sampling and top 1% variance sampling. Attach <code>calc_qc_evidence</code> (spreadsheet comparisons, signed notes) to run folder.<br>- <strong>Gate 5 — Mapping & XML:</strong> Apply mapping to produce <code>xml_canonical</code> and run <code>xsd</code> and <code>xpath</code> smoke checks. Produce <code>mapping_diff.csv</code>. Block on <code>blocking</code> diffs.<br>- <strong>Gate 6 — Acceptance Bundle:</strong> Assemble zip containing <code>xml_canonical</code>, <code>validation_report.csv</code>, <code>change_ledger.csv</code>, <code>manifest.json</code>, <code>run_log.json</code>, converter copy, <code>xsd_summary.json</code>, and signoffs. Compute <code>bundle_sha256</code>. Require sequential signoffs recorded in manifest: HR → Payroll → Tax. Each signoff must capture <code>signer_id</code>, <code>sso_event_id</code>, timestamp, and a short comment.<br>- <strong>Gate 7 — Staging Upload & Smoke:</strong> Upload signed bundle to staging API. Capture <code>staging_parse_summary.json</code>. Perform smoke checks and record <code>staging_evidence</code> including screenshots or API parse logs. If staging errors, create ticket and follow incident playbook.<br>- <strong>Gate 8 — Production & Amendment:</strong> Upload signed bundle to production endpoint with idempotency token. Save <code>upload_response.json</code>. On production parse errors, generate <code>amend_bundle</code> and repeat gates with required approvals.<br><br><strong>7.1 Manifest policy & registry (operational):</strong> Maintain <code>bundle_registry.csv</code> with <code>bundle_id</code>, <code>period</code>, <code>kpp</code>, <code>bundle_sha256</code>, <code>status</code>, <code>run_folder</code>, <code>archived_path</code>. Status flow: <code>draft</code> -> <code>validation_passed</code> -> <code>normalized</code> -> <code>qc_passed</code> -> <code>mapping_applied</code> -> <code>bundle_ready</code> -> <code>signed</code> -> <code>uploaded</code> -> <code>archived</code>. Enforce manifest validation against <code>manifest.schema.json</code> prior to signoff. Keep an index view in workbook <code>Bundle Registry</code> with filters for <code>status</code>, <code>period</code>, and <code>operator</code>. Archive signed bundle and manifest in immutable storage (WORM or object storage with immutability policy). </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>8 — Immutability, archival & audit pack generation (procedures & retention)</strong><br><strong>Archival policy (operational):</strong> After production upload, copy acceptance bundle to immutable storage (WORM or object store with immutability). Retention minimum 5 years, recommended 10 years. Record <code>archive_index.csv</code> entries with <code>bundle_id</code>, <code>archive_path</code>, <code>bundle_sha256</code>, <code>archived_ts</code>, <code>retention_until</code>, and <code>archived_by</code>. Maintain a secondary manifest copy in a secure vault and store manifest SHA in KMS/HSM ledger for long-term verification.<br><br><strong>Audit pack generation (procedural):</strong> Provide <code>audit_pack_generator</code> utility that accepts <code>bundle_id</code> or <code>employee_id</code> and produces encrypted zip containing: <code>calc_log_{record_id}.json</code>, <code>xml_canonical/{employee_id}.xml</code>, payslip (subject to policy), <code>signoff_receipts</code>, <code>manifest.txt</code>, <code>change_ledger</code> extracts relevant to the requested record. Each pack must include <code>pack_manifest.txt</code> listing per-file SHA256 checksums. Delivery via pre-signed time-limited URL with event recorded in <code>audit_pack_access_log.csv</code> capturing who generated pack, reason, and timestamp. Keep logs of pack access and require approval for packs including sensitive employee data.<br><br><strong>Integrity controls & periodic tests:</strong> Implement daily digest process computing digest over <code>change_ledger.csv</code> and <code>bundle_registry.csv</code> and sign digest with HSM/KMS producing <code>digest_{date}.sig</code>. Retain daily digests online for 90 days and archive older digests. Quarterly restore test: randomly select archived bundle, restore it, re-run PQ+mapping to reproduce <code>xml_canonical</code>, compute hashes and compare with archived <code>xml_sha256</code>. Record <code>restore_test_log.csv</code> and remediate any discrepancies. For critical integrity deviations escalate to IT security and audit teams. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>9 — Operator runbook (preflight + step-by-step execution, actionable)</strong><br><strong>Pre-flight checks (operator checklist):</strong><br>1. Confirm SSO authentication, role <code>Payroll Operator</code>, and MFA active. Record <code>operator_id</code> to clipboard for signing steps.<br>2. Create run folder under <code>/workspace/{YYYY}/{KPP}/{period}/{operator_ts}/</code>. Verify correct period and KPP; record run folder path in <code>Operator Notes</code> and <code>run_log</code>.<br>3. Copy raw export to <code>/raw/</code> and compute <code>sha256_raw</code>; save <code>export_metadata_{ts}.json</code> with extraction timestamp and system id.<br>4. Verify converter copy exists and compute <code>converter_sha256</code>. If missing, restore from <code>/Converter/archive/</code> and validate checksum before proceeding.<br>5. Open workbook, navigate to <code>BPMP_All</code> to trigger PQ refresh. Check <code>pq_diagnostics.csv</code> in <code>/validation/</code>. If <code>CRITICAL</code> items present, resolve before proceeding. Document all preflight steps in <code>preflight_report.json</code>.<br><br><strong>Execution steps (operator):</strong><br>1. Resolve <code>CRITICAL</code> findings from PQ diagnostics. If only <code>WARN</code> items exist, document acknowledgment in <code>run_log</code> with signoff evidence.<br>2. Set <code>PeriodYear</code> and <code>PeriodMonth</code> on <code>Config</code> sheet and validate via <code>ValidatePeriod</code> macro; record <code>period</code> in <code>run_log</code>.<br>3. If filter run required, set filter cell <code>F2</code> and press Enter; confirm <code>ShBPMPTempData</code> shows headers at A9 and data at A10 onward. Validate row count and sample rows to ensure staging not truncated.<br>4. Run <code>DeleteNamedRangesWithREF</code> only if preflight shows stale names; log action and names removed in <code>run_log</code> and attach ticket if removal was automated.<br>5. Run <code>CreateXMLFile(dryRun=True)</code> to populate Converter <code>DATA</code> sheet and create <code>mapping_diff.csv</code> and <code>xsd_summary.json</code>. Review diffs; if non-blocking, record signoff in <code>run_log</code>; if blocking, escalate to mapping owner.<br>6. After dry-run signoffs, run <code>CreateXMLFile(dryRun=False)</code> to produce canonical XML. Upon success validate <code>xml_sha256</code> matches computed file hash, save <code>manifest.json</code>, and record signoff entries in manifest signoffs array.<br>7. Build acceptance bundle in <code>/bundles/</code> and compute <code>bundle_sha256</code>. Add required artifacts and <code>signature</code> if available. Save <code>bundle_{id}.zip.sha256</code>.<br>8. Upload to staging endpoint; capture <code>staging_parse_summary.json</code> and <code>staging_evidence</code>. If staging shows parse errors, attach <code>staging_parse_summary.json</code> and earliest 200 failing rows to ticket and follow incident playbook.<br>9. Conduct smoke tests on representative records (low, median, high components). Capture <code>smoke_checks_{run_id}.json</code> and screenshots. Confirm parity with <code>calc_logs</code>.<br>10. Once HR, Payroll, and Tax signoffs recorded in manifest, upload to production with idempotency token. Capture <code>upload_response.json</code> and move acceptance bundle to <code>/archive/</code>. Update <code>bundle_registry.csv</code>. Update <code>last_successful_export.txt</code> with <code>run_id</code> and <code>manifest_sha256</code> for quick operator reference.<br><br><strong>Operator notes (operational rules):</strong> Never reuse run folders. Avoid manual edits to converter copies inside run folder; mapping changes must be performed by mapping owner under versioned change control. Keep run logs concise but thorough—auditors rely on logs to reconstruct decisions. Always attach <code>pq_diagnostics</code> and <code>validation_report</code> to tickets opened for remediation. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>10 — Troubleshooting: incidents, diagnostics & remediation playbooks (expanded)</strong><br><strong>No named ranges found (PQ discovery failure):</strong><br>- <strong>Symptoms:</strong> Combined table empty or PQ returns an error during combine step.<br>- <strong>Diagnostics:</strong> <code>pq_diagnostics</code> indicates expected names missing. Check <code>Params[PayrollRanges]</code> for mismatched names or disabled flags. Inspect Excel Name Manager for missing/renamed ranges.<br>- <strong>Remediation:</strong> Recreate named range by creating an Excel Table over source data and assign expected name, or update <code>Params[PayrollRanges]</code>. Re-run PQ and verify diagnostics. Log remediation steps and time in <code>run_log</code> and attach screenshots if manual fix required.<br><br><strong>Join returns no staff matches:</strong><br>- <strong>Symptoms:</strong> large <code>left_anti</code> counts after join.<br>- <strong>Diagnostics:</strong> <code>unmatched_payroll.csv</code>, <code>normalizer_preview.csv</code> provide context and candidate transforms.<br>- <strong>Remediation:</strong> escalate to HR to provide NPWP or EmployeeID mapping; for small volumes use operator reconciliation UI to accept matches; record acceptance in <code>change_ledger</code> and sign in manifest. For systemic issues, update <code>header_synonyms</code> or coordinate upstream provider to include stable keys.<br><br><strong>CreateXMLFile fails — Converter missing or XmlMap not found:</strong><br>- <strong>Symptoms:</strong> macro error when opening converter or <code>xmlMap</code> is Nothing.<br>- <strong>Diagnostics:</strong> <code>preflight_report.json</code> shows converter check failure; <code>CreateXMLFile</code> exits to error handler with descriptive error logged.<br>- <strong>Remediation:</strong> Restore converter from <code>/Converter/archive/</code> ensuring <code>converter_sha256</code> matches. If converter changed intentionally, mapping owner must provide mapping acceptance and new <code>converter_version</code> and update <code>manifest</code>. If XmlMap missing inside converter, revert to previous converter or re-attach XmlMap under mapping governance and re-run preflight checks. Log all changes and approvals.<br><br><strong>XSD errors or XML counts mismatch manifest:</strong><br>- <strong>Symptoms:</strong> XSD validation fails or XML node counts do not match staging row counts.<br>- <strong>Diagnostics:</strong> Compare <code>ShBPMPTempData</code> row_count to XML node count (via <code>xml_node_count</code>). Check for trailing blank rows or unexpected header rows affecting staging. Review <code>xsd_errors.log</code> for schema-specific failures.<br>- <strong>Remediation:</strong> Rebuild staging, correct mapping diffs, or adjust converter mapping under change control. If concurrency suspected, verify lock state and <code>run_log</code> timestamps to ensure single-run semantics. For ambiguous failures, escalate to integration/IT with <code>run_id</code> and <code>run_log</code> attached for forensic analysis. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>11 — Tests & UAT checklist (TCs + regression automation)</strong><br><strong>Core UAT test cases (operational):</strong><br>- <strong>TC-01 — Happy path:</strong> 1–10 sample rows with correct NPWP, EmployeeID, and gross components. Expect PQ combines ranges, <code>validation_summary</code> shows CRITICAL=0, mapping applied, XML created, staging parse passes, bundle archived and <code>upload_response.json</code> success. Pass condition: <code>xml_sha256</code> recorded and signoffs present.<br>- <strong>TC-02 — Missing payroll range:</strong> Remove expected named range. Expect PQ diagnostics indicate missing range and pipeline blocks. Pass condition: operator receives clear instruction and cannot progress to mapping without resolution.<br>- <strong>TC-03 — NPWP normalization:</strong> Provide NPWP with punctuation. Expect PQ normalizes to 15-digit string; <code>change_ledger</code> records normalization; validation shows no error. Pass: normalization recorded and auditable.<br>- <strong>TC-04 — Converter XmlMap change:</strong> Simulate changed XmlMap in converter. Expect preflight detects <code>converter_sha256</code> mismatch and blocks or requires dual approval. Pass: mapping promotion workflow triggered and enforced blocking.<br>- <strong>TC-05 — Gross-up handling:</strong> Include a record with <code>Gross Up</code> flag and solver traces. Expect <code>calc_logs</code> hold solver trace detail and validation confirms totals within 1 IDR tolerance. Pass: solver trace accepted and recorded.<br><br><strong>Regression automation (strategy):</strong> Nightly <code>golden_regression_runner</code> executes 30+ scenarios including edge cases (name collisions, NPWP edge lengths, currency formats, chunking, large row counts). Each run produces <code>regression_dashboard.html</code> summarizing pass/fail and sample artifacts with direct links. Failures create PR-blocking tickets and notify the team. Maintain stable <code>golden</code> dataset and expected outputs for regression verification. Regression runs must be reproducible and include mapping version used. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>12 — Governance, security, retention & evidence (expanded)</strong><br><strong>RBAC & access control (practical):</strong> Apply least privilege for run folders and converter copies. Define roles: <code>Payroll Operator</code> (execute runs and dry runs), <code>Mapping Owner</code> (edit mapping and approve mapping changes), <code>IT/Integrator</code> (maintain converter and run automation), <code>Auditor</code> (read-only access to runs). Enforce group ACLs on run folders and object storage. Maintain SSO with MFA and capture <code>sso_event_id</code> for each signoff entry. Audit logs must include <code>who</code>, <code>when</code>, <code>what</code> for each manual action affecting mapping or exports.<br><br><strong>Signing, HSM and manifest custody (policy):</strong> Prefer HSM/KMS signing for manifests and daily digests. If HSM not available, apply a documented dual-approval signoff recorded in manifest with <code>approver_id</code> and <code>sso_event_id</code>. Store signed manifests in immutable object store. Keep key custody records and rotate signing keys per policy. For high-integrity runs require manifest signature before production upload. Record signature metadata (key id, signer id, signature timestamp) in manifest.<br><br><strong>Retention lifecycle & restore tests:</strong> Minimum retention is 5 years; recommended 10. Lifecycle: active workspace for 2 years; cold storage for year 3–7; long-term archive for years 8–10+. Quarterly restore tests shall randomly select an archived bundle, restore it, and reproduce canonical XML using archived PQ artifacts and mapping. Record restore test results in <code>restore_test_log.csv</code> with pass/fail and remediation steps. Any integrity failure triggers immediate investigation and a remediation plan recorded in <code>run_log</code> and <code>archive_incident_log.csv</code>.<br><br><strong>Audit evidence & change control:</strong> All manual changes require <code>approval_id</code> (SSO event), ticket id, and must be logged in <code>change_ledger</code> and <code>run_log</code>. Provide auditors with <code>audit_pack</code> generator to assemble per-employee evidence for a given <code>bundle_id</code> or <code>employee_id</code>. <code>change_ledger</code> is append-only and digest-signed daily. Bundle registry must contain full signoff chain and <code>run_log</code> attachments for each bundle. Provide auditors read-only access to archive and timely exports on request. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>13 — Immediate recommended improvements (phase plan, prioritized)</strong><br><strong>Phase 0 (Days 0–7) — Fast wins:</strong><br>- Implement <code>pq_diagnostics</code> export capturing discovery state for named ranges and header mismatches.<br>- Add typed casting on critical numeric fields and export <code>conversion_errors.csv</code> for data engineering fixes.<br>- Produce <code>normalizer_preview.csv</code> to allow operator review of proposed deterministic fixes prior to auto-application.<br>- Implement <code>CreateXMLFile</code> dry-run and ensure <code>preflight_report.json</code> exists to prevent destructive runs.<br><br><strong>Phase 1 (Days 8–30) — Core hardening:</strong><br>- Refactor VBA for structured error handling and atomic writes.<br>- Implement <code>PreflightChecks()</code> and <code>ExportInProgress</code> locking.<br>- Add manifest generation and <code>run_log</code> outputs with structured JSON.<br>- Provide <code>manifest.schema.json</code> and incorporate manifest validation as a pipeline gate.<br>- Integrate a minimal auto-ticketing mechanism for <code>CRITICAL</code> validation failures to auto-create helpdesk tickets with attachments for triage.<br><br><strong>Phase 2 (Days 31–90) — Mapping & regression:</strong><br>- Establish mapping version control and golden-file regression testing.<br>- Build automated mapping promotion workflow with dual approvals tracked in manifests.<br>- Create interactive dashboards and <code>error_heatmap.html</code> for QC teams.<br>- Implement nightly regression jobs, integrate alerts in monitoring (Slack/Teams/email), and require PR-blocking behavior for regression fails affecting mapping outputs.<br><br><strong>Phase 3 (Months 3–12) — Platformization & scale:</strong><br>- Migrate heavy validation/calculation logic to a backend service (containerized, testable, CI-run).<br>- Integrate ticketing for <code>CRITICAL</code> issues to auto-create and route tickets and notify stakeholders.<br>- Integrate HSM/KMS signing into CI pipeline for mapping and converter changes.<br>- Evaluate replacing the ad-hoc Converter with a supported mapping engine for greater stability and improved XSD handling. </td></tr><tr><td data-label="BPMP XML Converter with Power Query &amp; VBA - User Guide"> <strong>14 — Deliverables available now and next steps (options A–E)</strong><br>Available immediate artifacts that can be produced inline on request:<br>- <strong>A)</strong> This entire document in single-column copyable Markdown table (complete).<br>- <strong>B)</strong> <code>mapping.csv</code> template tailored to final PQ <code>#Final</code> columns; includes transform hints and required flags for each target node and mapping owner fields for approval. Template will be delivered as plain-text CSV schema (no code) and instructions for mapping owners.<br>- <strong>C)</strong> Power Query M pseudo-spec describing steps to generate <code>validation_report.csv</code> and <code>conversion_errors.csv</code> including diagnostics functions and recommended column casts and error-handling strategies; the spec will not include executable M code but will be prescriptive in function behavior and expected outputs.<br>- <strong>D)</strong> Hardened <code>CreateXMLFile</code> macro algorithmic specification and developer change list (non-code), covering each function to implement, required logs, preflight checks, manifest creation and signing workflows. This includes exact JSON fields for <code>run_log</code> and <code>manifest</code> as data models for developers to implement.<br>- <strong>E)</strong> Power Query diagnostics design (functions and outputs) describing discovery, diagnostics, schema enforcement, and change ledger emission. The design includes sample diagnostic record formats and mapping to required output files.<br><br>Select any combination of B, C, D, E to produce now and those assets will be generated inline as plain-text artifacts. </td></tr></tbody></table></div><div class="row-count">Rows: 15</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>