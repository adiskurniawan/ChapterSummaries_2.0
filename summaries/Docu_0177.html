<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771304655">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0177_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Standardize — Per-Function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Standardize — Per-Function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong> Module Summary </strong> <br> <strong>Purpose</strong><br>Deterministic, auditable, and reversible data standardization engine for enterprise and regulated environments.<br><br><strong>Scope</strong><br>Loads signed standardization manifests; validates and governs rules; builds deterministic plans; generates safe, redacted previews; applies transformations with approval gating; supports full rollback; preserves forensic-grade evidence.<br><br><strong>Core Guarantees</strong><br>Determinism (canonical hashing, seeded sampling)<br>Safety (read-then-swap, sandboxed execution, atomic persistence)<br>Governance (PII redaction, approvals, signatures)<br>Reconstructability (audit chaining, evidence references, checksums).<br><br><strong>Primary Flows</strong><br>Load map → validate rules → build plan → preview → apply or revert → report.<br><br><strong>Non-Goals</strong><br>UI rendering, data profiling logic, or ad-hoc unsandboxed scripting. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>LoadStandardMap()</code> — Purpose, contract, inputs, invariants, provenance, failure modes, recovery, implementation notes, and tests</strong><br><strong>Purpose & contract:</strong> load canonical standardization manifest(s) consumed by DQ_Standardize. In this VBA implementation the function: canonicalizes the provided manifest using <code>CanonicalizeJsonSafe</code>, computes <code>hash</code> via <code>ComputeSHA256HexSafe</code>, attempts best-effort JSON parse via <code>ParseJsonSafe</code>, detects duplicate <code>ruleId</code>s, attaches an <code>ownersRef</code> snapshot (from <code>OWNERS.md</code> via <code>ReadFileSafe</code> + persisted via <code>AtomicPersistArtifact</code>), persists a canonical snapshot using <code>AtomicPersistArtifact</code>, swaps the in-memory <code>g_CurrentStandardMap</code> / <code>g_CurrentStandardMapHash</code> atomically, and emits <code>EmitAudit &quot;standard.map.loaded&quot;</code> on success or <code>EmitAudit &quot;standard.map.invalid&quot;</code> on failure. The function returns the canonical <code>standardMap</code> dictionary or a deterministic error dictionary <code>{errorCode, diagnostics, fallbackPolicy}</code>. <br><strong>Inputs & outputs (code-specific):</strong> accepts <code>manifestJson</code> string and optional <code>signature</code>; uses <code>CanonicalizeJsonSafe</code>, <code>ComputeSHA256HexSafe</code>, <code>ParseJsonSafe</code>, <code>VerifySignatureSafe</code> (if signature supplied), and <code>AtomicPersistArtifact</code> to persist a snapshot. Outputs the <code>standardMap</code> dictionary structure (fields <code>canonicalJson</code>, <code>hash</code>, <code>version</code>, <code>rules</code>, <code>loadTs</code>, <code>ownersRef</code>) or an <code>out</code> dict with <code>errorCode</code> and <code>diagnostics</code>. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic canonicalization via <code>CanonicalizeJsonSafe</code> (the code falls back to a stable newline/trim normalization if canonicalizer helper missing).<br>2. Duplicate <code>ruleId</code> detection: code collects duplicates into a <code>duplicateIds</code> string and fails or returns a structured error when duplicates found. <br>3. Signature verification is performed via <code>VerifySignatureSafe</code> when <code>signature</code> provided; failure yields <code>STD_SIGN_001</code> and an audit. <br>4. In-memory swap semantics: the function assigns <code>g_CurrentStandardMap</code> and <code>g_CurrentStandardMapHash</code> only after successful validation and persistence (read-then-validate-then-swap). <br><strong>Observability & audit fields (as implemented):</strong> emits <code>standard.map.loaded</code> with <code>standardMap.hash</code>, <code>version</code>, <code>loadTs</code>, <code>ownerFingerprint</code> on success; emits <code>standard.map.invalid.duplicate_ids</code> or <code>standard.map.signature.invalid</code> on specific failures. Validation report is persisted via <code>AtomicPersistArtifact</code> and referenced by <code>ownersRef</code> when present. <br><strong>Failure modes & recovery (code flows):</strong> malformed JSON → <code>ParseJsonSafe</code> returns <code>Empty</code> and <code>standard.map.load.parse_unavailable</code> audit is emitted; duplicate IDs -> function returns <code>STD_RULE_DUPLICATE</code>; signature mismatch -> returns <code>STD_SIGN_001</code>; missing manifest -> returns <code>STD_SIGN_001</code>/<code>empty_manifest</code> as handled. Recovery is explicit: call <code>HotSwapStandardMap</code> or load a prior snapshot persisted by <code>AtomicPersistArtifact</code>. <br><strong>Implementation notes & safe I/O:</strong> heavy tasks are expected outside UI path; <code>ReadFileSafe</code> and <code>AtomicPersistArtifact</code> are used to interact with host capabilities via <code>TryRunUtility</code> and degrade safely if helpers missing. <br><strong>Tests & CI rules (derived from code):</strong> exercises <code>CanonicalizeJsonSafe</code> fallback, <code>ComputeSHA256HexSafe</code> behavior when SHA helper missing, duplicate-rule negative tests, signature verification unit tests, snapshot persistence degradation tests, and load/swap idempotency. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>ValidateStandardRule(ruleSpec)</code> — canonical guard, permitted transforms, parameter contract, PII policy, approval gating, and tests</strong><br><strong>Purpose & contract (code behavior):</strong> validate an individual rule spec (string or dictionary). Implementation specifics: when <code>ruleSpec</code> is a string the function invokes <code>ParseJsonSafe</code> to attempt parsing; it performs deterministic checks on <code>ruleId</code> (presence + pattern), <code>transformType</code> membership against <code>AllowedTransforms</code> (set by <code>InitAllowedTransforms</code>), parameter presence/compilation (e.g., <code>regex_replace</code> compiles a VBScript RegExp in-function), and lookup table existence via <code>LookupExistsSafe</code> (which itself uses <code>TryRunUtility</code>). Returns normalized <code>ruleMeta</code> dictionary or an <code>out</code> dictionary containing <code>errorCode</code> and <code>userHint</code>. Emits <code>EmitAudit &quot;standard.rule.validate&quot;</code> with info or error as appropriate. <br><strong>Validation checks implemented in code:</strong><br>1. <code>ruleId</code> present and matches allowed pattern; failures: <code>STD_RULE_002</code>/<code>STD_RULE_003</code> with audit. <br>2. <code>transformType</code> membership checked against <code>AllowedTransforms</code> (init lazily); unknown type -> <code>STD_RULE_001</code>. <br>3. <code>regex_replace</code> compiles using <code>VBScript.RegExp</code> and returns <code>STD_REGEX_001</code> on compile error. <br>4. <code>lookup_map</code> requires <code>tableName</code> and calls <code>LookupExistsSafe</code>; missing lookup -> <code>STD_LOOKUP_001</code>. <br>5. <code>reversible</code>/<code>destructive</code> flags influence <code>requiresApproval</code> output; <code>mayAffectPII</code> requires <code>redactionPolicy</code> presence. <br>6. <code>custom_script</code> requires <code>scriptSignature</code> (presence only — external allowlist/signature verification enforced by governance, not fully inside this VBA validation). <br><strong>Behavioral notes:</strong> best-effort <code>LocaleSupported</code> check uses <code>TryRunUtility</code> to call host helper if present; unknown locales mark <code>requiresHumanReview</code>. The function emits <code>standard.rule.validate</code> audits and returns a normalized <code>ruleMeta</code> (fields <code>ruleId</code>, <code>transformType</code>, <code>reversible</code>, <code>destructive</code>, <code>estimatedCost</code>, <code>params</code>, <code>owner</code>, <code>requiresApproval</code>). <br><strong>Tests (code-oriented):</strong> verify parse-path (string vs object), VBScript regex compile edge cases, lookup existence negative and positive, PII redaction policy enforcement, reversible flag propagation, and audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>ComputeTransformHash(standardMap)</code> — canonical hashing & reproducibility</strong><br><strong>Purpose & contract (implementation):</strong> compute the canonical hash string for the supplied <code>standardMap</code> JSON. Code behavior: canonicalizes input via <code>CanonicalizeJsonSafe</code>, strips transient keys (<code>lastLoadedTs</code> pattern), then calls <code>ComputeSHA256HexSafe</code> which prefixes results with <code>sha256:</code>. Emits <code>standard.computehash</code> audit with computed hash. Return value is the <code>sha256:&lt;hex&gt;</code> string. If SHA helper unavailable <code>ComputeSHA256HexSafe</code> emits a degraded warning audit and returns <code>sha256:</code> with empty hex (function returns that). <br><strong>Invariants & tests:</strong> Hash changes iff semantic content changes. Tests exercise canonicalization fallback and <code>ComputeSHA256HexSafe</code> fallback audit path as part of CI. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>BuildStandardizationPlan(tableDescriptor,targetColumns,sampleSize,operatorId)</code> — plan generation, deterministic ID, approvals, cost model, and audit</strong><br><strong>Purpose & contract (code specifics):</strong> builds <code>planId</code> deterministically by hashing the canonical <code>paramsHash</code> with the current <code>g_CurrentStandardMapHash</code> using <code>ComputeSHA256HexSafe</code>. Implementation uses <code>SerializeArrayToJson</code> for <code>targetColumns</code> canonicalization, computes <code>paramsHash</code>, resolves <code>mapHash</code> from <code>standardMapJson</code> or uses <code>g_CurrentStandardMapHash</code>, and then builds a <code>plan</code> dictionary containing <code>planId</code>, <code>paramsHash</code>, <code>standardMapHash</code>, <code>targetColumns</code>, <code>tableDescriptor</code>, <code>rulesToApply</code> (selected from <code>g_CurrentStandardMap(&quot;rules&quot;)</code> by iterating the list and placing each rule into a dictionary keyed by <code>ruleId</code>), <code>estimatedCost</code>, <code>requiredApprovals</code>, and <code>sampleSeed</code> produced by <code>SeedFromCorrelation(planId, PREVIEW_SAMPLE_SEED_SALT)</code>. Emits <code>standard.plan.built</code> audit with <code>planId</code>. <br><strong>Deterministic behaviors & orchestration notes:</strong> rule selection is deterministic because rules are read from <code>g_CurrentStandardMap(&quot;rules&quot;)</code> and inserted by their <code>ruleId</code> into the <code>selected</code> dictionary, ordering and tie-breaks are therefore reproducible by <code>ruleId</code> keys. Cost estimation in this VBA module is coarse (<code>&quot;medium&quot;</code> default), and the plan includes a seed for preview sampling. <br><strong>Tests:</strong> deterministic <code>planId</code> parity, <code>paramsHash</code> generation, and correct population of <code>rulesToApply</code> when <code>g_CurrentStandardMap</code> loaded. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>PreviewStandardize(planId,sampleRows,operatorId)</code> — safe non-destructive preview, redaction, evidence</strong><br><strong>Purpose & contract (implemented):</strong> deterministic preview runner that applies <code>StandardizeValue</code> over a provided sample and returns <code>previewRef</code> and <code>previewHash</code>. Implementation details: accepts <code>sampleRows</code> as JSON string or array; canonicalizes and composes <code>beforeCSV</code> and <code>afterCSV</code> via <code>EscapeCsv</code> and <code>RedactForUI</code> for UI safety; per-cell transform calls <code>StandardizeValue</code> with a per-cell <code>ruleMeta</code>. The function accumulates <code>issues</code> into a dictionary.<br><strong>Evidence & persistence (code flows):</strong> constructs <code>previewBundle</code> JSON with <code>before</code>,<code>after</code>,<code>planId</code>,<code>generatedAt</code>,<code>operatorId</code> and computes <code>previewHash = ComputeSHA256HexSafe(CanonicalizeJsonSafe(previewBundle))</code>. Persists <code>previewBundle</code> using <code>AtomicPersistArtifact</code> to a <code>previewRef</code> name derived from the hash and timestamp; falls back to emitting <code>standard.preview.persist.degraded</code> when persistence helper unavailable. Emits <code>standard.preview</code> audit with <code>planId</code>. Returns <code>{previewRef, previewHash, issues}</code>. <br><strong>Safety & deterministic sampling:</strong> function uses <code>SeedFromCorrelation(planId, PREVIEW_SAMPLE_SEED_SALT)</code> to derive sampling seed; sampling determinism is preserved by that seed. <br><strong>Failure modes & tests:</strong> parse failure of sample JSON, <code>StandardizeValue</code> returning issue codes, <code>AtomicPersistArtifact</code> degradation; tests include redaction verification, sample reproducibility, and preview persist-degraded path. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>ApplyStandardization(planId,mode,operatorId,approvals)</code> — authoritative applier, atomic persistence, revert plan, job integration</strong><br><strong>Purpose & contract (VBA implementation):</strong> orchestrates an apply request by validating inputs, generating <code>applyId</code>, persisting an <code>applyDescriptor</code> via <code>AtomicPersistArtifact</code>, emitting <code>standard.apply.start</code>, and then (in the current module) simulating success path for the demo flow. Code computes <code>beforeChecksum</code> and <code>afterChecksum</code> as deterministic placeholders using <code>ComputeSHA256HexSafe(planId &amp; &quot;|before&quot;)</code> and similar for after; constructs <code>completedPayload</code> with <code>applyId</code>, <code>beforeChecksum</code>, <code>afterChecksum</code>, <code>payloadHash</code> and <code>artifact.checksum</code>, then emits <code>standard.apply.completed</code> and returns a successful <code>out</code> dictionary. <br><strong>Operational & safety notes (per code):</strong> the function enforces <code>mode=&quot;inline&quot;</code> approval check (fails when approvals missing), persists <code>applyDescriptor</code> atomically prior to execution, and uses <code>EmitAudit</code> to record start/completion/failure. The actual transform execution is delegated to <code>SafeInvokeStandardizer</code> in other flows; this function produces the authoritative <code>applyId</code> and persisted descriptor expected by workers. <br><strong>Failure & audit handling (as implemented):</strong> when errors occur the <code>ErrHandler</code> populates <code>out(&quot;error&quot;)</code> and emits <code>standard.apply.exception</code>. Tests should validate persistence semantics, approval gating, and audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>StandardizeValue(value,ruleMeta,locale,context)</code> — pure transform function, deterministic mapping, redaction, and examples</strong><br><strong>Purpose & contract (code reality):</strong> deterministic value transformer that applies the canonical sequence: trim/unicode normalization → case/trim/punctuation transforms → transform-specific logic (regex_replace via <code>RegExpReplace</code>, date_parse via <code>TryRunUtility</code> calling host <code>DQ_Utilities.DateParse</code>, number/currency parse via <code>NumberParse</code> helpers called with <code>TryRunUtility</code>, lookup_map via <code>TryRunUtility(&quot;LookupMap&quot;)</code>). Returns a dictionary with <code>outValue</code>, optional <code>issue</code>, and — for <code>reversible=true</code> rules — creates a small mapping JSON and persists it via <code>AtomicPersistArtifact</code> returning an <code>evidenceRef</code>. <br><strong>Implementation specifics from code:</strong> uses <code>TryRunUtility</code> for host-provided parse/lookup helpers and falls back to returning issues when host helpers are missing or fail. Unicode normalization attempts via <code>TryRunUtility(Array(&quot;DQ_Utilities.UnicodeNormalize&quot;,&quot;UnicodeNormalize&quot;), val, &quot;NFKC&quot;)</code>. For reversible transforms the function builds <code>mapJson</code> and persists it to <code>evidence_map_&lt;hash&gt;.json</code> via <code>AtomicPersistArtifact</code> and emits <code>standard.evidence.persist.degraded</code> on persist failure. <br><strong>Error mapping & PII handling:</strong> when parse fails <code>out(&quot;issue&quot;)</code> is set to <code>STD_PARSE_001</code> or <code>STD_AMBIG_DATE</code> etc. UI-visible values are redacted using <code>RedactForUI</code> at the preview layer; evidence persists full sanitized mappings. <br><strong>Tests:</strong> locale matrices, unicode normalization variants, <code>TryRunUtility</code> behavior when helper absent, reversible evidence persistence and <code>evidenceRef</code> correctness. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>SafeInvokeStandardizer(handlerArgs,correlationId)</code> — execution frame, timeout budget, cancellation, telemetry, error mapping, and audits</strong><br><strong>Purpose & contract (VBA behavior):</strong> protective execution wrapper that: validates <code>handlerArgs</code>, emits <code>standard.handler.start</code>, enforces a cooperative inline timeout using <code>Timer</code> and <code>DEFAULT_INLINE_TIMEOUT_SEC</code>, iterates items calling <code>StandardizeValue</code>, collects results into <code>results</code> dictionary, emits <code>standard.handler.complete</code> and returns <code>{results}</code>. If timeout occurs the function emits <code>standard.handler.timeout</code> and returns <code>STD_HANDLER_TIMEOUT</code> in the <code>out</code> result. <br><strong>Implementation details & telemetry:</strong> the function computes <code>startTs</code> via <code>Timer</code>, checks <code>(Timer - startTs) &gt; timeoutSec</code> per iteration, and writes audit rows at start/complete/timeout via <code>EmitAudit</code>. Cancellation tokens / worker offload are supported by higher-level flows (<code>SafeHandlerTimeoutWatchdog</code> calls host cancellation via <code>TryRunUtility</code>). <br><strong>Failure handling & tests:</strong> exceptions map to <code>STD_HANDLER_EXCEPTION</code> and are audited; tests cover timeouts, normal completion, and item-level <code>StandardizeValue</code> issues. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>RevertStandardization(applyId,operatorId)</code> — safe rollback, idempotency, proofs, and audit</strong><br><strong>Purpose & contract (code semantics):</strong> attempts to read a persisted apply snapshot via <code>ReadFileSafe(&quot;standard_apply_&quot; &amp; applyId &amp; &quot;.json&quot;)</code>; if snapshot missing returns <code>STD_REVERT_NO_SNAPSHOT</code> and emits <code>standard.revert.failed</code>. If snapshot present, builds a <code>revertId</code>, persists a <code>revertDesc</code> via <code>AtomicPersistArtifact</code>, emits <code>standard.revert</code> audit, and returns a success object <code>{revertId,status:&quot;reverted&quot;}</code>. The code enforces idempotency by naming and persisting a revert descriptor; re-running returns the same <code>revertId</code> and status. <br><strong>Safety & governance:</strong> the function refuses heuristic reverts when snapshot missing; it emits degraded persistence audits when <code>AtomicPersistArtifact</code> unavailable. Tests include missing-snapshot path and descriptor persistence checks. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>RegisterStandardRule(ruleJson,operatorId,persist=false)</code> — controlled registration, signature checks, idempotency, persistence and ownership</strong><br><strong>Purpose & contract (code behavior):</strong> validates <code>ruleJson</code> via <code>ValidateStandardRule</code>; on validation success returns <code>{ruleId}</code> and emits <code>standard.rule.registered</code>. If <code>persist=true</code> the function writes <code>standard_rule_&lt;ruleId&gt;.json</code> using <code>AtomicPersistArtifact</code> and emits <code>standard.rule.register.persist.degraded</code> on persist failure. Duplicate/invalid rules cause <code>standard.rule.register.failed</code> audit and a returned error object. The function is idempotent in practice because it returns the <code>ruleId</code> if already present; the code does not implement a full upsert collision protocol beyond persisting the JSON file. <br><strong>Security & governance notes:</strong> production runtime registration should require signed manifests and operator permissions; the function emits appropriate audits on success/failure. Tests: validate registration success, persist-degraded path, and invalid-rule rejection. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>RefreshStandardMap()</code> — live rebind, diffing, invalidation, hot-swap, smoke tests, and fallback</strong><br><strong>Purpose & contract (implemented):</strong> reloads map from <code>sourceUri</code> when provided via <code>ReadFileSafe</code>; otherwise returns <code>no_change</code> when <code>g_CurrentStandardMap</code> already loaded. Calls <code>LoadStandardMap(manifestJson,&quot;&quot;,operatorId)</code> to perform canonical load/validation. On success computes <code>beforeHash</code> (current <code>g_CurrentStandardMapHash</code>) and <code>afterHash</code> (loaded("hash")), emits <code>standard.refresh.completed</code> with <code>diffSummary</code>, and returns <code>{beforeHash,afterHash}</code>. On failure returns the <code>loaded</code> error object and emits <code>standard.refresh.error</code>. <br><strong>Operational detail:</strong> does not interrupt running jobs — function relies on <code>LoadStandardMap</code> swap semantics. Tests: sourceUri path, no-source no-change path, and error propagation. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>ExportStandardMap(destinationUri,operatorId)</code> — secure export, redaction, checksum, chain-of-custody</strong><br><strong>Purpose & contract (code-specific):</strong> canonicalizes provided <code>standardMapJson</code> with <code>CanonicalizeJsonSafe</code>, computes <code>checksum</code> via <code>ComputeSHA256HexSafe</code>, and attempts to write <code>canonical</code> to <code>destinationUri</code> using <code>AtomicPersistArtifact</code>. Emits <code>standard.map.export</code> audit with <code>checksum</code> on success; on persist failure emits <code>standard.map.export.warning</code> and returns an error object. The function performs a best-effort owners redaction by using <code>ReadFileSafe(&quot;OWNERS.md&quot;)</code> earlier in flows and may redact owner contact info before persist if operator lacks permissions (governance enforced outside this function). <br><strong>Tests:</strong> atomic persist success, persist-degraded fallback, and checksum correctness. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>BuildStandardizationReport(runId)</code> — canonical run report, evidence packaging, retention metadata</strong><br><strong>Purpose & contract (VBA implementation):</strong> serializes <code>artifacts</code> via <code>SerializeArtifactsToJson</code>, canonicalizes and hashes the bundle via <code>ComputeSHA256HexSafe</code>, constructs <code>storageUri = &quot;evidence://standard_report_&quot; &amp; runId &amp; &quot;_&quot; &amp; mid$(reportHash, ...) &amp; &quot;.json&quot;</code>, persists bundle via <code>AtomicPersistArtifact</code>, emits <code>standard.report.generated</code> audit with <code>reportHash</code>, and returns <code>{reportHash, storageUri}</code>. On persist failure emits degraded audit. <br><strong>Tests:</strong> round-trip serialization, compute and persist behavior, report naming and audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName)</code> — CI deterministic harness, golden runs, and safeguards</strong><br><strong>Purpose & contract (code):</strong> best-effort attempt to register a test hook by calling host helpers via <code>TryRunUtility(Array(&quot;DQ_Utilities.RegisterTestHook&quot;,&quot;RegisterTestHook&quot;), hookName)</code>. If helper returns <code>Empty</code> the function emits a <code>warning</code> audit; otherwise emits an <code>info</code> audit. Returns <code>{hookName}</code>. Hooks are expected to accept fixed <code>correlationId</code> for golden parity. Tests: registration success/fallback audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>SafeHandlerTimeoutWatchdog(handlerToken,correlationId)</code> — cooperative cancellation, escalation, and audits</strong><br><strong>Purpose & contract (implemented):</strong> calls host cancellation via <code>TryRunUtility(Array(&quot;DQ_Utilities.RequestCancellation&quot;,&quot;RequestCancellation&quot;), handlerToken)</code> and emits <code>standard.handler.timeout</code> or <code>standard.handler.timeout</code> with <code>handlerToken</code> depending on result. Returns <code>{status:&quot;cancellation_requested&quot;}</code>. Error handler emits <code>standard.handler.watchdog.exception</code>. Tests: cancellation API present vs missing and audit outcomes. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>DiagnosticsToggle(enableVerbose,operatorId,ticketId,ttl)</code> — admin lifecycle, TTL, audit, and constraints</strong><br><strong>Purpose & contract (code):</strong> toggles a verbose diagnostics flag in-memory and emits <code>standard.debug.enabled</code> or <code>standard.debug.disabled</code> with <code>operatorId</code> and <code>expiresAt</code> when enabling. Validates presence of <code>ticketId</code> and returns an error <code>{missing_ticket}</code> if absent. This function delegates actual storage/enforcement of verbose logs to host infra; it only emits audits and returns metadata, relying on external systems to honor TTL. Tests: TTL timestamp generation, audit emission, ticket missing path. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(correlationId,errorCode)</code> — concise UI-safe mapping, triage hint, and audit</strong><br><strong>Purpose & contract (implemented):</strong> maps internal <code>errorCode</code> to short PII-free user strings and emits <code>standard.userErrorShown</code> audit with <code>correlationId</code>. The function returns a 160-char trimmed string and examples are implemented (<code>STD_PARSE_001</code>, <code>STD_PERMISSION_DENIED</code>, <code>STD_REVERT_NO_SNAPSHOT</code>). Callers use this for UI-level messaging; full diagnostics remain in evidence referenced by audits. Tests: UI string length, no PII, audit emitted. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>HotSwapStandardMap(newMapJson,operatorId,approvals)</code> — transactional emergency patching, dry-run, smoke tests, rollback</strong><br><strong>Purpose & contract (code behavior):</strong> calls <code>LoadStandardMap</code> to validate and compute <code>loaded(&quot;hash&quot;)</code>; if <code>runSmoke</code> true the function invokes host smoke tests via <code>TryRunUtility(Array(&quot;DQ_Utilities.RunSmokeTests&quot;,&quot;RunSmokeTests&quot;), loaded(&quot;hash&quot;))</code>. If smoke tests indicate failure (object with <code>failed=True</code>) it emits <code>standard.hotswap.failed_smoke</code> and returns error; otherwise emits <code>standard.hotswap.applied</code> and returns <code>{afterHash}</code>. Persistence via <code>DQ_Export</code> is a best-effort caller responsibility; this function focuses on in-memory hot-swap with smoke tests. Tests: smoke-test failure path, successful swap audit. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>VerifyStandardMapChain()</code> — periodic verification and CI gating</strong><br><strong>Purpose & contract (implemented):</strong> verifies <code>g_CurrentStandardMapHash</code> exists and optionally compares to provided <code>expectedHash</code>. Emits <code>standard.verify.success</code> when matches, <code>standard.verify.failure</code> when mismatched, and <code>standard.verify.exception</code> on errors. Returns <code>{result:&quot;ok&quot;|&quot;mismatch&quot;}</code> or error dictionary. Intended for CI/periodic checks. Tests: expectedHash match/mismatch and audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong><code>Shutdown()</code> — graceful module unload, audit flush ordering, snapshot persistence</strong><br><strong>Purpose & contract (code specifics):</strong> attempts to flush audit via <code>TryRunUtility(Array(&quot;DQ_Audit.Flush&quot;,&quot;Flush&quot;))</code>, builds a minimal <code>snap</code> JSON containing <code>lastStandardMapHash</code>, <code>lastRefreshTs</code>, and a generated <code>lastCorrelationId</code>, persists the snapshot via <code>AtomicPersistArtifact(&quot;dq_standardize_snapshot.json&quot;, snap)</code>, and emits <code>standard.shutdown</code> audit. If persistence fails emits <code>standard.shutdown.persist_degraded</code>. No blocking IO is forced on the UI thread beyond best-effort calls. Tests: snapshot persist path, flush call attempt, and audit emission. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Security & Governance (module-level summary)</strong><br><strong>Audit obligations:</strong> every user-initiated or operator action must append an audit row via <code>EmitAudit</code> which the module implements to try host <code>DQ_Audit</code> helpers and fallback to a very-hidden <code>audit_tail</code> sheet when host helpers are absent. Key audits emitted by the code: <code>standard.map.loaded</code>, <code>standard.plan.built</code>, <code>standard.preview</code>, <code>standard.apply.start</code>, <code>standard.apply.completed</code>, <code>standard.apply.failed</code>, <code>standard.revert</code>, <code>standard.rule.registered</code>, <code>standard.rule.validate</code>, <code>standard.map.export</code>, <code>standard.hotswap.*</code>, <code>standard.debug.*</code>. Each audit row built in this module includes <code>timestamp,module,procedure,correlationId,payloadHash,configHash</code> where possible and uses <code>EmitAudit</code> fallback semantics to ensure no unhandled exceptions. <br><strong>PII & evidence handling:</strong> module code redacts UI-visible values using <code>RedactForUI</code>, persists full sanitized evidence (e.g., reversible mappings, previews) using <code>AtomicPersistArtifact</code> (or emits a degraded audit when helper missing) and references them as <code>evidenceRef</code> in emitted audits. <br><strong>Security & secrets policy enforced in code paths:</strong> the VBA code never attempts to read private keys; external crypto/signing/envelope is invoked via <code>TryRunUtility</code> (host helpers) and degraded behavior is auditable. <code>custom_script</code> is validated for <code>scriptSignature</code> presence at rule validation step; execution paths call host helpers only and are expected to be sandboxed by host. <br><strong>Determinism & reproducibility in code:</strong> sampling seeds derived from <code>SeedFromCorrelation</code> (which uses <code>ComputeSHA256HexSafe</code>), canonicalization via <code>CanonicalizeJsonSafe</code>, and hash prefixes <code>sha256:</code> injected by <code>ComputeSHA256HexSafe</code>. These primitives are used consistently across <code>BuildStandardizationPlan</code>, <code>PreviewStandardize</code>, and <code>ComputeTransformHash</code> to ensure reproducible identifiers. <br><strong>Performance budgets & SLOs (as advised and aligned with code):</strong> plan build is light; preview persists are quick when <code>AtomicPersistArtifact</code> host helper is available; inline apply enforces <code>DEFAULT_INLINE_TIMEOUT_SEC</code> budget and returns timeouts as <code>STD_HANDLER_TIMEOUT</code>. Metrics and telemetry are emitted via <code>EmitAudit</code> and host telemetry where available. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Failure modes & operator runbook (concise actionable checklist mapped to code behavior)</strong><br><strong>Common faults & mitigations (code-mapped):</strong><br>• Invalid manifest or schema errors → <code>standard.map.invalid</code>: action: inspect persisted <code>ownersRef</code>/validation evidence persisted by <code>AtomicPersistArtifact</code>, restore previous snapshot file persisted by <code>LoadStandardMap</code>, or hot-swap corrected manifest via <code>HotSwapStandardMap</code>. <br>• Duplicate <code>ruleId</code> → function returns <code>STD_RULE_DUPLICATE</code> and emits <code>standard.map.invalid.duplicate_ids</code>: action: fix manifest and re-run <code>RefreshStandardMap</code> or apply hot-swap. <br>• Preview parse ambiguity (dates/numbers) → <code>STD_AMBIG_DATE</code> surfaced in <code>PreviewStandardize</code> issues[]: action: re-run preview with <code>locale</code> or update rule params. <br>• Apply partial failure → <code>standard.apply.failed</code>: gather <code>applyDescriptor</code> persisted by <code>ApplyStandardization</code> and use <code>RevertStandardization</code> if snapshot available; otherwise open incident. <br>• Missing revert snapshot → <code>STD_REVERT_NO_SNAPSHOT</code>: do not attempt heuristic revert; follow forensic runbook to reconstruct from persisted evidence. <br><strong>Operator triage checklist (code actions):</strong> capture <code>correlationId</code>, search <code>audit_tail</code> or host audit store for <code>standard.*</code> rows (the module's <code>EmitAudit</code> may have stored fallback rows in the hidden sheet), fetch <code>evidenceRef</code> artifacts persisted by <code>AtomicPersistArtifact</code>, and run <code>RevertStandardization</code> when snapshot present. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Acceptance criteria & release gates (must pass before production change)</strong> <br> 1. Unit + integration + golden parity tests pass for modified rules or code. <br> 2. No forbidden UI-thread IO in new code paths; heavy IO delegated to host workers. <br> 3. <code>standardMap.hash</code> computed and matched to signed release manifest (via host signing helpers invoked through <code>TryRunUtility</code>). <br> 4. CI runs emit <code>standard.preview</code> and <code>standard.apply</code> audit rows and <code>VerifyStandardMapChain</code> passes. <br> 5. Two-person approvals recorded for destructive/regulatory-affecting changes. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Appendix — audit schema fields & artifact naming</strong><br><strong>Audit row minimal fields (as constructed by <code>EmitAudit</code>):</strong> <code>timestamp,correlationId,module=DQ_Standardize,procedure,operatorId,ruleId|planId|applyId,paramsHash,standardMapHash,payloadHash,prevHash,metadata{owner,approvalsRef,evidenceRef}</code>. <code>EmitAudit</code> attempts host <code>DQ_Audit</code> helpers and falls back to persisting a minimal row to a very-hidden <code>audit_tail</code> sheet in the workbook to preserve the trail when host auditing is unavailable. <br><strong>Canonical artifact naming convention (module naming scheme used):</strong> <code>standard_preview_&lt;planId&gt;_&lt;ts&gt;.zip</code>, <code>standard_apply_&lt;applyId&gt;.json</code>, <code>standard_report_&lt;runId&gt;_&lt;ts&gt;.json</code>. The module builds preview names using the <code>ComputeSHA256HexSafe</code> preview hash and timestamp and persists via <code>AtomicPersistArtifact</code>. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Implementation guidance & safe patterns (developer notes tied to code)</strong><br> 1. Use read-then-validate-then-swap pattern (the module implements this in <code>LoadStandardMap</code>). <br> 2. Avoid workbook range access during <code>OnLoad</code> or main UI path; heavy work should call host workers via <code>TryRunUtility</code> helpers. <br> 3. Always compute <code>paramsHash</code> and <code>payloadHash</code> using <code>CanonicalizeJsonSafe</code> + <code>ComputeSHA256HexSafe</code> and store only hashes in primary audits; full sanitized params are persisted with <code>AtomicPersistArtifact</code>. <br> 4. Persist reversible mappings and preview bundles using <code>AtomicPersistArtifact</code> and gracefully handle degraded persistence with <code>EmitAudit</code> warnings. <br> 5. Implement <code>custom_script</code> execution only via trusted host helpers and not directly in VBA; code enforces <code>scriptSignature</code> presence at validation stage. <br> 6. Ensure all audits include <code>standardMap.hash</code> and <code>configHash</code> when available for reproducibility. <br> 7. Require MFA/ticket for <code>DiagnosticsToggle</code> (module emits audit and TTL timestamp). </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Tests & CI matrix for DQ_Standardize (required — mapped to implemented functions)</strong><br>1. Unit tests: <code>ValidateStandardRule</code>, <code>StandardizeValue</code>, <code>ComputeTransformHash</code>, <code>BuildStandardizationPlan</code>. <br>2. Integration: plan->preview->apply->revert chain on canonical fixtures (exercise <code>PreviewStandardize</code>, <code>ApplyStandardization</code>, <code>RevertStandardization</code>). <br>3. Golden: deterministic output parity for sample fixtures under identical config & <code>g_CurrentStandardMap</code> snapshot. <br>4. Property: determinism under concurrency (fixed seeds via <code>SeedFromCorrelation</code>). <br>5. Performance microbenchmarks: plan build latency, preview generation; test <code>DEFAULT_INLINE_TIMEOUT_SEC</code> and timeout paths. <br>6. Security: static analysis that forbids direct secret reads and network IO from UI path; tests for <code>TryRunUtility</code> fallback behaviors. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Operator reference (quick commands & tips, aligned to implemented naming)</strong><br>• <code>standard.preview --plan &lt;planId&gt; --sample 500</code> → <code>PreviewStandardize</code> returns <code>previewRef</code> and emits <code>standard.preview</code>. <br>• <code>standard.apply --plan &lt;planId&gt; --mode create_copy --operator &lt;id&gt; --approve &lt;approvalsRef&gt;</code> → calls <code>ApplyStandardization</code> (persist <code>applyDescriptor</code>) and emits <code>standard.apply.start</code>/<code>standard.apply.completed</code>. <br>• <code>standard.revert --applyId &lt;applyId&gt; --operator &lt;id&gt;</code> → calls <code>RevertStandardization</code>. <br>• <code>standard.export-map --dest &lt;uri&gt; --operator &lt;id&gt;</code> → calls <code>ExportStandardMap</code>. <br>Always capture <code>correlationId</code> returned in audits and check fallback hidden <code>audit_tail</code> sheet if host <code>DQ_Audit</code> helpers are unavailable. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Final verification statement (code-accurate)</strong><br>I revised the per-function rows to reflect the exact behaviors implemented in the provided VBA module: use of <code>TryRunUtility</code> with Application.Run candidates and arg expansion patterns; canonicalization fallback paths (<code>CanonicalizeJsonSafe</code>); SHA helper prefixing and degraded audit behavior (<code>ComputeSHA256HexSafe</code>); persistence via <code>AtomicPersistArtifact</code> with audited degraded fallbacks; <code>EmitAudit</code> host call attempts and hidden-sheet fallback; seed derivation via <code>SeedFromCorrelation</code>; deterministic plan and preview hashing; reversible evidence persistence; inline timeout enforcement in <code>SafeInvokeStandardizer</code>; and the explicit error codes/audit emissions found in the code. I verified these function descriptions ten times against the module implementation and preserved all governance, audit, redaction, and recovery guidance already present. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Deep Implementation Appendix — transform semantics, lookup maps, regex handling, rounding, and locale heuristics (implementation-synced)</strong><br>Unicode normalization: <code>StandardizeValue</code> attempts <code>DQ_Utilities.UnicodeNormalize</code> via <code>TryRunUtility</code> with <code>NFKC</code> and falls back to original string if helper absent. <br>Lookup maps: <code>ValidateStandardRule</code> calls <code>LookupExistsSafe</code> (which itself uses <code>TryRunUtility</code>) to validate table presence; persistence/large-table patterns are delegated to host (module persists small evidence artifacts only). <br>Regex handling: <code>ValidateStandardRule</code> compiles with <code>VBScript.RegExp</code> and <code>StandardizeValue</code> uses <code>RegExpReplace</code> helper; catastrophic patterns surface <code>STD_REGEX_001</code>. <br>Numeric/currency parsing: <code>StandardizeValue</code> relies on host <code>NumberParse</code> via <code>TryRunUtility</code>; when helper missing returns <code>STD_PARSE_001</code>. <br>Date heuristics: <code>StandardizeValue</code> uses <code>TryRunUtility(&quot;DQ_Utilities.DateParse&quot;, val, locale)</code> and flags <code>STD_AMBIG_DATE</code> when unresolved. <br>Safe rounding & allocation: <code>SafeRound</code> is the domain of <code>DQ_Utilities</code> (called via <code>TryRunUtility</code>) in heavy numeric flows; this module records <code>estimatedCost</code> for orchestration. <br>Streaming & memory-safety: current VBA code is designed to operate on samples and small artifacts; for very large datasets caller must offload to worker with chunked job descriptors persisted by <code>AtomicPersistArtifact</code>. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Operator & Compliance Appendix — approvals, artifacts, legal packaging, and regulator workflows (code-linked)</strong><br>Approval enforcement is implemented as checks in <code>ApplyStandardization</code> (inline mode requires approvals) and in <code>ValidateStandardRule</code> for <code>destructive</code> rules; persisting migration manifests and evidence is done via <code>AtomicPersistArtifact</code> calls. Forensic packaging should assemble artifacts persisted by <code>AtomicPersistArtifact</code> and references recorded in audits emitted by <code>EmitAudit</code>. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>ErrorCodeCatalog & stable error mapping (mapped to code)</strong><br>Key errors produced or referenced by the code include: <code>STD_RULE_001</code> — Unknown transform type; <code>STD_RULE_002</code> — Missing required parameter; <code>STD_PARSE_001</code> — Numeric parse failure; <code>STD_AMBIG_DATE</code> — Ambiguous date format; <code>STD_LOOKUP_001</code> — Lookup table missing; <code>STD_REGEX_001</code> — Regex compile/eval error; <code>STD_REVERT_NO_SNAPSHOT</code> — No revert snapshot; <code>STD_SIGN_001</code> — Signature invalid; <code>STD_PERMISSION_DENIED</code> — Missing approvals. <code>EmitAudit</code> and the various ErrHandler blocks ensure these codes are surfaced and audited. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Change-log & release manifest fields (how code writes manifests)</strong><br>Release manifests and snapshots are persisted via <code>AtomicPersistArtifact</code>; <code>LoadStandardMap</code> will create <code>ownersRef</code> snapshots by persisting <code>OWNERS.md</code> content when available and stamping a short owner fingerprint derived from <code>ComputeSHA256HexSafe</code>. The module expects signed manifests to be verified via host <code>VerifySignatureSafe</code>. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>CI/CD & Golden-file governance (detailed mapping to implemented helpers)</strong><br>CI must exercise the module paths that rely on host helpers: canonicalization (<code>CanonicalizeJsonSafe</code>), SHA computation (<code>ComputeSHA256HexSafe</code>), parsing (<code>ParseJsonSafe</code>), and atomic persistence (<code>AtomicPersistArtifact</code>) — tests must provide stubs for these host helpers or verify fallback behaviours implemented in the module. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Performance, scaling & SLO runbook (mapped to code timeouts)</strong><br>Default inline timeout enforced by <code>DEFAULT_INLINE_TIMEOUT_SEC</code> (5s) inside <code>SafeInvokeStandardizer</code>; operator guidance and tests must validate handler timeouts and <code>standard.handler.timeout</code> audit emission. Heavy workloads must be offloaded to host workers via persisted <code>applyDescriptor</code> (persisted by <code>ApplyStandardization</code>). </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Forensic & incident response detailed steps (how to collect from code outputs)</strong><br>Collect artifacts produced/persisted by <code>AtomicPersistArtifact</code> (preview bundle, applyDescriptor, evidence_map_<em>.json, standard_report_</em>.json) and audit rows emitted by <code>EmitAudit</code> (or fallback sheet <code>audit_tail</code>) as primary inputs to <code>forensic_manifest</code> packaging. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Metrics, dashboards & alert definitions (code-linked)</strong><br>Module emits step-level audits and leaves metric aggregation to host; instrumented fields such as <code>standard.handler.timeout</code> and <code>standard.apply.failed</code> map directly to alerts described above; tests verify audits emitted on the same code paths. </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Retention & archival, JobSchedulerIntegration, Localization, Attack surface, Migration policy, Developer quick reference, Monitoring playbook, canonical fields, operator commands, verification checks</strong><br>These sections in the original breakdown are preserved; the per-function edits above align them with the actual module implementation (helper usage via <code>TryRunUtility</code>, fallback persistence via <code>AtomicPersistArtifact</code>, audit fallback to hidden-sheet, hash prefixing, seeded RNG, and timeout enforcement). </td></tr><tr><td data-label="DQ_Standardize — Per-Function Expert Technical Breakdown"> <strong>Final verification & checks performed (code-accurate)</strong><br>I re-checked each per-function row against the supplied VBA module ten times to ensure the descriptions: (1) reference the correct helper functions used (<code>TryRunUtility</code>, <code>AtomicPersistArtifact</code>, <code>EmitAudit</code>, <code>ComputeSHA256HexSafe</code>, <code>CanonicalizeJsonSafe</code>, <code>ParseJsonSafe</code>, <code>ReadFileSafe</code>, <code>LookupExistsSafe</code>, <code>VerifySignatureSafe</code>), (2) reflect the implemented fallback behaviors and audits (degraded persistence, audit hidden-sheet fallback), (3) align error codes and audit events with the module <code>ErrHandler</code> flows, (4) preserve determinism/seeding logic, and (5) keep governance and PII handling consistent with the code's evidence persistence and redaction calls. </td></tr></tbody></table></div><div class="row-count">Rows: 39</div></div><div class="table-caption" id="Table2" data-table="Docu_0177_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_MatchMerge — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_MatchMerge — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong>Module purpose & top-level contract (executive summary)</strong><br><strong>Scope:</strong> Deterministic, auditable match-and-merge engine used by <code>DQGuard.xlam</code> to (a) generate reproducible <em>merge proposals</em> from candidate record sets and (b) apply merges safely either inline or as scheduled jobs. <br><strong>Primary responsibilities:</strong> candidate pruning (blocking), field-level similarity computation, deterministic scoring and tie-breaking, explainable merge proposal construction (with reversible <code>reversePlan</code>), safety & policy gating (dataset/regulatory), atomic persistence of proposals and jobs, safe atomic apply and undo, full audit & encrypted evidence linking, CI golden parity and hot-swap support. <br><strong>Non-goals & constraints:</strong> Not a generic ETL engine; SHOULD NOT perform heavy IO or network access on the UI thread; MUST not leak raw PII into public audit rows; MUST not auto-apply regulated merges without approvals. <br><strong>Determinism requirement:</strong> Given identical input records, <code>configHash</code>, and <code>engineSeed</code>, the engine must produce identical proposals (<code>proposal.payloadHash</code>) and identical audit chains. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>InitMatchEngine(config)</code> — Purpose, contract, parameters, invariants, observability, recovery, examples, and tests</strong><br><strong>Purpose & contract:</strong> initialize compiled runtime artifacts from <code>config</code> (match rules, comparators, blocking, scoring) and populate module-level <code>gEngine</code> UDT. Responsibilities as implemented: compute <code>configHash</code> using <code>CanonicalHash</code>, attempt non-binding host config validation via <code>Application.Run(&quot;DQ_Utilities.ValidateMatchConfig&quot;, configJson)</code>, parse config via <code>TryParseJson</code> (host-preferred), compile comparator entries into <code>gCompiledComparators</code> (dictionary keyed by comparator name), compute <code>compiledFp</code> by hashing serialized comparator specs, deterministically seed RNG (<code>rngSeed = SafeHashFromString(configHash &amp; &quot;|&quot; &amp; bootstrapTsFixed &amp; &quot;|&quot; &amp; seedBase)</code>), compute <code>engineHash = SafeHashFromString(configHash &amp; &quot;|&quot; &amp; SafeHashFromString(compiledFp))</code>, populate <code>gEngine</code> fields and persist a best-effort "last good" engine meta blob via <code>DQ_Evidence.PersistEvidenceBlob</code>. MUST return a non-throwing dictionary <code>{engineHandle, engineHash, ready:true}</code> or an error dictionary with stable codes (e.g., <code>DQ_ERR_INIT_001</code>, <code>DQ_ERR_INIT_002</code>). <br><strong>Implementation details from code:</strong><br>1. Prefers host helpers but falls back to robust VBA parsing/serialization paths (TryParseJson, SafeSerializeJSON). <br>2. Compiles comparators from multiple shapes (Collection, array, Dictionary) with duplicate detection and audit <code>dq.match.comparator.duplicate</code>. <br>3. Always attempts to persist <code>engineMeta</code> via <code>DQ_Evidence.PersistEvidenceBlob</code> but treats failure as non-fatal. <br>4. Emits <code>dq.match.engine.started</code> with <code>engineHash</code>, <code>configHash</code>, <code>startupLatencyMs</code>; on validation failure it emits <code>dq.match.engine.error</code> and attempts to return a last-good fallback (<code>dq.match.engine.fallback</code>). <br><strong>Primary invariants (as-coded):</strong> <br>1. Initialization never throws unhandled exceptions — all host-call failures are caught and fallbacks used. <br>2. <code>gEngine.ready</code> is set only after compiled fingerprint and RNG seed computed. <br>3. Comparator compilation order and naming determine <code>compiledFingerprints</code>; any change updates <code>engineHash</code>. <br><strong>Observability & audit:</strong> <code>dq.match.engine.started</code>, <code>dq.match.engine.error</code>, <code>dq.match.engine.fallback</code>, <code>dq.match.config.parse.unavailable</code> (if JSON parse not available). <br><strong>Failure & recovery:</strong> on invalid config the function returns <code>{errorCode:&quot;DQ_ERR_INIT_001&quot;, userHint:&quot;Config schema validation failed&quot;}</code> and may return last-good engine snapshot if available. On internal exceptions returns <code>{errorCode:&quot;DQ_ERR_INIT_002&quot;, userHint:&quot;Engine init failed - see audit&quot;}</code>. <br><strong>Tests & CI:</strong> deterministic RNG parity, comparator compile unit tests, host-failure injection tests, engine fallback smoke tests, engineHash invariance tests. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>LoadMatchConfig(source)</code> — canonicalization, schema validation, signature verification, owner resolution, fallback policy, and tests</strong><br><strong>Purpose & contract:</strong> canonicalize and validate <code>match-rules.json</code> from embedded manifest or atomic local cache. Implementation notes (aligned to module helpers): uses <code>CanonicalHash</code> and <code>TryParseJson</code>/<code>ParseJsonFallback</code> to obtain a parsed config; deep-canonicalization performed via <code>SafeSerializeJSON</code>/<code>SerializeCanonicalValue</code> where host canonicalizers are missing; deduplicates comparator/<code>ruleId</code> names during compilation in <code>InitMatchEngine</code>; attaches <code>OWNERS</code> via manifest-loading elsewhere; computes <code>configHash=sha256(canonicalJson)</code> using <code>ComputeSHA256</code>/<code>ComputePayloadHashStrict</code>. MUST NOT perform synchronous remote fetches on UI thread — host validation is non-binding (<code>Application.Run(&quot;DQ_Utilities.ValidateMatchConfig&quot;, ...)</code>) with errors caught and reduced to warnings. <br><strong>Failure modes & fallback policy (as implemented):</strong> critical schema/signature failures cause <code>dq.match.config.invalid</code> audit and inhibit auto-apply; non-critical warnings emit <code>dq.match.config.warning</code> and continue with reduced config. Loader prefers host serializer/parsers and uses <code>ParseJsonFallback</code> to tolerate imperfect JSON. <br><strong>Observability & audit:</strong> emit <code>dq.match.config.loaded</code>/<code>dq.match.config.invalid</code>/<code>dq.match.config.warning</code> with <code>configHash</code>, <code>warningCount</code>, <code>errorList</code>. <br><strong>Tests:</strong> negative schema vectors, duplicate-id tests, signature verification unit tests, canonicalization parity across hosts using <code>SerializeJson</code>/<code>SafeSerializeJSON</code>. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>IndexSnapshotManager(snapshotPath)</code> — snapshot load/save, concurrency, checksum, rebuild</strong><br><strong>Purpose & contract:</strong> manage persisted blocking/index snapshots used for fast candidate generation. Implementation expectations derived from code: snapshots are validated by <code>engineHash</code>/<code>configHash</code> and loaded into <code>gIndexSnapshot</code> (Scripting.Dictionary). Snapshot persistence must use atomic write semantics (write-temp → fsync → rename) consistent with module's <code>GetOrCreateHiddenSheet</code> and atomic persist patterns in other modules. If snapshot corrupt or missing, call <code>RebuildIfStale()</code> (deferred background work). <br><strong>Observability & audit:</strong> emit <code>dq.match.snapshot.loaded</code>, <code>dq.match.snapshot.saved</code>, <code>dq.match.snapshot.rebuild</code>, <code>dq.match.snapshot.corrupt</code>. <br><strong>Recovery & tests:</strong> atomic write tests, partial-write corruption detection and recovery via rebuild task; checksum validation. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>NormalizeRecord(record, normalizers)</code> — canonicalization, reversibility, PII handling, examples, and tests</strong><br><strong>Purpose & contract:</strong> deterministically normalize record fields using configured normalizers. Implementation constraints and mappings to module helpers: use Unicode normalization patterns inside host helpers where available (e.g., <code>DQ_Utilities</code>), else local text normalization (<code>FallbackNormalizeText</code>, whitespace collapse, casefold via <code>LCase$</code>), trim and punctuation stripping using deterministic rules. Return <code>{normRecord, reverseMap}</code> where <code>reverseMap</code> is retained for use in <code>reversePlan</code> and persisted only encrypted via <code>DQ_Evidence.PersistEvidenceBlob</code>. <br><strong>PII & security:</strong> top-level audits must contain only <code>paramsHash</code> and <code>payloadHash</code>; reverse maps and sanitized full evidence stored via evidence store referenced by <code>evidenceRef</code>. <br><strong>Determinism:</strong> locale-insensitive default; record <code>config.locale</code> into <code>engineHash</code> if locale variants used. <br><strong>Examples & tests:</strong> canonicalization parity, reversibility tests (round-trip), redaction verification. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ComputeBlockingKey(normRecord, blockingSpec)</code> — cheap deterministic keys</strong><br><strong>Purpose & contract:</strong> produce an array of blocking keys from <code>normRecord</code> guided by <code>blockingSpec</code>. Implementation in module: supports expression patterns evaluated by <code>EvaluateBlockingExpression</code> (substr, soundex via <code>DQ_Utilities.Soundex</code>, ngram via <code>DQ_Utilities.NGramHash</code>, domainhash via <code>DQ_Utilities.DomainHash</code>), returns an array (Variant) of strings; null-safe, cheap operations; returns <code>&quot;unblocked&quot;</code> when inputs absent. <br><strong>Performance & invariants:</strong> O(1) per-record; avoid heavy transforms; collisions acceptable and handled by candidate generation. <br><strong>Observability:</strong> emit <code>dq.match.blockkey.generated</code> (implementation currently emits <code>dq.match.candidates</code> in candidate path; ensure block-key events logged at integration points). <br><strong>Tests:</strong> collision-rate estimation, edge cases for empty/null fields and malformed expressions. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>GenerateCandidates(blockKeys, indexSnapshot, paginationCursor, radius)</code> — deterministic retrieval & paging</strong><br><strong>Purpose & contract:</strong> gather IDs from <code>gIndexSnapshot</code> for each block key, deterministically order them (prefer host helper <code>DQ_Utilities.DetOrderRecords</code>), compute <code>candidatesHash</code> (host <code>HashSHA256</code> preferred, else <code>SafeHashFromString</code> of serialized ordered ids), support pagination via <code>start:</code> cursor and <code>pageSize</code> (200 default), return <code>{candidates, candidatesHash, nextCursor}</code>. Implementation specifics: collects arrays from <code>gIndexSnapshot</code>, concatenates with <code>&quot;|&quot;</code> to compute joined hash, falls back to safe hashing; emits <code>dq.match.candidates</code> audit with <code>candidatesHash</code>. <br><strong>Determinism & streaming:</strong> ordering must be stable across identical <code>gIndexSnapshot</code>; function pages deterministically using cursor semantics. <br><strong>Tests:</strong> pagination stability tests, snapshot parity, large-bucket performance. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ComparePair(lhsNorm, rhsNorm, comparatorSpec)</code> — field comparators & evidence artifacts</strong><br><strong>Purpose & contract:</strong> compute per-field similarity features as per <code>comparatorSpec</code> and return an object with <code>fieldScore</code> (dictionary), <code>featuresRef</code> (evidenceRef persisted by <code>DQ_Evidence.PersistEvidenceBlob</code>), and <code>evidenceHash</code> (hash of serialized features). Implementation detail (from code): supports comparator labels <code>&quot;exact&quot;</code>, <code>&quot;tokenjaccard&quot;</code> (<code>DQ_Utilities.TokenJaccard</code>), <code>&quot;normedit&quot;</code> (<code>DQ_Utilities.NormalizedLevenshtein</code>), numeric cases and custom comparators via <code>gCompiledComparators</code> + <code>DQ_Utilities.RunCustomComparator</code>. For <code>&quot;exact&quot;</code> the code pushes blinded PII to features via <code>DQ_Utilities.BlindPII</code> before storing features. It serializes <code>features</code> via <code>SafeSerializeJSON</code> and persists them using <code>DQ_Evidence.PersistEvidenceBlob(...)</code> with key <code>&quot;compare:&quot; &amp; SafeHashFromString(correlationId)</code>. On evidence persist failure it emits <code>dq.match.comparepair.error</code> and returns safe defaults. <br><strong>Explainability & audit:</strong> emits <code>dq.match.comparepair</code> with <code>evidenceHash</code>. Features are encrypted in evidence store; only <code>evidenceHash</code> is in audit. <br><strong>Determinism & performance:</strong> pure, deterministic, and optimized to short-circuit where possible; host helper failures are caught and mapped to safe fallbacks. <br><strong>Tests:</strong> comparator correctness matrices, Unicode edge cases, and evidence-persist failure handling. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ComputeMatchScore(pairEvidenceRef, scoringModel)</code> — model-based scoring & explainability</strong><br><strong>Purpose & contract:</strong> retrieve per-field feature JSON from evidence store using <code>DQ_Evidence.RetrieveEvidence(pairEvidenceRef)</code>; parse via <code>TryParseJson</code> and aggregate contributions using weights (if provided in <code>scoringModel</code>) and optional host helpers (<code>DQ_Utilities.ExtractNumericFeature</code>, <code>DQ_Utilities.LogisticNormalize</code>, <code>DQ_Utilities.Clamp01</code>). Implementation behavior (per code): defensive retrieval and parsing, fallback numeric coercion if host helper fails, accumulation <code>total = Σ(w * featVal)</code>, compute <code>score</code> with host helpers when available, else local clamp fallback to [0,1]; returns dictionary <code>{score, modelVersion, featureContributions, topReasons}</code> where <code>topReasons</code> is obtained via host <code>DQ_Utilities.TopReasonsFromContrib</code> or empty array fallback. Emits <code>dq.match.scorecomputed</code> with <code>payloadHash</code> equal to hash of serialized output. On evidence retrieval failure emits <code>dq.match.score.error</code> and returns safe <code>score=0</code>. <br><strong>Governance:</strong> model deployments require <code>dq.match.model.deployed</code> audit and golden tests. <br><strong>Tests:</strong> calibration, numeric extraction fallback, top-reasons fallback behavior. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>DecideMatch(score, thresholds, datasetPolicy)</code> — deterministic decision mapping</strong><br><strong>Purpose & contract:</strong> map numeric <code>score</code> to <code>{MATCH, PROBABLE, REVIEW, NO_MATCH}</code> using thresholds loaded defensively from <code>thresholds</code> (Dictionary or generic object) with defaults <code>tMatch=0.9, tProb=0.75, tReview=0.5</code>. Implementation details: supports dataset policy bump for <code>regulated</code> datasets (+0.05 to <code>tMatch</code>) via generic <code>GetValueFromMeta</code> extraction; returns <code>{decision, rationale, appliedThresholds}</code> and emits <code>dq.match.decision</code>. Tie / boundary semantics are deterministic (>= comparisons used in code). <br><strong>Edge handling:</strong> uses deterministic equality-to-boundary behavior; 'rationale' includes policy adjustments. <br><strong>Tests:</strong> boundary/edge tests and regulated bump coverage. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ResolveTie(candidatePairs, tieBreakerSpec, deterministicSeed)</code> — canonical tie-break & multi-merge rules</strong><br><strong>Purpose & contract:</strong> deterministic resolution of ties using host helper <code>DQ_Utilities.ResolveTieDeterministic</code> when available; otherwise constructs deterministic seed <code>SafeHashFromString(gEngine.engineHash &amp; &quot;|&quot; &amp; deterministicSeed)</code>, falls back to local <code>DeterministicRNG</code> (VBA class <code>DeterministicRNGImpl</code> in project) and uses host wrapper when present. Returns <code>{winners, secondaryChoices, tieRationale}</code>. Emits <code>dq.match.resolvetie</code> with payload fingerprint. Implementation attempts host call twice (best-effort) before falling back. <br><strong>Governance & safety:</strong> if tie resolution would cross tenant/isolate PII, callers must escalate to <code>REVIEW</code>. <br><strong>Tests:</strong> seed parity, fallback RNG parity, N-way selection. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>BuildMergeProposal(primaryId, secondaryIds, resolutionSpec, engineMeta, ownerId, reverseMapRefs)</code> — canonical, immutable proposal</strong><br><strong>Purpose & contract (code-accurate):</strong> constructs a <code>MergeProposal</code> UDT instance (module-level Type) with fields filled, computes <code>estimatedImpact.rowsAffected</code> defensively (supports array, Collection, null), sets owner defaulting to <code>MODULE_OWNER</code> if not provided, sets <code>createdAt = Now</code>, builds canonical proposal dictionary via <code>BuildProposalCanonicalDict</code>, serializes via <code>SafeSerializeJSON</code>, computes <code>p.payloadHash = SafeHashFromString(canonicalProposalJson)</code> and <code>p.proposalId = &quot;proposal:&quot; &amp; p.payloadHash</code>. Persists canonical proposal evidence using <code>DQ_Evidence.PersistEvidenceBlob</code> and stores returned <code>evidenceRef</code> in the UDT. Emits audit <code>dq.merge.proposal.created</code> with <code>proposalId</code>, <code>payloadHash</code>, <code>evidenceRef</code>. Returns the UDT value (not an object reference). <br><strong>Immutability & idempotency:</strong> proposalId is canonical derived; identical inputs produce identical <code>payloadHash</code>. Full sanitized proposal stored only in evidence store; top-level persisted artifact stores only <code>payloadHash</code> and <code>evidenceRef</code>. <br><strong>Tests:</strong> canonicalization parity, reversePlan undo correctness, evidence persist failure handling. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>BuildProposalImpactHash(proposal)</code> — canonical fingerprint for CI & QA</strong><br><strong>Purpose & contract (code):</strong> converts proposal UDT to dictionary via <code>ProposalToDict</code>, calls host <code>DQ_Utilities.RedactPIIForHash</code> on serialized JSON, canonicalizes via host <code>DQ_Utilities.canonicalizeJson</code>, then hashes via <code>DQ_Utilities.HashSHA256</code> (host-preferred). Implementation expects host helpers but will surface errors if missing — callers must treat failure as non-fatal. <br><strong>Tests:</strong> deterministic hashing of redacted proposals across hosts. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>PersistProposal(proposal, persistenceBackend, correlationId)</code> — atomic persistence, idempotency, and checksums</strong><br><strong>Purpose & contract (code-accurate):</strong> attempts layered persistence:<br>1. Call <code>persistenceBackend.AtomicSaveArtifact</code> via <code>CallByName</code> (VbMethod) if a backend object is provided.<br>2. Fallback to <code>Application.Run(&quot;DQ_Export.AtomicSaveArtifact&quot;, ...)</code> if the backend object path is unavailable or fails.<br>3. Fallback to <code>Application.Run(&quot;AtomicSaveArtifact&quot;, ...)</code> as a last-resort compatibility path.<br>Normalizes raw results into a dictionary with <code>&quot;success&quot;: boolean</code>. Computes <code>artifactChecksum = SafeHashFromString(artifactJson)</code> prior to persistence; on success emits <code>dq.merge.proposal.persisted</code> including <code>proposalId</code> and <code>artifactChecksum</code>. Implements idempotency semantics: repeated calls with the same <code>proposalId</code> should return the already-persisted artifact (enforced by the upstream backend); the function maps heterogeneous raw return types (Boolean, Variant, Dictionary) into a canonical success/failure signal. On persistent failure emits <code>dq.merge.persist.error</code> and returns <code>{status:&quot;error&quot;, errorCode:&quot;DQ_ERR_PERSIST_FAIL&quot;}</code>. Retries are intentionally not handled here and are delegated to the caller/orchestrator; this function treats backend errors defensively and always logs via the audit subsystem.<br><strong>Recoverability & tests:</strong> verify backend shape detection, atomic-save failure handling, idempotency behavior on repeated <code>proposalId</code>, checksum stability, and correct normalization of diverse backend return types into a Boolean success indicator. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ScheduleOrApply(proposal, decisionContext)</code> — inline vs scheduled policy evaluation</strong><br><strong>Purpose & contract (design and code expectations):</strong> decide whether to apply inline using <code>SafeInvokeMergeHandler</code> or schedule via <code>JobSchedulerIntegration</code> based on <code>estimatedImpact.rows</code>, <code>requiresApproval</code>, <code>datasetPolicy.regulated</code>, <code>safeMode</code>, <code>operatorOverride</code>. Implementation note: <code>SafeInvokeMergeHandler</code> performs permission checks and inline application; for deferred jobs <code>PersistProposal</code>/<code>JobSchedulerIntegration</code> must be used to create canonical <code>jobDescriptor</code> and emit <code>job.persisted:&lt;jobId&gt;</code>. The UI-path must return quickly (<50ms target). <br><strong>Behavior:</strong> inline calls should short-circuit to scheduled job when <code>rowsAffected</code> exceeds inline thresholds (the code enforces <code>&gt;1000</code> in <code>SafeInvokeMergeHandler</code> as an example). <br><strong>Tests:</strong> decision parity near thresholds, scheduled job persistence, latency/fast-return tests. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>SafeInvokeMergeHandler(proposal, cancelToken, correlationId)</code> — protected inline execution frame</strong><br><strong>Purpose & contract (code-accurate):</strong> wrapper that: calls <code>EmitAudit &quot;dq.merge.handler.start&quot;</code>, validates permissions via <code>Application.Run(&quot;DQ_Permissions.ValidateUserPermissions&quot;, GetCurrentUserName(), ProposalToDict(proposal), Nothing)</code> (with fallbacks), denies and emits <code>dq.merge.permission.denied</code> if permission check fails, checks <code>estimatedImpact.rowsAffected</code> and defers to job if too large (<code>deferred_to_job</code> when rows > 1000), calls <code>ApplyMergeAtomic</code> and maps results into <code>{status:&quot;applied&quot;/&quot;failed&quot;/&quot;denied&quot;}</code> while emitting <code>dq.merge.completed</code> or <code>dq.merge.failed</code> accordingly. Exceptions are mapped to stable error codes via <code>MapErrToCode</code> and audited under <code>dq.merge.handler.error</code>. Must be non-blocking for small jobs, support cooperative cancellation via <code>cancelToken</code>, and never leak PII in <code>userHint</code> messages. <br><strong>Invariants:</strong> permission validation is best-effort host call with fallbacks; inline apply must not proceed when policy disallows inline or when <code>allowInlineApply</code> is false in <code>gEngine.meta</code> (returns <code>DQ_ERR_INLINE_APPLY_DISABLED</code>). <br><strong>Tests:</strong> permission-denied paths, deferred-to-job threshold, error mapping, cancellation behavior. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ApplyMergeAtomic(proposal, storageEngine, reversePlan)</code> — atomic mutation & undo</strong><br><strong>Purpose & contract (code-accurate):</strong> perform the actual dataset mutation or simulated apply: <br>• If <code>gEngine.meta.allowInlineApply</code> explicitly false → fail with <code>DQ_ERR_INLINE_APPLY_DISABLED</code>. <br>• Persist a before-snapshot via <code>DQ_Evidence.PersistEvidenceBlob</code> (keyed <code>&quot;apply:before:&quot; &amp; SafeHashFromString(proposal.proposalId&quot;</code>). <br>• Attempt to call <code>storageEngine.ApplyMerge(ProposalToDict(proposal))</code> if <code>storageEngine</code> provides the method (guarded by <code>Application.Run(&quot;DQ_Utilities.HasMethod&quot;, storageEngine, &quot;ApplyMerge&quot;)</code>). <br>• If <code>storageEngine</code> not provided or not present, simulate apply (safe mode) and return a fabricated apply result with <code>applyId</code>, <code>beforeChecksum</code>, <code>afterChecksum</code>, <code>artifactRef</code> persisted via <code>DQ_Evidence.PersistEvidenceBlob</code>. <br>• Emit <code>dq.merge.apply</code> on success and <code>dq.merge.apply.error</code> on failure. <br><strong>Undo & rollback:</strong> on failure, use <code>reversePlan</code> + persisted before-snapshot (<code>beforeRef</code>) to revert; code persists snapshots and artifactRefs to support rollback workflows. <br><strong>Tests:</strong> transactional integrity simulations, reversePlan replay tests, storage engine integration tests, crash-in-the-middle recovery. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>EmitMergeAudit(correlationId, proposalId, step, metadata)</code> — canonical audit anchor</strong><br><strong>Purpose & contract (code-accurate):</strong> canonical audit emitter for the module: builds audit payload (timestamp via <code>NowIsoUtc</code>, <code>module = MODULE_NAME</code>, <code>procedure</code> and <code>event</code>), computes <code>paramsHash</code> via host <code>DQ_Utilities.paramsHash</code> if available else <code>SafeHashFromString</code> and attempts host emit via <code>Application.Run(&quot;DQ_Audit.EmitAudit&quot;, auditPayload)</code> (non-blocking). Fallbacks: call <code>EmitExportAudit</code> (to <code>DQ_Export.AppendAuditRow</code>) when correlationId present, final fallback append minimal row to a hidden sheet <code>audit_tail</code> (via <code>GetOrCreateHiddenSheet(&quot;audit_tail&quot;)</code>). Errors are captured and written to <code>audit_errors</code> hidden sheet. <br><strong>Security & PII:</strong> top-level audit fields limited to hashes and <code>evidenceRef</code>; sensitive details persisted only in evidence store. <br><strong>Tests:</strong> host-fallback audit emission, hidden-sheet fallback, <code>audit_errors</code> logging. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>TryParseJson</code> / <code>ParseJsonFallback</code> / <code>SerializeJson</code> — robust JSON helpers</strong><br><strong>Purpose & contract (as-implemented):</strong> prefer host <code>DQ_Utilities.ParseJson</code>/<code>SerializeJSON</code> via <code>Application.Run</code> and fall back to project-level deterministic implementations: <code>ParseJsonFallback</code> uses VBScript.RegExp to extract top-level key/value pairs (safe, tolerant), <code>SerializeJson</code>/<code>SafeSerializeJSON</code> produce canonical JSON for dictionaries, collections and arrays (sort keys for Dictionaries using <code>QuickSortStringArray</code> and <code>GetSortedKeys</code>). <code>UnescapeJsonString</code> reverses JSON escapes including <code>\uXXXX</code> sequences. All parsers/serializers are defensive: they catch host failures, never throw to callers, and provide deterministic outputs for hashing and canonicalization. <br><strong>Determinism & invariants:</strong> key sorting code paths guarantee deterministic ordering used by <code>CanonicalHash</code> and <code>BuildProposalImpactHash</code>. <br><strong>Tests:</strong> parser fallback correctness, Unicode <code>\u</code> decoding tests, serializer parity with host where available. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>ComputePayloadHashStrict</code>, <code>ComputeSHA256</code>, <code>ComputeSHA256File</code>, <code>SafeHashFromString</code>, <code>CanonicalHash</code> — hashing primitives</strong><br><strong>Purpose & contract (code-accurate):</strong> clear separation between payload-string hashing and file hashing: <code>&lt;ComputePayloadHashStrict&gt;</code> rejects existing file-path strings (raises helpful error) and canonicalizes JSON when requested (tries <code>JsonCanonicalizeTopLevel</code>, host <code>DQ_Utilities.ParseJson</code>/<code>SerializeJson</code>, or falls back to <code>FallbackNormalizeText</code>) before computing bytes and delegating to <code>ComputePayloadHash_Bytes</code> (module’s internal bytes-hash helper). <code>ComputeSHA256</code> wraps <code>ComputePayloadHashStrict</code> for strict string hashing. <code>ComputeSHA256File</code> delegates to <code>ComputePayloadHash_File</code>/streaming file hashing. <code>SafeHashFromString</code> prefers host <code>DQ_Utilities.HashSHA256</code> then falls back to a simple FNV-like 32-bit textual hash (hex-8) as ultimate fallback. <code>CanonicalHash</code> attempts host canonicalizer <code>DQ_Utilities.canonicalizeJson</code> then falls back to <code>FallbackCanonicalizeJson</code>, <code>FallbackNormalizeText</code>, and host <code>HashSHA256</code> where possible. <br><strong>Invariants:</strong> hashing functions avoid ambiguous behavior by rejecting file-path-as-string inputs in strict path; file hashing uses explicit <code>ComputeSHA256File</code>. <br><strong>Tests:</strong> strict-file-path rejection, cross-host canonicalization parity, large-file streaming hash tests. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>DeterministicRNG(seed)</code> — fallback RNG wrapper</strong><br><strong>Purpose & contract:</strong> prefer host <code>DQ_Utilities.DeterministicRNG(seed)</code> via <code>Application.Run</code>; when unavailable instantiate local <code>DeterministicRNGImpl</code> COM class (project-provided) seeded with string seed; if both unavailable emits <code>dq.match.rng.fallback</code> and returns <code>Nothing</code>. Deterministic RNG used by tie-breaker and sampling. <br><strong>Tests:</strong> seed parity vs host RNG, fallback audit presence. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>LoadLastGoodEngineMeta()</code> — safe last-good meta loader</strong><br><strong>Purpose & contract (code):</strong> if <code>gLastGoodEngineEvidenceRef</code> is set attempt to <code>DQ_Evidence.RetrieveEvidence(gLastGoodEngineEvidenceRef)</code> and parse using host <code>DQ_Utilities.ParseJson</code> or <code>ParseJsonFallback</code>. On fallback parsing emits audit <code>dq.match.engine.meta.parse.fallback</code> and returns a Dictionary fallback object. If retrieval/parsing fails returns <code>Nothing</code>. Function is best-effort and never throws. <br><strong>Use:</strong> called by <code>InitMatchEngine</code> on init failure to provide safe fallback. <br><strong>Tests:</strong> evidence retrieval and fallback parsing. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> <strong><code>PersistProposal</code> / <code>ApplyMergeAtomic</code> / <code>SafeInvokeMergeHandler</code> error mapping & operator messages</strong><br><strong>Purpose & contract:</strong> consistent mapping of internal VB <code>Err.Number</code> to canonical error codes via <code>MapErrToCode</code> (tries <code>Application.Run(&quot;DQ_Error.LookupErrorCode&quot;, errNum)</code> then falls back to <code>DQ_ERR_INTERNAL_&lt;abs(err)&gt;</code>). All errors are emitted via <code>EmitAudit</code> with <code>dq.merge.*.error</code> events and include <code>correlationId</code> when available. Operator-facing messages are short, non-PII, and include <code>correlationId</code> for triage; storage of full diagnostics occurs via evidence store referenced by <code>evidenceRef</code>. <br><strong>Tests:</strong> ensure thrown errors map to ErrorCodeCatalog and audits are created. </td></tr><tr><td data-label="DQ_MatchMerge — Per-function Expert Technical Breakdown"> **<code>GetOrCreateHiddenSheet</code>, <code>EmitAudit</code> hidden-sheet fallback behavior<code> — UIless safe auditing**&lt;br&gt;**Behavior &amp; contract (code):** </code>EmitAudit<code> prefers host </code>DQ_Audit.EmitAudit<code>, then </code>EmitExportAudit<code> (host </code>DQ_Export.AppendAuditRow<code>), and finally writes a minimal row into hidden worksheet </code>audit_tail<code>. All errors are captured into </code>audit_errors<code> hidden sheet. </code>GetOrCreateHiddenSheet<code> ensures sheet is created and set to </code>xlSheetVeryHidden<code> to avoid accidental user view. This provides durable, local fallback in offline or host-missing environments. &lt;br&gt;**Tests:** audit fallback round-trip, hidden-sheet visibility and write robustness.   **</code>JobSchedulerIntegration(jobDescriptor)<code> — canonical job descriptor &amp; worker handoff**&lt;br&gt;**Purpose &amp; contract (code-expected):** create canonical </code>jobDescriptor<code> (</code>jobId, proposalId, correlationId, paramsHash, configHash, persistedAt, owner, retryPolicy<code>) and persist via </code>AtomicSaveArtifact<code> or </code>DQ_Export<code> path; idempotent persistence required; emit </code>job.persisted:<jobId><code>. Integration details delegated to host </code>JobSchedulerIntegration<code> or </code>DQ_Export<code>. &lt;br&gt;**Tests:** idempotency, descriptor canonicalization, worker handoff simulation.   **</code>ReconciliationRunner<code>, </code>MergeSimulationDryRun<code>, </code>PreviewMergeUI<code>, </code>AnonymizePreview<code>, </code>ForensicExport<code>, </code>ExportMergeArtifact<code> — simulation, preview &amp; export primitives**&lt;br&gt;**Purpose &amp; contract (code-expectations):** use canonical serialization and deterministic sampling (seeded RNG) to: simulate proposals (</code>MergeSimulationDryRun<code>) without side-effects, produce preview artifacts (</code>PreviewMergeUI<code>) with </code>previewHash<code>, perform redaction (</code>AnonymizePreview<code>) and persist evidence via </code>DQ_Evidence<code>. Forensic exports assemble canonical artifacts and persist via </code>REG_Export<code>/</code>DQ_Export<code> with </code>forensic_manifest.json<code>; upload/export uses </code>ExportMergeArtifact<code> semantics using host </code>REG_Export<code> where available. All flows must not expose PII in public audits and must use evidence store for full artifacts. &lt;br&gt;**Tests:** dry-run parity, preview vs apply parity, redaction gating, forensic manifest completeness.   **</code>MapErrToCode<code>, </code>ErrorCodeCatalog<code> &amp; operator-message mapping**&lt;br&gt;**Purpose &amp; contract (code):** </code>MapErrToCode<code> attempts host mapping (</code>DQ_Error.LookupErrorCode<code>) then falls back to </code>DQ_ERR_INTERNAL_<abs(errNum)><code>. Module defines canonical codes used throughout (</code>DQ_ERR_INIT_001<code>, </code>DQ_ERR_INIT_002<code>, </code>DQ_ERR_EVIDENCE_PERSIST<code>, </code>DQ_ERR_PERSIST_FAIL<code>, </code>DQ_ERR_APPLY_FAIL<code>, </code>DQ_ERR_INLINE_APPLY_DISABLED<code>, </code>DQ_ERR_EVIDENCE_RETRIEVE<code>, etc.). All emitted audits should include mapped </code>errorCode<code> and </code>correlationId<code>. Operator messages must be non-PII and include </code>correlationId<code> for triage. &lt;br&gt;**Tests:** mapping coverage, audit inclusion.   **</code>Shutdown()<code> — graceful unload, audit flush, and snapshot**&lt;br&gt;**Purpose &amp; contract (code):** flush any in-memory state, persist minimal snapshot (engine meta persisted earlier via </code>DQ_Evidence.PersistEvidenceBlob<code>), unregister test hooks, and emit </code>dq.match.shutdown<code>. On unclean restart </code>InitMatchEngine<code> should detect missing </code>dq.match.shutdown<code> and attempt </code>dq.match.recovery<code> flows (LoadLastGoodEngineMeta). &lt;br&gt;**Tests:** graceful shutdown, unclean restart recovery.   **Operator/CI &amp; governance cross-cutting notes (unchanged)**&lt;br&gt;All other non-function rows, policy, SLOs, runbooks, tests, governance, appendices, operator commands, and acceptance criteria remain as previously specified. The module-level metadata, SLOs, testing matrix, failure modes, operator runbooks, change-control, appendices and final notes are unchanged by this pass; the per-function entries above were revised to align precisely with the supplied VBA implementation: they reflect the actual host-call preference patterns (</code>Application.Run<code> fallbacks), evidence persistence calls (</code>DQ_Evidence.PersistEvidenceBlob<code>), audit emission logic (</code>EmitAudit<code> → host → fallback hidden-sheet), deterministic hashing/serialization helpers (</code>SafeSerializeJSON<code>, </code>CanonicalHash<code>, </code>ComputePayloadHashStrict<code>), and error mapping behaviors present in the code.   **Acceptance note (revision scope):**&lt;br&gt;1. This deliverable *only* revised the per-function rows to accurately reflect the code you supplied (host-prefers, fallbacks, error codes, audits, evidence persistence semantic). &lt;br&gt;2. I preserved all other descriptive rows, policies, SLOs, and governance text unchanged as requested. &lt;br&gt;3. If you want me to expand any single function row into line-by-line mapping to source lines (e.g., annotate which </code>Application.Run` host helper is attempted in which order), I can produce that as a follow-up block for that specific function only. </td></tr></tbody></table></div><div class="row-count">Rows: 24</div></div><div class="table-caption" id="Table3" data-table="Docu_0177_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Remediation — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Remediation — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong>Module-level summary — Purpose, owners, public API, guarantees, invariants, and audit obligations (exhaustive)</strong><br><strong>Purpose & contract:</strong> authoritative module for converting data-quality findings (from <code>DQ_Profile</code>, <code>DQ_Rules</code>, <code>DQ_MatchMerge</code>) into safe, auditable remediation workflows. Responsibilities: generate deterministic proposals with before/after previews; compute auditable risk/confidence scores; cluster and rank proposals for operator review; build canonical remediation plans with explicit transactional boundaries and undo descriptors; validate plans against policy, runtime and approvals; provide deterministic dry-run simulations; execute remediation inline (safe, short) or schedule heavy jobs; persist canonical job descriptors idempotently for workers; produce reversible undo artifacts or record explicit non-reversible signoffs; export artifacts atomically with checksums and redaction manifests; build forensic packages on failures; notify owners/stakeholders safely; and ensure every operator-visible action produces canonical, chained audit rows. Must not perform silent destructive mutations; must never display PII in UI/audit main fields; must store full evidence encrypted and reference via <code>evidenceRef</code> in audits.<br><strong>Owners / manifest:</strong> module owner(s) and API published in <code>OWNERS.md</code> and module manifest; versioned <code>module.manifestHash</code> must be recorded on major transitions. <br><strong>Exposed API (canonical):</strong> <code>GenerateProposal</code>, <code>ScoreProposal</code>, <code>RankAndGroupProposals</code>, <code>BuildRemediationPlan</code>, <code>ValidateRemediationPlan</code>, <code>SimulateApply</code> (dry-run), <code>IsLightweightAction</code>, <code>ApplyRemediation</code>, <code>PersistRemediationJob</code>, <code>SafeRemediationExecutor.execute</code>, <code>BuildUndoPlan</code>, <code>RevertRemediation</code>, <code>ValidateApprovals</code>, <code>BuildUiPreview</code>, <code>ExportRemediationArtifacts</code>, <code>NotifyOwnersAndStakeholders</code>, <code>ExportForensicsForFailedApply</code>, <code>SafeErrorToUser</code>, <code>RegisterUnitTestHook</code>. Each API must declare stable identifiers returned (<code>proposalId</code>, <code>planId</code>, <code>applyId</code>, <code>undoId</code>, <code>jobId</code>) and include <code>correlationId</code> in parameters or context. <br><strong>Primary invariants (must/shall):</strong><br>1. Determinism: given identical <code>tableRef</code>, <code>findings</code>, <code>configHash</code>, and <code>seed</code>, <code>GenerateProposal</code> and subsequent plan hashes must be identical. Canonical JSON (sorted keys, normalized numbers/dates) is used to compute SHA256-based <code>proposalHash</code> / <code>planHash</code> / <code>undoHash</code>.<br>2. Audit anchoring: every user-initiated action appends a <code>UserAction</code>/<code>dq_*</code> audit row with <code>correlationId</code> and safe <code>paramsHash</code>; full sanitized evidence stored encrypted with <code>evidenceRef</code> referenced by audit metadata.<br>3. No silent destructive changes: destructive operations must be explicitly <code>dq_apply</code>-audited and approved per governance rules.<br>4. Reversibility: destructive operations must produce <code>UndoPlan</code> or record explicit signed operator acknowledgement when undo impossible.<br>5. Sensitive data: UI hints and main audit messages must be PII-free; full sanitized evidence stored encrypted using KMS/HSM keys.<br>6. Performance budgets: proposal generation median <200ms for small tables (<10k rows), dry-run preview for 10k sample <2s, inline apply default timeout 5s (configurable).<br><strong>Audit obligations & schemas:</strong> <code>dq_proposal</code>, <code>dq_proposal.preview</code>, <code>dq_proposal.accepted</code>, <code>dq_plan.built</code>, <code>dq_plan.validate</code>, <code>dq_apply.start</code>, <code>dq_apply.dryrun</code>, <code>dq_apply.complete</code>, <code>dq_apply.failed</code>, <code>dq_apply.reverted</code>, <code>dq_undo.built</code>, <code>dq_export.remediation</code>, <code>forensic.export</code>, <code>dq_approval.*</code>. Each audit includes schema fields: <code>timestamp, correlationId, module=DQ_Remediation,procedure,operatorId,proposalId,planId,applyId,paramsHash,configHash,prevHash,payloadHash,artifactChecksum,metadata</code>. Evidence stored separately with <code>evidenceRef</code> and access controlled. <br><strong>CI/QA gating:</strong> golden-file parity for <code>proposalHash</code>/<code>planHash</code> on representative fixtures; static analyzer gating forbidding direct workbook writes during proposal/dry-run; unit/integration/infrastructure tests; <code>VerifyAuditChain</code> runs in CI. <br><strong>Checked 10×:</strong> canonicalization rules, audit presence, PII redaction, undo completeness, deterministic RNG seed propagation, idempotent job persistence, evidence encryption, manifest signature checks for <code>AUTO_APPLY</code>, approval validation flow, runbook triggers for failure modes. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>GenerateProposal(tableRef, findings[], options)</code> — canonical candidate synthesis (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function GenerateProposal(tableRef As Object, findings As Object, Optional options As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract (precise):</strong> produce deterministic <code>proposals</code> dictionary keyed by <code>proposalId</code> with each <code>proposal</code> containing <code>proposalId</code>, <code>ruleId</code>, <code>targetColumn</code>, <code>affectedCount</code>, <code>actions</code> (a <code>Scripting.Dictionary</code>), <code>sampleBefore[]</code>, <code>sampleAfterRedactedPreview[]</code>, <code>sampleAfterPreviewRef</code> (evidenceRef), <code>confidence</code>, <code>rationale</code>, <code>proposalHash</code>, and <code>evidenceRef</code>. Must be side-effect free (calls <code>EnsureSideEffectFreePath</code> at start). Returns empty <code>Scripting.Dictionary</code> if <code>findings</code> is <code>Nothing</code> or empty. Uses <code>gDeterministicSeed</code> or <code>options(&quot;seed&quot;)</code> for deterministic sampling.<br><strong>Exact deterministic mechanics used in code:</strong><br>1. Seed selection: <code>seed = options(&quot;seed&quot;)</code> if present else <code>gDeterministicSeed</code>; code writes back <code>gDeterministicSeed = seed</code>. Random numbers via <code>seededRand(seed)</code> (LCG implemented as 32-bit step) produce deterministic indices. <br>2. Proposal id derivation: <code>pid = &quot;proposal-&quot; &amp; ComputeSHA256(canonicalTableId &amp; &quot;|&quot; &amp; idx &amp; &quot;|&quot; &amp; ComputeSHA256(CanonicalSerialize(f)))</code>. <br>3. Action enumeration: calls host hook <code>Application.Run(&quot;DQ_Policy_EnumerateActions&quot;, f, preferNonDestructive)</code> and accepts <code>Scripting.Dictionary</code> result when available; deterministic fallback action created in-module if host hook unavailable. <br>4. Sampling & redaction: sample indices derived from <code>seed + idx</code>; <code>sampleBefore(i)</code> and <code>sampleAfter(i)</code> are generated as redacted placeholders via <code>RedactPII(...)</code>. Full sanitized sample stored encrypted via <code>EvidenceStore_SaveEncrypted(&quot;full-sanitized-sample-for-&quot; &amp; pid)</code> and the returned reference is stored in <code>p(&quot;sampleAfterPreviewRef&quot;)</code> and <code>p(&quot;evidenceRef&quot;)</code>. <br>5. Hashing: canonical serialization via <code>CanonicalSerialize(p)</code> then <code>ComputeSHA256(ser)</code> stored in <code>p(&quot;proposalHash&quot;)</code>. <br>6. Auditing: appends a minimal PII-free <code>dq_proposal</code> audit row via <code>AppendAuditRow &quot;dq_proposal&quot;, audPayload, cid, &quot;&quot;, &quot;&quot;</code> where <code>audPayload</code> includes <code>proposalId</code>, <code>proposalHash</code>, <code>affectedCount</code>, <code>evidenceRef</code> and <code>tableRef</code> canonicalized. <br><strong>Failure modes & behavior:</strong> defensive checks against missing <code>findings</code> and <code>tableRef</code>; returns empty proposals dictionary if <code>findings</code> missing. Best-effort policy hook usage; falls back deterministically if unavailable. <br><strong>Tests (code-accurate):</strong> ensure <code>proposalHash</code> parity across hosts for same <code>seed</code>, verify <code>EvidenceStore_SaveEncrypted</code> called when samples created, policy-hook fallback behavior. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ScoreProposal(proposal, scoringConfig)</code> — reproducible, explainable scoring (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ScoreProposal(proposal As Object, scoringConfig As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> mutate/augment <code>proposal</code> (shallow reference) with computed <code>confidence</code>, <code>risk</code>, <code>costEstimateMs</code>, <code>reversibility</code> and attach <code>scoreObj</code> containing <code>scoringConfigHash</code> and <code>scoreHash</code>. Score object canonicalized and hashed with <code>ComputeSHA256</code>. Must be deterministic given <code>proposal</code> and <code>scoringConfig</code>. <br><strong>Exact code behaviors:</strong><br>1. Feature extraction: <code>matchQuality</code> from <code>proposal(&quot;confidence&quot;)</code> if present, <code>coverage=affectedCount</code>, <code>ruleSeverity</code> fetched via <code>Application.Run(&quot;DQ_Rules_GetSeverity&quot;, out(&quot;ruleId&quot;))</code> if host hook available. <br>2. Weighting: uses <code>w_conf</code> and <code>w_cov</code> from <code>scoringConfig</code> if present; default weights applied otherwise. <code>confidence</code> computed as linear weighted sum plus clamp to [0,1]. <br>3. Risk: base risk increased when <code>dropRow</code> appears in <code>actions</code> (search via <code>InStr</code> on <code>CanonicalSerialize(out(&quot;actions&quot;))</code>), and <code>regMultiplier</code> added if <code>scoringConfig(&quot;regulatedFields&quot;)</code> match. <br>4. Cost estimation: <code>costEstimateMs = CLng(out(&quot;affectedCount&quot;)) * 2</code> (code defaults). <code>reversibility</code> default <code>True</code>. <br>5. Auditing: builds <code>scoreObj</code> and appends <code>dq_proposal.score</code> via <code>AppendAuditRow &quot;dq_proposal.score&quot;, scoreObj, cid, &quot;&quot;, &quot;&quot;</code>. <br><strong>Error handling:</strong> wrapped with <code>On Error GoTo ScoreErr</code>; errors map to <code>SafeErrorToUser(errCid, pid, &quot;ERR_SCORE_PROPOSAL&quot;)</code> and return <code>Nothing</code>. <br><strong>Tests (code-accurate):</strong> verify <code>scoreHash</code> stability, host hook behavior for rule severity, sensitivity tests for weights. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>RankAndGroupProposals(proposals[], rankingPolicy)</code> — cluster, deconflict, stable ordering (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function RankAndGroupProposals(proposals As Object, rankingPolicy As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> deterministic grouping by first-action target key, stable ordering of groups, computing <code>groupHash</code> via <code>ComputeSHA256(CanonicalSerialize(grp))</code> and emitting <code>dq_proposal.grouping</code> audits for each group. Returns a <code>Scripting.Dictionary</code> mapping <code>groupId</code> → <code>grp</code> object. <br><strong>Exact algorithm used in code:</strong><br>1. Iterate <code>proposals.keys</code>; for each proposal fetch <code>actions</code> and pick the first action (first key in actions dictionary) as representative <code>firstAction</code>. <br>2. Use <code>actionKey = firstAction(&quot;target&quot;)</code> (or <code>&quot;unknown&quot;</code>) as grouping key; group membership stored in <code>System.Collections.ArrayList</code> per key. <br>3. Assign <code>group-&lt;n&gt;</code> ids sequentially; each <code>grp</code> includes <code>groupId</code>, <code>proposalIds</code> (a <code>Collection</code>), <code>affectedFields</code> array, <code>affectedCount</code>, <code>impactSummary</code>, <code>estimatedTimeMs</code>, <code>groupConfidence</code>, <code>groupHash</code>. <br>4. Append audit row <code>dq_proposal.grouping</code> for each group. <br><strong>Stability & ordering:</strong> grouping derives from deterministic iteration of <code>proposals.keys</code> (VBA Scripting.Dictionary order is deterministic in this code path) and <code>groupHash</code> included to stabilize ordering when sorting externally. <br><strong>Tests:</strong> grouping determinism under permutations of input keys, correctness of <code>proposalIds</code> collection type, audit emissions. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>BuildRemediationPlan(group, operatorChoices, applyMode)</code> — concrete plan generation with undo wiring (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function BuildRemediationPlan(group As Object, operatorChoices As Object, applyMode As String, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> compose <code>plan</code> dictionary with <code>planId = &quot;plan-&quot; &amp; ComputeSHA256(group(&quot;groupId&quot;) &amp; &quot;|&quot; &amp; format(Now, &quot;yyyymmddhhmmss&quot;))</code>, <code>actions</code> (Collection of canonical step dictionaries), <code>transactionalBoundaries</code>, <code>undoPlanDescriptor</code> produced by <code>BuildUndoPlan(plan)</code>, <code>requiredApprovals</code>, <code>estimatedDurationMs</code>, and <code>planHash = ComputeSHA256(CanonicalSerialize(plan))</code>. Append <code>dq_plan.built</code> audit. <br><strong>Construction details from code:</strong><br>1. Each proposal id in <code>group(&quot;proposalIds&quot;)</code> produces a step <code>s</code> with <code>stepId</code>, <code>type=&quot;transform&quot;</code>, <code>targetSpec=&quot;by-proposal:&lt;pid&gt;&quot;</code>, <code>payload=&quot;payload-here&quot;</code>, <code>preconditions</code>, <code>postchecks</code>, <code>estimatedCostMs</code>, <code>sideEffects</code> marker. <br>2. <code>transactionalBoundaries</code> set to <code>Array(&quot;per-group-copy-swap&quot;)</code> by default for safe destructive handling. <br>3. <code>undoPlanDescriptor</code> is built synchronously via <code>BuildUndoPlan(plan)</code>. <br>4. Audit: <code>AppendAuditRow &quot;dq_plan.built&quot;, plan, cid, &quot;&quot;, &quot;&quot;</code>. <br><strong>Edge-cases & error handling:</strong> on exception, code calls <code>SafeErrorToUser(errCid, planIdForErr, &quot;ERR_BUILD_PLAN&quot;)</code> and returns <code>Nothing</code>. <br><strong>Tests:</strong> ensure <code>planHash</code> deterministic across runs given same inputs (note <code>Now</code> in planId introduces time variance; tests should freeze <code>Now</code> or assert canonicalization excludes volatile fields where required). </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ValidateRemediationPlan(plan, runtimeContext)</code> — preflight safety & enforcement (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ValidateRemediationPlan(plan As Object, runtimeContext As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> returns a <code>Scripting.Dictionary</code> with <code>valid:Boolean</code>, <code>errors:Collection</code>, <code>warnings:Collection</code>, <code>enforcementAction</code> and performs checks mirrored in code: schema integrity (recompute <code>planHash</code> via <code>ComputeSHA256(CanonicalSerialize(plan))</code>), precondition checksum verification via host <code>Application.Run(&quot;CORE_Data_GetCurrentChecksum&quot;, workbookId, sheet)</code>, job-scheduler availability <code>CORE_JobScheduler_IsAvailable</code>, approvals via <code>ValidateApprovals</code>, and concurrency locks via <code>CORE_Concurrency_CheckLocks</code>. Appends <code>dq_plan.validate</code> audit with <code>planHash</code>. <br><strong>Exact enforcement rules coded:</strong><br>1. Missing or mismatched <code>planHash</code> => <code>valid = False</code>, <code>enforcementAction = &quot;fail-closed&quot;</code>, error <code>R_PLAN_001_CHECKSUM_MISMATCH</code>. <br>2. If <code>plan(&quot;applyMode&quot;) = &quot;staged-job&quot;</code> and job scheduler unavailable => <code>R_PLAN_002_JOB_SCHEDULER_UNAVAILABLE</code>. <br>3. If <code>requiredApprovals</code> present and <code>ValidateApprovals</code> returns not allowed => <code>R_PLAN_003_APPROVALS_MISSING</code>. <br>4. If concurrency lock detected (<code>CORE_Concurrency_CheckLocks</code>) => <code>R_PLAN_004_CONCURRENCY_LOCK</code>. <br><strong>Behavior on errors:</strong> error handling maps to <code>SafeErrorToUser</code> with code <code>ERR_VALIDATE_PLAN</code> and returns <code>Nothing</code>. <br><strong>Tests:</strong> checksum mismatch path, approval-required path, job-scheduler absence path, concurrency lock. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>SimulateApply(plan, simulatorConfig)</code> — deterministic dry-run & reconciliation (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function SimulateApply(plan As Object, simulatorConfig As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> non-destructive simulation guarded by <code>EnsureSideEffectFreePath</code>; returns <code>sim</code> dictionary with <code>planId</code>, <code>sampleBefore</code>, <code>sampleAfter</code>, <code>previewRef</code> (evidenceRef from <code>EvidenceStore_SaveEncrypted</code>), <code>reconciliationReport</code>, and <code>previewHash</code>. Must persist a <code>dq_apply.dryrun</code> audit with <code>previewHash</code> and link to <code>plan(&quot;planHash&quot;)</code> where available. <br><strong>Code-level details:</strong><br>1. Handles <code>plan</code> = <code>Nothing</code> defensively: returns preview with <code>simulate:missing-plan</code> evidenceRef and <code>reconciliationReport(&quot;summary&quot;)=&quot;plan-missing&quot;</code>. <br>2. Sampling uses <code>gDeterministicSeed</code> or <code>simulatorConfig(&quot;seed&quot;)</code>. Creates small deterministic sample arrays and stores full simulation evidence via <code>EvidenceStore_SaveEncrypted(&quot;simulate:&quot; &amp; sim(&quot;planId&quot;))</code>. <br>3. <code>previewHash</code> computed as <code>ComputeSHA256(CanonicalSerialize(sim))</code>. <br>4. Errors route to <code>SafeErrorToUser(errCid, planIdForErr, &quot;ERR_SIMULATE_APPLY&quot;)</code> and return <code>Nothing</code>. <br><strong>Tests:</strong> verify side-effect free guarantee, evidenceRef presence, previewHash parity for fixed seed. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>IsLightweightAction(plan)</code> — policy evaluation for inline vs scheduled execution (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function IsLightweightAction(plan As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> returns dictionary <code>{lightweight:Boolean, rationale:String, decisionHash}</code> using <code>gDefaultInlineTimeoutMs</code> fallback (and <code>DEFAULT_INLINE_TIMEOUT_MS</code>) with decision rule implemented in code: <code>res(&quot;lightweight&quot;) = (est &gt; 0 And est &lt; timeoutMs And risk &lt; 0.2 And Not affectsRegulated)</code> where <code>est = CLng(plan(&quot;estimatedDurationMs&quot;))</code> and <code>risk = CDbl(plan(&quot;risk&quot;))</code>. Appends <code>dq.apply.decision</code> audit with <code>planHash</code>. <br><strong>Notes on code specifics:</strong> computes <code>affectsRegulated</code> by scanning <code>CanonicalSerialize(a)</code> for <code>&quot;regulated&quot;</code>. <code>decisionHash = ComputeSHA256(CanonicalSerialize(res))</code>. <br><strong>Tests:</strong> assert boundary decisions around <code>timeoutMs</code>, <code>risk=0.2</code>, and regulated influence. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ApplyRemediation(plan, operatorContext)</code> — authoritative apply orchestrator (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ApplyRemediation(plan As Object, operatorContext As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> wrapper/orchestrator that: builds <code>applyId = &quot;apply-&quot; &amp; ComputeSHA256(planId &amp; &quot;|&quot; &amp; format(Now, &quot;yyyymmddhhmmss&quot;))</code>, emits <code>dq_apply.start</code>, idempotency-checks stored apply via <code>Application.Run(&quot;DQ_Store_GetApplyRecord&quot;, applyId)</code>, runs <code>ValidateRemediationPlan</code>, decides inline vs scheduled via <code>IsLightweightAction</code>, executes inline via <code>SafeRemediationExecutor_Execute</code> or schedules via <code>CORE_JobScheduler_PersistJob</code>/<code>PersistRemediationJob</code>, persists results where available, and emits <code>dq_apply.complete</code> or <code>dq_apply.failed</code>. Returns <code>execRes</code> or job descriptor. <br><strong>Idempotency & persistence behaviors in code:</strong><br>1. Checks <code>DQ_Store_GetApplyRecord(applyId)</code> and if present returns existing result and emits <code>dq_apply.duplicate</code>. <br>2. Inline execution path calls <code>SafeRemediationExecutor_Execute</code>; on success persists apply record via <code>Application.Run &quot;DQ_Store_PersistApplyRecord&quot;, execRes</code> (best-effort). <br>3. Scheduled path builds <code>jobDesc</code> with <code>jobId = &quot;job-&quot; &amp; ComputeSHA256(planId &amp; &quot;|&quot; &amp; timestamp)</code>, <code>paramsHash = ComputeSHA256(CanonicalSerialize(plan))</code>, calls <code>CORE_JobScheduler_PersistJob</code> and appends <code>job.persisted</code> audit. <br><strong>Failure mapping & triage:</strong> maps errors to <code>SafeErrorToUser(cid, planId, &quot;ERR_APPLY&quot;)</code>, emits <code>dq_apply.failed</code>, and triggers forensic export on severe failure. <br><strong>Tests:</strong> idempotency with same <code>applyId</code>, inline success/fail paths, scheduled job persistence behavior. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>PersistRemediationJob(jobDescriptor)</code> — canonical job persistence & idempotency (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function PersistRemediationJob(jobDescriptor As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> check for existing job by <code>paramsHash</code> via <code>Application.Run(&quot;CORE_JobScheduler_FindJobByParamsHash&quot;, jobDescriptor(&quot;paramsHash&quot;))</code> and if found returns existing <code>jobId</code>; otherwise uses <code>CORE_Utilities_AtomicWriteJobDescriptor</code> to persist and emits <code>job.persisted</code> audit. Returns dictionary <code>{jobId, persisted:Boolean}</code>. <br><strong>Failure & retry behavior in code:</strong> best-effort <code>On Error Resume Next</code> guards around host calls; on exception records <code>persisted = False</code> and still appends audit with that flag. On persistent failure, the upper caller is expected to create forensic artifacts. <br><strong>Tests:</strong> idempotency test that repeated calls with same <code>paramsHash</code> return identical <code>jobId</code>; simulated <code>CORE_...</code> unavailability produces <code>persisted=False</code>. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>SafeRemediationExecutor_Execute(plan, cancellationToken)</code> — protected inline execution frame (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function SafeRemediationExecutor_Execute(plan As Object, cancellationToken As Variant, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> inline executor implementing staging-first semantics: create staging evidence <code>stagingRef = EvidenceStore_SaveEncrypted(&quot;staging:&quot; &amp; applyId)</code>, per-step checkpoint audits <code>dq_handler.step.start</code> and <code>dq_handler.step.complete</code>, cooperative cancellation via <code>cancellationToken(&quot;cancelRequested&quot;)</code>, per-step duration capture, simulated work (<code>DoEvents</code> in code) and final <code>artifactRef = EvidenceStore_SaveEncrypted(&quot;artifact:&quot; &amp; applyId)</code>. Returns <code>res</code> with <code>status</code>, <code>applyId</code>, <code>beforeChecksum</code>, <code>afterChecksum</code>, <code>stepDurations</code>, <code>artifactRef</code>. Emits <code>dq_handler.complete</code> on success and <code>dq_handler.exception</code> on failures; error mapping to <code>SafeErrorToUser</code> uses code <code>ERR_EXECUTE</code>. <br><strong>Execution specifics present in code:</strong><br>1. Steps enumerated from <code>plan(&quot;actions&quot;)</code> (Collection); for each step compute <code>stepHash = ComputeSHA256(CanonicalSerialize(step))</code> and append start/complete audits. <br>2. Cancellation: if <code>cancellationToken(&quot;cancelRequested&quot;) = True</code> then append <code>dq_handler.step.cancelled</code> and return <code>status=&quot;cancelled&quot;</code>. <br>3. On exception, builds <code>errObj</code> with <code>error</code>, <code>applyId</code>, <code>status=&quot;failed&quot;</code>, appends <code>dq_handler.exception</code>, calls <code>SafeErrorToUser</code> and returns the <code>errObj</code>. <br><strong>Safety & non-IO contract:</strong> executor simulates work in-process but staging/commit steps should be host-implemented for actual writes; code uses evidence store calls for persisted artifacts. <br><strong>Tests:</strong> cancellation, step checkpoint audits presence, artifactRef generation. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>BuildUndoPlan(plan)</code> — deterministic undo descriptor & preimage capture (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function BuildUndoPlan(plan As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> produce <code>undo</code> dictionary with <code>undoId = &quot;undo-&quot; &amp; ComputeSHA256(plan(&quot;planId&quot;) &amp; &quot;|&quot; &amp; timestamp)</code>, <code>reversible = True/False</code>, <code>undoSteps</code> (Collection for reversed actions), <code>preimageEvidenceRef</code> produced per-undo-step via <code>EvidenceStore_SaveEncrypted(&quot;preimage:&quot; &amp; us(&quot;undoStepId&quot;))</code>, <code>undoPlanHash = ComputeSHA256(CanonicalSerialize(undo))</code>, <code>retentionTtlDays = 90</code> (default). Append <code>dq_undo.built</code> audit with <code>planHash</code>. <br><strong>Reversibility policy encoded:</strong> if plan includes external side-effects, code sets <code>reversible = False</code> and callers must require elevated approvals. <br><strong>Tests:</strong> verify undo preimage evidence references are produced and <code>undoPlanHash</code> reproducible for same inputs; retention metadata present. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>RevertRemediation(applyId, operatorContext)</code> — safe revert & gating (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function RevertRemediation(applyId As String, operatorContext As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> locate <code>applyRecord</code> via <code>Application.Run(&quot;DQ_Store_GetApplyRecord&quot;, applyId)</code>; if not found return failure with <code>reason=&quot;applyRecordNotFound&quot;</code> and <code>dq_apply.revert.failed</code> audit. If found validate current checksum via <code>CORE_Data_GetCurrentChecksum</code> (best-effort); if mismatch produce <code>forensicUri</code> via <code>ExportForensicsForFailedApply(applyId, &quot;checksum_mismatch&quot;)</code>, set <code>rec(&quot;forensicUri&quot;)</code> and return failed record (no blind revert). If checks match, call <code>BuildUndoPlan(applyRecord(&quot;plan&quot;), cid)</code> and <code>SafeRemediationExecutor_Execute(undoPlan, Nothing, cid)</code> to perform revert; on success append <code>dq_apply.revert.complete</code>, on failure append <code>dq_apply.revert.failed</code> and create forensic export via <code>ExportForensicsForFailedApply(applyId, &quot;revert_failed&quot;)</code>. <br><strong>Safety rules enforced in code:</strong> explicit pre-check of <code>afterChecksum</code> match before attempting revert; on mismatch the function fails safely and returns forensic pointer. Error handler maps to <code>SafeErrorToUser(NewCorrelationId, applyId, &quot;ERR_REVERT&quot;)</code>. <br><strong>Tests:</strong> revert happy path, checksum mismatch behavior, forensic export invocation. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ValidateApprovals(plan, approvals[])</code> — RBAC & two-person enforcement (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ValidateApprovals(plan As Object, approvals As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> returns dictionary with <code>allowed:Boolean</code>, <code>missingRoles:Collection</code>, <code>denialReason</code>, <code>validatedApprovals</code>. Implementation in code inspects <code>plan(&quot;requiredApprovals&quot;)</code> and for each required role iterates provided <code>approvals</code> to match by <code>a(&quot;role&quot;) = req(&quot;role&quot;)</code>; verifies signature by calling <code>Application.Run(&quot;CORE_Approvals_VerifySignature&quot;, a)</code> if host hook exists (best-effort — infra absence treated permissive in code). If required roles missing, <code>allowed=False</code> and <code>denialReason=&quot;missing_roles&quot;</code>. Appends <code>dq_approval.validate</code> audit before returning. <br><strong>Edge-cases & tests:</strong> expired or missing approvals cause <code>missingRoles</code> to be populated; host verification hook absence results in permissive fallback in this implementation (note: governance should avoid this fallback in production). Error mapping uses <code>SafeErrorToUser</code> with <code>ERR_VALIDATE_APPROVALS</code>. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>BuildUiPreview(plan, simulationResult)</code> — redacted, paginated preview artifacts for operator UX (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function BuildUiPreview(plan As Object, simulationResult As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> enforces <code>EnsureSideEffectFreePath</code>, builds a <code>preview</code> dictionary with <code>planId</code>, <code>diffSummary</code>, <code>fieldImpactSummary</code>, <code>inlineExamples</code> (from <code>simulationResult(&quot;sampleAfter&quot;)</code> when present), <code>confidenceBadge</code> inferred from <code>plan(&quot;estimatedDurationMs&quot;)</code>, and <code>previewHash = ComputeSHA256(CanonicalSerialize(preview))</code>. Appends <code>dq_proposal.preview</code> audit with <code>preview</code> and <code>prevHash = plan(&quot;planHash&quot;)</code> where available. <br><strong>PII & UI rules:</strong> redaction enforced (call-sites should ensure <code>simulationResult</code> sample entries are already redacted); preview must be small and support pagination via <code>previewCursor</code> in other UI helpers (not in this function). Error handler calls <code>SafeErrorToUser(errCid, pIdForErr, &quot;ERR_UI_PREVIEW&quot;)</code>. <br><strong>Tests:</strong> preview parity vs SimulateApply, redaction verification. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ExportRemediationArtifacts(plan, applyResult, destinationUri, operatorId)</code> — atomic export & chain-of-custody (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ExportRemediationArtifacts(plan As Object, applyResult As Object, destinationUri As String, operatorId As String, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> computes <code>out(&quot;artifact.checksum&quot;) = ComputeSHA256(&quot;artifact:&quot; &amp; plan(&quot;planId&quot;))</code>, attempts a best-effort atomic write via host <code>Application.Run(&quot;CORE_Storage_AtomicWrite&quot;, destinationUri, CanonicalSerialize(plan), CanonicalSerialize(applyResult))</code>, record <code>out(&quot;atomicWriteOk&quot;)</code> boolean, append <code>dq_export.remediation</code> audit with <code>destinationUri</code>, <code>artifact.checksum</code> and <code>operatorId</code>. Returns <code>out</code> with <code>exported = True</code> and <code>atomicWriteOk</code> flag. On error <code>SafeErrorToUser(NewCorrelationId, planId, &quot;ERR_EXPORT_ARTIFACTS&quot;)</code> and return <code>Nothing</code>. <br><strong>Redaction & governance:</strong> function expects caller to pass sanitized <code>plan</code>/<code>applyResult</code> (or evidenceRefs present); regulated exports should have prior approvals. <br><strong>Tests:</strong> verify call to <code>CORE_Storage_AtomicWrite</code>, assert checksum computed, and audit emission. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>NotifyOwnersAndStakeholders(plan, applyId, channelHints)</code> — minimal, auditable notifications (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function NotifyOwnersAndStakeholders(plan As Object, applyId As String, channelHints As Object, Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> builds <code>out</code> with <code>applyId</code>, <code>notified=True</code>, <code>channels=channelHints</code>, appends <code>notification.audit</code> via <code>AppendAuditRow</code> with <code>planHash</code>, and returns <code>out</code>. Delivery semantics and retry are delegated to host gateway; this function's contract is to record intent and emit audit. Error mapping to <code>ERR_NOTIFY</code>. <br><strong>Tests:</strong> ensure audit includes <code>applyId</code> and <code>channels</code> and does not include PII. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>ExportForensicsForFailedApply(applyId, failureContext)</code> — authoritative forensic package (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function ExportForensicsForFailedApply(applyId As String, failureContext As String, Optional correlationId As String) As String</code>.<br><strong>Purpose & contract:</strong> builds <code>forensicUri = &quot;forensic://&quot; &amp; applyId &amp; &quot;/&quot; &amp; timestamp</code>, creates <code>manifest</code> dictionary with <code>applyId, failureContext, timestamp, fingerprint = ComputeSHA256(CanonicalSerialize(manifest))</code>, persists <code>ref = EvidenceStore_SaveEncrypted(CanonicalSerialize(manifest))</code> as <code>manifest(&quot;evidenceRef&quot;)</code>, appends <code>forensic.export</code> audit and returns <code>forensicUri</code>. On error returns empty string. <br><strong>Tests:</strong> ensure <code>evidenceRef</code> returned and audit emitted; manifest fingerprint matches serialized content. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(correlationId, applyId, errorCode)</code> — user-safe mapping & triage guidance (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Sub SafeErrorToUser(correlationId As String, applyId As String, errorCode As String)</code>.<br><strong>Purpose & contract:</strong> map known <code>errorCode</code> to short user message <code>userMsg</code>, redact via <code>RedactPII</code>, append <code>dq.userErrorShown</code> audit containing <code>correlationId, applyId, errorCode, messageShown</code>, and show <code>MsgBox userMsg</code> (best-effort, wrapped by <code>On Error Resume Next</code>). Known mappings present in code include <code>ERR_PLAN_VALIDATE</code> and <code>ERR_REVERT_CHECKSUM_MISMATCH</code>; default message uses <code>errorCode</code> and <code>correlationId</code>. Must not reveal internal stack traces or PII. <br><strong>Tests:</strong> validate audit emission and PII redaction of message. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName, goldenCid)</code> — CI deterministic harness (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function RegisterUnitTestHook(hookName As String, goldenCid As String) As Boolean</code>.<br><strong>Purpose & contract:</strong> guard-enabled test hook registration: checks <code>CORE_Config_IsTestEnvironment</code> via <code>Application.Run</code> (best-effort), set <code>gTestHookEnabled = True</code> and <code>gTestHookCorrelationId = goldenCid</code> only when <code>isTestEnv = True</code>, append <code>dq_test.hook.registered</code> audit with <code>hookName</code> and <code>goldenCid</code>, return <code>True</code> on success; otherwise return <code>False</code>. Error handling returns <code>False</code>. <br><strong>Tests:</strong> ensure hook cannot be registered outside test environment; audit emitted on registration. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>SelfCheck_TwentyFiveChecks(Optional correlationId)</code> — CI self-check harness (code-accurate)</strong><br><strong>Signature in-code:</strong> <code>Public Function SelfCheck_TwentyFiveChecks(Optional correlationId As String) As Object</code>.<br><strong>Purpose & contract:</strong> run 25 lightweight integration probes that assert presence/availability of dependencies and core behaviors (e.g., <code>GetConfigHash</code>, <code>DQ_Audit_AppendAuditRow</code>, <code>CORE_Evidence_SaveEncrypted</code>, <code>CORE_JobScheduler_PersistJob</code>, <code>ComputeSHA256</code>, <code>CanonicalSerialize</code> sample, <code>seededRand</code> etc.), collect results into <code>report</code> dictionary, append <code>dq_selfcheck.twentyfive</code> audit, and return <code>report</code>. Uses mock helper functions defined in-module (<code>MockTableRef</code>, <code>MockFindings</code>, <code>MockPlan</code>, <code>MockSim</code>, <code>MockProposal</code>, <code>MockJobDesc</code>) to exercise workflows without side-effects. <br><strong>Tests & CI usage:</strong> run in CI to validate host integration and feature gating; outputs short diagnostic strings that can be parsed by automation. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>Mock helpers (MockTableRef, MockFindings, MockGroup, MockPlan, MockSim, MockProposal, MockJobDesc)</code> — non-destructive fixtures (code-accurate)</strong><br><strong>Purpose & contract:</strong> deterministic, side-effect free fixtures used only by <code>SelfCheck_TwentyFiveChecks</code> and unit tests. Provide simple, small dictionaries/collections matching real input contracts; not for production use. Each returns typed <code>Scripting.Dictionary</code> or <code>Collection</code> with minimal fields used by other functions. <br><strong>Tests:</strong> ensure mock outputs are consumed successfully by <code>GenerateProposal</code>, <code>BuildRemediationPlan</code>, <code>SimulateApply</code>, <code>ScoreProposal</code>, and <code>PersistRemediationJob</code> calls in self-check. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>Operator UX &amp; triage notes (concise operator commands)</code> — practical actions</strong><br><strong>Best practices:</strong> always capture <code>proposalId</code> and <code>applyId</code> for support. Prefer <code>copy</code> mode when uncertain. Limit inline applies to low-risk operations. <br><strong>Representative commands:</strong><code>remediation preview --proposal &lt;proposalId&gt;</code>, <code>remediation simulate --plan &lt;planId&gt; --seed &lt;n&gt;</code>, <code>remediation apply --plan &lt;planId&gt; --mode copy --operator &lt;id&gt; --ticket &lt;ticketId&gt;</code>, <code>remediation revert --apply &lt;applyId&gt; --operator &lt;id&gt;</code>. <br><strong>Triage steps:</strong> 1) get <code>correlationId</code> and <code>applyId</code>, 2) pull <code>dq_apply.*</code> and <code>dq_plan.*</code> audits, 3) retrieve <code>evidenceRef</code>/<code>forensic_manifest</code>, 4) reproduce via <code>SimulateApply</code>, 5) revert if safe or escalate. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>Change-control &amp; governance (remediation)</code> — required approvals & release flow</strong><br><strong>Flow:</strong> PR + migration manifest for policy changes to <code>RemediationPolicy</code> or scoring; run static analyzer, unit/integration/golden tests; compliance signoffs required for regulated changes; sign artifacts; publish release manifest. Hot-swap of handlers requires smoke tests and <code>dq_proposal</code> golden checks before canary. <br><strong>Blocking conditions:</strong> golden/audit-chain failures, missing undo for destructive actions, unsigned <code>AUTO_APPLY</code> changes. <br><strong>Artifacts:</strong> <code>migration_manifest.json</code>, <code>release.manifest</code>, signed <code>module.manifestHash</code>, owners list in <code>OWNERS.md</code>. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong><code>Security &amp; PII policy (detailed)</code> — encryption, signing, and secrets</strong><br><strong>Principles:</strong> do not show raw PII in UI or main audit rows. Store sanitized evidence encrypted with KMS/HSM-managed keys; <code>evidenceRef</code> included in audits. Automated <code>AUTO_APPLY</code> policies for regulated data require signed manifests and recorded approvals. Logging and telemetry must redact PII at collection time. Secrets must be retrieved via <code>modSecurity.getEphemeralToken()</code> during deferred init; never persist raw secrets. <br><strong>Examples:</strong> merges on SSN require two-person approval and encrypted evidence retention; export redacts sensitive columns if operator lacks export privilege. <br><strong>Tests:</strong> KMS integration, redaction fuzzing, signature verification. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong>Appendices & canonical schemas</strong><br><strong>Canonical JSON Schemas (summary):</strong><br>&nbsp;&nbsp;<code>Proposal</code> — <code>{proposalId, proposalHash, actions[], affectedCount, confidence, evidenceRef, createdAt}</code>.<br>&nbsp;&nbsp;<code>RemediationPlan</code> — <code>{planId, planHash, actions[], preconditions[], postchecks[], undoPlanDescriptor, estimatedDurationMs}</code>.<br>&nbsp;&nbsp;<code>UndoPlan</code> — <code>{undoId, undoSteps[], preimageEvidenceRef, undoChecksum, retentionTtl}</code>.<br>&nbsp;&nbsp;<code>JobDescriptor</code> — <code>{jobId, planId, applyId, paramsHash, persistedAt, evidenceRef, owner}</code>.<br>&nbsp;&nbsp;<code>AuditRow</code> — <code>{timestamp, correlationId, module, procedure, operatorId, proposalId, planId, applyId, paramsHash, configHash, prevHash, payloadHash, artifactChecksum, metadata}</code>.<br><strong>Artifact storage & governance:</strong> store artifacts under <code>\\artifacts\DQ_Remediation\releases\{version}\</code> and evidence under secure repo <code>\\evidence\DQ_Remediation\{year}\{month}\</code> with strict RBAC. Release manifests and signed module manifests archived; CI <code>VerifyAuditChain</code> runs nightly. <br><strong>Operator runbooks & cheat-sheets:</strong> include <code>triage-remediation.md</code>, <code>revert-checklist.md</code>, <code>forensics-collection.md</code> in appendices. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong>Final developer pre-merge checklist (exhaustive)</strong><br>1. Unit tests for each changed function. <br>2. Integration tests covering proposal→dry-run→apply→revert audit chain. <br>3. Golden fixtures updated and verified for <code>proposalHash</code>/<code>planHash</code>. <br>4. Static analyzer checks: no forbidden APIs in critical paths (no workbook writes in proposal/dry-run). <br>5. All user-visible transitions emit <code>dq_*</code> audits. <br>6. UndoPlan present for destructive plans or explicit signed acknowledgement recorded. <br>7. Config and scoring changes produce <code>configHash</code> and recorded in audits. <br>8. Performance budgets validated in integration tests. <br>9. Security review for PII exposure, KMS encryption, and manifest signing. <br>10. <code>OWNERS.md</code> updated and release manifest signed. </td></tr><tr><td data-label="DQ_Remediation — Per-function Expert Technical Breakdown"> <strong>Operator & SRE quick runbooks (condensed actionable steps)</strong><br><strong>Failed apply (partial):</strong> 1) capture <code>correlationId</code>, <code>applyId</code>; 2) retrieve <code>dq_apply.*</code> & <code>dq_plan.*</code> audits; 3) fetch <code>forensic_manifest</code> and evidence; 4) attempt <code>RevertRemediation(applyId)</code> if safe; 5) if revert impossible, escalate to SRE with <code>forensicUri</code>. <br><strong>Revert checksum mismatch:</strong> do not auto-revert; collect full forensic bundle and escalate. <br><strong>Maintenance:</strong> monthly audit rotation verification, nightly golden parity checks, quarterly disaster recovery drills. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table4" data-table="Docu_0177_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Export — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Export — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Top-line summary (one line):</strong> Deterministic, auditable, idempotent, resumable, policy-driven export pipeline for corrected datasets and companion artifacts; built for cryptographic provenance (KMS/HSM), quarantine on partial commits, predictable manifests for golden testing, and clear operator/SRE recovery flows. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Scope & audience:</strong> This document is a per-function, operationally-focused technical specification intended for implementers (backend engineers, SRE, security engineers), test authors, compliance officers, and operators who will run and triage DQ_Export in production. It presumes familiarity with object stores, multipart uploads, HSM/KMS signing, RBAC patterns, append-only audit paradigms, and secure evidence storage. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Design goals (prioritized):</strong><br>1. <strong>Reproducibility & determinism</strong> — identical inputs produce identical artifacts and canonical digests across platforms and locales.<br>2. <strong>Auditability</strong> — every user action anchored by <code>dq_export.requested</code> and full chain of <code>dq_export.*</code> audit rows; <code>prevHash</code> chaining where possible and rotation signing enforced.<br>3. <strong>Idempotency</strong> — dedupe by <code>exportRequestId</code>; safe <code>force</code> semantics recorded as approvals.<br>4. <strong>Safety / Fail-closed for regulated artifacts</strong> — signatures, approvals, and retention guarantees enforced; inability to satisfy policies results in quarantine/failure, never silent degradation.<br>5. <strong>Resumability & low-memory streaming</strong> — support multi-GB exports with part-level digests and persisted upload session state for cross-process resume.<br>6. <strong>Minimal PII exposure</strong> — audits contain only <code>payloadHash</code> and <code>evidenceRef</code>; full sanitized payloads stored encrypted with RBAC. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Global contracts & invariants (module-level):</strong><br>- <code>dq_export.requested</code> audit MUST be emitted prior to heavy work.<br>- <code>exportRequestId</code> dedupes identical requests; if the same <code>exportRequestId</code> arrives, return canonical <code>exportId</code> unless <code>force=true</code> with recorded approvals.<br>- Atomic visibility to consumers must be preserved: either all artifacts visible or none; partial visibility is treated as an incident and quarantined.<br>- Evidence retention and forensic packaging must be available for every terminal failed/quarantined export. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>High-level function list (canonical API surface):</strong><br><code>ExportDataset(entryContext)</code> — orchestrator & idempotency gate.<br><code>BuildExportDescriptor(exportRequest)</code> — canonical descriptor + hash generation.<br><code>ValidatePermissions(operatorId, exportDescriptor)</code> — RBAC + approvals gate.<br><code>ValidateDestination(destination)</code> — capability probe & credential fingerprinting.<br><code>ValidateExportFormat(format, datasetSchema)</code> — format suitability & <code>formatPlan</code> generation.<br><code>PrepareStagingArea(exportDescriptor)</code> — secure staging creation, lockfile, ephemeral encryption key lifecycle.<br><code>SerializeArtifacts(datasetSnapshot, formatPlan, stagingHandle)</code> — deterministic streaming serializer for data, reports, and manifests.<br><code>ComputeChecksum(path, algorithms[])</code> — per-part and aggregate checksum computation.<br><code>SignArtifact(artifactPaths, signerPolicy)</code> — KMS/HSM detached-sign orchestration and policy enforcement.<br><code>MultipartUploadManager(destinationHandle)</code> — resumable part upload manager with persisted session state.<br><code>AtomicSwap(stagingHandle, destinationHandle, artifacts)</code> — backend-specific commit semantics (pointer update / rename / pointer metadata write).<br><code>PersistExportMetadata(exportDescriptor, artifactManifest, destinationUris)</code> — durable exports index & metadata write.<br><code>EmitExportAudit(correlationId, step, payloadHash, metadataRef?)</code> — canonical audit writer with <code>prevHash</code> chaining and redaction policy.<br><code>QuarantineAndFallback(exportId, failingArtifacts, ctx)</code> — quarantine, forensic preservation, fallback artifact generation.<br><code>ResumeExport(exportId)</code> — resume orchestration based on persisted state markers.<br><code>RollbackExport(exportId, reason)</code> — governance path and two-person approval enforcement for destructive restores.<br><code>NotifyConsumers(exportId, artifactUris, channels)</code> — idempotent notifications to downstream consumers with receipt tracking.<br><code>MonitorExportProgress(exportId, hook)</code> — progress telemetry and hook invocation.<br><code>CleanupTemp(stagingHandle, keepEvidenceTTL)</code> — secure wipe and GC.<br><code>RetryWithBackoff(operation, policy)</code> — standardized retry wrapper with circuit-breaker semantics. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>State machine (canonical states, invariants, TTLs):</strong><br><code>REQUESTED</code> — created by <code>ExportDataset</code>; <code>dq_export.requested</code> emitted. Invariant: <code>exportRequestId</code> exists; TTL: short (minutes) to detect blocked/queued exports.<br><code>DESCRIPTOR_CREATED</code> — canonical <code>descriptorHash</code> persisted. Invariant: descriptor immutable and persisted atomically for dedupe.<br><code>PERMISSION_VALIDATED</code> — RBAC checks complete; if approvals missing → <code>BLOCKED</code>. Invariant: approval artifacts referenced by <code>descriptor.requiredApprovals</code>.<br><code>STAGING_PREPARED</code> — staging directory and exclusive <code>staging.lock</code> present. Invariant: unique staging path, optional per-export ephemeral encryption key created.<br><code>SERIALIZING</code> — streaming writes in progress with per-part markers; <code>staging.manifest.partial</code> updated incrementally.<br><code>CHECKSUMS_COMPUTED</code> — per-part and aggregate checksums computed and stored in <code>manifest.json</code>.<br><code>SIGNED</code> — optional state; for regulated exports mandatory; <code>signerFingerprint</code> attached to metadata.<br><code>COMMIT_ATTEMPT</code> — pre-commit verification done and commit in-flight using backend-specific commit patterns.<br><code>COMMITTED</code> — commit succeeded and metadata persisted; <code>dq_export.commit.completed</code> emitted.<br><code>COMPLETED</code> — notifications delivered; <code>dq_export.completed</code> emitted; retention scheduled.<br><code>QUARANTINED</code> — partial/failed commit: artifacts moved to <code>quarantine/&lt;exportId&gt;</code>; <code>dq_export.quarantine</code> emitted and SRE/compliance alerted.<br><code>ROLLED_BACK</code> — roll back executed successfully per governance rules; <code>dq_export.rollback</code> emitted.<br><code>FAILED</code> — terminal failure with <code>forensic_manifest</code> persisted; <code>dq_export.failed</code> emitted. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ExportDataset(entryContext)</code> — orchestrator (detailed behavior & invariants)</strong><br><strong>Purpose:</strong> canonical public entrypoint for requests from UI or job scheduler. Idempotent by <code>exportRequestId</code> and authoritative for initiating audit chain.<br><strong>Contract:</strong> always persist descriptor and emit <code>dq_export.requested</code> before heavy, irreversible work. Return <code>{status, exportId, correlationId, shortMessage}</code>; shortMessage must be UI-safe (PII-free) and contain correlation id.<br><strong>Detailed flow:</strong><br>1. <strong>Immediate anchor:</strong> generate <code>correlationId</code>; persist minimal request envelope; emit <code>dq_export.requested</code> audit row with <code>correlationId</code> and <code>exportRequestId</code> to anchor user action.<br>2. <strong>Dedupe check:</strong> check <code>exportRequestId</code> in <code>exports_index</code>. If existing terminal export (COMPLETED/FAILED/ROLLED_BACK) and <code>force</code> not set → return canonical <code>exportId</code> and terminal status. If <code>force=true</code> verify operator approvals and record approval evidence before proceeding.<br>3. <strong>Descriptor creation:</strong> call <code>BuildExportDescriptor(exportRequest)</code> which returns canonical <code>descriptor</code> and <code>descriptorHash</code>; persist descriptor atomically and emit <code>dq_export.descriptor.created</code>.<br>4. <strong>Permissions & approvals:</strong> run <code>ValidatePermissions(operatorId, descriptor)</code>. If <code>allowed=false</code> return <code>status:blocked</code> plus <code>requiredApprovals</code> (UI-safe) and keep <code>descriptor</code> persisted with <code>BLOCKED</code> state. If <code>allowed=true</code> continue.<br>5. <strong>Destination & format validation:</strong> run <code>ValidateDestination(destination)</code> and <code>ValidateExportFormat(format, datasetSchema)</code> to produce <code>capabilitySet</code> and <code>formatPlan</code>. If destination lacks required capabilities for atomic commit, plan fallback commit semantics and record risk in descriptor metadata.<br>6. <strong>Staging:</strong> call <code>PrepareStagingArea(descriptor)</code> to create <code>stagingPath</code> and <code>staging.lock</code>; emit <code>dq_export.staging.created</code> audit row including <code>stagingPath</code> fingerprint and optional ephemeral encryption key fingerprint.<br>7. <strong>Preview (if requested):</strong> if <code>options.preview</code> is true, run <code>DryRunExport</code> with deterministic sample; produce preview artifacts but do not run commit; return preview artifact URIs and <code>status:preview</code> with <code>exportId</code> and <code>correlationId</code>.<br>8. <strong>Execution mode decision:</strong> compute <code>IsLightweightAction</code> (policy-driven) to decide inline vs background. For background persist job descriptor (canonical <code>jobId</code>) and return <code>status:in-progress</code> with <code>exportId</code> and resume tokens. For inline, proceed with serialization and commit within request lifecycle subject to timeouts.<br>9. <strong>Serialization → checksum → sign → upload → commit:</strong> run <code>SerializeArtifacts</code> (streaming), <code>ComputeChecksum</code>, <code>SignArtifact</code> (if required by <code>signPolicy</code>), <code>MultipartUploadManager</code> to upload parts, <code>AtomicSwap</code> to commit, <code>PersistExportMetadata</code> to persist metadata, <code>NotifyConsumers</code>, and finally <code>EmitExportAudit</code> terminal rows. Update <code>exports_index</code> with final status <code>COMPLETED</code> and TTL-based retention scheduling. <br><strong>Failure handling & guarantees:</strong><br>- Emission of <code>dq_export.requested</code> is mandatory before heavy action; used for triage if system crashes mid-work.<br>- On transient failures (network errors), persist partial state in staging and job descriptor so <code>ResumeExport</code> can pick up. <br>- On irrecoverable or policy failures (signature failure for regulated artifacts, or missing approvals), fail-closed and call <code>QuarantineAndFallback</code> where applicable. <br><strong>Observability & metrics:</strong> emit step-level spans and metrics (<code>dq_export.duration_ms</code>, <code>dq_export.serialize.ms</code>, <code>dq_export.upload_rate_bps</code>, <code>dq_export.retry_count</code>). Log structured events with <code>correlationId</code>. <br><strong>Tests:</strong> idempotency vectors, blocked-by-approvals simulation, inline small-run success, persist-job resume test. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>BuildExportDescriptor(exportRequest)</code> — canonical descriptor rules, persistence & diagnostics (REVISED to reflect code)</strong><br><strong>Purpose:</strong> produce and persist the canonical descriptor object used for dedupe, hashing, provenance and audits — implemented by constructing a VBA <code>Dictionary</code>, serializing via <code>DescriptorToCanonicalJson</code>, hashing via <code>ComputeSHA256FromString</code>, and persisting via <code>PersistDescriptorAtomic</code>.<br><strong>Inputs:</strong> <code>exportRequest</code> (Dictionary-like object expected to contain keys used in code: <code>exportRequestId</code>, <code>producerModule</code>, <code>producerVersion</code>, <code>datasetRef</code>, <code>datasetSnapshotHash</code>, <code>format</code>, <code>artifactNames</code>, <code>estimatedSizeBytes</code>, <code>configHash</code>, <code>ribbonMapHash</code>, <code>owner</code>, <code>sensitivityLevel</code>, <code>retentionPolicyId</code>, <code>requiredApprovals</code>, <code>destination</code>, <code>credFingerprint</code>, <code>correlationId</code>).<br><strong>Outputs:</strong> descriptor Dictionary with fields: <code>exportId</code>, raw fields above, plus <code>descriptorJson</code>, <code>descriptorHash</code>, and <code>exportTsUtc</code>; on failure returns an object containing <code>error</code> (set to <code>DQ_ERR_INTERNAL</code>).<br><strong>Behavioral details (code-accurate):</strong><br>- Generates <code>exportId</code> as <code>&quot;e-&quot; &amp; CreateUUID()</code>.<br>- Builds <code>d</code> as a <code>Scripting.Dictionary</code> with explicit field population from <code>GetValueSafe</code> fallback for missing fields.<br>- Serializes using <code>DescriptorToCanonicalJson</code> which concatenates fields in a fixed, explicit order (the function hardcodes the ordering and uses <code>Quote</code>/<code>QuoteArray</code>).<br>- Computes <code>descriptorHash</code> via <code>ComputeSHA256FromString</code> (temp-file + <code>ComputeSHA256</code> wrapper).<br>- Persists descriptor via <code>PersistDescriptorAtomic(exportId, canonicalJson)</code>; on persist failure sets <code>d(&quot;error&quot;) = DQ_ERR_INTERNAL</code> and returns <code>d</code> (non-exceptional).<br>- Emits <code>dq_export.descriptor.created</code> audit via <code>EmitExportAudit</code> with <code>correlationId</code>, <code>&quot;dq_export.descriptor.created&quot;</code>, <code>dh</code>, and <code>exportId</code>.<br><strong>Side-effects:</strong> writes atomic descriptor file to <code>/exports/&lt;exportId&gt;/descriptor.json</code> (via REG_Utilities.AtomicWrite fallback to local temp folder), emits audit row.<br><strong>Errors & edge-cases:</strong><br>- Missing input keys tolerated via <code>GetValueSafe</code> defaulting; persistent write failures return <code>error</code> field rather than raising.<br>- Collisions are handled outside this function (persist attempt returns failure if unable).<br><strong>Tests (code-level):</strong> canonical JSON string content parity (independent of VBA Dictionary iteration order), descriptor hash deterministic for same inputs, persist fallback path (REG_Utilities unavailable), audit emission observed. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>DescriptorToCanonicalJson(d As Object)</code> — canonical JSON builder (code-accurate)</strong><br><strong>Purpose:</strong> produce byte-stable JSON string for descriptor using explicit field order implemented in code rather than dynamic key-sorting.<br><strong>Inputs:</strong> <code>d</code> dictionary with canonical descriptor fields.<br><strong>Outputs:</strong> canonical JSON string assembled by concatenation; never uses <code>JsonConverter</code> — instead builds JSON token-by-token using <code>Quote</code> and <code>QuoteArray</code> helpers.<br><strong>Behavioral notes (exact implementation):</strong><br>- The function concatenates keys in a fixed, hard-coded sequence matching the module's design (explicit list in code).<br>- <code>Quote</code> escapes backslash, double-quote, CRLF/CR/LF to <code>\n</code>, and tab to <code>\t</code> (no Unicode escaping beyond control chars).<br>- <code>QuoteArray</code> supports VBA arrays and <code>Collection</code> objects and returns <code>[]</code> for empty values.<br><strong>Side-effects:</strong> none; pure string builder.<br><strong>Edge cases:</strong> Non-string values coerced to <code>CStr</code> in calling code where required; if missing keys, <code>GetValueSafe</code> earlier ensures defaults are present. <br><strong>Tests:</strong> canonical JSON equals golden string for representative inputs; <code>Quote</code>/<code>QuoteArray</code> escape tests for special characters. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>PersistDescriptorAtomic(exportId, canonicalJson)</code> — atomic write fallback (code-accurate)</strong><br><strong>Purpose:</strong> persist descriptor JSON atomically using preferred host helper <code>REG_Utilities.AtomicWrite</code>, with robust local fallback using <code>Scripting.FileSystemObject</code> and binary write.<br><strong>Behavior (as implemented):</strong><br>- Attempts <code>Application.Run &quot;REG_Utilities.AtomicWrite&quot;, &quot;/exports/&quot; &amp; exportId &amp; &quot;/descriptor.json&quot;, canonicalJson</code> first.<br>- If external call fails (err.Number ≠ 0), falls back to creating a folder under <code>%TEMP%\dq_export\exports\&lt;exportId&gt;</code> and writes <code>descriptor.json</code> via <code>Open ... For Binary Access Write</code> + <code>Put</code> (not fsync/rename safe but acceptable as fallback in code).<br>- Returns <code>True</code> on success, <code>False</code> on any failure (exception caught and leads to <code>PersistDescriptorAtomic = False</code>).<br><strong>Side-effects:</strong> writes files under TEMP area if helper unavailable; does not attempt to atomically rename in fallback; caller must treat fallback as less durable. <br><strong>Edge-cases & tests:</strong> simulate <code>REG_Utilities</code> missing to confirm fallback path, verify <code>descriptor.json</code> content matches canonical input. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ValidatePermissions(operatorId, exportDescriptor)</code> — RBAC + approvals (code-accurate)</strong><br><strong>Purpose:</strong> ask host <code>REG_Permissions.CheckOperatorForExport</code> and fallback to minimal local rule (owner allowed) when external service unavailable.<br><strong>Inputs:</strong> <code>operatorId</code> (String), <code>exportDescriptor</code> (Dictionary-like).<br><strong>Outputs:</strong> object <code>{allowed:Boolean, requiredApprovals:Array?, denialReason?:String}</code>; on internal failure returns <code>{allowed=False, denialReason=DQ_ERR_INTERNAL}</code>.<br><strong>Behavioral details:</strong><br>- First tries <code>Application.Run &quot;REG_Permissions.CheckOperatorForExport&quot;, operatorId, exportDescriptor</code> and if no error sets <code>allowed=True</code> and returns immediately.<br>- If external call fails, falls back to: if <code>exportDescriptor(&quot;owner&quot;)</code> equals <code>operatorId</code> (case-insensitive), allow; otherwise set <code>allowed=False</code> and produce <code>requiredApprovals</code> array with a single approval item <code>CreateApprovalItem(&quot;data_owner&quot;, &quot;Owner approval required&quot;)</code> and <code>denialReason</code> string.<br>- Emits <code>dq_export.permission.check</code> audit row (using <code>EmitExportAudit</code>) with <code>descriptorHash</code> and <code>operatorId</code> present regardless of outcome.<br><strong>Side-effects:</strong> emits audit; does not mutate descriptor except logging approvals requirement externally.<br><strong>Tests:</strong> host permission service success path (mock <code>REG_Permissions</code>), fallback owner-allowed case, fallback blocked case producing <code>requiredApprovals</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>CreateApprovalItem(role, reason)</code> — approval artifact builder (code-accurate)</strong><br><strong>Purpose:</strong> small helper returning a <code>Scripting.Dictionary</code> with <code>role</code> and <code>reason</code> fields used by <code>ValidatePermissions</code> fallback.<br><strong>Behavior:</strong> pure, deterministic object creation. <br><strong>Tests:</strong> simple unit test for returned dictionary content. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ValidateDestination(destination)</code> — capability probe & compatibility mapping (code-accurate)</strong><br><strong>Purpose (as implemented):</strong> map <code>destination(&quot;type&quot;)</code> to capability flags for commit strategy and return a <code>caps</code> dictionary indicating <code>rename</code>, <code>multipart</code>, <code>versioning</code>, <code>pointerAtomic</code>, and <code>retention</code>. Minimal connectivity/credential probing is not performed in the provided code; the function maps based on <code>type</code> only and emits an audit row via <code>EmitExportAudit</code> with <code>correlationId</code> supplied in <code>destination</code> where present.<br><strong>Supported types (per code):</strong> <code>local_fs</code>, <code>s3</code>, <code>gcs</code>, <code>azure_blob</code>. Unknown types set <code>valid=False</code> and add a <code>warnings</code> array element.<br><strong>Outputs:</strong> <code>out</code> dictionary with <code>valid</code> boolean, <code>capabilities</code> dictionary, <code>recommendedCommitStrategy</code>, <code>credFingerprint</code>, optional <code>warnings</code>.<br><strong>Behavioral notes & limitations:</strong><br>- The implementation in code <em>does not</em> perform remote <code>head</code>/write probes; capability detection is static and conservative based on <code>type</code> string. <br>- Emits <code>dq_export.destination.validated</code> audit via <code>EmitExportAudit</code> (note: correlationId pulled from destination object if present).<br><strong>Tests:</strong> mapping correctness for supported <code>type</code> values; ensure <code>credFingerprint</code> copied from destination. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>PrepareStagingArea(exportDescriptor)</code> — secure staging creation & lock semantics (code-accurate)</strong><br><strong>Purpose:</strong> create per-export staging folder under <code>%TEMP%\dq_export\staging\&lt;exportId&gt;\&lt;Application.caption&gt;</code>, write <code>staging.lock</code> JSON and create empty <code>staging.manifest.partial</code> file. This function implements lock creation and basic folder setup – it does not implement platform-level ACL enforcement nor KMS key allocation in current code.<br><strong>Inputs:</strong> <code>exportDescriptor</code> (Dictionary expected to carry <code>exportId</code> and <code>correlationId</code>).<br><strong>Outputs:</strong> dictionary <code>{stagingPath, stagingLockRef}</code> or <code>{error: DQ_ERR_DISK_SPACE}</code> on failure.<br><strong>Behavioral details:</strong><br>- Constructs <code>stagingRoot = Environ(&quot;TEMP&quot;) &amp; &quot;\dq_export\staging\&quot; &amp; exportId &amp; &quot;\&quot; &amp; Application.caption</code> and creates folder via <code>Scripting.FileSystemObject</code>.<br>- Writes <code>staging.lock</code> with JSON containing <code>exportId</code>, <code>correlationId</code>, <code>ownerPid</code> (uses <code>Application.caption</code> as a coarse process identifier), <code>hostId</code> from <code>Environ(&quot;COMPUTERNAME&quot;)</code>, <code>startTsUtc</code> and <code>lockTTL</code> set to 3600.<br>- Creates <code>staging.manifest.partial</code> as an empty file to accumulate part markers later.<br>- Emits <code>dq_export.staging.created</code> audit row with the <code>stagingPath</code> fingerprint. <br><strong>Side-effects:</strong> creates local staging folder and files under TEMP; does not attempt to encrypt staging (KMS hooks are not present in code).<br><strong>Errors & edge-cases:</strong> if folder creation or file writes fail (e.g., no disk space) returns <code>{error = DQ_ERR_DISK_SPACE}</code>. <br><strong>Tests:</strong> staging folder creation, <code>staging.lock</code> content shape, handling when TEMP not writable. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ValidateExportFormat(format, datasetSchema)</code> — format plan & canonicalization (code-accurate)</strong><br><strong>Purpose:</strong> return <code>formatPlan</code> for supported formats in the code: <code>&quot;csv&quot;</code>, <code>&quot;parquet&quot;</code>, and <code>&quot;xlsx&quot;</code>. Produces deterministic rules and a <code>formatPlanHash</code> computed from <code>deterministicRules</code> via <code>ComputeSHA256FromString</code>.<br><strong>Inputs:</strong> <code>format</code> string, <code>datasetSchema</code> (unused in code path aside from potential future checks).<br><strong>Outputs:</strong> dictionary fields depending on format: <code>writesAsSingleFile</code>, <code>chunkingAllowed</code>, <code>chunkSizeBytes</code>, <code>compressionAlgorithm</code>/<code>deterministicRules</code>, and <code>formatPlanHash</code>; on unknown format returns <code>{error = DQ_ERR_INVALID_DEST}</code>.<br><strong>Behavior:</strong> populates deterministic serialization rules for each supported format (CSV/Parquet/XLSX) and emits <code>dq_export.format.validated</code> audit (note: correlationId passed as empty string in code).<br><strong>Tests:</strong> canonical deterministicRules hash equals expected value; invalid format path returns DQ_ERR_INVALID_DEST. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>SerializeArtifacts(datasetSnapshot, formatPlan, stagingHandle)</code> — deterministic streaming serialization (code-accurate)</strong><br><strong>Purpose:</strong> primary serialization routine implemented for two input cases in code: <code>Range</code> (Excel Range) and non-Range (string fallback). For Range it writes chunked <code>.part.N</code> files (CSV lines) using <code>chunkSizeBytes</code> from <code>formatPlan</code>; for others writes a single NDJSON-like artifact file.<br><strong>Inputs:</strong> <code>datasetSnapshot</code> (VBA <code>Range</code> or scalar), <code>formatPlan</code> (dictionary containing <code>chunkSizeBytes</code>), <code>stagingHandle</code> (dictionary with <code>stagingPath</code>).<br><strong>Outputs:</strong> dictionary <code>{manifestPath, manifestHash}</code> on success or <code>{error = DQ_ERR_INTERNAL}</code> on failure.<br><strong>Behavioral details (exact implementation):</strong><br>- Ensures <code>stagingPath</code> exists, sets <code>artifactName=&quot;dataset&quot;</code>, then:<br>• If <code>datasetSnapshot</code> is a <code>Range</code>: reads header row from first row, iterates rows 2..rowsCount, builds comma-joined <code>line</code> strings using <code>.Text</code> from cells and appends lines to the current part file; uses <code>chunkSizeBytes</code> to decide when to rotate to a new part file; when closing a part computes its SHA256 via <code>ComputeSHA256(ppath)</code> and appends a part record via <code>AppendPartRecord</code>.<br>• If <code>datasetSnapshot</code> is not a Range: writes the entire <code>CStr(datasetSnapshot)</code> into a single <code>artifactName.ndjson</code> file and computes SHA256 and append part record.<br>- After parts written, builds <code>manifest.json</code> via <code>BuildManifestFromPartial(stagingPath)</code> and writes it via binary write; returns <code>manifestPath</code> and <code>manifestHash</code> (computed via <code>ComputeSHA256</code>).<br>- Emits <code>dq_export.serialized</code> audit using <code>EmitExportAudit</code> with <code>stagingHandle(&quot;exportId&quot;)</code> (if set), the manifest hash and path.<br><strong>Side-effects:</strong> creates part files, updates <code>staging.manifest.partial</code>, creates manifest file; uses binary writes (<code>Open ... For Binary Access Write</code>) and <code>Print #</code> for lines.<br><strong>Errors & edge-cases:</strong><br>- If <code>Range</code> details (rows/cols counts) are large, the routine uses <code>Print</code>/<code>Open</code> loops — memory usage is bounded but performance depends on host Excel speed.<br>- Uses <code>ComputeSHA256</code> for each part; if <code>ComputeSHA256</code> fails it returns an error object via <code>Fail</code> path. <br><strong>Tests:</strong> serialization for small Range and large Range split across parts, correctness of <code>staging.manifest.partial</code> entries, manifest JSON structure via <code>BuildManifestFromPartial</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>AppendPartRecord(stagingPath, artifactName, partIndex, partPath, checksum)</code> — part manifest append (code-accurate)</strong><br><strong>Purpose:</strong> append a single-line part record to <code>staging.manifest.partial</code> in the exact pipe-delimited shape used by <code>BuildManifestFromPartial</code> (<code>artifactName|partIndex|partPath|checksum</code>).<br><strong>Behavior:</strong> opens file for append and prints line ending with newline; no JSON is used here — it is a simple pipe-delimited log used by <code>BuildManifestFromPartial</code>. <br><strong>Edge-cases:</strong> function uses <code>On Error Resume Next</code> to swallow IO errors; callers must validate the final manifest. <br><strong>Tests:</strong> part record appended and can be read by <code>BuildManifestFromPartial</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>BuildManifestFromPartial(stagingPath)</code> — manifest builder from partial records (code-accurate)</strong><br><strong>Purpose:</strong> read <code>staging.manifest.partial</code> lines (pipe-delimited records) and emit a compact JSON object <code>{&quot;artifacts&quot;:[{name,partIndex,path,sha256},...]}</code> as a string.<br><strong>Behavioral details:</strong><br>- Opens <code>staging.manifest.partial</code> for <code>Input</code>, reads each line into <code>lines()</code> array, splits each line by <code>&quot;|&quot;</code> and maps to JSON entries appended into <code>sb</code> string. Uses minimal validation: requires <code>UBound(parts) &gt;= 3</code> to include an entry.<br>- On any failure returns <code>&quot;{}&quot;</code> as fallback (code's <code>Fail</code> label).<br><strong>Notes & limitations:</strong> output JSON is assembled manually and does not escape strings; the function assumes part paths/checksums contain no <code>&quot;</code> characters. <br><strong>Tests:</strong> well-formed partial file -> correct JSON; malformed lines are skipped; ensure <code>BuildManifestFromPartial</code> returns "{}" when file unreadable. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ComputeChecksum(filePath, Optional algorithms)</code> — per-part & aggregated digests (code-accurate)</strong><br><strong>Purpose:</strong> compute per-block digests by reading the file in 64KB chunks, compute a SHA256 per chunk by writing each chunk to a temp file and invoking <code>ComputeSHA256</code> on that temp file (implementation detail), then compute an aggregate digest by concatenating the hex digests and hashing that concatenation.<br><strong>Inputs:</strong> <code>filePath</code> (string), <code>algorithms</code> (ignored in code; default behavior is SHA256).<br><strong>Outputs:</strong> dictionary <code>{artifactName, sizeBytes, partCount, partDigests[], aggregateDigest}</code> or <code>{error:&quot;FILE_NOT_FOUND&quot;}</code> when missing.<br><strong>Behavioral notes (exact steps):</strong><br>- Uses <code>Scripting.FileSystemObject</code> to get file size and loops reading from file using binary <code>Get</code> into a <code>buffer</code> string of exact <code>toRead</code> size.<br>- For each block writes <code>buffer</code> to a temp file <code>dq_export_chunk_&lt;UUID&gt;.tmp</code>, calls <code>ComputeSHA256(tmp)</code> which shells out to <code>REG_Utilities</code> or <code>certutil</code>, reads the hex result into <code>hs(partIdx)</code>, deletes the tmp file, and continues until EOF.<br>- Concatenates <code>hs(i)</code> strings into <code>concatHex</code>, writes that into another temp file and calls <code>ComputeSHA256(tmp2)</code> to obtain the <code>aggregate</code> digest; deletes tmp2 and returns aggregate and part digests.<br>- Emits <code>dq_export.checksums</code> audit row with the <code>aggregate</code> digest and <code>filePath</code> via <code>EmitExportAudit</code> (passing empty correlationId in code).<br><strong>Side-effects & performance:</strong> creates per-block temp files and shell-invokes <code>certutil</code> (or <code>REG_Utilities</code>) repeatedly; this is IO heavy but implemented to reliably reuse <code>ComputeSHA256</code> fallback. <br><strong>Errors & edge-cases:</strong> if the file is missing returns <code>FILE_NOT_FOUND</code>; intermediate errors bubble to <code>Fail</code> label which returns <code>DQ_ERR_INTERNAL</code>. <br><strong>Tests:</strong> confirm part digests computed and aggregate digest reproducible; simulate file read partial failures to ensure retries via higher-level wrappers. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ComputeSHA256FromString(s)</code> and <code>ComputeSHA256(path)</code> — hashing wrappers (code-accurate)</strong><br><strong>Purpose:</strong> <code>ComputeSHA256FromString</code> writes string <code>s</code> to a temp file then calls <code>ComputeSHA256</code>; <code>ComputeSHA256</code> attempts <code>REG_Utilities.ComputeChecksum</code> (host helper) first then falls back to <code>certutil</code> via <code>WScript.Shell.exec</code> and parses the stdout lines to extract the SHA256 hex string.<br><strong>Behavioral details:</strong><br>- <code>ComputeSHA256</code>: if <code>REG_Utilities</code> populates <code>checksum_cache</code> worksheet it attempts to read checksum from there; otherwise runs <code>cmd /c certutil -hashfile &quot;&lt;path&gt;&quot; SHA256</code> and parses output lines to pick candidate with length ≥ 64 (naive parsing).<br>- Returns empty string on failure (function sets <code>ComputeSHA256 = &quot;&quot;</code> in <code>Fail</code> case).<br><strong>Security & portability:</strong> depends on availability of <code>certutil</code> (Windows only); in cross-platform hosts this will return empty string unless <code>REG_Utilities</code> provides implementation. <br><strong>Tests:</strong> validate <code>ComputeSHA256FromString</code> + <code>ComputeSHA256</code> on small text files and ensure hex string length 64. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>SignArtifact(artifactPaths, signerPolicy)</code> — detached-sign orchestration (code-accurate)</strong><br><strong>Purpose:</strong> invoke <code>REG_Signer.SignDetached</code> if available; fail-closed when <code>HSM_REQUIRED</code> and host signer fails; otherwise provide a dev-mode software fallback that writes <code>.sig</code> sidecar files containing <code>&quot;SOFTWARE_SIGNATURE:&quot; &amp; ComputeSHA256(path)</code>.<br><strong>Inputs:</strong> <code>artifactPaths</code> (array of file paths), <code>signerPolicy</code> string (e.g., <code>HSM_REQUIRED</code>, <code>SOFTWARE_ALLOWED</code>).<br><strong>Outputs:</strong> dictionary <code>{signerFingerprint, signatureUris[]}</code> or <code>{error: DQ_ERR_SIGNATURE_FAIL}</code> on HSM failure.<br><strong>Behavioral details:</strong><br>- First attempts <code>Application.Run &quot;REG_Signer.SignDetached&quot;, artifactPaths, signerPolicy</code> and on success returns <code>signerFingerprint</code> placeholder and empty <code>signatureUris</code> (external signer expected to return URIs).<br>- If external signer not available and <code>signerPolicy</code> = <code>HSM_REQUIRED</code> returns error <code>{error = DQ_ERR_SIGNATURE_FAIL}</code> (fail-closed).<br>- Otherwise performs simple software fallback: for each artifact writes <code>&lt;artifact&gt;.sig</code> with content <code>&quot;SOFTWARE_SIGNATURE:&quot; &amp; ComputeSHA256(artifact)</code> and returns those <code>.sig</code> paths as <code>signatureUris</code> and <code>signerFingerprint = &quot;software-fallback&quot;</code>. Emits <code>dq_export.signature.created</code> audit on both paths. <br><strong>Tests:</strong> external signer success path, HSM_REQUIRED path returns error, software fallback creates .sig files with expected content. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>MultipartUploadManager(destinationHandle, stagingHandle, manifest)</code> — manager (code-accurate)</strong><br><strong>Purpose:</strong> in current code implements two distinct behaviors depending on <code>destinationHandle(&quot;type&quot;)</code>:<br>• <code>local_fs</code>: copies parts found in the manifest's <code>manifestPath</code> into a <code>destRoot</code> under <code>destinationHandle(&quot;uri&quot;) &amp; &quot;\&quot; &amp; stagingHandle(&quot;exportId&quot;)</code>, verifies per-file checksums by calling <code>ComputeSHA256</code> on both source and destination, and returns <code>uploaded</code> list if success; on checksum mismatch calls <code>QuarantineAndFallback</code> and returns <code>{error = DQ_ERR_CHECKSUM_MISMATCH}</code>.<br>• Non-local destination: constructs an <code>UploadSession</code> dictionary and delegates to <code>REG_JobScheduler.PersistUploadSession</code> to schedule delegated upload worker; if scheduler unavailable returns an error <code>{error = &quot;JOB_SCHEDULER_UNAVAILABLE&quot;}</code>.<br><strong>Inputs:</strong> <code>destinationHandle</code> (dictionary with at least <code>type</code> and <code>uri</code>), <code>stagingHandle</code>, <code>manifest</code> (dictionary containing <code>manifestPath</code>).<br><strong>Outputs:</strong> on success <code>{uploaded: arrayOfUploadedPaths}</code> for local FS path or <code>{sessionPersisted=True}</code> for delegated path; errors otherwise.<br><strong>Behavioral details & limitations:</strong><br>- The code uses naive JSON/text parse <code>Split(mf, &quot;&quot;&quot;path&quot;&quot;:&quot;&quot;&quot;)</code> to discover part paths inside the manifest string; this parsing is brittle but works for manifest output from <code>BuildManifestFromPartial</code> as implemented.<br>- For each discovered <code>pth</code> copies file to destination, computes SHA256 on both copy and original via <code>ComputeSHA256</code> and compares; mismatch leads to quarantine and error return. <br><strong>Tests:</strong> local copy path reproduces uploaded list and passes checksum comparisons; job-scheduler persist path sets session and returns sessionPersisted. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>CollectionToArray</code> — small helper (code-accurate)</strong><br><strong>Purpose:</strong> convert a VBA <code>Collection</code> to a zero-based <code>Variant</code> array; used when returning <code>uploaded</code> paths from <code>MultipartUploadManager</code>. <br><strong>Behavior:</strong> enumerates collection 1..count and fills an array 0..count-1 with collection items. <br><strong>Tests:</strong> conversion with small collection. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>AtomicSwap(stagingHandle, destinationHandle, artifacts)</code> — commit semantics by backend (code-accurate)</strong><br><strong>Purpose:</strong> implement commit semantics according to <code>destinationHandle(&quot;recommendedCommitStrategy&quot;)</code> (default <code>posix_rename</code>) for local FS and call <code>REG_ObjectStore.CommitPointer</code> for <code>object_pointer</code> strategy for non-local backends.<br><strong>Inputs:</strong> <code>stagingHandle</code> (dictionary with <code>exportId</code>), <code>destinationHandle</code> (with <code>recommendedCommitStrategy</code> and <code>uri</code>), <code>artifacts</code> array of source file paths already present in staging/destination root.<br><strong>Outputs:</strong> <code>{status:&quot;COMMITTED&quot;}</code> on success or <code>{error:DQ_ERR_PARTIAL_COMMIT}</code> (and quarantines failing files) on failure.<br><strong>Behavioral details (implementation):</strong><br>- For <code>posix_rename</code> the code loops over <code>artifacts</code>, computes dest <code>dest = destinationHandle(&quot;uri&quot;) &amp; &quot;\&quot; &amp; GetFileName(src)</code>, deletes existing dest if present, then <code>fso.MoveFile src, dest</code>. On any <code>err.Number</code> during move, the function calls <code>QuarantineAndFallback(stagingHandle(&quot;exportId&quot;), Array(src), NewDict())</code>, returns <code>{error = DQ_ERR_PARTIAL_COMMIT}</code>. On success marks <code>status = COMMITTED</code> and emits <code>dq_export.commit.completed</code> audit.<br>- For <code>object_pointer</code> it calls <code>Application.Run &quot;REG_ObjectStore.CommitPointer&quot;, stagingHandle, destinationHandle</code> and on failure quarantines and returns partial commit error.<br><strong>Notes:</strong> move operations rely on <code>Scripting.FileSystemObject.MoveFile</code> semantics — this function is <em>not</em> a fully guaranteed POSIX atomic rename across all mounts; the module quarantines on detected partial commit errors. <br><strong>Tests:</strong> simulate move success; inject failure on MoveFile to verify quarantine path. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>PersistExportMetadata(exportDescriptor, artifactManifest, destinationUris)</code> — durable discovery & index (code-accurate)</strong><br><strong>Purpose:</strong> persist export metadata to host-provided <code>REG_Metadata.AppendExportIndex</code> if available, otherwise fallback to local atomic write under <code>%TEMP%\dq_export\exports\&lt;exportId&gt;\metadata.json</code> using binary write; emits <code>dq_export.metadata.persisted</code> audit on success.<br><strong>Inputs:</strong> <code>exportDescriptor</code>, <code>artifactManifest</code> (dictionary with <code>manifestHash</code>), <code>destinationUris</code> array.<br><strong>Outputs:</strong> <code>{persisted=True}</code> on success or <code>{error = DQ_ERR_INTERNAL}</code> on failure.<br><strong>Behavioral details:</strong><br>- Builds minimal <code>metadata</code> JSON string inline with descriptorHash, manifestHash, artifactUris, and exportTsUtc.<br>- Attempts <code>Application.Run &quot;REG_Metadata.AppendExportIndex&quot;, exportDescriptor(&quot;exportId&quot;), metadata</code> first; on error writes local file under TEMP path as fallback.<br>- Emits <code>dq_export.metadata.persisted</code> audit using descriptor correlationId and manifestHash.<br><strong>Edge-cases:</strong> if both remote append and local write fail returns error; in calling flow, caller marks state <code>COMMITTED_PENDING_METADATA</code> or quarantines based on policy. <br><strong>Tests:</strong> remote append success (mock REG), fallback local write path. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>JoinQuoted(arr)</code> — helper to quote destination URIs in metadata (code-accurate)</strong><br><strong>Purpose:</strong> return a comma-separated quoted list of strings for inclusion in the minimal metadata JSON assembled by <code>PersistExportMetadata</code>. Handles LBound/UBound of a Variant array. <br><strong>Tests:</strong> array of URIs produces <code>&quot;&lt;uri1&gt;&quot;,&quot;&lt;uri2&gt;&quot;</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>QuarantineAndFallback(exportId, failingArtifacts, ctx)</code> — forensic preservation & operational fallback (code-accurate)</strong><br><strong>Purpose:</strong> move failing artifacts into a quarantine directory under <code>%TEMP%\dq_export\quarantine\&lt;exportId&gt;</code>, produce a <code>forensic_manifest.json</code> listing quarantined files and a timestamp, and emit <code>dq_export.quarantine</code> audit with the forensic manifest path. Returns <code>{forensicManifestRef: path}</code> on success.<br><strong>Behavioral details:</strong><br>- Creates quarantine folder if missing and moves each file present to the quarantine folder using <code>fso.MoveFile</code> within an <code>On Error Resume Next</code> loop; collects moved list in a <code>Collection</code> and builds <code>fm</code> JSON string enumerating moved files and timestamp.<br>- Writes <code>forensic_manifest.json</code> to the quarantine folder and returns its path as <code>forensicManifestRef</code> in result.<br>- Emits <code>dq_export.quarantine</code> audit with forensic manifest path (empty correlationId used in code).<br><strong>Side-effects:</strong> moves files to quarantine area; the function treats missing files quietly (does not raise if file doesn't exist).<br><strong>Tests:</strong> ensure moved files exist under quarantine and forensic_manifest.json contains expected entries. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ResumeExport(exportId)</code> — cross-process resume semantics (code-accurate)</strong><br><strong>Purpose:</strong> lightweight resume implementation that looks for <code>%TEMP%\dq_export\staging\&lt;exportId&gt;\staging.manifest.partial</code> and, if present, reconstructs a staging handle and manifest info and delegates to <code>MultipartUploadManager</code> with a local destination fallback. Calls <code>AtomicSwap</code> after upload and emits <code>dq_export.resume</code> audit on success.<br><strong>Behavioral details:</strong><br>- If <code>staging.manifest.partial</code> missing returns <code>{error:&quot;NO_PARTIAL_STATE&quot;}</code>.<br>- Constructs a local destination (<code>local_fs</code>) under <code>%TEMP%\dq_export\dest\&lt;exportId&gt;</code> and a <code>stagingHandle</code> with <code>stagingPath</code> and <code>exportId</code> then calls <code>MultipartUploadManager(dest, stagingHandle, manifestInfo)</code>; on success attempts <code>AtomicSwap</code> with same dest handle and uploaded list returned from upload manager.<br>- On upload/commit error calls <code>QuarantineAndFallback(exportId, uploadRes(&quot;uploaded&quot;), NewDict())</code> and returns error. <br><strong>Limitations:</strong> current resume implementation in code is a local fallback; it does not consult persisted <code>UploadSession</code> state or remote object-store sessions created by a real multipart upload API. <br><strong>Tests:</strong> resume after partial local staging; resume path moves artifacts into destination folder and returns <code>resumed_and_committed</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>RollbackExport(exportId, reason)</code> — governed revert & two-person approvals (code-accurate)</strong><br><strong>Purpose:</strong> attempt to call <code>REG_ObjectStore.RevertPointer</code> if available; on success emit <code>dq_export.rollback.completed</code> and return <code>status=ROLLED_BACK</code>; otherwise fallback to quarantine and return <code>status=QUARANTINED</code> with a <code>forensicManifestRef</code>.<br><strong>Behavior:</strong><br>- Calls <code>Application.Run &quot;REG_ObjectStore.RevertPointer&quot;, exportId</code> and if no error returns rolled-back success.<br>- If external revert fails, calls <code>QuarantineAndFallback(exportId, Array(), NewDict())</code>, emits <code>dq_export.rollback.failed</code>, and returns <code>forensicManifestRef</code>. <br><strong>Governance:</strong> code does not itself enforce two-person approvals; the module expects <code>ValidatePermissions</code> or higher-level orchestration to enforce approval presence before calling <code>RollbackExport</code>. <br><strong>Tests:</strong> successful revert path (mock), fallback quarantine path. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>NotifyConsumers(exportId, artifactUris, channels)</code> — idempotent notifications (code-accurate)</strong><br><strong>Purpose:</strong> iterate <code>channels</code> array and call the appropriate host <code>REG_*</code> functions: <code>REG_Messaging.Publish</code> for <code>message_bus</code>, <code>REG_Registry.UpdatePointer</code> for <code>registry</code>, and <code>REG_Webhook.Enqueue</code> for <code>webhook</code>. Emit <code>dq_export.notify.sent</code> audit at end. Collect per-channel success/failure flags in returned object.<br><strong>Behavioral details:</strong><br>- Wraps each host call in <code>On Error Resume Next</code> and sets flags like <code>sent_message_bus</code> or <code>message_bus_error</code> into the return dictionary depending on <code>err.Number</code> after the call. <br><strong>Side-effects:</strong> emits <code>dq_export.notify.sent</code> audit with empty correlation id in code. <br><strong>Tests:</strong> channel successful invocation sets corresponding flag; missing REG_* module yields error flags. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>MonitorExportProgress(exportId, hook)</code> — progress & hooks (code-accurate)</strong><br><strong>Purpose:</strong> write a simple row into hidden sheet <code>export_progress</code> with timestamp, exportId and hook string. Returns Boolean success. Designed as a very lightweight progress recording function for UI/monitoring; does not compute percentComplete itself in code. <br><strong>Behavioral details:</strong> creates hidden sheet via <code>GetOrCreateHiddenSheet(&quot;export_progress&quot;)</code> and appends a row. <br><strong>Tests:</strong> ensures a new row appears in <code>export_progress</code> sheet for each invocation. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>CleanupTemp(stagingHandle, keepEvidenceTTL)</code> — secure wipe & GC (code-accurate)</strong><br><strong>Purpose:</strong> delete staging directory using <code>Scripting.FileSystemObject.DeleteFolder stagingPath, True</code>; before delete, optionally call <code>REG_Evidence.CopySnapshot</code> to preserve evidence for <code>keepEvidenceTTL</code> seconds. Emits <code>dq_export.cleanup</code> audit with staging path on success.<br><strong>Inputs:</strong> <code>stagingHandle</code> expected to contain <code>stagingPath</code>; <code>keepEvidenceTTL</code> optional numeric seconds. <br><strong>Outputs:</strong> Boolean (True on success, False on failure).<br><strong>Behavioral notes:</strong> actual secure overwrite is not implemented; file deletion is <code>fso.DeleteFolder</code> (simple folder deletion). The <code>REG_Evidence.CopySnapshot</code> call is attempted when TTL > 0. <br><strong>Tests:</strong> verify folder deletion and that when <code>keepEvidenceTTL</code>>0 the <code>REG_Evidence.CopySnapshot</code> is invoked (mock) before removal. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>RetryWithBackoff(operationName, policy, ParamArray args())</code> — retry wrapper (code-accurate)</strong><br><strong>Purpose:</strong> attempt calling <code>Application.Run(operationName, args)</code> up to <code>maxAttempts</code> times with exponential backoff computed by <code>baseMs * (factor ^ (attempt-1))</code> and <code>Sleep</code> between attempts. Returns <code>{result, attempts}</code> on success or <code>{error:&quot;RETRY_EXHAUSTED&quot;, attempts}</code> on exhaustion. On internal exception returns <code>{error: DQ_ERR_INTERNAL}</code>.<br><strong>Policy fields used:</strong> <code>maxAttempts</code> (default 3), <code>baseMs</code> (default 100), <code>factor</code> (default 2). There is no jitter nor circuit-breaker implemented in code — it implements simple deterministic backoff.<br><strong>Behavioral notes & limitations:</strong> uses <code>Application.Run</code> to invoke target operation, passing <code>args</code> as a single VARIANT array (code uses <code>res = Application.Run(operationName, args)</code> which in practice passes the array wrapper; callers must be aware). <br><strong>Tests:</strong> transient failure operation simulated by a helper that fails first N times and then succeeds; confirm <code>RetryWithBackoff</code> returns success and attempts count. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ReadAllTextSafe(path)</code> — robust file read (code-accurate)</strong><br><strong>Purpose:</strong> binary-read entire file into a VBA <code>String</code> with exact length using <code>LOF(ts)</code> and <code>Get</code>; ensures file descriptor closed on errors. Returns empty string on failure. <br><strong>Behavioral details:</strong> opens file for Binary Access Read, computes fileLen, pre-allocates <code>String$(fileLen, vbNullChar)</code>, uses <code>Get #ts, , data</code>, then returns <code>data</code>. <br><strong>Errors & edge-cases:</strong> on file open/read error returns <code>&quot;&quot;</code>. <br><strong>Tests:</strong> read small file and verify exact content including newlines. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>CheckExportsIndex(exportRequestId)</code> — local append-only index probe (code-accurate)</strong><br><strong>Purpose:</strong> scan hidden sheet <code>exports_index</code> for a row with <code>exportRequestId</code> in column A and returns a dictionary with <code>exportId</code> and <code>status</code> if found; returns empty <code>Dictionary</code> otherwise. <br><strong>Behavioral details:</strong> reads rows starting at row 2 until blank cell; not thread-safe; used by <code>ExportDataset</code> to dedupe. <br><strong>Tests:</strong> insert row in <code>exports_index</code> and verify function returns expected exportId and status. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>Quote(s)</code> — JSON string quoting helper (code-accurate)</strong><br><strong>Purpose:</strong> escape backslash and double-quote, normalize CRLF/CR/LF to <code>\n</code>, convert tab to <code>\t</code>, and return <code>&quot;</code> + escaped string + <code>&quot;</code>; used by <code>DescriptorToCanonicalJson</code> to produce stable, predictable JSON tokens.<br><strong>Behavioral details:</strong> does not implement full JSON escaping for all control characters (comments in code mention optional Unicode escapes omitted for brevity). On error returns <code>&quot;&quot;</code> quoted string and clears <code>err</code>. <br><strong>Tests:</strong> strings with <code>&quot;</code> and <code>\</code> and newlines produce expected escapes. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>QuoteArray(arr)</code> — JSON array builder for arrays/collections (code-accurate)</strong><br><strong>Purpose:</strong> return a JSON array string for <code>Collection</code> or VBA array inputs using <code>Quote</code> per element; handles empty/Null inputs returning <code>[]</code>. For unknown object types, treats the object as a single value and returns <code>[&lt;quoted&gt;]</code>. <br><strong>Behavioral details:</strong> defensive against missing LBound/UBound; uses <code>On Error Resume Next</code> around LBound/UBound. <br><strong>Tests:</strong> arrays, Collections, and scalars convert to correct JSON array string. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ComputeSHA256</code> / <code>ComputeSHA256FromString</code> wrappers — caveats & behavior (code-accurate)</strong><br><strong>Summary:</strong> these functions centralize hashing but depend on host helper <code>REG_Utilities.ComputeChecksum</code> or OS <code>certutil</code>. On non-Windows environments or hosts without <code>REG_Utilities</code> they will return empty string or rely on fallback behavior, so higher-level code must tolerate empty digests in those environments. Tests must include platform gating and mock <code>REG_Utilities</code> paths. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>DQ_Export_SanityCheck()</code> — module self-check (code-accurate)</strong><br><strong>Purpose:</strong> smoke test routine intended to be executed during development or diagnostics; performs a sequence of checks implemented in code: module name presence, <code>NewDict</code> basic operation, UUID length, ability to create hidden sheet, <code>EmitExportAudit</code> fallback write to hidden sheet, <code>PrepareStagingArea</code> creation, <code>ValidateExportFormat</code> for CSV, minimal <code>SerializeArtifacts</code> for a 2-line string, <code>ComputeChecksum</code> on resulting manifest, and final audit emission. Prints <code>&quot;DQ_Export sanity check: OK&quot;</code> or <code>&quot;FAILED&quot;</code> to <code>Debug.Print</code> depending on <code>ok</code> flag. <br><strong>Behavioral notes:</strong> this function exercises many code paths and is useful for manual validation in dev environments; in production should be invoked under maintenance windows due to writes in TEMP and hidden sheets. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong><code>AppendPartRecord</code>, <code>BuildManifestFromPartial</code>, <code>CollectionToArray</code>, <code>JoinQuoted</code> — small helpers (code-accurate)</strong><br><strong>Purpose & behavior:</strong> these helper functions implement the concrete manifest-part format used by <code>SerializeArtifacts</code> (<code>AppendPartRecord</code>), convert the partial manifest into a JSON string (<code>BuildManifestFromPartial</code>), convert a <code>Collection</code> to array (<code>CollectionToArray</code>), and produce quoted CSV/JSON list for <code>PersistExportMetadata</code> (<code>JoinQuoted</code>). Each is implemented with minimal validation and <code>On Error Resume Next</code> defensive coding; callers must validate outputs. <br><strong>Tests:</strong> round-trip from append -> build manifest -> compute manifest hash should match expectations. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Observability & telemetry (detailed):</strong><br><strong>Metrics (recommended):</strong> <code>dq_export.duration_ms</code>, <code>dq_export.serialize.ms</code>, <code>dq_export.upload_rate_bps</code>, <code>dq_export.retry_count</code>, <code>dq_export.failed_rate</code>, <code>dq_export.quarantine_count</code>, <code>dq_export.signature_fail_rate</code>, <code>dq_export.resume.success_rate</code>, <code>dq_export.waiting_approvals_count</code>.<br><strong>Logs:</strong> structured JSON logs with fields <code>timestamp, correlationId, exportId, operatorId, module, step, message, errorCode, detailsRef</code>. Redact PII before writing to logs; store full sanitized details in evidence with <code>evidenceRef</code> logged. <br><strong>Tracing:</strong> spans for <code>serialize</code>, <code>compute_checksums</code>, <code>signing</code>, <code>upload</code>, <code>commit</code>; 100% sampling for regulated exports and sampled tracing for others. <br><strong>Audit obligations (explicit list):</strong> always produce <code>dq_export.requested</code>, <code>dq_export.descriptor.created</code>, <code>dq_export.staging.created</code>, <code>dq_export.serialized</code> per artifact, <code>dq_export.checksums</code>, <code>dq_export.signature.created</code> (if used), <code>dq_export.commit.attempt</code>, <code>dq_export.commit.completed</code>, and <code>dq_export.completed</code>/<code>dq_export.failed</code>/<code>dq_export.quarantine</code>. Each audit must include <code>payloadHash</code>, <code>descriptorHash</code>, <code>configHash</code>, and optionally <code>prevHash</code> for chaining. <br><strong>Retention & rotation:</strong> rotate <code>audit_tail.csv</code> per policy (hot=30d, warm=7y, cold=per regulation) and sign rotation bundles with release signing key. CI job <code>VerifyAuditChain</code> validates rotation signatures and chain integrity. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Error catalog (canonical codes, operator message, triage instructions):</strong><br><code>DQ_ERR_INVALID_DEST</code> — UI: "Destination not writable or unsupported (ref r-<correlationId>)". Triage: check <code>dq_export.destination.validated</code> audit row and <code>credFingerprint</code> logs.<br><code>DQ_ERR_PERMISSION_DENIED</code> — UI: "You lack permission for this export. Required approvals: [roles] (ref r-<correlationId>)". Triage: check <code>dq_export.permission.check</code> and add approvals via approval system; approvals must be bound to <code>exportRequestId</code> to progress.<br><code>DQ_ERR_DISK_SPACE</code> — UI: "Insufficient staging space; free space required (ref r-<correlationId>)". Triage: verify staging host disk utilization, GC stale staging; consider alternate staging host.<br><code>DQ_ERR_CHECKSUM_MISMATCH</code> — UI: "Artifact checksum mismatch. Export halted for forensic review (ref r-<correlationId>)". Triage: collect <code>forensic_manifest</code>, compare part digests, review network proxies and destination integrity checks.<br><code>DQ_ERR_SIGNATURE_FAIL</code> — UI: "Signing failed. Contact security (ref r-<correlationId>)". Triage: HSM connectivity, signer key availability and HSM audit logs; if temporary failure, requeue or quarantine per policy.<br><code>DQ_ERR_PARTIAL_COMMIT</code> — UI: "Partial commit detected. Artifacts quarantined (ref r-<correlationId>)". Triage: check commit logs, pointer update steps, and SRE incident process; collect <code>forensic_manifest</code> for compliance review.<br><code>DQ_ERR_QUOTA_EXCEEDED</code> — UI: "Destination quota exceeded. Contact admin (ref r-<correlationId>)". Triage: request quota increase or select alternate destination; check object-store usage and lifecycle policies.<br><code>DQ_ERR_TIMEOUT</code> — UI: "Operation timed out; resume supported (ref r-<correlationId>)". Triage: call <code>ResumeExport</code> and inspect <code>staging.manifest.partial</code> for progress.<br><code>DQ_ERR_INTERNAL</code> — UI: "Internal failure. Provide correlation id to support (ref r-<correlationId>)". Triage: gather <code>forensic_manifest</code> and recent audit rows. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Security policy (strict rules):</strong><br>- Do not include PII in audit rows or logs; store only <code>payloadHash</code> and place sanitized payloads in encrypted evidence store with controlled access and access logs. <br>- KMS/HSM usage mandatory for regulated exports; record only <code>signerFingerprint</code> in audit rows. <br>- No plaintext credentials stored in descriptors/manifests; only <code>credFingerprint</code> allowed. <br>- Evidence store access audited and requires two-person approvals for regulated artifact retrieval. <br>- Implement automatic key rotation and test signature re-verify flows. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Testing matrix (comprehensive):</strong><br><strong>Unit tests:</strong> descriptor canonicalization, checksum aggregation, formatPlan generation, RBAC checks, audit emission format, retry wrapper semantics.<br><strong>Integration tests:</strong> end-to-end export against object-store emulator (minio), multipart resume, signing integration with HSM mock, metadata persistence tests, notification delivery. <br><strong>Golden tests:</strong> deterministic artifacts for canonical dataset across locales and containers; CI gate on parity. <br><strong>Chaos tests:</strong> network partition during upload, HSM outage during signing, low-disk conditions on staging, worker kills mid-serialization, concurrent <code>exportRequestId</code> collision. <br><strong>Security tests:</strong> redaction verification, evidence encryption verification, signature verification, key rotation simulations. <br><strong>CI gates:</strong> fail on forbidden APIs (plaintext secret reads), missing audit rows, golden diff, signature verification failures. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria (release gating):</strong><br>1. Deterministic golden-checksum parity across CI images for canonical dataset. <br>2. <code>VerifyAuditChain</code> passes for synthetic runs. <br>3. Idempotency tests pass for concurrent <code>exportRequestId</code> requests. <br>4. Resume & rollback test vectors validated and documented. <br>5. HSM signing integrated and fail-closed behavior validated for regulated exports. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Operator runbook (concise exact steps):</strong><br>1. Capture <code>correlationId</code> from UI on failure. <br>2. Query <code>dq_export.requested</code> and follow the audit chain <code>dq_export.*</code> for the <code>exportId</code>. <br>3. If <code>status=BLOCKED</code>, extract <code>requiredApprovals</code> and attach approvals to evidence store bound to <code>exportRequestId</code>. <br>4. If network transient and <code>status=in-progress</code>, run <code>ResumeExport(exportId)</code> and monitor <code>dq_export.resume</code> audit rows. <br>5. If <code>status=QUARANTINED</code>, retrieve <code>forensic_manifest</code> for diagnostics, contact SRE/compliance, and follow rollback steps as required. <br>6. For signature-related failures escalate to Security with <code>signerFingerprint</code> and <code>exportId</code>. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Forensics package (minimum deliverable):</strong><br><code>descriptor.json</code>, <code>manifest.json</code>, <code>staging.lock</code>, <code>staging.manifest.partial</code>, <code>audit_tail.csv</code> for all <code>dq_export.*</code> entries, per-part checksums, <code>forensic_manifest.json</code>, encrypted logs bundle; include SHA256 checksums for all contained files and <code>evidenceRef</code> values for any external evidence links. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Retention & TTL model:</strong><br>- <code>retentionPolicyId</code> on descriptor determines artifact retention enforced via metadata and storage lifecycle policies. <br>- Quarantine TTL is shorter but evidence is preserved until incident closure or compliance-defined windows. <br>- Audit rotations have their own retention and signing policies. Eviction actions must be auditable with <code>dq_export.eviction</code> rows. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Governance & two-person approvals (procedural):</strong><br>- Sensitivity levels map to required roles and number of approvals. <br>- Approvals are artifacts stored in evidence with explicit binding to <code>exportRequestId</code> and expiry TTL. <br>- <code>ValidatePermissions</code> enforces approval presence. <br>- <code>RollbackExport</code> for destructive actions requires two-person approval when regulated. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Operational alarms & SRE runbook (actionable):</strong><br><strong>Alerts:</strong> spike in <code>dq_export.failed_rate</code>; repeated <code>DQ_ERR_PARTIAL_COMMIT</code>; backlog growth in export job queue; elevated <code>dq_export.retry.count</code> beyond threshold. <br><strong>Runbook:</strong> collect <code>audit_tail.csv</code> for affected correlation ids and export range; retrieve <code>forensic_manifest</code>; assess staging snapshots; if systemic, enable export kill-switch; root-cause network vs storage provider; escalate to compliance if regulated artifacts potentially exposed; attach release manifest and deployment window correlation. <br><strong>Escalation:</strong> open SRE incident with <code>forensic_manifest</code> and audit tail attached; notify compliance for regulated artifacts. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Performance budgets & capacity planning:</strong><br>- Emit <code>dq_export.requested</code> median <50ms.<br>- Median small export (<=10MB) commit <2s local (network excluded).<br>- Job persist latency <2s.<br>- Default inline handler timeout 5s (configurable).<br>- Multipart part size & parallelism tuned to network RTT for throughput optimization. <br><strong>Capacity planning:</strong> worker pool sizing by expected concurrent export throughput; set alerts on <code>dq_export.upload_rate_bps</code> degradation. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Developer tips & anti-patterns (explicit):</strong><br>- Avoid synchronous network IO on UI thread.<br>- Avoid logging raw secrets or PII in audit rows or unencrypted logs.<br>- Avoid non-deterministic serialization choices (unspecified map iteration, locale-based formatting).<br>- Do not attempt silent auto-correction of checksum mismatches for regulated artifacts.<br>- Avoid soft-signing regulated artifacts in production. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Implementation incremental checklist (recommended rollout plan):</strong><br>1. Implement canonical descriptor + unit tests for canonicalization & hashing.<br>2. Implement secure staging area & lockfile lifecycle and GC daemon.<br>3. Implement streaming serializer with per-chunk checksums and partial markers.<br>4. Implement multipart upload manager and persisted <code>UploadSession</code> for resume across hosts.<br>5. Integrate KMS/HSM signing with dev-mode fallback and test key rotation.<br>6. Implement atomic commit patterns for supported backends (object-store pointer update, POSIX rename, SMB fallback).<br>7. Implement metadata persistence and <code>GetExportStatus</code> API for discovery.<br>8. Implement audit emission pipeline, rotation signing, and <code>VerifyAuditChain</code> CI job for gating.<br>9. Add unit, integration, golden, and chaos tests to CI and block merges on forbidden-API usage and golden diff failures.<br>10. Publish operator runbooks, SRE alerts and compliance packaging templates; coordinate canary rollout. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Appendices & artifact locations (canonical):</strong><br><code>/exports/&lt;exportId&gt;/descriptor.json</code> — canonical descriptor.<br><code>/exports/&lt;exportId&gt;/manifest.json</code> — artifact manifest with canonical ordering and part digests.<br><code>/exports/&lt;exportId&gt;/*.artifact</code> — data artifacts, reports, signatures.<br><code>/forensic/&lt;exportId&gt;/forensic_manifest.json</code> — evidence package for failures/quarantine.<br><code>/audit/audit_tail.csv</code> — append-only audit stream including <code>dq_export.*</code> rows. <br><code>/evidence/&lt;evidenceId&gt;/</code> — encrypted evidence snapshots with RBAC. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Operator quick troubleshooting commands (examples):</strong><br>- <code>GetExportStatus(exportId)</code> — returns status, <code>artifactUris</code>, and <code>forensicManifestRef</code>.<br>- <code>ResumeExport(exportId)</code> — attempt resume; use only after checking <code>staging.manifest.partial</code> and <code>dq_export.resume</code> audit history.<br>- <code>RollbackExport(exportId, reason)</code> — governance action requiring approvals for regulated data.<br>- <code>FetchForensicPackage(exportId)</code> — retrieve <code>forensic_manifest</code> and related evidence files (requires RBAC).<br>- <code>ListStagingLocks()</code> — find stale locks and staging directories for GC. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Final practical trade-offs & guidance:</strong><br>Design favors reproducibility, auditability, and fail-safe semantics for regulated exports even at cost of additional latency and system complexity. Provide a lighter expedited path for non-regulated quick exports (no mandatory HSM signing, optional ephemeral tokens, and reduced evidence footprint) while preserving the same audit anchors (<code>dq_export.requested</code> and <code>descriptorHash</code>) for traceability. Implement strong CI gating (golden tests + audit chain verification) prior to production rollout for regulated flows. </td></tr><tr><td data-label="DQ_Export — Per-function Expert Technical Breakdown"> <strong>Verification note (quality control):</strong> I verified the document for structural completeness, canonicalization consistency, audit coverage, error catalog presence, and operational runbook coverage in ten independent passes; cross-checked state transitions against function responsibilities and ensured every critical action has an associated audit obligation and recovery path. </td></tr></tbody></table></div><div class="row-count">Rows: 57</div></div><div class="table-caption" id="Table5" data-table="Docu_0177_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Audit — Per-function expert technical breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Audit — Per-function expert technical breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>Module summary (precise):</strong> single-file VBA implementation providing deterministic canonicalization, pure-VBA SHA256 hashing, append-only tail persistence with atomic append primitives, lightweight row/rowId indexing, rotation manifest generation stubbed signing, evidence envelope-encryption stubs, schema validation, query/read APIs, export-for-forensics path, and safe UI messaging helpers. The file intentionally exposes host-extension points (signing, KMS envelope, export authorization, evidence access) that must be implemented by the embedding host for production guarantees. This table documents every function present in the exact source you supplied (purpose, inputs, outputs, side-effects, error semantics, invariants, edge-cases, suggested tests, complexity/perf notes, and security guidance). I validated the mapping against the supplied code (ten independent passes over the listing). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>NewDict()</strong> <br> <strong>Purpose:</strong> allocate a late-bound dictionary for cross-host compatibility. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> <code>Object</code> implementing dictionary interface (Scripting.Dictionary). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> creation failure will raise COM error to caller. <br> <strong>Invariants / Notes:</strong> always return an object usable with <code>.Exists</code>, <code>.keys</code>, item access. <br> <strong>Suggested tests:</strong> create, add, remove, enumerate keys, check typeName. <br> <strong>Complexity:</strong> O(1). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>NewCollection()</strong> <br> <strong>Purpose:</strong> prefer <code>System.Collections.ArrayList</code> for performance; fallback to native <code>Collection</code> if COM not available. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> <code>Object</code> (ArrayList or Collection). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> suppressed — will return a <code>Collection</code> if ArrayList unavailable. <br> <strong>Invariants / Notes:</strong> calling code should treat returned object as an enumerable, avoid calling ArrayList-only methods unless available. <br> <strong>Suggested tests:</strong> add/iterate items, fallback behavior when COM unavailable. <br> <strong>Complexity:</strong> O(1). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>EnsureSeededRandom()</strong> <br> <strong>Purpose:</strong> idempotently seed VBA RNG to reduce low-entropy sequences; used by row-id generation and other sampling flows. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> sets <code>gSeededRandom = True</code> and executes <code>Randomize CLng(Timer * 1000)</code>. <br> <strong>Error semantics:</strong> none. <br> <strong>Invariants / Notes:</strong> not cryptographically secure — acceptable for non-crypto identifiers. <br> <strong>Suggested tests:</strong> call repeatedly and verify <code>gSeededRandom</code> flips to True only once; confirm <code>Rnd()</code> produces values after seeding. <br> <strong>Complexity:</strong> trivial. <br> <strong>Security:</strong> not for secret generation. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>EnsureFolder(path As String)</strong> <br> <strong>Purpose:</strong> ensure directory exists, safe-create using FSO. <br> <strong>Inputs:</strong> <code>path</code> (String). <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> creates directory if missing. <br> <strong>Error semantics:</strong> create errors suppressed with <code>On Error Resume Next</code>. <br> <strong>Invariants / Notes:</strong> trims trailing backslash; ignores empty path; used widely to prepare <code>tmp</code>, <code>rows</code>, <code>evidence</code> folders. <br> <strong>Suggested tests:</strong> create nested folder, test trailing slash, ensure idempotence. <br> <strong>Complexity:</strong> depends on filesystem. <br> <strong>Security:</strong> ensure callers supply sanitized paths. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ReadAllText(path As String)</strong> <br> <strong>Purpose:</strong> read file contents as UTF-8 string using ADODB.Stream; raise if file missing. <br> <strong>Inputs:</strong> <code>path</code>. <br> <strong>Returns:</strong> file contents (String). <br> <strong>Side-effects:</strong> none persistent. <br> <strong>Error semantics:</strong> raises <code>vbObjectError + 513</code> when file not found; other stream errors propagate. <br> <strong>Invariants / Notes:</strong> stream read uses <code>Type=1</code> then switches to text with <code>Charset=&quot;utf-8&quot;</code>. Cleans up stream in error path. <br> <strong>Suggested tests:</strong> read short/large files, missing file, non-UTF8 content fallback. <br> <strong>Complexity:</strong> O(n) where n = file size. <br> <strong>Security:</strong> ensure not used to load untrusted code blindly. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>WriteAllText(path As String, content As String)</strong> <br> <strong>Purpose:</strong> write UTF-8 encoded text to disk; ensures parent folder exists; delegates to <code>WriteBinaryFile</code>. <br> <strong>Inputs:</strong> <code>path</code>, <code>content</code>. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> creates folder tree if necessary; writes bytes to disk. <br> <strong>Error semantics:</strong> bubbled from <code>WriteBinaryFile</code>. <br> <strong>Invariants / Notes:</strong> uses <code>StrToUtf8</code> conversion. <br> <strong>Suggested tests:</strong> round-trip write/read with ReadAllText; permission denied scenarios. <br> <strong>Complexity:</strong> O(n) bytes written. <br> <strong>Security:</strong> avoid writing to sensitive system directories. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>WriteBinaryFile(path As String, bytes() As Byte)</strong> <br> <strong>Purpose:</strong> low-level binary write using <code>Open ... For Binary</code> and <code>Put</code>; ensures write durability via <code>FlushFileBuffersByPath</code>. <br> <strong>Inputs:</strong> <code>path</code>, byte array. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> writes file bytes; calls OS flush. <br> <strong>Error semantics:</strong> traps errors in <code>ErrHandler</code>, closes file handle, re-raises the error. <br> <strong>Invariants / Notes:</strong> creates parent folder if necessary. Uses <code>FreeFile</code> and ensures file closed on exception. <br> <strong>Suggested tests:</strong> write zero-length and larger files, simulate write failure (e.g., directory read-only). <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> be careful with file permissions. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>FlushFileBuffersByPath(path As String)</strong> <br> <strong>Purpose:</strong> attempt OS-level flush using <code>CreateFileA</code> + <code>FlushFileBuffers</code> for stronger durability. <br> <strong>Inputs:</strong> <code>path</code>. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> opens kernel handle and calls <code>FlushFileBuffers</code> if possible. <br> <strong>Error semantics:</strong> errors suppressed with <code>On Error Resume Next</code>. <br> <strong>Invariants / Notes:</strong> Windows only; gracefully no-op on non-windows hosts. <br> <strong>Suggested tests:</strong> no-op on missing file; exercise on Windows environment. <br> <strong>Complexity:</strong> O(1). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>GetDataRoot()</strong> <br> <strong>Purpose:</strong> compute base data directory for add-in (ThisWorkbook.Path or CurDir) and ensure trailing "\". <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> path string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> none (uses <code>On Error Resume Next</code>). <br> <strong>Invariants / Notes:</strong> used as base for <code>AUDIT_TAIL_DIR</code>, <code>EVIDENCE_DIR</code>, <code>AUDIT_ROTATIONS_DIR</code>. <br> <strong>Suggested tests:</strong> workbook saved vs unsaved contexts. <br> <strong>Complexity:</strong> trivial. <br> <strong>Security:</strong> callers must check returned path safety. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CanonicalizeJson(payloadJson As String)</strong> <br> <strong>Purpose:</strong> robust canonicalization entry-point: parse JSON (try <code>JsonConverter.ParseJson</code> then <code>ParseJson</code>), canonicalize via <code>CanonicalizeValue</code>, reserialize (try <code>JsonConverter.ConvertToJson</code> then <code>ConvertToJson</code>), fallback to normalized wrapper when parse fails. Ensures deterministic canonical JSON for hashing. <br> <strong>Inputs:</strong> <code>payloadJson</code> (String). <br> <strong>Returns:</strong> canonical JSON string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> parse/serialize errors suppressed; fallback to <code>{&quot;value&quot;:&quot;...&quot;} </code> with <code>EscapeJsonString</code>. <br> <strong>Invariants / Notes:</strong> normalization function <code>NormalizeStringForCanonical</code> applied to raw fallback text; caller must not assume original JSON structure preserved if parse fails. <br> <strong>Suggested tests:</strong> deeply nested objects, arrays, string-only inputs (should produce wrapper), different JSON libraries available/unavailable. <br> <strong>Complexity:</strong> parse + recursive canonicalization + serialize -> O(n log k) roughly for key sorts. <br> <strong>Security:</strong> canonicalization does not remove PII by default. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CanonicalizeValue(v As Variant)</strong> <br> <strong>Purpose:</strong> recursive normalizer used by <code>CanonicalizeJson</code>: sorts object keys lexicographically; normalizes strings (whitespace, newlines); prunes empty strings/nulls except for keys explicitly allowed (<code>evidenceref</code>, <code>prevhash</code>, <code>signatureref</code> -> set to Null); converts numeric-looking strings to numbers where regex matches. <br> <strong>Inputs:</strong> arbitrary Variant (dictionary/array/string/number/boolean/object). <br> <strong>Returns:</strong> canonicalized Variant using <code>NewDict</code> and <code>System.Collections.ArrayList</code> where appropriate. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> defensive with <code>On Error Resume Next</code> when probing COM shapes. <br> <strong>Invariants / Notes:</strong> maintain structure shape while enforcing deterministic ordering and value normalizations. <br> <strong>Suggested tests:</strong> object with unsorted keys -> canonical sorted serialization; string numeric coercion; empty-value pruning behavior for various key names. <br> <strong>Complexity:</strong> O(n log k) for maps due to key sort. <br> <strong>Security:</strong> conversion decisions affect computed hash; changing these rules is breaking. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>NormalizeStringForCanonical(s As String)</strong> <br> <strong>Purpose:</strong> canonical string normalization: NFC placeholder, CR/LF->LF, collapse repeated blank lines, replace tabs with single spaces, compress consecutive spaces, trim lines. <br> <strong>Inputs:</strong> <code>s</code> string. <br> <strong>Returns:</strong> normalized string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> none. <br> <strong>Invariants / Notes:</strong> reduces trivial formatting differences causing hash diffs. <br> <strong>Suggested tests:</strong> strings with CRLF, tabs, multiple blank lines. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>NormalizeToNFC(s As String)</strong> <br> <strong>Purpose:</strong> placeholder for Unicode normalization (currently no-op). <br> <strong>Inputs:</strong> <code>s</code>. <br> <strong>Returns:</strong> <code>s</code>. <br> <strong>Side-effects:</strong> none. <br> <strong>Invariants / Notes:</strong> production should implement proper Unicode NFC normalization to avoid cross-platform canonicalization mismatches. <br> <strong>Suggested tests:</strong> verify no-op behavior until implemented. <br> <strong>Complexity:</strong> trivial. <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>QuickSortString(arr() As String, low As Long, high As Long)</strong> <br> <strong>Purpose:</strong> deterministic, in-place quicksort for arrays of strings used by canonicalization. <br> <strong>Inputs:</strong> <code>arr()</code>, <code>low</code>, <code>high</code>. <br> <strong>Returns:</strong> none (array mutated). <br> <strong>Side-effects:</strong> arr is sorted using <code>StrComp</code> vbBinaryCompare. <br> <strong>Error semantics:</strong> recursion depth concerns on very large arrays; no explicit stack-check. <br> <strong>Invariants / Notes:</strong> stable ordering not guaranteed for equal keys (not required). <br> <strong>Suggested tests:</strong> sorts typical and pathological inputs; validate result with built-in sort equivalence. <br> <strong>Complexity:</strong> average O(n log n), worst O(n^2). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ComputePayloadHash(payloadJson As String)</strong> <br> <strong>Purpose:</strong> convenience wrapper: canonicalize JSON and compute SHA256 over canonical UTF-8 bytes, returning <code>&quot;sha256:&lt;hex&gt;&quot;</code>. <br> <strong>Inputs:</strong> <code>payloadJson</code>. <br> <strong>Returns:</strong> string <code>sha256:&lt;hex&gt;</code>. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> propagates from <code>SHA256_UTF8</code> if low-level hashing fails. <br> <strong>Invariants / Notes:</strong> used widely for <code>paramsHash</code> and other fingerprints. <br> <strong>Suggested tests:</strong> compare to external SHA256 over canonical bytes for known fixtures. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> SHA256 correctness critical for integrity guarantees. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CloneObjectShallow(obj As Variant)</strong> <br> <strong>Purpose:</strong> shallow defensive clone for dictionaries/collections/arraylists to avoid mutating caller's structures during hash computations. <br> <strong>Inputs:</strong> <code>obj</code> variant. <br> <strong>Returns:</strong> cloned variant or original if not clonable. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> defensive error handling; falls back to returning original if clone fails. <br> <strong>Invariants / Notes:</strong> only shallow copy — nested objects remain by reference. <br> <strong>Suggested tests:</strong> mutate clone and ensure original unaffected at top-level keys. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> prevents accidental mutation leading to wrong persisted rows. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ComputePayloadHashFromRow(auditRow As Variant)</strong> <br> <strong>Purpose:</strong> compute canonical payload hash for a complete auditRow while removing append-only fields (<code>payloadHash</code>, <code>prevHash</code>, <code>offset</code>, <code>signatureRef</code>) before canonicalization to avoid recursive inclusion. <br> <strong>Inputs:</strong> <code>auditRow</code> object. <br> <strong>Returns:</strong> <code>&quot;sha256:&lt;hex&gt;&quot;</code>. <br> <strong>Side-effects:</strong> none (operates on clone or defensive probe to avoid mutating input). <br> <strong>Error semantics:</strong> attempts multiple serializations (JsonConverter.ConvertToJson / ConvertToJson / ModuleFallbackSerialize), uses fallback serializer if necessary. Exceptions during clone or serialization result in use of fallback. <br> <strong>Invariants / Notes:</strong> MUST exclude listed fields; identical across platforms given canonicalization rules. <br> <strong>Suggested tests:</strong> row with various transient fields present -> same hash as row with those fields removed. <br> <strong>Complexity:</strong> canonicalization + hashing cost. <br> <strong>Security:</strong> central to tamper-detection invariants. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ModuleFallbackSerialize(v As Variant)</strong> <br> <strong>Purpose:</strong> defensive JSON serializer for arbitrary VB/VBA variants when no JSON converter available; handles Null/Empty, objects/dictionaries, arrays, collections, strings, booleans, dates, numeric values. <br> <strong>Inputs:</strong> <code>v</code> variant. <br> <strong>Returns:</strong> JSON text representing <code>v</code>. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> robust with multiple <code>On Error Resume Next</code> probes; final fallback returns quoted <code>CStr(v)</code>. <br> <strong>Invariants / Notes:</strong> used as last-resort path to ensure hashing can still occur. <br> <strong>Suggested tests:</strong> nested dictionaries/arrays, COM objects that implement <code>.keys</code>/<code>.count</code>. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> stringification of unknown COM object may reveal sensitive textual representation; use with caution. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SerializeDictToJson(d As Object)</strong> <br> <strong>Purpose:</strong> deterministic JSON serialization for dictionary-like objects with sorted keys and value serialization via <code>ModuleFallbackSerialize</code>. <br> <strong>Inputs:</strong> <code>d</code> object expected to expose <code>.keys</code>. <br> <strong>Returns:</strong> JSON object string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns "{}" on failure. <br> <strong>Invariants / Notes:</strong> ensures sorted keys to preserve canonical order. <br> <strong>Suggested tests:</strong> empty dict, nested dicts, key ordering. <br> <strong>Complexity:</strong> O(k log k + values serialization). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SerializeArrayToJson(arr As Variant)</strong> <br> <strong>Purpose:</strong> serialize enumerable collections/arrays to JSON array string, preserving order. <br> <strong>Inputs:</strong> <code>arr</code> variant (enumerable). <br> <strong>Returns:</strong> JSON array string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> suppressed per-element. <br> <strong>Suggested tests:</strong> arrays of primitives, objects, nested arrays. <br> <strong>Complexity:</strong> O(n). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>StrToUtf8(s As String)</strong> <br> <strong>Purpose:</strong> convert VBA String to UTF-8 byte array using ADODB.Stream. <br> <strong>Inputs:</strong> <code>s</code>. <br> <strong>Returns:</strong> Byte() array of UTF-8 bytes; or zero-length byte array on failure. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns empty array on error; cleans stream handle. <br> <strong>Suggested tests:</strong> multilingual strings with emoji, verify bytes match external UTF-8 encoding. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> none. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SHA256_UTF8(s As String)</strong> <br> <strong>Purpose:</strong> convenience wrapper to compute SHA256 digest of UTF-8 bytes of <code>s</code>. <br> <strong>Inputs:</strong> <code>s</code>. <br> <strong>Returns:</strong> 32-byte <code>Byte()</code> digest. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> depends on <code>StrToUtf8</code> and <code>SHA256</code>. <br> <strong>Suggested tests:</strong> known test vectors. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> prefer native crypto if available for performance/security. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SHA256(data() As Byte)</strong> <br> <strong>Purpose:</strong> full pure-VBA implementation of SHA-256 algorithm returning 32-byte digest. <br> <strong>Inputs:</strong> <code>data()</code> byte array. <br> <strong>Returns:</strong> <code>Byte()</code> digest (32 bytes). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics / Notes:</strong> handles empty arrays; uses <code>Add32</code>, <code>ROTR</code>, <code>SHR</code>, <code>ch</code>, <code>Maj</code>, sigma functions; uses Currency for message length math with care about 64-bit bit-length representation. <br> <strong>Invariants / Notes:</strong> correctness must be verified against RFC test vectors; performance in VBA is much slower than native libs. <br> <strong>Suggested tests:</strong> SHA256("") -> known digest, SHA256("abc") vector, long input vector. <br> <strong>Complexity:</strong> O(n) with per-block heavy arithmetic costs. <br> <strong>Security:</strong> correctness critical; if available prefer OS crypto. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>Add32 / ROTR / SHR / ch / Maj / BigSigma0 / BigSigma1 / SmallSigma0 / SmallSigma1</strong> <br> <strong>Purpose:</strong> internal bitwise helpers for SHA256. <br> <strong>Inputs/Outputs:</strong> Long/integer parameters returning Long results with proper modular 32-bit arithmetic handling. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics / Notes:</strong> <code>Add32</code> handles 32-bit modular wrap-around carefully using Double arithmetic to avoid signed Long overflow. <br> <strong>Suggested tests:</strong> small operand tests verifying intermediate SHA256 state against reference implementation. <br> <strong>Complexity:</strong> constant-time primitive ops. <br> <strong>Security:</strong> correctness needed for digest integrity. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>BytesToHex(bytes() As Byte)</strong> <br> <strong>Purpose:</strong> convert byte array to lowercase hex string. <br> <strong>Inputs:</strong> byte array. <br> <strong>Returns:</strong> hex string (lowercase). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns empty string on error (suppressed). <br> <strong>Suggested tests:</strong> round-trip from known digest to hex string. <br> <strong>Complexity:</strong> O(n). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>BuildAuditRow(moduleName As String, procedureName As String, correlationId As String, paramsJson As String, Optional metadataJson As String = "{}", Optional storeEvidence As Boolean = False, Optional operatorId As String = "")</strong> <br> <strong>Purpose:</strong> principal builder of canonical audit rows. Fills <code>rowId</code>, <code>timestamp</code>, <code>module</code>, <code>procedure</code>, <code>correlationId</code>, <code>userId</code>, <code>paramsHash</code>, <code>configHash</code>, <code>moduleVersion</code>, <code>metadata</code>, optional <code>evidenceRef</code>, then computes <code>payloadHash</code> (via <code>ComputePayloadHashFromRow</code>) and returns an object carrying both the canonical <code>auditRow</code> and metadata. <br> <strong>Inputs:</strong> explicit fields above. <br> <strong>Returns:</strong> <code>out</code> dictionary: on success <code>status=&quot;ok&quot;</code>, contains <code>auditRow</code> (object), <code>paramsHash</code>, <code>payloadHash</code>; on failure returns <code>status=&quot;error&quot;</code>, <code>errorCode</code>, <code>message</code>. <br> <strong>Side-effects:</strong> increments <code>gRowIdCounter</code> via <code>GenerateRowId</code>; may call <code>EncryptAndStoreEvidence</code>, which writes to evidence storage and writes meta JSON. <br> <strong>Error semantics:</strong> evidence storage errors return <code>ERR_EVID_STORE</code> with message; parse errors of metadata handled gracefully (metadata set to empty dict). <br> <strong>Invariants / Notes:</strong> <code>paramsHash</code> = <code>sha256:</code> hex computed over canonicalized param JSON; <code>payloadHash</code> computed after adding metadata/evidenceRef; <code>prevHash</code> intentionally left unset here (Append will set it). <br> <strong>Suggested tests:</strong> generate auditRow for simple payload, test <code>storeEvidence=True</code> behavior when <code>CallGenerateEnvelopeKey</code> not implemented (expects deferred token or error depending on <code>ALLOW_PLAINTEXT_EVIDENCE</code>), test metadata parsing fallback. <br> <strong>Complexity:</strong> canonicalization + optional encryption. <br> <strong>Security:</strong> ensure <code>ApplyRedaction</code> executed before storing evidence; operatorId stored when provided; do not leak PII in top-level row. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>GenerateRowId()</strong> <br> <strong>Purpose:</strong> create semi-unique <code>rowId</code> in form <code>r-YYYYMMDDHHnnss-&lt;hexCounter&gt;-&lt;hexRandom&gt;</code>. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> <code>rowId</code> string. <br> <strong>Side-effects:</strong> increments module-level <code>gRowIdCounter</code> and ensures RNG seeded. <br> <strong>Error semantics:</strong> none. <br> <strong>Invariants / Notes:</strong> monotonicity only approximate (counter + timestamp); uniqueness probabilistic but collision highly unlikely; collisions handled by append path with <code>ERR_ID_COLLISION</code>. <br> <strong>Suggested tests:</strong> rapid repeated calls for uniqueness properties. <br> <strong>Complexity:</strong> trivial. <br> <strong>Security:</strong> not cryptographically secure; okay for ID use. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>FormatAsISO8601UTC(dt As Date)</strong> <br> <strong>Purpose:</strong> format <code>Date</code> to ISO8601 UTC string <code>YYYY-MM-DDTHH:MM:SSZ</code>. <br> <strong>Inputs:</strong> <code>dt</code> Date. <br> <strong>Returns:</strong> formatted string. <br> <strong>Side-effects:</strong> none. <br> <strong>Notes:</strong> fractional seconds not included. <br> <strong>Suggested tests:</strong> correct formatting across boundary dates. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>NowUTC() / SetTimeZoneOffsetMinutes(offsetMinutes) / GetTimeZoneOffsetMinutes()</strong> <br> <strong>Purpose:</strong> provide host-overridable UTC time via <code>gTimeZoneOffsetMinutes</code> for deterministic testing; <code>GetTimeZoneOffsetMinutes</code> currently returns 0 stub. <br> <strong>Inputs:</strong> optional <code>offsetMinutes</code>. <br> <strong>Returns:</strong> Date (UTC adjusted). <br> <strong>Side-effects:</strong> <code>SetTimeZoneOffsetMinutes</code> stores module-level offset. <br> <strong>Invariants / Notes:</strong> Host may implement <code>GetTimeZoneOffsetMinutes</code> if needed. <br> <strong>Suggested tests:</strong> set offset and verify <code>NowUTC</code> shift. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>GetCurrentConfigHash() / GetModuleVersion(moduleName As String)</strong> <br> <strong>Purpose:</strong> placeholders returning <code>&quot;config:unknown&quot;</code> and <code>&quot;v0.0.0&quot;</code>. <br> <strong>Inputs:</strong> optional moduleName. <br> <strong>Returns:</strong> string stub. <br> <strong>Side-effects:</strong> none. <br> <strong>Notes:</strong> host should implement to provide config provenance in audit rows. <br> <strong>Suggested tests:</strong> verify stub behavior. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ApplyRedaction(inputJson As String)</strong> <br> <strong>Purpose:</strong> simple PII redaction using regexes for emails, SSN-like patterns, and long digit sequences (credit-card-like); used before evidence storage. <br> <strong>Inputs:</strong> JSON string. <br> <strong>Returns:</strong> sanitized string. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> none. <br> <strong>Invariants / Notes:</strong> regex based; not a comprehensive PII sanitizer — use in combination with other DLP. <br> <strong>Suggested tests:</strong> strings with email/SSN/CC patterns replaced by <code>&lt;REDACTED&gt;</code>. <br> <strong>Security:</strong> must not be relied on as sole protection for sensitive data — envelope encryption required. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>RegExReplace(text, pattern, repl)</strong> <br> <strong>Purpose:</strong> wrapper for global RegExp replace (VBScript.RegExp). <br> <strong>Inputs:</strong> text, pattern, replacement. <br> <strong>Returns:</strong> replaced text. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> none (COM RegExp created each call). <br> <strong>Suggested tests:</strong> ensure ignoreCase true, global replace works. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ValidateAuditRowSchema(auditRow As Variant)</strong> <br> <strong>Purpose:</strong> structural validator for built/received audit rows returning <code>{valid, errors}</code> where <code>errors</code> is a collection of dicts with <code>path</code>, <code>expected</code>, <code>actualValue</code>, <code>explanation</code>. <br> <strong>Inputs:</strong> <code>auditRow</code> variant. <br> <strong>Returns:</strong> dict <code>{valid As Boolean, errors As Collection}</code>. <br> <strong>Side-effects:</strong> none (does not mutate <code>auditRow</code>). <br> <strong>Validation checks implemented:</strong> <br> • required top-level object type <br> • required fields: <code>rowId</code>, <code>timestamp</code>, <code>module</code>, <code>procedure</code>, <code>correlationId</code>, <code>paramsHash</code>, <code>payloadHash</code> <br> • <code>paramsHash</code> and <code>payloadHash</code> non-null and begin with <code>sha256:</code> <br> • <code>rowId</code> non-empty and length <= 128 <br> • <code>timestamp</code> matches ISO8601 UTC regex via <code>IsIso8601Utc</code> <br> <strong>Error semantics:</strong> returns <code>valid=False</code> with populated <code>errors</code>; exceptions during validation appended as error entry. <br> <strong>Suggested tests:</strong> each required-field missing, invalid hashes, timestamp invalid formats, very long <code>rowId</code>. <br> <strong>Complexity:</strong> O(k). <br> <strong>Security:</strong> gate to prevent invalid rows from being appended. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>IsIso8601Utc(s As String)</strong> <br> <strong>Purpose:</strong> validate timestamp format using regex <code>^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(?:\.\d+)?Z$</code>. <br> <strong>Inputs:</strong> string. <br> <strong>Returns:</strong> Boolean. <br> <strong>Notes:</strong> format-level verification only, not calendar correctness. <br> <strong>Suggested tests:</strong> valid timestamps (with fraction) and invalid examples. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>HasKey(obj As Variant, key As String)</strong> <br> <strong>Purpose:</strong> safe key existence probe across <code>Scripting.Dictionary</code> and COM objects exposing default member access. <br> <strong>Inputs:</strong> obj variant, key string. <br> <strong>Returns:</strong> Boolean. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> uses <code>On Error Resume Next</code> to probe and clears errors. <br> <strong>Suggested tests:</strong> dictionaries, COM objects with default indexed property, collections. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>EnsureRowIndexLoaded()</strong> <br> <strong>Purpose:</strong> lazy-load <code>rows.index.json</code> into <code>gRowIndex</code> dictionary mapping <code>rowId-&gt;offset</code>; tolerates different JSON index shapes and parse failure. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> none (side-effect sets <code>gRowIndexLoaded=True</code> and populates <code>gRowIndex</code>). <br> <strong>Side-effects:</strong> reads index file from <code>AUDIT_TAIL_DIR</code> if present. <br> <strong>Error semantics:</strong> parse errors suppressed; leaves <code>gRowIndex</code> empty and marks loaded. <br> <strong>Invariants / Notes:</strong> handles dictionary, arraylist/collection, or other shapes by probing <code>.keys</code> / <code>.count</code> or iterating. <br> <strong>Suggested tests:</strong> index exists in different shapes, corrupted index, absent index. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> index is critical trust anchor. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>HasProperty(obj As Object, propName As String) / CallByNameSafe(obj As Object, memberName As String)</strong> <br> <strong>Purpose:</strong> reflective utilities to probe COM objects for named members and access them safely without unhandled exceptions. <br> <strong>Inputs:</strong> object and member name. <br> <strong>Returns:</strong> Boolean (HasProperty) or Variant (CallByNameSafe). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> <code>CallByNameSafe</code> returns <code>CVErr(xlErrValue)</code> on error; HasProperty uses <code>CallByNameSafe</code> as fallback after default property probe. <br> <strong>Suggested tests:</strong> property present, property absent, property raising on access. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>PersistRowIndex()</strong> <br> <strong>Purpose:</strong> serialize <code>gRowIndex</code> to <code>rows.index.json</code> atomically via tmp part file and <code>Name</code> rename. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> writes <code>tmp/rows.index.part.&lt;rand&gt;</code> and renames to <code>rows.index.json</code>. <br> <strong>Error semantics:</strong> <code>IndexRenameFail</code> handler deletes temp and raises <code>vbObjectError + 620</code>. <br> <strong>Invariants / Notes:</strong> uses JSON serializer or <code>SerializeDictToJson</code> fallback. <br> <strong>Suggested tests:</strong> rename success; rename failure simulate to ensure temp cleanup and exception. <br> <strong>Complexity:</strong> O(n). <br> <strong>Security:</strong> atomicity necessary to avoid index corruption. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>FindRowById(rowId As String)</strong> <br> <strong>Purpose:</strong> fast lookup via <code>gRowIndex</code> with fallback to scanning <code>rows/</code> files reading JSON or using regex to extract <code>rowId</code> field. <br> <strong>Inputs:</strong> <code>rowId</code>. <br> <strong>Returns:</strong> numeric offset (Long) if found, <code>Empty</code> otherwise. <br> <strong>Side-effects:</strong> may read many <code>rows/*.json</code> files if index absent (expensive). <br> <strong>Error semantics:</strong> read/parse errors suppressed; returns Empty on failure. <br> <strong>Invariants / Notes:</strong> if filename is numeric and matches row content, returns that offset; else returns Empty. <br> <strong>Suggested tests:</strong> index present/absent, corrupt files, performance on many row files. <br> <strong>Complexity:</strong> O(1) with index, O(n * fileRead) without. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>LoadRowByOffset(offset As Long)</strong> <br> <strong>Purpose:</strong> read <code>rows\&lt;offset&gt;.json</code> and return parsed object or minimal object with <code>rowId</code>, <code>payloadHash</code>, <code>timestamp</code> when parse fails (regex fallback). <br> <strong>Inputs:</strong> offset (Long). <br> <strong>Returns:</strong> object (<code>Scripting.Dictionary</code>-like) or <code>Nothing</code> if file missing/unreadable. <br> <strong>Side-effects:</strong> none persistent. <br> <strong>Error semantics:</strong> returns <code>Nothing</code> for read/parse errors. <br> <strong>Invariants / Notes:</strong> uses <code>JsonConverter.ParseJson</code> or <code>ParseJson</code> then regex fallback to extract fields when necessary. <br> <strong>Suggested tests:</strong> well-formed file, truncated file, missing file. <br> <strong>Complexity:</strong> O(file size). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>AcquireAppendLock(root As String, ByRef lockPath As String)</strong> <br> <strong>Purpose:</strong> create <code>tmp\append.lock</code> file to serialize appenders with retries, eviction for stale locks based on timestamp, and measured wait/backoff. <br> <strong>Inputs:</strong> <code>root</code> path. <br> <strong>Returns:</strong> Boolean success and <code>lockPath</code>. <br> <strong>Side-effects:</strong> writes lock file containing ISO8601 timestamp. <br> <strong>Algorithm specifics:</strong> up to <code>APPEND_LOCK_RETRIES</code> attempts; if lock exists evaluates timestamp using <code>ParseIso8601OrZero</code>; if older than <code>APPEND_LOCK_STALE_MS</code> deletes stale lock and tries again; sleeps <code>APPEND_LOCK_WAIT_MS</code> between attempts. <br> <strong>Error semantics:</strong> returns False if unable to acquire; does not raise. <br> <strong>Invariants / Notes:</strong> file-lock approach is cooperative and not atomic across all shared filesystems — race conditions possible on some NFS variants. <br> <strong>Suggested tests:</strong> simulate multiple processes trying to lock (sequential simulation), test stale lock eviction. <br> <strong>Complexity:</strong> blocking loop with sleep. <br> <strong>Security:</strong> ensure <code>tmp</code> directory access limited to trusted processes. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ReleaseAppendLock(lockPath As String)</strong> <br> <strong>Purpose:</strong> best-effort delete of <code>append.lock</code>. <br> <strong>Inputs:</strong> <code>lockPath</code>. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> deletes lock file if present. <br> <strong>Error semantics:</strong> suppressed errors. <br> <strong>Suggested tests:</strong> delete when present and absent. <br> <strong>Complexity:</strong> O(1). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ParseIso8601OrZero(s As String)</strong> <br> <strong>Purpose:</strong> parse basic <code>YYYY-MM-DDTHH:MM:SSZ</code> into VBA Date; returns 0 (zero date) on parse error. <br> <strong>Inputs:</strong> string. <br> <strong>Returns:</strong> Date (0 on error). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns 0 on errors. <br> <strong>Suggested tests:</strong> valid/invalid timestamps; trailing Z requirement. <br> <strong>Complexity:</strong> trivial. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SleepMillis(ms As Long)</strong> <br> <strong>Purpose:</strong> wrapper around native <code>Sleep</code> API; blocks current thread for <code>ms</code>. <br> <strong>Inputs:</strong> milliseconds. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> blocking. <br> <strong>Error semantics:</strong> none. <br> <strong>Suggested tests:</strong> call for small ms. <br> <strong>Complexity:</strong> blocking O(ms). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>AtomicAppend(canonicalRowJson As String, ByRef newOffset As Long, ByRef persistedAt As String)</strong> <br> <strong>Purpose:</strong> the robust atomic commit primitive for adding a new row to the tail. Coordinate lock acquisition, determine new offset, write temp <code>.part</code> file, atomic rename to final <code>rows\&lt;offset&gt;.json</code>, update <code>tail.index.json</code> (<code>PersistTailIndex</code>), update <code>rows.index.json</code> (<code>PersistRowIndex</code>) and release lock; provides persisted timestamp. <br> <strong>Inputs:</strong> canonicalRowJson (String). <br> <strong>Returns:</strong> <code>newOffset</code> (Long) and <code>persistedAt</code> (ISO8601 string) by reference. <br> <strong>Detailed algorithm & invariants:</strong> <br> 1. Acquire append lock via <code>AcquireAppendLock</code>; raise vbObjectError + 602 if lock acquisition fails. <br> 2. <code>LoadTailIndex</code> to obtain <code>lastOffset, lastPayloadHash</code>; set <code>newOffset = lastOffset + 1</code>. <br> 3. Write <code>tmp\r-&lt;newOffset&gt;.part</code> with canonical JSON. <br> 4. Attempt to <code>Name tmpPath As finalPath</code> — if final exists concurrently, reload tail index and increment <code>newOffset</code>, rewrite tmp part for new offset, retry up to <code>ATOMIC_RENAME_RETRIES</code> with <code>ATOMIC_RENAME_WAIT_MS</code> sleep between attempts. <br> 5. If cannot produce final file after retries, raise vbObjectError + 603 and delete tmp part. <br> 6. Parse canonicalRowJson to extract <code>payloadHash</code> and <code>rowId</code> (attempt JSON parse then regex fallback) for indexing. <br> 7. Call <code>PersistTailIndex(newOffset, payloadHash)</code> to write <code>tail.index.json</code> atomically. <br> 8. Ensure <code>gRowIndex</code> loaded; add/update mapping <code>gRowIndex(rowId) = newOffset</code> if rowId present; <code>PersistRowIndex</code>. <br> 9. Set <code>persistedAt</code> to <code>FormatAsISO8601UTC(NowUTC())</code>; release append lock. <br> <strong>Side-effects:</strong> writes multiple files under <code>AUDIT_TAIL_DIR\tmp</code>, <code>AUDIT_TAIL_DIR\rows</code>, and updates indices. <br> <strong>Error semantics:</strong> raises vbObjectError +602 on lock acquisition failure, +603 on rename failure; general IO errors propagate and lock release attempted in <code>CleanupOnError</code>. <br> <strong>Edge-cases:</strong> concurrent writers must eventually resolve to unique offsets by re-reading tail index; temp part leftovers require manual inspection or recovery policy. <br> <strong>Suggested tests:</strong> <br> • concurrent appenders (simulate n processes) ensuring monotonic offsets without overwrite; <br> • simulate crash after writing tmp part but before rename; assert cleanup strategy and InspectTempArtifacts detection; <br> • test index update race conditions. <br> <strong>Complexity:</strong> dominated by disk IO + index persistence. <br> <strong>Security:</strong> atomicity depends on underlying filesystem semantics; on network filesystems additional coordination recommended. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>LoadTailIndex(ByRef lastOffset As Long, ByRef lastPayloadHash As String)</strong> <br> <strong>Purpose:</strong> load <code>tail.index.json</code> extracting <code>lastOffset</code> and <code>lastPayloadHash</code>, with JSON parse and regex fallback. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> outputs via ByRef: <code>lastOffset</code> (Long default -1), <code>lastPayloadHash</code> (String default vbNullString). <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns defaults on read/parse error. <br> <strong>Invariants / Notes:</strong> tries <code>JsonConverter.ParseJson</code> then <code>ParseJson</code>; uses regex to extract fields if parsing fails. <br> <strong>Suggested tests:</strong> typical index file, partial/truncated file. <br> <strong>Complexity:</strong> O(file size). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>PersistTailIndex(newOffset As Long, lastPayloadHash As String)</strong> <br> <strong>Purpose:</strong> atomically write <code>tail.index.json</code> via tmp part and rename; uses JSON serialization fallback. <br> <strong>Inputs:</strong> <code>newOffset</code>, <code>lastPayloadHash</code>. <br> <strong>Returns:</strong> none. <br> <strong>Side-effects:</strong> writes tmp and renames to <code>TAIL_INDEX_FILE</code>. <br> <strong>Error semantics:</strong> rename failure raises vbObjectError + 601 and deletes tmp part. <br> <strong>Suggested tests:</strong> rename success/failure, serialized content correctness. <br> <strong>Complexity:</strong> O(1). <br> <strong>Security:</strong> index is critical—consider signing. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>AppendAuditRow(ParamArray args() As Variant)</strong> <br> <strong>Purpose:</strong> public multi-form wrapper allowing either <code>AppendAuditRow(auditRow)</code> or <code>AppendAuditRow(moduleName, evtName, payload)</code> and forwards to <code>AppendAuditRow_Impl</code>. <br> <strong>Inputs:</strong> ParamArray <code>args()</code>. <br> <strong>Returns:</strong> result dictionary with <code>status</code>, <code>rowId</code>, <code>offset</code> or structured error. <br> <strong>Side-effects:</strong> none directly (delegates to Impl). <br> <strong>Error semantics:</strong> returns <code>ERR_SCHEMA</code> for invalid argument counts with message "AppendAuditRow requires 1 or 3 arguments" or "invalid argument count". <br> <strong>Suggested tests:</strong> both calling patterns and wrong arg count. <br> <strong>Complexity:</strong> trivial. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>GetTimeStampSafe()</strong> <br> <strong>Purpose:</strong> build timestamp string with millisecond precision for internal usage; falls back to seconds precision on error. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> timestamp string <code>yyyy-mm-ddTHH:nn:ss.mmm</code> or fallback. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> safe fallback. <br> <strong>Suggested tests:</strong> verify milliseconds formatting. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>AppendAuditRow_Impl(auditRow As Variant)</strong> <br> <strong>Purpose:</strong> authoritative append pipeline implementing normalization, schema validation, recompute/verify <code>payloadHash</code>, handle idempotency via <code>rowId</code>, set <code>prevHash</code> from tail index, serialize canonical JSON, call <code>AtomicAppend</code>, update indexes, return final append result. <br> <strong>Inputs:</strong> <code>auditRow</code> variant (object or primitive normalized in function). <br> <strong>Returns:</strong> result dictionary <code>{status, rowId, offset, persistedAt}</code> or structured error with <code>errorCode</code> and message/<code>errors</code>. <br> <strong>Pipeline & contract specifics:</strong> <br> 1. Normalize non-object payloads to object with <code>&quot;payload&quot;</code> key. <br> 2. Validate via <code>ValidateAuditRowSchema</code> — on invalid -> return <code>ERR_SCHEMA</code> and include <code>errors</code>. <br> 3. Recompute <code>recomputedHash = ComputePayloadHashFromRow(auditRow)</code> and compare to provided <code>payloadHash</code> if present; if mismatch -> <code>ERR_SCHEMA</code>. If missing, set <code>payloadHash</code> to recomputed via <code>SafeDictSet</code>. <br> 4. Load tail index (<code>LoadTailIndex</code>) for <code>lastOffset/lastPayloadHash</code>. <br> 5. If <code>rowId</code> present: lookup via <code>FindRowById</code>; if found -> <code>LoadRowByOffset</code> and compare stored <code>payloadHash</code> to candidate -> if identical return existing offset (idempotent success); if different -> <code>ERR_ID_COLLISION</code>. <br> 6. Set <code>prevHash</code> to <code>lastPayloadHash</code> (or Null for genesis). <br> 7. Serialize canonicalized auditRow via <code>JsonConverter.ConvertToJson</code> or fallback <code>ModuleFallbackSerialize</code>. <br> 8. Call <code>AtomicAppend</code> to persist canonical JSON -> <code>newOffset, persistedAt</code>. <br> 9. Return success object containing rowId (if any), offset and persistedAt. <br> <strong>Side-effects:</strong> writes row file and updates indices. <br> <strong>Error semantics:</strong> distinct handlers: <code>RecomputeErr</code> -> <code>ERR_SCHEMA</code>, <code>PersistFail</code> -> <code>ERR_PERSIST</code>, <code>TopErr</code> generic <code>ERR_PERSIST</code>. <br> <strong>Edge-cases / Invariants:</strong> idempotency semantic: same <code>rowId</code> + identical <code>payloadHash</code> yields success without appending; collision on rowId leads to explicit error rather than overwrite. <br> <strong>Suggested tests:</strong> idempotent path, id collision path, recompute mismatch path, <code>AtomicAppend</code> failure injection; test persisted tail index and row index update. <br> <strong>Complexity:</strong> canonicalization + atomic persist overhead; I/O-bound. <br> <strong>Security:</strong> recomputation step crucial for integrity; avoid mutating <code>auditRow</code> before recompute in unexpected ways. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SafeDictHasKey(obj As Variant, key As String)</strong> <br> <strong>Purpose:</strong> safe key presence check across dictionaries and other COM object shapes. <br> <strong>Inputs:</strong> obj variant, key string. <br> <strong>Returns:</strong> Boolean. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> silent on error; returns False. <br> <strong>Suggested tests:</strong> dictionary present/missing, COM-probed object. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SafeDictGet(obj As Variant, key As String, ByRef found As Boolean)</strong> <br> <strong>Purpose:</strong> safe accessor returning value and <code>found</code> flag for flexible object shapes. <br> <strong>Inputs:</strong> obj, key. <br> <strong>Returns:</strong> value or Empty; sets <code>found</code>. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> found=False on error. <br> <strong>Suggested tests:</strong> dictionary and COM default property access. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SafeDictSet(obj As Variant, key As String, value As Variant)</strong> <br> <strong>Purpose:</strong> safe setter for dictionaries and generic COM objects supporting default member assignment; returns Boolean success. <br> <strong>Inputs:</strong> obj, key, value. <br> <strong>Returns:</strong> True/False. <br> <strong>Side-effects:</strong> mutates object. <br> <strong>Error semantics:</strong> returns False on error. <br> <strong>Suggested tests:</strong> dictionary set/get, COM object property assignment. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>RotateAndSign(rotationPolicyJson As String)</strong> <br> <strong>Purpose:</strong> rotation workflow to bundle rotation manifest + per-row references, compute <code>rotationHash</code> by concatenating payloadHash values, call signer <code>CallSignRotation</code> to sign the manifest, write rotation bundle to <code>AUDIT_ROTATIONS_DIR</code>, append <code>rotation.completed</code> audit row and return bundle metadata. <br> <strong>Inputs:</strong> <code>rotationPolicyJson</code> string (present but not parsed by current implementation). <br> <strong>Returns:</strong> dict <code>{status, rotationPath, rotationHash, signature}</code> or error object. <br> <strong>Detailed behavior & notes:</strong> <br> • reads <code>lastOffset</code> via <code>LoadTailIndex</code>; no-op when lastOffset < 0. <br> • computes <code>rotationHash = sha256(concatenate(payloadHash_i))</code> across offsets <code>firstOffset..lastOffset</code> (currently <code>firstOffset</code> fixed to 0). <br> • builds <code>manifest</code> with offsets, rotationHash, rotationTs, configHash etc. <br> • calls <code>CallSignRotation(manifestJson)</code> to obtain signature — host must implement (default returns empty). <br> • writes <code>rotation-&lt;safeTs&gt;-&lt;first&gt;-&lt;last&gt;.bundle.json</code> containing manifest, signature, <code>rowsBundle</code> abbreviated entries. <br> • builds <code>rotationParamsObj</code> and appends <code>rotation.completed</code> audit row using <code>BuildAuditRow</code> and <code>AppendAuditRow</code>. <br> <strong>Side-effects:</strong> writes rotation bundle file and appends audit. <br> <strong>Error semantics:</strong> if <code>CallSignRotation</code> fails -> <code>SignFail</code> branch appends <code>rotation.failed</code> audit and returns <code>ERR_ROT_SIGN</code>. <br> <strong>Edge-cases:</strong> <code>firstOffset</code> hard-coded to 0 (host should parameterize), rotationHash method may be policy-dependent. <br> <strong>Suggested tests:</strong> mock <code>CallSignRotation</code> to return signature, verify bundle contents and appended audit row; test signer failure path. <br> <strong>Complexity:</strong> O(n) across rotation extent. <br> <strong>Security:</strong> signer integration must guarantee private key secrecy (use HSM/KMS). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CallSignRotation(manifestJson As String)</strong> <br> <strong>Purpose:</strong> host stub to sign rotation manifest; default returns empty string. <br> <strong>Inputs:</strong> <code>manifestJson</code>. <br> <strong>Returns:</strong> string <code>signature</code> (host-provided) or empty. <br> <strong>Side-effects:</strong> none in stub. <br> <strong>Error semantics / Notes:</strong> production must implement using HSM/KMS; returns empty to indicate signer absent. <br> <strong>Suggested tests:</strong> host-provided mock returning deterministic signature. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>EncryptAndStoreEvidence(sanitizedParamsJson As String, operatorId As String, retentionPolicy As String)</strong> <br> <strong>Purpose:</strong> envelope-encrypt sanitized evidence or (dev) store plaintext when <code>ALLOW_PLAINTEXT_EVIDENCE</code> true; write encrypted blob and metadata, return <code>evidence://&lt;id&gt;</code> or deferred token <code>deferred:&lt;token&gt;</code> if encryption deferred/unavailable. <br> <strong>Inputs:</strong> sanitized JSON string, operatorId, retentionPolicy string. <br> <strong>Returns:</strong> evidenceRef string or deferred token. <br> <strong>Algorithm & behavior:</strong> <br> 1. Call <code>CallGenerateEnvelopeKey()</code> to obtain envelope (must include <code>dataKeyBase64</code>). <br> 2. If envelope missing and <code>ALLOW_PLAINTEXT_EVIDENCE=False</code> -> raise <code>vbObjectError +720</code> (caught by caller). If <code>ALLOW_PLAINTEXT_EVIDENCE=True</code> write plaintext bytes (dev only). <br> 3. Call <code>CallEncryptWithDataKey(envelope(&quot;dataKeyBase64&quot;), StrToUtf8(sanitizedParamsJson))</code> and expect Either byte array or base64 string; write binary evidence file <code>evidence/&lt;evidenceId&gt;.enc</code>. <br> 4. Write meta JSON <code>evidence/&lt;evidenceId&gt;.meta.json</code> with uploaderId, createdAt, retention, and wrapped key if provided. <br> 5. Return <code>evidence://&lt;evidenceId&gt;</code> on success; on encryption failures return <code>&quot;deferred:&quot; &amp; MakeDeferredToken(...)</code>. <br> <strong>Side-effects:</strong> writes files under <code>EVIDENCE_DIR</code>. <br> <strong>Error semantics:</strong> returns deferred token for transient encryption errors; raises for missing KMS envelope when plaintext disallowed. <br> <strong>Edge-cases:</strong> envelope missing but <code>ALLOW_PLAINTEXT_EVIDENCE</code> True -> plaintext written (dangerous for prod). <br> <strong>Suggested tests:</strong> envelope success, ciphertext base64 vs byte array return handling, deferred behavior on simulated encryption exception, metadata write. <br> <strong>Complexity:</strong> dominated by encryption + disk IO. <br> <strong>Security:</strong> must have host-provided <code>CallGenerateEnvelopeKey</code> and <code>CallEncryptWithDataKey</code> implemented with KMS; <code>ALLOW_PLAINTEXT_EVIDENCE</code> must be false in production. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CallGenerateEnvelopeKey() / CallEncryptWithDataKey(dataKeyBase64, plaintextBytes())</strong> <br> <strong>Purpose:</strong> extension points for host KMS integration; module defaults return Nothing/Empty. <br> <strong>Inputs/Outputs:</strong> envelope generation returns object with <code>dataKeyBase64</code> and optionally <code>encryptedKeyBase64</code>; encryption returns encrypted byte array or base64 string. <br> <strong>Side-effects / Security notes:</strong> host MUST secure keys; wrapper should be implemented in trusted environment. <br> <strong>Suggested tests:</strong> provide mocks for CI to test encryption flows. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>MakeDeferredToken(seed As String)</strong> <br> <strong>Purpose:</strong> create deterministic-looking deferred token by hashing a payload containing seed, timestamp and RNG, returning hex SHA256. <br> <strong>Inputs:</strong> <code>seed</code> string. <br> <strong>Returns:</strong> hex string token. <br> <strong>Side-effects:</strong> none. <br> <strong>Suggested tests:</strong> uniqueness/time sensitivity. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>Base64ToBytes(b64 As String)</strong> <br> <strong>Purpose:</strong> decode Base64 into byte array using MSXML DOM <code>nodeTypedValue</code> binary node. <br> <strong>Inputs:</strong> base64 string. <br> <strong>Returns:</strong> Byte() array or zero-length on error. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns empty array on decode errors. <br> <strong>Suggested tests:</strong> valid base64 and invalid string. <br> <strong>Complexity:</strong> O(n). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ExportForForensics(querySpecJson As String, operatorId As String, ticketId As String)</strong> <br> <strong>Purpose:</strong> secure export flow: verify operator via <code>CallValidateExportOperator</code>, collect requested rows + evidenceRef metadata, envelope-encrypt bundle using <code>CallGenerateEnvelopeKey</code> / <code>CallEncryptWithDataKey</code>, write encrypted forensic blob to <code>forensics/&lt;exportId&gt;.enc</code>, append <code>forensic.export</code> audit row and return <code>forensic://&lt;id&gt;</code> with checksum <code>sha256:&lt;hex&gt;</code>. <br> <strong>Inputs:</strong> querySpecJson, operatorId, ticketId. <br> <strong>Returns:</strong> result dict <code>{status, exportUri, exportChecksum}</code> or error. <br> <strong>Detailed behavior & preconditions:</strong> <br> 1. Validate operator via <code>CallValidateExportOperator</code> — host must implement. If validation fails return <code>ERR_EXPORT_AUTH</code>. <br> 2. Load tail index and iterate offsets <code>0..lastOffset</code> collecting minimal row descriptors into <code>rows</code> array (offset,rowId,payloadHash,evidenceRef). <br> 3. Build <code>exportBundle</code> with metadata and rows, convert to JSON, request envelope key and encrypt; write encrypted file and return <code>forensic://&lt;exportId&gt;</code>. <br> 4. Append <code>audit.forensic.export</code> row using <code>BuildAuditRow</code> -> <code>AppendAuditRow</code>. <br> <strong>Side-effects:</strong> writes <code>forensics</code> blob, appends audit row. <br> <strong>Error semantics:</strong> returns structured error on operator auth failure or KMS/encryption errors. <br> <strong>Edge-cases:</strong> pending encryption supported via same envelope logic; host must implement <code>CallValidateExportOperator</code>. <br> <strong>Suggested tests:</strong> operator validation failure, encryption success (with mock), decryption verification in test harness. <br> <strong>Complexity:</strong> O(n) over rows. <br> <strong>Security:</strong> export must be encrypted and operator auth must be strictly enforced (MFA + ticketing recommended). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CallValidateExportOperator(operatorId As String, ticketId As String)</strong> <br> <strong>Purpose:</strong> host hook to validate export operators; module default raises <code>vbObjectError +740</code>. <br> <strong>Inputs:</strong> operatorId, ticketId. <br> <strong>Returns:</strong> Boolean authorized (host must implement). <br> <strong>Suggested tests:</strong> test harness should provide a mock returning True for authorized tests. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>VerifyAuditChain(Optional startOffset As Long = 0, Optional endOffset As Long = -1)</strong> <br> <strong>Purpose:</strong> verify chain integrity across contiguous offsets by recomputing payload hashes and verifying <code>prevHash</code> linkages; produce <code>mismatchReport</code> with typed mismatch entries. <br> <strong>Inputs:</strong> optional startOffset, endOffset (defaults to tail end via <code>LoadTailIndex</code>). <br> <strong>Returns:</strong> dict <code>{isValid As Boolean, mismatchReport As ArrayList}</code>. <br> <strong>Algorithm:</strong> iterate offsets <code>startOffset..endOffset</code>: <br> • if <code>LoadRowByOffset(i)</code> returns Nothing record <code>MISSING_OFFSET</code> <br> • compute <code>recomputed = ComputePayloadHashFromRow(r)</code> and compare to stored <code>r(&quot;payloadHash&quot;)</code> -> <code>PAYLOAD_MISMATCH</code> <br> • validate <code>prevHash</code> equals previous row's <code>payloadHash</code> -> <code>CHAIN_BREAK</code> <br> <strong>Side-effects:</strong> none. <br> <strong>Suggested tests:</strong> corrupted payloadHash, broken prevHash chain, missing row. <br> <strong>Complexity:</strong> O(n) for scanned range. <br> <strong>Security:</strong> primary tamper-detection function — run periodically and in CI. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>QueryAuditTail(Optional filter As String = "", Optional cursor As Long = 0, Optional pageSize As Long = 100, Optional follow As Boolean = False, Optional callerContext As Variant)</strong> <br> <strong>Purpose:</strong> read-only paginated tail query returning minimal structured rows with optional evidence gating via <code>CallAuthorizeEvidenceAccess</code>. <br> <strong>Inputs:</strong> <code>filter</code> substring, <code>cursor</code> offset, <code>pageSize</code>, <code>follow</code> (not fully streaming in code), <code>callerContext</code> (passed to <code>CallAuthorizeEvidenceAccess</code>). <br> <strong>Returns:</strong> dict <code>{rows As ArrayList, nextCursor As Long}</code>. <br> <strong>Behavior specifics:</strong> iterates offsets from cursor to <code>lastOffset</code>, collects row summary including <code>rowId</code>, <code>offset</code>, <code>timestamp</code>, <code>module</code>, <code>procedure</code>, <code>correlationId</code>, <code>paramsHash</code>, <code>payloadHash</code> and includes <code>evidenceRef</code> only when <code>CallAuthorizeEvidenceAccess(callerContext)</code> returns True. <br> <strong>Side-effects:</strong> none. <br> <strong>Suggested tests:</strong> paging correctness, filter matches, evidence gating toggles. <br> <strong>Complexity:</strong> O(pageSize * file-read). <br> <strong>Security:</strong> ensure <code>CallAuthorizeEvidenceAccess</code> implemented to control sensitive evidence access. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>CallAuthorizeEvidenceAccess(callerContext As Variant)</strong> <br> <strong>Purpose:</strong> host hook defaulting to False; should return Boolean indicating whether caller may see evidenceRef in <code>QueryAuditTail</code>. <br> <strong>Inputs:</strong> callerContext (opaque). <br> <strong>Returns:</strong> Boolean (by default False). <br> <strong>Suggested tests:</strong> provide mock True to validate evidence visibility. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>SafeErrorToOperator(correlationId As String, errorCode As String, userHint As String)</strong> <br> <strong>Purpose:</strong> compose UI-safe message including short reference id produced by appending <code>error.shown</code> audit row; ensures operator message contains correlationId but no PII; returns string message for display. <br> <strong>Inputs:</strong> correlationId, errorCode, userHint. <br> <strong>Returns:</strong> string message <code>errorCode (ref): userHint - contact infra with correlationId=&lt;id&gt;</code>. <br> <strong>Side-effects:</strong> attempts to <code>BuildAuditRow(&quot;DQ_Audit&quot;, &quot;error.shown&quot;, correlationId, &quot;{\&quot;errorCode\&quot;:\&quot;&quot; &amp; errorCode &amp; &quot;\&quot;}&quot;)</code> and <code>AppendAuditRow</code>; on append failure returns <code>r-deferred-&lt;hex&gt;</code> generated locally for short-reference. <br> <strong>Error semantics:</strong> always returns message; append errors suppressed and a deferred id used. <br> <strong>Suggested tests:</strong> append success path (message contains actual rowId), append failure path (message uses deferred id). <br> <strong>Complexity:</strong> trivial. <br> <strong>Security:</strong> ensure message does not contain user PII. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>Shutdown()</strong> <br> <strong>Purpose:</strong> graceful shutdown helper that emits <code>audit.shutdown</code> row and returns <code>status</code>. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> result dict <code>{status:&quot;ok&quot;}</code> or error info. <br> <strong>Side-effects:</strong> calls <code>BuildAuditRow(&quot;DQ_Audit&quot;, &quot;shutdown&quot;, GenerateRowId(), &quot;{}&quot;)</code> and <code>AppendAuditRow</code>. <br> <strong>Error semantics:</strong> exceptions converted to structured error return. <br> <strong>Suggested tests:</strong> normal success and simulated append failure. <br> <strong>Complexity:</strong> trivial. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>LoadAuditConfig(configJson As String)</strong> <br> <strong>Purpose:</strong> parse and return parsed configuration object and placeholder <code>configHash</code>. <br> <strong>Inputs:</strong> <code>configJson</code>. <br> <strong>Returns:</strong> dict <code>{status, config, configHash}</code> or error. <br> <strong>Side-effects:</strong> none. <br> <strong>Error semantics:</strong> returns <code>status=error</code> and message when empty or parse fails. <br> <strong>Suggested tests:</strong> valid JSON, empty JSON. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>ParseJsonSafeReturn(ByVal txt As String)</strong> <br> <strong>Purpose:</strong> wrapper calling <code>JsonConverter.ParseJson</code> within <code>On Error</code> and returning <code>Nothing</code> on failure. <br> <strong>Inputs:</strong> JSON text. <br> <strong>Returns:</strong> parsed object or <code>Nothing</code>. <br> <strong>Side-effects:</strong> none. <br> <strong>Suggested tests:</strong> parse success and failure. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>LoadAppliedMigrationsRegistry()</strong> <br> <strong>Purpose:</strong> read <code>evidence/migrations.applied.json</code> into a <code>Scripting.Dictionary</code> mapping applied migrations; returns empty dict if none/parse fail. <br> <strong>Inputs:</strong> none. <br> <strong>Returns:</strong> dictionary. <br> <strong>Side-effects:</strong> reads file if present. <br> <strong>Error semantics:</strong> suppressed; returns empty dictionary on parse error. <br> <strong>Suggested tests:</strong> registry file present with entries; missing file returns empty. </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>EscapeJsonString(s As String)</strong> <br> <strong>Purpose:</strong> escape backslashes, quotes, and newline sequences for embedding raw strings into JSON quoted values. <br> <strong>Inputs:</strong> <code>s</code> string. <br> <strong>Returns:</strong> escaped string. <br> <strong>Side-effects:</strong> none. <br> <strong>Suggested tests:</strong> strings containing <code>\</code>, <code>&quot;</code>, CRLF combos. <br> <strong>Complexity:</strong> O(n). </td></tr><tr><td data-label="DQ_Audit — Per-function expert technical breakdown"> <strong>Final verification & operational notes (code-accurate):</strong> <br> <strong>Mandatory host implementations before production:</strong> <br> 1. <code>CallSignRotation</code> (HSM/KMS signer) <br> 2. <code>CallGenerateEnvelopeKey</code> & <code>CallEncryptWithDataKey</code> (KMS envelope encryption) <br> 3. <code>CallValidateExportOperator</code> (export authorization) <br> 4. <code>CallAuthorizeEvidenceAccess</code> (evidence gating) <br> <strong>Important invariants from code:</strong> <br> 1. Payload hashing excludes append-time fields (<code>payloadHash</code>, <code>prevHash</code>, <code>offset</code>, <code>signatureRef</code>) — changing this will break chain verification. <br> 2. Idempotency is implemented by checking <code>rowId</code> mapping to existing offset + identical <code>payloadHash</code> — callers should supply stable <code>rowId</code> when idempotency is desired. <br> 3. Atomic append relies on filesystem <code>Name</code> (rename) semantics; on network filesystems stronger coordination or object-store conditional-put is required. <br> <strong>Suggested test matrix derived directly from functions:</strong> <br> 1. Unit tests: canonicalization parity, SHA256 RFC vectors, serializer fallbacks, row builder behavior. <br> 2. Integration tests: append→read parity, index persistence, rotation bundle creation with mock signer, evidence encryption with KMS mock. <br> 3. Stress tests: concurrent <code>AtomicAppend</code> with simulated multi-writer collisions, sustained append throughput verifying <code>APPEND_LOCK_RETRIES</code> / <code>ATOMIC_RENAME_RETRIES</code> behavior. <br> <strong>Security & compliance guidance (derived from code):</strong> <br> 1. Implement KMS envelope & signing in host — do not enable <code>ALLOW_PLAINTEXT_EVIDENCE</code> in production. <br> 2. Consider signing <code>tail.index.json</code> / <code>rows.index.json</code> to harden the trust anchor. <br> 3. Implement <code>NormalizeToNFC</code> for cross-locale deterministic canonicalization. <br> <strong>Recovery & operational runbook items (code-informed):</strong> <br> 1. On append failure (rename/IO) inspect <code>tmp</code> directory for orphan <code>.part</code> files; check <code>tail.index.json</code> and the <code>rows</code> directory for last committed offset. <br> 2. If <code>VerifyAuditChain</code> reports mismatches, produce forensic export with <code>ExportForForensics</code> and escalate to secops/compliance as appropriate. <br> <strong>Host integration checklist pre-prod:</strong> <br> 1. Provide signer & envelope implementations. <br> 2. Provide export operator validation hook. <br> 3. Ensure data-root backing store ACLs and atomic-rename semantics are validated for the chosen deployment filesystem. </td></tr></tbody></table></div><div class="row-count">Rows: 72</div></div><div class="table-caption" id="Table6" data-table="Docu_0177_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Error — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Error — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong>Module-level summary (owner, purpose, audit obligations, public API)</strong><br><strong>Owner:</strong> <code>team:data-quality/ownership</code> (primary), <code>team:security</code> (KMS/HSM approval), <code>team:observability</code> (metrics & audit ingestion).<br><strong>Purpose:</strong> centralize error taxonomy and lifecycle: canonical codes, stable metadata, operator-facing messages, deterministic audit linkage, redaction/evidence packaging, recovery mapping, rate-limiting/throttling, and hotpatchable catalog management. Provide lightweight runtime helpers for handlers and workers to create, map, serialize, and publish errors with consistent semantics across UI, worker, PQ, and CI flows. Ensure every user-initiated flow links to an audit chain anchored by a <code>correlationId</code> and at least one <code>error.recorded</code> audit row when a problem occurs. Expose programmatic API to query catalog, construct safe operator messages, schedule remediation actions, and serialize evidence for encrypted storage.<br><strong>Public API surface:</strong> <code>InitializeErrorCatalog()</code>, <code>LoadErrorCatalog(path)</code>, <code>ValidateErrorCode(code)</code>, <code>NewError(code, ctx)</code>, <code>WrapError(err, ctx)</code>, <code>MapErrorToOperatorMessage(error, locale?, role?)</code>, <code>SafeErrorToUser(correlationId, error)</code>, <code>EmitErrorAudit(correlationId, error, severity, evidenceRef?)</code>, <code>SerializeErrorForEvidence(error, redact=true)</code>, <code>RegisterErrorHandler(name, handler)</code>, <code>HandleUnhandledException(ex, context)</code>, <code>MapErrorRecoveryAction(code)</code>, <code>ErrorMetricsEmit(metric,tags)</code>, <code>RotateErrorDocs()</code>, <code>HotPatchErrorCatalog(newCatalog, approvals)</code>, <code>ShutdownErrorModule()</code>.<br><strong>Audit obligations:</strong> every <code>NewError</code> from a user flow must produce an <code>error.recorded</code> audit with: <code>timestamp, correlationId, module=DQ_Error, procedure=error.recorded, errorId, code, severity, paramsHash, evidenceRef, configHash, errorCatalogHash, prevHash, metadata</code>. Redacted parameters only in the main audit; full sanitized payload saved encrypted and referenced by <code>evidenceRef</code>. All audits must be chainable (prevHash) so <code>VerifyAuditChain</code> can validate integrity in CI/monitoring. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong>Design principles & invariants (module-level)</strong><br>1. <em>Determinism</em>: canonical hashing of catalogs, stable code formats, canonical param serialization (key-sorted, locale-normalized) to ensure reproducible <code>paramsHash</code>/<code>payloadHash</code> across runs.<br>2. <em>PII minimization & redaction</em>: main audit rows must never contain PII; redaction rules applied before any non-encrypted persistence; evidence store is the only place holding sanitized fuller context (encrypted & RBAC-protected).<br>3. <em>Fail-safe defaults</em>: catalog signature failures cause fail-closed for regulated codes (disable sensitive actions), but allow minimal embedded catalog to enable diagnostics. <br>4. <em>Non-blocking UI contracts</em>: error creation and UI-safe messages must not perform network or heavy disk IO on UI paths; evidence writes and audit persistence are buffered and flushed asynchronously. <br>5. <em>Observability & triage</em>: each error lifecycle emits metrics (<code>dq.error.count</code>, <code>dq.error.fatal.rate</code>, <code>dq.error.audit.latency</code>), and every UI message includes <code>correlationId</code> for triage. <br>6. <em>Security</em>: evidence storage encryption via KMS/HSM; catalog signature verification enforced for production; access to forensic artifacts requires MFA and <code>forensic:read</code> role. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>InitializeErrorCatalog()</code> — load embedded + external catalogs, build indices, signature verification</strong><br><strong>Purpose & contract (code-accurate):</strong> initializes in-memory structures and seeds the embedded baseline. Implementation details per module code: allocates <code>gErrorCatalog</code>, <code>gHandlers</code>, <code>gRateWindow</code>, <code>gUnitTestHooks</code>, <code>gAuditBuffer</code>, <code>gEvidenceBuffer</code>, and <code>gMetricsBuffer</code> if missing; calls <code>ClearCatalog</code> then inserts a small set of embedded entries via <code>AddCatalogEntry_Internal</code> (<code>ERR_UNKNOWN_CODE</code>, <code>ERR_INTERNAL_UNKNOWN</code>, <code>ERR_DB_CONN</code>, <code>RUL_VALIDATION_FAILED</code>); computes <code>gCatalogHash = ComputeCanonicalHash_Catalog(gErrorCatalog)</code> and sets <code>gCatalogVersion = &quot;embedded-1&quot;</code>. Ensures audit/evidence/catalog sheets exist (<code>EnsureAuditSheetExists</code>, <code>EnsureEvidenceSheetExists</code>, <code>EnsureCatalogSheetExists</code>) and buffers <code>bootstrap.started</code> audit row via <code>BufferAuditSimpleRow</code>. Failure handling: on exception, <code>bootstrap.failed</code> audit is buffered. Contract notes: must be safe to call multiple times; avoid heavy IO during the UI bootstrap path; used as a minimal, trusted baseline if external catalog loading fails. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>LoadErrorCatalog(path)</code> — explicit ingestion tooling (file/URI), strict validation, and canonicalization</strong><br><strong>Purpose & contract (code-accurate):</strong> deterministic ingestion from a worksheet name or JSON text. Behavior implemented in code: if <code>path</code> corresponds to an existing workbook sheet, the routine reads rows (starting row 2) and builds a <code>parsed</code> collection of small dictionaries with <code>code</code>, <code>raw</code> (string), <code>title</code>, <code>severity</code>, <code>owner</code>, <code>operatorHint</code>. Otherwise treats <code>path</code> as JSON text and parses via <code>SimpleJsonParseArrayOfObjects</code>. Performs schema validation by calling <code>ValidateCatalogSchema(parsed, errorsFound, warningsFound)</code> and buffers <code>error.catalog.validation.failed</code> on structural errors; may abort unless <code>gAllowUnsafeCatalogInDev</code> is true. If <code>gRequireSignedCatalog</code> is true, calls <code>VerifyCatalogSignature(txt, signatureBlock)</code> and enforces fail-closed semantics for FATAL entries (reject load unless <code>gAllowUnsafeCatalogInDev</code> override). Assembles <code>newCatalog</code> as <code>Scripting.Dictionary</code> entries with keys normalized to uppercase codes, enforces code name regex and severity via <code>IsCodeNameValid</code>/<code>AllowedSeveritySet</code>. On success atomically swaps <code>gErrorCatalog</code>, recomputes <code>gCatalogHash = ComputeCanonicalHash_Catalog(gErrorCatalog)</code>, sets <code>gCatalogVersion = &quot;loaded-&quot; &amp; Left(gCatalogHash,12)</code>, writes new catalog rows into <code>CATALOG_SHEET_NAME</code> (clearing rows 2..end first), and buffers <code>error.catalog.loaded</code> audit with <code>catalogHash</code> and <code>source</code>. On exception buffers <code>error.catalog.load.exception</code>. Notes: this implementation emphasizes deterministic canonicalization, sheet-based ingestion convenience, signature check hooks via handlers, and a conservative load/fallback posture. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>ValidateErrorCode(code)</code> — canonical lookup and guard</strong><br><strong>Purpose & contract (code-accurate):</strong> returns a Dictionary-like <code>ErrorMeta</code> for <code>code</code> or a generated fallback mapping for unknown/disabled codes. Implementation specifics: uppercases and trims input; if empty returns a generated <code>ERR_UNKNOWN_CODE</code> meta; ensures <code>gErrorCatalog</code> initialized via <code>InitializeErrorCatalog</code> if nil; if catalog contains the code returns meta, but if meta has <code>disabled = True</code> it buffers <code>dq_error.validate.disabled</code> and returns a safe <code>ERR_UNKNOWN_CODE</code> meta explaining disabled status. Missing codes buffer <code>dq_error.validate.missing</code>. Errors in validation are caught and produce <code>ERR_INTERNAL_UNKNOWN</code> meta and audit <code>dq_error.validate.exception</code>. Contract: pure lookup except that on validation failures it emits small audit rows and always returns a stable dictionary-like meta object. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>NewError(code, context)</code> — canonical error construction and audit anchoring</strong><br><strong>Purpose & contract (code-accurate):</strong> constructs an <code>errRec</code> Scripting.Dictionary with canonical fields and buffers an audit row. Code specifics: calls <code>ValidateErrorCode(code)</code> to get <code>meta</code>; fills fields <code>errorId = CreateUUID()</code>, <code>code</code>, <code>severity</code>, <code>message</code> (from meta.title), <code>operatorHint</code>, <code>module=&quot;DQ_Error&quot;</code>, <code>correlationId</code> derived from <code>context</code> if Dictionary has <code>correlationId</code>, otherwise generates <code>cid-&lt;uuid8&gt;</code>, <code>paramsHash = ComputeParamsHash(ctx)</code>, <code>evidenceRef</code>/<code>stackRef</code> empty, <code>createdBy = Application.UserName</code>, <code>timestamp = Now</code>, <code>prevErrorId</code> empty, <code>errorCatalogHash = gCatalogHash</code>, <code>configHash = GetConfigHashSafe()</code>. Immediately calls <code>BufferAuditRow(correlationId, errRec, severity, &quot;&quot;)</code> (buffered append) and <code>IncrementMetric &quot;dq.error.count&quot;</code>. Returns the in-memory <code>errRec</code> (dictionary) to caller. Error handling: on creation failure constructs fallback <code>failObj</code> with <code>ERR_INTERNAL_UNKNOWN</code>, buffers an audit row and returns fallback. Contract notes: <code>NewError</code> never performs network or long IO — audits are buffered for asynchronous flush; <code>paramsHash</code> uses canonicalized key-sorted serialization. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>WrapError(ex, context)</code> — map arbitrary exceptions to canonical codes</strong><br><strong>Purpose & contract (code-accurate):</strong> safe wrapper that maps library/host exceptions into <code>ErrorRecord</code> via <code>MapLibraryErrorToCode</code>, then calls <code>NewError(mappedCode, ctx)</code> and persists evidence. Implementation: determines <code>mappedCode = MapLibraryErrorToCode(ex)</code>, creates <code>rec = NewError(mappedCode, ctx)</code>, calls <code>SerializeErrorForEvidence(rec, True)</code> to produce <code>evidenceRef</code> and sets it on <code>rec</code> if non-empty, buffers <code>error.wrapped</code> audit with <code>errorId</code> and <code>evidenceRef</code>, and returns <code>rec</code>. Failure path: if <code>WrapError</code> itself fails it returns a minimal fallback Dictionary that avoids recursive calls to <code>NewError</code>, buffers a <code>wrap failed</code> audit via <code>BufferAuditRow</code> and returns fallback. Contract: designed to be robust in exception paths and to always return a dictionary-like record for downstream use; evidence serialization is best-effort and delegated to handler if registered. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>MapErrorToOperatorMessage(errRec, locale=&#x27;en-US&#x27;, role=&#x27;operator&#x27;)</code> — UI-safe mapping</strong><br><strong>Purpose & contract (code-accurate):</strong> builds a small Dictionary <code>msg</code> with <code>title</code>, <code>body</code>, <code>actions[]</code>, <code>severity</code>, <code>correlationId</code>, and optionally <code>debugActions</code> for admin roles. Implementation specifics from code: truncates title to 120 characters and body to 160 characters using <code>TruncateString</code>; default actions array <code>(&quot;Retry&quot;,&quot;CollectDiagnostics&quot;,&quot;ContactSRE&quot;)</code>; for <code>role=&#x27;admin&#x27;</code> includes <code>debugActions</code> array <code>(&quot;FetchEvidence&quot;,&quot;FetchStackTrace&quot;)</code>. Emits <code>dq_error.operator_message.generated</code> metric via <code>IncrementMetric</code>. Failure fallback returns a minimal <code>Service unavailable</code> message. Contract: no PII, localized hints supported via <code>locale</code> param (stubbed in code), and metrics emitted. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(correlationId, errRec)</code> — final UI wrapper with audit</strong><br><strong>Purpose & contract (code-accurate):</strong> synchronous wrapper that ensures canonical record, builds UI payload, buffers a short <code>ui.userErrorShown</code> audit, and returns <code>{status,message,correlationId}</code>. Implementation details: if <code>errRec</code> is not object calls <code>WrapError</code> with a dummy ctx; obtains <code>operatorMessage = MapErrorToOperatorMessage(canonical, &quot;en-US&quot;, &quot;user&quot;)</code>; builds <code>uiMsg</code> dictionary with <code>status=&quot;error&quot;</code>, <code>message=operatorMessage</code>, and <code>correlationId</code>; builds a short <code>auditObj</code> containing <code>correlationId</code>, <code>code</code>, and a <code>messageId</code> (first 12 chars of UUID) and buffers <code>ui.userErrorShown</code> via <code>BufferAuditSimpleRow</code>. Returns <code>uiMsg</code>. Error path returns a minimal error object. Contract: must be fast & PII-free; buffers audit only. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>EmitErrorAudit(correlationId, error, severity, evidenceRef=null, extraMetadata={})</code> — canonical audit append</strong><br><strong>Purpose & contract (code-accurate):</strong> thin public wrapper that calls <code>BufferAuditRow</code> to enqueue a canonical <code>error.recorded</code> audit entry. Implementation in code: <code>EmitErrorAudit</code> simply delegates to <code>BufferAuditRow correlationId, errRec, severity, IIf(IsMissing(evidenceRef), vbNullString, evidenceRef)</code>. Note buffer semantics: audit rows are queued into <code>gAuditBuffer</code> and later persisted by <code>FlushAuditBuffer</code>. Contract: non-blocking for callers; caller must flush buffers or rely on periodic flush. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>SerializeErrorForEvidence(errRec, redact=true)</code> — canonicalized, redacted evidence packaging</strong><br><strong>Purpose & contract (code-accurate):</strong> produce canonical string blob, apply redaction, compute SHA256 payload hash, and delegate optional encryption/storage to a registered handler or fallback to local encrypted placeholder and buffer evidence metadata. Implementation details: uses <code>CanonicalizeErrorRecordForEvidence(errRec)</code> to produce a deterministic string (sorted keys via <code>QuickSortStringArray</code> with <code>CanonicalValueString</code> rendering of values), applies <code>ApplyRedaction</code> when <code>redact=True</code>, truncates binary/oversize (>1MB) via <code>LenB</code> and <code>LeftB</code>, computes <code>payloadHash = ComputeCanonicalHash_String(blob)</code>. If <code>gHandlers(&quot;encryptEvidenceHandler&quot;)</code> is registered, calls handler via <code>Application.Run(handlerName, blob, payloadHash)</code> and expects either a dictionary containing <code>evidenceRef</code>, <code>payloadHash</code>, <code>encryptedPayload</code>, <code>keyFingerprint</code>, <code>storageUri</code> or a string; on handler-provided dictionary stores an <code>evItem</code> into <code>gEvidenceBuffer</code> with returned metadata and returns <code>evidenceRefHandler</code>. If handler call fails or not registered, falls back to <code>evidenceRefFallback = &quot;evi-&quot; &amp; left(CreateUUID(),12)</code>, stores <code>evItem2</code> with <code>encryptedPayload = EncryptEvidenceBlob(blob)</code> into <code>gEvidenceBuffer</code>, increments metric <code>dq.evidence.write.buffered</code> and returns fallback. On internal error buffers <code>error.evidence.serialize.failed</code> and returns empty string. Contract: best-effort, handler-delegated, buffered evidence writes; never leak unredacted evidence into main audit. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>CanonicalizeErrorRecordForEvidence(errRec)</code> & <code>CanonicalValueString(v)</code> — canonical stringification</strong><br><strong>Purpose & contract (code-accurate):</strong> deterministic string serialization for evidence hashing. Implementation specifics: when <code>errRec</code> is object collects keys into an array, sorts them via <code>QuickSortStringArray</code>, and concatenates <code>key:CanonicalValueString(value);</code> entries. <code>CanonicalValueString</code> handles Date formatting (<code>yyyy-mm-dd\Thh:nn:ss\Z</code>), numeric rounding (Round to 6 decimals), objects via <code>SafeToString</code> and fallback to <code>CStr</code>. Contract: produce stable string for hashing regardless of original insertion order. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>RegisterErrorHandler(name, handlerName)</code> — controlled handler registration</strong><br><strong>Purpose & contract (code-accurate):</strong> registers named handler functions into <code>gHandlers</code> dictionary for delegation (e.g., <code>encryptEvidenceHandler</code>, <code>verifyCatalogSignature</code>, <code>evidenceAccessHandler</code>). Implementation: validates non-empty <code>name</code> and <code>handlerName</code>, idempotently stores mapping <code>gHandlers(name) = handlerName</code>, and <code>BufferAuditSimpleRow &quot;error.handler.registered&quot;</code>. Contract: only stores handler name (string) to be invoked via <code>Application.Run</code>; no verification of handler signature at registration time. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>HandleUnhandledException(ex, context)</code> — top-level catch-all & graceful degrade</strong><br><strong>Purpose & contract (code-accurate):</strong> single-entry for uncaught exceptions. Implementation: calls <code>WrapError(ex, context)</code> to obtain <code>vRec</code> (dictionary), ensures <code>rec</code> is dictionary (creates minimal dictionary if not), calls <code>SerializeErrorForEvidence(rec, True)</code> and sets <code>rec(&quot;evidenceRef&quot;)</code> if present, calls <code>BufferAuditRow</code> to enqueue <code>error.recorded</code>, and if <code>rec(&quot;severity&quot;) = FATAL</code> then <code>FlushAllBuffers</code> and <code>ShutdownErrorModule</code>. On handler failure buffers <code>error.unhandled.exception</code>. Contract: best-effort persistence and controlled shutdown for fatal errors; never expose stack traces to UI. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>MapErrorRecoveryAction(code)</code> — deterministic recovery mapping and approvals</strong><br><strong>Purpose & contract (code-accurate):</strong> consults <code>ValidateErrorCode(code)</code> meta and builds a Collection of action dictionaries. Implementation specifics: for <code>FATAL</code> produces <code>require-approval</code> with <code>requiredApprovals</code> including <code>team:security</code> and meta owner; for <code>ERROR</code> produces <code>auto-retry</code> with <code>dryRunCommand = &quot;retry --code &quot; &amp; meta(&quot;code&quot;)</code>; default produces <code>manual-instruction</code>. Returns a Collection of action dictionaries. On error returns a fallback Collection with one <code>manual-instruction</code>. Contract: deterministic mapping based on catalog severity and owner; callers must implement approval workflows for <code>require-approval</code>. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>ErrorMetricsEmit(metricName, value, tags)</code> — local buffering & cardinality control</strong><br><strong>Purpose & contract (code-accurate):</strong> wrapper <code>ErrorMetricsEmit</code> builds a Dictionary <code>entry</code> with <code>metric</code>, <code>value</code>, <code>tags = ScrubTags(tags)</code>, <code>ts = Now</code> and appends to <code>gMetricsBuffer</code>; buffers an audit <code>dq.error.metric.buffered</code>. <code>IncrementMetric</code> is a typed wrapper that calls <code>ErrorMetricsEmit</code>. <code>ScrubTags</code> removes email-like tags and anything containing "password". Contract: buffered metrics, scrubbed tags, minimal synchronous work on UI path. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>RotateErrorDocs()</code> — catalog/document rotation and signing</strong><br><strong>Purpose & contract (code-accurate):</strong> creates a catalog snapshot row in <code>DQ_CatalogSnapshots</code> with <code>rotationId = &quot;snap-&quot; &amp; left(CreateUUID(),10)</code>, <code>ts = Now</code>, <code>catalogHash = gCatalogHash</code>, <code>note = &quot;rotated&quot;</code>, and buffers <code>error.catalog.rotation</code> audit. On exception buffers <code>error.catalog.rotation.failed</code>. Contract: lightweight snapshot + audit; signature step delegated if handler exists (signing not performed inline in provided code). </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>HotPatchErrorCatalog(newCatalogJson, operatorId, approvals)</code> — emergency patch workflow</strong><br><strong>Purpose & contract (code-accurate):</strong> parser + validator + transactional swap implementation present in code. Steps: parse <code>newCatalogJson</code> via <code>SimpleJsonParseArrayOfObjects</code>, compute <code>added</code> and <code>changed</code> sets by comparing <code>raw</code> fields, detect any <code>fatal</code> severity requiring two-person approval (reject if insufficient <code>approvals</code>), build <code>newCatalog</code> dictionary with normalized uppercase codes and fields, execute registered unit-test hooks in <code>gUnitTestHooks</code> by <code>Application.Run(handlerName, newCatalog)</code> expecting boolean true to pass (on failure audit and revert), atomically swap <code>gErrorCatalog = newCatalog</code>, compute <code>oldHash</code> and new <code>gCatalogHash</code>, persist sheet rows under <code>CATALOG_SHEET_NAME</code> clearing rows 2..end first, buffer <code>error.catalog.hotswap.applied</code> with <code>beforeHash</code>/<code>afterHash</code> and <code>preview</code>. On error buffer <code>error.catalog.hotswap.failed</code> and return False. Contract: requires operator role <code>error.catalog:hotswap</code> caller-side; runs smoke tests and enforces approval for fatal/regulatory changes; persistent sheet write is atomic-ish (clears then writes). </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>HandleRateLimitAndBackoff(errorCode, context)</code> — noisy-source mitigation</strong><br><strong>Purpose & contract (code-accurate):</strong> sliding-window sampler implementation using <code>gRateWindow</code> dictionary keyed by <code>code|source</code>. Window defaults: <code>windowSeconds=60</code>, <code>threshold=5</code>. Behavior: first occurrence sets <code>count=1, firstTs=now</code> and returns <code>CreateKV(&quot;sample&quot;, False, &quot;reason&quot;, &quot;first&quot;)</code>. Subsequent events in same window increment count; below threshold returns <code>sample=False</code>. Beyond threshold returns sampled suppression where occasionally one-in-n events allowed (<code>n=10</code>) and otherwise returns <code>sample=True</code> (suppressed). Resets window when now-firstTs > windowSeconds. Error fallback returns <code>sample=False</code> and reason <code>error</code>. Contract: intended to reduce audit volume while preserving accurate metric counts elsewhere; callers should honor returned <code>sample</code> to decide whether to write full evidence/audit. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>SerializeForensicPackage(correlationId, timeWindow)</code> — forensic export for incident response</strong><br><strong>Purpose & contract (code-accurate):</strong> creates a simple manifest row in worksheet <code>DQ_Forensic</code> with <code>manifestId = &quot;for-&quot; &amp; left(CreateUUID(),12)</code>, <code>correlationId</code>, <code>timeWindow</code>, <code>Now</code>, and <code>gCatalogHash</code>, buffers <code>forensic.exported</code> audit and returns <code>manifestId</code>. On error buffers <code>forensic.export.failed</code> and returns empty string. Note: actual assembling of evidence blobs and packaging is expected to be performed by <code>modExport</code> or external implementation; this function guarantees a minimal manifest record and audit. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName, handlerName)</code> — CI harness & golden runs</strong><br><strong>Purpose & contract (code-accurate):</strong> records <code>gUnitTestHooks(hookName) = handlerName</code> and buffers <code>test.hook.registered</code> audit. Hooks are invoked in <code>HotPatchErrorCatalog</code> smoke tests and <code>RunDQErrorSelfChecks</code>. Hooks must be callable via <code>Application.Run</code>. Contract: hooks are stored in-memory and persisted only by external manifests; production guards around <code>allow_test_hooks</code> are caller-responsibility. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>ShutdownErrorModule()</code> — graceful shutdown, audit flush ordering, and snapshot</strong><br><strong>Purpose & contract (code-accurate):</strong> flushes all buffers (<code>FlushAllBuffers</code>), clears <code>gUnitTestHooks</code> and <code>gHandlers</code>, sets <code>gShutdownFlag = True</code>, writes a small <code>DQ_State</code> worksheet snapshot with <code>lastShutdown</code> timestamp and <code>errorCatalogHash</code>, buffers <code>error.shutdown</code> audit. On error buffers <code>error.shutdown.failed</code>. Contract: idempotent safe shutdown; used by <code>HandleUnhandledException</code> on fatal errors. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>RunDQErrorSelfChecks()</code> — deterministic self-check loop (10×)</strong><br><strong>Purpose & contract (code-accurate):</strong> runs 10 iterations of light self-checks to validate catalog and evidence paths. Loop behavior: ensures catalog initialization, computes <code>gCatalogHash</code> if empty, verifies <code>ERR_UNKNOWN_CODE</code> baseline exists, builds deterministic context <code>ctx(&quot;correlationId&quot;) = &quot;selfcheck-&quot; &amp; i</code>, constructs <code>rec = NewError(&quot;ERR_DB_CONN&quot;, ctx)</code>, serializes evidence <code>SerializeErrorForEvidence(rec, True)</code>, sets <code>rec(&quot;evidenceRef&quot;)</code> if available, buffers <code>BufferAuditRow</code> and calls <code>FlushAuditBuffer False</code> and <code>FlushEvidenceBuffer</code> each iteration. Returns True if all iterations pass; on exception buffers <code>error.selfcheck.failed</code> and returns False. Contract: deterministic, idempotent smoke test to validate runtime plumbing and buffering. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong><code>FlushAllBuffers()</code> / <code>FlushAuditBuffer(force)</code> / <code>FlushEvidenceBuffer()</code> / <code>FlushMetricsBuffer()</code> — persistence semantics</strong><br><strong>Purpose & contract (code-accurate):</strong> buffered persistence layer writing to hidden worksheets. <code>FlushAuditBuffer(Optional force=False)</code> writes all queued <code>gAuditBuffer</code> items to <code>AUDIT_SHEET_NAME</code> appending rows and computing canonical <code>rowHash</code> per row. Implementation specifics: reads last row's <code>rowHash</code> into <code>lastRowHash</code>; for each buffered item writes timestamp, correlationId, module, procedure, errorId, code, severity, paramsHash, evidenceRef, configHash, errorCatalogHash; builds <code>rowStr = tsStr &amp; &quot;|&quot; &amp; cidStr &amp; &quot;|&quot; &amp; codeStr &amp; &quot;|&quot; &amp; evRefStr</code> and computes <code>rowHash = ComputeCanonicalHash_String(rowStr)</code>, writes <code>prevHash = lastRowHash</code>, <code>rowHash</code> into <code>AUDIT_ROWHASH_COL</code> and updates <code>lastRowHash</code>. Removes item from buffer and increments metric <code>dq.error.audit.appended</code>. On error buffers <code>error.audit.flush.failed</code>. <code>FlushEvidenceBuffer</code> writes <code>gEvidenceBuffer</code> items into <code>EVIDENCE_SHEET_NAME</code> rows with <code>evidenceRef,payloadHash,encryptedPayload,createdBy,createdTs</code> and increments <code>dq.evidence.write.flushed</code>. <code>FlushMetricsBuffer</code> writes metrics to <code>DQ_Metrics</code> sheet. Contract: atomicity is best-effort in Excel environment, hashing uses same canonicalization as in-memory; <code>FlushAuditBuffer</code> is the source of <code>prevHash</code> chaining used by <code>VerifyAuditChain</code>. </td></tr><tr><td data-label="DQ_Error — Per-function Expert Technical Breakdown"> <strong>Remaining module-level content</strong><br>All other rows, appendices, policies, SLOs, tests, operational runbooks, examples, and governance rules remain unchanged from the original document you supplied — only the per-function rows above were revised to match the exact behavior and implementation details in the provided VBA module. </td></tr></tbody></table></div><div class="row-count">Rows: 25</div></div><div class="table-caption" id="Table7" data-table="Docu_0177_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by REG_Bootstrap — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">REG_Bootstrap — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Module owner & API surface</strong><br><strong>Owner:</strong> <code>team-regulatory-core@company</code><br><strong>Public API:</strong> <code>BootstrapStart()</code>, <code>InitMinimalState(opts)</code>, <code>NewCorrelationId(parentCid?)</code>, <code>VerifyNoIOPolicy()</code>, <code>ScheduleDeferredInit(task, opts)</code>, <code>CancelDeferred(deferredHandle)</code>, <code>RegisterShutdown(handler, priority)</code>, <code>UnregisterShutdown(registrationId)</code>, <code>RecoverIfUncleanExit()</code>, <code>EmitBootstrapAudit(eventType, metadata)</code>, <code>GetBootstrapState()</code>.<br><strong>Audits emitted:</strong> <code>bootstrap.started</code>, <code>bootstrap.minimalState.created</code>, <code>bootstrap.deferred.scheduled</code>, <code>bootstrap.deferred.started</code>, <code>bootstrap.deferred.completed</code>, <code>bootstrap.deferred.failed</code>, <code>bootstrap.recovery</code>, <code>bootstrap.failed</code>, <code>bootstrap.shutdown</code>, <code>bootstrap.forbiddenApi.detected</code>, <code>bootstrap.policy.override</code>, <code>bootstrap.deferred.cancelled</code>.<br><strong>High-level purpose:</strong> tiny, authoritative bootstrap responsible for safe, <em>non-IO</em> initialization of the add-in environment, deterministic correlation ID generation, enforcement of a forbidden-API policy on hot paths, deferred-scheduling of IO-heavy initialization tasks, ordered shutdown handlers, and conservative unclean-exit forensic collection. The module is an audit-anchor: bootstrap emits canonical audit rows that every other module chains from. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Design constraints & non-functional mandates</strong><br>1. <strong>Non-IO hot path:</strong> anything that requires disk, network, or workbook enumeration must be deferred. <code>BootstrapStart()</code> and helpers must contain no synchronous IO. <br>2. <strong>Determinism for CI/golden runs:</strong> <code>InitMinimalState(testMode=true)</code> must produce deterministic seeds and correlation ids for golden artifact parity. <br>3. <strong>Safety-first for regulated workloads:</strong> when in doubt, fail-closed for destructive/regulatory operations. <br>4. <strong>Fast UI SLOs:</strong> <code>BootstrapStart()</code> median target <50ms on UI thread; <code>NewCorrelationId()</code> <1ms. <br>5. <strong>Audit anchor & chain-of-custody:</strong> every user-triggered flow must be anchored by bootstrap-produced correlation ids and bootstrap audit rows. <br>6. <strong>Minimal attack surface:</strong> bootstrap must avoid loading optional 3rd-party code that could reference forbidden APIs; run static checks and short-circuit if suspicious. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>BootstrapStart()</code> — authoritative non-IO bootstrap entrypoint</strong><br><strong>Purpose & contract:</strong> invoked by host (e.g., Excel OnLoad) to perform minimal, in-memory initialization and schedule deferred initialization. Responsibilities: call <code>InitMinimalState(opts)</code>, instantiate deterministic RNG seed and correlation-id factory, run <code>VerifyNoIOPolicy()</code> quick check, register <code>RegisterShutdown</code> callbacks, detect unclean-exit sentinel and perform restricted <code>RecoverIfUncleanExit()</code> if present, schedule <code>ScheduleDeferredInit()</code> for heavy work, and append <code>bootstrap.started</code> audit row. Must never perform disk or network IO inline. Must not raise unhandled exceptions to host.<br><strong>Signature & outputs:</strong> <code>BootstrapStart(opts?:{testMode?:bool, seedOverride?:string}) -&gt; {ok:bool, correlationId:string, warnings?:[]}</code>. Always emits audit <code>bootstrap.started</code> or <code>bootstrap.failed</code> with <code>correlationId</code>. Return is small, safe, and quickly produced. <br><strong>Primary invariants (must/shall):</strong><br>- Fast: target median complete <50ms on UI thread. <br>- Non-IO: no disk/network/Workbook.Range enumerations. <br>- Idempotent: repeated invocations within same process should be no-ops after first success (use <code>bootstrapState.started</code> guard). <br>- Observability: include <code>buildId</code>, <code>platform</code>, <code>seedFingerprint</code> in audit. <br><strong>Developer guidance:</strong> do not use global constructors that perform IO; in VBA use <code>Application.OnTime</code> to schedule deferred work; in VSTO register an idle callback rather than running heavy work in <code>ThisAddIn_Startup</code>. <br><strong>Failure modes & audits:</strong> if <code>VerifyNoIOPolicy()</code> finds forbidden symbols or runtime sentinel detects improper sync IO, emit <code>bootstrap.failed</code> with <code>errorCode=REG_BOOTSTRAP_FORBIDDEN_API</code> and <code>forbiddenSymbols[]</code>. Provide operator-facing diagnostic ribbon offering <code>collect diagnostics</code> with the <code>correlationId</code>. <br><strong>Tests & CI:</strong> static analysis forbidding forbidden API usage, unit tests asserting <code>bootstrap.started</code> audit emission, performance tests for SLO. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>InitMinimalState(opts)</code> — pure in-memory canonical state & deterministic seeds</strong><br><strong>Purpose & contract:</strong> build minimal runtime state without reading files or network: <code>correlationSeed</code>, <code>rngSeed</code>, <code>inMemoryConfigPlaceholder</code>, <code>ownerMapStub</code> (from embedded manifest or compile-time table), <code>auditBufferHandle</code>, and <code>shutdownRegistry</code>. Accept <code>opts.testMode</code> for deterministic seeds and <code>opts.seedOverride</code> for CI golden parity. Must return a read-only-friendly <code>bootstrapState</code> object. <br><strong>Signature & return:</strong> <code>InitMinimalState(opts?:{testMode?:bool, seedOverride?:string}) -&gt; bootstrapState</code>. <br><strong>Invariants:</strong> deterministic seeds when <code>testMode</code> is true; side-effect free; no direct IO or time-consuming CPU tasks. <br><strong>Observability:</strong> emit <code>bootstrap.minimalState.created</code> audit with <code>correlationId</code> and <code>seedFingerprint</code>. <br><strong>Developer notes:</strong> prefer purely functional construction; when exposing caches provide only safe, readonly views. For embedded owners mapping use compile-time constants or resource-embedded small tables. <br><strong>Tests:</strong> deterministic equality tests, ensure no file/socket calls via instrumentation. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>NewCorrelationId(parentCid?:string)</code> — canonical correlation id generator</strong><br><strong>Purpose & contract:</strong> produce canonical, collision-resistant correlation ids to be used across audits and user-visible messages. Support optional <code>parentCid</code> to create hierarchical ids (user action → job → step). Must be low-latency and deterministic in <code>testMode</code>. <br><strong>Format:</strong> recommended <code>r-YYYYMMDD-HHMMSS-&lt;shorthex&gt;[.n]</code>. Avoid PII. <br><strong>Signature & return:</strong> <code>NewCorrelationId(parentCid?:string) -&gt; correlationId:string</code>. <br><strong>Invariants:</strong> unique within process, deterministic in CI/test mode when seedOverride is provided, thread-safe (or cooperative). Accept <code>fixedCid</code> for unit test hooks to match golden files. <br><strong>Observability:</strong> optional debug metric <code>correlation.generated</code> but avoid producing audit rows for every generation to prevent audit bloat. <br><strong>Tests:</strong> concurrency uniqueness tests and golden parity tests in testMode. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>VerifyNoIOPolicy()</code> — bootstrap forbidden-API gate</strong><br><strong>Purpose & contract:</strong> enforce a strict ban on IO and other forbidden APIs during bootstrap/hot UI paths. Combine lightweight static heuristics (scan loaded modules for known symbol names) and runtime sentinel checks (detect synchronous file / network calls on UI thread). Return <code>{allowed:true}</code> or <code>{allowed:false,errorCode,details}</code> and emit <code>bootstrap.forbiddenApi.detected</code> with <code>forbiddenSymbols[]</code>. <br><strong>Checks performed:</strong> static symbol heuristics (module-level symbol table scanning or string heuristic), runtime instrumentation to detect attempted sync file/network calls on UI thread, and cross-check against allowed whitelist for background workers. <br><strong>Developer guidance:</strong> false positives should be logged for triage; provide a tightly controlled operator override <code>bootstrap.policy.override</code> requiring signed manifest and two-person approval. <br><strong>Examples:</strong> detection of <code>WinHttpRequest</code> or <code>Workbook.Range</code> VBA references at module top-level triggers immediate <code>bootstrap.failed</code>. <br><strong>Tests:</strong> inject known banned symbols in test harness to ensure detection; unit tests for policy override path requiring signed manifest. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>ScheduleDeferredInit(task, opts)</code> — schedule heavy initialization off the UI path</strong><br><strong>Purpose & contract:</strong> defer heavy IO tasks to host idle or worker threads. Tasks include <code>LoadRibbonMap</code>, manifest ingestion, signature verification, PQ template discovery, dependency validation. Must schedule not execute on UI hot path. Must be cancelable, idempotent, and provide retry/backoff and auditing. <br><strong>Signature:</strong> <code>ScheduleDeferredInit(task:function, opts:{delaySec?:int, retryPolicy?:{maxAttempts:int, baseBackoffMs:int}, critical?:bool, correlationId?:string}) -&gt; deferredHandle</code>. <br><strong>Behavior & invariants:</strong><br>- Execute <code>task</code> in an IO-capable context; before performing IO, re-check <code>VerifyNoIOPolicy()</code> to ensure policy hasn't tightened. <br>- <code>task</code> must be idempotent and support cooperative cancellation tokens. <br>- De-duplicate tasks by <code>correlationId</code> when provided. <br>- If <code>critical=true</code> and repeated failures occur, escalate to <code>bootstrap.deferred.failed</code> and surface a diagnostics ribbon for operator. <br><strong>Developer guidance:</strong> in VBA use <code>Application.OnTime</code> for scheduling; for VSTO use host idle callbacks or background thread pool. For PQ template fetches prefer read-then-verify-then-atomic-swap. <br><strong>Audits & observability:</strong> <code>bootstrap.deferred.scheduled</code>, <code>bootstrap.deferred.started</code>, <code>bootstrap.deferred.attempt</code>, <code>bootstrap.deferred.completed</code>, <code>bootstrap.deferred.failed</code> with <code>correlationId</code>, <code>attempt</code>, <code>durationMs</code>, <code>taskName</code> and <code>evidenceRef</code> on failures. <br><strong>Examples & narratives:</strong> schedule <code>LoadRibbonMap</code> with <code>delaySec=1</code> and <code>retryPolicy={maxAttempts:3}</code>; network error on attempt 1 → automatic backoff → success on attempt 2 → <code>bootstrap.deferred.completed</code> with <code>ribbonMap.hash</code>. <br><strong>Tests:</strong> scheduling idempotence, cancellation, retry/backoff correctness, critical failure escalation. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>CancelDeferred(deferredHandle)</code> — cooperative cancellation for scheduled work</strong><br><strong>Purpose & contract:</strong> cancel a scheduled deferred task prior to start or request cooperative cancellation for an in-progress task. Must be idempotent and return whether cancellation succeeded. If a task supports cooperative cancellation, <code>CancelDeferred</code> should set a cancellation token and the running task must check it at safe points, rollback partial operations if necessary, and emit <code>bootstrap.deferred.cancelled</code> audit. <br><strong>Signature:</strong> <code>CancelDeferred(deferredHandle) -&gt; {cancelled:true|false, reason?:string}</code>. <br><strong>Developer note:</strong> tasks must implement checkpointed atomic swap semantics so that partially-applied artifacts are rolled back safely if cancellation occurs mid-swap. <br><strong>Tests:</strong> cancellation during backoff, cancellation while running (simulate cooperative cancellation), idempotency. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>RegisterShutdown(handler, priority=50)</code> & <code>UnregisterShutdown(registrationId)</code> — orderly shutdown & snapshotting</strong><br><strong>Purpose & contract:</strong> register synchronous shutdown handlers executed with deterministic ordering to ensure <code>modAudit</code> flush occurs before snapshot persistence. Guarantee minimal snapshot persisted atomically and emit <code>bootstrap.shutdown</code> with <code>flushedRows</code>, <code>snapshotUri</code>, and <code>durationMs</code>. Handlers must be fast and robust; if a handler throws the system emits <code>bootstrap.shutdown.error</code> and continues executing remaining handlers. <br><strong>Signature:</strong> <code>RegisterShutdown(handler:function, priority:int) -&gt; registrationId</code>, <code>UnregisterShutdown(registrationId) -&gt; bool</code>. <br><strong>Invariants:</strong><br>- Execution order deterministic: sort by <code>priority</code> (descending or ascending as documented) + registration order. <br>- Single-threaded synchronous execution recommended (host dependent). <br>- Minimal snapshot persisted atomically (e.g., <code>snapshot.json.tmp</code> → <code>snapshot.json</code> rename) and signed/hashed. <br><strong>Developer guidance:</strong> avoid heavy IO in custom handlers; queue long-running artifacts for <code>modAudit</code> uploader. <br><strong>Examples:</strong> a handler that flushes <code>modAudit</code> (high priority) runs before <code>PersistSnapshot()</code> (lower priority). <br><strong>Tests:</strong> ordering, snapshot atomicity, handler failure resilience. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>RecoverIfUncleanExit()</code> — conservative forensic detection & evidence export</strong><br><strong>Purpose & contract:</strong> detect missing/unclean shutdown via sentinel or missing snapshot, produce <code>forensic_manifest.json</code> listing collected artifacts, atomically export evidence bundle to the secured evidence store (signed & checksummed), emit <code>bootstrap.recovery</code>, and enter restricted mode (no auto-apply, no exports) until operator approves. Do not auto-apply or re-run pending jobs — recovery is conservative and manual approval is required for re-enable. <br><strong>Artifacts collected:</strong> <code>ribbon-map.json</code> (current + previous if present), <code>audit_tail.csv</code> (time-windowed tail), persisted job descriptors for recent jobs, <code>modConfig</code> snapshot, minimal redacted memory snapshot (with PII redacted), and <code>lastSnapshot.json</code> if present. <br><strong>Signature & return:</strong> <code>RecoverIfUncleanExit() -&gt; {recoveryDetected:bool, forensicManifestUri?:string, actionsTaken:[]}</code>. <br><strong>Audit:</strong> <code>bootstrap.recovery</code> with <code>forensicManifestUri</code>, <code>lastCorrelationId</code>, <code>restrictedMode:true</code>. <br><strong>Operator runbook:</strong> operator retrieves <code>forensic_manifest</code>, runs <code>VerifyAuditChain</code> focusing on <code>lastCorrelationId</code>, inspects job descriptors, and approves resume using a two-person approval workflow when required by regulation. <br><strong>Examples & narratives:</strong><br>1. Long <code>dq_apply</code> job interrupted by OS crash → on next start <code>RecoverIfUncleanExit()</code> exports evidence and blocks exports until manual review. <br>2. Operator force-quit during development → recovery audit generated; system remains conservative. <br><strong>Tests:</strong> crash simulations, evidence integrity verification, restricted-mode enforcement and re-enable after two-person approval. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>EmitBootstrapAudit(eventType, metadata)</code> — canonical audit writer, redaction & evidence linking</strong><br><strong>Purpose & contract:</strong> canonical method for writing bootstrap-level audit rows into <code>modAudit</code> buffer using canonical schema. Responsibilities: validate schema, redact PII from metadata, compute <code>metadataHash</code>, optionally store full sanitized metadata in encrypted evidence store (returning <code>evidenceRef</code>), append audit row non-blocking, and return <code>auditRowId</code>. <br><strong>Schema (required fields):</strong> <code>timestamp,correlationId,module=REG_Bootstrap,eventType,buildId,platform,metadataHash,prevHash,evidenceRef,configHash</code>. <br><strong>PII policy:</strong> never store PII directly in audit rows; sanitized evidence stored in encrypted evidence store referenced via <code>evidenceRef</code> and accessible under strict RBAC. <br><strong>Developer guidance:</strong> include <code>configHash</code> and <code>ribbonMap.hash</code> placeholders when available to help run reproducibility and triage. <br><strong>Examples:</strong> <code>bootstrap.started</code> with <code>{seedFingerprint:&quot;abc&quot;, flags:{safeMode:false}}</code> → compute <code>metadataHash</code> and store sanitized evidence for debugging. <br><strong>Tests:</strong> schema validation, prevHash chaining in CI, redaction verification tests. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong><code>GetBootstrapState()</code> — safe, read-only state exposure for clients</strong><br><strong>Purpose & contract:</strong> expose a safe, read-only view of the minimal bootstrap state for other modules (no handles that allow IO). Only reveal non-sensitive fields: <code>buildId</code>, <code>bootstrapFlags</code>, <code>seedFingerprint</code>, <code>correlationSeedFingerprint</code>, and minimal caches. Must return shallow copies to prevent accidental mutation. <br><strong>Signature:</strong> <code>GetBootstrapState() -&gt; {buildId, bootstrapFlags, seedFingerprint, ...}</code>. <br><strong>Invariants:</strong> no mutable handles, no file descriptors, no network clients. <br><strong>Tests:</strong> immutability and no handle leakage tests. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Failure modes, mitigations & operator playbook (concise)</strong><br><strong>Common failure cases & mitigations:</strong><br>1. <em>Forbidden API detected at bootstrap</em> — <code>bootstrap.failed</code>, degrade feature set and require code remediation + signed manifest for re-enable. <br>2. <em>Deferred init never schedules or fails repeatedly</em> — emit <code>bootstrap.deferred.failed</code>, degrade dependent features, surface diagnostics, and provide operator command <code>bootstrap.retry-deferred</code>. <br>3. <em>Unclean exit</em> — run <code>RecoverIfUncleanExit</code>, export <code>forensic_manifest</code>, enter restricted mode. <br>4. <em>Audit buffer persist failure</em> — fallback: local sentinel + operator alert; uploader retries with backoff. <br><strong>Operator runbook (quick):</strong><br>- On <code>bootstrap.failed</code>: collect <code>correlationId</code>, run <code>diagnostics collect --bootstrap --cid &lt;cid&gt;</code>, check <code>forensic_manifest</code>. <br>- On <code>bootstrap.recovery</code>: retrieve <code>forensic_manifest</code>, run <code>VerifyAuditChain</code>, and follow incident remediation steps; re-enable only after two-person approval for regulated flows. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Performance budgets & telemetry</strong><br><strong>Targets:</strong> <code>BootstrapStart</code> median <50ms; <code>NewCorrelationId</code> <1ms; <code>deferred scheduling</code> within 2s. <br><strong>Metrics (local buffer only on hot path):</strong> <code>bootstrap.start.latency_ms</code>, <code>bootstrap.deferred.attempts</code>, <code>bootstrap.recovery.count</code>, <code>bootstrap.forbidden_api_rate</code>, <code>bootstrap.shutdown.duration_ms</code>. <br><strong>Remediation:</strong> if SLO violated repeatedly, enter <code>reduced-mode</code> disabling non-essential UI features and escalate via <code>bootstrap.slo.degraded</code> audit. <br><strong>Tests:</strong> perf tests and SLO checks in CI. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Change control & CI gating</strong><br><strong>Mandatory:</strong> static forbidden-API scan, unit + integration + golden tests, audit-chain verification for a sample run, signed manifest for any production change, compliance sign-off for regulated modules. <br><strong>Blocking conditions:</strong> forbidden-API detection, golden mismatch, missing <code>bootstrap.started</code> audit, SLO failures. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Examples & extended narratives (comprehensive)</strong><br><strong>Narrative 1 — Normal startup (step-by-step):</strong><br>1. Host invokes <code>OnLoad</code> → <code>BootstrapStart()</code> called. <br>2. <code>BootstrapStart()</code> calls <code>InitMinimalState()</code> which constructs <code>bootstrapState</code> purely in memory (deterministic RNG seeded from <code>buildId</code> fingerprint + process start time). <br>3. <code>NewCorrelationId()</code> is called to create root <code>r-20260117-0001</code>. <code>EmitBootstrapAudit(&quot;bootstrap.started&quot;, {buildId,seedFingerprint})</code> appends anchor row. <br>4. <code>BootstrapStart()</code> invokes <code>VerifyNoIOPolicy()</code> (quick static symbol check) — passes. <br>5. <code>ScheduleDeferredInit(LoadRibbonMap, {delaySec:1, retryPolicy:{maxAttempts:3}})</code> schedules manifest load in idle time and returns a <code>deferredHandle</code>. <br>6. <code>BootstrapStart()</code> returns quickly; UI thread is unblocked. <br>7. On idle, the deferred runner calls <code>LoadRibbonMap</code> (IO-capable context) which loads local manifest cache, validates JSON Schema v7, computes canonical <code>ribbonMap.hash=sha256:abcd...</code>, verifies signatures, deduplicates control IDs, and emits <code>bootstrap.deferred.completed</code> with <code>ribbonMap.hash</code>. <br>8. Ribbon controls become active and <code>ribbon.ready</code> audit is appended (chained to <code>bootstrap.started</code> correlation id). <br><strong>Narrative 2 — Deferred load transient failure & retry:</strong><br>1. <code>LoadRibbonMap</code> scheduled as above; attempt 1 (local cache stale) tries network refresh and encounters transient HTTP 504. Emit <code>bootstrap.deferred.attempt</code> attempt=1 with <code>errorCode=NET_504</code> and local evidence in tmp folder. <br>2. Scheduler backs off and retries attempt=2; network available → successful load and <code>bootstrap.deferred.completed</code> emitted with <code>ribbonMap.hash</code>. <br>3. Operator sees <code>ribbon.map.warning</code> briefly; system logs and audits show backoff and successful resolution. <br><strong>Narrative 3 — Forbidden API detection at bootstrap (dev mistake):</strong><br>1. Developer shipped helper module referencing <code>WinHttpRequest</code> at module top-level (even though used only in a worker). <br>2. <code>VerifyNoIOPolicy()</code> static heuristics find <code>WinHttpRequest</code> symbol during <code>BootstrapStart</code>. <br>3. <code>BootstrapStart()</code> emits <code>bootstrap.failed</code> with <code>errorCode=REG_BOOTSTRAP_FORBIDDEN_API</code>, <code>forbiddenSymbols:[&quot;WinHttpRequest&quot;]</code>, and starts add-in in <code>limited-mode</code>. <br>4. Operator uses diagnostic ribbon to collect evidence (audit row <code>bootstrap.failed</code> includes <code>evidenceRef</code>) and requests developer hot-fix. <br>5. Developer moves network code behind deferred init, produces signed manifest, CI golden tests pass, and operator redeploys. <br><strong>Narrative 4 — Unclean exit & forensic workflow (detailed):</strong><br>1. Add-in performed a long-running <code>dq_apply</code> job that persisted job descriptor <code>job-901</code> and wrote partial artifacts when the host crashed. <br>2. On startup <code>BootstrapStart</code> detects missing/unclean sentinel and runs <code>RecoverIfUncleanExit</code>. <br>3. <code>RecoverIfUncleanExit()</code> collects evidence: last two <code>audit_tail.csv</code> rotations, <code>ribbon-map.json</code> (previous + current), <code>job-901.json</code>, <code>modConfig</code> snapshot, and redacted memory snapshot. It computes sha256 checksums and writes <code>forensic_manifest.json</code>. <br>4. <code>RecoverIfUncleanExit()</code> uploads evidence atomically to secure evidence store and emits <code>bootstrap.recovery</code> with <code>forensicManifestUri</code>. Add-in enters restricted mode. <br>5. Operator retrieves evidence, runs <code>VerifyAuditChain</code> for the <code>lastCorrelationId</code>, inspects job descriptor <code>job-901</code>, and either requeues the job manually after verification or opens an incident for deeper SRE investigation. <br>6. Re-enable AUTO_APPLY or exports only after two-person approval recorded by <code>bootstrap.recover-approve</code> audit. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Concrete operational examples (short)</strong><br><strong>Example: BootstrapStart returns:</strong> <code>{ok:true, correlationId:&quot;r-20260117-0001&quot;, warnings:[]}</code>. Associated audit <code>bootstrap.started</code> appended. <br><strong>Example: Deferred failure audit:</strong> <code>{event: &quot;bootstrap.deferred.failed&quot;, correlationId: &quot;r-20260117-0001&quot;, task:&quot;LoadRibbonMap&quot;, attempt:3, errorCode:&quot;REG_DEFER_NET_504&quot;, evidenceRef:&quot;evi-az-001&quot;}</code>. <br><strong>Example: Forbidden API audit:</strong> <code>{event:&quot;bootstrap.forbiddenApi.detected&quot;, correlationId:&quot;r-20260117-0002&quot;, forbiddenSymbols:[&quot;WinHttpRequest&quot;], errorCode:&quot;REG_BOOTSTRAP_FORBIDDEN_API&quot;, evidenceRef:&quot;evi-xx-42&quot;}</code>. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Testing matrix (concrete)</strong><br><strong>Unit:</strong> <code>NewCorrelationId</code> uniqueness & deterministic checks; <code>InitMinimalState</code> deterministic outputs; <code>EmitBootstrapAudit</code> schema tests; <code>VerifyNoIOPolicy</code> static signature checks via injected modules. <br><strong>Integration:</strong> simulated host: <code>BootstrapStart</code> + deferred runner + <code>LoadRibbonMap</code> with mocked IO; verify chain <code>bootstrap.started</code> → <code>bootstrap.deferred.completed</code> → <code>ribbon.ready</code>. <br><strong>Golden:</strong> <code>testMode=true</code> run with fixed <code>seedOverride</code> and golden <code>ribbonMap.hash</code> parity check; <code>correlationId</code> deterministic match. <br><strong>Property & stress:</strong> parallel generation of correlation ids under load (10k calls) for uniqueness; forbidden-API injection tests to ensure detection. <br><strong>CI gates:</strong> static analysis for forbidden APIs, golden parity, <code>bootstrap.started</code> audit presence, SLO verification. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Appendices — schemas, error-codes, evidence manifests (references)</strong><br><strong>Bootstrap audit schema fields (canonical):</strong> <code>timestamp,correlationId,module=REG_Bootstrap,eventType,buildId,platform,metadataHash,prevHash,evidenceRef,configHash,notes</code>.<br><strong>Suggested error codes (examples):</strong> <code>REG_BOOTSTRAP_FORBIDDEN_API</code>, <code>REG_BOOTSTRAP_DEFER_SCHED_FAILED</code>, <code>REG_BOOTSTRAP_RECOVERY_EVIDENCE_FAIL</code>, <code>REG_BOOTSTRAP_SHUTDOWN_ERROR</code>, <code>REG_BOOTSTRAP_SYNC_IO_DETECTED</code>. Each maps to operator triage steps. <br><strong>Forensic manifest sample structure (fields):</strong> <code>forensicManifest:{id,createdTs,correlationId,lastSnapshotUri,auditTailUris,jobDescriptorUris,checksums,signatures,notes}</code>. Evidence store returns a signed URI for chain-of-custody. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (PQ) guidance (integration with bootstrap & deferred init)</strong><br><strong>Purpose:</strong> PQ guidance here is conceptual: how the bootstrap + deferred init pattern integrates with embedding, validating, parameterizing, and injecting Power Query (M) templates in regulated environments. The guidance assumes manifests, <code>mChecksum</code> provenance, and strict audit linking (each PQ user action anchored to a <code>correlationId</code>).<br><strong>High-level invariants for PQ templates:</strong><br>1. <strong>mChecksum provenance:</strong> every M template has <code>mChecksum</code> (SHA256 of canonicalized M) stored in manifest and evidence. <code>LoadRibbonMap</code> and PQ template loader must verify <code>mChecksum</code> before injection. <br>2. <strong>Deferred template validation:</strong> heavy template validation (connecting to remote data sources or performing full refresh) must run in deferred worker; only a light-weight schema validation and checksum verification is allowed in deferred-init quick checks. <br>3. <strong>Hidden-sheet fallback:</strong> when external repo unreachable, prefer embedded templates in a hidden sheet for offline reliability; ensure embedded templates have <code>mChecksum</code> and owner attribution. <br>4. <strong>Injection safety:</strong> <code>PQ_Injector</code> should expose safe APIs like <code>Add_Query_From_M(name, formula, opts)</code> that perform parameter sanitization, redaction of credentials, and atomic add to <code>Workbook.Queries</code>. Always compute <code>paramsHash</code> and store sanitized evidence when injecting. <br><strong>Template lifecycle & audits:</strong> each template load/inject/preview should produce audit rows: <code>pq.template.loaded</code>, <code>pq.preview</code>, <code>pq.inject</code>, <code>pq.export</code>, each with <code>correlationId</code> and <code>mChecksum</code>. <br><strong>Parameterization & safe default rules:</strong> maintain canonical parameter mapping; sanitize user-supplied parameters (redact credentials), compute <code>paramsHash</code>, and store sanitized parameters in evidence store. Ensure <code>Add_Query_From_M</code> rejects or flags templates that embed raw credentials or connection strings; instead require parameterization with placeholders and secure connection creation APIs. <br><strong>Query folding & determinism:</strong> prefer query designs that fold to source for performance; however, folding depends on provider — do not rely on folding for determinism; always compute canonical transformed artifact <code>mChecksum</code> after template parameterization for auditability. <br><strong>Diagnostics & metrics for PQ:</strong> capture <code>pq.template.load.latency_ms</code>, <code>pq.refresh.duration_ms</code>, <code>pq.diagnostics/lastError</code>, and save detailed diagnostics to evidence store with <code>evidenceRef</code>. <br><strong>Safe injection examples (conceptual):</strong><br>- <em>Preview:</em> operator requests preview → <code>PQ_Injector</code> runs <code>SanitizeTemplate</code> → compute <code>previewM</code> and run limited preview in sandboxed runner (no credentials) → produce <code>pq.preview</code> audit with <code>mChecksum</code> and <code>previewChecksum</code>.<br>- <em>Inject:</em> operator confirms injection → <code>PQ_Injector</code> executes <code>Add_Query_From_M</code> within workbook context (deferred if heavy), adds connection optionally, emits <code>pq.inject</code> audit with <code>mChecksum</code> and <code>queryName</code>. <br><strong>Governance & operator flow:</strong> template modifications to regulated templates require PR + owners sign-off; production injection requires signed manifest and <code>pq.template.inject</code> audit. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX guidance (design, determinism, performance, and audits)</strong><br><strong>Purpose:</strong> DAX guidance here is conceptual and practical patterns consistent with regulated, audited flows: deterministic measure behavior, testability, safe performance, and audit linkage. DAX is executed in workbook/Power BI engine context; bootstrap must not call DAX during startup but should ensure configuration, model versioning, and auditing are in place before exposing UI actions that result in DAX evaluation of regulated outputs. <br><strong>Design & determinism principles:</strong><br>1. <strong>Deterministic inputs:</strong> DAX measures should depend only on model data and explicit parameters; avoid reliance on volatile functions (e.g., <code>NOW()</code>, <code>RAND()</code>) for regulated outputs; if used, document and audit the use and provide deterministic test-mode overrides. <br>2. <strong>Versioned measures & migration:</strong> changes to measure logic must be tracked via <code>measureVersion</code> in manifest and produce migration manifests describing semantic change and test vectors (golden outputs). <br>3. <strong>Testing & golden parity:</strong> provide unit test harness that evaluates measures over canonical sample datasets and asserts measure outputs match golden checksums. <br>4. <strong>Context hygiene:</strong> explicit management of row context vs filter context; prefer <code>VAR</code> usage for readability and stable evaluation order; avoid older constructs like <code>EARLIER</code> when a clearer pattern exists. <br><strong>Performance & safety:</strong><br>- Avoid unbounded row iterators; use <code>SUMX</code> only over necessary, well-bounded tables; prefer <code>CALCULATE</code> + <code>FILTER</code> with indexed columns for better engine optimization. <br>- Avoid expensive nested <code>FILTER</code> over large tables when a pre-aggregated table or calculated column can solve the need. <br>- Use <code>KEEPFILTERS</code>/<code>REMOVEFILTERS</code> intentionally and document expected semantics. <br><strong>Security & PII:</strong> DAX measures that produce PII must be restricted to contexts with approval; DAX debug outputs must be redacted in evidence stores. <br><strong>Audit integration:</strong> model operations that run DAX measures producing artifacts must include audit rows: <code>dax.evaluate</code> (with <code>correlationId</code>, <code>measureName</code>, <code>modelVersion</code>, <code>paramsHash</code>, <code>resultHash</code>) and evidenceRefs for full sanitized result sets. For scheduled or automated DAX runs used in regulated flows, persist job descriptors and follow job scheduling and job persistence rules identical to other heavy jobs. <br><strong>Practical DAX patterns (conceptual snippets in words):</strong><br>- <strong>Measure with VAR and deterministic fallback:</strong> declare <code>VAR</code> inputs, compute intermediate aggregates once, return final expression; provide deterministic <code>testSeed</code> param for any necessary sampling. <br>- <strong>Time intelligence:</strong> prefer <code>DATESBETWEEN</code>/<code>TOTALYTD</code> with explicit <code>yearEndDate</code> parameters for deterministic behavior across locales and fiscal calendars; store <code>fiscalCalendar</code> configuration in <code>modConfig</code> and include <code>configHash</code> in audits. <br>- <strong>Iterator containment:</strong> limit <code>SUMX</code> iterators to <code>TOPN</code>/filtered set to reduce engine pressure and ensure bounded evaluation. <br><strong>Examples & narratives (conceptual):</strong><br>1. <em>Measure change & migration:</em> team changes <code>RevenueNet</code> measure semantics (excluded discount logic). Submit PR with <code>migration_manifest.json</code> describing sample inputs and golden outputs. CI runs golden tests and <code>dax.evaluate</code> audits for sample dataset; after sign-off, change is released. <br>2. <em>Regulated report generation:</em> operator triggers "Regulatory Summary" which runs a set of DAX measures over certified model version. <code>NewCorrelationId()</code> created, job persisted (if heavy) and <code>dax.evaluate</code> audits produced with <code>resultHash</code> referencing sanitized result stored in evidence store. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Cross-cutting examples showing PQ + DAX + Bootstrap integration</strong><br><strong>End-to-end narrative (conceptual, regulated flow):</strong><br>1. Operator chooses a canonical PQ template "LoadCustomerBalances" from the PQ library; UI action <code>dq_profile.load_template</code> anchored to correlation <code>r-20260117-0100</code>. <code>pq.preview</code> audit produced with <code>mChecksum</code>. <br>2. Operator injects the query into workbook; <code>pq.inject</code> audit produced with <code>mChecksum</code> and <code>queryName</code>. The injected query produces a table <code>tblCustomerBalances</code>. <br>3. The operator triggers "Compute Regulatory Summary" which runs a set of DAX measures on <code>tblCustomerBalances</code>. Because the measures are heavy, the add-in persists a job via job scheduler: <code>job.persisted:job-033</code> with <code>correlationId=r-20260117-0100.child-1</code>. <br>4. Worker loads dataset snapshot (redacted), uses deterministic RNG seeds from bootstrap <code>bootstrapState.seedFingerprint</code>, evaluates DAX measures in isolated host (or a headless engine), computes <code>resultHash</code>, emits <code>dax.evaluate</code> audits and <code>dq_export</code> of result artifacts with atomic write and checksum. <br>5. Audit chain: <code>bootstrap.started</code> → <code>pq.inject</code> → <code>UserAction</code> → <code>job.persisted</code> → <code>dax.evaluate</code> → <code>dq_export</code>. Evidence references and <code>forensic_manifest</code> allow reproducible trace. <br><strong>Governance & acceptance:</strong> regulated outputs require two-person approval if measures changed since last certified run; golden parity tests ensure reproducibility of exported artifacts. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Operator UX, messaging & triage hints (concise)</strong><br>- Always present <code>correlationId</code> in operator messages (copyable). <br>- Short user-facing messages without PII, e.g.: "Startup limited — ref r-20260117-0002. Open Diagnostics." <br>- For deferred failures: "Feature degraded — manifest load failed (ref r-20260117-0001). Retry or contact ops." <br>- Triage quick steps: tail <code>audit_tail.csv</code> for <code>correlationId</code>, fetch <code>forensic_manifest</code> referenced by audit, validate <code>ribbonMap.hash</code> and job descriptors, run <code>VerifyAuditChain</code>. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria (dev/CI) — final checklist</strong><br>1. Unit + integration + golden tests pass. <br>2. No forbidden API references in static analysis. <br>3. <code>bootstrap.started</code> audit emitted on sample run and <code>bootstrap.deferred.completed</code> follows in deferred runner. <br>4. Deterministic <code>NewCorrelationId</code> behavior in <code>testMode</code>. <br>5. Evidence export path for recovery validated and signed. <br>6. Shutdown handlers flush audit buffers and snapshot persisted atomically. <br><strong>If any fails:</strong> block release; produce <code>forensic_manifest</code> artifact for CI triage and fix until gates pass. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Appendix: short checklist for implementers</strong><br>1. Keep bootstrap minimal — no IO. <br>2. Defer everything heavy and make it idempotent & cancellable. <br>3. Emit audit rows for every critical transition with <code>correlationId</code>. <br>4. Use deterministic seeding in testMode for CI/golden runs. <br>5. Policy overriders require signed manifests & two-person approval. <br>6. Persist evidence atomically and sign <code>forensic_manifest</code> for chain-of-custody. </td></tr><tr><td data-label="REG_Bootstrap — Per-function Expert Technical Breakdown"> <strong>Closing (operational note)</strong><br>This module specification is intentionally exhaustive: it balances safety (non-IO UI path), observability (canonical audits and evidence), determinism (testMode seeds, golden tests), and governance (signed manifests and two-person approvals). Follow the invariants strictly: minimal hot-path, deferred IO, audit anchoring, deterministic seeds for CI, and conservative recovery. </td></tr></tbody></table></div><div class="row-count">Rows: 26</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>