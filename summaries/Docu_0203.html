<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771612982">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li>
<li class="toc-item"><a class="toc-link" href="#Table10">Table 10</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0203_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modAuditExportHelpers (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modAuditExportHelpers (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Module purpose (concise)</strong><br><code>modAuditExportHelpers</code> is responsible for reliably converting workbook audit artifacts into production-ready export packages. It handles streaming exports (CSV / NDJSON), SQL script generation, manifest and checksum creation, deterministic file naming, chunking/partitioning for very large exports, optional cryptographic signing integration points, and robust retry/validation flows. The module is strictly read-only for business data sources and treats the workbook as the authoritative provenance source; every export is recorded to a local <code>__Export_Audit</code> table for traceability and replay. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Design principles & operational constraints</strong><br>1. Deterministic output: identical inputs + config → identical files and checksums; include <code>codeVersion</code> and <code>configSnapshot</code> in the manifest. <br>2. Streaming-first: avoid building full-file strings in memory; write records in batches and flush frequently to avoid Excel memory exhaustion. <br>3. Idempotent exports: every export has <code>exportId</code> and <code>exportVersion</code>; re-running produces a new export artefact with a new <code>exportId</code> and does not modify prior packages. <br>4. Audit integration: write compact <code>__Export_Audit</code> rows for each significant step; include <code>exportId</code>, <code>runId</code>, file paths, checksums, signer, and status. <br>5. Security & privacy: respect <code>modConfig.HashPII</code> and <code>modConfig.ExportMode</code>; module supports both plaintext and hashed exports but enforces config validation before exporting PII. <br>6. Config-driven behavior: parameters such as <code>ExportBatchRows</code>, <code>ExportFormat</code>, <code>Compression</code>, <code>SigningEnabled</code>, <code>ChecksumAlgorithm</code>, and <code>ExportDest</code> are read from <code>modConfig</code>. <br>7. Portable artifact format: prefer NDJSON for large-scale ingestion; produce CSV for human readability; supply SQL script when destination requires INSERT statements. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Public surface — functions (summary for consumers)</strong><br>1. <code>StartExport(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — orchestrates end-to-end export for a run, returns manifest dictionary. <br>2. <code>StreamRecordsFromAuditLog(runId As String, batchSize As Long, callbackName As String, callbackArgs As Scripting.Dictionary) As Scripting.Dictionary</code> — stream reader that pages audit rows and calls writer callback. <br>3. <code>WriteCSVFile(fullPath As String, records As Variant, delimiter As String, includeHeader As Boolean) As Scripting.Dictionary</code> — buffered CSV writer supporting parts. <br>4. <code>WriteJSONFile(fullPath As String, records As Variant, ndjson As Boolean) As Scripting.Dictionary</code> — newline-delimited JSON writer and array JSON fallback. <br>5. <code>BuildSQLInsertScript(tableName As String, records As Variant, batchSize As Long, options As Scripting.Dictionary) As Scripting.Dictionary</code> — SQL script generator with deterministic ordering. <br>6. <code>ExportManifest(runId As String, exportFiles As Collection, destPath As String) As Scripting.Dictionary</code> — build manifest JSON and persist. <br>7. <code>ComputeFileChecksum(fullPath As String, algorithm As String) As String</code> — streaming checksum (CRC32, SHA1, SHA256) using local helper or external helper when required. <br>8. <code>PackageExport(exportDir As String, destZip As String, includeManifest As Boolean) As Scripting.Dictionary</code> — compress package and create signature placeholder. <br>9. <code>SignArtifact(filePath As String, signerConfig As Scripting.Dictionary) As Scripting.Dictionary</code> — integration hook for external PKI or helper signing service. <br>10. <code>ValidateExport(manifest As Scripting.Dictionary, options As Scripting.Dictionary) As Scripting.Dictionary</code> — run pre-hand-off checks. <br>11. <code>RetryWithBackoff(operationFuncName As String, args As Scripting.Dictionary, maxRetries As Long) As Scripting.Dictionary</code> — resilient wrapper used by IO and signing operations. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: StartExport (orchestrator)</strong><br>Purpose: run-level entry point that composes streaming, manifesting, signing, and validation into a single deterministically repeatable export pipeline.<br>Signature: <code>StartExport(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Inputs & options:<br>- <code>runId</code> (required): reference to the run being exported.<br>- <code>options</code> keys: <code>format</code> (<code>ndjson|csv|sql</code>), <code>compress</code> (Boolean), <code>sign</code> (Boolean), <code>exportVersion</code> (Integer), <code>exportDest</code> (path), <code>batchSize</code> (rows), <code>includeHeader</code> (Boolean).<br>Behavior sequence (detailed):<br>1. Validate <code>runId</code> exists and <code>Audit_Log</code> contains rows; if empty, record <code>EXPORT_NO_ROWS</code> and return with <code>status=NO_ROWS</code>. <br>2. Acquire export lock (write to <code>__Export_Locks</code>) to prevent concurrent exports for same runId; if lock held, return <code>LOCK_HELD</code>. <br>3. Create transient export directory: <code>ExportStaging/&lt;runId&gt;_&lt;exportVersion&gt;</code>. <br>4. Initialize <code>exportFiles</code> collection and open writer(s) based on <code>format</code>. <br>5. Call <code>StreamRecordsFromAuditLog</code> with batchSize and file-writer callback to stream rows to target file(s); writer returns file path(s) and row counts. <br>6. On completion compute checksums for each file using <code>ComputeFileChecksum</code>. <br>7. Call <code>ExportManifest</code> to create manifest referencing files and checksums. <br>8. Call <code>ValidateExport</code> to run sanity checks (row counts, checksum parity, optional schema check). <br>9. If <code>sign</code> requested, call <code>SignArtifact</code> on final package. <br>10. Move package to <code>exportDest</code>, write <code>EXPORT_COMPLETE</code> record to <code>__Export_Audit</code>, release lock, and return manifest structure. <br>Error paths:<br>- On transient IO failures during streaming, call <code>RetryWithBackoff</code> and attempt to resume from last checkpoint saved in <code>__Export_Status</code>. <br>- On persistent failures, write <code>EXPORT_FAILED</code> with error details and create <code>ForensicPack</code> snapshot. <br>Outputs: structured dictionary <code>{ exportId, runId, files:[{path,rows,size,checksum}], manifestPath, signed:true/false, status }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: StreamRecordsFromAuditLog</strong><br>Purpose: efficiently read <code>Audit_Log</code> rows for a run and deliver them to writer callbacks in batches, supporting resume and checkpointing.<br>Signature: <code>StreamRecordsFromAuditLog(runId As String, batchSize As Long, callbackName As String, callbackArgs As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Key behaviors and constraints:<br>1. Paging model: read contiguous ranges into variant 2D arrays (single COM call per batch) to minimize Range access overhead. <br>2. Checkpointing: after each successful batch callback, write <code>__Export_Status</code> row for <code>runId</code> with <code>lastRowExported</code>, <code>lastBatchTime</code>, and <code>partialFiles</code> to enable resume. <br>3. Callback semantics: the callback named by <code>callbackName</code> must accept <code>(recordsArray As Variant, callbackArgs As Scripting.Dictionary)</code> and return <code>{ success:Boolean, writtenRows:Long, filePath:String }</code>. <br>4. Filtering: support <code>callbackArgs</code> with <code>columns</code> (list), <code>where</code> predicate (simple column->value equality) to allow sub-select exports. <br>5. Error handling: if callback fails, call <code>RetryWithBackoff</code> for callback invocation; after <code>maxRetries</code> record <code>STREAM_FAILED</code>. <br>6. Resume: if <code>__Export_Status</code> indicates partial export, resume from <code>lastRowExported + 1</code>. <br>Return: <code>{ exportedRows, batches, durationMs, success }</code>. <br>Audit: write <code>STREAM_START</code> and <code>STREAM_COMPLETE</code> rows to <code>__Export_Audit</code> with statistics. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: WriteCSVFile (stream writer)</strong><br>Purpose: write CSV safely and deterministically for ingestion consumers; support part-files and atomic finalization.<br>Signature: <code>WriteCSVFile(fullPath As String, records As Variant, delimiter As String, includeHeader As Boolean) As Scripting.Dictionary</code>.<br>Key implementation notes:<br>1. Deterministic column order is required: prefer <code>modConfig.ExportColumnOrder</code> array; fallback to first record keys sorted alphabetically for reproducibility. <br>2. Escaping rules: if a field contains delimiter, double-quote it; double-quote characters inside fields are doubled. Normalize newline characters inside fields to <code>\n</code> or literal line breaks depending on <code>modConfig</code>. If <code>modConfig.QuoteAllFields=True</code> then quote every field for maximum safety. <br>3. Streaming & buffering: write records in batches controlled by <code>modConfig.ExportFlushRows</code> and flush to disk periodically. For very large exports write part files <code>part0001.csv</code>, <code>part0002.csv</code> and record them in manifest. <br>4. Header row: when <code>includeHeader=True</code> write a header line exactly once at the beginning of the first part file. <br>5. Atomic finalize: write to a temporary file with <code>.tmp</code> suffix and rename to final filename on successful completion to avoid partial-file ingestion by downstream systems. <br>6. Row counting: track and return number of rows written so manifest can assert parity against <code>Audit_Log</code> expected rows. <br>Return: <code>{ success:True/False, filePath:fullPath, rowsWritten:Long, errorMsg:Optional }</code>. <br>Edge-cases & mitigations:<br>- If a single record contains > <code>modConfig.MaxFieldBytes</code>, write <code>evidenceRef</code> instead of embedding large field, and append evidence file to package. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: WriteJSONFile (ndjson and array)</strong><br>Purpose: generate newline-delimited JSON (preferred) or JSON array exports in a deterministic, streaming-friendly way.<br>Signature: <code>WriteJSONFile(fullPath As String, records As Variant, ndjson As Boolean) As Scripting.Dictionary</code>.<br>Behavior specifics:<br>1. NDJSON mode: write each record as a single JSON line, ensuring stable key ordering (alphabetical or explicit <code>ExportColumnOrder</code>). This ensures easy streaming ingestion and parallelism. <br>2. Array mode (fallback): write <code>[</code> then stream records separated by <code>,</code> and close <code>]</code> — this consumes more memory for consumer but is sometimes required. <br>3. JSON serialization: prefer safe serialization that preserves numeric precision and uses consistent escaping for control characters; implement <code>JsonSanitize()</code> to standardize embedded JSON fields (like <code>beforeJSON</code>) to canonical property ordering and remove trailing whitespace. <br>4. Field size handling: if a record has a very large nested object, produce a reference to <code>evidence/&lt;id&gt;.json</code> instead and include the evidence file in manifest. <br>5. Checkpoint & parting: same part-file and atomic rename strategy as CSV writer. <br>Return: <code>{ success, filePath, rowsWritten, partFiles[] }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: BuildSQLInsertScript</strong><br>Purpose: generate vendor-neutral SQL insert scripts with deterministic column ordering and optional upsert support; streaming-friendly for very large exports.<br>Signature: <code>BuildSQLInsertScript(tableName As String, records As Variant, batchSize As Long, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Behavioral details:<br>1. Column ordering: use config <code>ExportColumnOrder</code> or sort keys consistently. <br>2. Value escaping: text values single-quote escaped (replace <code>&#x27;</code> with <code>&#x27;&#x27;</code>), null mapping for empty variants; numeric formatting honors <code>modConfig.SqlNumberFormat</code>. <br>3. Batching: write <code>BEGIN TRANSACTION</code> then groups of <code>INSERT INTO table (cols) VALUES (...),(...);</code> followed by <code>COMMIT</code> to balance atomicity and loader performance. For databases without multi-row values support default to single-row INSERTs grouped in transaction windows. <br>4. Optional vendor upsert support: if <code>options(&quot;vendor&quot;)</code> provided (e.g., "postgres","mssql"), generate vendor-specific <code>ON CONFLICT</code> or <code>MERGE</code> constructs using <code>modConfig.SQLUpsertKey</code>. <br>5. File generation: prefer streaming to SQL file via <code>WriteTextStreaming</code>; include comments at top: <code>-- exportId</code>, <code>-- runId</code>, <code>-- codeVersion</code>. <br>Return: <code>{ success, scriptPath, rowsGenerated, warnings }</code>. <br>Notes: Use SQL scripts only when downstream DB ingestion cannot consume NDJSON/CSV or when transactional application-level logic is required. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: ExportManifest</strong><br>Purpose: generate a canonical manifest JSON that provides machine-readable provenance and checksums for every exported file.<br>Signature: <code>ExportManifest(runId As String, exportFiles As Collection, destPath As String) As Scripting.Dictionary</code>.<br>Manifest schema (recommended canonical minimal fields):<br>1. <code>exportId</code> — UUID for this export. <br>2. <code>runId</code> — source run identifier. <br>3. <code>exportVersion</code> — integer. <br>4. <code>createdAt</code> — ISO8601 UTC timestamp. <br>5. <code>files</code> — array of <code>{ fileName, relativePath, sizeBytes, rowCount (if applicable), checksum:{algorithm, value} }</code>. <br>6. <code>codeVersion</code> — git sha or build tag. <br>7. <code>configSnapshotRef</code> — path or inline JSON of the <code>modConfig</code> snapshot used. <br>8. <code>signatures</code> — optional array of <code>{ signerId, algorithm, signatureValue, signedAt }</code>. <br>9. <code>retention</code> — <code>{ policyName, expiresAt }</code> computed from <code>modConfig.RetentionDays</code> and <code>createdAt</code>. <br>10. <code>notes</code> — string with free-form operational notes. <br>Manifest production & validation:<br>- Compute <code>sizeBytes</code> and <code>rowCount</code> (ndjson line count or CSV line count excluding header). <br>- Validate checksums computed earlier match file contents; if mismatch, set manifest <code>status=INVALID</code> and include <code>validationErrors</code>. <br>- Write manifest with deterministic key ordering and pretty printing for human readability; also write compact <code>manifest.ndjson</code> if required. <br>Return: <code>{ success, manifestPath, manifestDict }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: ComputeFileChecksum</strong><br>Purpose: produce reliable file-level checksum values for manifest and validation.<br>Signature: <code>ComputeFileChecksum(fullPath As String, algorithm As String) As String</code>.<br>Supported algorithms & implementation guidance:<br>1. <code>CRC32</code> for quick non-cryptographic checks. <br>2. <code>SHA1</code> as legacy option. <br>3. <code>SHA256</code> recommended for strong integrity. <br>Implementation notes:<br>- Perform streaming reads in blocks (e.g., 4MB) to compute digest without loading file into memory. <br>- If environment lacks native cryptographic APIs in VBA, call an external helper (signed PowerShell or small signed executable) to compute SHA256; capture stdout and parse hex digest. <br>- Return digest as uppercase hex string. <br>Edge-case handling: if helper unavailable, emit <code>CHECKSUM_NOT_COMPUTED</code> and write a warning to <code>__Export_Audit</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: PackageExport</strong><br>Purpose: compress exported files and manifest into an archival package and optionally prepare signature integration points.<br>Signature: <code>PackageExport(exportDir As String, destZip As String, includeManifest As Boolean) As Scripting.Dictionary</code>.<br>Behavior & specifics:<br>1. Gather <code>exportDir</code> contents referenced in manifest; optionally include <code>__Export_Audit</code> fragment and <code>configSnapshot</code>. <br>2. Prefer OS-level zipping via <code>Shell</code> for performance; fallback to COM zip utilities. <br>3. On completion compute package checksum via <code>ComputeFileChecksum</code>. <br>4. Optionally create detached signature <code>destZip.sig</code> or embed signature into <code>manifest[&quot;signatures&quot;]</code> after calling <code>SignArtifact</code>. <br>5. Write <code>PACKAGE_CREATED</code> row to <code>__Export_Audit</code> with <code>zipPath</code>, <code>sizeBytes</code>, <code>checksum</code>, <code>durationMs</code>. <br>Atomicity & error handling:<br>- Create package into a temporary path and move to final destination once checksum created. If compression fails, delete temp and retry with backoff. <br>Return: <code>{ success, zipPath, zipSize, zipChecksum, error }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: SignArtifact</strong><br>Purpose: integrate with a secure signing mechanism to produce a cryptographic signature for the package, enhancing immutability and non-repudiation.<br>Signature: <code>SignArtifact(filePath As String, signerConfig As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Integration patterns and security notes:<br>1. <strong>Local helper model</strong> — call a signed local helper (PowerShell script, small .NET signed exe) that performs private-key based PKCS7 or detached signature generation. The helper must be signed and its path referenced in <code>modConfig.SignerHelperPath</code>. <br>2. <strong>Remote signing service</strong> — POST package metadata or artifact to a secure signing endpoint using mTLS or API key stored in secret manager; remote returns signature blob and signerId. Do not embed private keys in workbook. <br>3. <strong>Minimal output</strong> — return <code>{ signerId, algorithm, signatureValue, signedAt, verificationStatus }</code>. <br>4. <strong>Audit & manifest</strong> — append signature info to manifest and write <code>EXPORT_SIGNED</code> row in <code>__Export_Audit</code>. <br>Failure & mitigation:<br>- If signing fails, depending on <code>modConfig.RequireSigning</code> either abort finalization or continue and flag package <code>unsigned=true</code> with operator acknowledgment required. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: ValidateExport</strong><br>Purpose: final verification pass that ensures files match manifest expectations and are ready for hand-off.<br>Signature: <code>ValidateExport(manifest As Scripting.Dictionary, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Checks performed:<br>1. File existence and accessibility. <br>2. Checksum validation for each file (call <code>ComputeFileChecksum</code>). <br>3. Row count parity: for ndjson files count lines, for CSV count lines minus header; compare to <code>manifest.files[].rowCount</code> if present. <br>4. Schema conformant check (optional): if <code>options(&quot;schemaValidation&quot;)=True</code> and schema provided, validate the first N rows against JSON schema for shape. <br>5. Signature verification: if manifest contains signatures, call <code>VerifySignature</code> helper. <br>Return: <code>{ valid:True/False, errors:[], warnings:[] }</code> and write <code>EXPORT_VALIDATION</code> row to <code>__Export_Audit</code>. <br>On failure: if <code>modConfig.AutoForensicOnExportFail=True</code> create <code>ForensicPack</code> and set manifest <code>status=INVALID</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: RetryWithBackoff</strong><br>Purpose: provide robust retries for IO and external integration with exponential backoff and jitter.<br>Signature: <code>RetryWithBackoff(operationFuncName As String, args As Scripting.Dictionary, maxRetries As Long) As Scripting.Dictionary</code>.<br>Behavior:<br>1. Execute target operation by name (internal dispatcher that calls function or external helper). <br>2. On failure, sleep <code>t = baseDelay * (2^attempt) + jitter</code> where <code>baseDelay</code> and <code>jitter</code> are read from <code>modConfig</code>. <br>3. Log each attempt to <code>__Export_Audit</code> with <code>attemptNo</code>, <code>error</code>, and backoff time. <br>4. On exceeding <code>maxRetries</code> return <code>{ success:False, attempts:maxRetries, lastError }</code>. <br>Return: <code>{ success, attempts, result, lastError }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Function: Stream-based small helpers</strong><br>Purpose: internal writer helpers used as callbacks by <code>StreamRecordsFromAuditLog</code> and external callers.<br>Key helpers (public/internal):<br>1. <code>WriteCSVBatch(recordsArray As Variant, args As Scripting.Dictionary) As Scripting.Dictionary</code> — receives a 2D array and writes CSV lines. <br>2. <code>WriteJSONBatch(recordsArray As Variant, args As Scripting.Dictionary) As Scripting.Dictionary</code> — writes NDJSON lines for batch. <br>3. <code>WriteSQLBatch(recordsArray As Variant, args As Scripting.Dictionary) As Scripting.Dictionary</code> — append INSERT rows to SQL script file stream. <br>Properties of these helpers:<br>- Must be idempotent for a given batch ID; each batch includes <code>batchId</code> used to detect duplicate writes on resume. <br>- Report rows written, last written line number, and file path for checkpointing. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Manifest & schema recommendations (canonicality)</strong><br>1. Use stable keys and alphabetic ordering in JSON to maintain deterministic manifests across runs. <br>2. Include both <code>codeVersion</code> and <code>configSnapshot</code> (full JSON dump or reference path) in manifest for reproducibility. <br>3. Provide <code>schemaVersion</code> for exported record shape; consumer PQ can branch based on this field. <br>4. Include <code>rowCount</code> and <code>approxSizeBytes</code> per file so downstream checks are quick. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Error taxonomy recorded in __Export_Audit</strong><br>Common error codes and recommended remediation:<br>1. <code>EXPORT_IO_ERROR</code> — filesystem unavailable or permission denied; remediation: check <code>ExportDest</code> permissions and disk space. <br>2. <code>CHECKSUM_MISMATCH</code> — file content changed after checksum; remediation: quarantine file, re-export. <br>3. <code>SCHEMA_VALIDATION_FAIL</code> — first N rows violate expected schema; remediation: inspect offending rows and adjust PQ/exports or update schema. <br>4. <code>SIGNING_ERROR</code> — signer unreachable or rejected artifact; remediation: validate signer availability and credentials. <br>5. <code>EXPORT_RETRY_EXCEEDED</code> — transient retry exhausted; remediation: escalate to ops and examine partial artifacts. <br>6. <code>EXPORT_PARTIAL</code> — some parts exported; remediation: examine <code>__Export_Status</code> and resume export. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Power Query (PQ) conceptual integration guidance</strong><br>1. <strong>NDJSON ingestion recipe</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Source: Folder connector or single file <code>File.Contents(path)</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Use <code>Lines.FromBinary(File.Contents(...))</code> producing a list of lines. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Convert lines with <code>List.Transform(..., Json.Document)</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) Expand the records (componentBreakdown) into relational columns using <code>Record.FieldValues</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;e) Enforce types using <code>Table.TransformColumnTypes</code> with schema from manifest. <br>2. <strong>CSV ingestion recipe</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Use <code>Csv.Document</code> with <code>Delimiter</code> and <code>Encoding</code> per manifest. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Promote headers and <code>Trim</code> whitespace. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Parse <code>beforeJSON</code>/<code>afterJSON</code> fields by <code>Json.Document</code>. <br>3. <strong>Validation in PQ</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) After load, run an aggregation to compute the sum of <code>Delta</code> and compare with <code>ImpactReport</code> totals to validate parity. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Use manifest <code>exportId</code> field as watermark to avoid duplicate ingestion. <br>4. <strong>Automation</strong>: nightly scheduled refresh should check for <code>manifest</code> presence and only ingest exports with <code>status=VALID</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Conceptual DAX measures (operations & validation)</strong><br>Suggested DAX for export monitoring model <code>ExportAudit</code> and <code>ExportManifest</code>:<br>1. <code>TotalExports = COUNTROWS(&#x27;ExportManifest&#x27;)</code>.<br>2. <code>ExportSuccessRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;ExportManifest&#x27;),&#x27;ExportManifest&#x27;[status]=&quot;COMPLETED&quot;), [TotalExports])</code>.<br>3. <code>AvgExportDuration = AVERAGE(&#x27;ExportAudit&#x27;[durationMs])</code>.<br>4. <code>ChecksumMismatchRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;ExportAudit&#x27;),&#x27;ExportAudit&#x27;[errorCode]=&quot;CHECKSUM_MISMATCH&quot;), [TotalExports])</code>.<br>5. <code>AvgRowsPerExport = AVERAGE(&#x27;ExportManifest&#x27;[totalRows])</code>. <br>Use-case: drive alerting thresholds and operational SLAs — e.g., alert when <code>ExportSuccessRate &lt; 98%</code> over 7 days. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Examples & narratives (operational scenarios)</strong><br>Example 1 — Normal NDJSON export for run <code>R123</code>:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Operator calls <code>StartExport(&quot;R123&quot;, {format:&quot;ndjson&quot;, compress:True, sign:True})</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>StreamRecordsFromAuditLog</code> pages 10k rows in batches of 500; <code>WriteJSONFile</code> emits <code>audit_R123_v1.part01.ndjson</code> ... <code>part20.ndjson</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Checksums computed per part, manifest written with <code>exportId=E-20260219-001</code>, package zipped and signed; <code>__Export_Audit</code> logged <code>EXPORT_COMPLETE</code> with manifest path. <br>Example 2 — Partial export resume:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Export interrupted at batch 12; <code>__Export_Status</code> shows <code>lastRowExported=6000</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Operator fixes permissions; re-runs <code>StartExport</code> which detects partial export and resumes at row 6001 writing further parts; new <code>exportVersion</code> created to avoid overwriting. <br>Example 3 — Forensic pack on checksum mismatch:<br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>ValidateExport</code> finds checksum mismatch on <code>part03</code>; module quarantines artifact, creates <code>forensic_R123_20260219.zip</code> containing <code>__Stage_Backup_R123</code>, partial exports, <code>__Export_Audit</code> rows and traces; alerts ops. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Testing & acceptance criteria</strong><br>Unit & integration scenarios to include in <code>modTestingHarness</code>:<br>1. <strong>CSV escaping</strong>: field containing <code>,&quot;</code> and newline round-trips through PQ parsing and matches original structure. <br>2. <strong>NDJSON validity</strong>: each line parsed by <code>Json.Document</code>; line count equals manifest rowCount. <br>3. <strong>Checksum correctness</strong>: <code>ComputeFileChecksum</code> SHA256 value matches external tool (PowerShell <code>Get-FileHash</code>). <br>4. <strong>Resume behavior</strong>: interrupt streaming at random batch and verify resume continues from checkpoint without duplicating rows. <br>5. <strong>Signing</strong>: if <code>SignArtifact</code> integrated with test signer, signature verifies correctly. <br>6. <strong>Performance</strong>: export of N rows (configurable) completes under resource thresholds; memory usage remains stable. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Operational runbook snippets (concise)</strong><br>1. To re-run a failed export: locate <code>__Export_Audit</code> entry for <code>EXPORT_FAILED</code>, inspect error, if IO fix, increment <code>exportVersion</code> and call <code>StartExport</code> again; archive previous partial artifacts. <br>2. To validate an exported package: fetch package, compute SHA256 locally and compare with manifest entry; run <code>ValidateExport</code> and look for <code>valid=True</code>. <br>3. To produce a legal subset: call <code>StreamRecordsFromAuditLog</code> with <code>where</code> filter on <code>rowId</code> or <code>inputRowHash</code> and <code>WriteJSONFile</code> target, then package and sign as usual. <br>4. To enable signing: configure <code>modConfig.SignerHelperPath</code> and <code>modConfig.RequireSigning</code> then test sign on a small export in staging before production. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Developer notes, pitfalls, and optimizations</strong><br>1. Avoid heavy per-row VBA string concatenations — build using Variant arrays and call a single <code>WriteBlock</code> for batches. <br>2. Keep part files size below <code>modConfig.TargetPartSizeBytes</code> to help downstream parallel ingestion and avoid platform upload limits. <br>3. Use <code>Option Explicit</code>, consistent error handling patterns, and centralize IO error mapping so <code>RetryWithBackoff</code> can make accurate decisions. <br>4. For SHA256, prefer calling a signed helper rather than implementing hashing in pure VBA for performance and correctness on large files. <br>5. Document export formats and column ordering externally and include <code>manifest.version</code> to help consumers handle format changes. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Security & compliance checklist</strong><br>1. Ensure <code>ExportDest</code> is an approved, access-controlled network path; do not export to local user temp folders in production. <br>2. Purge export staging areas after successful export per <code>RetentionDays</code>. <br>3. Keep signing keys outside workbook; use external PKI or signer helper. <br>4. When hashing PII use salted SHA256 with salt stored in secure config, and record <code>hashAlgorithm</code> in manifest. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Migration & versioning</strong><br>1. When changing exported column schema, increment <code>manifest.schemaVersion</code> and keep backwards-compatible exports for at least <code>modConfig.BackCompatDays</code>. <br>2. Provide conversion PQ scripts for legacy manifests to new manifests for consumers. <br>3. Add automated regression tests verifying golden exports for each <code>exportVersion</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Acceptance & release checklist (for production rollout)</strong><br>1. Unit tests pass for writers, checksum helper verified against OS tool. <br>2. Streaming resume tested with artificial interruption. <br>3. Export ACL and signing helper integrated with operational PKI. <br>4. Admin UI exposes <code>ExportDest</code>, <code>SigningEnabled</code>, and <code>RetentionDays</code> with access restricted to Admin role. <br>5. CI pipeline runs export tests and publishes signed artifact to staging for ops acceptance. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Conceptual Power Query (PQ) and DAX guidance (summary)</strong><br>Power Query: ingest NDJSON by <code>Lines.FromBinary</code> → <code>Json.Document</code> → expand <code>componentBreakdown</code> JSON into columns; validate counts against manifest. <br>DAX: useful measures include <code>ExportSuccessRate</code>, <code>AvgExportDuration</code>, <code>ChecksumMismatchRate</code>, and <code>AvgRowsPerExport</code> to monitor health and SLA compliance. Implement alerts when <code>ChecksumMismatchRate</code> or <code>ExportFailureRate</code> exceed tolerances. </td></tr><tr><td data-label="Per-function technical breakdown — modAuditExportHelpers (VBA)"> <strong>Final summary (operational value)</strong><br><code>modAuditExportHelpers</code> provides deterministic, auditable, and scalable export capabilities required for enterprise hand-off of workbook-originated audit artifacts. It prioritizes streaming to protect Excel from memory exhaustion, manifest-driven provenance for reproducible ingestion, and robust retry/validation/signing workflows for production assurance. Implementers should pair these VBA exports with a lightweight external signer and a PQ ingestion pipeline to close the loop on reproducible, auditable exports into data warehouses and archival stores. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table2" data-table="Docu_0203_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modUtilities** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modUtilities</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Module purpose (short)</strong><br><code>modUtilities</code> is the shared utility library used across the UpdateHR+ VBA codebase. It provides small, well-tested, deterministic helpers for safe Range access, logging wrappers, time utilities, identity resolution, memoization, string/regex utilities, light-weight hashing, CSV/JSON safe serializers, configuration reading helpers, and a small set of developer-facing diagnostics. The module intentionally avoids business logic; it exposes pure helpers that are stable, fast, and safe to call from tight loops. All functions are designed to be side-effect-minimizing (few or no sheet writes), to return explicit status codes or structured dictionaries where relevant, and to emit audit-trace entries rather than performing application-level commits. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Design principles & constraints</strong><br>1. Single-responsibility: each function performs one clear operation (no hidden I/O). <br>2. Determinism: given same inputs and <code>runId</code> state, functions return same outputs. <br>3. Minimal COM usage in hot paths: prefer pure-VBA operations and in-memory arrays; centralise any required Range interactions into a small set of wrappers. <br>4. Fail-safe by default: functions return status objects (success:Boolean, errCode:String, message:String) rather than raising unhandled errors. <br>5. Lightweight telemetry: heavy profiling is opt-in via <code>modConfig.FineGrainedTelemetry</code>. <br>6. Clear naming and predictable side-effects: helpers named <code>Safe*</code> or <code>Get*</code> do not write to sheets; <code>Write*</code> functions do write but are guarded and logged. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Public surface (catalog)</strong><br>Top-level functions and utilities provided by <code>modUtilities</code> (each expanded below).<br>1. <code>GetCurrentUserId() As String</code> — canonical operator identity resolution. <br>2. <code>SafeRangeRead(rng As Range, Optional defaultValue As Variant, Optional maxRetries As Long) As Variant</code> — robust read wrapper. <br>3. <code>SafeRangeWrite(rng As Range, value As Variant, Optional maxRetries As Long) As Boolean</code> — robust write wrapper with retries and backoff. <br>4. <code>MemoizeCall(cacheKey As String, computeFunc As Variant, ttlSeconds As Long) As Variant</code> — in-run memoization utility. <br>5. <code>RegexReplace(pattern As String, input As String, replaceWith As String, Optional options As Scripting.Dictionary) As String</code> — precompiled VBScript RegExp wrapper. <br>6. <code>SimpleHash(value As String) As String</code> — deterministic non-cryptographic digest for provenance (e.g., SHA1-like or CRC32). <br>7. <code>ToJsonSafe(v As Variant) As String</code> — lightweight JSON serializer for simple dictionaries/arrays and primitives (no full JSON engine required). <br>8. <code>FromJsonSafe(json As String) As Scripting.Dictionary</code> — minimal parser for the module's safe JSON outputs (keeps compatibility in audit export). <br>9. <code>FormatTimestamp(Optional dt As Date) As String</code> — ISO8601 UTC timestamp string. <br>10. <code>LogDebug(category As String, msg As String, Optional meta As Scripting.Dictionary)</code> — append to <code>__Diagnostics</code> or <code>__Telemetry</code> depending on config. <br>11. <code>EnsureNamedRangeExists(name As String) As Boolean</code> — validate workbook named ranges and return boolean. <br>12. <code>ChunkArray(arr As Variant, chunkSize As Long) As Collection</code> — utility to split big arrays into chunks. <br>13. <code>CSV_Escape(value As Variant) As String</code> — CSV-safe escaping for export. <br>14. <code>SafeCreateHiddenSheet(name As String) As Worksheet</code> — create or return an existing hidden worksheet with protection defaults. <br>15. <code>WaitMs(milliseconds As Long)</code> — utility using <code>Sleep</code> or tight <code>Timer</code> loop with <code>DoEvents</code> for short waits in retry backoffs. <br>16. <code>TryParseDouble(s As String, ByRef outVal As Double) As Boolean</code> — robust parse for numeric strings with locale handling. <br>17. <code>ResolveWorkbookPathPolicy()</code> — read environment-specific workbook path rules (used by export helpers). </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: GetCurrentUserId</strong><br>Purpose: resolve effective user identity for audit and UI authorization.<br>Signature: <code>GetCurrentUserId() As String</code>.<br>Behavior & logic:<br>1. Resolution order (deterministic): <br>&nbsp;&nbsp;&nbsp;&nbsp;a) workbook custom property <code>OperatorUserId</code> if present and non-empty; <br>&nbsp;&nbsp;&nbsp;&nbsp;b) hidden config sheet <code>__Config</code> key <code>DefaultOperator</code> for unattended runs; <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Windows environment <code>Environ(&quot;USERNAME&quot;)</code> fallback; <br>&nbsp;&nbsp;&nbsp;&nbsp;d) return <code>&quot;unknown_user&quot;</code> as last resort. <br>2. Normalisation: trim, uppercase/lowercase per project policy (store as lower-case to reduce collisions). <br>3. Audit: when called during a run that has <code>runId</code>, returns <code>userId</code> and writes a small <code>UserResolve</code> debug row to <code>__Diagnostics</code> if <code>modConfig.DebugUserResolve = True</code>. <br>Edge cases & notes:<br>- If <code>OperatorUserId</code> is present but differs from OS user, prefer workbook property (explicit override). <br>- Do not perform network calls here; identity must be local. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: SafeRangeRead</strong><br>Purpose: robust single-range read with retry/backoff, transient error handling, and optional default fallback.<br>Signature: <code>SafeRangeRead(rng As Range, Optional defaultValue As Variant = Empty, Optional maxRetries As Long = 3) As Variant</code>.<br>Behavior & implementation detail:<br>1. Attempt to read <code>rng.Value</code> into a Variant; wrap with <code>On Error</code> to catch COM errors and reattempt up to <code>maxRetries</code>. <br>2. Backoff strategy: linear or exponential small wait (<code>WaitMs</code>) between attempts with <code>DoEvents</code> to allow Excel to recover. <br>3. Error classification: distinguish transient COM errors (e.g., clipboard busy, OLE call timeout) vs fatal errors (invalid range). Map fatal errors to returning <code>defaultValue</code> and a call to <code>LogDebug(&quot;SafeRangeRead&quot;,&quot;Fatal&quot;,meta)</code>. <br>4. Return value: read value or <code>defaultValue</code> in failure. <br>Usage guidance:<br>- Use for reading single-cell inputs inside loops; for multi-cell reads prefer bulk variant-array read in caller and avoid repeated <code>SafeRangeRead</code> calls. <br>Telemetry and audit:<br>- If <code>modConfig.LogRangeErrors=True</code> then append a compact line to <code>__Diagnostics</code> with <code>sheet</code>, <code>address</code>, <code>attempts</code>, <code>errorNumber</code>, <code>errorMessage</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: SafeRangeWrite</strong><br>Purpose: robust single-range write with retry/backoff, optional verification, and safe-fail semantics.<br>Signature: <code>SafeRangeWrite(rng As Range, value As Variant, Optional maxRetries As Long = 3, Optional verify As Boolean = True) As Boolean</code>.<br>Key behavior:<br>1. Writes in guarded block with <code>On Error</code>. On transient failures, retry with backoff as <code>SafeRangeRead</code> does. <br>2. After initial write, if <code>verify=True</code>, read back the target value and compare to <code>value</code>. If mismatch, retry; after <code>maxRetries</code> failures, write a <code>SafeWriteFailed</code> debug row and return <code>False</code>. <br>3. For array writes (multi-cell), prefer passing a 2D Variant array and ensure the target range size matches to avoid partial writes; otherwise return <code>False</code> with <code>errCode = &quot;RANGE_MISMATCH&quot;</code>. <br>4. Logging: successful writes record a lightweight telemetry point when <code>modConfig.LogWrites=True</code> (runId, sheet, address, size, timeMs). <br>Performance notes:<br>- Avoid calling per-cell; aggregate writes into arrays at higher module level. <br>Security considerations:<br>- For sensitive cells (salary, bank account), optionally mark them in <code>modConfig.SensitiveTargets</code> to reduce logging granularity (only log counts not values). </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: MemoizeCall</strong><br>Purpose: in-run memoization cache for pure functions to reduce repeated computation (e.g., <code>NGramFingerprint</code>, <code>PhoneticEncode</code>).<br>Signature: <code>MemoizeCall(cacheKey As String, computeFunc As Variant, ttlSeconds As Long) As Variant</code>.<br>Behavior:<br>1. <code>cacheKey</code> is a stable string (caller must include <code>runId</code> when cross-run isolation required). <br>2. Module-level dictionary <code>dictMemo</code> stores <code>{value, insertedAt}</code>. On read, if <code>Now - insertedAt &lt; ttlSeconds</code> return cached value; otherwise call <code>computeFunc()</code> (the computeFunc reference is executed by caller convention), store and return. <br>3. Threading note: VBA runs single-threaded; there is no concurrency issue across threads within the same Excel instance. However, if multiple Excel instances are used, caches are local to process. <br>4. Memory management: <code>dictMemo</code> growth limited by <code>modConfig.MemoMaxEntries</code> and eviction uses simple LRU or FIFO policy; a developer can call <code>ClearMemo(runId)</code> at run end or periodically. <br>Examples of use: caching <code>PhoneticEncode(&quot;...&quot;)</code> results, <code>NGramFingerprint</code> results, <code>NormalizedFuzzyScore</code> for repeated candidate pairs. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: RegexReplace</strong><br>Purpose: wrapper around VBScript.RegExp to execute replace patterns safely and with precompiled pattern caching.<br>Signature: <code>RegexReplace(pattern As String, input As String, replaceWith As String, Optional options As Scripting.Dictionary) As String</code>.<br>Behavior & features:<br>1. Pattern caching: module-level dictionary <code>dictRegexCache</code> stores precompiled RegExp objects keyed by <code>(pattern|ignorecase|multiline)</code> to avoid repeated object creation overhead. <br>2. Options: <code>ignoreCase</code> (default True), <code>global</code> (default True), <code>multiLine</code> (default False), <code>escapePattern</code> (if True will escape <code>pattern</code> before compiling). <br>3. Safety: the function traps RegExp compile errors and returns input unchanged while logging the compile error to <code>__Diagnostics</code> to prevent run failure due to a bad pattern. <br>4. Unicode behavior: uses VBScript RegExp limitations; for advanced Unicode transforms recommend calling small helper <code>NormalizeUnicode</code> before regex. <br>Example usage: strip NBSP characters, fold multiple spaces to single, remove punctuation except apostrophes. <br>Performance note: precompile frequently-used patterns at run start (e.g., patterns in <code>modConfig.CanonicalizationPatterns</code>) to reduce latency. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: SimpleHash</strong><br>Purpose: compute a deterministic lightweight digest used for internal provenance (not a cryptographic signature).<br>Signature: <code>SimpleHash(value As String) As String</code>.<br>Requirements & behavior:<br>1. Use non-cryptographic deterministic algorithm (e.g., CRC32 or FNV-1a) implemented in VBA for portability. <br>2. Output format: hex string <code>lowercase</code> with fixed width (e.g., 8 hex digits) to easily fit into Excel cells. <br>3. Use cases: compute <code>inputRowHash</code>, simple row checksums for <code>Audit_Log</code>, and build quick content-equality checks for replay detection. <br>4. Document in <code>__Run_Config</code> that <code>SimpleHash</code> is not cryptographic and should not be used for legal signing. For immutable/trustworthy signatures, integrate with external PKI as described in <code>modSignatures</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: ToJsonSafe & FromJsonSafe</strong><br>Purpose: minimal JSON roundtrip for small dictionaries/arrays for audit and export without heavy dependencies.<br>Signatures: <code>ToJsonSafe(v As Variant) As String</code> and <code>FromJsonSafe(json As String) As Scripting.Dictionary</code>.<br>Design & constraints:<br>1. <code>ToJsonSafe</code> supports primitives (String/Number/Boolean/Null), 1-level dictionaries and 1-level arrays (no deep arbitrary graph). It produces stable property ordering (sorted keys) to make deterministic checksums reproducible. <br>2. <code>FromJsonSafe</code> is defensive: accept only schema matching <code>ToJsonSafe</code> output; return <code>Nothing</code> or error object for malformed input rather than throwing. <br>3. Escaping: escape control chars, quotes, and ensure numeric types preserved. <br>4. Use-case: write <code>beforeJSON</code> and <code>afterJSON</code> in <code>Audit_Log</code> cells; small payloads only (avoid serialising massive arrays). <br>Implementation notes: keep parser simple and documented; if project later requires full JSON, migrate to external helper service or reference a vetted VBA JSON library and include migration scripts. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: FormatTimestamp</strong><br>Purpose: consistent ISO-8601 UTC timestamp formatting used across telemetry, audit, and export file names.<br>Signature: <code>FormatTimestamp(Optional dt As Date) As String</code>.<br>Behavior:<br>1. If <code>dt</code> omitted uses <code>Now</code> and converts to UTC using <code>VBA.UTC</code> approach (compute local offset via <code>Now</code> and <code>Timer</code> heuristics or use Windows API if available). <br>2. Output format: <code>YYYY-MM-DDTHH:MM:SSZ</code> (e.g., <code>2026-02-19T10:15:03Z</code>). <br>3. Use for run manifest fields, <code>Audit_Log</code> timestamps, and export manifest. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: LogDebug</strong><br>Purpose: centralised light-weight logging used by all modules for debug, telemetry, and optional persistence to <code>__Diagnostics</code> or <code>__Telemetry</code> sheets.<br>Signature: <code>LogDebug(category As String, msg As String, Optional meta As Scripting.Dictionary) As Boolean</code>.<br>Behavior & features:<br>1. Logging destinations controlled by <code>modConfig</code>: <code>LogToSheet = &quot;__Diagnostics&quot; | &quot;__Telemetry&quot; | &quot;None&quot; | &quot;External&quot;</code>. <br>2. If <code>External</code> and <code>modConfig.TelemetryEndpoint</code> configured, queue a batched outbound telemetry payload; otherwise write to local hidden sheet as an append-only row. <br>3. Each appended row includes: <code>utcTimestamp</code>, <code>runId</code> (if available), <code>category</code>, truncated <code>msg</code> (max length set by <code>modConfig.LogMsgMaxLen</code>), serialized <code>meta</code> (via <code>ToJsonSafe</code>). <br>4. Return <code>True</code> on success. If <code>LogToSheet</code> present and sheet missing, create via <code>SafeCreateHiddenSheet</code>. <br>Telemetry considerations:<br> - Keep volume modest: use <code>LogDebug</code> for warnings/errors and sample telemetry only; heavy telemetry should be batched and flagged as <code>telemetryType = &quot;sampled&quot;</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: EnsureNamedRangeExists</strong><br>Purpose: validate presence and basic integrity of a named range before runs.<br>Signature: <code>EnsureNamedRangeExists(name As String) As Boolean</code>.<br>Behavior & validation checks:<br>1. Attempt <code>ThisWorkbook.Names(name)</code> access; handle <code>On Error</code> and return <code>False</code> if missing. <br>2. If present, optionally validate target sheet exists and range address resolves; check range size > 0. <br>3. If invalid and <code>modConfig.AutoCreateMissingRanges = True</code>, create an empty range placeholder <code>sheet.Cells(1,1)</code> and write a <code>NAMED_RANGE_PLACEHOLDER</code> comment for admin attention; return <code>False</code> but include <code>placeholderCreated</code> meta in <code>__Diagnostics</code>. <br>Use-case: pre-run preflight checks call <code>EnsureNamedRangeExists</code> for all required named ranges. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: ChunkArray</strong><br>Purpose: safe splitting of Variant arrays into smaller chunks for batch processing and chunk-commits.<br>Signature: <code>ChunkArray(arr As Variant, chunkSize As Long) As Collection</code>.<br>Behavior:<br>1. Accepts one-dimensional or two-dimensional Variant arrays (also accepts a Collection); returns a Collection of Variant arrays. <br>2. Preserve order deterministically. <br>3. Edge behaviors: if <code>chunkSize &lt;= 0</code> throw controlled error; if <code>arr</code> empty return empty Collection. <br>4. Use-case: in <code>modBatchProcessing</code> to create commit-chunks for staging, minimize memory peaks. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: CSV_Escape</strong><br>Purpose: escape a value for CSV export ensuring correct quoting and newline handling.<br>Signature: <code>CSV_Escape(value As Variant) As String</code>.<br>Behavior & rules:<br>1. Convert <code>Null</code>/Empty to empty string. <br>2. If value contains delimiter, newline, or quotes, wrap in double-quotes and double internal quotes (standard RFC4180). <br>3. For numeric types, output as string representation preserving decimal dot; handle thousands separators by avoiding locale-specific formatting. <br>4. Use <code>CSV_Escape</code> when building exports in <code>modAuditExportHelpers</code> to produce robust CSV readable by PQ. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: SafeCreateHiddenSheet</strong><br>Purpose: create or return an existing hidden worksheet with consistent protection & naming policy used by staging and diagnostics sheets.<br>Signature: <code>SafeCreateHiddenSheet(name As String) As Worksheet</code>.<br>Behavior & safeguards:<br>1. If <code>name</code> exists return it. <br>2. If not, add new worksheet, set <code>Visible = xlSheetVeryHidden</code>, set <code>EnableFormatProtection = True</code>, optionally protect with <code>modConfig.InternalSheetPassword</code> (store hashed), and write header row based on <code>name</code>. <br>3. Fail-safe: if sheet creation fails (Excel permissions), throw a structured error object logged by <code>LogDebug</code> and return <code>Nothing</code>. <br>Security notes: restrict value exposure; avoid writing sensitive PII to these sheets unless necessary and masked. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: WaitMs</strong><br>Purpose: small helper to pause execution for a specified number of milliseconds (useful in retry backoffs).<br>Signature: <code>WaitMs(milliseconds As Long)</code>.<br>Implementation:<br>1. Use Windows <code>Sleep</code> API if available (preferred) or fallback to looped <code>DoEvents</code> checking <code>Timer</code> to approximate sleep. <br>2. Ensure no infinite loops and that waiting under small amounts does not lock UI completely; call <code>DoEvents</code> inside wait. <br>Warning: avoid long sleeps inside UI threads; use small backoffs (e.g., 50–200ms). </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: TryParseDouble</strong><br>Purpose: robust numeric parsing handling common locale issues and sanitized input strings.<br>Signature: <code>TryParseDouble(s As String, ByRef outVal As Double) As Boolean</code>.<br>Behavior:<br>1. Trim whitespace and remove non-numeric trailing characters (e.g., currency symbols) if present and configured. <br>2. Replace locale-specific decimal separators by standard dot or consult <code>modConfig.DecimalSeparator</code> when set. <br>3. Attempt <code>CDbl</code>; trap errors and return <code>False</code> if parsing fails. <br>4. Useful for reading Calculator UI cells where formatting may include parentheses for negatives or currency symbols. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Function: ResolveWorkbookPathPolicy</strong><br>Purpose: compute canonical file system paths for import/export based on environment and <code>modConfig</code> rules.<br>Signature: <code>ResolveWorkbookPathPolicy() As Scripting.Dictionary</code>.<br>Behavior & keys returned:<br>1. <code>exportDir</code> — canonical absolute path for artifacts; prefer <code>modConfig.ExportDir</code> if present; otherwise construct from <code>ThisWorkbook.Path &amp; &quot;\exports\&quot;</code>. <br>2. <code>archiveDir</code> — where to move completed exports. <br>3. <code>useNetwork</code> boolean — true if <code>ExportDir</code> points to network UNC path. <br>4. Writes a small diagnostic entry to <code>__Diagnostics</code> to help operators debug path issues. <br>Security: validate that <code>exportDir</code> is writable; if not, return an error and a remediation suggestion. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Explainability & audit integration (how utilities feed audit)</strong><br>1. Each <code>SafeRangeWrite</code>/<code>SafeRangeRead</code> failure writes a compact <code>__Diagnostics</code> row with <code>runId</code>, function, sheet, address, attempts, and errorNumber. <br>2. <code>MemoizeCall</code> events are optionally recorded (miss/hit) to <code>__Telemetry</code> to calculate <code>MemoHitRate</code>. <br>3. <code>SimpleHash</code> results are used as compact <code>inputRowHash</code> values and included verbatim in <code>Audit_Log</code>. <br>4. <code>ToJsonSafe</code> output is used in <code>Audit_Log.beforeJSON</code> and <code>.afterJSON</code> cells to enable PQ expansion later. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Power Query (PQ) conceptual guidance (consuming utilities output)</strong><br>1. <strong>Ingest <code>__Diagnostics</code>/<code>__Telemetry</code></strong>: Use PQ to load the CSV/ndjson export produced by <code>modAuditExportHelpers</code>. Parse JSON <code>meta</code> fields using <code>Json.Document</code> and expand records into columns for BI. <br>2. <strong>Memoization analysis</strong>: import <code>MemoProfile</code> lines to compute <code>MemoHitRate = DIVIDE([MemoHits],[MemoHits]+[MemoMisses])</code> and visualize as a trend. <br>3. <strong>Range error trend analysis</strong>: parse <code>SafeRangeRead</code>/<code>SafeRangeWrite</code> rows, group by <code>errorNumber</code> and <code>sheet</code>, compute counts and moving windows to surface flaky ranges. <br>4. <strong>Path policy dialog</strong>: ingest <code>ResolveWorkbookPathPolicy</code> manifest to verify <code>exportDir</code> and produce an alert if the path is not accessible in a monitored location. <br>Implementation note: always parse <code>timestamp</code> through DateTimeZone.FromText in PQ and convert to UTC. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Conceptual DAX measures (analytics using PQ-ingested utils telemetry)</strong><br>1. <code>MemoHitRate = DIVIDE(SUM(&#x27;MemoProfile&#x27;[Hits]), SUM(&#x27;MemoProfile&#x27;[Hits]) + SUM(&#x27;MemoProfile&#x27;[Misses]))</code>.<br>2. <code>RangeErrorRate = DIVIDE(COUNTROWS(FILTER(&#x27;Diagnostics&#x27;,&#x27;Diagnostics&#x27;[category]=&quot;SafeRangeError&quot;)), COUNTROWS(&#x27;ProcessedRows&#x27;))</code>.<br>3. <code>AvgWriteVerifyTimeMs = AVERAGE(&#x27;WriteTelemetry&#x27;[verifyMs])</code>.<br>4. <code>TelemetryVolumePerRun = COUNTROWS(FILTER(&#x27;Telemetry&#x27;,&#x27;Telemetry&#x27;[runId]=SELECTEDVALUE(&#x27;Runs&#x27;[runId])))</code>. <br>Use these measures on an operations dashboard to detect environment regressions and to track improvements when caching or batching is enabled. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Performance & memory considerations</strong><br>1. Avoid calling <code>SafeRangeRead</code>/<code>SafeRangeWrite</code> inside tight per-cell loops; instead bulk-read into variant arrays and operate in-memory. <br>2. <code>dictRegexCache</code> and <code>dictMemo</code> are module-level; monitor size and provide <code>ClearCaches()</code> API to free memory between large runs. <br>3. <code>ToJsonSafe</code> and <code>FromJsonSafe</code> are intentionally lightweight and not suitable for very large nested objects; for large payloads prefer file-based exports. <br>4. Use <code>ChunkArray</code> to split giant lists prior to heavy processing to avoid overallocation. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Error codes & conventions</strong><br>Standardised return/Error patterns (<em>adopt across module consumers</em>):<br>1. <code>OK</code> — success (or Boolean True/Variant non-error). <br>2. <code>ERR_TRANSIENT</code> — transient COM error that may succeed on retry. <br>3. <code>ERR_FATAL</code> — non-recoverable error; contain <code>errNumber</code> and <code>errText</code>. <br>4. <code>ERR_RANGE_MISMATCH</code> — write/read range shape mismatch. <br>5. <code>ERR_MEMO_FULL</code> — memo cache max entries exceeded. <br>Consumers should map these into <code>Audit_Log</code> <code>status</code> or <code>runSummary.errors</code>. Always include <code>errCode</code> and short <code>errMessage</code> in audit rows. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Edge cases & mitigations</strong><br>1. <strong>COM flakiness</strong>: Retry with backoff, but after repeated failures escalate (write <code>RUN_PAUSED</code> and append <code>__Diagnostics</code> entry) instead of busy-looping. <br>2. <strong>Large caches</strong>: provide <code>MemoMaxEntries</code> config and an eviction policy (LRU) to avoid memory exhaustion. <br>3. <strong>Locale numeric parsing</strong>: <code>TryParseDouble</code> aggressively normalizes decimal separators and parentheses; if parse fails, surface cell content in diagnostics for manual review. <br>4. <strong>Excel protected sheets</strong>: <code>SafeRangeWrite</code> detects <code>ReadOnly</code> or <code>Protect</code> states and returns <code>ERR_FATAL</code> with remediation message (unlock required). </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Testing checklist (unit & integration)</strong><br>Unit tests to include in <code>modTestingHarness</code>:<br>1. <code>GetCurrentUserId</code> returns workbook override when set and OS user fallback when not. <br>2. <code>SafeRangeRead</code>/<code>SafeRangeWrite</code> simulate transient COM errors by mocking and verify retry path and final error row in <code>__Diagnostics</code>. <br>3. <code>MemoizeCall</code> respects TTL and eviction policy. <br>4. <code>RegexReplace</code> returns expected replacements for canonical patterns; caching reduces create-time by measurable amount. <br>5. <code>ToJsonSafe</code>/<code>FromJsonSafe</code> roundtrip simple dictionaries and arrays deterministically. <br>Integration tests:<br>1. Run with a small sample workbook and produce telemetry; verify <code>MemoHitRate</code> computed via PQ matches expected. <br>2. Simulate protected sheet and verify <code>SafeRangeWrite</code> returns <code>ERR_FATAL</code> and writes diagnostic row. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Operational how-to items (operator & developer)</strong><br>1. Clearing transient caches: run <code>modUtilities.ClearCaches</code> at end of run or manually via config UI. <br>2. Enabling fine-grained telemetry: set <code>modConfig.FuzzyProfileEnabled</code> and <code>modConfig.LogRangeErrors</code> for a diagnostic window; remember to turn off in production to reduce workbook growth. <br>3. When adding new heavy utility: ensure corresponding PQ ingestion step is added to <code>__Fuzzy_Tuning</code> or <code>__Diagnostics</code> ETL to keep BI parity. <br>4. For legal-grade signing or hashing upgrade: replace <code>SimpleHash</code> with an external sign service integrated via <code>modAuditExportHelpers</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Examples & narratives (non-code)</strong><br>Example A — transient write scenario:<br>- An operator runs a large batch and an intermittent COM error (<code>-2147417848</code>) occurs on a write. <code>SafeRangeWrite</code> retries 3 times with short backoffs; on final failure it writes <code>SafeWriteFailed</code> to <code>__Diagnostics</code> with <code>sheet</code>, <code>address</code>, <code>attempts=3</code> and <code>errNumber</code>. <code>modCoreEngine</code> sees <code>ERR_FATAL</code> in chunk commit and calls <code>RollbackRun</code> for safety. <br>Example B — memoization benefiting fuzzy scoring:<br>- <code>ComputeFuzzyBatchScores</code> uses <code>MemoizeCall</code> for <code>NGramFingerprint</code> and <code>PhoneticEncode</code>. On repeated candidate comparisons across rows, the memo hit rate increases from 12% to 78%, reducing CPU per-row by ~40% in profiling. The <code>__Telemetry</code> <code>MemoProfile</code> rows show <code>MemoHitRate=0.78</code> for the run and <code>modConfig</code> allowed operators to confidently raise <code>MaxFuzzyComparisonsPerRow</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Power Query (PQ) example: ingesting utilities telemetry</strong><br>1. Source: CSV export from <code>modAuditExportHelpers.WriteCSVFile</code> for <code>__Diagnostics</code>.<br>2. Step 1: Load file and convert <code>timestamp</code> column using <code>DateTimeZone.FromText</code>. <br>3. Step 2: Expand <code>meta</code> JSON using <code>Json.Document</code>, add columns <code>sheet</code>, <code>address</code>, <code>errorNumber</code>. <br>4. Step 3: Aggregate by <code>errorNumber</code> and <code>sheet</code> to produce a dashboard-ready table <code>RangeErrorSummary</code>. <br>5. Visualization: plot <code>RangeErrorSummary[Count]</code> over time to pinpoint flaky ranges. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Conceptual DAX example (for monitoring)</strong><br>1. <code>RangeErrorRate = DIVIDE(SUM(&#x27;RangeErrors&#x27;[Count]), SUM(&#x27;ProcessedRows&#x27;[RowCount]))</code>.<br>2. <code>AvgMemoHitRate = AVERAGE(&#x27;MemoProfile&#x27;[MemoHitRate])</code>.<br>3. <code>SlowComparePct95 = PERCENTILEX.INC(&#x27;FuzzyProfile&#x27;,&#x27;FuzzyProfile&#x27;[timeMs],0.95)</code> (requires PQ-ingested <code>timeMs</code>). </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Implementation checklist for developers</strong><br>1. Implement <code>dictRegexCache</code> and <code>dictMemo</code> as <code>Scripting.Dictionary</code> with <code>Exists</code> and explicit <code>Remove</code> methods for eviction. <br>2. Centralise all sheet writes to <code>modUtilities.LogDebug</code> and <code>SafeCreateHiddenSheet</code> to maintain consistent hidden-sheet patterns. <br>3. Provide unit test harness entries for each function above and include golden outputs in repository for CI regression. <br>4. Document all <code>modConfig</code> keys impacting utilities in <code>__Run_Config</code> and surface editable safe fields in admin UI only. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Change control & versioning</strong><br>1. Version <code>modUtilities</code> with semantic versioning in <code>__Run_Config</code> (<code>utilitiesVersion</code>) and embed in <code>Audit_Log</code> rows for each run. <br>2. When changing serialization (<code>ToJsonSafe</code>) or hashing (<code>SimpleHash</code>) update migration note and provide script to rebuild <code>Audit_Log</code> checksums if required. </td></tr><tr><td data-label="Per-function technical breakdown — modUtilities (VBA)"> <strong>Final summary</strong><br><code>modUtilities</code> is the defensive foundation of UpdateHR+. It encapsulates safe Excel I/O, memoization, deterministic timestamping and hashing, small JSON utilities, regex helpers, CSV escaping, and telemetry/logging primitives. Proper implementation reduces run instability, simplifies error handling across the orchestration stack, and produces clean artifacts for PQ ingestion and DAX monitoring. Follow the performance heuristics (bulk reads/writes, TTL-bounded memo caches, precompiled regex), respect <code>modConfig</code> controls, and ensure all diagnostic outputs are consumed by the nightly PQ ETL to maintain operational observability. </td></tr></tbody></table></div><div class="row-count">Rows: 33</div></div><div class="table-caption" id="Table3" data-table="Docu_0203_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modConfig (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modConfig (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Preface — validation & scope</strong><br>I reviewed the session and this spec thoroughly. This document focuses exclusively on <code>modConfig</code> — its per-function responsibilities, signatures, behaviors, failure modes, governance interactions, testing, PQ/DAX guidance, and runbook steps. It assumes the rest of the architecture (core engine, matching, fuzzy, audit) uses <code>modConfig</code> as the sole trusted configuration source. All numbered lists below use <code>&lt;br&gt;</code> for line breaks. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Module purpose (concise)</strong><br><code>modConfig</code> provides a typed, validated, auditable configuration layer for UpdateHR+. It loads environment-specific settings, enforces governance constraints, exposes typed accessors, persists immutable run snapshots, supports admin UI binding and safe edits, offers CI/CD promote/import helpers, and stores sensitive values safely. The module prevents unsafe runtime decisions by performing defensive validation and enforces role-based policies around changing critical keys. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Design principles & guarantees</strong><br>1. Single source of truth — all runtime settings consumed by other modules must be retrieved from <code>modConfig</code> APIs and not from direct cell reads. <br>2. Immutable run snapshots — every run must call <code>PersistConfigSnapshot</code> before any write so runs are reproducible. <br>3. Typed accessors — callers use <code>GetConfigBool</code>, <code>GetConfigInt</code>, <code>GetConfigDouble</code>, <code>GetConfigString</code> to avoid ad-hoc casting. <br>4. Defensive validation — <code>ValidateConfig</code> returns structured errors/warnings and prevents runs on critical failures. <br>5. Least privilege edits — only Admin role may change critical keys; changes are recorded to <code>Macro_ChangeLog</code>. <br>6. Fail-safe defaults — missing or invalid keys revert to conservative, safe defaults and log warnings. <br>7. Sensitive handling — secrets stored in <code>__Secrets</code> sheet with redaction on exports. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>High-level responsibilities</strong><br>1. Load and expose effective configuration for an environment (<code>dev</code>/<code>test</code>/<code>prod</code>). <br>2. Validate logical constraints and value bounds. <br>3. Provide typed get/set APIs with audit logging. <br>4. Persist immutable per-run snapshots (<code>__Run_Config</code>) used for replay. <br>5. Bind config to admin UI with staged apply and two-step approval for production changes. <br>6. Support import/export for CI/CD promotion and environment parity. <br>7. Provide runtime override support and emergency kill-switches. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Primary data sources & storage</strong><br>1. Hidden worksheet <code>__Config</code> — canonical config table (key, value, type, min, max, uiHint, requiresAdmin, sensitiveFlag, description). <br>2. Optional external JSON config files (repo-managed) used for promotions. <br>3. <code>__Secrets</code> sheet — vault for sensitive keys (protected). <br>4. <code>__Run_Config</code> — per-run immutable snapshots. <br>5. <code>Macro_ChangeLog</code> — audit trail for config edits. <br>6. <code>__Config_Backups</code> — automated backups when writes occur. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Public API — function list (short)</strong><br>1. <code>LoadConfig(env As String) As Scripting.Dictionary</code> — load effective config. <br>2. <code>GetConfigValue(key As String, Optional defaultValue As Variant) As Variant</code> — generic accessor. <br>3. <code>GetConfigBool(key As String, Optional defaultValue As Boolean) As Boolean</code> — typed boolean. <br>4. <code>GetConfigInt(key As String, Optional defaultValue As Long) As Long</code> — typed integer. <br>5. <code>GetConfigDouble(key As String, Optional defaultValue As Double) As Double</code> — typed float. <br>6. <code>GetConfigString(key As String, Optional defaultValue As String) As String</code> — typed string. <br>7. <code>SetConfigValue(key As String, value As Variant, changedBy As String, Optional reason As String) As Scripting.Dictionary</code> — admin setter with audit. <br>8. <code>ValidateConfig() As Scripting.Dictionary</code> — full-surface validation. <br>9. <code>PersistConfigSnapshot(runId As String, appliedBy As String, Optional notes As String) As String</code> — write immutable snapshot; returns snapshotId. <br>10. <code>ExportConfigToJSON(path As String, Optional includeSecrets As Boolean = False) As Boolean</code> — produce JSON for promotion. <br>11. <code>ImportConfigFromJSON(path As String, appliedBy As String) As Scripting.Dictionary</code> — import, validate, and stage. <br>12. <code>PersistRuntimeOverrides(runId As String, overrides As Scripting.Dictionary, appliedBy As String) As Scripting.Dictionary</code> — per-run overrides. <br>13. <code>BindConfigToUI(configSheet As Worksheet) As Boolean</code> — bind for admin UI. <br>14. <code>ReloadConfigIfChanged() As Boolean</code> — detect external changes and reload in-memory cache. <br>15. <code>GetAllKeys() As Collection</code> — canonical key list and metadata. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: LoadConfig</strong><br>Signature: <code>LoadConfig(env As String) As Scripting.Dictionary</code>.<br>Purpose: assemble effective configuration for <code>env</code> using <code>__Config</code> defaults, env-specific overrides, and secure secrets where needed.<br>Inputs: <code>env</code> one of <code>dev|test|prod|local</code>.<br>Behavior & steps:<br>1. Read <code>__Config</code> into an in-memory dict (use <code>ReadConfigSheet()</code>). <br>2. Apply environment overlays: keys marked <code>env.*</code> or specific <code>env</code> rows override defaults. <br>3. Merge <code>__Secrets</code> values for sensitive keys if run by Admin and <code>includeSecrets</code> allowed. <br>4. Convert typed values per <code>KeyMetadata()</code> (booleans, ints, doubles, JSON strings). <br>5. Compute <code>computedKeys</code> such as <code>chunkSize = Min(batchSize, floor(totalRows/20))</code> if not explicitly set. <br>6. Validate via <code>ValidateConfig</code> (warnings allowed); return dictionary <code>{&quot;IsValid&quot;:True,&quot;Config&quot;:dict,&quot;Warnings&quot;:col}</code> or raise structured error if critical failure and <code>env=&quot;prod&quot;</code>. <br>Outputs: returns effective config dictionary ready for typed read functions. <br>Error handling: on file/parse error logs <code>ConfigLoadError</code> and returns <code>{IsValid:False,Errors:col}</code> to caller. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: GetConfigValue / typed getters</strong><br>Signatures: <code>GetConfigValue(key As String, Optional defaultValue As Variant) As Variant</code>; <code>GetConfigBool</code>, <code>GetConfigInt</code>, <code>GetConfigDouble</code>, <code>GetConfigString</code>.<br>Purpose: safe reads with type coercion, validation, and warnings.<br>Behavior:<br>1. <code>GetConfigValue</code> checks in-memory active config first; if missing returns <code>defaultValue</code>. <br>2. Typed getters call <code>GetConfigValue</code>, attempt type conversion with robust parsing: boolean accepts <code>True/False/1/0/&quot;yes&quot;/&quot;no&quot;</code>, ints parse numeric strings and clamp within min/max per <code>KeyMetadata</code>. <br>3. If parsing fails, they write a <code>ConfigTypeWarning</code> in telemetry and return <code>defaultValue</code>. <br>4. All getters include optional parameter <code>raiseIfMissing</code> in internal overload; when true, throw structured error. <br>Examples:<br>- <code>GetConfigBool(&quot;fuzzyProfileEnabled&quot;, False)</code> returns False if key missing.<br>- <code>GetConfigDouble(&quot;autoApplyThreshold&quot;, 0.88)</code> returns default if value invalid. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: SetConfigValue</strong><br>Signature: <code>SetConfigValue(key As String, value As Variant, changedBy As String, Optional reason As String) As Scripting.Dictionary</code>.<br>Purpose: admin-grade setter that validates and persists a change, writes <code>Macro_ChangeLog</code> entry, and optionally stages changes for approval if promotion required.<br>Behavior & safety flow:<br>1. Authenticate <code>changedBy</code> via <code>modUtilities.GetCurrentUserId()</code> and ensure <code>UserRoles</code> shows Admin if <code>KeyMetadata(key).requiresAdmin=True</code>. <br>2. Call <code>ValidateSingleKey(key, value)</code> to normalize and check bounds. <br>3. If invalid return <code>{IsSuccess:False,Errors:col}</code>. <br>4. If valid, write to <code>__Config</code> sheet using <code>WriteConfigSheet</code> (with backup snapshot <code>__Config_Backup_&lt;ts&gt;</code>), compute <code>beforeChecksum</code>, <code>afterChecksum</code> via <code>ComputeConfigChecksum</code>, and write <code>Macro_ChangeLog</code> record: <code>{changeId, key, beforeValue (redacted if sensitive), afterValue (redacted if sensitive), changedBy, reason, timestamp}</code>. <br>5. If <code>requiresApproval</code> metadata true for that key and <code>env=&quot;prod&quot;</code>, mark change <code>STAGED</code> and return <code>{IsSuccess:True,Status:&quot;STAGED&quot;,approvalTicketId:...}</code>; the change is not applied to active <code>LoadConfig(&quot;prod&quot;)</code> until <code>ApproveStage</code> called. <br>6. Return success dictionary with <code>IsSuccess</code> and audit metadata. <br>Edge cases: attempts by non-admin to change admin-only key returns <code>IsSuccess=False</code> with explicit <code>permissionDenied</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: ValidateConfig</strong><br>Signature: <code>ValidateConfig() As Scripting.Dictionary</code>.<br>Purpose: full-surface validation; used pre-run and by UI to ensure safety.<br>Checks performed (non-exhaustive):<br>1. Presence: required keys present (<code>userRoles</code>, <code>batchSize</code>, <code>autoApplyThreshold</code>, <code>reviewThreshold</code>). <br>2. Type and range: <code>0.5 &lt;= autoApplyThreshold &lt; 1.0</code>, <code>reviewThreshold &lt;= autoApplyThreshold</code>, <code>batchSize</code> > 0 and < <code>10000</code>, <code>gsTimeoutSec</code> reasonable > 1. <br>3. Logical constraints: <code>ReviewerThreshold &lt;= AutoApplyThreshold</code>; <code>dailyAutoApplyCapRows</code> must be integer >=0. <br>4. Security: <code>hashSalt</code> present if <code>externalScorerUrl</code> configured. <br>5. Connectivity check: optionally test <code>externalScorerUrl</code> endpoint with a lightweight HEAD/OPTIONS call (skipped if offline). <br>6. Warnings for marginal settings: extremely low <code>autoApplyThreshold</code> warns about false positives; extremely high <code>batchSize</code> warns about memory. <br>Return value: <code>{IsValid:Boolean, Errors:Collection, Warnings:Collection, Diagnostics:Dictionary}</code>. <br>Usage: Called by <code>modCoreEngine.ValidatePreRun</code> and by <code>BindConfigToUI</code> preview. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: PersistConfigSnapshot</strong><br>Signature: <code>PersistConfigSnapshot(runId As String, appliedBy As String, Optional notes As String) As String</code>.<br>Purpose: create an immutable per-run snapshot of effective configuration so runs are reproducible and audits can tie behavior to a snapshot.<br>Behavior & schema:<br>1. Read in-memory effective config (LoadConfig must have run). <br>2. Compute <code>snapshotId = &quot;cfg-&quot; &amp; runId &amp; &quot;-&quot; &amp; Format(NowUTC,&quot;yyyymmddhhmmss&quot;)</code>. <br>3. Compute <code>configChecksum = ComputeConfigChecksum(dictConfig)</code>. <br>4. Write a row to <code>__Run_Config</code> with columns: <code>snapshotId</code>, <code>runId</code>, <code>appliedBy</code>, <code>timestampUTC</code>, <code>codeVersion</code>, <code>configJSON</code> (pretty-printed), <code>configChecksum</code>, <code>notes</code>. <br>5. Return <code>snapshotId</code>; also write a brief <code>Audit_Log</code> run header referencing snapshot id (if called before run start, <code>modCoreEngine</code> records link). <br>Usage: <code>modCoreEngine</code> must call this before any stage that could produce deterministic outputs (matching, GS, commit). </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: ExportConfigToJSON</strong><br>Signature: <code>ExportConfigToJSON(path As String, Optional includeSecrets As Boolean = False) As Boolean</code>.<br>Purpose: create a stable JSON file for repo promotion, QA, or offline review.<br>Behavior:<br>1. Load effective config using <code>LoadConfig(currentEnv)</code> and flatten to deterministic ordering by keys sorted alphabetically. <br>2. Exclude sensitive keys by default. If <code>includeSecrets=True</code> require Admin and encrypt secrets using optional <code>modSignatures</code> helper or call external helper service to encrypt. <br>3. Produce manifest block including <code>exportedBy</code>, <code>timestampUTC</code>, <code>codeVersion</code>, and <code>checksum</code>. <br>4. Write JSON to <code>path</code> and return True on success. <br>Use case: commit JSON to repo as <code>config/prod/&lt;version&gt;.json</code> for CI promotion. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: ImportConfigFromJSON</strong><br>Signature: <code>ImportConfigFromJSON(path As String, appliedBy As String) As Scripting.Dictionary</code>.<br>Purpose: load config from repo or package and stage it for environment activation.<br>Behavior:<br>1. Parse JSON, validate shape against <code>KeyMetadata()</code>. <br>2. Call <code>ValidateConfig</code> on parsed content. <br>3. If <code>IsValid=True</code>, write to <code>__Config</code> as <code>STAGED</code> plus produce <code>importId</code>. <br>4. Return <code>{IsSuccess:Boolean, importId, Errors, Warnings, stagedKeys}</code>. <br>Activation: admin must <code>SetConfigValue</code> for each critical key or call <code>ActivateImportedConfig(importId, appliedBy)</code>, which writes to <code>__Config</code> and logs <code>Macro_ChangeLog</code>. <br>Safety: never auto-activate imported production config without explicit admin approval. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: PersistRuntimeOverrides</strong><br>Signature: <code>PersistRuntimeOverrides(runId As String, overrides As Scripting.Dictionary, appliedBy As String) As Scripting.Dictionary</code>.<br>Purpose: temporarily override config for a single run (e.g., increase <code>autoApplyThreshold</code> for a special run) while ensuring auditability and automatic expiry.<br>Behavior & constraints:<br>1. Validate each override key with <code>ValidateSingleKey</code>. <br>2. Persist overrides in <code>__Run_Config</code> under <code>overrides</code> node with expiry metadata: <code>validUntil</code> (ISO timestamp). <br>3. Require <code>appliedBy</code> and <code>rationale</code> fields; if override affects critical keys or monetary caps, require <code>appliedBy</code> to be <code>Admin</code> or require reviewer approval depending on <code>KeyMetadata</code>. <br>4. On <code>Runtime</code> start, <code>modCoreEngine</code> will merge overrides into effective config for that run. <br>5. Return <code>{IsSuccess, overriddenKeys, notes}</code>. <br>Reproducibility: overrides are part of run snapshot to permit exact replay. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: BindConfigToUI</strong><br>Signature: <code>BindConfigToUI(configSheet As Worksheet) As Boolean</code>.<br>Purpose: populate the admin configuration worksheet with grouped controls, data validation, and help text so non-developers can safely review and edit config.<br>Behavior & UI binding patterns:<br>1. Render groups: Matching, GoalSeek, Batch, Limits, Security, Telemetry. <br>2. For each key use <code>KeyMetadata()</code> to place appropriate control: boolean → checkbox cell, enumerated → data validation list, numeric → cell with min/max comments. <br>3. Lock admin-only cells via worksheet protection and only enable editing after <code>AdminUnlock</code> flow with password/prompt. <br>4. Provide <code>PreviewChanges</code> button that calls <code>ValidateConfig</code> and optionally calls <code>modFuzzyScores.ProfileFuzzyComparisons</code> to show estimated reviewer load for threshold changes. <br>5. UI access methods call <code>SetConfigValue</code> or stage changes for approval. <br>6. Provide visual diff when staged changes exist: highlight changed cells and show <code>Macro_ChangeLog</code> entries inline. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: ReloadConfigIfChanged</strong><br>Signature: <code>ReloadConfigIfChanged() As Boolean</code>.<br>Purpose: detect external edits (file or sheet) and refresh in-memory config cache to prevent stale reads.<br>Behavior:<br>1. Compute <code>currentChecksum = ComputeConfigChecksum</code> on <code>__Config</code>. <br>2. Compare to <code>cachedChecksum</code> stored in memory by <code>modConfig</code>; if different then reload and write telemetry <code>ConfigReload</code>. <br>3. If reload occurs while a run is active, return <code>ConflictWarning</code> and require <code>modCoreEngine</code> to decide whether to continue with cached snapshot or abort. <br>4. Optionally perform a <code>ValidateConfig</code> after reload and log warnings. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Function: GetAllKeys / KeyMetadata</strong><br>Signature: <code>GetAllKeys() As Collection</code> and <code>KeyMetadata(key As String) As Scripting.Dictionary</code>.<br>Purpose: provide canonical key list and metadata used by UI, validators, and CI gates.<br>Metadata fields for each key include: <code>type</code>, <code>default</code>, <code>min</code>, <code>max</code>, <code>description</code>, <code>uiControlType</code>, <code>requiresAdmin</code>, <code>sensitiveFlag</code>, <code>exampleValue</code>, <code>validateRegex</code> (if applicable), <code>promoteRequired</code> (if change requires CI gating). <br>Use cases: <code>modTestingHarness</code> uses <code>GetAllKeys()</code> to ensure test coverage of config-driven branches. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>ComputeConfigChecksum (helper)</strong><br>Signature: <code>ComputeConfigChecksum(dictConfig As Scripting.Dictionary) As String</code>.<br>Purpose: deterministic checksum for drift detection and snapshot integrity.<br>Behavior:<br>1. Flatten config to key-sorted canonical string: <code>key1=value1;key2=value2;...</code>. <br>2. Compute CRC32 or SHA1 (VBA implementation) to produce checksum string. <br>3. Use checksum on <code>__Run_Config</code> and in <code>Macro_ChangeLog</code> to record before/after states. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>ValidateSingleKey (helper)</strong><br>Signature: <code>ValidateSingleKey(key As String, value As Variant) As Scripting.Dictionary</code>.<br>Purpose: validate and normalize a single config key value.<br>Behavior:<br>1. Use <code>KeyMetadata</code> to determine expected type & min/max. <br>2. Cast and clamp numerical values, parse percent strings (e.g., <code>&quot;88%&quot;</code> → 0.88), accept boolean textual forms. <br>3. Check pattern via <code>validateRegex</code> if present. <br>4. Return <code>{IsValid:Boolean, NormalizedValue:Variant, ErrorMsg:String, WarningMsg:String}</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Governance flows & safe defaults</strong><br>1. Any change to <code>autoApplyThreshold</code>, <code>dailyAutoApplyCapAmount</code>, or <code>dailyAutoApplyCapRows</code> must be staged if environment=prod and require Admin approval. <br>2. Default safe values: <code>autoApplyThreshold=0.88</code>, <code>reviewThreshold=0.70</code>, <code>dailyAutoApplyCapRows=1000</code>, <code>dailyAutoApplyCapAmount=1000000.0</code>. <br>3. If any required key missing, <code>LoadConfig</code> injects default and writes a <code>ConfigFallback</code> warning into <code>Audit_Log</code>. <br>4. Changes to <code>fuzzyWeights</code> must be accompanied by <code>__Fuzzy_Tuning</code> recompute and <code>ProfileFuzzyComparisons</code> results attached to the <code>Macro_ChangeLog</code> entry. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>CI/CD & promotion integration</strong><br>1. <code>ExportConfigToJSON</code> produces artifact for repo; CI pipeline must run <code>ValidateConfig</code> and <code>modTestingHarness.RunRegressionSuite</code> after config change PRs. <br>2. For promotion: <code>dev -&gt; test -&gt; prod</code>, each environment import requires <code>ImportConfigFromJSON</code> and Admin activation with <code>appliedBy</code> recorded. <br>3. Config changes to critical keys require PR with <code>validationReport</code> attached showing expected reviewer load and precision/recall impact. <br>4. <code>configVersion</code> should track git commit hash; <code>modConfig</code> sets <code>configVersion</code> in snapshot automatically when <code>ExportConfigToJSON</code> called. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Security & secrets handling</strong><br>1. Sensitive keys have <code>sensitiveFlag=True</code> in <code>KeyMetadata</code>. These are stored in <code>__Secrets</code> and redacted in <code>Macro_ChangeLog</code> and exports unless <code>includeSecrets=True</code> and caller is Admin. <br>2. <code>SetConfigValue</code> for sensitive keys writes a <code>changeChecksum</code> instead of plaintext to <code>Macro_ChangeLog</code>. <br>3. When exporting with secrets, recommend encrypting file via OS-level utility; <code>modConfig</code> can optionally call a wrapper PowerShell script (packaged in deployment) to perform encryption — implementers must sign helper scripts. <br>4. Access control: Admin-only keys require UI two-person approval for production changes. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Telemetry & health metrics</strong><br>1. <code>modConfig</code> emits telemetry rows to <code>__Telemetry</code> on: <code>configLoad</code>, <code>configReload</code>, <code>configValidationSummary</code>, <code>configExport</code>, <code>configImport</code>, <code>configChange</code>. <br>2. Telemetry fields: <code>timestampUTC</code>, <code>eventType</code>, <code>userId</code>, <code>env</code>, <code>errorsCount</code>, <code>warningsCount</code>, <code>checksumBefore</code>, <code>checksumAfter</code>. <br>3. Telemetry used by operations dashboards to compute <code>ConfigChangeRate</code>, <code>AvgAutoApplyThreshold</code>, <code>PctRunsWithOverride</code>, and <code>ConfigValidationFailures</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Power Query (PQ) conceptual integration</strong><br>1. Export <code>__Run_Config</code> snapshots as flattened rows: <code>snapshotId, runId, configKey, configValue, configChecksum, codeVersion, timestampUTC</code>. <br>2. PQ steps to ingest snapshots: <code>File -&gt; CSV/JSON -&gt; Json.Document</code> to parse <code>configValue</code> when JSON typed, <code>Expand</code> -> <code>Change Type</code> -> <code>Pivot</code> to create a wide table keyed by <code>runId</code> and with config columns. <br>3. Build <code>ConfigDrift</code> table by merging consecutive snapshots and using <code>Table.Difference</code> style logic; create <code>ConfigDelta</code> column containing changed keys. <br>4. Use PQ to feed BI and DAX measures for trend analysis. <br>Example PQ formula narrative: refresh config snapshot CSV, parse JSON columns, expand keys, group by <code>snapshotId</code>, aggregate list of changed keys into <code>ConfigDelta</code> for each snapshot. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Conceptual DAX measures (monitoring)</strong><br>1. <code>ConfigsChanged = DISTINCTCOUNT(&#x27;ConfigSnapshots&#x27;[snapshotId])</code>.<br>2. <code>AvgAutoApplyThreshold = AVERAGE(&#x27;ConfigSnapshots&#x27;[autoApplyThreshold])</code>.<br>3. <code>ConfigDriftCount = COUNTROWS(FILTER(&#x27;ConfigDiff&#x27;,&#x27;ConfigDiff&#x27;[changed]=TRUE))</code>.<br>4. <code>PctRunsWithOverride = DIVIDE(CALCULATE(COUNTROWS(Runs), Runs[hasOverride]=TRUE), COUNTROWS(Runs))</code>.<br>Use these in the operations dashboard to correlate config changes with run outcomes and incidents. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Examples — narratives & sample flows</strong><br>Example 1 — Safe production change:<br>1. Operator proposes change in <code>modConfigUI</code> to <code>autoApplyThreshold</code> from 0.88 -> 0.85 and clicks <code>Stage</code>. <br>2. <code>SetConfigValue</code> stages change: writes to <code>__Config</code> as <code>STAGED</code>, writes <code>Macro_ChangeLog</code> entry <code>STAGED</code> with <code>changeId</code>. <br>3. Admin reviews, runs <code>PreviewChanges</code> which calls <code>ProfileFuzzyComparisons</code> on last 30 days of confirmed matches and shows expected precision drop. <br>4. Admin rejects or approves; if approved <code>ActivateStagedConfig(changeId,adminId)</code> writes final <code>__Config</code> and calls <code>PersistConfigSnapshot</code> with <code>appliedBy=admin</code>. <br>5. <code>modCoreEngine</code> picks up snapshot for next run. <br>Example 2 — Emergency stop:<br>1. On suspect behavior, Admin sets <code>killSwitchAutoApply=true</code> via <code>SetConfigValue</code> with <code>emergency=true</code> and two-person approval. <br>2. <code>PersistConfigSnapshot</code> records emergency snapshot and <code>modCoreEngine</code> applies new effective config causing all auto-applies to pause (autoApplyThreshold effectively 1.0). <br>3. Incident logged and downstream teams notified. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Testing & QA (coverage)</strong><br>Unit tests to implement in <code>modTestingHarness</code> for <code>modConfig</code>:<br>1. <code>LoadConfig</code> loads valid JSON and returns expected typed values; missing keys injected with defaults. <br>2. <code>ValidateSingleKey</code> parses percent strings (<code>&quot;88%&quot;</code>) and rejects non-numeric values. <br>3. <code>SetConfigValue</code> denies non-admin to change admin keys and correctly stages/activates changes. <br>4. <code>PersistConfigSnapshot</code> writes snapshot row and snapshotId reproducible. <br>5. <code>ImportConfigFromJSON</code> rejects invalid JSON and validates missing required keys. <br>Integration tests:<br>1. <code>modCoreEngine</code> pre-run must detect critical config validation failure and abort with structured <code>validationErrors</code>. <br>2. Promotion pipeline emulation: export JSON, import into <code>test</code> env, validate, stage, promote to <code>prod</code> requiring admin activation. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Edge cases & mitigation</strong><br>1. Partial sheet corruption — if <code>__Config</code> contains malformed rows use <code>ReadConfigSheet</code> to ignore invalid lines, write <code>ConfigParseWarning</code> and fallback to defaults. <br>2. Simultaneous edits — use <code>AcquireConfigLock</code> (sheet marker) to serialize writes; <code>ReloadConfigIfChanged</code> detects drift and prevents writes if concurrent change observed. <br>3. Deleted secrets — when <code>hashSalt</code> missing but <code>externalScorerUrl</code> present, <code>ValidateConfig</code> flags critical error and prevents prod runs until resolved. <br>4. Massive change sets (hundreds keys) — enforce <code>batchSize</code> limit for UI edits and require CI gating for bulk changes. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Operational runbook snippets (concise steps)</strong><br>1. Pre-run: click <code>Preview</code> → <code>ValidateConfig</code> must return <code>IsValid=True</code> and no critical errors; call <code>PersistConfigSnapshot(runId, operator)</code> before stage. <br>2. Post-run: review <code>ConfigValidationSummary</code> in <code>__Telemetry</code> and escalate any warnings that triggered during run. <br>3. Changing config in prod: Stage -> AdminReview -> Activate -> Snapshot -> Macro_ChangeLog entry created. <br>4. Emergency: toggle <code>killSwitchAutoApply</code>, persist snapshot, notify governance, open incident ticket. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Troubleshooting quick guide</strong><br>1. Unexpected reviewer load spike after config change: check recent snapshots and <code>Macro_ChangeLog</code> for <code>autoApplyThreshold</code> changes; run <code>ProfileFuzzyComparisons</code> to verify. <br>2. Runs failing pre-run validation: get <code>ValidateConfig</code> errors and fix missing keys or invalid ranges. <br>3. External service failures: check <code>externalScorerUrl</code> string, <code>externalScorerHealth</code> telemetry, and <code>hashSalt</code> presence. <br>4. Secrets not applied: ensure <code>__Secrets</code> sheet unlocked and <code>LoadConfig</code> run as Admin to include secrets. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Acceptance criteria for modConfig delivery</strong><br>1. All typed accessors correctly convert and clamp values; unit tests pass. <br>2. <code>ValidateConfig</code> detects configured invalid states and blocks prod runs. <br>3. <code>PersistConfigSnapshot</code> produces immutable JSON snapshots and snapshots are ingestible by PQ. <br>4. Admin UI supports staged apply and displays diffs; change actions require Admin approval for critical keys. <br>5. Export/Import JSON works reproducibly and CI gating triggers regression tests when critical keys change. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Example JSON export (canonical)</strong><br><code>{ &quot;env&quot;:&quot;prod&quot;, &quot;snapshotId&quot;:&quot;cfg-20260219-0001&quot;, &quot;timestamp&quot;:&quot;2026-02-19T10:00:00Z&quot;, &quot;codeVersion&quot;:&quot;commit-sha&quot;, &quot;config&quot;: { &quot;batchSize&quot;:1000, &quot;autoApplyThreshold&quot;:0.88, &quot;reviewThreshold&quot;:0.70, &quot;dailyAutoApplyCapRows&quot;:1000, &quot;dailyAutoApplyCapAmount&quot;:1000000.0, &quot;gsTimeoutSec&quot;:30, &quot;externalScorerUrl&quot;:&quot;https://scorer.internal/api/score&quot;, &quot;userRoles&quot;:{&quot;operator&quot;:[&quot;alice&quot;],&quot;reviewer&quot;:[&quot;bob&quot;],&quot;admin&quot;:[&quot;carol&quot;]} }, &quot;metadata&quot;: { &quot;appliedBy&quot;:&quot;carol&quot;, &quot;checksum&quot;:&quot;sha1:...&quot; } }</code><br>Note: sensitive fields omitted unless <code>includeSecrets=True</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Governance checklist (before enabling auto-apply)</strong><br>1. Confirm <code>autoApplyThreshold</code> chosen by <code>RecommendThresholds</code> from historical confirmed matches. <br>2. Verify <code>dailyAutoApplyCapRows</code> and <code>dailyAutoApplyCapAmount</code> defined and tested. <br>3. Confirm <code>userRoles</code> mapping correct and Admin accounts valid. <br>4. Ensure <code>PersistConfigSnapshot</code> created and linked in <code>Macro_ChangeLog</code>. <br>5. Ensure regression suite passed for golden dataset with new config. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Developer notes & implementation heuristics</strong><br>1. Store <code>KeyMetadata</code> as a two-column table in <code>__Config</code> with JSON in a metadata column to make keys self-descriptive. <br>2. Use <code>Scripting.Dictionary</code> consistently for in-memory config to allow case-insensitive keys. <br>3. Always convert numeric strings to <code>Double</code> then cast to <code>Long</code> for ints to avoid type mismatch. <br>4. Keep <code>ComputeConfigChecksum</code> deterministic by sorting keys and serializing to UTF-8 normalized forms before hashing. <br>5. When writing config sheet always create <code>__Config_Backup_&lt;ts&gt;</code> to facilitate manual recovery. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Conceptual PQ & DAX (practical recipes)</strong><br>1. PQ recipe: import <code>__Run_Config</code> snapshot CSV, <code>Json.Document</code> on <code>config</code> column, <code>Record.ToTable</code> to flatten, <code>Pivot</code> to create wide config table keyed by <code>snapshotId</code>, <code>Expand</code> to convert nested objects. <br>2. Use PQ to compute <code>ConfigDelta</code> by merging snapshots on <code>snapshotId</code> order and calculating <code>List.Difference</code>. <br>3. DAX recipe: build a small model table <code>ConfigSnapshots</code> and compute <code>ConfigChangeRate</code> measures as shown earlier to monitor configuration changes over time. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Long-term maintainability & evolution guidance</strong><br>1. Version <code>KeyMetadata()</code> and keep changelog: any change to key semantics must increment <code>configSchemaVersion</code> and include migration steps. <br>2. When adjusting defaults that affect behavior (e.g., <code>autoApplyThreshold</code>), run A/B tests on a shadow dataset and capture results in <code>__Fuzzy_Tuning</code> and in the release notes. <br>3. For large orgs consider centralizing <code>config</code> in an external service and let <code>modConfig</code> act as a read-only cache, but keep workbook-level overrides for offline operations. <br>4. Document every key in an internal developer doc with examples and safe ranges. </td></tr><tr><td data-label="Per-function technical breakdown — modConfig (VBA)"> <strong>Final summary (practical priorities for implementers)</strong><br>1. Implement typed getters and <code>ValidateConfig</code> first to prevent unsafe runs. <br>2. Implement <code>PersistConfigSnapshot</code> and ensure <code>modCoreEngine</code> calls it before processing. <br>3. Build admin UI for staged changes and two-step approval. <br>4. Add CI checks and <code>ExportConfigToJSON</code> for promotion pipelines. <br>5. Treat secrets carefully and implement <code>__Secrets</code> guarded access. </td></tr></tbody></table></div><div class="row-count">Rows: 37</div></div><div class="table-caption" id="Table4" data-table="Docu_0203_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modMappingStore (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modMappingStore (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Module purpose (executive summary)</strong><br><code>modMappingStore</code> is the authoritative mapping and index layer for UpdateHR+. It is responsible for loading the canonical master employee dataset, building and maintaining the in-memory indexes used by matching and scoring, managing alias lifecycle and legacy crosswalks, detecting duplicates, and providing deterministic snapshots for replay and migration. The module exposes read-optimized APIs for <code>modMatchingEngine</code> and admin APIs for safe mapping mutations (with full audit). It prioritises determinism, minimal sheet I/O in hot paths, clear audit trails for every mutation, and graceful behaviour for large master sizes. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Design principles & operational constraints</strong><br>1. Single source of truth: all mapping changes (aliases, master updates, legacy crosswalks) must flow through <code>modMappingStore</code> to maintain consistent provenance. <br>2. Load-once-per-run: call <code>LoadMasterStore</code> at run start to build in-memory indexes; avoid reloading mid-run unless explicitly requested and approved. <br>3. Deterministic canonicalisation: use the same <code>CleanName</code> / <code>NGramFingerprint</code> / <code>PhoneticEncode</code> primitives as other modules to guarantee identical keys. <br>4. Memory hygiene: for large masters prefer arrays + dictionaries (not nested Collections) to reduce COM overhead. <br>5. Audit every mutation: alias and master changes append immutable <code>Alias_Log</code> / <code>Master_Log</code> rows containing before/after JSON, user, timestamp, and rationale. <br>6. Idempotent upserts: provide deterministic <code>aliasId</code>/<code>mappingKey</code> generation so repeated calls do not create duplicates. <br>7. Config-driven safety: honour <code>modConfig</code> keys like <code>AllowHotReload</code>, <code>StrictMasterLoad</code>, and retention/archival rules. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Public API summary (functions exposed)</strong><br>1. <code>LoadMasterStore(Optional masterSheetName As String = &quot;HRMaster&quot;) As Boolean</code> — load master sheet into memory and build indexes. <br>2. <code>ReloadMasterIfStale(thresholdMinutes As Long) As Boolean</code> — reload when stale, with safe gating. <br>3. <code>GetCandidatesByCleanName(cleanName As String) As Collection</code> — exact-name lookup. <br>4. <code>GetCandidatesByToken(token As String) As Collection</code> — token inverted-index lookup. <br>5. <code>GetCandidatesByFingerprint(fingerprint As String) As Collection</code> — n-gram fingerprint lookup. <br>6. <code>ResolveAlias(aliasName As String) As String</code> — returns targetEmployeeId or special status. <br>7. <code>UpsertAlias(aliasName As String, targetEmployeeId As String, createdBy As String, Optional rationale As String) As String</code> — create/update alias. <br>8. <code>RemoveAlias(aliasId As String, removedBy As String, Optional rationale As String) As Boolean</code> — deactivate or delete alias. <br>9. <code>FindPotentialDuplicates(Optional thresholds As Scripting.Dictionary) As Collection</code> — duplicate-group detector. <br>10. <code>ExportMappingSnapshot(destPath As String, format As String) As Boolean</code> — canonical export (CSV/NDJSON/SQL). <br>11. <code>UpsertMasterRecord(masterRec As Scripting.Dictionary, updatedBy As String, Optional mergePolicy As String = &quot;ask&quot;) As String</code> — admin insert/update. <br>12. <code>GetMasterSnapshotForReplay(runId As String) As Collection</code> — return mapping snapshot used for deterministic replay. <br>13. <code>HarmonizeLegacyIds(legacyPairsRange As Range) As Long</code> — load legacy id crosswalks. <br>14. <code>QueryMasterByMetadata(filters As Scripting.Dictionary, Optional sortBy As String) As Collection</code> — flexible master queries. <br>15. <code>DumpIndexStats(destSheet As Worksheet)</code>, <code>RebuildIndexes()</code>, <code>PruneAliases(olderThanDays As Long)</code>, <code>RepairLegacyConflicts()</code> — diagnostics and maintenance helpers. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: LoadMasterStore</strong> — detailed breakdown<br><strong>Purpose:</strong> read the canonical <code>HRMaster</code> sheet and build in-memory, read-optimised indexes for fast lookups.<br><strong>Signature:</strong> <code>LoadMasterStore(Optional masterSheetName As String = &quot;HRMaster&quot;) As Boolean</code>.<br><strong>Inputs:</strong> <code>masterSheetName</code> defaults to <code>HRMaster</code> and must contain a header row with canonical columns (employeeId, fullName, orgUnit, costCenter, hireDate, activeFlag, legacyIds, aliases).<br><strong>Outputs / Side-effects:</strong> returns Boolean success; populates module-level dictionaries: <code>dictByEmployeeId</code>, <code>dictByCleanName</code>, <code>dictTokenIndex</code>, <code>dictFingerprintIndex</code>, <code>dictLegacyIdIndex</code>, <code>dictOrgIndex</code>, <code>dictCostCenterIndex</code>; writes <code>__Master_LastLoaded</code> metadata cell and appends <code>MasterLoad</code> diagnostic entry.<br><strong>Process steps:</strong><br>1. Validate sheet exists and named range integrity; if missing fail with <code>ERR_MASTER_NOT_FOUND</code>. <br>2. Bulk-read sheet into a variant 2D array in a single call to avoid COM overhead. <br>3. For each row perform canonicalisation: call <code>modMatchingEngine.CleanName</code> to produce <code>cleanName</code>, token list and <code>tokenKey</code>. <br>4. Produce n-gram fingerprint via <code>modFuzzyScores.NGramFingerprint</code> and phonetic code via <code>modFuzzyScores.PhoneticEncode</code>. <br>5. Build per-row <code>masterRecord</code> object (Scripting.Dictionary) with canonical fields and derived fields. <br>6. Insert <code>masterRecord</code> into <code>dictByEmployeeId(employeeId)</code> and into inverted indexes: add <code>employeeId</code> to <code>dictByCleanName(cleanName)</code>, append to <code>dictTokenIndex(token)</code> for each token, add to <code>dictFingerprintIndex(fingerprint)</code>. <br>7. Build <code>dictLegacyIdIndex</code> mapping each <code>legacyId</code> → employeeId (with conflict logging). <br>8. Summarise load metrics (rowCount, duplicateEmployeeIds, aliasCount, indexSizes) and write to <code>__Diagnostics</code>. <br><strong>Performance notes:</strong><br>- For large master (>50k) use scalable patterns: chunk reading, pre-allocate arrays, avoid Collections in index value lists (store as simple dynamic arrays or CSV strings for value lists and convert to Collection only when returning). <br><strong>Error handling:</strong><br>- If duplicate <code>employeeId</code> found: depending on <code>modConfig.StrictMasterLoad</code> either abort or log <code>DuplicateEmployeeId</code> and continue with <code>WARN</code>. <br><strong>Audit:</strong> write a <code>MasterLoad</code> entry to <code>__Diagnostics</code> and, if requested, append a <code>MappingSnapshot</code> export. <br><strong>Test cases:</strong><br>- Golden sample load must produce exact counts and index sizes recorded in a baseline file. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: ReloadMasterIfStale</strong> — detailed breakdown<br><strong>Purpose:</strong> refresh in-memory indexes if source has changed or is stale; safe gating prevents mid-run inconsistencies.<br><strong>Signature:</strong> <code>ReloadMasterIfStale(thresholdMinutes As Long) As Boolean</code>.<br><strong>Behavior:</strong><br>1. Read <code>__Master_LastLoaded</code> timestamp; compute age minutes. <br>2. If age > <code>thresholdMinutes</code> then: <br>&nbsp;&nbsp;&nbsp;&nbsp;a) If <code>modCoreEngine</code> reports active run in progress and <code>modConfig.AllowHotReload=False</code>, schedule reload for next run and return False with <code>scheduled=true</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Otherwise call <code>LoadMasterStore</code> and compute <code>diffSummary = {added, removed, changed}</code>; write <code>MasterReload</code> audit entry and <code>__Master_ChangeLog</code>. <br>3. If reload fails, restore previous in-memory snapshot and log failure with <code>MasterReloadFailed</code> diagnostics. <br><strong>Use cases:</strong> automated daily source syncs, admin-initiated refreshes after HR feed updates. <br><strong>Edge cases:</strong> unstable master sheet (partial updates) should trigger rollback and alert rather than overwrite in-memory indexes. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: GetCandidatesByCleanName</strong> — detailed breakdown<br><strong>Purpose:</strong> O(1)-ish exact lookup of candidate list by canonical clean name.<br><strong>Signature:</strong> <code>GetCandidatesByCleanName(cleanName As String) As Collection</code>.<br><strong>Behavior & outputs:</strong><br>1. Normalize <code>cleanName</code> via <code>modMatchingEngine.CleanName</code> to ensure consistent keying. <br>2. Lookup <code>dictByCleanName(cleanName)</code> and return a shallow copy Collection of <code>masterRecord</code> dictionaries. <br>3. If not found return empty Collection. <br><strong>Performance note:</strong> cheap dictionary lookup; ideal for Stage A exact matching. <br><strong>Audit linkage:</strong> callers should record which rule matched <code>A_EXACT</code> in <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: GetCandidatesByToken / GetCandidatesByFingerprint</strong> — detailed breakdown<br><strong>Purpose:</strong> fast prefiltering using token inverted-index and n-gram fingerprint index to build candidate superset.<br><strong>Signatures:</strong> <code>GetCandidatesByToken(token As String) As Collection</code>, <code>GetCandidatesByFingerprint(fingerprint As String) As Collection</code>.<br><strong>Behavior:</strong><br>1. Token lookup: return set union of candidate lists for the input tokens. Implement union via hash set (dictionary of keys) to prevent duplicates. <br>2. Fingerprint lookup: return candidates whose fingerprint exactly matches input fingerprint; used for corporate names and short phrases where fingerprint collisions are low. <br>3. Return lists of employeeIds (strings) or masterRecord Collections depending on <code>options(&quot;returnRecords&quot;)</code>. <br><strong>Optimisations:</strong> for large index key lists store candidate arrays rather than Collections to reduce overhead; convert to Collection only when required by caller. <br><strong>Examples:</strong> token "smith" might return 500 employeeIds for a global org; fingerprint <code>acme|international|pty</code> often returns 1–3 candidates. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: ResolveAlias</strong> — detailed breakdown<br><strong>Purpose:</strong> map an alias name to target employee id using alias store with deterministic fallback logic.<br><strong>Signature:</strong> <code>ResolveAlias(aliasName As String) As String</code>.<br><strong>Behavior & return semantics:</strong><br>1. Canonicalise <code>aliasName</code> with <code>CleanName</code>. <br>2. Lookup <code>dictAliasByCleanName(cleanAlias)</code>.<br>3. If single mapping found return <code>targetEmployeeId</code>. <br>4. If multiple targets found return special status <code>AMBIGUOUS_ALIAS</code> (empty string returned plus write <code>AliasAmbiguous</code> to <code>Alias_Log</code> for UI). <br>5. If no direct alias found and <code>modConfig.AliasPhoneticFallback=True</code> attempt phonetic fallback via <code>dictAliasPhoneticIndex</code>. <br>6. If nothing found return empty string (meaning: no alias resolved). <br><strong>Audit integration:</strong> include <code>aliasResolutionId</code> in <code>Audit_Log</code> entries where alias was used for auto-apply to preserve provenance. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: UpsertAlias</strong> — detailed breakdown<br><strong>Purpose:</strong> create or update an alias mapping with full governance controls and audit trail.<br><strong>Signature:</strong> <code>UpsertAlias(aliasName As String, targetEmployeeId As String, createdBy As String, Optional rationale As String) As String</code>.<br><strong>Behavior & steps:</strong><br>1. Canonicalise alias; validate <code>targetEmployeeId</code> exists in <code>dictByEmployeeId</code>; if not exist return <code>ERR_TARGET_NOT_FOUND</code>. <br>2. Compute deterministic <code>aliasId</code> (e.g., GUID derived from <code>aliasClean</code> + <code>targetEmployeeId</code> or salted hash) to ensure idempotency. <br>3. If alias exists and same target: update <code>modifiedBy</code>, <code>modifiedAt</code>, append <code>Alias_Log</code> action <code>UPDATE</code> and return <code>aliasId</code>. <br>4. If exists and different target: create <code>Alias_Conflict</code> record and either raise <code>CONFLICT</code> for reviewer resolution or, if <code>createdBy</code> has admin privileges and <code>force=true</code>, overwrite and log <code>FORCE_UPDATE</code>. <br>5. On insert: write <code>AliasStore</code> sheet new row, update <code>dictAliasByCleanName</code>, update <code>dictAliasPhoneticIndex</code> and append <code>Alias_Log</code> with <code>INSERT</code>. <br>6. If alias matches many historical occurrences (exceeds <code>modConfig.AutoAliasLimit</code>), mark for reviewer confirmation before allowing auto-apply on historical data.<br><strong>Governance & policy:</strong> admin-only option to bypass conflict checks must be logged; provide UI hook to generate <code>AliasRequest</code> for human approval when needed. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: RemoveAlias</strong> — detailed breakdown<br><strong>Purpose:</strong> deactivate or delete alias with safety checks and audit trail.<br><strong>Signature:</strong> <code>RemoveAlias(aliasId As String, removedBy As String, Optional rationale As String, Optional hardDelete As Boolean = False) As Boolean</code>.<br><strong>Behavior & safeguards:</strong><br>1. Validate aliasId exists. <br>2. If alias last-used within <code>modConfig.AliasProtectionWindowDays</code>, require <code>adminOverride=True</code> to remove; otherwise continue. <br>3. Mark alias as <code>inactive=true</code> in <code>AliasStore</code> and in-memory <code>dictAliasByCleanName</code>; write <code>Alias_Log</code> entry with <code>action=DEACTIVATE</code>. <br>4. If <code>hardDelete=True</code> and retention policy allows, physically delete alias row and append <code>Alias_Log</code> with <code>action=DELETE</code> and retention manifest. <br>5. Return True on success. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: FindPotentialDuplicates</strong> — detailed breakdown<br><strong>Purpose:</strong> detect candidate duplicate groups in master using multi-stage clustering so reviewers can merge or clean master records.<br><strong>Signature:</strong> <code>FindPotentialDuplicates(Optional thresholds As Scripting.Dictionary) As Collection</code>.<br><strong>Default thresholds:</strong> if unspecified, <code>thresholds(&quot;tokenOverlapMin&quot;)=0.6</code>, <code>thresholds(&quot;combinedMin&quot;)=0.75</code>, <code>thresholds(&quot;blockSizeMax&quot;)=200</code>.<br><strong>Algorithm (multi-stage):</strong><br>1. <strong>Block</strong> by <code>tokenKey</code> and <code>fingerprint</code> to create small candidate groups to avoid O(n^2). <br>2. <strong>Within block</strong> compute cheap features (tokenOverlap, trigramJaccard) and shortlist pairs that exceed <code>tokenOverlapMin</code>. <br>3. <strong>For shortlisted pairs</strong> compute <code>NormalizedFuzzyScore</code> and mark pairs with <code>combined &gt;= combinedMin</code>. <br>4. <strong>Cluster</strong> transitive pairs into groups using union-find or simple graph traversal. <br>5. <strong>Summarise</strong> each group with <code>members[]</code>, <code>avgScore</code>, <code>maxScore</code>, <code>commonTokens</code>, <code>recommendedAction</code> (<code>MERGE_CANDIDATE</code>, <code>REVIEW</code>, <code>IGNORE</code>). <br>6. <strong>Return</strong> collection of group dictionaries for UI review. <br><strong>Outputs used by UI:</strong> <code>frmReviewerUI</code> displays groups with example postings and suggested merge actions. <br><strong>Performance notes:</strong> use size-limited blocks and parallel offline processing (scheduled task) for large masters to avoid run-time impact. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: ExportMappingSnapshot</strong> — detailed breakdown<br><strong>Purpose:</strong> generate canonical, reproducible exports of the mapping store for migration, backup, or ML training ingestion.<br><strong>Signature:</strong> <code>ExportMappingSnapshot(destPath As String, format As String) As Boolean</code> where <code>format</code> ∈ {"CSV","NDJSON","SQL"}.<br><strong>Export contract & steps:</strong><br>1. Sort masterRecords deterministically by <code>employeeId</code> or specified <code>sortKey</code> to ensure stable exports. <br>2. For NDJSON: emit one JSON object per line with stable property ordering: <code>employeeId</code>, <code>fullName</code>, <code>cleanName</code>, <code>tokenKey</code>, <code>fingerprint</code>, <code>phoneticCode</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>hireDate</code>, <code>activeFlag</code>, <code>aliases[]</code>, <code>legacyIds[]</code>, <code>otherMetadata</code>. <br>3. For CSV: flatten <code>aliases</code> and <code>legacyIds</code> as JSON strings inside columns or explode to a secondary alias table if <code>explodeAliases=True</code>. <br>4. Compute file checksum (prefer SHA256 via external helper if available; otherwise use robust CRC32 with manifest comment) and write <code>manifest.json</code> containing <code>exportTimeUtc</code>, <code>rowCount</code>, <code>checksum</code>, <code>codeVersion</code>, <code>configSnapshot</code>. <br>5. Append <code>MappingExport</code> audit event referencing <code>manifest</code>. <br><strong>Use cases:</strong> DB ingest, analytics, hand-off to data teams, or submission to ML pipelines. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: UpsertMasterRecord (admin)</strong> — detailed breakdown<br><strong>Purpose:</strong> controlled insert/update of master rows with schema validation, optional merge logic, and audit trail.<br><strong>Signature:</strong> <code>UpsertMasterRecord(masterRec As Scripting.Dictionary, updatedBy As String, Optional mergePolicy As String = &quot;ask&quot;) As String</code>.<br><strong>Validation & flow:</strong><br>1. Schema validation: require <code>employeeId</code>, <code>fullName</code>; optional but recommended <code>orgUnit</code>, <code>costCenter</code>, <code>hireDate</code>. <br>2. If <code>employeeId</code> exists: compute <code>diff</code> between <code>before</code> and <code>after</code> fields and if changes non-sensitive apply inline update and append <code>Master_Log</code> with <code>action=UPDATE</code>. <br>3. If <code>employeeId</code> does not exist: if <code>mergePolicy=&quot;find&quot;</code> attempt to find matching existing record via <code>FindPotentialDuplicates</code> and either merge (if deterministic) or ask reviewer. <br>4. On <code>merge</code>, create <code>mergePlan</code> (move postings, alias consolidation) and log <code>Master_Log</code> entry with <code>action=MERGE</code>. <br>5. After successful insert/update, update in-memory indexes (<code>dictByEmployeeId</code>, <code>dictByCleanName</code>, token/fingerprint indexes) and persist to <code>HRMaster</code> sheet per admin policy (immediate write or batched sync). <br>6. Return <code>employeeId</code> or <code>newEmployeeId</code>. <br><strong>Governance:</strong> admin-only function; every call must be audited and produce <code>Macro_ChangeLog</code> entry for release traceability. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: GetMasterSnapshotForReplay</strong> — detailed breakdown<br><strong>Purpose:</strong> provide the exact master mapping context used during a historical run to allow deterministic replay and forensic analysis.<br><strong>Signature:</strong> <code>GetMasterSnapshotForReplay(runId As String) As Collection</code>.<br><strong>Behavior:</strong><br>1. If <code>__Master_Snapshots</code> contains snapshot keyed by <code>runId</code>, load and return it. <br>2. Else take stable shallow copy of current <code>dictByEmployeeId</code> and persist to <code>__Master_Snapshots</code> with <code>snapshotId=runId</code> and <code>snapshotMeta</code> (loadTimeUtc, codeVersion, configSnapshot). <br>3. Return the snapshot collection to caller. <br><strong>Use-case:</strong> <code>modBatchUtilities.ReplayRun</code> uses this to ensure matching results are reproduced identically when <code>codeVersion</code> and <code>configSnapshot</code> match original run. <br><strong>Audit:</strong> link <code>mappingSnapshotId</code> into <code>Audit_Log</code> rows. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: HarmonizeLegacyIds</strong> — detailed breakdown<br><strong>Purpose:</strong> ingest legacy system id mapping pairs and populate <code>dictLegacyIdIndex</code> for crosswalk lookups when incoming postings include legacy ids.<br><strong>Signature:</strong> <code>HarmonizeLegacyIds(legacyPairsRange As Range) As Long</code>.<br><strong>Process:</strong><br>1. Read <code>legacyPairsRange</code> with columns: <code>legacySystem</code>, <code>legacyId</code>, <code>employeeId</code>. <br>2. Validate <code>employeeId</code> exists; if not, record <code>LegacyHarmonizeError</code> for manual resolution. <br>3. Insert mapping in <code>dictLegacyIdIndex(legacySystem &amp; &quot;|&quot; &amp; legacyId) = employeeId</code> and write rows to <code>LegacyCrosswalk</code> sheet with audit. <br>4. Return count of successful pairs applied. <br><strong>Edge handling:</strong> support many-to-one mapping; if a <code>legacyId</code> maps to multiple <code>employeeId</code>, mark conflict and stop automated harmonization for that id until reviewed. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Function: QueryMasterByMetadata</strong> — detailed breakdown<br><strong>Purpose:</strong> flexible queries for UI and diagnostics to select master records by metadata filters.<br><strong>Signature:</strong> <code>QueryMasterByMetadata(filters As Scripting.Dictionary, Optional sortBy As String = &quot;employeeId&quot;) As Collection</code>.<br><strong>Supported filters:</strong> <code>orgUnit</code>, <code>costCenter</code>, <code>activeFlag</code>, <code>hireDateFrom</code>, <code>hireDateTo</code>, <code>textSearch</code> (applies to <code>fullName</code>/<code>cleanName</code>), <code>hasAliases</code>(Boolean).<br><strong>Behavior:</strong><br>1. Use pre-built index dicts like <code>dictOrgIndex</code> and <code>dictCostCenterIndex</code> when filters align to reduce scan cost. <br>2. For textSearch fallback to iterating <code>dictByEmployeeId</code> but use in-memory string search on <code>cleanName</code> to keep consistent canonical matching. <br>3. Return collection of <code>masterRecord</code> dictionaries sorted by <code>sortBy</code>. <br><strong>Use-case:</strong> UI filters in <code>frmReviewerUI</code> and admin reports. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Diagnostics & maintenance helpers (detailed)</strong><br>1. <code>DumpIndexStats(destSheet As Worksheet)</code> — write index sizes (token cardinality, fingerprint frequencies, alias counts), top-N tokens by frequency, top-N fingerprints with counts, top ambiguous aliases to <code>destSheet</code> for analyst review. <br>2. <code>RebuildIndexes()</code> — rebuild token and fingerprint indexes from current <code>dictByEmployeeId</code>; used after manual sheet repairs. Append <code>IndexRebuild</code> log entry. <br>3. <code>PruneAliases(olderThanDays As Long)</code> — mark aliases inactive older than specified days, move to <code>AliasArchive</code>, and append <code>Alias_Log</code> prune entries. <br>4. <code>RepairLegacyConflicts()</code> — generate <code>LegacyConflictReport</code> listing legacy ids with multiple employeeId mappings and optionally create tasks for manual resolution. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Power Query (PQ) conceptual integration guidance</strong><br>1. <strong>MappingSnapshot ingestion:</strong> export <code>MappingSnapshot.ndjson</code> and load in PQ using <code>Json.Document</code>. Convert nested alias arrays into a separate <code>MappingAlias</code> table via <code>Table.ExpandRecordColumn</code> and <code>Table.ExpandListColumn</code>. <br>2. <strong>Token & fingerprint verification in PQ:</strong> re-compute <code>tokenKey</code> and <code>trigrams</code> as a cross-check; recommended PQ steps: <code>Text.Lower</code>, <code>RemovePunctuation</code> (Text.Select), <code>Split</code> on whitespace, then use <code>List.Transform</code> to build trigrams by <code>Text.Range</code>. <br>3. <strong>Master diff PQ:</strong> load two snapshots and <code>Merge Queries</code> by <code>employeeId</code> to compute <code>Added</code>, <code>Removed</code>, and <code>Changed</code> master rows. <br>4. <strong>Alias audit PQ:</strong> parse <code>Alias_Log</code> NDJSON and produce a timeline visual of alias changes for compliance review. <br>Implementation note: PQ transforms should be deterministic and include <code>Sort</code> steps to ensure stable outputs for CI golden tests. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Conceptual DAX measures for governance & BI</strong><br>1. <code>TotalAliases = COUNTROWS(AliasStore)</code>.<br>2. <code>AmbiguousAliases = COUNTROWS(FILTER(AliasStore, AliasStore[targetCount]&gt;1))</code>.<br>3. <code>DuplicateEmployeeIds = COUNTROWS(FILTER(Master, Master[duplicateFlag]=TRUE))</code>.<br>4. <code>AvgCandidatesPerToken = AVERAGE(TokenIndex[candidateCount])</code>.<br>5. <code>AliasChangeRate30d = DIVIDE(CALCULATE(COUNTROWS(AliasLog),DATESINPERIOD(AliasLog[date],LASTDATE(AliasLog[date]),-30,DAY)), [TotalAliases])</code>.<br>Use these measures to build dashboards showing mapping health, alias growth, conflicts, and cleanup backlog. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Explainability & audit integration (detailed)</strong><br>1. Every mutation (UpsertAlias, RemoveAlias, UpsertMasterRecord, HarmonizeLegacyIds) must append a log row with <code>changeId</code>, <code>actionType</code>, <code>subjectId</code> (employeeId/aliasId), <code>beforeJSON</code>, <code>afterJSON</code>, <code>userId</code>, <code>timestamp</code>, <code>rationale</code>, and <code>runId</code> (if in-run). <br>2. For any master merge or alias conflict resolution, store <code>mergePlan</code> or <code>resolutionPlan</code> JSON capturing source members, target employee id, postings moved, and reviewer approvals. <br>3. <code>GetMasterSnapshotForReplay</code> links <code>mappingSnapshotId</code> into <code>Audit_Log</code> rows so every applied change during a run can be replayed deterministically using the exact mapping context. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Performance & scaling recommendations (engineering checklist)</strong><br>1. Prefer arrays + dictionaries for value storage when master > 50k rows; avoid nested Collections. <br>2. Chunk reads/writes to sheet: read master in chunks to reduce memory spikes; write alias store changes in batched transactions. <br>3. Use lazy index rebuilds: mark <code>indexesStale = True</code> and rebuild only when necessary or at safe points. <br>4. Offload central index to lightweight helper service for extremely large orgs; keep local caches for hot partitions. <br>5. Monitor <code>DumpIndexStats</code> outputs and adjust <code>modConfig</code> thresholds like <code>blockSizeMax</code> and <code>MaxFuzzyComparisonsPerRow</code> accordingly. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Edge cases & mitigation strategies</strong><br>1. <strong>Employee ID reuse:</strong> detect if same <code>employeeId</code> appears with conflicting <code>hireDate</code>/<code>fullName</code>; mark for <code>HRReview</code> and block automated mapping changes. <br>2. <strong>Alias collisions with canonical names:</strong> if aliasClean equals an existing cleanName, create an <code>AliasConflict</code> instead of overwriting master. <br>3. <strong>Legacy id conflicts:</strong> when a legacy id maps to multiple employeeIds, create <code>LegacyConflictReport</code> and prevent automated harmonization for those ids. <br>4. <strong>Partial master sheet writes:</strong> protect <code>LoadMasterStore</code> with checksum of sheet; if checksum fails (partial update), abort and restore previous snapshot to prevent inconsistent indexes. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Testing checklist (unit & integration)</strong><br>Unit tests (via <code>modTestingHarness</code>):<br>1. <code>LoadMasterStore</code> on small sample: verify <code>dictByEmployeeId</code> count and <code>dictTokenIndex</code> keys match expected. <br>2. <code>ResolveAlias</code> returns correct employeeId for known alias and <code>AMBIGUOUS_ALIAS</code> for ambiguous alias. <br>3. <code>UpsertAlias</code> idempotency: repeat call returns same <code>aliasId</code> and no duplicate rows in <code>AliasStore</code>. <br>4. <code>FindPotentialDuplicates</code> returns seeded groups for synthetic clustered dataset. <br>Integration tests:<br>1. End-to-end matching: <code>modMatchingEngine</code> uses <code>GetCandidatesByToken</code>/<code>GetCandidatesByFingerprint</code> and top-K includes expected employee for gold sample. <br>2. Replay parity: after <code>LoadMasterStore</code> and <code>ExportMappingSnapshot</code>, <code>ReplayRun</code> with snapshot returns identical candidate rankings compared to original run. <br>3. Export/import roundtrip: <code>ExportMappingSnapshot</code> → PQ ingestion → regenerate master snapshot → compare equality. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Operational runbook snippets (admins)</strong><br>1. <strong>Refresh master after HR feed update:</strong> call <code>ReloadMasterIfStale(0)</code> as Admin, inspect <code>__Master_ChangeLog</code> and run <code>DumpIndexStats</code> to identify unusual token cardinalities. <br>2. <strong>Add alias:</strong> use Admin UI to call <code>UpsertAlias</code> with <code>rationale</code> and sample postings; if alias affects many postings, route to reviewer and do not enable historical auto-apply until reviewer accepts. <br>3. <strong>Clean duplicates:</strong> run <code>FindPotentialDuplicates</code> weekly, present groups in <code>frmReviewerUI</code>, and apply merges after dual-review approval. <br>4. <strong>Export snapshot for migration:</strong> call <code>ExportMappingSnapshot(...,&quot;NDJSON&quot;)</code>, verify <code>manifest.json</code> checksums and ship artifact to DB team. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Examples & narratives (non-code)</strong><br>Example 1 — Alias resolves a payroll feed:<br>1. Payroll feed contains <code>J. O&#x27;Neill</code> posting. CleanName canonicalises to <code>j oneill</code>. <br>2. <code>ResolveAlias(&quot;J. O&#x27;Neill&quot;)</code> returns <code>E789</code>. Matching pipeline credits alias and auto-applies mapping to <code>E789</code> with audit referencing <code>aliasId</code>. <br>3. <code>Alias_Log</code> shows <code>INSERT</code> action with <code>rationale=&quot;payroll mapping for Irish site&quot;</code> and <code>createdBy=&quot;hr_ops&quot;</code>. <br>Example 2 — Duplicate detection and merge:<br>1. <code>FindPotentialDuplicates</code> found <code>E120</code> and <code>E121</code> with <code>avgFuzzy=0.92</code>. <br>2. Reviewer examines evidence in <code>frmReviewerUI</code> and approves <code>MERGE</code> into <code>E120</code>. <br>3. <code>UpsertMasterRecord</code> for merge with <code>mergePlan</code> moves alias pointers, consolidates legacyIds, and <code>Master_Log</code> records the merge and <code>beforeJSON</code> snapshots for both records. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Security, governance & retention</strong><br>1. All alias/master edits require <code>userId</code> and recorded <code>rationale</code>; admin-level changes flagged in <code>Macro_ChangeLog</code>. <br>2. Retention: <code>Alias_Log</code> and <code>Master_Log</code> retention policy enforced via <code>modConfig.RetentionDays</code> and periodic archival to secured central audit DB. <br>3. Access control: restrict <code>UpsertMasterRecord</code> and <code>RemoveAlias</code> to Admin role in <code>modConfig.UserRoles</code>. <br>4. Export security: require outbound network/OS-level controls and signed manifests for export artifacts. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Migration & compatibility notes</strong><br>1. If canonicalisation rules change (e.g., <code>CleanName</code> behaviour), create <code>MappingMigrationPlan</code> and re-run <code>ExportMappingSnapshot</code>/<code>FindPotentialDuplicates</code> to detect deltas; preserve <code>mappingStoreVersion</code> in <code>__Run_Config</code>. <br>2. Provide migration scripts via <code>modMigration</code> to upgrade old alias schemas to new schemas in an idempotent manner and include <code>__Migration_History</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Change log & versioning recommendations</strong><br>1. Persist <code>mappingStoreVersion</code> and <code>codeVersion</code> in <code>__Run_Config</code> and export manifests. <br>2. Include golden unit-vectors for core functions (<code>NGramFingerprint</code>, <code>ResolveAlias</code>) as part of CI regression tests to detect algorithm regressions. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Acceptance criteria for delivery</strong><br>1. LoadMasterStore loads canonical sample dataset deterministically and indexes sizes match golden baseline. <br>2. ResolveAlias/UpsertAlias idempotency tests pass. <br>3. FindPotentialDuplicates returns target groups for seeded synthetic duplicates. <br>4. ExportMappingSnapshot produces NDJSON with stable ordering and valid manifest checksum. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Developer pitfalls & best practices</strong><br>1. Avoid nested Collections for very large indexes; prefer arrays + dictionaries. <br>2. Keep in-memory caches tied to <code>runId</code> lifecycle and clear them after run to avoid memory leaks. <br>3. Don’t reload master mid-run without admin confirmation; prefer scheduling reload for next run. <br>4. Ensure all alias/mapping writes append audit rows immediately and persist changes to sheet only after in-memory indexes updated (write-ahead logging style) to avoid inconsistency. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Appendix: recommended config keys (modConfig) referenced by module</strong><br>1. <code>AllowHotReload</code> (Boolean) — allow master reload mid-run only with admin override. <br>2. <code>StrictMasterLoad</code> (Boolean) — abort master load on duplicate employeeId or continue with WARN. <br>3. <code>AliasProtectionWindowDays</code> (Integer) — protect recently-used aliases from removal without admin override. <br>4. <code>AutoAliasLimit</code> (Integer) — alias creation affecting more than this many historical rows requires reviewer approval. <br>5. <code>MaxMasterRowsForCollections</code> (Integer) — above this threshold use arrays not Collections. <br>6. <code>RetentionDays</code> (Integer) — retention for logs before archival. </td></tr><tr><td data-label="Per-function technical breakdown — modMappingStore (VBA)"> <strong>Closing operational summary</strong><br><code>modMappingStore</code> must be implemented as a robust, deterministic, and auditable mapping layer focused on performance and governance. It provides the indexes that make matching fast and the governance trails that make the system auditable and safe for enterprise use. Priorities for implementers: deterministic canonicalisation, efficient in-memory index structures, idempotent alias handling, comprehensive audit logs for every mutation, and safe reload/upgrade paths for master data. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><div class="table-caption" id="Table5" data-table="Docu_0203_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modAliasManagement** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modAliasManagement</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Module purpose (summary)</strong><br><code>modAliasManagement</code> coordinates the governed lifecycle of alias records used by the UpdateHR+ matching and reconciliation pipeline. It provides deterministic request intake, conflict detection, reviewer-driven approval and rejection flows, bulk import and safe ingestion, revocation/deprecation, forensic snapshots, PQ-ready exports for analytics/ML, role-based controls, and telemetry hooks. The module never performs silent changes to the canonical mapping; all promotions go through <code>modMappingStore.UpsertAlias</code>. Every state transition is append-only to audit tables and preserves provenance to enable replay, forensics, and ML training. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Design principles & constraints</strong><br>1. Single responsibility: alias lifecycle, governance, and safe promotion only. <br>2. Deterministic outputs (no randomization). <br>3. Append-only audit trail—never delete events, only append <code>REVOKE</code>/<code>DEPRECATE</code>. <br>4. Least-privilege enforcement: separate roles for Requester, Reviewer, Admin; no silent self-approvals unless explicitly enabled and recorded. <br>5. Memory & performance: avoid large in-memory collections in inner loops; batch imports use streaming write. <br>6. Privacy: PII hashed before external export when <code>modConfig.HashPII=True</code>. <br>7. Idempotency: operations keyed by <code>requestId</code> or deterministic <code>aliasFingerprint</code>; repeated calls produce idempotent results. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>High-level responsibilities (bulleted)</strong><br>1. Accept alias requests and attach evidence. <br>2. Surface pending requests to reviewers via <code>frmReviewerUI</code> and <code>modSuggestionUI</code>. <br>3. Detect conflicts and compute <code>conflictScore</code>. <br>4. Enforce policy (dual-approval, high-dollar checks, self-approval restrictions). <br>5. Promote aliases into <code>Alias_Mapping</code> via <code>modMappingStore</code>. <br>6. Revoke/deprecate aliases and produce <code>ForensicPack</code> when used in applied runs. <br>7. Export PQ/NDJSON artifacts for ML & BI. <br>8. Provide bulk import and safe quarantine. <br>9. Instrument telemetry and produce <code>AliasMetrics</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Public API — per-function breakdown (detailed)</strong><br>1. <code>RequestAlias(aliasNameRaw As String, targetEmployeeId As String, requestedBy As String, evidence As Scripting.Dictionary) As Scripting.Dictionary</code> — create request.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>aliasNameRaw</code> (free-text), <code>targetEmployeeId</code> (canonical id, optional but recommended), <code>requestedBy</code> (userId), <code>evidence</code> (optional dict: <code>sampleRows[]</code>, <code>postingIds[]</code>, <code>runId</code> references).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: canonicalise alias (<code>canonicalizeAlias</code>) to <code>cleanAlias</code>, compute <code>aliasFingerprint</code> via <code>NGramFingerprint</code> rules, validate <code>targetEmployeeId</code> existence via <code>modMappingStore.ResolveEmployee</code>, check immediate conflicts (<code>DetectAliasConflicts</code>), persist request row to <code>Alias_Requests</code> with <code>status = PENDING</code> or <code>CONFLICT</code> as appropriate, append <code>REQUEST_CREATED</code> event to <code>Alias_Log</code> and <code>Audit_Log</code>. Returns request dictionary: <code>{requestId, status, cleanAlias, aliasFingerprint, createdAt, evidenceSummary}</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Edge conditions: if <code>targetEmployeeId</code> missing but resolvable by deterministic heuristics, attach <code>resolutionCandidates[]</code> and <code>status=NEEDS_CLARIFICATION</code>. If evidence invalid, return <code>ERROR</code> with <code>errorCode=EVIDENCE_INVALID</code> and write audit. <br><br>2. <code>GetPendingAliasRequests(filterOptions As Scripting.Dictionary) As Collection</code> — list pending requests for reviewer UI.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>filterOptions</code> may include <code>orgUnit</code>, <code>sinceDate</code>, <code>limit</code>, <code>offset</code>, <code>statusFilter</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: query <code>Alias_Requests</code> sheet/table, apply filters, join minimal mapping store info for context (employee name, org), return collection of request objects. Provide <code>totalCount</code> for pager. Use streaming reads for large sets. <br><br>3. <code>ApproveAlias(requestId As String, approverId As String, approverComment As String, Optional effectiveDate As Date, Optional forceApprove As Boolean=False) As Scripting.Dictionary</code> — approve and promote alias.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Preconditions: <code>approverId</code> must be in <code>Reviewer</code> or <code>Admin</code> role per <code>modConfig.UserRoles</code>; if <code>forceApprove=False</code> and <code>DetectAliasConflicts</code> returns <code>Block</code>, block approval. If high-risk (materiality or dual-approval threshold triggered) require additional approver(s) before promotion. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: re-run <code>DetectAliasConflicts</code>; if conflicts are <code>Review</code>, append <code>APPROVAL_ATTEMPT</code> event and continue; if <code>Block</code> and <code>forceApprove=False</code>, set <code>status=CONFLICT_BLOCKED</code> and return the conflict details. If clear, call <code>modMappingStore.UpsertAlias(cleanAlias, targetEmployeeId, approverId, meta)</code> to create mapping record; update <code>Alias_Requests</code> status to <code>APPROVED</code>; append <code>APPROVED</code> event in <code>Alias_Log</code> and append <code>ALIAS_PROMOTE</code> audit row containing <code>beforeSnapshot</code> and <code>afterSnapshot</code>. Return approval record with <code>approvalToken</code> and <code>mappingReference</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Idempotency: if request already approved, return existing approval record with <code>idempotent=true</code>. <br><br>4. <code>RejectAlias(requestId As String, approverId As String, reason As String) As Scripting.Dictionary</code> — reject with rationale.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: set <code>Alias_Requests.status=REJECTED</code>, append <code>REJECTED</code> event in <code>Alias_Log</code> and <code>Audit_Log</code> with <code>reason</code>, notify requester if <code>modConfig.WebhookEnabled</code>. Optionally attach <code>rejectionCodes</code> to guide remediation (e.g., <code>ALIAS_TOO_GENERIC</code>, <code>TARGET_NOT_FOUND</code>, <code>CONFLICT_WITH_CANONICAL</code>). Return rejection object. <br><br>5. <code>EscalateAlias(requestId As String, escalatorId As String, escalateToRole As String, notes As String) As Boolean</code> — escalate to senior reviewer or specialist.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: set request state to <code>ESCALATED</code>, append <code>ESCALATED</code> event, create reviewer assignment entry, notify via UI marker and optional webhook, and return <code>True</code>. Track <code>escalationCount</code> for telemetry. <br><br>6. <code>RevokeAlias(aliasId As String, revokedBy As String, reason As String, Optional revokeEffectiveDate As Date) As Scripting.Dictionary</code> — remove alias from active mapping (deprecate) while preserving history.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: mark <code>Alias_Mapping.deprecatedFlag=True</code>, set <code>deprecatedAt</code>, <code>deprecateReason</code>, append <code>REVOKED</code> event to <code>Alias_Log</code> and <code>Audit_Log</code>. If alias was used in applied runs, trigger <code>CreateForensicPackForAliasUsage(aliasId)</code> to list affected runs and produce <code>RevertDescriptor</code> hints. Return revocation record with <code>impactSummary</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Note: do not physically delete alias rows—use soft-deprecation for audit integrity. <br><br>7. <code>ListAliasesForEmployee(employeeId As String) As Collection</code> — return current + historical aliases for an employee.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Return active aliases with <code>approvedAt</code>, approver, <code>deprecatedFlag</code>, plus a short provenance log per alias. Useful for reviewer context and conflict resolution. <br><br>8. <code>DetectAliasConflicts(aliasNameRaw As String, Optional targetEmployeeId As String) As Scripting.Dictionary</code> — run deterministic conflict scoring.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Checks performed:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a) canonical collision (<code>cleanAlias == existingCleanName</code>) <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b) fingerprint collision (<code>aliasFingerprint == fingerprintOfCanonical</code>) <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c) cross-employee alias mapping (alias already assigned to different employee) <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d) reserved token detection (<code>contractor</code>, <code>temp</code>, <code>misc</code>) <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e) recent rejection/revocation within <code>AliasReopenWindowDays</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;• Output: <code>conflictScore</code> numeric 0..1, <code>conflictTypes[]</code>, <code>recommendation</code> (<code>Block</code>/<code>Review</code>/<code>Allow</code>), and <code>evidence</code> array linking to matching mapping rows. <br><br>9. <code>ExportAliasRequests(format As String, destPath As String, Optional filter As Scripting.Dictionary) As Boolean</code> — export requests and log events for PQ/BI.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Supported formats: <code>CSV</code>, <code>NDJSON</code>. Export includes <code>Alias_Requests</code> fields and <code>Alias_Log</code> events for selected requests; includes <code>manifest.json</code> with <code>codeVersion</code>, <code>configSnapshot</code>, <code>exportChecksum</code>. If <code>modConfig.HashPII=True</code>, alias names in exports are hashed. <br><br>10. <code>IngestAliasFromCSV(filePath As String, createdBy As String, importOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — safe bulk ingestion pipeline.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: stream-parse CSV, validate each row against <code>validateEvidence</code> and <code>detectConflicts</code>, create <code>Alias_Requests</code> rows with <code>importBatchId</code>, return <code>importReport</code> with <code>rowsProcessed</code>, <code>rowsAccepted</code>, <code>rowsFailed</code>, <code>failReasons[]</code>, and <code>conflictCount</code>. For large imports use chunked processing and write import audit events (<code>IMPORT_STARTED</code>, <code>IMPORT_ROW_OK/FAIL</code>, <code>IMPORT_FINISHED</code>). If <code>importOptions(&quot;autoApprove&quot;)=True</code>, attempt to approve rows that meet low-conflict thresholds but still require reviewer notification for high-risk items. <br><br>11. <code>CreateAliasAuditSnapshot(requestId As String) As Scripting.Dictionary</code> — produce a self-contained forensic snapshot for a request including <code>Alias_Requests</code> row, <code>Alias_Log</code> events, <code>mappingStoreVersion</code> snapshot, <code>evidence</code> embedded, and references to affected runs. Useful for compliance and forensic export. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Internal helper functions (detailed)</strong><br>1. <code>canonicalizeAlias(raw As String) As Scripting.Dictionary</code> — normalise alias using the canonical rules shared with <code>modMatchingEngine</code> and <code>modFuzzyScores</code>: NBSP→space, collapse whitespace, lower-case, remove punctuation except allowed internal characters, strip configured suffixes, optional accent-stripping, remove honorifics. Returns <code>cleanAlias</code>, <code>tokens[]</code>, <code>tokenKey</code>, <code>aliasFingerprint</code>. <br>2. <code>aliasFingerprintToKey(fp As String) As String</code> — final stable key generation (e.g., compressed sorted grams) safe for worksheet keys and dictionary indices. <br>3. <code>appendAliasLogEvent(evtType As String, evtPayload As Scripting.Dictionary)</code> — atomic append to <code>Alias_Log</code> and forward to <code>modAudit.AppendAuditRow</code> with <code>actionType=ALIAS_EVENT</code>. Ensures event duplication resistant: compute eventChecksum = SHA1(<code>runId|requestId|evtType|timestamp</code>) and store. <br>4. <code>validateEvidence(evidence As Scripting.Dictionary) As Scripting.Dictionary</code> — verify <code>sampleRows</code> format, presence of required fields; optionally verify <code>postingIds</code> exist in <code>Detail_Budget</code> or postings sample (if provided). Return <code>valid</code> Boolean and normalized <code>evidenceSummary</code>. <br>5. <code>notifyReviewers(event As Scripting.Dictionary)</code> — increment <code>PendingAliasCount</code> cell, optionally call external webhook when <code>modConfig.WebhookEnabled=True</code>. Provide batched notifications to minimize spam. <br>6. <code>resolveEmployeeIdFromHint(hint As Scripting.Dictionary) As Scripting.Dictionary</code> — attempt deterministic resolution when requester provides partial details (name + orgUnit). Returns <code>resolvedEmployeeId</code> or <code>candidates[]</code> plus <code>resolutionConfidence</code>. <br>7. <code>computeConflictScore(metadata As Scripting.Dictionary) As Double</code> — internal formula combining fingerprint match strength, canonical equality, prior rejection count, reserved token weight, and temporal recency. Use configurable weights in <code>modConfig.AliasConflictWeights</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Data model & sheet schemas (detailed)</strong><br><strong>Alias_Requests</strong> (sheet/table): <code>requestId | aliasNameRaw | cleanAlias | aliasFingerprint | targetEmployeeId | targetEmployeeName | evidenceSummary | requestedBy | requestedByRole | createdAtUTC | status | lastUpdatedAtUTC | assignedReviewer | importBatchId | conflictScore | resolutionCandidates</code>.<br><strong>Alias_Log</strong> (append-only): <code>eventId | requestId | eventType | actorId | actorRole | payloadJSON | timestampUTC | runId | eventChecksum</code>. Event types include: <code>REQUEST_CREATED</code>, <code>APPROVAL_ATTEMPT</code>, <code>APPROVED</code>, <code>REJECTED</code>, <code>ESCALATED</code>, <code>REVOKED</code>, <code>IMPORT_STARTED</code>, <code>IMPORT_ROW_OK</code>, <code>IMPORT_ROW_FAIL</code>, <code>IMPORT_FINISHED</code>, <code>REOPENED</code>. <br><strong>Alias_Mapping</strong> (active mapping): <code>aliasId | cleanAlias | aliasFingerprint | employeeId | createdBy | approvedBy | createdAtUTC | approvedAtUTC | deprecatedFlag | deprecatedAtUTC | deprecateReason | mappingVersion</code>.<br><strong>Alias_Imports</strong> (import batches): <code>importBatchId | fileName | importedBy | startedAtUTC | finishedAtUTC | rowsTotal | rowsAccepted | rowsFailed | importReportPath</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Validation & business rules (policy examples)</strong><br>1. Alias canonicalisation must produce non-empty <code>cleanAlias</code>; otherwise <code>ALIAS_EMPTY</code> error. <br>2. <code>targetEmployeeId</code> must exist in <code>modMappingStore</code> or resolution must provide candidate list; ambiguous targets yield <code>NEEDS_CLARIFICATION</code>. <br>3. If <code>conflictScore &gt;= modConfig.ConflictBlockThreshold</code> then block approval unless <code>forceApprove=True</code> and approver is <code>Admin</code> and a <code>forceApprovalRationale</code> is recorded. <br>4. Self-approval only if <code>modConfig.AllowSelfApproval=True</code> and <code>approver</code> has <code>Admin</code> role and second approver audit is captured. <br>5. Dual-approval required when <code>modMateriality.EvaluateMateriality</code> indicates alias use could affect material accounts (e.g., transfers > <code>DualApprovalThreshold</code>). <br>6. Bulk imports exceeding <code>modConfig.ImportConflictQuota</code> result in quarantining the entire batch and notifying admins. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Integration points with other modules (explicit)</strong><br>1. <code>modMappingStore.UpsertAlias(cleanAlias, employeeId, createdBy, meta)</code> — canonical write; <code>modAliasManagement</code> calls this only after approval. <br>2. <code>modMatchingEngine</code> — consumes <code>Alias_Mapping</code> and <code>Alias_Log</code> to prefer alias-based matches and to compute priors. <br>3. <code>modAudit.AppendAuditRow</code> — used for all alias events to ensure central audit consistency. <br>4. <code>frmReviewerUI</code> + <code>modSuggestionUI</code> — UI surfaces use <code>GetPendingAliasRequests</code>, <code>ApproveAlias</code>, <code>RejectAlias</code>, <code>EscalateAlias</code>. <br>5. <code>modTelemetry.RecordTelemetryPoint</code> — alias metrics: requests/day, approvals/day, average approval lead time, conflict rate, revoke rate. <br>6. <code>modConfigUI</code> — exposes alias policies (weights, thresholds, auto-approve flags) and binds to <code>modConfig</code> keys used by this module. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Explainability & audit integration</strong><br>1. <code>appendAliasLogEvent</code> payloads include <code>cleanAlias</code>, <code>aliasFingerprint</code>, <code>evidenceSummary</code>, <code>preApprovalConflicts</code>, <code>postApprovalMappingSnapshot</code>, and optional <code>forceApprovalRationale</code>. <br>2. <code>CreateAliasAuditSnapshot</code> bundles request event sequence, mapping store snapshot, and affected applied runs (if any). Snapshot is saved as ndjson export anchored by <code>snapshotId</code>. <br>3. For ML training, export <code>featureVector</code> per request with features: <code>aliasLength</code>, <code>tokenCount</code>, <code>tokenOverlapWithCanonical</code>, <code>trigramJaccard</code>, <code>priorConfirmCount</code>, <code>postingSignatureOverlap</code>, <code>conflictScore</code>, <code>requesterRole</code>, <code>timeToApprove</code>, and <code>label</code> (approved=1/rejected=0). </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>UI & reviewer flows (detailed)</strong><br>1. Reviewer dashboard shows all <code>PENDING</code> requests with sortable columns: <code>conflictScore</code>, <code>createdAt</code>, <code>evidenceCount</code>, <code>targetEmployeeName</code>, <code>impactEstimate</code>. <br>2. Selecting a request opens the Evidence panel: shows sample postings (up to N), example posting signatures, candidate mapping rows from master store, prior alias attempts, and top-N automated match suggestions from <code>modMatchingEngine</code>. <br>3. Reviewer actions:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) <code>Approve</code> — triggers <code>ApproveAlias</code> with optional <code>approverComment</code>; if dual-approval required sets <code>status=AWAITING_SECOND_APPROVAL</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) <code>Reject</code> — triggers <code>RejectAlias</code> with <code>reason</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) <code>Escalate</code> — triggers <code>EscalateAlias</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) <code>RequestMoreInfo</code> — sends request back with required evidence fields (e.g., "please supply 3 sample postings"). <br>4. Bulk actions: require explicit confirm dialog showing counts and total estimated material impact and limited by <code>modConfig.MaxBulkApproveRows</code>. If exceeded, require super-user sign-off. <br>5. Notifications: the system updates the workbook <code>PendingAliasCount</code>; optionally calls webhook/email when configured. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Conflict detection algorithm (implementation detail)</strong><br>1. Input: <code>cleanAlias</code>, <code>aliasFingerprint</code>, optional <code>targetEmployeeId</code>.<br>2. Steps:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Check if <code>cleanAlias</code> exactly equals any existing canonical <code>cleanName</code> in master store → immediate <code>canonicalCollision=true</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Compute fingerprint collisions: lookup <code>aliasFingerprint</code> in <code>dictFingerprintIndex</code>. If found, compute <code>fingerprintMatchStrength</code> via token overlap and trigram Jaccard between alias and canonical keys. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Check if <code>aliasFingerprint</code> maps to multiple employeeIds (cross-mapping); if so set <code>crossMap=true</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) Reserved token check: match lowercased alias tokens against <code>modConfig.ReservedAliasTokens</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;e) Temporal check: if a prior alias with same fingerprint was rejected or revoked within <code>modConfig.AliasReopenWindowDays</code>, increase <code>conflictScore</code> and require additional reviewer justification. <br>3. Score composition (example): <code>conflictScore = 0.4*canonicalCollisionFlag + 0.25*fingerprintMatchStrength + 0.15*crossMapFlag + 0.1*recentRejectNormalized + 0.1*reservedFlag</code> (weights configurable). <br>4. Recommendation mapping: <code>conflictScore &gt;= 0.9</code> => <code>Block</code>; <code>0.4 &lt;= conflictScore &lt; 0.9</code> => <code>Review</code>; <code>&lt;0.4</code> => <code>Allow</code>. Always attach <code>conflictDetails[]</code> explaining matching rows and sample evidence. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Bulk import processing & safety rules</strong><br>1. Import pipeline processes CSV in chunks of <code>modConfig.ImportChunkSize</code> to avoid memory spikes. <br>2. Row-level validation: canonicalisation, target resolution, evidence presence. <br>3. Conflict handling: any row that hits <code>Block</code> placed in <code>ImportQuarantine</code> with <code>failReason</code> and not included in <code>Alias_Requests</code> active queue. <br>4. Reporting: <code>importReport</code> includes <code>rowsProcessed</code>, <code>rowsAccepted</code>, <code>rowsFailed</code>, <code>failReasons</code> sample, <code>conflictCount</code>, <code>timeTaken</code>. <br>5. Post-import actions: optionally auto-approve rows with <code>conflictScore &lt; modConfig.ImportAutoApproveThreshold</code> and <code>importOptions(&quot;autoApprove&quot;)=True</code>. Auto-approval must still respect <code>DualApprovalThreshold</code> and call <code>APPROVED</code> event with <code>autoApproved=true</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Forensics & revocation flows (detailed)</strong><br>1. When revoking an alias that has been used in applied runs: <br>&nbsp;&nbsp;&nbsp;&nbsp;a) generate <code>ForensicPack</code> containing <code>Alias_Requests</code> row, full <code>Alias_Log</code> slice, <code>mappingStoreVersion</code> at approval time, <code>ApplyDescriptor</code> references where alias was used, and sample <code>Audit_Log</code> entries for committed runs. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) produce <code>RevertDescriptor</code> list: for each affected run produce <code>runId</code>, <code>rowId</code>, <code>applyDescriptorReference</code>, and suggested revert action (inline inverse apply or manual review). <br>&nbsp;&nbsp;&nbsp;&nbsp;c) mark alias <code>deprecatedFlag=True</code>, append <code>REVOKED</code> event with <code>impactSummary</code> and notify governance group. <br>2. Revert authorization: require multi-party approval for reverts that touch > <code>modConfig.RevertMaterialityThreshold</code> monetary exposure. Record approver signatures and timestamps in audit. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Power Query (PQ) conceptual guidance for alias artifacts</strong><br>1. <strong>Source:</strong> exported ndjson from <code>ExportAliasRequests</code> containing <code>Alias_Requests</code> and nested <code>Alias_Log</code> <code>payloadJSON</code>. <br>2. <strong>Steps:</strong> use <code>Json.Document</code> to parse nested JSON, expand <code>payloadJSON</code> into columns (<code>cleanAlias</code>, <code>aliasFingerprint</code>, <code>evidenceSummary</code>), convert timestamps to datetime, and normalize <code>eventType</code>. <br>3. <strong>Derived tables:</strong> produce <code>AliasMetrics</code> aggregated by day and <code>eventType</code> for BI, and <code>AliasTraining</code> table with feature columns for ML ingestion. <br>4. <strong>Reproducibility:</strong> ensure PQ sorts by <code>createdAtUTC</code> then <code>eventId</code> before grouping/aggregation to guarantee stable outputs. <br>5. <strong>Example PQ transforms (conceptual):</strong> parse ndjson -> expand <code>payloadJSON</code> -> select feature columns -> compute <code>conflictFlag</code> column using <code>conflictScore</code> thresholds -> pivot to daily counts. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Conceptual DAX measures for governance dashboards</strong><br>1. <code>AliasRequestsPerDay = COUNTROWS(&#x27;AliasRequests&#x27;)</code> grouped by date. <br>2. <code>AliasApprovalRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;AliasLog&#x27;), &#x27;AliasLog&#x27;[eventType]=&quot;APPROVED&quot;), COUNTROWS(&#x27;AliasRequests&#x27;))</code>. <br>3. <code>AliasConflictRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;AliasLog&#x27;), &#x27;AliasLog&#x27;[eventType]=&quot;REQUEST_CREATED&quot; &amp;&amp; &#x27;AliasLog&#x27;[conflictFlag]=1), COUNTROWS(&#x27;AliasRequests&#x27;))</code>. <br>4. <code>AvgAliasApprovalLeadTime = AVERAGE(&#x27;AliasLog&#x27;[approvalTimeMinutes])</code> computed by difference between <code>APPROVED.timestamp</code> and <code>REQUEST_CREATED.timestamp</code> per request. <br>5. <code>AliasImportFailRate = DIVIDE([ImportRowsFailed], [ImportRowsTotal])</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Explainability & ML feature export (recommended fields)</strong><br>Produce labeled training records with fields: <code>requestId, cleanAlias, aliasFingerprint, aliasLength, tokenCount, tokenOverlapWithCanonical, trigramJaccard, priorConfirmCount, postingSignatureOverlap, conflictScore, requesterRole, timeToApproveMinutes, labelApproved(1/0), createdAtUTC, codeVersion</code>. Use PQ to merge <code>Alias_Log</code> <code>APPROVED</code> events to produce <code>labelApproved</code>. Hash or redact PII when exporting. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Telemetry & operational metrics</strong><br>1. Recorded metrics: <code>aliasRequestsPerHour</code>, <code>aliasApprovalsPerHour</code>, <code>aliasRejectRate</code>, <code>aliasConflictRate</code>, <code>avgApprovalLatencyMs</code>, <code>aliasRevokeRate</code>. <br>2. Emit telemetry via <code>modTelemetry.RecordTelemetryPoint</code> for each major lifecycle event with <code>category=alias</code> and <code>metrics={}</code>. <br>3. Provide simple health checks: <code>PendingAliasCount</code>, <code>AvgConflictScore</code> displayed on operator UI. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Security, privacy & compliance controls</strong><br>1. PII control: <code>modConfig.HashPII</code> determines whether alias strings are hashed prior to external export. <br>2. Role enforcement: every action checks <code>modConfig.UserRoles</code> mapping; do not allow UI actions that exceed role. <br>3. Audit immutability: use <code>modAudit.SealAuditRun</code> for run-level sealing; exports include <code>manifest</code> and <code>sealChecksum</code>. <br>4. Retention: follow <code>modConfig.RetentionDays</code>; prior to deletion export to secure archive and store deletion audit event. <br>5. Access logs: record <code>actorId</code>, <code>actorRole</code>, <code>ipHint</code> (if available from webhook trigger) for sensitive actions (approve/revoke). </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Edge cases & mitigation strategies</strong><br>1. Concurrent duplicate requests: use <code>AcquireLock(aliasFingerprint)</code> to avoid race; if concurrency detected, mark both requests with <code>concurrencyNote</code> and queue for reviewer. <br>2. Ambiguous employee resolution: if <code>resolveEmployeeIdFromHint</code> yields multiple candidates, set <code>status=NEEDS_CLARIFICATION</code> and attach candidate list; do not autocreate mapping. <br>3. Revocation with existing applied runs: automatically create <code>ForensicPack</code> and <code>RevertDescriptor</code> and require governance approval before reverts. <br>4. Import of large conflicting batches: quarantine batch and notify admins; do not auto-promote more than <code>modConfig.ImportAutoApproveLimitPercent</code> of rows. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Testing strategy (unit, integration, performance)</strong><br>Unit tests (via <code>modTestingHarness</code>):<br>1. <code>RequestAlias</code> returns expected <code>aliasFingerprint</code> for variety of raw inputs including punctuation, diacritics, and whitespace variants. <br>2. <code>DetectAliasConflicts</code> correctly classifies canonical collisions and cross-map conditions with deterministic conflictScore outputs. <br>3. <code>ApproveAlias</code> integrates with <code>modMappingStore.UpsertAlias</code> and persists mapping row and <code>APPROVED</code> event. <br>4. <code>RejectAlias</code> leaves mapping unchanged and writes <code>REJECTED</code> event. <br>Integration tests:<br>1. End-to-end: create request -> approve -> confirm <code>modMatchingEngine</code> picks alias for sample input and <code>Audit_Log</code> includes component breakdown. <br>2. Bulk import: ingest 10k synthetic rows; verify <code>IngestAliasFromCSV</code> completes, produces <code>importReport</code>, and quarantine behaviour when threshold exceeded. <br>Performance tests:<br>1. Measure ingest throughput and ensure memory footprint stable; tune <code>ImportChunkSize</code> until acceptable on baseline hardware. <br>Acceptance criteria:<br>1. All unit and integration tests pass. <br>2. Conflict detection false-positive rate below configured tolerance on historical sample. <br>3. No silent loss of evidence during import or approval. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Operational runbook snippets (how-to)</strong><br>1. <strong>Approve flow:</strong> reviewer opens request > inspect evidence > run conflict details > if clear press Approve > record comment > check <code>AliasLog</code> for <code>APPROVED</code> event and mapping row in <code>Alias_Mapping</code>. <br>2. <strong>Handle high conflict incidence:</strong> generate <code>AliasConflictReport</code> for top fingerprints, review candidate sets, recommend alias merges or master-store deduplication. <br>3. <strong>Revoke incident:</strong> create <code>ForensicPack</code> for aliasId, notify governance, and prepare <code>RevertDescriptor</code> for affected runs; require multi-party approval before proceeding. <br>4. <strong>Tuning thresholds:</strong> run <code>RecommendAliasThresholds</code> (admin helper) using <code>Alias_Log</code> and <code>ConfirmedMatches</code> to propose policy updates. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Migration & change-control guidance</strong><br>1. Changing canonicalisation rules requires migration: recompute <code>cleanAlias</code> and <code>aliasFingerprint</code> for existing requests and mapping rows and record <code>legacyCleanAlias</code> fields. <br>2. Maintain <code>aliasModuleVersion</code> in <code>__Run_Config</code>; require regression suite on new release. <br>3. All behavior changes must be recorded in <code>Macro_ChangeLog</code> with <code>changeId</code>, <code>codeVersion</code>, <code>testResults</code>, and <code>approver</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Example narratives & use-cases (illustrative)</strong><br>Example A — Single manual alias request:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Requestor submits <code>aliasNameRaw = &quot;J. Smith (temp)&quot;</code>, target <code>E123</code> with two sample postings. System canonicalises to <code>j smith</code> fingerprint <code>|j|smith|</code>. <code>DetectAliasConflicts</code> finds reserved token (<code>temp</code>) and <code>conflictScore=0.45</code> recommending <code>Review</code>. Reviewer examines evidence and approves; mapping created and <code>APPROVED</code> audit row appended. <br>Example B — Bulk import with mixed conflicts:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Import 10k rows, 8% hit <code>Block</code> conflict threshold; pipeline quarantines those, produces <code>importReport</code> with <code>failReasons</code> for QA. Remaining accepted rows become <code>Alias_Requests</code> with <code>importBatchId</code>. <br>Example C — Revoke after applied runs:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Alias <code>xyz</code> used in 120 applied runs discovered to be incorrect. <code>RevokeAlias</code> creates <code>ForensicPack</code> and <code>RevertDescriptor</code> for those runs; governance authorizes revert for 20 low-impact runs and schedules manual review for high-impact ones. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Data exports & PQ/DAX guidance (concise)</strong><br>1. Export <code>Alias_Log</code> ndjson and use PQ: <code>Json.Document</code> -> expand <code>payloadJSON</code> -> add computed fields (<code>conflictScoreBucket</code>) -> create <code>AliasMetrics</code> and <code>AliasTraining</code> tables. <br>2. DAX measures: <code>AliasApprovalRate</code>, <code>AvgAliasApprovalLeadTime</code>, <code>AliasConflictRate</code>, and <code>AliasesDeprecated</code>. Use these for SLAs and governance dashboards. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Developer notes & heuristics</strong><br>1. Use <code>aliasFingerprint</code> built from sorted unique 3-grams across tokens to balance uniqueness and collision tolerance. <br>2. Keep evidence size small (up to 10 sample postings) to reduce audit bloat. <br>3. Store timestamps in UTC ISO format for portability. <br>4. Design import to be resumable—maintain <code>lastProcessedLine</code> per batch. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Acceptance checklist for production rollout</strong><br>1. Unit & integration tests green for all alias flows. <br>2. PQ ingestion and training export validated on golden dataset. <br>3. Telemetry dashboards display <code>aliasRequestsPerDay</code> and <code>AvgApprovalLT</code>. <br>4. Role-based access control validated and enforced in UI. <br>5. Migration plan for canonicalisation changes exists and tested. </td></tr><tr><td data-label="Per-function technical breakdown — modAliasManagement (VBA)"> <strong>Summary (concise)</strong><br><code>modAliasManagement</code> is the governed, auditable, and deterministic lifecycle manager for alias requests and mapping promotions: it validates, triages, conflicts, and promotes aliases with full provenance, integrates with mapping and matching layers, provides safe bulk ingest and revoke/forensic capabilities, and emits PQ-ready exports and DAX-friendly metrics for operational governance. </td></tr></tbody></table></div><div class="row-count">Rows: 27</div></div><div class="table-caption" id="Table6" data-table="Docu_0203_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modMigration** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modMigration</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Module purpose (concise)</strong><br><code>modMigration</code> is the controlled, auditable, and idempotent migration engine for the UpdateHR+ workbook. It upgrades workbook schema and large tables, transforms audit formats, produces canonical migration artifacts, and provides deterministic rollback and forensic evidence. The module is designed to be safe for production: manifest-driven where possible, chunked for scale, checkpointed for resumability, and fully auditable. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Design principles & operational constraints</strong><br>1. Idempotency: every migration step has a guard token and is safe to re-run; <code>__Migration_History</code> prevents duplicate application. <br>2. Recoverability: every applied step must have a pre-step snapshot adequate to restore state; <code>CreateMigrationSnapshot</code> is mandatory for destructive or mass-change steps. <br>3. Atomic-step model: migrations are ordered sequences of small atomic steps (schema, transform, verify, commit). Each step must verify before commit. <br>4. Minimal in-sheet mutations during processing: large transforms should stream to CSV/ndjson then apply staged changes. <br>5. Auditable: all steps, decisions, and verification metrics are appended to <code>__Migration_History</code> and mirrored to <code>Audit_Log</code> when applicable. <br>6. Governance: sign-off gating and reviewer approval enforced for large or high-materiality migrations; signature tokens recorded via <code>modSignatures</code>. <br>7. Performance: chunked processing and streaming to avoid Excel memory spikes; threshold controls in <code>modConfig</code> for chunk size and stream-switch. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>High-level responsibilities</strong><br>1. Validate migration manifests and preconditions. <br>2. Create pre-migration snapshots and backups. <br>3. Execute step-by-step transformations with staging and verification. <br>4. Provide dry-run simulation and impact reporting for reviewers. <br>5. Commit changes atomically (chunked) and record history. <br>6. Export canonical migration artifacts (CSV/NDJSON/SQL) and manifests for DB ingestion. <br>7. Provide deterministic rollback and produce ForensicPack for incidents. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: EnsureSchema(targetVersion As String, Optional runOptions As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: top-level entry to ensure workbook reaches <code>targetVersion</code> via manifest-driven steps. <br>Inputs: <code>targetVersion</code> (semantic string), <code>runOptions</code> keys: <code>dryRun</code>(Bool), <code>userId</code>(String), <code>requireSignOff</code>(Bool), <code>skipChecks</code>(Bool). <br>Behavior: load manifest <code>__Migration_Manifest</code> or manifest file, call <code>ValidateMigrationPlan</code>, compute pending steps by comparing <code>__Migration_History</code>, perform pre-checks (<code>ValidatePreconditions</code>), create snapshot using <code>CreateMigrationSnapshot</code>, sequentially call <code>ApplyMigrationStep</code> for each pending step, run <code>VerifyMigration</code> after each, update <code>__Migration_History</code>, and if all steps succeed, mark manifest as applied and optionally call <code>ExportMigrationArtifacts</code>. <br>Return: dictionary with <code>runId</code>, <code>status</code> (<code>COMPLETED</code>/<code>FAILED</code>/<code>AWAITING_SIGNOFF</code>), <code>appliedSteps</code>, <code>skippedSteps</code>, <code>diagnostics</code>. <br>Audit: initial run header appended to <code>__Migration_History</code> and to <code>Audit_Log</code> with pre-snapshot checksum and <code>codeVersion</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: ValidateMigrationPlan(manifest As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: static manifest validation and idempotency checks. <br>Checks performed: existence and schema of steps; each step has <code>stepId</code>, <code>type</code>, <code>guard</code> or idempotency check, <code>inputs</code>, <code>preconditions</code> (required named ranges / columns), <code>postconditions</code> (expected columns / checksums), <code>rollbackDescriptor</code>. <br>Idempotency verification: ensure each step includes a deterministic guard (existence of target column, presence of step token) or pre-check to detect already-applied state. <br>Output: <code>errors[]</code>, <code>warnings[]</code>, <code>resolvedGuards[]</code> for UI display. <br>Implementation note: fail fast; manifest with ambiguous rename or conflicting column mappings is rejected until corrected. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: CreateMigrationSnapshot(runId As String, scope As String) As Scripting.Dictionary</strong><br>Purpose: create pre-change backups to enable revert and forensic analysis. <br>Scope options: <code>schemaOnly</code>, <code>auditOnly</code>, <code>full</code>.<br>Actions:<br>- For <code>schemaOnly</code>: record table/column metadata into <code>__Migration_Backup_&lt;runId&gt;_schema</code>. <br>- For <code>auditOnly</code>: stream <code>Audit_Log</code> to <code>__Migration_Artifacts\&lt;runId&gt;\audit_backup_part_{n}.ndjson</code> if large; write header metadata. <br>- For <code>full</code>: snapshot all critical sheets into CSVs and produce compressed manifest. <br>Metadata returned: <code>snapshotPath</code>, <code>snapshotChecksum</code>, <code>sizeBytes</code>, <code>rowCounts</code>, <code>timestamp</code>, <code>userId</code>. <br>Implementation details: streaming export for large ranges using <code>SnapshotRangeToCSV</code> to avoid memory effects; create per-chunk checksums and a run-level combined checksum for validation. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: DryRunMigration(manifest As Scripting.Dictionary, runId As String) As Scripting.Dictionary</strong><br>Purpose: simulate migration without mutating production sheets; used for reviewer approval. <br>Behavior: apply transformations to <code>__Stage_Temp</code> or to ephemeral CSVs, run <code>VerifyMigration</code> checks in the staged environment, and produce <code>ImpactReport</code> including <code>schemaDiff</code>, <code>rowCountChanges</code>, <code>expectedBeforeAfterSamples</code>, and <code>materialityEstimates</code>. <br>Outputs: <code>impactReportSheet</code>, <code>impactCsvPath</code>, <code>evidenceSamples</code> and <code>materialityFlag</code>. <br>Use-case: feed reviewer UI <code>frmReviewerUI</code> or admin sheet <code>__Migration_Preview</code> for approval flows. <br>Note: dry run must record <code>simulatedRunId</code> in <code>__Migration_History</code> as <code>SIMULATION</code> and not alter production manifest tokens. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: ApplyMigrationStep(step As Scripting.Dictionary, runContext As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: execute an individual migration step in atomic fashion. <br>Supported step types: <code>addColumn</code>, <code>renameColumn</code>, <code>dropColumn</code> (admin-only), <code>updateFormula</code>, <code>transformAuditRows</code>, <code>moveSheet</code>, <code>changeRangeType</code>, <code>exportCsv</code>, <code>importCsv</code>, <code>invokeExternal</code> (helper service), <code>runScript</code> (whitelisted macro call). <br>Workflows per step:<br>1. Preconditions check: verify guard expressions and <code>preconditions</code> specified in step. <br>2. Pre-step snapshot: create per-step snapshot <code>__Migration_Backup_&lt;runId&gt;_step_&lt;stepId&gt;</code>. <br>3. Execute transformation into <code>__Stage_Migrate_&lt;runId&gt;</code>; transformations are manifest-driven where possible (field maps, column expressions), streaming output to CSV for large sets. <br>4. Post-step verification via <code>VerifyMigration</code> using step <code>postconditions</code>. <br>5. Commit: copy staged changes to target workbook locations using <code>ApplyStagedToSheet</code> and append migration token for the step to <code>__Migration_History</code>. <br>Failure: if post-check fails, revert using pre-step snapshot, record error, and if <code>runContext(&quot;stopOnError&quot;)=True</code> bubble up to stop the whole run. <br>Return: <code>status</code>, <code>stepId</code>, <code>metrics</code>, <code>errors</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: VerifyMigration(step As Scripting.Dictionary, verificationOptions As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: run a set of deterministic verification checks after a step or during dry-run. <br>Checks: <br>- Structural: presence/absence of columns, data types, named ranges. <br>- Row counts: <code>rowsBefore == rowsAfter</code> unless transform expects changes. <br>- Checksums: per-chunk row checksums and sheet-level checksum (<code>ComputeSheetChecksum</code>). <br>- Semantic sample checks: parse sample rows and assert semantic mapping (e.g., legacy <code>colA</code> mapped to <code>beforeJSON.fieldX</code> equals expected). <br>- PQ refresh test: attempt to refresh PQ query optionally (if PQ used) and capture success/failure. <br>Return: <code>verified</code> Boolean, <code>metrics</code> (row counts, checksum matches), <code>sampleDiffs</code>. <br>Policy: verification failures produce <code>WARNING</code> or <code>FAIL</code> depending on severity; <code>FAIL</code> requires stop or explicit override. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: MigrateAuditFormat(oldFormat As String, newFormat As String, options As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: transform legacy audit schema into the new normalized JSON-based audit schema (or reverse for compatibility). <br>Important behaviors:<br>1. Mapping-driven processing: use <code>options(&quot;fieldMap&quot;)</code> to map legacy columns into nested <code>beforeJSON</code>/<code>afterJSON</code> structures. <br>2. Streaming transform: process <code>Audit_Log</code> in <code>modConfig.AuditTransformStreamThreshold</code>-sized chunks; write to staging CSV parts to avoid Excel RAM limits. <br>3. Preserve legacy: do not delete old columns until <code>seal</code> step; write <code>legacyBackup</code> fields to store original row as JSON. <br>4. Compute <code>rowChecksum</code> per row using <code>ComputeRowChecksum</code> and append to transformed row. <br>5. Verify: re-expand <code>beforeJSON</code> and <code>afterJSON</code> for random sample and compare to original legacy columns; compute <code>semanticParityPct</code>. <br>6. Commit: staged transformed rows replace or append to <code>Audit_Log</code> as per <code>step.commitMode</code> (inplace-update or append-new). <br>Return: verification metrics, <code>appliedChunks</code>, <code>errorRows</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: RollbackMigration(migrationRunId As String, rollbackOptions As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: deterministic reverse of an applied migration run or partial revert to a step. <br>Behavior:<br>1. Read <code>__Migration_History</code> for <code>migrationRunId</code> and enumerate applied steps in reverse order. <br>2. For each step, locate <code>__Migration_Backup_&lt;migrationRunId&gt;_step_&lt;stepId&gt;</code> and apply snapshot using <code>ApplyStagedToSheet</code> to restore prior state. <br>3. Verify the revert for each step by recomputing checksums and sample semantic checks. <br>4. If pre-step snapshot missing for a step, flag <code>FORCED_MANUAL_INTERVENTION</code> and create <code>ForensicPack</code>, then pause. <br>5. Record each rollback action in <code>__Migration_History</code> with <code>actionType=ROLLBACK_STEP</code> and <code>userId</code> who initiated rollback. <br>Return: <code>revertedSteps</code>, <code>failedReverts</code>, <code>forensicBundlePath</code>. <br>Governance: destructive forced reverts require multi-party approval and <code>modSignatures</code> tokens. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: GenerateMigrationReport(runId As String, format As String, destPath As String) As Scripting.Dictionary</strong><br>Purpose: produce human & machine-readable migration report and package. <br>Contents: <code>manifest</code>, <code>appliedSteps</code>, <code>verificationMetrics</code>, <code>commitChecksums</code>, <code>materialitySummary</code>, <code>forensicReferences</code>, <code>configSnapshot</code>, <code>codeVersion</code>, <code>migrationSignature</code> (optional). <br>Formats supported: <code>JSON</code>, <code>NDJSON</code>, <code>CSV</code>, <code>SQL</code> (parameterized insert script), <code>ZIP</code> bundling. <br>Return: <code>packagePath</code>, <code>fileChecksums</code>, <code>reportSummary</code>. <br>Operational note: do not include raw PII in summary exports unless destination is secure and approved; support encryption or signing via external helper if configured. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: ExportMigrationArtifacts(runId As String, destFolder As String, options As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: deliver migration artifacts for DB ingestion or archiving. <br>Artifacts: <code>ApplyDescriptor</code> JSONs, <code>Audit_Log</code> transformed CSVs (streamed), <code>migration_manifest.json</code>, <code>migration_report.json</code>, <code>row-level checksums</code>, <code>signature</code> file. <br>Options: <code>compress</code> (Bool), <code>sign</code> (Bool), <code>autoUpload</code> (Bool) with <code>uploadEndpoint</code>. <br>Return: <code>exportPaths</code>, <code>uploadStatus</code>. <br>Security: if <code>sign</code> requested and local signing unavailable, return <code>signingNotAvailable</code> and advise external signing process. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: DryRunCompare(originalRunId As String, simulatedRunId As String) As Scripting.Dictionary</strong><br>Purpose: compare actual run to simulated dry-run to validate parity before commit. <br>Comparisons performed: <code>Audit_Log</code> row-level diffs for a sample, schema diffs, <code>ApplyDescriptor</code> diffs, <code>checksum</code> comparisons, and PQ parse parity. <br>Output: <code>diffReport</code> with <code>mismatchRows</code>, <code>severityScore</code>, <code>recommendedResolutions</code>. <br>Use: sign-off evidence to proceed to commit. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Public function: RecordMigrationHistory(record As Scripting.Dictionary) As Boolean</strong><br>Purpose: append-only writer for <code>__Migration_History</code>. <br>Record fields: <code>runId</code>, <code>stepId</code>, <code>action</code> (<code>APPLY</code>,<code>VERIFY</code>,<code>ROLLBACK</code>,<code>SIMULATE</code>), <code>status</code>, <code>userId</code>, <code>timestamp</code>, <code>checksumBefore</code>, <code>checksumAfter</code>, <code>artifactRef</code>. <br>Implementation detail: ensure append-only semantics by always inserting new rows and never overwriting existing entries; compute <code>rowChecksum</code> for each history entry and provide a <code>seal</code> mechanism to mark runs as immutable unless admin unlock with multi-signature approval. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Internal helper: ComputeSheetChecksum(sheet As Worksheet, Optional columns As Collection) As String</strong><br>Purpose: deterministic checksum for verification after transforms. <br>Methodology:<br>1. Serialize ordered rows and selected columns into canonical text (normalize line endings, TRIM, stable number formatting). <br>2. Compute CRC32 or MD5-like digest (VBA-based implementation). <br>3. For large sheets compute chunk-level checksums and then a combined checksum (concatenate chunk checksums and compute final digest). <br>Design note: checksum function must be stable across Excel versions and locales; use explicit number formatting in serialization. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Internal helper: SnapshotRangeToCSV(sheet As Worksheet, rangeSpec As String, destPath As String) As Scripting.Dictionary</strong><br>Purpose: streaming export to CSV to avoid memory overload. <br>Behavior: iterate rows in batches, write to <code>destPath</code> append mode, and compute per-batch checksum. Return <code>filePath</code>, <code>batchesWritten</code>, <code>totalRows</code>, <code>checksum</code>. <br>Use-case: audit backups, bulk staging for transforms. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Internal helper: ApplyStagedToSheet(stagingWS As Worksheet, targetSheet As Worksheet, Optional commitMode As String = "inplace") As Scripting.Dictionary</strong><br>Purpose: apply staged updates atomically for a commit chunk. <br>Flow:<br>1. For each staged record, identify <code>targetAddress</code> and <code>afterValue</code> and use <code>modUtilities.SafeRangeWrite</code> to write value. <br>2. For performance group writes by contiguous ranges and set <code>Application.ScreenUpdating = False</code>, <code>Application.Calculation = xlCalculationManual</code>. <br>3. On write failure attempt retry policy and on persistent failure mark the record as <code>COMMIT_FAIL</code> with error code. <br>4. Return commit metrics: <code>rowsAttempted</code>, <code>rowsCommitted</code>, <code>rowsFailed</code>, <code>timeMs</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Internal helper: SchemaDiff(oldMeta As Scripting.Dictionary, newMeta As Scripting.Dictionary) As Scripting.Dictionary</strong><br>Purpose: compute human-friendly schema differences: added columns, removed columns, renamed columns (with heuristics), type changes, and formula differences. <br>Output: <code>added[]</code>, <code>removed[]</code>, <code>renamedPairs[]</code>, <code>typeChanges[]</code>, <code>safeToAutoApply</code> flag. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Internal helper: CreateForensicPack(runId As String, reason As String) As String</strong><br>Purpose: collect all artifacts associated with a run into a single forensic zip for incident handling. <br>Includes: <code>__Migration_History</code>, <code>__Migration_Backup_&lt;runId&gt;</code> snapshots, <code>__Fuzzy_Profile</code> entries for the run, <code>__GS_Metrics</code> entries, <code>Audit_Log</code> pre/post snapshots (sanitized as required), <code>migration_manifest.json</code>, <code>codeVersion</code>, <code>configSnapshot</code>, and <code>reproSteps.txt</code> describing exact command sequence to reproduce run. <br>Return: path to compressed forensic zip. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Detailed example migration scenario (end-to-end narrative)</strong><br>Goal: migrate <code>Audit_Log</code> from legacy flat schema to normalized JSON schema and add <code>rowChecksum</code> while ensuring PQ consumers continue to function during a transition window.<br>Step-by-step:<br>1. Developer prepares a manifest <code>m-20260219-AL</code> describing steps: snapshot audit, transform to normalized JSON, verify PQ compatibility, commit, and later remove legacy columns after retention window. <br>2. Operator executes dry-run: <code>DryRunMigration(manifest, runId=&#x27;sim-20260219-001&#x27;)</code>. The module stages transformed audit rows to <code>__Stage_Temp</code>, runs <code>VerifyMigration</code> which attempts to parse back JSON and compares values, and outputs an <code>ImpactReport</code> with <code>semanticParityPct=99.995%</code> and lists rows that need manual review. <br>3. Reviewer signs off (signature recorded by <code>modSignatures.RecordReviewerSignature</code>) because materiality is low. <br>4. Operator calls <code>EnsureSchema(targetVersion=&quot;1.4.0&quot;, runOptions={&quot;userId&quot;:&quot;opA&quot;})</code>. <code>CreateMigrationSnapshot</code> exports <code>Audit_Log</code> to <code>__Migration_Artifacts\m-20260219-AL\audit_backup_part_*.ndjson</code>. <br>5. <code>ApplyMigrationStep</code> runs step <code>s-002</code> transform in chunks of 2000 rows: each chunk created in staging, verified via <code>ComputeSheetChecksum</code> per-chunk and via spot-sample semantic checks, then <code>ApplyStagedToSheet</code> writes chunk atomically. <code>__Migration_History</code> appended per chunk. <br>6. After full commit <code>VerifyMigration</code> runs PQ refresh test; if PQ parse errors occur <code>RollbackMigration</code> is triggered and <code>ForensicPack</code> assembled. <br>7. If commit verified, <code>GenerateMigrationReport</code> and <code>ExportMigrationArtifacts</code> produce artifacts and manifest for DB team. Legacy columns are kept for retention period and removed in a separate non-blocking step after retention and notification. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Power Query (PQ) conceptual integration & transforms</strong><br>Guidance for PQ consumers and migration coordination:<br>1. Publish a <code>PQ_Compatibility_Report</code> listing impacted queries and recommended M-code patches. <br>2. Implement PQ conditional parsing: <code>if Record.HasFields(parseRow, &quot;beforeJSON&quot;) then Json.Document(parseRow[beforeJSON]) else LegacyMapping(parseRow)</code>. <br>3. Add <code>VerifyRowChecksum</code> PQ step that recomputes row checksum from parsed fields and compares to <code>rowChecksum</code> exported by <code>modMigration</code> to surface mismatches. <br>4. For incremental migration, provide a <code>MigrationStagingTable</code> in workbook or data source that PQ can source while migration in review. <br>5. For ML training or monitoring, export <code>componentBreakdown</code> and <code>explainVersion</code> as fields in the PQ output for traceability. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Conceptual DAX measures & BI checks for migration dashboards</strong><br>Examples to include in a migration dashboard for reviewers and ops:<br>1. <code>MigrationRowParity = DIVIDE([RowsMatched],[TotalRowsInSource])</code> — fraction of rows where parity checks passed. <br>2. <code>ChecksumMatchPct = DIVIDE([RowsWithChecksumMatch],[TotalRowsChecked])</code> — percent of rows whose recomputed checksum equals the included <code>rowChecksum</code>. <br>3. <code>AvgVerifyDeltaPct = AVERAGE(&#x27;MigrationVerification&#x27;[deltaPct])</code> — average percent delta across verified numeric fields. <br>4. <code>FailedVerificationCount = COUNTROWS(FILTER(&#x27;MigrationHistory&#x27;,&#x27;MigrationHistory&#x27;[status]=&quot;FAILED&quot;))</code>. <br>5. <code>DaysSinceLastSuccessfulMigration = DATEDIFF(MAX(&#x27;MigrationHistory&#x27;[completedAt]), NOW(), DAY)</code>. <br>Use these measures to set gating thresholds and trigger alerts when deviation increases beyond normal drift. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Governance, approvals & policy enforcement</strong><br>1. Migration runs exceeding <code>modConfig.MigrationHighRowThreshold</code> or <code>modConfig.MigrationHighMateriality</code> transition to <code>AWAITING_SIGNOFF</code>. They require at least one <code>Reviewer</code> and one <code>Admin</code> signature recorded in <code>migration_manifest.signoffs</code>. <br>2. Any destructive step (drop / delete) requires explicit <code>Admin</code> role and <code>two-factor</code> sign-off; the manifest should include <code>safetyWindow</code> and <code>retentionWindow</code> parameters. <br>3. Change control: every manifest and <code>migration_report</code> entry must be referenced in <code>Macro_ChangeLog</code> with <code>commitHash</code> and release notes. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Security & privacy controls</strong><br>1. Sensitive fields: any artifacts containing PII must be encrypted before export. <code>ExportMigrationArtifacts</code> supports encryption via external helper. <br>2. Access controls: only <code>Admin</code> or authorized system accounts may run <code>RollbackMigration</code> or <code>dropColumn</code> steps. <br>3. Audit & chain-of-custody: <code>ForensicPack</code> contains <code>hostMachine</code>, <code>userId</code>, and <code>timestamp</code> for every action; maintain archived copies in central immutable store. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>CI/CD & test harness integration</strong><br>1. Store migration manifests in source control under <code>migrations/</code> with manifest lint pre-commit checks. <br>2. CI pre-merge job runs <code>DryRunMigration</code> and <code>VerifyMigration</code> on sanitized sample workbook and compares outputs to golden baseline; fail on unexpected diffs. <br>3. Include <code>modTestingHarness</code> tests for migration: unit tests for <code>ComputeSheetChecksum</code>, integration tests for streaming transforms, and rollback test cases that ensure snapshot recovery. <br>4. Release gating: only signed artifacts with successful CI migration runs proceed to production migration. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Edge cases & mitigations</strong><br>1. Missing pre-step snapshot: abort migration and produce <code>ForensicPack</code>; do not proceed unless manual override with <code>FORCE_ACK</code> and documented risk. <br>2. PQ consumer breaks: detect by attempting PQ refresh (if accessible); on failure auto-revert the latest step and notify reviewers with <code>impactReport</code>. <br>3. Partial commit due to crash: use chunk-level checkpoint persisted in <code>__Run_Status</code> to resume or safely rollback committed chunks. <br>4. Interleaved user edits during migration: <code>EnsureSchema</code> attempts to acquire <code>RunLock</code>; if lock cannot be obtained, abort or require admin override. <br>5. Large audit volumes: use <code>SnapshotRangeToCSV</code> with streaming chunking and avoid in-memory loads. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Testing checklist (executable)</strong><br>Unit tests to cover:<br>1. <code>ValidateMigrationPlan</code> rejects invalid manifests and flags ambiguous renames. <br>2. <code>ComputeSheetChecksum</code> stable across format/locale variations. <br>3. <code>CreateMigrationSnapshot</code> produces files with matching checksums on repeated snapshot. <br>Integration tests:<br>1. Full dry-run of <code>MigrateAuditFormat</code> on sanitized dataset and confirm <code>ImpactReport</code> matches expected. <br>2. End-to-end apply + verify + rollback flow for a small manifest; guarantee return to original state. <br>Performance tests:<br>1. Stream transform of <code>Audit_Log</code> with production-like volume completes within memory and time targets. <br>Security tests:<br>1. Artifact export encryption validation and access rights enforcement. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Sample migration manifest (illustrative)</strong><br><code>{ &quot;manifestId&quot;:&quot;m-20260219-AL&quot;, &quot;targetVersion&quot;:&quot;1.4.0&quot;, &quot;codeVersion&quot;:&quot;git-abc123&quot;, &quot;createdBy&quot;:&quot;dev1&quot;, &quot;createdAt&quot;:&quot;2026-02-19T09:00:00Z&quot;, &quot;steps&quot;:[ { &quot;stepId&quot;:&quot;s-001&quot;,&quot;type&quot;:&quot;snapshot&quot;,&quot;scope&quot;:&quot;auditOnly&quot;,&quot;guard&quot;:&quot;NOT_EXISTS(__Migration_Backup_m-20260219-AL)&quot; }, { &quot;stepId&quot;:&quot;s-002&quot;,&quot;type&quot;:&quot;transform&quot;,&quot;module&quot;:&quot;migrateAuditFormat&quot;,&quot;inputs&quot;:{&quot;fieldMap&quot;:{&quot;InputName&quot;:&quot;beforeJSON.name&quot;,&quot;BeforeValA&quot;:&quot;beforeJSON.amounts.a&quot;}}, &quot;preconditions&quot;:[&quot;column InputName exists&quot;], &quot;postconditions&quot;:[&quot;column beforeJSON exists&quot;], &quot;rollback&quot;:&quot;s-rollback-002&quot; } ], &quot;signoffs&quot;:[], &quot;notes&quot;:&quot;&quot; }</code><br>Manifest rules: every step must include <code>guard</code> or be reversible; <code>preconditions</code> and <code>postconditions</code> explicit; <code>rollback</code> directive set for complex transforms. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Operational runbook (short steps)</strong><br>1. Pre-check: run CI tests, sign release artifact, ensure <code>modConfig</code> snapshot saved. <br>2. Dry-run: call <code>DryRunMigration</code> and produce <code>ImpactReport</code>. <br>3. Approval: gather reviewer signature via UI; record signature token. <br>4. Snapshot: <code>CreateMigrationSnapshot(runId, &quot;full&quot;)</code>. <br>5. Apply: <code>EnsureSchema(targetVersion, runOptions)</code> with <code>stopOnError=True</code>. <br>6. Verify: confirm <code>VerifyMigration</code> metrics and PQ compatibility. <br>7. Export report & artifacts, upload to secure archive, update <code>Macro_ChangeLog</code>. <br>8. Post-run: monitor BI parity dashboards for 48–72 hours before removing legacy columns. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Forensic & incident handling</strong><br>1. Automated on-failure: create <code>ForensicPack</code>, set <code>runStatus=INCIDENT</code>, restrict workbook changes, and notify the escalation group with <code>forensicBundlePath</code>. <br>2. Manual restore: use <code>RollbackMigration</code> with multi-signature approval only when <code>ForensicPack</code> analysis confirms safe restore path. <br>3. Preserve chain-of-custody: store <code>ForensicPack</code> in immutable storage and record access logs. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Developer notes & anti-patterns to avoid</strong><br>1. Do not perform large transforms entirely in-VBA memory for large audit tables — stream to CSV and apply staged writes. <br>2. Avoid destructive single-step deletes; prefer staged deprecation with retention windows. <br>3. Avoid mutable global state for migration runs; store run context explicitly and pass to functions to make runs re-entrant and testable. <br>4. Never modify existing <code>__Migration_History</code> rows; append-only semantics required. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Acceptance criteria for production migration</strong><br>1. Dry-run parity: <code>DryRunMigration</code> produces <code>ImpactReport</code> with <code>semanticParityPct &gt;= 99.9%</code> for sample set and reviewers signed off. <br>2. Successful commit: <code>EnsureSchema</code> completes with <code>status=COMPLETED</code> and <code>failedSteps=0</code>. <br>3. Verification: <code>VerifyMigration</code> reports <code>checksumMatchPct &gt;= 99.99%</code> for critical columns. <br>4. Rollback tested: <code>RollbackMigration</code> validated on staging with full restore. <br>5. Artifacts: <code>GenerateMigrationReport</code> and <code>ExportMigrationArtifacts</code> produced and stored in secure archive with checksums. </td></tr><tr><td data-label="Per-function technical breakdown — modMigration (VBA)"> <strong>Closing guidance (concise)</strong><br><code>modMigration</code> should be built as the controlled operations plane for schema & audit changes: manifest-driven, snapshot-first, stage-then-verify, commit-then-seal, and always auditable. Integrate PQ compatibility checks and DAX migration dashboards into reviewer paths and require signed releases before authorising production runs. Prioritise streaming transforms, per-step snapshots, and explicit rollback artifacts so every change is reversible and traceable. </td></tr></tbody></table></div><div class="row-count">Rows: 34</div></div><div class="table-caption" id="Table7" data-table="Docu_0203_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modSignatures (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modSignatures (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Module purpose (summary)</strong><br><code>modSignatures</code> supplies deterministic, auditable, and operationally-safe signature and checksum primitives for the UpdateHR+ orchestration. It provides: run-level seals, row-level checksums, reviewer signature capture, artifact manifest creation, local HMAC-style tokens for workbook-level tamper detection, integration hooks for external PKI/HSM signing, key lifecycle helpers, verification routines, exports for central audit ingestion, and policy validation gates used pre-commit. The design prioritises reproducibility, explainability (reason strings and versioning), light-weight internal hashing for operational detection, and optional external signing for legal-grade immutability. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>High-level design principles & constraints</strong><br>1. Deterministic canonicalisation: canonical strings are built in fixed field order and keys sorted for JSON objects to avoid non-determinism. <br>2. Separation of concerns: <code>modSignatures</code> never mutates business data (except appending signature audit rows); it computes tokens and writes signature records to dedicated sheets only. <br>3. Two-tier trust model: lightweight internal tokens (VBA HMAC/hash) for operational tamper detection; external PKI/HSM integration for cryptographic non-repudiation when required. <br>4. Minimal surface area for secrets: by default the module expects keys to be fetched at runtime from secure stores (enterprise key vault) via an integration wrapper; never store private keys in workbook cells for production. <br>5. Audit-first design: every computed token or verification emits an audit record or warning row for forensic trace. <br>6. Role & policy aware: signing and rotation operations require roles and produce multi-actor approvals when policy demands. <br>7. Interoperable artifacts: manifests and signature records use JSON-friendly schema to work with Power Query and ingestion into central audit DBs. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Public surface (function catalogue; each function detailed later)</strong><br>1. <code>ComputeRunSignature(runId As String) As String</code> — compute and persist run-level signature token. <br>2. <code>ComputeRowChecksum(runId As String, auditRowIndex As Long) As String</code> — compute per-audit-row checksum. <br>3. <code>ComputeCompositeSeal(runId As String) As String</code> — aggregate row checksums into a run seal. <br>4. <code>RecordReviewerSignature(runId As String, reviewerId As String, rowId As Long, decisionHash As String, Optional meta As Scripting.Dictionary) As String</code> — capture reviewer approval signature token and persist. <br>5. <code>VerifyRunSignature(runId As String, signatureToken As String) As Scripting.Dictionary</code> — verify run-level signatures with diagnostic detail. <br>6. <code>VerifyAuditRowChecksum(runId As String, auditRowIndex As Long) As Scripting.Dictionary</code> — verify single-row checksum and return diagnostics. <br>7. <code>ComputeArtifactManifest(artifactPath As String, runId As String, Optional options As Scripting.Dictionary) As Scripting.Dictionary</code> — produce canonical manifest for export artifacts (files). <br>8. <code>SignArtifact(manifest As Scripting.Dictionary, Optional useExternalPKI As Boolean) As Scripting.Dictionary</code> — sign manifest using local HMAC or external PKI; return signature metadata. <br>9. <code>VerifyArtifactSignature(manifest As Scripting.Dictionary) As Scripting.Dictionary</code> — verify manifest signature and file checksums. <br>10. <code>GenerateKeypair(keyType As String, Optional keyParams As Scripting.Dictionary) As Scripting.Dictionary</code> — helper for dev key creation; primarily advisory for HSM. <br>11. <code>LoadPublicKey(keyId As String) As Scripting.Dictionary</code> — load publicKey metadata used for verification. <br>12. <code>RotateSigningKey(newKeyId As String, adminId As String) As Scripting.Dictionary</code> — coordinate rotation with audit trail. <br>13. <code>ExportSignaturesCSV(runId As String, destPath As String) As Boolean</code> — export signature rows. <br>14. <code>ValidateSignaturePolicy(runId As String, policyId As String) As Scripting.Dictionary</code> — verify pre-commit signature policy (dual-signature, PKI requirement, thresholds). <br>15. <code>StampTimestamp() As String</code> — deterministic UTC timestamp + per-run monotonic counter. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ComputeRowChecksum</strong><br>Purpose: produce deterministic, per-audit-row checksum that captures the canonical content of an audit row for tamper detection.<br>Signature: <code>ComputeRowChecksum(runId As String, auditRowIndex As Long) As String</code>.<br>Inputs & expected context:<br>1. <code>auditRowIndex</code> is index into <code>Audit_Log</code> for <code>runId</code>. Caller ensures row exists and fields are canonical. <br>Processing behaviour & canonicalisation rules:<br>1. Read canonical columns in fixed order: <code>[runId, rowId, actionType, inputRowHash, beforeJSON, afterJSON, candidateId, confidence, gsRef, status, userId, timestamp]</code>. <br>2. Canonicalise JSON blobs: parse JSON, sort object keys alphabetically, remove insignificant whitespace, reserialize in stable form. <br>3. Normalize textual fields: collapse NBSP, convert to NFC unicode form if configured, trim. <br>4. Concatenate fields with field separator <code>|</code> and compute digest using <code>modConfig.SignHashAlgo</code> (prefer SHA256 when external helper available; otherwise SHA1 fallback). <br>5. Return lowercase hex digest string; write <code>rowChecksum</code> value back to <code>Audit_Log</code> row as a side-effect when caller requests persistent storage. <br>Edge behaviour & errors:<br>• On JSON parse failure, produce <code>ROW_CHECKSUM_JSON_ERROR</code> diagnostic and return <code>ERR_JSON</code>. <br>• On missing columns, return <code>ERR_SCHEMA</code> and emit an audit warning. <br>Use in larger flows: <code>ComputeRowChecksum</code> is used by <code>ComputeCompositeSeal</code> and verification routines. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ComputeCompositeSeal</strong><br>Purpose: derive an ordered run-level seal (aggregate checksum) sensitive to content and order of audit rows for a run. Used by run sealing and as canonical proof for manifests.<br>Signature: <code>ComputeCompositeSeal(runId As String) As String</code>.<br>Algorithm and determinism:<br>1. Query <code>Audit_Log</code> for rows where <code>runId</code> equals input, order by <code>rowId</code> ascending (deterministic). <br>2. For each row ensure <code>rowChecksum</code> present; if missing compute via <code>ComputeRowChecksum</code>. Append <code>rowChecksum</code> tokens into a buffer string in the row order. <br>3. Compute final digest: <code>composite = Hash(bufferString, algo=modConfig.SignHashAlgo)</code>. Optionally compute HMAC if <code>modConfig.SealHMACKey</code> available to produce <code>hmac(composite)</code>. <br>4. Persist <code>composite</code> into <code>__Audit_Seals</code> with <code>runId</code>, <code>compositeChecksum</code>, <code>hashAlgo</code>, <code>hmacFlag</code>, <code>timestamp</code>. <br>Verification note: recomputing the composite requires same row order & identical row checksums to match. <br>Failure modes: if any row fails checksum recompute, <code>ComputeCompositeSeal</code> returns <code>ERR_ROW_MISMATCH</code> with a list of mismatched <code>rowId</code>s for forensics. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ComputeRunSignature</strong><br>Purpose: build a deterministic canonical string for run-level signing and produce a signature token, either internal (HMAC/hash) or external (PKI). This token is the run's tamper-evidence token used in manifests and operator UI.<br>Signature: <code>ComputeRunSignature(runId As String, Optional useExternal As Boolean = False) As Scripting.Dictionary</code>.<br>Inputs & canonical payload:<br>1. Gather run metadata: <code>runId</code>, <code>initiatingUser</code>, <code>startTime</code>, <code>endTime</code>, <code>codeVersion</code>, <code>configSnapshotId</code>, <code>compositeSeal</code> (from <code>ComputeCompositeSeal</code>). <br>2. Construct canonical payload string in fixed order: <code>runId|initiatingUser|startTime|endTime|codeVersion|configSnapshotId|compositeSeal</code>. <br>Signing modes:<br>1. <strong>Internal token (default)</strong>: compute digest <code>hex = Hash(payload, algo=modConfig.SignHashAlgo)</code> and prepend token namespace <code>INT-&lt;hex&gt;</code>. Set <code>keyId = &quot;internal&quot;</code>. <br>2. <strong>External PKI</strong>: send canonical payload to <code>SignExternalPayload(payload)</code> wrapper, get back <code>{ signatureToken, keyId, signerCertChain, signatureAlgo }</code> and store returned metadata. <br>Return dictionary: <code>{ signatureToken, keyId, hashAlgo, timestamp, signerInfo }</code> and side-effect: persist record to <code>__Signatures</code> and append <code>RUN_SIGNATURE</code> row to <code>Audit_Log</code> with <code>signatureToken</code>. <br>Operational: <code>modCoreEngine.SealRun</code> calls this post-commit to seal run. <br>Failure & fallback: if external signing fails and <code>modConfig.ExternalSigningRequired=True</code> abort commit; if optional, fall back to internal token but record <code>PKI_FALLBACK</code> in audit and send operator alert. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: RecordReviewerSignature</strong><br>Purpose: record an explicit human reviewer confirmation as a tamper-evident, auditable signature with optional dual-approval behaviour and metadata.<br>Signature: <code>RecordReviewerSignature(runId As String, reviewerId As String, rowId As Long, decisionHash As String, Optional meta As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Validation steps and policy enforcement:<br>1. Validate reviewer role and permissions using <code>modConfig.UserRoles</code>. If insufficient, return <code>ERR_ROLE</code>. <br>2. Validate row existence and that the row is in expected state for signature (e.g., <code>status = REVIEW_PENDING</code>). <br>3. Canonical payload: <code>runId|rowId|decisionHash|reviewerId|timestamp|codeVersion|configSnapshotId</code>. <br>4. If policy requires <code>requireReviewerMfa</code>, UI-layer must have verified MFA before call; <code>RecordReviewerSignature</code> asserts <code>meta(&quot;mfaValidated&quot;)=True</code> or returns <code>ERR_MFA</code>. <br>Signing & persistence:<br>1. If <code>modConfig.UseExternalSigningForReviewer=True</code> then call external signing service; else compute internal signature token <code>SIG-INT-&lt;hex&gt;</code>. <br>2. Append signature record to <code>__Signatures</code>: fields <code>runId,rowId,signatureToken,keyId,signerId,actionType,metaJson,timestamp</code>. <br>3. Append <code>Audit_Log</code> row with <code>actionType=REVIEW_SIGN</code> including <code>signatureToken</code> and <code>meta</code>. <br>Dual-approval: if <code>meta(&quot;requiresDualApproval&quot;)=True</code>, mark signature entry <code>PENDING_SECOND_SIGNATURE</code> and block <code>CommitRun</code> until second signature recorded; the second signature must reference the original signature token to form an approval pair. <br>Return: dictionary containing <code>signatureToken, status, auditRowRef</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: VerifyRunSignature</strong><br>Purpose: perform verification of run-level signature tokens, supporting both internal tokens and external PKI tokens, and return detailed diagnostics for forensics.<br>Signature: <code>VerifyRunSignature(runId As String, signatureToken As String) As Scripting.Dictionary</code>.<br>Verification flow:<br>1. Find signature record in <code>__Signatures</code> for <code>runId</code> + <code>signatureToken</code>. If not found return <code>{&quot;verified&quot;:False,&quot;reason&quot;:&quot;NOT_FOUND&quot;}</code>. <br>2. Recompute <code>compositeSeal</code> via <code>ComputeCompositeSeal</code> and rebuild canonical payload (same ordering used when signing). <br>3. If <code>keyId=&quot;internal&quot;</code>, recompute hash and compare token; match → verified True, else false. <br>4. If external, call <code>VerifyExternalSignature(signatureToken, payload, keyId)</code> wrapper which validates cryptographic signature against public key or certificate chain. Return verify result plus signer cert fingerprint. <br>5. Diagnostic return dictionary keys: <code>verified(Boolean)</code>, <code>reason</code> (e.g., <code>OK</code>,<code>MISMATCH</code>,<code>EXPIRED_KEY</code>,<code>NOT_FOUND</code>,<code>PKI_ERROR</code>), <code>expectedHash</code>, <code>actualToken</code>, <code>keyId</code>, <code>verifyMs</code>, <code>diagnostics</code> (detailed trace). <br>Side-effects: always append <code>SIG_VERIFY</code> audit entry with diagnostics (do not mutate run or audit rows). </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: VerifyAuditRowChecksum</strong><br>Purpose: verify the checksum of an individual audit row and produce actionable diagnostics for any mismatch.<br>Signature: <code>VerifyAuditRowChecksum(runId As String, auditRowIndex As Long) As Scripting.Dictionary</code>.<br>Steps & outputs:<br>1. Recompute <code>rowChecksum</code> via <code>ComputeRowChecksum</code>. <br>2. Compare to persisted <code>Audit_Log.rowChecksum</code>. If match return <code>{&quot;verified&quot;:True,&quot;rowId&quot;:..., &quot;note&quot;:&quot;OK&quot;}</code>. <br>3. On mismatch return <code>{&quot;verified&quot;:False,&quot;rowId&quot;:..., &quot;expected&quot;: &lt;recomputed&gt;, &quot;stored&quot;: &lt;persisted&gt;, &quot;diffs&quot;:[list of fields differing], &quot;recommendedAction&quot;:&quot;createForensicPack&quot;}</code>. <br>Diagnostics include truncated JSON excerpts of <code>beforeJSON</code> and <code>afterJSON</code> to help operators detect corruption (avoid dumping raw PII in telemetry; redact if <code>modConfig.RedactPII=True</code>). </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ComputeArtifactManifest</strong><br>Purpose: generate a canonical manifest describing one or more artifact files (CSV/ndjson/zip) to be signed and shipped to external parties or central audit DBs.<br>Signature: <code>ComputeArtifactManifest(artifactDirOrFilePath As String, runId As String, Optional options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Manifest structure & rules:<br>1. <code>manifestId</code> (UUID), <code>runId</code>, <code>createdAt</code> (StampTimestamp), <code>codeVersion</code>, <code>configSnapshotId</code>, <code>files</code> (array of <code>{fileName, fileSize, rowCount (optional), checksum, checksumAlgo}</code>), <code>manifestChecksum</code>, <code>notes</code>. <br>Canonical ordering: sort <code>files</code> by <code>fileName</code> lexicographically to ensure stable manifest checksums. <br>Checksum algorithm: use <code>modConfig.ArtifactChecksumAlgo</code> (prefer <code>SHA256</code> where external helper available; fallback to workbook algorithm). <br>Implementation details:<br>1. For CSV/ndjson compute row counts (streamed processing to avoid memory blowup). <br>2. Compute checksums per file via streaming read and persist file metadata. <br>3. Concatenate file checksums in canonical order and compute <code>manifestChecksum</code>. <br>Return: full manifest dictionary and optionally write <code>manifest.json</code> to artifact directory. <br>Audit: append <code>ARTIFACT_MANIFEST_CREATED</code> row in <code>Audit_Log</code> referencing <code>manifestId</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: SignArtifact</strong><br>Purpose: sign a computed manifest with either a local HMAC or external PKI and return a signed manifest record appropriate for downstream verification.<br>Signature: <code>SignArtifact(manifest As Scripting.Dictionary, Optional useExternalPKI As Boolean = False) As Scripting.Dictionary</code>.<br>Modes & tokens:<br>1. <strong>Internal HMAC Mode</strong>: if <code>useExternalPKI=False</code> the function uses <code>modConfig.SealHMACKey</code> (retrieved from secure store wrapper) to compute <code>HMAC(manifestChecksum)</code>. Token format: <code>INT-HMAC-&lt;hex&gt;</code>. <code>keyId</code> recorded as <code>internal-hmac-vX</code>. <br>2. <strong>External PKI Mode</strong>: call <code>SignExternalPayload(manifestCanonicalString)</code> wrapper (mutual TLS/REST) which returns <code>{signatureToken, keyId, signerCertFingerprint, signatureAlgo, signedAt}</code>. <br>Return dictionary fields: <code>signatureToken</code>, <code>signatureAlgo</code>, <code>keyId</code>, <code>signedAt</code>, <code>manifestChecksum</code>, <code>verificationHints</code> (e.g., <code>publicKeyId</code>, <code>certChainRef</code>). <br>Side-effects: append <code>ARTIFACT_SIGNED</code> row to <code>Audit_Log</code> and write <code>manifest.json</code> and <code>manifest.signature</code> files in artifact directory. <br>Governance: if manifest contains material changes > <code>modConfig.PKIRequiredThreshold</code>, and external signing is not used, the function must return <code>ERR_PKI_REQUIRED</code> and not produce an internal token. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: VerifyArtifactSignature</strong><br>Purpose: verify that manifest file checksums match file bytes and that the signature token matches the manifest checksum using either internal HMAC verification or external PKI verification.<br>Signature: <code>VerifyArtifactSignature(manifest As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Process & outputs:<br>1. Recompute file checksums for each file listed and compare to manifest <code>files[].checksum</code>; produce <code>fileMismatches</code> array if any. <br>2. Recompute <code>manifestChecksum</code> and compare to <code>manifest.manifestChecksum</code>. <br>3. If <code>keyId</code> indicates internal, recompute HMAC and compare; if external, call <code>VerifyExternalSignature(signatureToken, manifestCanonicalString, keyId)</code> wrapper which returns verification status and cert diagnostics. <br>4. Return dictionary <code>{&quot;verified&quot;:Boolean,&quot;fileMismatches&quot;:[], &quot;signatureVerified&quot;:Boolean,&quot;diagnostics&quot;:String}</code> and write <code>ARTIFACT_VERIFY_RESULT</code> row to <code>Audit_Log</code>. <br>Failure modes: generate <code>ForensicPack</code> instruction and include steps for re-import or quarantine. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: GenerateKeypair / Key management helpers</strong><br>Purpose: provide lifecycle helpers for key management and define interfaces to HSM / PKI systems.<br>Signature: <code>GenerateKeypair(keyType As String, Optional keyParams As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Notes & governance:<br>1. For production, this function only generates a metadata wrapper and returns instructions to generate keys in HSM; it must not generate or store private keys in the workbook. <br>2. For dev/test, allows generation of ephemeral keypairs and storing publicKey in <code>__Keys</code> (flagged <code>devOnly=True</code>). <br>Key management helpers:<br>1. <code>LoadPublicKey(keyId As String)</code> — returns public key and certificate chain metadata. <br>2. <code>ListAvailablePublicKeys()</code> — list keys registered in <code>__Keys</code>. <br>3. <code>RotateSigningKey(newKeyId As String, adminId As String)</code> — requires admin role; append <code>KEY_ROTATION</code> row to <code>Macro_ChangeLog</code>, set <code>activeKeyId</code> in <code>__Run_Config</code>, archive previous key metadata, and require multi-admin sign-off if policy demands. <br>Key rotation policy: rotation must preserve verification of historic signatures by retaining archived public keys and associating run-level <code>keyId</code> snapshot with each run. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ExportSignaturesCSV</strong><br>Purpose: export signature records to CSV for ingestion into central audit database or long-term storage.<br>Signature: <code>ExportSignaturesCSV(runId As String, destPath As String) As Boolean</code>.<br>Output schema: <code>runId, rowId, signatureToken, keyId, signerId, actionType, timestamp, hashAlgo, manifestChecksum, explainVersion</code>. <br>Security: optionally compress and encrypt output using external helper. Operation must validate write permissions and return <code>ERR_WRITE</code> if not permitted. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: ValidateSignaturePolicy</strong><br>Purpose: apply signature-related policy checks prior to commit — used by <code>modCoreEngine.CommitRun</code> to enforce dual-approval, PKI requirements, or minimum signer counts for material runs.<br>Signature: <code>ValidateSignaturePolicy(runId As String, policyId As String) As Scripting.Dictionary</code>.<br>Policy model & checks:<br>1. Policies stored in <code>__SignaturePolicies</code> table: fields <code>policyId</code>, <code>minReviewerSignatures</code>, <code>requirePKIIfMaterial(true/false)</code>, <code>materialityThresholdAmount</code>, <code>requireAdminSignOff</code> (bool). <br>2. For each policy, compute metrics: <code>materialRows</code>, <code>materialAmount</code>, <code>reviewSignCount</code>, <code>adminSignCount</code>. <br>3. Return <code>{satisfied:Boolean, failures:Collection, recommendedActions:Collection}</code>. If not satisfied <code>CommitRun</code> must block and surface <code>failures</code> to operator UI and append <code>SIGNATURE_POLICY_BLOCK</code> to <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Function: StampTimestamp</strong><br>Purpose: provide stable UTC timestamps and per-run monotonic event counters used by all signature payloads so replays remain deterministic.<br>Signature: <code>StampTimestamp() As String</code>.<br>Behavior:<br>1. Returns <code>YYYY-MM-DDTHH:MM:SSZ|seq</code> where <code>seq</code> increments per-call and persists in <code>__TimestampCounter</code> keyed by <code>runId</code>. <br>2. Ensures no two events in same run share identical timestamp+seq on platforms with coarse clock resolution. <br>Note: timestamp format chosen for compatibility with PQ ISO parsing and BI tooling. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Integration points & expected call graph</strong><br>1. <code>modCoreEngine.RunUpdateHR</code> — at run end calls <code>ComputeCompositeSeal</code> → <code>ComputeRunSignature</code> and demands <code>ValidateSignaturePolicy</code> before committing. <br>2. <code>modAudit.AppendAuditRow</code> — requests <code>ComputeRowChecksum</code> before append (or <code>modSignatures</code> can be called in a post-append hook). <br>3. <code>frmReviewerUI</code> / <code>modSuggestionUI</code> — call <code>RecordReviewerSignature</code> when reviewer approves; UI must enforce MFA and role checks before invoking. <br>4. <code>modAuditExportHelpers.PackageExport</code> — calls <code>ComputeArtifactManifest</code> and <code>SignArtifact</code> prior to producing ZIP for handoff. <br>5. <code>modBatchProcessing</code> — when chunk-commits occur, module may compute chunk manifests and call <code>SignArtifact</code> per chunk for chunk-level forensic traceability. <br>6. <code>modTelemetry</code> — logs PKI availability, signature error rates, and verification times reported by <code>modSignatures</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Manifest JSON schema (recommended canonical)</strong><br>Top-level fields and intent:<br>1. <code>manifestId</code> : string (uuid). <br>2. <code>runId</code> : string. <br>3. <code>createdAt</code> : string (ISO UTC). <br>4. <code>codeVersion</code>, <code>configSnapshotId</code> : string. <br>5. <code>files</code> : array of objects <code>{ fileName, fileSize, rowCount?, checksum, checksumAlgo }</code> sorted lexicographically by <code>fileName</code>. <br>6. <code>manifestChecksum</code> : string. <br>7. <code>signature</code> : object <code>{ signatureToken, keyId, signatureAlgo, signedAt }</code>. <br>8. <code>notes</code> : optional. <br>Store <code>manifest.json</code> inside exported ZIP alongside <code>manifest.signature</code> to give downstream verifier everything in one package. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Power Query (PQ) conceptual transforms & ingestion recipes</strong><br>1. <strong>Ingest signatures manifest</strong>: Source = <code>manifest.json</code> from artifact ZIP. Use <code>Json.Document</code> to parse. Expand <code>files</code> into a table and keep <code>manifestChecksum</code> at row level. Add column <code>runId</code>. <br>2. <strong>Row-level verification table</strong>: If artifact contains <code>Audit_Log</code> CSV with <code>rowChecksum</code> column, join PQ <code>Audit_Log</code> rows with <code>manifest.files</code> entries (matching by <code>runId</code> and <code>rowOrdinal</code> or <code>postingId</code>) and compute <code>rowChecksumMatch = rowChecksum = manifestChecksumLookup</code>. Use PQ computed columns to mark mismatches. <br>3. <strong>Signature dashboard</strong>: flatten <code>__Signatures</code> export; produce summary table: <code>signerId, keyId, signatureCount, verifyFailures</code>. <br>4. <strong>Forensics PQ recipe</strong>: load <code>manifest.json</code>, load <code>Audit_Log</code> export, and load <code>__Signatures</code>. Build <code>ForensicPack</code> PQ table for investigators with join keys and computed mismatch flags. <br>Implementation note: ensure PQ transforms sort and canonicalize inputs the same way as <code>modSignatures</code> to avoid false positives. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Conceptual DAX measures for verification & operations</strong><br>1. <code>SignedRuns = DISTINCTCOUNT(Signatures[runId])</code>.<br>2. <code>PctRunsSealed = DIVIDE([SignedRuns], DISTINCTCOUNT(Runs[runId]))</code>.<br>3. <code>FailedSignatureVerifications = COUNTROWS(FILTER(SignatureVerifications, SignatureVerifications[verified]=FALSE))</code>.<br>4. <code>AverageVerifyMs = AVERAGE(SignatureVerifications[verifyMs])</code>.<br>5. <code>ArtifactIntegrityRate = DIVIDE(CALCULATE(COUNTROWS(Artifacts), Artifacts[fileMismatch]=0), COUNTROWS(Artifacts))</code>.<br>Use in operations dashboards and run-level drilldowns to quickly find suspect runs. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Explainability, provenance & audit integration</strong><br>1. Every signature record includes <code>explainVersion</code> and <code>hashAlgo</code> to enable deterministic re-verification after algorithm evolution. <br>2. When generating signatures, <code>modSignatures</code> persists <code>codeVersion</code> and <code>configSnapshotId</code> with each signature row so replays are reproducible. <br>3. For reviewer signatures include <code>meta</code> capturing MFA status, deviceId (if available), and human rationale (short) stored as redacted if <code>modConfig.RedactPII=True</code>. <br>4. For artifact signs include <code>manifestChecksum</code> and <code>files[]</code> checksums in the signed payload so downstream verifiers can assert object-level integrity. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Security, privacy & operational policies (recommended)</strong><br>1. Never store private keys in workbook; use key vault/HSM integration. <br>2. For PII within signed payloads: prefer hashing/salting sensitive fields before inclusion and record salt handling policy in <code>manifest.notes</code>. <br>3. Require <code>modConfig.UseExternalSigningForMaterial</code> true when <code>totalMaterialAmount</code> > <code>modConfig.PKIRequiredThreshold</code>. <br>4. Key rotation: require <code>minAdminApprovals</code> and log rotation in <code>__KeyHistory</code>; archive old public keys to allow verifying historical signatures. <br>5. Retention: export <code>__Audit_Seals</code> daily to central, immutable storage and remove secret material from local workbook within retention policy windows. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Testing & acceptance criteria (detailed)</strong><br>Unit tests:<br>1. Deterministic checksum vectors: fixed <code>Audit_Log</code> golden rows produce expected <code>rowChecksum</code> (match golden hex). <br>2. Composite seal stability: the golden set of row checksums yields known <code>compositeChecksum</code>. <br>3. Signing round-trip (internal): <code>ComputeRunSignature</code> produces token and <code>VerifyRunSignature</code> returns verified True. <br>4. Manifest signing & verify: manifest signed (internal) verifies with <code>VerifyArtifactSignature</code>. <br>Integration tests:<br>1. External PKI integration: with test PKI endpoint ensure <code>SignArtifact</code> receives signature and <code>VerifyArtifactSignature</code> validates using <code>LoadPublicKey</code>. <br>2. Key rotation test: rotate key and verify older run signatures still verify using archived public key. <br>3. Policy enforcement test: runs above material thresholds require PKI and block commit if PKI not available; tests assert <code>CommitRun</code> blocked with <code>SIGNATURE_POLICY_BLOCK</code>. <br>Performance tests:<br>1. File checksum streaming must handle artifact sizes up to enterprise target (e.g., 1GB) with memory usage within Excel host limits; validate streaming read. <br>2. Signature verification latency reported to telemetry; ensure <code>AvgVerifyMs</code> within SLA. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Example narratives & sequences</strong><br>Example 1 — normal run seal (internal token):<br>1. <code>modCoreEngine</code> completes commit and calls <code>ComputeCompositeSeal</code> obtaining <code>compHash</code>. <br>2. <code>ComputeRunSignature</code> builds canonical payload and computes <code>INT-A1B2...</code> token via HMAC/SHA1. <br>3. <code>__Signatures</code> appended and <code>Audit_Log</code> row added with <code>actionType=RUN_SIGNATURE</code>. <br>4. Export artifact manifest includes <code>manifestChecksum</code> and <code>signatureToken</code>. <br>Example 2 — PKI sign for migration artifact:<br>1. <code>ComputeArtifactManifest</code> computes per-file checksums and <code>manifestChecksum</code>. <br>2. <code>SignArtifact(..., useExternalPKI=True)</code> posts to internal PKI service; returns <code>RSA-SHA256</code> signature and <code>keyId=prod-signing-2025</code>. <br>3. ZIP includes <code>manifest.json</code> and <code>manifest.signature</code>. DB ingestion verifies signature before accept. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Edge cases & mitigation</strong><br>1. <strong>Missing <code>rowChecksum</code></strong>: <code>ComputeCompositeSeal</code> will compute missing checksums automatically and note rows needing manual review if JSON canonicalisation fails. <br>2. <strong>External PKI outage</strong>: circuit-breaker toggles <code>modConfig.ExternalSigningAvailable=False</code> and <code>SignArtifact</code> falls back to internal signing if policy permits or blocks if policy mandates PKI. <br>3. <strong>Workbook corruption</strong>: verification failures produce <code>ForensicPack</code> instructions and lock the run for investigation (prevent further commits). <br>4. <strong>Time drift</strong>: when verifying external signatures, compare signer timestamp and local time; if drift > <code>modConfig.MaxClockDriftSec</code> produce <code>TIMESTAMP_DRIFT</code> warning. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Operational runbook snippets (practical operator steps)</strong><br>1. Pre-deploy checklist: ensure <code>activeKeyId</code> is production PKI key; run <code>ComputeRunSignature</code> on test run and verify token; ensure <code>__Signatures</code> sheet present. <br>2. On export: <code>ComputeArtifactManifest</code> → <code>SignArtifact</code> → produce <code>manifest.json</code> and <code>manifest.signature</code> → <code>ExportSignaturesCSV</code> for central ingestion; send package via secure channel. <br>3. Verification failure: run <code>VerifyArtifactSignature</code> on manifest; on failure generate <code>ForensicPack</code> and contact security with the pack link; do not re-run commit until resolved. <br>4. Key rotation: follow <code>RotateSigningKey</code> flow with at least two admin sign-offs and update <code>__Run_Config.activeKeyId</code>. Append rotation entry to <code>Macro_ChangeLog</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Power Query (PQ) example transforms for signatures & manifests</strong><br>1. <strong>Import manifest.json</strong>: <code>Source = Json.Document(File.Contents(&quot;manifest.json&quot;))</code> → expand <code>files</code> with <code>Table.ExpandRecordColumn</code>. <br>2. <strong>Normalize checksums</strong>: <code>Text.Lower([checksum])</code> and parse <code>checksumAlgo</code>. <br>3. <strong>Join with Audit Log</strong>: <code>Merge</code> manifest runId with <code>Audit_Log</code> export; compute <code>rowChecksumMatch</code> and <code>fileMismatchFlag</code>. <br>4. <strong>Generate verification table</strong>: create <code>Verification</code> PQ output with <code>runId,manifestId,fileName,checksum,verified</code> to feed BI. <br>Implementation detail: PQ step must sort <code>files</code> by <code>fileName</code> to mirror canonical ordering used in manifest checksum. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Conceptual DAX measures for signature monitoring</strong><br>1. <code>TotalSignedManifests = COUNTROWS(Manifests)</code>.<br>2. <code>ManifestVerificationRate = DIVIDE([ManifestsVerified],[TotalSignedManifests])</code>.<br>3. <code>PctRunsWithPKISign = DIVIDE(CALCULATE(COUNTROWS(Signatures), Signatures[keyId] &lt;&gt; &quot;internal&quot;), [SignedRuns])</code>.<br>4. <code>AvgSignatureLatencyMs = AVERAGE(SignatureVerifications[verifyMs])</code>.<br>Use these to monitor PKI availability and integrity trends. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Testing & acceptance checklist (deliverable ready)</strong><br>1. Golden vectors for <code>ComputeRowChecksum</code> and <code>ComputeCompositeSeal</code> included in repo and run in CI nightly. <br>2. Dev test harness for internal signature generation & verification. <br>3. Staging PKI integration test passing and recorded. <br>4. <code>ExportSignaturesCSV</code> output validated by central audit ingestion process. <br>5. Security review sign-off verifying no private keys stored in workbook. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Implementation notes & pitfalls to avoid</strong><br>1. Do not serialize JSON without stable key ordering — different serializers produce different digests. <br>2. Avoid storing private keys on workbook; always use key vault/HSM wrappers. <br>3. Avoid using non-deterministic orders (e.g., dictionaries without ordering) when building canonical strings; always sort keys and rows. <br>4. Beware Excel string encoding differences: normalise to UTF-8/NFC before hashing. <br>5. Ensure streaming file reads for checksums to avoid out-of-memory on large artifacts. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Business & compliance guidance</strong><br>1. For compliance (SOX/ISO), prefer external PKI signing of migration artifacts and export manifests to immutable central repository. <br>2. Keep run-level <code>manifest.json</code> and <code>manifest.signature</code> for retention policy; store in central archive with access controls. <br>3. Use <code>ValidateSignaturePolicy</code> to enforce organizational rules about dual approval and PKI use for material changes. </td></tr><tr><td data-label="Per-function technical breakdown — modSignatures (VBA)"> <strong>Final summary (operational takeaway)</strong><br><code>modSignatures</code> is the module that turns strongly-typed, deterministic run and artifact state into tamper-evident tokens and signed manifests. For operational value: use internal tokens for everyday tamper detection, integrate PKI/HSM for legal-grade signing of migration artifacts, always persist code/config snapshots with signatures for reproducibility, and export sealed manifests to central immutable audit storage as part of your CI/CD and run governance. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><div class="table-caption" id="Table8" data-table="Docu_0203_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modMateriality** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modMateriality</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Module purpose (concise)</strong><br><code>modMateriality</code> implements deterministic materiality calculations, policy enforcement, escalation routing, evidence packaging, and run-level aggregation for UpdateHR+. It converts numeric deltas and contextual signals into auditable flags, buckets, and enforcement actions used to gate commits, route reviewer work, and provide evidence for BI and forensic review. The module is configuration-driven, deterministic, and designed to export structured artifacts for Power Query and DAX analysis. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Design principles & constraints</strong><br>1. Deterministic behavior: identical inputs + config snapshot = identical outputs and flags recorded in <code>Audit_Log</code>.<br>2. Explainability: every decision emits a compact <code>rationale</code> string and a structured <code>componentBreakdown</code> object suitable for audit and PQ ingestion.<br>3. Config-driven: thresholds, weights, currency mapping, and escalation routes come from <code>modConfig</code> snapshot persisted per run.<br>4. Performance: O(1) per-row evaluation, streaming aggregates for large runs, and chunked summary generation to avoid memory spikes.<br>5. Separation of concerns: reads staging and staging metadata but never mutates primary business sheets; writes flags into staging <code>ApplyDescriptor</code> and audit only. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Public API (summary)</strong><br>1. <code>EvaluateMateriality(rowData As Scripting.Dictionary, runContext As Scripting.Dictionary) As Scripting.Dictionary</code> — core per-row evaluator, returns flags and rationale.<br>2. <code>ComputeMaterialityScore(rowData As Scripting.Dictionary, config As Scripting.Dictionary) As Double</code> — scalar scoring combining absolute, relative, and context multipliers.<br>3. <code>ClassifyMaterialityBucket(score As Double, config As Scripting.Dictionary) As String</code> — bucket mapping to <code>Auto</code>, <code>Monitor</code>, <code>Escalate</code>, <code>Critical</code>.<br>4. <code>MaterialityPolicyEnforcer(runId As String, stagingWS As Worksheet) As Scripting.Dictionary</code> — pre-commit gate applying business rules and blocking/queuing actions.<br>5. <code>AggregateMateriality(runId As String, stagingRange As Range) As Scripting.Dictionary</code> — run-level summaries (top-N exposures, aggregates by org/cost center).<br>6. <code>GenerateMaterialityReport(runId As String, options As Scripting.Dictionary) As String</code> — create reviewer-friendly evidence report (sheet/CSV/ndjson).<br>7. <code>PersistMaterialityFlags(runId As String, stagingWS As Worksheet) As Boolean</code> — persist flags into staging and append audit rows.<br>8. <code>RecommendMaterialityThresholds(historyRange As Range, targetControl As Scripting.Dictionary) As Scripting.Dictionary</code> — analytics to recommend thresholds given historical data.<br>9. <code>SimulateMaterialImpact(runId As String, samplePostingsRange As Range, applyDescriptors As Collection) As Scripting.Dictionary</code> — non-destructive simulation applying descriptors to posting samples.<br>10. <code>OverrideMaterialFlag(runId As String, rowId As Long, overrideMeta As Scripting.Dictionary) As Boolean</code> — controlled override flow that records approver and rationale. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — EvaluateMateriality</strong><br>Signature: <code>EvaluateMateriality(rowData, runContext) As Dictionary</code><br>Inputs:<br>- <code>rowData</code> expected keys: <code>rowId</code>, <code>inputRowHash</code>, <code>candidateId</code> (opt), <code>proposedAmount</code>, <code>priorAmount</code> (or <code>baseline</code>), <code>currency</code>, <code>costCenter</code>, <code>orgUnit</code>, <code>employeeId</code> (opt), <code>changeType</code> (salary/budget/headcount/reclass), <code>effectiveDate</code>, <code>evidenceRefs</code> (array).<br>- <code>runContext</code> expected keys: <code>runId</code>, <code>configSnapshot</code>, <code>userId</code>, <code>runTime</code>, optional <code>fxTable</code> for cross-currency conversions.<br>Processing steps (deterministic pipeline):<br>1. Normalize numeric values: convert <code>proposedAmount</code> and <code>priorAmount</code> to Double; handle missing values by flags (<code>baselineMissing</code>).<br>2. Convert currencies if needed using <code>fxTable</code> to a run-base currency for consistent comparisons; if FX missing, set <code>currencyWarning</code> flag and default to conservative comparison method.<br>3. Compute <code>absDelta = Abs(proposed - prior)</code> and <code>signedDelta = proposed - prior</code> for directional policies.<br>4. Compute <code>relDelta = If(prior&lt;&gt;0, absDelta / Abs(prior), specialRelFallback)</code> where <code>specialRelFallback</code> is <code>absDelta / config.AbsoluteReference</code> or <code>1.0</code> depending on policy; set <code>relFallback</code> boolean when prior missing or zero.<br>5. Determine contextual multipliers: fetch <code>orgMultiplier</code> from <code>config.EffectiveOrgMultipliers</code> (fallback 1.0), <code>costCenterMultiplier</code> if configured, <code>changeTypeMultiplier</code> from <code>config.ChangeTypeMultipliers</code> (differentiate salary, headcount, budget reclass), and <code>employeeSeniorityFactor</code> derived from employee tenure when <code>employeeId</code> present and tenure available.<br>6. Call <code>ComputeMaterialityScore</code> with those components to produce <code>materialScore</code> normalized to 0..1.<br>7. Map <code>materialScore</code> to a <code>materialBucket</code> via <code>ClassifyMaterialityBucket</code>, then set <code>isMaterial</code> boolean and <code>requiresReviewer</code> based on bucket and thresholds (e.g., <code>Monitor</code> may be auto-apply but flagged for monitoring; <code>Escalate</code> and <code>Critical</code> always require review).<br>8. Compose <code>rationaleString</code> (concise human readable), and create <code>componentBreakdown</code> object listing intermediate numbers: <code>absDelta</code>, <code>relDelta</code>, <code>orgMultiplier</code>, <code>typeMultiplier</code>, <code>employeeFactor</code>, <code>scoreComponents</code>.<br>Outputs:<br>- Dictionary keys: <code>rowId</code>, <code>inputRowHash</code>, <code>absDelta</code>, <code>relDelta</code>, <code>materialScore</code>, <code>materialBucket</code>, <code>isMaterial</code>, <code>requiresReviewer</code>, <code>escalationRoute</code>, <code>rationaleString</code>, <code>componentBreakdown</code>, <code>timestamp</code>.<br>Audit: the calling module must append the returned dictionary (or serialized JSON) to <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — ComputeMaterialityScore</strong><br>Signature: <code>ComputeMaterialityScore(rowData, config) As Double</code><br>Purpose: combine normalized absolute and relative impacts plus contextual modifiers into a single scalar usable for binning.<br>Algorithm patterns (configurable):<br>1. Base normalizations:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) <code>normAbs = Min(absDelta / config.AbsoluteReference, 1.0)</code> where <code>AbsoluteReference</code> is typically a large monetary benchmark chosen by finance (e.g., median monthly payroll for an org).<br>&nbsp;&nbsp;&nbsp;&nbsp;b) <code>normRel = Min(relDelta / config.RelativeReference, 1.0)</code> where <code>RelativeReference</code> might be 0.10 to normalize relative spikes to 100% at 10% change.<br>2. Compose weighted sum:<br>&nbsp;&nbsp;&nbsp;&nbsp;<code>rawScore = wAbs*normAbs + wRel*normRel</code> where weights <code>wAbs</code>, <code>wRel</code> are from <code>config.MaterialityWeights</code> and sum to 1 or are normalized later.<br>3. Apply contextual multipliers and caps:<br>&nbsp;&nbsp;&nbsp;&nbsp;<code>adjustedScore = rawScore * (1 + (orgMultiplier-1) * wOrgInfluence) * (1 + (typeMultiplier-1)*wTypeInfluence)</code> where <code>wOrgInfluence</code> & <code>wTypeInfluence</code> cap the influence of multipliers and keep adjustedScore within [0,1].<br>4. Special-case transforms:<br>&nbsp;&nbsp;&nbsp;&nbsp;- Headcount changes convert FTE deltas to monetary equivalence: <code>monetaryDelta = fteDelta * avgSalaryByOrg</code> before normalization.<br>&nbsp;&nbsp;&nbsp;&nbsp;- Retroactive adjustments apply an aging factor (older effectiveDate reduces score or flags specially).<br>5. Final scaling and clamp: <code>score = Clamp(adjustedScore, 0, 1)</code>; optionally map 0..1 to 0..100 scale if configured.<br>Return: numeric <code>score</code> with intermediate values stored in <code>componentBreakdown</code> for audit. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — ClassifyMaterialityBucket</strong><br>Signature: <code>ClassifyMaterialityBucket(score, config) As String</code><br>Default bucket mapping (configurable):<br>- <code>Auto</code> = score < <code>config.AutoThreshold</code> (e.g., 0.25).<br>- <code>Monitor</code> = <code>AutoThreshold</code> ≤ score < <code>config.ReviewerThreshold</code> (e.g., 0.25–0.5).<br>- <code>Escalate</code> = <code>ReviewerThreshold</code> ≤ score < <code>config.CriticalThreshold</code> (e.g., 0.5–0.85).<br>- <code>Critical</code> = score ≥ <code>config.CriticalThreshold</code> (e.g., ≥0.85).<br>Return: bucket label plus <code>bucketRationale</code> (e.g., <code>&quot;score 0.78 &gt;= 0.5 reviewer threshold =&gt; Escalate&quot;</code>).<br>Note: bucket mapping includes operational overrides: if <code>absDelta</code> passes <code>config.AbsoluteHardStop</code> then forcibly <code>Critical</code> regardless of score. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — MaterialityPolicyEnforcer</strong><br>Signature: <code>MaterialityPolicyEnforcer(runId, stagingWS) As Dictionary</code><br>Purpose: enforce run-level and per-row policies derived from material flags before commit.<br>Enforcement checks and actions (common set):<br>1. <strong>Critical block</strong>: if any staged row has bucket <code>Critical</code> and no valid override recorded, set run <code>status=BLOCKED</code> and populate <code>blockedReason</code> listing rowIds and amounts.<br>2. <strong>Dual approval</strong>: if <code>TotalCriticalAmount</code> > <code>config.DualApprovalAmount</code>, require two approvers with recorded <code>RecordReviewerSignature</code> entries before allowing commit. <br>3. <strong>Daily auto-apply caps</strong>: compute <code>todayAutoAppliedAmount</code> from <code>__DailyApplyTotals</code> and compare adding planned auto applies from staging; if caps exceeded, demote excess auto-applications to <code>Monitor</code> and mark <code>requiresReviewer=True</code>. <br>4. <strong>Aggregate materiality detection</strong>: sum deltas by <code>costCenter</code> and if aggregated sum crosses <code>config.AggregateMaterialityThreshold</code>, mark all involved rows for review even if individual rows were <code>Auto</code>. <br>5. <strong>Escalation routing</strong>: map <code>materialType</code> & <code>amount</code> to roles per <code>config.EscalationRouteMap</code> and produce <code>requiredApprovals</code> list with role contact metadata. <br>Behaviour:<br>- Return dictionary: <code>status</code> (<code>OK</code>, <code>AWAITING_REVIEW</code>, <code>BLOCKED</code>), <code>blockedRows</code>, <code>actions</code> (array of per-row enforcement actions), <code>requiredApprovals</code> (list), <code>notes</code>.<br>- Write enforcement decisions into staging <code>ApplyDescriptor</code> columns <code>enforcementAction</code> and append audit rows for traceability. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — AggregateMateriality</strong><br>Signature: <code>AggregateMateriality(runId, stagingRange) As Dictionary</code><br>Purpose: compute run-level summaries and top exposures used by dashboards and reviewer UI.<br>Steps:<br>1. Stream staging rows instead of loading entire sheet to avoid memory issues: read by chunk and accumulate aggregates. <br>2. Compute metrics: <code>TotalRows</code>, <code>AutoRows</code>, <code>MonitorRows</code>, <code>EscalateRows</code>, <code>CriticalRows</code>, <code>TotalAbsDeltaByBucket</code>, <code>TopNByAbsDelta</code>, <code>TopNByScore</code>, <code>MaterialByOrgUnit</code>, <code>MaterialByCostCenter</code>, <code>DailyAutoApplyEstimate</code>. <br>3. Produce <code>ReviewerLoadEstimate</code> as count of rows requiring hands-on review, plus estimated time (rows * avgReviewTimeSec from config). <br>4. Return dictionary with all aggregates and write <code>__Run_Summary</code> sheet and <code>Audit_Log</code> run-level artifact. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — GenerateMaterialityReport</strong><br>Signature: <code>GenerateMaterialityReport(runId, options) As String</code><br>Purpose: produce reviewer evidence package sized for human consumption and auditor ingestion.<br>Report content recommendations:<br>- Header: <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, <code>generatedBy</code>, <code>timestamp</code>.<br>- Per-row evidence: <code>rowId</code>, <code>inputRowHash</code>, <code>candidateId</code>, <code>proposed</code>, <code>prior</code>, <code>absDelta</code>, <code>relDelta</code>, <code>score</code>, <code>materialBucket</code>, <code>requiresReviewer</code>, <code>escalationRoute</code>, <code>componentBreakdownJSON</code>, <code>evidenceRefs</code> (sample posting ids), <code>simulationRef</code> (if simulation run).<br>Options:<br>- <code>format</code>: <code>&quot;sheet&quot;</code> (create <code>__Material_Report_&lt;runId&gt;</code>), <code>&quot;csv&quot;</code>, or <code>&quot;ndjson&quot;</code>.<br>- <code>includePostings</code>: boolean include sample postings (may increase file size).<br>- <code>topNContext</code>: integer number of nearby postings to include per row.<br>Output: returns artifact path or sheet name. Append a <code>MaterialReportGenerated</code> audit row with artifact reference. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — PersistMaterialityFlags</strong><br>Signature: <code>PersistMaterialityFlags(runId, stagingWS) As Boolean</code><br>Purpose: write computed flags into staging and ensure audit entries are appended in an idempotent manner.<br>Behavior:<br>1. For each staged row with a computed material object, write fields <code>materialScore</code>, <code>materialBucket</code>, <code>isMaterial</code>, <code>requiresReviewer</code>, <code>escalationRoute</code>, <code>materialRationale</code> into staging columns. <br>2. Append an <code>Audit_Log</code> row with <code>actionType=&quot;MaterialFlagSet&quot;</code> containing <code>componentBreakdown</code> JSON and <code>runId</code>. <br>3. Idempotency: skip rows that already have <code>materialFlagTimestamp</code> matching current <code>runId</code> unless <code>forceRecompute=True</code>. <br>4. Return <code>True</code> if all writes succeed; on partial failure write <code>MaterialityPersistError</code> row and return <code>False</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — RecommendMaterialityThresholds</strong><br>Signature: <code>RecommendMaterialityThresholds(historyRange, targetControl) As Dictionary</code><br>Purpose: analytical helper that sweeps thresholds against historical confirmed adjustments to recommend operational thresholds consistent with risk appetite.<br>Procedure:<br>1. Input <code>historyRange</code> should include confirmed decisions (labelled data): <code>inputRowHash</code>, <code>appliedCandidateId</code>, <code>confirmedBy</code>, <code>labelIsMaterial</code> (1/0), and original <code>componentBreakdown</code>. <br>2. Recompute <code>materialScore</code> for each historical row using current weighting and compute rank position of actually confirmed candidate to align behavior. <br>3. Sweep threshold grid (e.g., 0.10..0.99 step 0.01) capturing <code>TP</code>, <code>FP</code>, <code>FN</code>, <code>TN</code> for each threshold, then compute <code>precision</code>, <code>recall</code>, <code>F1</code>, and expected <code>reviewerLoad</code> (rows below threshold).<br>4. Return recommended thresholds: <code>autoApplyThreshold</code> (smallest threshold meeting <code>targetControl.targetPrecision</code>), <code>reviewThreshold</code> (balance of recall and acceptable reviewer load), <code>criticalThreshold</code> (e.g., percentile for top X material exposures). <br>Outputs for PQ/BI: also return arrays for plotting precision/recall, ROC-like curve, and reviewer load vs threshold. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — SimulateMaterialImpact</strong><br>Signature: <code>SimulateMaterialImpact(runId, samplePostingsRange, applyDescriptors) As Dictionary</code><br>Purpose: non-destructive preview of bulk impact across sample historical postings to show disclosure-level and period-level effects.<br>Algorithm:<br>1. Join posted sample rows to descriptors by <code>postingSignature</code> or cost-center mapping. <br>2. For each posting hit compute <code>beforeAmount</code>, <code>afterAmount</code> (applying ApplyDescriptor logic), <code>delta</code>, accumulate per <code>DisclosureBucket</code> and <code>Period</code> (month/year). <br>3. Compute <code>DeltaPct</code> relative to <code>DisclosureBucket</code> baseline and set <code>MaterialFlag</code> when delta crosses <code>config.MaterialityThresholds</code>. <br>4. Return structured artifact with <code>perBucketSummaries</code>, <code>TopImpacts</code>, and <code>evidenceRefs</code> for each material cell. Also store <code>__Sim_&lt;runId&gt;</code> sheet. <br>Use-case: reviewer uses this to reason about systemic impacts of many small adjustments. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Function details — OverrideMaterialFlag</strong><br>Signature: <code>OverrideMaterialFlag(runId, rowId, overrideMeta) As Boolean</code><br>Behavior and controls:<br>1. Validate <code>overrideMeta.overrideBy</code> role against <code>modConfig.ApproverRoles</code> and <code>overrideMeta.overrideType</code>. <br>2. Check <code>modConfig.OverrideLimits</code> to ensure approver allowed to change specific bucket or amount ranges. <br>3. Persist override record into <code>__Overrides</code> with <code>beforeFlag</code>, <code>afterFlag</code>, <code>justification</code>, <code>signatureHash</code>, <code>expiry</code> and append <code>Audit_Log</code> row <code>actionType=&quot;MaterialOverride&quot;</code>. <br>4. If override accepted, adjust staging <code>ApplyDescriptor</code> flags and return <code>True</code>. Otherwise return <code>False</code> and record <code>OverrideRejected</code> with reason. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Integration & orchestration notes</strong><br>1. <code>modCoreEngine</code> must call <code>EvaluateMateriality</code> for each row before staging an ApplyDescriptor and call <code>MaterialityPolicyEnforcer</code> before <code>CommitRun</code> to determine commit gating. <br>2. <code>modSuggestionUI</code> and <code>frmReviewerUI</code> consume <code>GenerateMaterialityReport</code> and <code>AggregateMateriality</code> to display context and evidence to human reviewers and to capture overrides via <code>OverrideMaterialFlag</code>. <br>3. All outputs must persist <code>configSnapshot</code> and <code>codeVersion</code> for reproducibility and forensic replay. <br>4. <code>modAudit</code> receives all materiality decisions appended as <code>MaterialFlagSet</code>, <code>MaterialReportGenerated</code>, <code>MaterialOverride</code>, and <code>MaterialPolicyEnforcement</code> audit rows. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Power Query (PQ) conceptual workflow (consumption of materiality artifacts)</strong><br>1. Source: <code>Audit_Log</code> export (ndjson/CSV) produced by <code>modAudit.ExportAudit</code>. <br>2. Parse <code>componentBreakdown</code> JSON into flat columns using <code>Json.Document</code> and <code>Record.ToTable</code>. <br>3. Create derived columns: <code>DeltaPct = Number.Round([absDelta] / nullIfZero([priorAmount]), 4)</code> and <code>MonetaryImpactBucket = if [absDelta] &gt; threshold then &quot;High&quot; else &quot;Low&quot;</code>. <br>4. Build a dimension table <code>MaterialityBuckets</code> used in BI and join to <code>Audit_Log</code> by <code>materialBucket</code>. <br>5. For simulation outputs, parse <code>__Sim_&lt;runId&gt;</code> sheet and expand per-disclosure aggregations for trend analysis. <br>6. Provide a parameterized PQ query to re-bucket scores using alternate thresholds for exploratory tuning; keep <code>runId</code> and <code>configSnapshot</code> to ensure reproducibility. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Conceptual DAX measures (operational monitoring & policy KPIs)</strong><br>1. <code>TotalMaterialAmount = SUMX(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[isMaterial]=TRUE()), &#x27;RunDetail&#x27;[absDelta])</code>.<br>2. <code>PctCritical = DIVIDE( COUNTROWS(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[materialBucket]=&quot;Critical&quot;)), COUNTROWS(&#x27;RunDetail&#x27;) )</code>.<br>3. <code>ReviewerLoadEstimate = COUNTROWS(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[requiresReviewer]=TRUE()))</code>.<br>4. <code>AutoApplyBlockedByCaps = COUNTROWS(FILTER(&#x27;RunDetail&#x27;, &#x27;RunDetail&#x27;[enforcementAction]=&quot;DEMOTE_TO_REVIEW&quot;))</code>.<br>5. <code>MaterialityTrend12m = CALCULATE([TotalMaterialAmount], DATESINPERIOD(Calendar[Date], MAX(Calendar[Date]), -12, MONTH))</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Examples & worked narratives</strong><br>Example A — Salary uplift (clear Critical):<br>- Inputs: prior=60,000; proposed=75,000 => <code>absDelta=15,000</code>; <code>prior&gt;0</code> => <code>relDelta=0.25</code>. <br>- Config: <code>AbsoluteReference=10,000</code>, <code>RelativeReference=0.1</code>, weights wAbs=0.7, wRel=0.3. <br>- <code>normAbs=1.0</code>, <code>normRel=1.0</code>, <code>rawScore=1.0</code>, <code>orgMultiplier=1.1</code> => <code>score ≈ 1.0</code> => <code>Critical</code>. <br>- Enforcement: block commit, route to <code>PayrollLead</code> + require <code>FinanceDirector</code> sign-off due to <code>DualApprovalAmount</code> breach. <br>Example B — Small GL reclass (Auto):<br>- Inputs: prior=2,000; proposed=2,100 => <code>absDelta=100</code>; <code>relDelta=0.05</code>. <br>- Score computed ~0.07 => <code>Auto</code>. If daily auto caps not exceeded, staged apply allowed and annotated in audit. <br>Example C — Aggregation escape pattern:<br>- Many small adjustments each below auto threshold, but aggregated by cost center total to 150k > <code>AggregateMaterialityThreshold</code> => <code>MaterialityPolicyEnforcer</code> escalates all involved rows to review to prevent slicing-around-controls. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Telemetry & metrics to capture</strong><br>1. <code>materialEvalTimeMs</code> per row and percentiles (p50/p95). <br>2. <code>materialScoreDistribution</code> histogram (bins). <br>3. <code>autoApplyBlockedByCap</code> count. <br>4. <code>overrideRate</code> fraction of material flags manually overridden. <br>5. <code>escalationLatency</code> median elapsed time from staging to reviewer sign-off. <br>Emit aggregated telemetry to <code>__Telemetry</code> and, if configured, to external telemetry endpoint via <code>modTelemetry</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Test cases & acceptance criteria (executable tests)</strong><br>Unit tests (examples):<br>1. <code>EvaluateMateriality</code> returns <code>score=0</code> and <code>Auto</code> bucket when proposed==prior. <br>2. Boundary checks: if <code>score == AutoThreshold</code> exactly, classify deterministically into <code>Monitor</code> or <code>Auto</code> per config tie rule. <br>3. Currency conversion: same numeric delta in different currencies yields same normalized comparisons when <code>fxTable</code> present. <br>Integration tests:<br>1. Run-level enforcement: when a <code>Critical</code> row present and no overrides, <code>MaterialityPolicyEnforcer</code> must return <code>status=BLOCKED</code>. <br>2. Aggregate detection: when multiple small rows sum to above aggregate threshold, they must be flagged for review. <br>Performance tests:<br>1. Evaluate 100k rows in chunks; measure average <code>EvaluateMateriality</code> time and ensure memory usage stays within acceptable bounds. <br>Regression tests:<br>1. Threshold recommendation stability: run <code>RecommendMaterialityThresholds</code> on canonical dataset; results within tolerance over multiple runs. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Edge cases & mitigations (detailed)</strong><br>1. <strong>Missing baseline/prior</strong>: mark <code>baselineMissing=True</code>, compute <code>score</code> using absolute normalization and set <code>requiresReviewer=True</code> if <code>absDelta</code> > a conservative fallback; log reason. <br>2. <strong>Currency mismatches</strong>: if FX rates absent, conservative fallback to higher material classification and <code>currencyWarning=True</code> in rationale. <br>3. <strong>Retroactive/dated adjustments</strong>: age-adjust multiplier or require explicit reviewer sign-off for backdated effective dates beyond <code>config.MaxRetroDays</code>. <br>4. <strong>Split / multi-target actions</strong>: compute both aggregate materiality and per-target; require split descriptor and per-target reviewer instruction if any per-target delta exceeds per-target thresholds. <br>5. <strong>Data-quality anomalies</strong>: if evidenceRefs missing or malformed, set <code>evidenceMissing</code> flag and require reviewer verification. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Governance & compliance notes</strong><br>1. Persist <code>configSnapshot</code> with each run and include <code>configVersion</code> and <code>codeVersion</code> in audit to enable regulatory replay. <br>2. All overrides require recorded <code>signatureHash</code> and <code>justification</code>. <br>3. For high-assurance environments, export material artifacts to central immutable audit DB and keep local workbook audit as operational trace only. <br>4. Maintain <code>Macro_ChangeLog</code> with code changes, threshold changes, and sign-off for production changes. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Power Query (PQ) recipe (developer-friendly)</strong><br>1. Import <code>Audit_Log</code> export (ndjson). <br>2. Use <code>Json.Document</code> to parse <code>componentBreakdown</code> and expand into columns <code>absDelta</code>, <code>relDelta</code>, <code>score</code>, <code>materialBucket</code>. <br>3. Build <code>MaterialSummary</code> by grouping on <code>runId</code> and <code>materialBucket</code> to compute counts and sums. <br>4. Parameterize <code>AutoThreshold</code>, <code>ReviewerThreshold</code> to allow interactive re-bucketing for analysts. <br>5. Export <code>MaterialReport</code> as a dataset consumed by Power BI; include <code>runId</code> and <code>artifactPath</code> for traceability. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Conceptual DAX examples (expanded)</strong><br>1. <code>TotalMaterialAmount = SUMX(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[isMaterial]=TRUE()), &#x27;RunDetail&#x27;[absDelta])</code>.<br>2. <code>PctCritical = DIVIDE(CALCULATE(COUNTROWS(&#x27;RunDetail&#x27;), &#x27;RunDetail&#x27;[materialBucket]=&quot;Critical&quot;), COUNTROWS(&#x27;RunDetail&#x27;))</code>.<br>3. <code>ReviewerLoadEstimate = COUNTROWS(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[requiresReviewer]=TRUE()))</code>.<br>4. <code>DualApprovalNeeded = IF([TotalCriticalAmount] &gt; VALUES(Config[DualApprovalAmount]), TRUE(), FALSE())</code>.<br>5. <code>MaterialityByOrg = SUMMARIZE(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[orgUnit],&quot;MaterialAmount&quot;,SUM(&#x27;RunDetail&#x27;[absDelta]))</code> then convert to visuals. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Operational runbook snippets</strong><br>1. Pre-run: ensure <code>modConfig</code> snapshot and <code>fxTable</code> current; confirm <code>Macro_ChangeLog</code> shows no recent materiality weight changes. <br>2. Run: after staging complete, run <code>AggregateMateriality</code>, review <code>Top10ByAbsDelta</code> and <code>GenerateMaterialityReport</code> for flagged rows. <br>3. Review: reviewers examine <code>MaterialReport</code>, exercise <code>OverrideMaterialFlag</code> only with justifications; dual-approval enforced where required. <br>4. Post-commit: export <code>MaterialReport</code> and <code>Audit_Log</code> to central audit store per retention policy and mark run closed. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Implementation tips & pitfalls</strong><br>1. Avoid wide in-memory collections for large runs — stream aggregates and write intermediate state to hidden sheets for resiliency. <br>2. Always snapshot <code>configSnapshot</code> per run to avoid silent behavior drift when config changes. <br>3. Do not rely solely on <code>score</code> — incorporate absolute caps and business rules to catch large-dollar anomalies that normalized scores could understate. <br>4. Ensure all overrides are audited and that UI requires reason and approver identity. <br>5. Provide analysts PQ exports to test thresholds before changing live config. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Acceptance criteria checklist (deliverable)</strong><br>1. All public functions implemented with stable signatures and documented param/return conventions. <br>2. Deterministic behavior verified by unit/regression tests; <code>EvaluateMateriality</code> reproducible. <br>3. Policy enforcer correctly blocks commits per config and requires approvals. <br>4. Audit completeness: every material flag decision and override emits a complete <code>componentBreakdown</code> JSON and persisted <code>configSnapshot</code>. <br>5. Performance: meets SLA for target volume with chunked aggregation. <br>6. PQ and DAX examples parse and return expected KPI values for sample runs. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Appendix — sample rationale & componentBreakdown JSON (schema)</strong><br>Example structure (conceptual, not code):<br><code>{ &quot;absDelta&quot;: 12345.67, &quot;relDelta&quot;: 0.215, &quot;normAbs&quot;: 1.0, &quot;normRel&quot;: 1.0, &quot;orgMultiplier&quot;: 1.25, &quot;typeMultiplier&quot;: 1.0, &quot;employeeFactor&quot;: 0.95, &quot;rawScore&quot;: 0.98, &quot;adjustedScore&quot;: 0.78, &quot;materialBucket&quot;: &quot;Escalate&quot;, &quot;escalationRoute&quot;: &quot;PayrollLead&quot;, &quot;rationale&quot;: &quot;absDelta=12,345; rel=21.5%; orgMult=1.25 =&gt; score=0.78 =&gt; Escalate&quot; }</code><br>Store this compressed JSON in <code>Audit_Log</code> and expand in PQ for analytics. </td></tr><tr><td data-label="Per-function technical breakdown — modMateriality (VBA)"> <strong>Final recommendations for rollout</strong><br>1. Pilot with conservative thresholds and full audit enabled; monitor <code>overrideRate</code> and <code>precision</code> on a labeled sample. <br>2. Provide analysts with scheduled <code>RecommendMaterialityThresholds</code> outputs and PQ parameterization to tune thresholds with evidence. <br>3. Establish SOP for override approvals and forensic pack generation. <br>4. After stable pilot, progressively relax auto-apply thresholds according to measured precision and business tolerance. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table9" data-table="Docu_0203_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modImpactSimulation** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modImpactSimulation</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Module purpose (concise)</strong><br><code>modImpactSimulation</code> provides a deterministic, non-destructive simulation engine for ApplyDescriptor-driven changes. It builds representative samples, applies mapping and adjustment descriptors, captures row-level before/after state and evidence, computes disclosure-style aggregates and materiality flags, exports canonical artifacts for review and migration, and assembles forensic packs. The module is designed for auditability, replayability, and BI-friendly exports (Power Query / DAX). </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Design principles & invariants</strong><br>1. Non-destructive: never mutate primary production sheets; operate on copies (in-memory arrays or hidden simulation sheets).<br>2. Deterministic ordering: sort and process rows in a stable order (<code>postingDate</code>, then <code>postingId</code>) to guarantee reproducible results. <br>3. Provenance: every simulated action records <code>runId</code>, <code>applyId</code>, <code>inputRowHash</code>, <code>evidenceRef</code> and <code>codeVersion</code>. <br>4. Idempotency: identical inputs + config produce identical artifacts; use <code>configSnapshot</code> and <code>seed</code> persisted with artifacts. <br>5. Performance-first: prefer 2D <code>Variant</code> arrays and chunked writes; avoid COM calls in inner loops. <br>6. Privacy-first: default to hashed posting ids in external artifacts unless explicit PII permission. <br>7. Explainability: produce <code>componentBreakdown</code> and <code>rationale</code> per apply for audit and ML retraining. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Public API — function list (high level)</strong><br>1. <code>SimulateRunPreview(runId As String, simulateOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — orchestrator, full-run simulation and report generation. <br>2. <code>BuildSimulationSample(sampleSpec As Scripting.Dictionary) As Scripting.Dictionary</code> — construct representative sample using configurable strategies: <code>random</code>, <code>stratified</code>, <code>recentBias</code>, <code>full</code>. <br>3. <code>ApplyDescriptorToSample(applyDesc As Scripting.Dictionary, sampleRef As Scripting.Dictionary, Optional evidenceLimit As Long)</code> — deterministic application of a single descriptor to the sample, returning detail diffs and evidence. <br>4. <code>RunWhatIfAdjustments(simSheetRef As Scripting.Dictionary, adjustments As Collection, Optional recalcOptions As Scripting.Dictionary)</code> — ephemeral Calculator adjustments and capture of derived outputs, fully reversible. <br>5. <code>ComputeDisclosureAggregates(simSheetRef As Scripting.Dictionary, groupKeys As Collection, periodKey As String) As Scripting.Dictionary</code> — group-level aggregation and materiality detection. <br>6. <code>ExportSimulationCSV(runId As String, destFolder As String, Optional formatOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — canonical export (aggregates CSV, detail ndjson, evidence CSV, manifest). <br>7. <code>ValidateSimulationArtifacts(runId As String) As Scripting.Dictionary</code> — artifact integrity and checksum validation. <br>8. <code>CreateForensicPack(runId As String, destPath As String, Optional options As Scripting.Dictionary) As Boolean</code> — assemble full forensic bundle for incident handling. <br>9. <code>ReplaySimulation(runId As String, replayOptions As Scripting.Dictionary)</code> — deterministic replay using persisted manifest and descriptors for QA and audit diffs. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: SimulateRunPreview — orchestrator (detailed)</strong><br>Purpose: top-level flow that executes a full simulation and produces ImpactReport artifacts.<br>Signature: <code>SimulateRunPreview(runId, simulateOptions) As Dictionary</code>.<br>Inputs — typical keys in <code>simulateOptions</code> (must validate):<br>• <code>sampleSpec</code> — dictionary specifying <code>sourceSheet</code>, <code>method</code> (<code>random | stratified | recentBias | full</code>), <code>sampleSize</code>, <code>periodFrom</code>, <code>periodTo</code>, <code>stratifyBy</code> field.<br>• <code>applyDescriptors</code> — collection of descriptors (can be staging buffer or candidate suggestions).<br>• <code>groupKeys</code> — collection of aggregation keys for disclosure (e.g., <code>[&quot;DisclosureBucket&quot;,&quot;CostCenter&quot;]</code>).<br>• <code>periodKey</code> — field used for period grouping (e.g., <code>postingPeriod</code>).<br>• <code>evidenceLimit</code> — max rows to attach per descriptor (default 10).<br>• <code>dryRun</code> — boolean: when True do not persist hidden workbook sheets (operate purely in memory if possible).<br>Processing pipeline (strict sequence to ensure determinism):<br>1. <strong>Pre-validate</strong> inputs using <code>ValidateSimulationSpec</code> (verify source sheets exist, canonical columns present, groupKeys non-empty). <br>2. <strong>Create run manifest</strong>: build <code>runManifest = { runId, userId, timestampUtc, codeVersion, configSnapshot, seed }</code> and persist to <code>__SimManifest_&lt;runId&gt;</code> or return in dictionary for dry runs. <br>3. <strong>Build sample</strong>: call <code>BuildSimulationSample(sampleSpec)</code> — returns <code>sampleRef</code> (sheet name or in-memory array, rowCount, columnMap). Use <code>SimInMemoryLimit</code> config to decide between memory vs sheet mode. <br>4. <strong>Apply descriptors</strong>: iterate <code>applyDescriptors</code> in deterministic sorted order (<code>applyId</code> lexicographic). For each descriptor call <code>ApplyDescriptorToSample</code>. Append per-descriptor result to <code>__SimDetail_&lt;runId&gt;</code> and store per-descriptor summary in <code>__SimSummary_&lt;runId&gt;</code>. Write <code>SIMULATE_APPLY</code> audit rows with matchedCount and delta. <br>5. <strong>Compute aggregates</strong>: call <code>ComputeDisclosureAggregates(sampleRef, groupKeys, periodKey)</code> producing <code>ImpactAggregates</code> sheet and summary. <br>6. <strong>Validation & checksums</strong>: run <code>ValidateSimulationArtifacts(runId)</code> to compute and save sheet checksums. <br>7. <strong>Export artifacts</strong>: call <code>ExportSimulationCSV(runId, destFolder, formatOptions)</code> to serialize artifacts. <br>8. <strong>Finalize</strong>: write <code>SIMULATE_FINISH</code> audit row and return <code>ImpactReport</code> dictionary containing artifact paths, top material groups, per-descriptor deltas, and manifest checksum. <br>Design notes:<br>- Keep all per-run caches keyed by <code>runId</code> and clear at the end of function or on failure. <br>- If an error occurs during descriptor application, capture diagnostics and continue to next descriptor when <code>simulateOptions(&quot;continueOnError&quot;)=True</code>; otherwise rollback in-memory and surface error. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: BuildSimulationSample — sampling & shaping</strong><br>Purpose: create a representative, auditable sample target for simulation processing.<br>Signature: <code>BuildSimulationSample(sampleSpec) As Dictionary</code>.<br>Supported sampling methods and their implementation details:<br>1. <code>random</code> — uniform random sample from <code>sourceSheet</code> restricted to date range and optional filters. Use seeded PRNG (<code>manifest.seed</code>) for reproducibility. Implementation: read the relevant table into a 2D <code>Variant</code> array, compute random indices, copy into <code>__Sim_&lt;runId&gt;</code> or return as array. <br>2. <code>stratified</code> — sample proportionally across a grouping field (e.g., <code>DisclosureBucket</code>); compute group sizes and sample from each group proportionally but enforce <code>minPerGroup</code> to include rare/critical groups. This avoids missing material but rare buckets. <br>3. <code>recentBias</code> — weight sampling toward recent periods; apply exponential decay weights to date bins. <br>4. <code>full</code> — copy entire table; only allowed when <code>sampleSize</code> is null and <code>modConfig.AllowFullSample</code>=True. <br>Output contract (dictionary):<br>- <code>sheetName</code> or <code>inMemory</code> flag, <code>rowCount</code>, <code>colHeaders</code> array, <code>colIndexMap</code> (colName -> index), <code>checksum</code> (crc32 or stronger), <code>mode</code> (<code>memory|sheet</code>). <br>Validation and precondition checks:<br>- Ensure canonical columns exist: <code>postingId</code>, <code>postingDate</code>, <code>amount</code>, <code>costCenter</code>, <code>disclosureBucket</code>. If missing, return validation error object and log to <code>Audit_Log</code>. <br>Performance notes:<br>- When building sample in sheet-mode, use <code>Range.Value2 = variantArray</code> writes in a single operation for speed. <br>- When in memory, prefer column index maps to avoid string lookups in inner loops. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: ApplyDescriptorToSample — deterministic descriptor application</strong><br>Purpose: apply a single <code>ApplyDescriptor</code> to the sample; produce detailed before/after rows, evidence refs, and per-descriptor aggregates.<br>Signature: <code>ApplyDescriptorToSample(applyDesc As Dictionary, sampleRef As Dictionary, Optional evidenceLimit As Long) As Dictionary</code>.<br>Descriptor canonical form expected (keys):<br>- <code>applyId</code>, <code>runId</code>, <code>inputRowHash</code>, <code>candidateId</code>, <code>actions</code> (array), <code>userId</code>, <code>timestamp</code>, <code>rationale</code>.<br>Action object form (keys):<br>- <code>actionId</code>, <code>priority</code>, <code>matchCriteria</code> (structured), <code>transformType</code> (<code>directSet|adjust|split|move|composed</code>), <code>transformSpec</code> (structured), <code>validationRules</code> (optional).<br>Match criteria language (structured, not Eval):<br>1. Accept a set of predicate tokens: <code>{ field, op, value }</code> where <code>op</code> in <code>[&quot;=&quot;,&quot;&lt;&gt;&quot;,&quot;&gt;&quot;,&quot;&lt;&quot;,&quot;&gt;=&quot;,&quot;&lt;=&quot;,&quot;in&quot;,&quot;notin&quot;,&quot;between&quot;,&quot;like&quot;]</code>. <br>2. Support boolean composition with <code>and</code>/<code>or</code> nodes. <br>3. Compile into an in-memory predicate function (pre-compile stage: translate to lambdas or indexable boolean arrays). Caching compiled predicates across descriptors speeds repeated checks. <br>Processing steps (deterministic):<br>1. <strong>Compile criteria</strong> -> predicate function. <br>2. <strong>Filter sample</strong> -> generate <code>matchedIndices</code> using the predicate; for sheet-mode use <code>AutoFilter</code> first then read matched rows into memory. <br>3. <strong>Sort matchedIndices</strong> deterministically: by <code>postingDate</code> then <code>postingId</code> then <code>rowOrdinal</code>. <br>4. <strong>Apply transforms</strong> per matched row in sorted order: transforms supported:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) <code>directSet</code> — set fields to constant values. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) <code>adjust</code> — numeric add/subtract or percent (e.g., +10%); apply <code>DecimalPrecision</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) <code>split</code> — create multiple synthetic rows splitting <code>amount</code> by percentages; implement <code>largest-residual</code> rounding allocation to ensure totals match. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) <code>move</code> — simulate reversal + new posting entries (represent as synthetic rows in detail). <br>&nbsp;&nbsp;&nbsp;&nbsp;e) <code>composed</code> — sequence of transforms executed in specified order. <br>5. <strong>Compute diffs</strong>: for each affected sample row record <code>beforeJSON</code> and <code>afterJSON</code>, <code>delta</code> numeric, <code>matchReason</code>, and <code>appliedBy</code>. <br>6. <strong>Evidence collection</strong>: capture up to <code>evidenceLimit</code> exemplar rows (postingId excerpt + narrative snippet) and store in <code>__SimEvidence_&lt;runId&gt;</code> with <code>evidenceRefId</code>. For privacy, optionally hash <code>postingId</code>. <br>7. <strong>Write detail</strong>: append detail rows to <code>__SimDetail_&lt;runId&gt;</code> in chunked batches to avoid memory pressure. Each detail row includes <code>applyId</code>, <code>runId</code>, <code>sampleRowOrdinal</code>, <code>postingId</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>delta</code>, <code>evidenceRefId</code>, <code>rationale</code>, <code>timestamp</code>. <br>8. <strong>Compute descriptor summary</strong>: <code>matchedCount</code>, <code>totalDelta</code>, <code>maxDeltaRowRef</code>, <code>evidenceRefs[]</code>. Return dictionary containing summary and <code>detailSheetName</code>. <br>Important constraints & invariants:<br>- Always apply the same rounding rule (centralized function using <code>modConfig.DecimalPrecision</code>) to avoid floating drift. <br>- For split transforms ensure <code>sum(afterAmounts) == beforeAmount</code> within rounding residual; assign residual to the largest slice. <br>- If a descriptor would create circular matches (an earlier applied transform would make a row meet match criteria of the same or later descriptor again), detect and either stop (and return <code>APPLY_LOOP</code> status) or flag for manual review depending on <code>simulateOptions(&quot;allowLooping&quot;)</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: RunWhatIfAdjustments — calculator-driven what-if</strong><br>Purpose: apply ephemeral input changes to a Calculator sheet or simulation workbook to observe downstream effects and reconcile budget outputs.<br>Signature: <code>RunWhatIfAdjustments(simSheetRef As Dictionary, adjustments As Collection, Optional recalcOptions As Dictionary) As Dictionary</code>.<br>Typical scenario: a descriptor changes a headcount or rate cell which cascades through formulas that in turn alter <code>Detail_Budget</code> values. The function supports verifying end-state outputs without committing changes.<br>Process steps and safeguards:<br>1. <strong>Snapshot</strong>: capture named cell values, target output cells, and <code>Application</code> state (<code>Calculation</code>, <code>ScreenUpdating</code>, <code>EnableEvents</code>) into <code>__WhatIf_Backup_&lt;runId&gt;</code>. <br>2. <strong>Safety checks</strong>: ensure <code>simSheetRef</code> is a copy or explicitly marked <code>isSimCopy=True</code>; refuse to operate on live production sheet unless admin override present. <br>3. <strong>Apply adjustments</strong>: map each adjustment to a named cell or target address and write value(s) in batch. Use <code>SafeRangeWrite</code> wrapper with retries for transient COM errors. <br>4. <strong>Recalculate</strong>: if <code>recalcOptions(&quot;fullRecalc&quot;)=True</code> call <code>Application.CalculateFull</code> else <code>simSheetRef.Calculate</code>; enforce a timeout (e.g., <code>GS_TimeoutSec</code>) and capture performance metrics. <br>5. <strong>Capture outputs</strong>: read target outputs (configured list of cells/ranges), compute deltas, and capture formula error flags. <br>6. <strong>Revert</strong>: restore original named cell values and Application state from <code>__WhatIf_Backup_&lt;runId&gt;</code>; if revert fails, escalate and write forensic pack. <br>Return: <code>{ status:&quot;OK&quot;|&quot;WARN&quot;|&quot;FAIL&quot;, beforeOutputs, afterOutputs, deltaOutputs, runtimeMs, warnings }</code>. <br>Design notes:<br>- Use this function to test downstream impacts for reviewers before committing mapping changes. <br>- Always log the exact set of cells changed for revert determinism. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: ComputeDisclosureAggregates — grouping & materiality</strong><br>Purpose: aggregate row-level simulations into disclosure buckets and identify material groups that require review or escalation.<br>Signature: <code>ComputeDisclosureAggregates(simSheetRef As Dictionary, groupKeys As Collection, periodKey As String) As Dictionary</code>.<br>Steps and outputs:<br>1. <strong>Canonicalization</strong>: ensure simulated sheet has <code>beforeAmount</code>, <code>afterAmount</code>, <code>delta</code>, <code>postingDate</code>, and grouping fields present. Compute <code>period</code> using <code>DateToPeriod</code> helper with <code>modConfig.FiscalCalendar</code> if <code>periodKey</code> not present. <br>2. <strong>Grouping</strong>: group rows by <code>groupKeys</code> + <code>period</code> and compute aggregates: <code>sumBefore</code>, <code>sumAfter</code>, <code>sumDelta</code>, <code>countAffected</code>, <code>avgDelta</code>, <code>maxDeltaRowRef</code>, <code>minDeltaRowRef</code>. <br>3. <strong>Materiality tests</strong>: for each group compute: <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>absDelta = ABS(sumDelta)</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>absPct = IF(sumBefore=0 THEN NULL ELSE absDelta / ABS(sumBefore))</code> <br>&nbsp;&nbsp;&nbsp;&nbsp;• mark <code>materialFlag=TRUE</code> if <code>absDelta &gt;= modConfig.GroupMaterialityAbsolute</code> OR <code>absPct &gt;= modConfig.GroupMaterialityRelative</code>. <br>4. <strong>Augment aggregates</strong>: add <code>evidenceRefSample</code> for top N rows per material group and <code>materialRationale</code> explaining why flagged. <br>5. <strong>Export shape</strong>: produce <code>ImpactAggregates</code> sheet with stable column order <code>[&#x27;disclosureBucket&#x27;,&#x27;period&#x27;,&#x27;costCenter&#x27;,&#x27;sumBefore&#x27;,&#x27;sumAfter&#x27;,&#x27;sumDelta&#x27;,&#x27;pctDelta&#x27;,&#x27;countAffected&#x27;,&#x27;materialFlag&#x27;,&#x27;evidenceRef&#x27;]</code>. <br>Return dictionary: <code>{aggregateSheet:&quot;__ImpactAggregates_&lt;runId&gt;&quot;, aggregateCount, materialGroupsCollection}</code>. <br>Design notes:<br>- Use deterministic sorting by <code>disclosureBucket, period, costCenter</code> for CSV parity. <br>- Provide optional <code>drillRowsLimit</code> config to attach representative rows for each material group. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: ExportSimulationCSV — canonical artifacts</strong><br>Purpose: serialize simulation artifacts in deterministic format for BI ingestion, migration handoff, and archival.<br>Signature: <code>ExportSimulationCSV(runId As String, destFolder As String, Optional formatOptions As Dictionary) As Dictionary</code>.<br>Artifacts created (names deterministic):<br>1. <code>impact_&lt;runId&gt;_aggregates.csv</code> — canonical aggregates CSV, sorted and typed. <br>2. <code>impact_&lt;runId&gt;_detail.ndjson</code> — newline-delimited JSON of per-row details from <code>__SimDetail_&lt;runId&gt;</code>. <br>3. <code>impact_&lt;runId&gt;_evidence.csv</code> — evidence table mapping <code>evidenceRefId</code> to excerpts (hashed postingId optional). <br>4. <code>impact_&lt;runId&gt;_manifest.json</code> — contains <code>runId</code>, <code>codeVersion</code>, <code>configSnapshotRef</code> (or inline), file list with checksums, export timestamp and sign-off metadata (operator/reviewer signatures) if present. <br>Export rules & implementation details:<br>- <strong>Atomic writes</strong>: write files to a <code>temp</code> folder and rename on success to final name. <br>- <strong>Numeric formatting</strong>: fixed <code>modConfig.DecimalPrecision</code> and invariant culture; timestamps ISO-8601 UTC. <br>- <strong>Checksums</strong>: compute CRC32 in-VBA and prefer SHA256 if external helper is configured; store checksum in manifest and <code>Audit_Log</code>. <br>- <strong>Privacy</strong>: if <code>simulateOptions(&quot;hashPII&quot;)=True</code>, replace <code>postingId</code> with <code>SHA256(salt+postingId)</code> in exports and include <code>piiHashSaltRef</code> in manifest (salt stored in secure config). <br>Return dictionary: <code>{files:[...], manifestPath, checksums:{...}, status}</code>. Append export row to <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: ValidateSimulationArtifacts — integrity & health checks</strong><br>Purpose: ensure artifacts are consistent before reviewer sign-off or migration handoff.<br>Signature: <code>ValidateSimulationArtifacts(runId As String) As Dictionary</code>.<br>Checks performed:<br>1. <strong>Existence</strong>: all expected sheets and exported files exist. <br>2. <strong>Row counts</strong>: sample rowCount aligns with detail rows and manifest. <br>3. <strong>Checksum verification</strong>: compare file checksums with manifest. <br>4. <strong>Cell health</strong>: scan <code>__Sim_&lt;runId&gt;</code> and <code>__SimDetail_&lt;runId&gt;</code> for formula errors or unusual values (NaN, #REF!, #VALUE!). <br>5. <strong>Materiality presence</strong>: confirm material groups flagged where expected. <br>6. <strong>Evidence completeness</strong>: each material group has required <code>evidenceRefCount</code> configured. <br>Return structure: <code>{status:&quot;OK&quot;|&quot;WARN&quot;|&quot;FAIL&quot;, issues:[{code,message}], checksumsOk:Boolean}</code> and append result to <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: CreateForensicPack — packaging for incidents</strong><br>Purpose: assemble a secure, replayable forensic bundle containing simulation workbook, audit, apply descriptors, evidence, manifest and optional encryption metadata.<br>Signature: <code>CreateForensicPack(runId As String, destPath As String, Optional options As Dictionary) As Boolean</code>.<br>Contents of forensic pack (recommended):<br>1. <code>manifest.json</code> — run metadata including <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, files and checksums. <br>2. <code>sim_&lt;runId&gt;.xlsx</code> — workbook snapshot containing <code>__Sim_&lt;runId&gt;</code>, <code>__SimDetail_&lt;runId&gt;</code>, <code>__SimEvidence_&lt;runId&gt;</code>, <code>__ImpactAggregates_&lt;runId&gt;</code>. <br>3. <code>audit_&lt;runId&gt;.ndjson</code> — fleece of <code>Audit_Log</code> rows for the run. <br>4. <code>apply_descriptors_&lt;runId&gt;.json</code> — all descriptors used. <br>5. <code>evidence_bundle_&lt;runId&gt;.zip</code> — zipped evidence CSVs and attachments (if permitted). <br>6. optional <code>signature.p7s</code> or <code>manifest.sig</code> if external PKI signing is available. <br>Pack rules and operational constraints:<br>- <strong>Encryption</strong>: advise external helper for AES-256/PGP encryption; store encryption metadata in manifest. <br>- <strong>PII redaction</strong>: produce both a <code>full</code> and <code>redacted</code> pack when compliance policy requires; redaction uses hashing with saved salt in secure config. <br>- <strong>Chain-of-custody</strong>: append <code>packCreatedBy</code>, <code>packCreatedAt</code>, and <code>packChecksum</code> to <code>Audit_Log</code>. <br>Return <code>True</code> on success; log failure and reasons otherwise. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Function: ReplaySimulation & CompareSimulationDiffs</strong><br>Purpose: reproduce a simulation run deterministically for QA and prove idempotency; produce row-level diffs between original and replayed runs.<br>Signature: <code>ReplaySimulation(runId As String, replayOptions As Dictionary) As Dictionary</code> and <code>CompareSimulationDiffs(runA As String, runB As String) As Dictionary</code>.<br>Replay steps:<br>1. Load <code>manifest</code> and <code>apply_descriptors_&lt;runId&gt;.json</code>. <br>2. Reconstruct sample using <code>BuildSimulationSample</code> with same <code>sampleSpec</code> from manifest (or use persisted <code>__Sim_&lt;runId&gt;</code> snapshot if provided). <br>3. Re-run apply logic in deterministic order using same <code>configSnapshot</code> and <code>codeVersion</code>. <br>4. Write replay detail to <code>__ReplayDetail_&lt;runId&gt;</code>. <br>Diff algorithm:<br>1. Align rows by <code>inputRowHash</code> or deterministic <code>rowOrdinal</code>. <br>2. For numeric fields compare using <code>DecimalPrecision</code> tolerance; for strings compare equality after canonicalisation. <br>3. Output <code>mismatchRows</code> with <code>field</code>, <code>valueA</code>, <code>valueB</code>, <code>reason</code>. <br>Return: <code>{replayStatus:&quot;OK&quot;|&quot;DIFF&quot;|&quot;ERROR&quot;, diffsCount, diffsSample}</code> and append to <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Helper: CompilePredicate / EvaluatePredicate (internal)</strong><br>Purpose: safe, structured predicate compiler to avoid Eval and to support high-performance matching.<br>Capabilities:<br>1. Accept <code>matchCriteria</code> structured dictionaries and compile them to an internal representation (predicate tokens and evaluation plan). <br>2. Support comparison ops: <code>=, &lt;&gt;, &gt;, &lt;, &gt;=, &lt;=, in, notin, between, like</code> and boolean composition <code>and</code>/<code>or</code>/<code>not</code>. <br>3. Support match on nested JSON fields when <code>beforeJSON</code> parsed. <br>4. Provide <code>EvaluatePredicate(rowArray, colIndexMap)</code> returning Boolean. <br>Performance: pre-compile and reuse predicate lambdas for repeated descriptors across rows. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Helper: EvidenceManager</strong><br>Purpose: manage evidence storage, hashing, excerpting, privacy controls, and export-ready packaging.<br>Functions and behaviours:<br>1. <code>StoreEvidence(runId, postingRows, maxEvidence)</code> — create evidence records with <code>evidenceRefId</code>, excerpt text (first N chars), <code>postingDate</code>, <code>postingIdHash</code> if PII hashed, and truncated narrative. <br>2. <code>GetEvidenceRefs(evidenceRefIds)</code> — return CSV-friendly excerpts for export. <br>3. <code>PiiHash(postingId, salt)</code> — cryptographic hash for safe exports; persist <code>saltRef</code> in manifest but keep salt secret. <br>Design notes: prefer <code>sha256(salt + postingId)</code> and never export salt in public artifacts. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Helper: RoundingPolicy & Numeric helpers</strong><br>Purpose: centralize numeric rounding and residual allocation to maintain arithmetic determinism.<br>Key behaviours:<br>1. <code>RoundToPrecision(value, precision)</code> — uses banker's rounding or configured rule; consistent across module. <br>2. <code>AllocateSplit(totalAmount, percentages[], precision)</code> — compute slice amounts, allocate residual to largest-slice recipient to preserve sum equality. <br>3. <code>SafeAdd(a,b)</code> — safe numeric addition with NaN and overflow handling. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Helper: ChecksumUtilities & ManifestManager</strong><br>Purpose: compute file and sheet checksums and maintain manifest for reproducible replays.<br>Functions:<br>1. <code>ComputeSheetChecksum(sheetName)</code> — compute a stable checksum across header and rows using row-wise CRC or md5. <br>2. <code>ComputeFileChecksum(filePath)</code> — wrapper using VBA CRC32 fallback or external SHA256 helper. <br>3. <code>WriteManifest(runId, manifestDict)</code> — write <code>manifest.json</code> with file list and checksums. <br>Best practice: store <code>codeVersion</code> (git SHA or build tag) and <code>configSnapshot</code> inline in manifest for reproducibility. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Power Query (PQ) conceptual integration — ingest & transformation steps</strong><br>Objective: provide clear PQ steps to turn exported simulation artifacts into BI-ready tables and model training datasets.<br>Recommended PQ flow (detailed narrative):<br>1. <strong>Ingest <code>impact_&lt;runId&gt;_aggregates.csv</code></strong>: use <code>From File</code> → <code>From CSV</code>, <code>Promote Headers</code>, apply <code>Change Type</code> (numeric columns to Decimal Number, periods to Date). <br>2. <strong>Ingest <code>impact_&lt;runId&gt;_detail.ndjson</code></strong>: use <code>From File</code> → <code>From Text/CSV</code> reading ndjson as <code>each line</code> then <code>Json.Document</code> to parse each JSON row; expand <code>beforeJSON</code> and <code>afterJSON</code> into columns <code>beforeAmount</code>, <code>afterAmount</code>, <code>costCenterBefore</code>, <code>costCenterAfter</code>. <br>3. <strong>Normalize evidence</strong>: import <code>impact_&lt;runId&gt;_evidence.csv</code> and left-join on <code>evidenceRefId</code>. <br>4. <strong>Compute DeltaPct</strong>: <code>DeltaPct = if [beforeAmount] = 0 then null else [delta] / [beforeAmount]</code>. <br>5. <strong>Mark MaterialFlag</strong>: use manifest thresholds to compute <code>MaterialFlag</code>. <br>6. <strong>Produce training set</strong>: expand componentBreakdown JSON into flat features (<code>tokenOverlap</code>, <code>fuzzyScore</code>, <code>priorConfirmCount</code>) join with <code>ConfirmedMatches</code> to derive <code>label</code>. <br>7. <strong>Publish</strong> to dataflow or dataset with <code>runId</code> partitioning and incremental refresh for audit. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Conceptual DAX measures — examples for dashboards</strong><br>Designed to provide finance & ops quick insights derived from simulation artifacts once loaded into a Power BI model table called <code>Sim_Impact_Flat</code>:<br>1. <code>TotalSimDelta = SUM(Sim_Impact_Flat[delta])</code>.<br>2. <code>MaterialGroupCount = COUNTROWS(FILTER(Sim_Aggregates, Sim_Aggregates[materialFlag] = TRUE))</code>.<br>3. <code>PctMaterialGroups = DIVIDE([MaterialGroupCount], COUNTROWS(Sim_Aggregates))</code>.<br>4. <code>MaxMaterialDelta = MAXX(FILTER(Sim_Aggregates, Sim_Aggregates[materialFlag]=TRUE), ABS(Sim_Aggregates[sumDelta]))</code>.<br>5. <code>AverageDeltaPerApply = AVERAGE(Sim_Impact_Flat[delta])</code>. <br>Use slicers for <code>runId</code>, <code>period</code> and <code>disclosureBucket</code> and pin <code>ImpactReport</code> visuals to reviewer dashboard with drill-through to <code>evidenceRef</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Examples & narratives (walkthroughs)</strong><br>Example 1 — Simple cost centre re-map:<br>&nbsp;&nbsp;&nbsp;&nbsp;Input: applyDescriptor sets <code>costCenter</code> for postings with <code>narrative</code> containing "tempstaff" from <code>CC100</code> → <code>CC200</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;Flow: <code>BuildSimulationSample(stratified)</code> ensures sample contains postings from <code>CC100</code>. <code>ApplyDescriptorToSample</code> matches rows by <code>like</code> on <code>narrative</code>, directSet <code>costCenter=CC200</code>, produces <code>__SimDetail</code> with before/after rows and small <code>delta=0</code> (reallocation). <code>ComputeDisclosureAggregates</code> shows reclassification but no material delta; reviewer can accept. <br>Example 2 — High-dollar reallocation causing materiality: <br>&nbsp;&nbsp;&nbsp;&nbsp;Descriptor moves salary postings from <code>DeptA</code> to <code>DeptB</code> with <code>move</code> transform. Simulation reveals <code>sumDelta</code> in <code>DisclosureBucket X</code> = 1.2M which exceeds <code>GroupMaterialityAbsolute</code>; <code>ComputeDisclosureAggregates</code> flags material groups, <code>ExportSimulationCSV</code> creates artifacts and <code>CreateForensicPack</code> bundles evidence for governance sign-off. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Testing matrix (unit / integration / performance)</strong><br>Unit tests (via <code>modTestingHarness</code>):<br>1. <code>BuildSimulationSample</code> returns reproducible sample given same seed; test with random and stratified modes. <br>2. <code>ApplyDescriptorToSample</code> for <code>directSet</code>, <code>adjust</code>, <code>split</code>, <code>move</code> produce expected before/after totals and rounding behavior; validate <code>matchedCount</code> and <code>evidenceRefs</code>. <br>3. <code>RunWhatIfAdjustments</code> restores calculator state exactly; test that after revert the same formula-driven cells equal pre-run values. <br>Integration tests:<br>1. Full <code>SimulateRunPreview</code> against canonical dataset should produce identical <code>ImpactReport</code> to golden artifact (ignoring timestamps). <br>2. <code>ExportSimulationCSV</code> artifacts parse cleanly into PQ flow and DAX measures computed equal expected values. <br>Performance tests:<br>1. For given hardware baseline ensure <code>AvgApplyMsPerRow</code> under SLA and peak memory usage < threshold; run synthetic dataset with N rows to measure scaling. <br>Acceptance criteria:<br>• <code>ValidateSimulationArtifacts</code> returns <code>OK</code>.<br>• Finance reviewer signs off on <code>ImpactReport</code> for material groups when present. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Telemetry, metrics & operational alerts</strong><br>Record these telemetry points to <code>__Telemetry</code> and optionally push to external telemetry endpoint:<br>1. <code>SimRunDurationMs</code> and <code>SimRunRowCount</code>.<br>2. <code>AvgApplyMsPerRow</code>, <code>MaxApplyMs</code> and <code>ComparisonsPerRow</code>. <br>3. <code>EvidenceCountPerApply</code> and <code>MaterialGroupsCount</code>. <br>4. <code>ExportSuccessRate</code> and <code>ChecksumMismatchRate</code>. <br>Alerting rules (recommended):<br>- <code>ChecksumMismatchRate &gt; 0</code> => immediate paging to ops.<br>- <code>MaterialGroupsCount &gt; threshold</code> => reviewer escalation email. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Security, privacy & compliance controls</strong><br>1. Default exports redact or hash posting ids unless <code>simulateOptions.allowPlainPII = True</code> and the operator has <code>Admin</code> role. <br>2. For regulated environments require <code>ForensicPack</code> to be encrypted and signed by external PKI; store keys outside workbook. <br>3. Artifact retention follows <code>modConfig.RetentionDays</code>; purge older simulation artifacts automatically (record purge in <code>Audit_Log</code>). <br>4. Ensure role checks before export or forensic pack creation. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Edge cases & mitigation guidance</strong><br>1. <strong>No match</strong>: descriptor returns <code>NO_MATCH</code> with sample rows used for attempted matching and suggestion to broaden criteria or create alias via <code>modAliasManagement</code>. <br>2. <strong>Split rounding residual</strong>: implement largest-residual allocation and record residual handling in <code>__SimDetail</code>. <br>3. <strong>Circular applies</strong>: detect re-matching chain and stop further automatic application; record <code>APPLY_LOOP</code> and require manual review. <br>4. <strong>Huge samples</strong>: fallback to stratified sampling with careful bucket selection and document representativity limitations in manifest. <br>5. <strong>Currency mismatches</strong>: require <code>fxRates</code> snapshot in <code>simulateOptions</code>; convert to base currency before aggregating and record FX assumptions. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Developer implementation notes & optimisations</strong><br>1. Use a single <code>colIndexMap</code> for sample arrays to avoid repeated string-to-index lookups. <br>2. Pre-compile match predicates once per descriptor and reuse across rows. <br>3. Batch append to detail sheet in sizes tuned to environment (<code>modConfig.ExportBatchSize</code>). <br>4. Keep per-run memo caches in dictionary keyed by <code>runId</code> and clear when run completes. <br>5. Use deterministic, stable sorting functions implemented once and reused. <br>6. For heavy workloads, provide optional integration with external helper service for batch simulation/execution to avoid Excel resource limits. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Operational runbook snippets (operator + reviewer flows)</strong><br>1. <strong>Operator pre-simulate</strong>: confirm <code>sampleSpec</code>, ensure <code>SimExportPath</code> has space, verify <code>modConfig</code> thresholds. <br>2. <strong>Dry run</strong>: run <code>SimulateRunPreview</code> with <code>dryRun=True</code>; review <code>ImpactReport</code> in <code>frmReviewerUI</code> and inspect <code>evidenceRefs</code>. <br>3. <strong>Reviewer</strong>: review top material groups, drill to evidence and per-descriptor detail; if satisfied sign-off and allow export. <br>4. <strong>Export & handoff</strong>: run <code>ExportSimulationCSV</code> and hand package to DB team, or call <code>CreateForensicPack</code> for high-assurance transfer. <br>5. <strong>Incident</strong>: if unexpected material deltas discovered post-deploy, run <code>CreateForensicPack</code>, freeze run artifacts, and escalate to governance. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Power Query (PQ) conceptual example — detailed steps</strong><br>1. <strong>Load aggregates CSV</strong>: From File → CSV → Promote Headers → Change Types (<code>sumBefore</code> & <code>sumAfter</code> numeric). <br>2. <strong>Load detail ndjson</strong>: From Text → parse each line with <code>Json.Document</code>, convert to table, expand <code>beforeJSON</code> and <code>afterJSON</code>. <br>3. <strong>Normalize evidence</strong>: load <code>impact_evidence.csv</code>, join on <code>evidenceRefId</code>. <br>4. <strong>Compute columns</strong>: <code>DeltaPct = if [beforeAmount] = 0 then null else [delta]/[beforeAmount]</code>. <br>5. <strong>Material flag</strong>: apply manifest thresholds to compute <code>MaterialFlag</code>. <br>6. <strong>Publish dataset</strong>: schedule refresh on artifact changes; use <code>runId</code> parameter for partitioned filter. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Conceptual DAX examples (operational KPIs)</strong><br>1. <code>TotalSimDelta = SUM(ImpactDetail[delta])</code>.<br>2. <code>MaterialGroupCount = COUNTROWS(FILTER(ImpactAggregates, ImpactAggregates[materialFlag] = TRUE))</code>.<br>3. <code>PctMaterialGroups = DIVIDE([MaterialGroupCount], COUNTROWS(ImpactAggregates))</code>.<br>4. <code>AvgDeltaPerApply = AVERAGE(ImpactDetail[delta])</code>.<br>5. <code>TopMaterialBuckets = TOPN(10, FILTER(ImpactAggregates, ImpactAggregates[materialFlag] = TRUE), ABS(ImpactAggregates[sumDelta]), DESC)</code> (used to populate reviewer widget). </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Testing & acceptance criteria (practical checklists)</strong><br>Unit tests (must pass):<br>1. <code>BuildSimulationSample</code> reproducibility with same seed. <br>2. <code>ApplyDescriptorToSample</code> correctness across transform types and rounding behavior. <br>3. <code>RunWhatIfAdjustments</code> performs full revert with Calculator state unchanged. <br>Integration tests (must pass):<br>1. Full <code>SimulateRunPreview</code> on golden dataset produces identical aggregate CSV (disregard timestamps). <br>2. <code>ExportSimulationCSV</code> artifacts parse cleanly into PQ; DAX measures compute expected values. <br>Performance tests:<br>1. For target volume X ensure run finishes under SLA; report <code>AvgApplyMsPerRow</code> and <code>PeakMemory</code>. <br>Operational acceptance gates:<br>• <code>ValidateSimulationArtifacts</code> returns <code>OK</code> and finance reviewer approves ImpactReport for material groups. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Change control, versioning & migration guidance</strong><br>1. Include <code>simVersion</code>, <code>codeVersion</code>, and <code>configSnapshot</code> in manifest. <br>2. Any change to rounding rules, split allocation, or materiality thresholds must be accompanied by an update to <code>modTestingHarness</code> golden artifacts and a migration script to re-run prior runs if required for audit. <br>3. Keep a <code>__Migration_History</code> logging migration id, reason and impact on previous artifacts. </td></tr><tr><td data-label="Per-function technical breakdown — modImpactSimulation (VBA)"> <strong>Final operational summary — why this module matters</strong><br><code>modImpactSimulation</code> is the safety sandbox for UpdateHR+ — it lets operators and reviewers understand the downstream financial and disclosure consequences of mapping changes before committing them. When implemented correctly it reduces deployment risk, provides auditable evidence for governance, and feeds clean labeled artifacts to ML and BI teams while preserving privacy and deterministic replayability. Implementers should prioritize deterministic processing, minimal COM interaction, robust manifest/checksum hygiene, and clear reviewer evidence presentation to maximize organizational trust and control. </td></tr></tbody></table></div><div class="row-count">Rows: 30</div></div><div class="table-caption" id="Table10" data-table="Docu_0203_10" style="margin-top:2mm;margin-left:3mm;"><strong>Table 10</strong></div>
<div class="table-wrapper" data-table-id="table-10"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modBatchUtilities** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modBatchUtilities</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Module purpose (short)</strong><br><code>modBatchUtilities</code> is the run orchestration and lifecycle utility module for UpdateHR+. It provides deterministic scheduling, partitioning, replay, diffing, manifesting, forensic export, lock management, and safe-run automation. The module is intentionally focused on run-level mechanics (scheduling, replay, compare, manifest, forensic packaging, partition planning, locks, telemetry hooks) and avoids business logic (matching, scoring, GoalSeek). Its outputs are used by <code>modCoreEngine</code>, <code>modBatchProcessing</code>, operator UI modules, and audit ingestion pipelines. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>High-level design principles</strong><br>1. Deterministic replay: schedule and replay use preserved <code>configSnapshot</code> and <code>codeVersion</code> to reproduce results; replays are dry-run by default and require explicit approval to commit. <br>2. Idempotency-first: every action includes <code>inputRowHash</code> and <code>runId</code> keys; replay/commit routines detect duplicates and prevent double-writes. <br>3. Append-only provenance: scheduling, replay, compare and forensic actions write immutable audit rows with artifact references and checksums. <br>4. Fail-safe defaults: scheduled runs default to dry-run preview prior to any commit and require reviewer approval for material adjustments. <br>5. Minimal dependencies: artifacts are persisted as spreadsheet sheets and NDJSON/CSV exports; external services are optional and used only for convenience (webhooks, artifact store). <br>6. Operational transparency: every operation produces human-readable manifests and machine-readable artifacts for PQ and BI ingestion. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Public surface (summary)</strong><br>Exposed methods (used by UI and core modules):<br>1. <code>ScheduleRun(runOptions As Scripting.Dictionary, scheduledTime As Date) As Scripting.Dictionary</code> — create scheduled entry, validate, return <code>scheduleId</code>. <br>2. <code>ListScheduledRuns(Optional filter As Scripting.Dictionary) As Collection</code> — enumerate scheduled runs. <br>3. <code>CancelScheduledRun(scheduleId As String, userId As String) As Boolean</code> — cancel pending schedules; audit cancellation. <br>4. <code>AcquireRunLock(lockId As String, ownerId As String, timeoutSecs As Long) As Boolean</code> — acquire guard for run-level operations. <br>5. <code>ReleaseRunLock(lockId As String, ownerId As String) As Boolean</code> — release lock. <br>6. <code>PartitionRun(inputRange As Range, partitionKeyExpr As String, partitionConfig As Scripting.Dictionary) As Collection</code> — compute safe partition plan and persist <code>__Run_Plan</code>. <br>7. <code>CreateRunManifest(runId As String) As Scripting.Dictionary</code> — build canonical manifest (codeVersion, configSnapshot, runPlan, checksums). <br>8. <code>ReplayRun(originalRunId As String, replayOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — deterministic dry-run replay with diff and optional commit when authorized. <br>9. <code>CompareRunDiffs(runIdA As String, runIdB As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — produce row-level and field-level diffs with summary metrics. <br>10. <code>ExportForensics(runId As String, destPath As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — produce forensic bundle (ndjson/csv/manifest/archive). <br>11. <code>RegisterExternalTrigger(scheduleId As String, triggerConfig As Scripting.Dictionary) As Boolean</code> — optional webhook/automation registration. <br>12. <code>DetectOrphanedLocks()</code> — admin helper to find stale locks. <br>13. <code>ReplayPreFlightChecks(originalManifest As Scripting.Dictionary, currentEnv As Scripting.Dictionary) As Scripting.Dictionary</code> — produce warning/error list for replay safety. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Data artifacts & canonical sheets used by module</strong><br>1. <code>__Run_Schedule</code> — scheduled runs table: <code>scheduleId</code>, <code>runName</code>, <code>staffRangeName</code>, <code>scheduledTimeUTC</code>, <code>runOptionsJSON</code>, <code>status</code>, <code>createdBy</code>, <code>createdAtUTC</code>. <br>2. <code>__Run_Locks</code> — lock table: <code>lockId</code>, <code>owner</code>, <code>acquiredAtUTC</code>, <code>expiresAtUTC</code>, <code>context</code>. <br>3. <code>__Run_Plan</code> — partition/plan sheet with <code>partitionId</code>, <code>startOrdinal</code>, <code>endOrdinal</code>, <code>rowCount</code>, <code>partitionKey</code>, <code>safeToRunParallel</code>. <br>4. <code>__Run_Manifest</code> — run manifests stored as JSON per run. <br>5. <code>__Run_Diff_&lt;A&gt;_&lt;B&gt;</code> — diffs exported for pairs of runs. <br>6. <code>__Forensic_Registry</code> — registry of forensic artifacts (forensicId, runId, location, checksum). <br>7. <code>__Replay_Status</code> — in-progress replay metadata. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: ScheduleRun</strong><br>Signature: <code>ScheduleRun(runOptions As Scripting.Dictionary, scheduledTime As Date) As Scripting.Dictionary</code>.<br>Purpose: create scheduled run entry with pre-flight validation and manifest preview.<br>Inputs: <code>runOptions</code> keys (required): <code>runName</code>, <code>staffRangeName</code>, <code>dryRun</code> (Boolean), <code>maxRows</code>(<code>Long|Optional</code>), <code>partitionKey</code>(<code>String|Optional</code>), <code>notify</code> (<code>Collection|Optional</code>), <code>scheduledBy</code>(String).<br>Processing steps & validations:<br>1. Validate <code>staffRangeName</code> exists and not empty; if missing return <code>status=&quot;VALIDATION_FAILED&quot;</code> with diagnostics. <br>2. Call <code>modCoreEngine.ValidatePreRun</code> logic to confirm Calculator named cells are present. <br>3. Check <code>modConfig</code> caps like <code>DailyAutoApplyCapRows</code> — if schedule likely to breach caps produce <code>status=&quot;NEEDS_APPROVAL&quot;</code>. <br>4. Create <code>scheduleId</code> GUID, persist entry to <code>__Run_Schedule</code> with <code>status=&quot;PENDING&quot;</code>. <br>5. Optionally compute <code>manifestPreview</code> containing <code>scheduleId</code>, <code>scheduledTimeUTC</code>, <code>previewRunId</code> (deterministic placeholder) and partial <code>runPlan</code> if partitionKey provided. <br>Outputs: dictionary <code>{scheduleId, status, previewManifest}</code>. <br>Audit: append <code>SCHEDULE_CREATED</code> row to <code>Audit_Log</code> with <code>scheduleId</code> and <code>createdBy</code>.<br>Error codes: <code>VALIDATION_FAILED</code>, <code>SCHEDULE_WRITE_ERROR</code>, <code>LOCK_HELD</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: ListScheduledRuns</strong><br>Signature: <code>ListScheduledRuns(Optional filter As Scripting.Dictionary) As Collection</code>.<br>Purpose: read and return scheduled runs for UI and automation.<br>Filter keys: <code>status</code> (PENDING, RUNNING, CANCELLED), <code>createdBy</code>, <code>timeWindowStart</code>, <code>timeWindowEnd</code>.<br>Behaviour: read <code>__Run_Schedule</code> sheet, filter in-memory and return collection of dictionaries. Provide pagination if requested optional <code>filter(&quot;pageSize&quot;)</code> and <code>filter(&quot;page&quot;)</code> fields. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: CancelScheduledRun</strong><br>Signature: <code>CancelScheduledRun(scheduleId As String, cancelledBy As String) As Boolean</code>.<br>Purpose: safely cancel pending schedules.<br>Steps:<br>1. Acquire lock row-level for scheduleId. <br>2. If <code>status</code> is <code>IN_PROGRESS</code> or <code>COMPLETED</code>, return <code>False</code> and <code>reason=&quot;CannotCancelInProgressOrCompleted&quot;</code>. <br>3. Set <code>status=&quot;CANCELLED&quot;</code>, set <code>cancelledBy</code>, <code>cancelledAtUTC</code>, write <code>SCHEDULE_CANCELLED</code> audit row with <code>scheduleId</code>, <code>cancelledBy</code>, <code>reasonOptional</code>. <br>4. Release locks and notify <code>notify</code> list if present. <br>Return: True if cancelled, otherwise False with diagnostic. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: AcquireRunLock / ReleaseRunLock</strong><br>Signatures: <code>AcquireRunLock(lockId As String, ownerId As String, timeoutSecs As Long) As Boolean</code> and <code>ReleaseRunLock(lockId As String, ownerId As String) As Boolean</code>.<br>Purpose: prevent overlapping operations on runs, manifests, and exports.<br>Behaviour & rules:<br>1. Acquire: if no existing lock or existing lock expired, write <code>lockId</code>, <code>ownerId</code>, <code>acquiredAtUTC</code>, <code>expiresAtUTC = NowUTC + timeoutSecs</code> in <code>__Run_Locks</code> and return True. <br>2. If lock exists and not expired return False and current owner id. <br>3. Release: only owner or admin may release; remove row or mark <code>releasedAtUTC</code> and append <code>LOCK_RELEASE</code> audit row. <br>4. Orphan detection: <code>DetectOrphanedLocks</code> lists locks older than <code>RunLockTimeoutSecs</code> and flags them for admin. <br>Security: steeling an active lock requires admin role and must produce <code>LOCK_STEAL</code> audit entry with rationale. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: PartitionRun</strong><br>Signature: <code>PartitionRun(inputRange As Range, partitionKeyExpr As String, partitionConfig As Scripting.Dictionary) As Collection</code>.<br>Purpose: compute partitioning plan for large datasets to enable parallel processing or manageable chunking while avoiding cross-partition write conflicts.<br>Inputs:<br>• <code>inputRange</code> — 2D range with canonical columns including <code>inputRowHash</code>.<br>• <code>partitionKeyExpr</code> — simple expression referencing columns (e.g., <code>costCenter</code>, <code>orgUnit</code>, <code>Left(employeeId,3)</code>), evaluated per row.<br>• <code>partitionConfig</code> keys: <code>maxRowsPerPartition</code>, <code>maxPartitions</code>, <code>preserveOrder</code>(Boolean), <code>preferredShardCount</code>.<br>Algorithm steps (detailed):<br>1. Load inputRange into in-memory variant array to avoid COM overhead. <br>2. Evaluate <code>partitionKeyExpr</code> per row using precompiled expression evaluator; store <code>partitionKey</code> and <code>rowOrdinal</code>. <br>3. Compute frequency distribution by <code>partitionKey</code>. <br>4. Greedy packing: sort keys by descending frequency; assign keys to partitions attempting to keep each partition ≤ <code>maxRowsPerPartition</code>. If a single key exceeds <code>maxRowsPerPartition</code>, split that key into subpartitions using stable hashing (e.g., <code>crc32(inputRowHash) mod N</code>) where N = ceil(keySize / maxRowsPerPartition). <br>5. If <code>preserveOrder=True</code>, ensure partition boundaries are contiguous ranges of ordinals; otherwise partitions are sets (non-contiguous) with minimal cross-partition writes but may disrupt input order. <br>6. Compute <code>safeToRunParallel</code> boolean: true when partitions write to separate target address spaces (detected if partitionKey maps to unique cost-centers and the write target range is cost-center-scoped); false otherwise and sequential commit recommended. <br>7. Persist <code>__Run_Plan</code> sheet with canonical <code>partitionId</code>, <code>startOrdinal</code>, <code>endOrdinal</code> (if contiguous), <code>rowCount</code>, <code>partitionHash</code>, <code>safeToRunParallel</code>. <br>Return: collection of partition dictionaries. <br>Edge conditions & guidance:<br>• Avoid partitioning by unstable keys (like free-text descriptions). <br>• For write-conflict safety, prefer partitions that map directly to independent target ledgers (e.g., separate cost-centers). <br>• Provide suggested <code>preferredShardCount</code> to operations for worker allocation. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: CreateRunManifest</strong><br>Signature: <code>CreateRunManifest(runId As String) As Scripting.Dictionary</code>.<br>Purpose: produce canonical manifest used for replay, audit, and forensic exports. Manifest is persisted and exported for immutable storage.<br>Manifest contents (canonical fields):<br>1. <code>runId</code>, <code>runName</code>, <code>createdBy</code>, <code>createdAtUTC</code>.<br>2. <code>codeVersion</code> (git commit or moduleVersion string), <code>moduleVersions</code> map for key modules (modCoreEngine, modMatchingEngine, modFuzzyScores, modBatchUtilities). <br>3. <code>configSnapshot</code> — full <code>modConfig</code> values used for run, persisted as JSON. <br>4. <code>runPlan</code> — serialized <code>__Run_Plan</code> rows if present. <br>5. <code>stagingChecksum</code> — checksum of <code>__Stage_Run_&lt;runId&gt;</code> using CRC32 or SHA1 via helper; included for rollback integrity check. <br>6. <code>auditSeal</code> — value returned by <code>modAudit.SealAuditRun</code>. <br>7. <code>artifactList</code> — list of exported artifacts (paths) with per-file checksums. <br>8. <code>forensicRef</code> — optional if forensic export existed. <br>9. <code>manifestChecksum</code> — checksum of manifest JSON for quick verification. <br>Behaviour:<br>• Persist manifest JSON into <code>__Run_Manifest</code> hidden sheet and optionally export to <code>manifest_&lt;runId&gt;.json</code>. <br>• Append <code>MANIFEST_CREATED</code> audit row with <code>manifestChecksum</code>. <br>Uses: <code>ReplayRun</code> loads manifest to ensure consistent config and code baseline; forensic exports include manifest. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: ReplayRun</strong><br>Signature: <code>ReplayRun(originalRunId As String, replayOptions As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Purpose: reproduce a prior run deterministically to validate, debug, or re-run with the same inputs/config, optionally committing if parity and approvals permit.<br>Important policy: default behaviour = dry-run only; commit requires approvals and parity checks.<br>Step-by-step behaviour:<br>1. Load <code>originalManifest = CreateRunManifest(originalRunId)</code> (or read existing manifest row). <br>2. Call <code>ValidateReplayEnvironment(originalManifest, currentEnv)</code> to produce warnings/errors. If <code>errors</code> non-empty return with <code>status=&quot;REPLAY_BLOCKED&quot;</code> and diagnostics. <br>3. Acquire replay lock with <code>AcquireRunLock(&quot;replay_&quot;+originalRunId, currentUser, RunLockTimeoutSecs)</code>. <br>4. Set up ephemeral replay context: use <code>configSnapshot</code> from manifest, set <code>codeVersion</code> ideally by loading the versioned module code branch (in Excel this is limited; at a minimum include <code>codeVersion</code> in audit and ensure <code>modTestingHarness</code> runs smoke tests). <br>5. Execute <code>modCoreEngine.RunUpdateHR</code> with <code>dryRun=True</code> and <code>runId</code> set to <code>replay_&lt;originalRunId&gt;_&lt;timestamp&gt;</code>; ensure <code>RunUpdateHR</code> supports <code>overrideConfig</code> to apply manifest config snapshot. <br>6. On completion, call <code>CompareRunDiffs(originalRunId, replayRunId, options)</code> to compute <code>diffReport</code> and <code>parity</code> metrics. <br>7. If <code>replayOptions(&quot;commit&quot;)=True</code> then: confirm <code>parity &gt;= modConfig.ReplayParityThreshold</code> or ensure explicit reviewer approval exists (check <code>__Approvals</code>), then call <code>CommitRun</code> with <code>commitAsReplay</code> flag; write new <code>REPLAY_COMMITTED</code> audit row linking originalRunId and newRunId. <br>8. Return dictionary with <code>replayRunId</code>, <code>parity</code>, <code>diffSummary</code>, <code>warnings</code>, <code>commitStatus</code>. <br>Important caveats:<br>• Replays rely on original <code>configSnapshot</code> and <code>codeVersion</code> for determinism. If code has changed, replay will run but must annotate <code>codeVersionDelta</code> in results. <br>• Replays should never auto-commit without parity checks and approvals. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: CompareRunDiffs</strong><br>Signature: <code>CompareRunDiffs(runIdA As String, runIdB As String, Optional options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Purpose: produce row-level and field-level diffs to help reviewers determine where runs diverge.<br>Algorithm & output:<br>1. Load <code>Audit_Log</code> rows filtered to relevant <code>actionType</code>s for both runs (e.g., APPLY, REVIEW_DECISION). <br>2. Build dictionaries keyed by <code>inputRowHash</code> (preferred) to avoid ordinal sensitivity. <br>3. For each <code>inputRowHash</code> unioned set produce <code>diff</code> object containing: <code>inputRowHash</code>, <code>rowIdA</code>, <code>rowIdB</code>, <code>statusA</code>, <code>statusB</code>, <code>candidateA</code>, <code>candidateB</code>, <code>beforeA</code>, <code>afterA</code>, <code>beforeB</code>, <code>afterB</code>, <code>fieldLevelDiffs</code> (for each changed field list <code>fieldName</code>, <code>valueA</code>, <code>valueB</code>, <code>delta</code>), <code>materialFlag</code> boolean if any delta exceeds <code>options(&quot;materialityThreshold&quot;)</code>. <br>4. Summarize <code>diffSummary</code>: counts <code>Identical</code>, <code>ValueMismatch</code>, <code>CandidateDiff</code>, <code>MissingInA</code>, <code>MissingInB</code>, <code>MaterialDifferences</code>, <code>TopFieldsChanged</code>. <br>5. Persist <code>__Run_Diff_&lt;A&gt;_&lt;B&gt;</code> sheet and optionally export CSV/ndjson. <br>6. Return dictionary <code>{diffCount, diffSummary, diffSheetRef, topMismatches[]}</code>. <br>Options: <code>fieldsToIgnore</code> (e.g., timestamp), <code>materialityThreshold</code>, <code>maxDiffsToReturn</code>. <br>Performance: use dictionary lookups to keep complexity near O(N) where N = combined rows. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: ExportForensics</strong><br>Signature: <code>ExportForensics(runId As String, destPath As String, Optional options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Purpose: assemble a forensic bundle for incident investigation or audit, including audit rows, staging backups, GS traces, fuzzy profiles, manifests, and computed diffs.<br>Contents & behaviour:<br>1. Files typically included: <code>audit.csv</code> (all rows for run), <code>apply_descriptors.ndjson</code>, <code>stage_backup.csv</code>, <code>gs_metrics.csv</code>, <code>fuzzy_profile.csv</code>, <code>manifest.json</code>, <code>diffs.csv</code> (if comparing), <code>simulation_preview.csv</code> (if available). <br>2. Stream-write files to disk in <code>destPath</code> to avoid memory blowouts. <br>3. Create <code>manifest.json</code> with list of files and per-file checksums and <code>archiveChecksum</code>. <br>4. Compress bundle as <code>forensic_&lt;runId&gt;.zip</code> using OS zip (Shell) or helper; if <code>options(&quot;encrypt&quot;)=True</code> then call external helper/service for strong encryption. <br>5. Register artifact in <code>__Forensic_Registry</code> and append <code>FORENSIC_EXPORT</code> audit row with <code>forensicId</code>, <code>location</code>, <code>checksum</code>, <code>createdBy</code>. <br>Return dictionary <code>{forensicId, archivePath, checksum}</code>. <br>Operational notes: store forensic artifacts in secure, access-controlled location per compliance. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: RegisterExternalTrigger</strong><br>Signature: <code>RegisterExternalTrigger(scheduleId As String, triggerConfig As Scripting.Dictionary) As Boolean</code>.<br>Purpose: optionally register schedule with external automation (webhook, RPA worker). <br>Behaviour:<br>1. Validate <code>triggerConfig</code> contains <code>endpointUrl</code>, <code>auth</code> token placeholder (do not store secret in workbook in plaintext). <br>2. Store <code>triggerConfig</code> metadata (without secret) in <code>__External_Triggers</code>. <br>3. If handshake requested, perform <code>ping</code> attempt and write <code>TRIGGER_REGISTERED</code> audit row. <br>Security note: do not store secrets in workbook; use key vault or external helper. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Function-level breakdown: DetectOrphanedLocks</strong><br>Signature: <code>DetectOrphanedLocks() As Collection</code>.<br>Purpose: administrative helper to find and report locks past expiration.<br>Behaviour:<br>1. Scan <code>__Run_Locks</code> for rows where <code>expiresAtUTC &lt; NowUTC</code> and <code>releasedAtUTC</code> blank. <br>2. Return collection of lock dictionaries with <code>lockId</code>, <code>owner</code>, <code>acquiredAtUTC</code>, <code>expiresAtUTC</code>, <code>context</code>. <br>3. For each, append <code>LOCK_ORPHANED_DETECTED</code> audit row and optionally send a notification to admins. <br>Admin action required: owner may be offline; only admin may steal lock which triggers <code>LOCK_STEAL</code> audit entry requiring explanation. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Replay & pre-flight validation: ValidateReplayEnvironment</strong><br>Signature: <code>ValidateReplayEnvironment(originalManifest As Scripting.Dictionary, currentEnv As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Checks performed and possible warnings/errors:<br>1. <code>codeVersion</code> parity — if mismatch produce <code>CODE_MISMATCH</code> warning; if code delta crosses migration boundary produce <code>REPLAY_BLOCKER</code>. <br>2. <code>configSnapshot</code> parity — compare keys; if differences in security or thresholds produce <code>CONFIG_DELTA</code> warnings. <br>3. External services parity — if external scorers or telemetry endpoints differ produce <code>EXTERNAL_MISMATCH</code> warnings. <br>4. Named ranges and Calculator integrity: compute formula hashes for critical cells; if mismatch produce <code>CALCULATOR_MISMATCH</code>. <br>5. Disk/Memory checks for forensic exports and replay operation. <br>Return: <code>{errors[], warnings[], ok:Boolean}</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Conceptual Power Query (PQ) integration guidance</strong><br>1. <strong>Ingest manifests and run plans:</strong> export manifests <code>manifest_runId.json</code> and <code>__Run_Plan</code> as CSV/JSON; PQ <code>Json.Document</code> parse the manifest and expand <code>runPlan</code> into relational rows for BI. <br>2. <strong>Replay parity dashboard:</strong> PQ merges <code>diffSummary</code> CSV with <code>__Telemetry</code> to create time-series visualizations of <code>replayParity</code> and <code>diffTypes</code>. <br>3. <strong>Forensic ingestion:</strong> forensic NDJSON (apply_descriptors ndjson) loaded via PQ into <code>RunEvents</code> table, expand nested <code>beforeJSON</code>/<code>afterJSON</code> for transaction-level analysis. <br>4. <strong>Partition analytics:</strong> import <code>__Run_Plan</code> and compute <code>partitionSkew</code> and <code>hotPartition</code> lists; build visuals to decide rebalancing. <br>Implementation note: always include <code>codeVersion</code> and <code>manifestChecksum</code> columns to filter by baseline in PQ queries. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Conceptual DAX measures for run-level monitoring</strong><br>Suggested measures for a <code>RunSummary</code>/<code>RunPlan</code>/<code>RunDiffs</code> model in Power BI:<br>1. <code>ScheduledRunSuccessRate = DIVIDE([CommittedScheduledRuns],[TriggeredScheduledRuns])</code>.<br>2. <code>AvgReplayParity = AVERAGE(RunDiffs[parity])</code>.<br>3. <code>MaterialMismatchPct = DIVIDE([MaterialMismatchCount],[TotalComparedRows])</code>.<br>4. <code>AvgForensicExportTime = AVERAGE(RunSummary[ForensicExportLatencySeconds])</code>.<br>5. <code>PartitionSkewIndex = VAR mean = AVERAGE(RunPlan[rowCount]) VAR sd = STDEV.P(RunPlan[rowCount]) RETURN DIVIDE(sd,mean)</code>.<br>Use these measures to trigger anomalies and feed operational SLAs. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Telemetry & observability hooks</strong><br>1. Emit telemetry points to <code>modTelemetry.RecordTelemetryPoint</code> at key lifecycle events: <code>SCHEDULE_CREATED</code>, <code>SCHEDULE_TRIGGERED</code>, <code>REPLAY_STARTED</code>, <code>REPLAY_COMPLETED</code>, <code>REPLAY_COMMITTED</code>, <code>FORENSIC_EXPORTED</code>. Each telemetry payload includes <code>runId</code>, <code>scheduleId</code> (if any), durations, parity, artifact sizes, and <code>errorCodes</code> if any. <br>2. Capture <code>LockWaitTime</code> per run and average across runs for bottleneck detection. <br>3. Emit <code>PartitionSkewMetric</code> for each partition plan to identify imbalance. <br>4. Export forensic artifact manifest paths and checksums to telemetry for external ingestion. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Security & governance integration</strong><br>1. Role enforcement: scheduling and cancellation require <code>Operator</code> role; replay commit requires <code>Reviewer</code> or <code>Admin</code> role if run > configured material thresholds. <br>2. Approval workflow: replay commit must be preceded by approval recorded in <code>__Approvals</code> sheet with <code>approverId</code>, <code>approvalTime</code>, <code>approvalToken</code>, <code>rationale</code>. <br>3. Secrets: do not store webhook tokens in workbook plain-text—recommend using an external key vault and only storing reference IDs in <code>__External_Triggers</code>. <br>4. Artifacts retention: <code>modConfig.RetentionDays</code> controls retention for manifests and forensic artifacts; automatic archive/export recommended for longer-term immutable storage. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Edge cases & mitigations</strong><br>1. <strong>Orphaned locks:</strong> detect via <code>DetectOrphanedLocks</code>; require admin unlock with <code>LOCK_STEAL</code> audit entry and rationale; implement automatic expiration policy. <br>2. <strong>Code/config drift:</strong> <code>ValidateReplayEnvironment</code> flags mismatches and blocks commit; require admin sign-off to proceed with commit if drift is present. <br>3. <strong>Missing staging backup for replay:</strong> block replay with reason <code>MISSING_BACKUP</code>; generate forensic pack suggestion and notify admin. <br>4. <strong>Huge forensic export memory:</strong> always stream to file and avoid in-memory aggregation; chunk writes recommended with <code>bufferSize</code> tuned per environment. <br>5. <strong>Partition hot-keys:</strong> if a partition key (e.g., large cost-center) exceeds partition size, split into deterministic subpartitions using <code>crc32(inputRowHash) mod N</code>. <br>6. <strong>Time zone confusion:</strong> store all schedule timestamps in UTC and show local conversions in UI; manifest always uses UTC. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Performance & scaling guidance</strong><br>1. For very large runs (100k+ rows), always use <code>PartitionRun</code> and process partitions in parallel worker processes or separate workbook instances. <br>2. Use chunked commit in <code>modCoreEngine</code> with <code>modConfig.BatchSize</code> to apply staged changes; <code>modBatchUtilities</code> coordinates chunk ordering and final commit sequence. <br>3. Avoid heavy Excel sheet operations in single threads; do in-memory processing and only write outputs at chunk boundaries. <br>4. Use streaming writes (Append-to-file) for forensic artifacts and diffs to minimize memory. <br>5. For parallel workers, ensure central lock manager (worksheet <code>__Run_Locks</code>) is the single source of truth to prevent commit races. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Testing & validation checklist</strong><br>Unit and integration tests for <code>modBatchUtilities</code> (to include in <code>modTestingHarness</code>):<br>1. <code>ScheduleRun</code> validation test: schedule with missing named ranges fails with <code>VALIDATION_FAILED</code>. <br>2. <code>CancelScheduledRun</code> transitions status to <code>CANCELLED</code> when pending. <br>3. <code>AcquireRunLock</code> enforces exclusivity and <code>DetectOrphanedLocks</code> finds expired locks. <br>4. <code>PartitionRun</code> on skewed data produces subpartitions and <code>maxRowsPerPartition</code> respected. <br>5. <code>CreateRunManifest</code> includes <code>stagingChecksum</code> matching <code>__Stage_Backup_&lt;runId&gt;</code> checksum. <br>6. <code>ReplayRun</code> dry-run parity >= expected on canonical sample; commit blocked without approval if parity below threshold. <br>7. <code>CompareRunDiffs</code> correctly classifies <code>Identical</code>, <code>ValueMismatch</code>, and <code>MaterialMismatch</code> using synthetic inputs. <br>8. Forensic export streams large artifacts successfully and <code>__Forensic_Registry</code> entry present. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Operational runbook snippets (procedural)</strong><br>1. Schedule a night run: Operator → UI → Schedule options → <code>ScheduleRun</code> → confirm <code>__Run_Schedule</code> entry → ensure external trigger registered. <br>2. Monitor scheduled run: automation polls <code>__Run_Schedule</code>; when triggered <code>AcquireRunLock</code> called; run status set to <code>IN_PROGRESS</code>. <br>3. If run fails: check <code>__Run_Status</code>, check <code>__Run_Locks</code> for stale locks, generate <code>ForensicPack</code> and escalate to operations. <br>4. Replay for audit: retrieve <code>manifest</code>, <code>ValidateReplayEnvironment</code>, run <code>ReplayRun</code> dry-run, review <code>diffReport</code>, collect approvals, commit if parity acceptable. <br>5. For incident revert: use <code>ApplyDescriptors</code> plus <code>__Stage_Backup_&lt;runId&gt;</code> to compose revert applydescriptor and run in dry-run to validate before committing. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Power Query (PQ) example steps for run artifacts</strong><br>1. Source: <code>manifest_runId.json</code> exported from <code>CreateRunManifest</code> — use <code>Json.Document</code> to parse manifest. <br>2. Expand <code>runPlan</code> array to table, transform <code>startOrdinal</code> and <code>endOrdinal</code> to numeric, create <code>partitionSize</code> column. <br>3. Load <code>__Run_Diff_&lt;A&gt;_&lt;B&gt;.csv</code>, filter <code>materialityThreshold</code> column and expand <code>fieldsChanged</code> nested JSON for top fields analysis. <br>4. Combine manifest, telemetry, and diff tables to compute daily <code>ReplayParity</code> trends and <code>PartitionSkew</code> over time. <br>5. Export PQ outputs as <code>RunDashboard</code> tables for Power BI. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Conceptual DAX measures for run & partition dashboards</strong><br>1. <code>ReplayParityRate = DIVIDE([MatchedRows],[TotalComparedRows])</code>.<br>2. <code>AvgPartitionSize = AVERAGE(RunPlan[rowCount])</code>.<br>3. <code>HotPartitionRatio = DIVIDE(MAX(RunPlan[rowCount]), SUM(RunPlan[rowCount]))</code>.<br>4. <code>ForensicExportCoverage = DIVIDE(COUNTROWS(FILTER(RunSummary,RunSummary[forensicExported]=TRUE)), COUNTROWS(RunSummary))</code>.<br>5. <code>AvgLockWaitSeconds = AVERAGE(RunTelemetry[LockWaitTimeSeconds])</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Examples & narratives (human readable)</strong><br>Example 1 — Nightly scheduled job (small):<br>- Operator schedules <code>staff_list_weekly</code> at <code>02:00Z</code>. <code>ScheduleRun</code> writes <code>__Run_Schedule</code>. An external orchestrator polls and triggers at time; workbook acquires lock and runs <code>RunUpdateHR</code> in normal flow. On success <code>CreateRunManifest</code> persisted and <code>manifest_runId.json</code> exported to secure share. <br>Example 2 — Large payroll batch partitioned:<br>- 120k input rows partitioned by <code>costCenter</code> into 60 partitions (2k rows each). Workers process partitions in parallel; central orchestrator performs sequential chunk-level commits to avoid cross-partition write clashes on shared ledgers. <code>__Run_Plan</code> persisted to provide operator visibility. <br>Example 3 — Replay for audit:<br>- External auditor requests replay of <code>runId=abc123</code>. <code>ReplayRun</code> loads manifest, detects <code>codeVersion</code> matches, runs dry-run, parity = 99.985%. Produce <code>replay_diff.html</code> and <code>forensic_abc123.zip</code>. Auditor approves commit; new run recorded <code>replayOf=abc123</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Operational metrics to collect</strong><br>1. <code>ScheduledRunLatency</code> (time between scheduledTime and trigger execution). <br>2. <code>ReplayParityDistribution</code> across codeVersions. <br>3. <code>AverageForensicExportTime</code> and <code>ExportFailureRate</code>. <br>4. <code>LockContentionRate</code> (percent of schedule attempts that wait for lock). <br>5. <code>PartitionSkew</code> (variance/mean of partition row counts). </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Recommended governance & policies</strong><br>1. Require stored manifests for every run and persist them to secure central blob store nightly. <br>2. Require reviewer approval for replay commits where <code>materiality &gt; modConfig.ReplayMaterialityThreshold</code>. <br>3. Rotate run-manifest export keys and use an external key vault for webhook secrets. <br>4. Keep forensic archives for <code>modConfig.RetentionDays</code> and push immutable copies to central audit DB for long-term retention. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Implementation checklist for engineers</strong><br>1. Implement robust lock semantics with expiry and explicit release; include <code>owner</code> and <code>purpose</code> fields. <br>2. Implement streaming write helpers for CSV/NDJSON to avoid memory issues. <br>3. Create deterministic manifest builder and JSON serializer. <br>4. Ensure <code>ReplayRun</code> supports running <code>modCoreEngine.RunUpdateHR</code> with override config and dry-run mode. <br>5. Provide a secure artifact registry and <code>__Forensic_Registry</code> sheet with access control metadata. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Testing scenarios to include in CI</strong><br>1. End-to-end scheduled-run simulation (single small dataset). <br>2. Partitioning logic on synthetic skewed input (verify subpartition creation). <br>3. Replay parity test for known golden run (dry-run parity must match golden). <br>4. Forensic export streaming test with very large dataset to validate memory usage. <br>5. Lock concurrency test: attempt concurrent acquisitions and ensure single-holder semantics. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Known limitations & future enhancements</strong><br>1. Excel-level limitations: module cannot enforce codeVersion rollback automatically; for strict determinism a source-controlled deployment process is necessary that pins module code. <br>2. Secrets storage: workbook should not store secrets; integrate with external key vault for robust security. <br>3. Parallel commit complexities: full parallel commit safety requires target-system-level isolation or transaction support—otherwise commit sequencing is required. <br>4. External triggers: for robust scheduling use enterprise schedulers (Airflow/RPA) with idempotent webhooks rather than trusting workbook timers. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchUtilities (VBA)"> <strong>Final operational summary</strong><br><code>modBatchUtilities</code> is the safety gate and automation backbone for scheduled processing, deterministic replay, forensic evidence collection, and run partitioning. It ensures runs are scheduled and replayed reproducibly, prevents concurrent conflicts via locks, provides partitioning strategies for scale, emits machine-readable manifests for audit and PQ ingestion, and creates forensic bundles for investigations. Implementers should pair this module with strict code-versioning, secure artifact stores, and conservative governance to achieve enterprise-grade auditability and safety. </td></tr></tbody></table></div><div class="row-count">Rows: 33</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>