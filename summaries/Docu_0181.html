<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771304657">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0181_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Export — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Export — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_EXPORT — documented in OWNERS.md with on-call rotation, approvers, and escalation contacts listed in release manifests. <br><strong>Public API (complete surface):</strong> PrepareExportPayload, ComputeMChecksum, CollectPQDiagnostics, PackageExportArtifact, AtomicExport, VerifyExport, StageLocalFallback, RetryExport, EmitExportAuditRow, WriteExportManifest, ValidateExportDestination, EncryptAndSignArtifact, InspectTempArtifacts, RepairExportArtifact, RotateExportRetention, ExportConnectionsList, ExportQueryList, ExportTemplateArchive, ExportReports, ExportIdempotencyKey, ExportSigningKeyRotate, ExportEvidencePublish. <br><strong>Audits emitted:</strong> pq_export.attempt, pq_export.completed, pq_export.failure, pq_export.verification_failed, pq_export.degraded, pq_export.stage_local, pq_export.manifest_written, pq_export.temp_artifact_found, pq_export.repair, pq_export.rotate_retention, pq_export.prepare.start/complete/failure, pq_export.package.attempt/completed, pq_export.atomic.attempt/completed/failure, pq_export.verify.attempt/result, pq_export.diagnostics.collected. Every audit row includes: correlationId, module=PQ_Export, procedure, paramsHash, artifactChecksum (where applicable), destinationUri (sanitized), timestamp, operatorId (if interactive), evidenceRef when full payload or diagnostics are stored externally. <br><strong>Purpose & intended use:</strong> orchestrate deterministic, auditable, crash-safe export of Power Query artifacts (M queries, parameter manifests, connection descriptors) and diagnostics. Provide canonical packaging, compute stable fingerprints (mChecksum and artifactChecksum), write artifacts atomically to durable storage (with staged fallback), verify integrity, sign/encrypt when required by policy, and emit audits and manifests for downstream reconciliation and compliance. Intended to run in worker/agent contexts; not on the ribbon UI thread. <br><strong>Non-goals / constraints:</strong> not responsible for credential lifecycle management (use CORE_CredentialVault); not a general-purpose long-term archive engine (use CORE_Storage for lifecycle beyond export retention); not performing heavy interactive UI operations; will not attempt to recover corrupted remote stores automatically beyond safe staged retransfer patterns; must not include raw PII in top-level audit fields (use evidenceRef for detailed payloads). </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Determinism: identical canonical inputs, correlationId, and configuration produce identical artifact bytes and checksums across supported hosts. <br>2. Atomicity: consumers observe either the previous artifact or the new artifact — never a truncated file. <br>3. Audit-anchored: each export attempt emits at least one audit row anchored to correlationId and paramsHash. <br>4. Verification: artifacts are checksummed and verified post-write; any mismatch triggers controlled rollback and an explicit verification failure audit. <br>5. Degraded path: when atomic replace semantics unavailable (e.g., some NFS/SMB deployments), module falls back to documented staged-local flows and emits pq_export.degraded with rationale. <br>6. UI safety: no long blocking IO on UI thread; export orchestration must occur in background worker processes or scheduled jobs. <br><strong>SLOs:</strong> median atomic export for 1MB artifact on local SSD <200ms; verify pass rate >99.9% in healthy infra; stage-local fallback success >99% when remote is degraded. <br><strong>CI / acceptance gates:</strong> cross-platform golden artifact parity, manifest write atomicity tests, degraded-path tests (simulated NFS failure), signature verification tests, audit emission verification, forbidden-API static checks. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>High-level workflow & invariants (conceptual runbook):</strong><br>1. Prepare & canonicalize artifact inputs (PrepareExportPayload). <br>2. Compute stable mChecksum for template + params (ComputeMChecksum). <br>3. Collect host/query diagnostics (CollectPQDiagnostics). <br>4. Package canonical contents into deterministic archive (PackageExportArtifact). <br>5. Validate destination (ValidateExportDestination). <br>6. Use AtomicExport to write artifact atomically; on failure, use RetryExport orchestration. <br>7. Verify exported artifact (VerifyExport). <br>8. Persist manifest atomically (WriteExportManifest). <br>9. Emit export audit rows linking artifactChecksum, mChecksum, manifestChecksum. <br>10. If primary path unavailable, StageLocalFallback and schedule retransfer job using ExportIdempotencyKey. <br><strong>Cross-cutting invariants:</strong> deterministic RNG seeded from correlationId for sampling; any numeric-critical transforms must be offloaded to SafeRound flows; all long-lived state writes accompanied by audit rows and optional evidenceRef to encrypted evidence storage. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>PrepareExportPayload(inputs, templateMeta, diagnostics=null, requireHighPrecision=false)</code></strong><br><strong>Purpose & contract:</strong> produce a canonical, deterministic payload from M queries and parameter metadata suitable for packaging. Must be pure and side-effect free. Ensures stable normalization (syntax/whitespace/Unicode), deterministic parameter ordering, and optional decimal normalization for high-precision templates. Returns {canonicalMMap, paramsManifest, diagnosticsBlob, payloadFingerprint}. <br><strong>Parameters & return:</strong> <br>• <code>inputs</code>: list of query objects: {name, originalM, parameters}. <br>• <code>templateMeta</code>: {templateId, templateVersion, ownerId, packagingPolicy}. <br>• <code>diagnostics</code>: optional diagnostics snapshot collected by host (may be null). <br>• <code>requireHighPrecision</code>: boolean. <br>Return: payload object with canonicalized M texts keyed by query name, paramsManifest JSON string with stable ordering, optional diagnosticsBlob reference, and payloadFingerprint = sha256hex(canonicalM + paramsManifest + diagnosticsBlob) computed deterministically. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic canonicalization: same inputs -> same canonical outputs. <br>2. No time-variant metadata in canonicalized blobs (strip mtimes, host-specific IDs). <br>3. PII handling: sanitize sensitive param values and produce evidenceRef for encrypted full params. <br><strong>Algorithm & implementation notes:</strong><br>1. Parse M via a parser-aware normalization step to avoid accidental semantic changes; do not use naive regexes. <br>2. Normalize Unicode to NFC and line endings to LF. <br>3. Remove comment blocks that are explicitly flagged as non-authoritative or developer comment-only regions, but preserve comment markers for audit traceability. <br>4. Normalize numeric literals: when requireHighPrecision true annotate decimals with explicit metadata (scale) and include decimal normalization map in diagnosticsBlob. <br>5. Serialize paramsManifest to compact, canonical JSON with stable key ordering and deterministic number formatting (e.g., fixed exponent notation rules). <br>6. Compute payloadFingerprint as streaming SHA256 to support large inputs. <br><strong>Edge cases & invalid inputs:</strong><br>1. Unparseable M text: return EX_PQ_PREP_PARSE_FAIL with error position and emit pq_export.prepare.failure. <br>2. Excessively large artifacts (> configured cap): return EX_PQ_PREP_TOO_LARGE and suggest chunking. <br>3. Mixed encodings: coerce to UTF-8 or error EX_PQ_PREP_ENCODING_FAIL. <br><strong>Observability & audit fields:</strong> pq_export.prepare.start(correlationId, templateId, payloadCandidateHash) and pq_export.prepare.complete(correlationId, payloadFingerprint, durationMs). On error emit pq_export.prepare.failure with evidenceRef. <br><strong>Examples & narratives:</strong><br>1. Template preview edited by operator: PrepareExportPayload canonicalizes edited M ensuring that visual whitespace changes do not alter canonical payloadFingerprint used to prove that injected query equals the exported artifact. <br>2. High-precision finance template: requireHighPrecision true causes decimal map to be included and recorded so rounding decisions can be replayed for compliance. <br><strong>Tests & CI vectors:</strong><br>1. Unicode normalization golden vectors. <br>2. Parser re-serialization round-trip test: parse canonicalM -> reserialize -> identical string. <br>3. Fuzzed invalid M inputs verifying safe error reporting. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ComputeMChecksum(canonicalMMap, paramsManifest)</code></strong><br><strong>Purpose & contract:</strong> compute a stable <code>mChecksum</code> fingerprint for a template package formed by canonicalMMap and paramsManifest. <code>mChecksum</code> is the canonical fingerprint used to track template versions and map to provenance. Implementation must produce identical results across supported languages and OSes. <br><strong>Parameters & return:</strong> canonicalMMap: map of queryName->canonicalM; paramsManifest: canonical JSON string. Returns {mChecksum: sha256hex, mShort: first12chars}. <br><strong>Primary invariants:</strong><br>1. Input must be canonicalized via PrepareExportPayload. <br>2. Hash computation uses canonical concatenation order: alphabetically ordered query names; each canonicalM is prefixed with a stable header (e.g., "===query:<name>===\n"). <br><strong>Algorithm & implementation notes:</strong><br>1. Use streaming SHA256 to handle large query sets. <br>2. Combine inputs as: for each queryName in sorted(canonicalMMap): append header + canonicalM; after queries append paramsManifest with an explicit newline separator. <br>3. Return hex digest lowercase; compute short reference for UI caches. <br><strong>Edge cases:</strong><br>1. Empty template (no queries): defined mChecksum = SHA256("EMPTY_TEMPLATE_v1") to avoid nulls. <br>2. Non-UTF8 bytes: reject with EX_PQ_CHECKSUM_ENCODING_FAIL. <br><strong>Observability & audit fields:</strong> pq_export.mchecksum(correlationId, templateId, mChecksum). <br><strong>Tests:</strong> cross-language parity golden tests for known canonical inputs. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>CollectPQDiagnostics(connectionHandles, queries, refreshContext, samplePolicy)</code></strong><br><strong>Purpose & contract:</strong> collect structured diagnostics for a preview/export run including provider traces, query step timings, folding metadata, error stacks, and refresh path sequences. When volume of traces is large apply deterministic sampling seeded by correlationId. Diagnostics must be scrubbed to remove credentials and secrets; any sanitized portion must be stored separately encrypted and referenced by evidenceRef. <br><strong>Parameters & return:</strong> connectionHandles: list of connections; queries: list of query descriptors; refreshContext: {hostOs, powerQueryVersion, providerVersions, correlationId}; samplePolicy: {maxTraces, samplingSeed=null}. Returns diagnosticsBlob (possibly compressed) and diagnosticsFingerprint. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic sampling: when sampling is needed, use DeterministicRNG seeded from correlationId so replay reproduces same sample. <br>2. No secrets: scrub credentials, tokens; replace with scrubbed placeholders and produce evidenceRef for full encrypted traces when required. <br><strong>Algorithm & implementation notes:</strong><br>1. Capture per-query metrics: loadTimeMs, foldHint, provider, step-level timings, lastError message (redacted), and provider trace snippets. <br>2. For provider-level network traces capture only metadata and error frames; avoid storing connection strings or raw tokens. <br>3. Compress large traces and store in evidence store with evidenceRef referenced in diagnosticsBlob when size exceeds threshold. <br><strong>Edge cases:</strong><br>1. Unknown provider: produce minimal stub and emit pq_export.diagnostics.partial. <br>2. Provider returns binary traces: compress and record evidenceRef. <br><strong>Observability & audit fields:</strong> pq_export.diagnostics.collected(correlationId, diagnosticsFingerprint, queriesCount, evidenceRefOptional). <br><strong>Examples:</strong> a PQ refresh failing on OLEDB provider yields diagnosticsBlob capturing step timings and provider error codes enabling SRE to triage underlying data source issues. <br><strong>Tests:</strong> scrub tests verifying no credentials in diagnostics; parity tests under deterministic sampling. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>PackageExportArtifact(payload, mChecksum, diagnosticsBlob=null, manifestFields={})</code></strong><br><strong>Purpose & contract:</strong> produce a deterministic archive (artifact) containing canonicalM files, paramsManifest, optional diagnostics, and manifest stub. Artifact bytes must be canonical across hosts (no variable mtimes or host-specific metadata) and include a packagingVersion to allow future format evolution. Returns artifactStream (seekable), artifactSizeBytes, artifactFingerprintCandidate (sha256hex). <br><strong>Packaging rules & invariants:</strong><br>1. Deterministic archive: file ordering fixed, metadata normalized (mtime=0, uid/gid stripped or normalized), compression deterministic (fixed compression level if used). <br>2. Manifest included as first entry: manifest stub contains correlationId, mChecksum, packagingVersion, templateVersion, ownerId, packagingPolicy. <br>3. Archive format policy: prefer deterministic ZIP with normalized headers; alternative tar+gz with deterministic headers permitted but must be signaled in packagingVersion. <br><strong>Algorithm & implementation notes:</strong><br>1. Build archive in streaming manner computing SHA256 while writing. <br>2. Files layout example: manifest.json, queries/<name>.m, params.json, diagnostics/<fingerprint>.json (if present), reports/. <br>3. Use canonical header for each file (no timestamps, deterministic perms). <br><strong>Edge cases & fallbacks:</strong><br>1. Host lacks deterministic ZIP implementation: implement deterministic tar writer or produce content manifest JSON + flat file set; emit pq_export.package.degraded and add rationale. <br>2. Artifact size > allowed thresholds: split into chunked package files and produce top-level reassembly manifest. <br><strong>Observability & audit fields:</strong> pq_export.package.attempt(correlationId, artifactCandidateFingerprint, artifactSizeBytes). pq_export.package.completed(correlationId, artifactFingerprintCandidate). <br><strong>Examples:</strong> packaging step ensures identical artifact bytes produced in CI golden run and on operator workstation — allowing byte-for-byte provenance checks. <br><strong>Tests:</strong> cross-platform byte-for-byte parity tests for representative template sets; reassembly tests for chunked artifacts. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>AtomicExport(artifactStream, artifactPath, tmpSuffix=&quot;.pqpart&quot;, fsyncFile=true, fsyncParent=true, perms=null, maxAttempts=3)</code></strong><br><strong>Purpose & contract:</strong> write artifact to <code>artifactPath</code> using crash-safe atomic semantics. After success, <code>artifactPath</code> must contain the new artifact with verified checksum, and no caller should observe a truncated (partial) artifact. Return {success, artifactPath, artifactChecksum, attempts, elapsedMs}. On failure emit pq_export.atomic.failure with diagnostics. <br><strong>Detailed step-by-step behavior (must/shall):</strong><br>1. Call ValidateExportDestination to ensure path canonical and acceptable. <br>2. Compute tempPath = artifactPath + tmpSuffix + "." + pid + "." + deterministicSuffix. <br>3. Open tempPath with exclusive create flags (O_EXCL); stream artifact bytes while computing SHA256; optionally write sidecar metadata file with payloadFingerprint, correlationId and packagingVersion. <br>4. If fsyncFile true ensure fdatasync/fsync called on file descriptor after write completes. <br>5. Use atomic replace semantics: os.replace on POSIX or ReplaceFile/MoveFileEx with appropriate flags on Windows. <br>6. If fsyncParent true, fsync parent directory to ensure rename persistence. <br>7. Re-open artifactPath read-only and compute SHA256 to verify artifactChecksum equals computed checksum. <br>8. On verification mismatch perform controlled rollback, attempt repair from tempPath if possible, and emit pq_export.verification_failed. <br>9. On transient errors (EINTR, EIO, ETIMEDOUT), apply RetryExport wrapper according to retry/backoff policy. <br><strong>Cross-platform concerns & documented fallbacks:</strong><br>1. Network filesystems with weak rename semantics: detect mountType via ValidateExportDestination; if not safe, return E_DEGRADED and recommend StageLocalFallback. <br>2. Windows locked-file semantics: handle SHARE_DENY and implement retry/backoff with escalating operator notification. <br>3. Cross-device renames: copy-and-rename-safe-sequence with atomic marker file approach and pq_export.degraded audit. <br><strong>Recovery & runbook:</strong><br>1. If temp artifacts persist on failure, call InspectTempArtifacts and present candidate temp copies for repair. <br>2. For ENOSPC: emit pq_export.atomic.ENOSPC with mount path and freeBytes; optionally trigger StageLocalFallback. <br>3. For permission denied: emit pq_export.atomic.EPERM with ACL snapshot evidenceRef. <br><strong>Observability & audit fields:</strong> pq_export.atomic.attempt(correlationId, artifactPath, tempPath, payloadFingerprint) pq_export.atomic.completed(correlationId, artifactPath, artifactChecksum, durationMs, attempts) pq_export.atomic.failure(correlationId, artifactPath, errorCode, attempts, diagnosticsRef). <br><strong>Tests & CI:</strong> simulate rename/fsync failures via filesystem mocks; concurrency tests with concurrent readers to verify there are no partial reads observed; cross-OS tests for replace semantics. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>VerifyExport(artifactPath, expectedChecksum, allowRepair=false)</code></strong><br><strong>Purpose & contract:</strong> recompute artifact checksum and compare to expected; if mismatch and allowRepair true attempt repair using available temp artifacts. Return {verified: bool, actualChecksum, repairAttempted: bool, repairResult}. <br><strong>Steps:</strong><br>1. Stream-read artifactPath computing SHA256; compare to expectedChecksum. <br>2. If matches, emit pq_export.verify.result verified. <br>3. If mismatch and allowRepair true: InspectTempArtifacts for candidate temp copies; for each candidate compute checksum and if matches expectedChecksum attempt atomic replace via RepairExportArtifact. <br>4. If repair fails, emit pq_export.verification_failed and escalate if artifact marked regulated. <br><strong>Edge cases:</strong><br>1. Corrupt reads due to partial writes: ensure AtomicExport invariants; if detected, escalate to SRE with forensic_manifest. <br><strong>Observability & audit fields:</strong> pq_export.verify.attempt(correlationId, artifactPath, expectedChecksum) pq_export.verify.result(correlationId, artifactPath, verified, actualChecksum, durationMs). <br><strong>Tests:</strong> inject corrupted bytes into artifact and assert verify detects mismatch and repair path works when temp copy available. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>StageLocalFallback(artifactStream, stagePath, policy={})</code></strong><br><strong>Purpose & contract:</strong> persist artifact locally when primary destination unavailable; persist using local AtomicWrite semantics and emit pq_export.stage_local with reason and stagedChecksum. Schedules retransfer job with ExportIdempotencyKey for eventual finalization. <br><strong>Behavior & steps:</strong><br>1. Choose stagePath preferably on same volume as retransfer worker to avoid cross-device copy. <br>2. Write using AtomicExport semantics on local FS; compute stagedChecksum. <br>3. Emit pq_export.stage_local(correlationId, stagePath, stagedChecksum, reason). <br>4. Persist a retransferDescriptor (AtomicWrite) containing stagePath, targetDestination, ExportIdempotencyKey, and schedule time. <br>5. For regulated artifacts require two-person approval audit row before stage-local permitted. <br><strong>Governance & security:</strong> stage directories must be access-controlled and encrypted-at-rest according to policy; stage retention limited and managed by RotateExportRetention. <br><strong>Observability & audit fields:</strong> pq_export.stage_local(correlationId, stagePath, stagedChecksum, reason). <br><strong>Tests:</strong> simulate remote store outages and verify stage-local write and scheduled retransfer artifacts. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>RetryExport(fn_export, retries=3, backoff={baseMs:200, factor:2}, jitter=true, deterministic_jitter=false, idempotencyKey=null, cancelToken=null)</code></strong><br><strong>Purpose & contract:</strong> robust retry orchestration wrapper to handle transient export failures while preserving idempotency semantics. Emit pq_export.retry.attempt and pq_export.retry.complete audits. <br><strong>Behavioral rules & safeguards:</strong><br>1. Only retry on exceptions classified as transient in ExportError taxonomy. <br>2. If idempotencyKey provided ensure fn_export is safe to re-run or external idempotency guard present. <br>3. If deterministic_jitter true use DeterministicRNG seeded from correlationId to compute jitter for CI repeatability. <br>4. Honor cancelToken to abort early and emit pq_export.retry.cancelled. <br><strong>Backoff semantics:</strong><br>1. backoffMs = baseMs * factor<strong>(attemptIndex-1) with jitter applied. <br>2. Limit total retry budget per-call to avoid worker starvation. <br></strong>Observability & audit fields:<strong> pq_export.retry.attempt(correlationId, target, attemptIndex, errorCode, backoffMs) pq_export.retry.complete(correlationId, target, attempts, outcome, elapsedMs). <br></strong>Tests & policy enforcement:** static analyzer rejects RetryExport usage from UI thread; CI uses deterministic_jitter for golden timing tests. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>EmitExportAuditRow(correlationId, operatorId, procedure, paramsHash, resultHash=null, artifactChecksum=null, destinationUri=null, evidenceRef=null, metadata={})</code></strong><br><strong>Purpose & contract:</strong> canonical method to write an audit row for PQ_Export with consistent schema and PII constraints. Writes to CORE_Audit append-only buffer and persists audit_tail locally for immediate forensic needs. <br><strong>Schema fields:</strong> timestamp, correlationId, module=PQ_Export, procedure, operatorId, paramsHash, resultHash, artifactChecksum, destinationUri(sanitized), evidenceRef, durationMs, errorCode (optional), metadata object. <br><strong>Constraints:</strong> do not include raw PII in top-level fields; when full parameters or raw traces are needed store them encrypted in evidence store and reference with evidenceRef. <br><strong>Behavior & notes:</strong> audit append must be low-latency and non-blocking; for critical failures perform synchronous flush to local durable buffer to ensure persisted trail even if downstream telemetry fails. <br><strong>Observability:</strong> audit write returns auditRowId and optional evidenceRef pointer for external evidence. <br><strong>Tests:</strong> audit schema conformance tests and retention verification tests in CI. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>WriteExportManifest(artifactPath, artifactChecksum, manifestPath, manifestFields)</code></strong><br><strong>Purpose & contract:</strong> atomically persist final manifest JSON mapping artifact to provenance metadata. Must be written atomically and include configHash and correlationId. Returns manifestChecksum. <br><strong>Required manifest fields:</strong> correlationId, artifactPath, artifactChecksum, mChecksum, packagingVersion, templateVersion, ownerId, operatorId (optional), configHash, signedBy (if signature applied), packagingPolicy, timestamp. <br><strong>Behavior & steps:</strong><br>1. Build manifest JSON with canonical key order and deterministic formatting. <br>2. Persist manifest via AtomicExport (AtomicWrite) to manifestPath to ensure either old or new manifest persists. <br>3. Optionally sign manifest using EncryptAndSignArtifact signing flow and include signatureRef in manifest. <br>4. Emit pq_export.manifest_written(correlationId, manifestPath, manifestChecksum). <br><strong>Edge cases:</strong> manifest write failure after artifact persisted must produce pq_export.manifest_missing audit and schedule compensating job to re-attempt manifest write. <br><strong>Tests:</strong> simulate manifest write failure and assert compensating behavior. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>ValidateExportDestination(destinationUri, requireExists=true, requireWrite=true, artifactSizeBytes=null)</code></strong><br><strong>Purpose & contract:</strong> pre-flight validation of export destination: path canonicalization, permission check, free-space check, and semantics detection (local, NFS, SMB, cloud bucket). Return validatedDestination object with canonicalPath, mountType, supportsAtomicReplace boolean, freeBytes. <br><strong>Checks performed:</strong><br>1. Path canonicalization (no traversal, normalized symlinks). <br>2. Existence check if required. <br>3. Write/replace permission check for effective user. <br>4. If artifactSizeBytes provided check free space and enforce ENOSPC policy. <br>5. Detect mount type and atomic replace support heuristics. <br><strong>Behavior on mismatch:</strong><br>1. If insufficient free space return EX_PQ_DEST_ENOSPC with mount path and freeBytes. <br>2. If mount lacks atomic replace for regulated artifacts return EX_PQ_DEST_NOT_SAFE and recommend StageLocalFallback. <br><strong>Observability:</strong> pq_export.destination.validated(correlationId, destinationUri, mountType, freeBytes) <br><strong>Tests:</strong> path traversal attack vectors, permission denial and insufficient space cases. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>EncryptAndSignArtifact(artifactStream, encryptionPolicy=null, signingKeyRef=null)</code></strong><br><strong>Purpose & contract:</strong> optional encryption/signing of artifact for confidentiality and non-repudiation per packagingPolicy. Encryption uses envelope encryption (ephemeral AES-GCM data key wrapped with KMS); signing uses detached signature persisted as signatureRef in manifest. Return {transformedArtifactStream, postTransformChecksum, signatureRef, evidenceRef}. <br><strong>Security constraints:</strong> private signing keys in HSM or CORE_KeyVault; signing performed in secure worker context; do not store signing keys in local disk. <br><strong>Behavior:</strong><br>1. If encryptionPolicy set: generate ephemeral data key, encrypt stream using AES-GCM while streaming, wrap data key via KMS and include key-wrap metadata in manifest. <br>2. Compute checksum of encrypted artifact as artifactChecksumPostEncryption. <br>3. If signingKeyRef provided: compute detached signature over final artifact bytes and persist signatureRef. <br><strong>Observability & audit fields:</strong> pq_export.encrypt.attempt, pq_export.sign.attempt, pq_export.encrypt.completed, pq_export.sign.completed with evidenceRef to key-wrap metadata. <br><strong>Edge cases & guidance:</strong><br>1. Ensure manifest includes key-wrap metadata and signatureRef. <br>2. For downstream consumers require public key or verification endpoint. <br><strong>Tests:</strong> round-trip encryption/decryption with mocked KMS, signature verification tests, negative tests for missing key permissions. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>InspectTempArtifacts(baseTempDir, correlationId=null, tmpSuffix=&quot;.pqpart&quot;)</code></strong><br><strong>Purpose & contract:</strong> scan temp directories for artifacts left by failed AtomicExport attempts, surface candidate temp copies for repair or forensic capture. Return listing with tempPaths, size, ownerPid, ageMs, candidatePayloadFingerprint computed where readable. <br><strong>Behavior:</strong><br>1. Enumerate temp files matching tmpSuffix pattern. <br>2. For each candidate attempt to compute payloadFingerprint (streaming hash) if readable. <br>3. Emit pq_export.temp_artifact_found(correlationId, tempPath, candidateFingerprint, ageMs). <br><strong>Repair guidance:</strong> only attempt automatic repair when ownership and permissions validated and within maintenance window. Otherwise persist forensic manifest and notify SRE. <br><strong>Tests:</strong> create temp artifacts of varying ages and verify detection. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>RepairExportArtifact(tempPath, targetPath, allowOverwrite=false, dryRun=true)</code></strong><br><strong>Purpose & contract:</strong> attempt to recover final artifact from a verified temp copy and atomically place it into <code>targetPath</code>. Must validate checksum and operator approvals before overwriting. Returns repairResult {repaired, reason, beforeChecksum?, afterChecksum?}. <br><strong>Safety rules:</strong><br>1. Require maintenance window or operator approval for cross-process overwrite in production. <br>2. Verify temp candidate checksum matches manifest expectation before replacing. <br>3. If dryRun true only report actions without performing replace. <br><strong>Behavior & steps:</strong><br>1. Read tempPath compute checksum. <br>2. Compare to expectedChecksum from manifest or artifact sidecar. <br>3. If matches and allowOverwrite true perform AtomicExport-style atomic replace (rename) with proper fsyncs. <br>4. Emit pq_export.repair(correlationId, tempPath, targetPath, result). <br><strong>Tests:</strong> repair success for valid temp copy and safe no-op when dryRun. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong><code>RotateExportRetention(exportRoot, policy)</code></strong><br><strong>Purpose & contract:</strong> implement retention lifecycle for export artifacts and manifests. Delete or archive artifacts per retention buckets; preserve artifacts flagged as regulatory or protected. Emit pq_export.rotate_retention audit summarizing actions. <br><strong>Policy-driven steps:</strong><br>1. Enumerate artifacts and manifests under exportRoot. <br>2. Compute age and retention bucket per policy rules. <br>3. For deletions record forensic_manifest entries and perform secure delete or archive to warm/cold store; for archives write archive manifest and perform AtomicExport to archive store. <br>4. Emit pq_export.rotate_retention(correlationId, deletedCount, archivedCount, retainedProtectedCount). <br><strong>Edge cases:</strong><br>1. External references: if artifact referenced by other services mark retain and emit retention_conflict audit. <br><strong>Tests:</strong> simulation with mock artifacts and protected flags verifying no unintended deletions. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Domain helper functions & convenience helpers:</strong><br><strong>ExportConnectionsList(connectionDescriptors, manifestFields)</strong> — produce canonical connections list with stable ordering, excluding raw credentials. <br><strong>ExportQueryList(queries, includeDependencies=false)</strong> — exports query names, mChecksum references, dependency graph, folding hints. <br><strong>ExportTemplateArchive(librarySelection)</strong> — packages multiple templates into a single export artifact with manifest mapping templateId -> mChecksum; supports per-template packagingVersion and per-template evidenceRefs. <br><strong>ExportReports(reportObjects)</strong> — generate human-readable HTML/PDF reports packaged alongside artifact; PDFs must be produced via canonical templating to ensure deterministic output where required. <br><strong>ExportIdempotencyKey(jobDescriptor)</strong> — compute deterministic idempotency key from correlationId + jobDescriptorHash enabling safe retries and duplicate-suppression by job scheduler. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (concepts & mapping)</strong><br><strong>Audit schema for PQ_Export:</strong> each audit row includes: timestamp, correlationId, module=PQ_Export, procedure, operatorId (where interactive), paramsHash, resultHash (optional), artifactChecksum, destinationUri (sanitized), evidenceRef, durationMs, attempts, configHash, metadata. Full parameter dumps are stored encrypted in evidence store referenced by evidenceRef. <br><strong>Representative ErrorCodes & operator guidance:</strong><br>1. PQ_EXPORT_ENOSPC — run retention/space mitigation, StageLocalFallback. <br>2. PQ_EXPORT_EPERM — check ACLs, run permission remediation. <br>3. PQ_EXPORT_VERIFICATION_FAILED — InspectTempArtifacts, attempt RepairExportArtifact, re-run packaging if needed. <br>4. PQ_EXPORT_DEGRADED — treat artifact as staged-only until retransfer completed; schedule retransfer job. <br>5. PQ_EXPORT_ELOCKED — identify locking process, retry with backoff or escalate to SRE. <br>6. PQ_EXPORT_PARSE_FAIL — fix M text; emit prepare.failure and stop. <br><strong>Metrics:</strong> pq_export.latency_ms, pq_export.success_rate, pq_export.degraded_rate, pq_export.verify_fail_rate, pq_export.retry_count. Metrics buffered locally and exported by CORE_Telemetry in audited batches. <br><strong>Evidence policy:</strong> top-level audit rows store param hashes only; full sanitized parameters and raw diagnostics stored encrypted in evidence store (hot/warm archive) and referenced by evidenceRef. PII must never be present in top-level audit fields. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-language golden governance (comprehensive)</strong><br><strong>Unit tests (must include):</strong><br>1. PrepareExportPayload canonicalization vectors for M constructs, Unicode, and param permutations. <br>2. ComputeMChecksum parity across supported languages and OSes for canonical inputs. <br>3. CollectPQDiagnostics scrub tests ensuring no credentials persist and deterministic sampling parity. <br>4. PackageExportArtifact deterministic archive bytes across OSes. <br>5. AtomicExport rename/fsync failure simulations using FS mocks. <br>6. VerifyExport mismatch and repair flows with temp artifacts. <br>7. StageLocalFallback behavior and retransfer descriptor persistence. <br><strong>Integration tests:</strong><br>1. End-to-end export: prepare -> checksum -> package -> validate -> atomic export -> verify -> manifest write -> audit emission. <br>2. Fault-injection tests: simulate ENOSPC, locked files, NFS rename anomalies; ensure degraded path and stage-local fallback exercised. <br>3. Signature & encryption round-trip with mocked KMS/HSM. <br><strong>Property tests:</strong><br>1. Deterministic artifact bytes under canonical input property test across random small variations. <br>2. Idempotency invariants: repeated runs with same ExportIdempotencyKey produce single authoritative artifact and idempotency suppression behaviour in job scheduler. <br><strong>Performance tests:</strong><br>1. Packaging throughput for artifacts at 1MB, 10MB, 100MB sizes. <br>2. AtomicExport latency p50/p95 under local SSD and network mount. <br><strong>CI golden gating:</strong><br>1. Golden artifact parity tests for regulated templates — any change to packaging must include migration manifest and owner approval. <br>2. Static analyzer forbids UI-thread IO operations. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always use PrepareExportPayload + ComputeMChecksum before packaging to ensure canonical fingerprints. <br>2. Always persist artifacts using AtomicExport semantics (not raw writes) when artifact will be consumed by other processes. <br>3. Always write manifest with WriteExportManifest and emit audit via EmitExportAuditRow. <br>4. Use ExportIdempotencyKey for retryable orchestrated exports; use deterministic_jitter in CI for repeatability. <br><strong>Forbidden patterns:</strong><br>1. Do not write raw credentials into diagnostics or manifests. <br>2. Do not perform long-running IO on UI thread; static analyzer must reject such PRs. <br>3. Do not rely on host-specific rename semantics without fallback; do not call os.rename on network mounts without ValidateExportDestination checks. <br><strong>Code-review checklist:</strong> ensure audit emission, AtomicExport usage, manifest write, evidenceRef usage for sensitive payloads, idempotency token presence for retriable flows, and signing fields present if packagingPolicy requires signatures. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (executable steps)</strong><br><strong>AtomicExport ENOSPC runbook:</strong><br>1. Query pq_export.atomic.failure for correlationId and mount path; collect freeBytes snapshot from audit. <br>2. SSH to host and run df -h and iostat for mount; collect vmstat and kernel logs for timeframe. <br>3. If staging allowed, run exports stage-local --artifact <id> to move artifact to secure staging and re-run retransfer job. <br>4. If persistent, escalate to infra with forensic_manifest and audit_tail. <br><strong>Verification failure triage:</strong><br>1. Query pq_export.verification_failed audits for expectedChecksum and artifactPath. <br>2. Run VerifyExport in dry-run and InspectTempArtifacts for candidate temp copies. <br>3. If repair possible, schedule repair under maintenance window and re-verify; else re-run packaging and export. <br><strong>Stage-local handling for regulated artifacts:</strong><br>1. Require two-person approval before StageLocalFallback; record approval in audit rows. <br>2. Mark staged artifact as non-authoritative and schedule retransfer; notify downstream consumers. <br><strong>When to call SRE:</strong> repeated ENOSPC for critical export or persistent verification fail after repair attempts; include forensic_manifest and temp artifact listing in ticket. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Extremely detailed long-form narratives & examples (multiple scenarios)</strong><br><strong>Scenario 1 — Operator exports regulated PQ template to shared cloud repo (complete trace):</strong><br>1. Operator clicks "Export" in PQ_Ribbon; ribbon handler creates correlationId r-20260117-xyz and emits UserAction audit. <br>2. Orchestrator calls PrepareExportPayload(requireHighPrecision=true) and ComputeMChecksum; payloadFingerprint and mChecksum produced and recorded. <br>3. CollectPQDiagnostics captures last-refresh traces scrubbed of credentials; diagnosticsFingerprint produced. <br>4. PackageExportArtifact builds deterministic ZIP archive and computes artifactCandidateFingerprint. <br>5. ValidateExportDestination confirms cloud bucket supports atomic object replace (per provider) and free space quotas. <br>6. AtomicExport streams artifact to final URI using provider-specific atomic replace APIs; fsync semantics satisfied where supported. <br>7. VerifyExport recomputes checksum and matches expected; WriteExportManifest atomically persists manifest with signatureRef after signing via HSM. <br>8. EmitExportAuditRow writes pq_export.completed linking correlationId, mChecksum, artifactChecksum and manifestChecksum. <br>9. CI golden-run compares artifactChecksum to golden for regulated templates and blocks release if mismatch. <br><strong>Traceability:</strong> chain of evidence from correlationId -> jobDescriptor -> mChecksum -> artifactChecksum -> manifestChecksum -> audit rows enables full reproducibility and compliance proofs. <br><strong>Scenario 2 — NFS rename anomaly and stage-local fallback:</strong><br>1. AtomicExport rename fails with EINVAL due to NFS idiosyncrasy; module emits pq_export.degraded and falls back to StageLocalFallback. <br>2. StageLocalFallback writes artifact to local staging area using AtomicExport semantics on local disk, produces stagedChecksum, and emits pq_export.stage_local. <br>3. A retransfer job created with ExportIdempotencyKey reattempts transfer when remote becomes available; job uses RetryExport with idempotencyKey to ensure safe re-attempts. <br>4. Until finalization, consumers treat staged artifact as non-authoritative; manifest indicates staging state and operator approval where needed. <br><strong>Governance:</strong> degrade gracefully, ensure operators are notified and downstream consumers blocked from using staged artifact as authoritative. <br><strong>Scenario 3 — Deterministic replay for compliance and forensic reproduction:</strong><br>1. Export run persisted evidenceRefs for canonicalM, diagnosticsBlob, and any RNG state used for sampling. <br>2. Compliance request arrives; forensic tool downloads evidence, re-runs PrepareExportPayload and PackageExportArtifact in reproduce mode producing byte-identical artifact and artifactChecksum matching original, verifying integrity of pipeline. <br>3. If mismatch, forensic manifest includes audit_tail and packaging logs allowing engineers to pinpoint divergence (e.g., packagingVersion change or canonicalization bug). <br><strong>Narrative takeaways:</strong> record evidence, make packaging deterministic, and store enough metadata to reproduce exact artifact for audits. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — mapping PQ_Export principles to PQ workflows (detailed conceptual mapping)</strong><br><strong>Context:</strong> M execution and PQ hosts differ; PQ_Export cannot change M runtime semantics but provides authoritative packaging and persistence around M artifacts. <br><strong>Mapping patterns & recommendations:</strong><br>1. <strong>Atomic persistence mapping:</strong> PQ cannot guarantee atomic file replace; PQ_Ribbon must call a signed helper or worker to run AtomicExport. PQ templates should rely on worker-side persistence for authoritative artifact creation. <br>2. <strong>mChecksum & injection governance:</strong> template metadata must include <code>mChecksum</code> computed by ComputeMChecksum; injector must verify mChecksum before injecting to prevent tampering. <br>3. <strong>Diagnostics capture:</strong> host collects provider traces and supplies to CollectPQDiagnostics; M code remains pure and does not store provider secrets. <br>4. <strong>High-precision numeric templates:</strong> mark templates <code>requiresHighPrecision</code>; offload numeric rounding/aggregation to worker SafeRound primitives and include decimal normalization map in artifact. <br>5. <strong>Idempotent refresh & export:</strong> orchestrator persist jobDescriptor with ExportIdempotencyKey before export; retries use idempotencyKey to avoid duplicates. <br><strong>Operator narrative:</strong> when exporting a template, prepare canonical payload, compute mChecksum, package and atomically persist artifact, and verify checksum; if staging occurs, operator must approve for regulated artifacts. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Export metadata into semantic models & reports (detailed conceptual mapping)</strong><br><strong>Context:</strong> DAX is read-time only; it consumes persisted artifacts and metadata. Exports must persist RunMetadata that DAX can query for provenance. <br><strong>Patterns & recommended practices:</strong><br>1. <strong>RunMetadata persistence:</strong> Export pipeline persist RunMetadata row (correlationId, artifactChecksum, exportTs, mChecksum, manifestChecksum) as table consumable by semantic model; DAX measures can surface verification status. <br>2. <strong>Checksum reconciliation:</strong> During refresh, ETL writes expected artifactChecksum into model table; DAX measures compare to current loaded checksum allowing UI flags for verification. <br>3. <strong>Deterministic sampling for dashboards:</strong> sampling seeds persisted with evidenceRef allow reproducible sample-driven diagnostics surfaced in DAX-driven reports. <br>4. <strong>Avoid allocation logic in DAX:</strong> rounding and allocation must be resolved at ETL/export time (SafeRoundResiduals) and persisted as resolved numeric fields; DAX should present final values and provenance. <br><strong>Narrative example:</strong> Worker exports reconciled sales table via PQ_Export and writes RunMetadata including artifactChecksum; DAX measure <code>IsVerified</code> returns 1 when artifactChecksum equals expected value in model metadata, driving a verification indicator in report. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Forensic artifacts, evidence paths & recommended retention (expanded)</strong><br><strong>Minimum forensic artifacts to collect for an export incident:</strong><br>1. jobDescriptor.json persisted via AtomicWrite containing jobId, correlationId, paramsHash, configHash and idempotencyKey. <br>2. artifact file(s) with SHA256 checksums and manifest.json. <br>3. audit_tail.csv rows for the correlationId containing pq_export.* and UserAction rows. <br>4. diagnosticsBlob and evidenceRef to raw traces (encrypted). <br>5. serialized RNG state used for deterministic sampling. <br>6. temp artifact listings and InspectTempArtifacts output. <br><strong>Evidence storage & retention patterns:</strong><br>1. Hot evidence store: <code>/evidence/hot/pq_export/&lt;correlationId&gt;/</code> for 30 days; limited access. <br>2. Warm archive: secure, signed archive for regulatory retention (7 years or per regulation). <br>3. Forensic_manifest.json enumerating artifact URIs, checksums, evidenceRefs, and chain-of-custody metadata. <br><strong>Retention cadence & verification:</strong> monthly retention verification job emits housekeeping.audit and performs proof-of-delete for removed artifacts. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (detailed):</strong><br>1. Owners present in OWNERS.md and contactable. <br>2. Public API documented and versioned. <br>3. PrepareExportPayload and ComputeMChecksum golden vectors validated across OSes. <br>4. AtomicExport cross-platform tests and degraded-path tests pass. <br>5. Manifest write atomicity tests pass. <br>6. Audit emission tests validated in modAudit harness. <br>7. Security review completed for EncryptAndSignArtifact and HSM integration. <br>8. Static analyzer green for forbidden-API patterns. <br><strong>Blocking conditions:</strong> missing audit emissions for critical transitions, failing golden artifacts, manifest races, or unresolved security issues. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & example scripts (conceptual)</strong><br><strong>Unit test highlights:</strong><br>1. <code>test_prepare_canonicalization</code> — inputs include varied M syntax, Unicode, comments; assert canonicalM equals golden. <br>2. <code>test_mchecksum_parity</code> — compute checksum in multiple host implementations and assert equality. <br>3. <code>test_package_determinism</code> — build artifact twice and assert byte-for-byte equality. <br>4. <code>test_atomic_rename_failure</code> — simulate rename error and assert fallback stage-local path created and pq_export.degraded emitted. <br><strong>Integration tests:</strong><br>1. End-to-end export pipeline with mock destination implementing atomic replace API. <br>2. Fault injection scenario with ENOSPC and revision via StageLocalFallback and retransfer job. <br><strong>Performance & load:</strong><br>1. Packaging 1000 small templates concurrently to exercise streaming hash and archive concurrency. <br>2. AtomicExport latency under heavy I/O load. <br><strong>CI gates:</strong> golden parity, audit emission checks, security scanning for PII leaks. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & examples (prescriptive)</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-abc</code> — collects audit_tail.csv, diagnosticsBlob, serialized RNG state, artifacts, and forensic_manifest.json for run. <br>2. <code>exports repair --temp &lt;tempPath&gt; --target &lt;artifactPath&gt;</code> — attempts repair under maintenance; dry-run flag available. <br>3. <code>exports replay --correlation r-... --evidenceRef &lt;evidence&gt;</code> — deterministic replay using persisted canonicalM and diagnostics; dry-run option. <br>4. <code>exports retransfer --stage &lt;stagePath&gt; --dest &lt;destinationUri&gt;</code> — idempotent retransfer job to finalize staged artifacts. <br><strong>When to call SRE:</strong> after two ENOSPC attempts for critical job descriptors, or after repeated RetryExport exhaustion producing PQ_EXPORT_VERIFICATION_FAILED; include forensic_manifest and audit_tail. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded)</strong><br><strong>Failure mode: verification mismatch after write</strong><br>1. Likely cause: non-deterministic packaging metadata or corrupted write. <br>2. Mitigation: run VerifyExport, InspectTempArtifacts, attempt RepairExportArtifact, re-run packaging under controlled environment; if repeated, open incident with forensic_manifest. <br><strong>Failure mode: partial artifact observed by consumer</strong><br>1. Likely cause: direct write to final path bypassing AtomicExport or rename semantics not atomic on remote FS. <br>2. Mitigation: enforce AtomicExport usage by policy and static analyzer; block consumer usage until manifest verification passes. <br><strong>Failure mode: non-deterministic mChecksum parity</strong><br>1. Likely cause: inconsistent canonicalization rules across hosts. <br>2. Mitigation: update canonicalization to use parser-aware normalization, add golden vectors, and perform cross-language parity runs. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Governance checklists & PR requirements (explicit)</strong><br>1. PR must include unit tests for new behavior and golden vectors if packaging or checksum logic changed. <br>2. Changes to packaging format or checksum algorithm require migration manifest and approver sign-off from OWNERS. <br>3. Any change to AtomicExport semantics requires SRE sign-off and cross-OS regression tests. <br>4. Release manifest update and signing required for production change affecting template injection. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Appendix — long-form incident reconstruction example (ordered steps)</strong><br><strong>Incident:</strong> "Export verification mismatch for run r-20260112-455" <br><strong>Reconstruction steps:</strong><br>1. Retrieve pq_export.* and UserAction audit rows for correlationId. <br>2. Pull artifactPath and manifest from artifacts store using manifestChecksum recorded in audit. <br>3. Compute local artifact checksum and compare to manifest expectedChecksum; record mismatch diagnostics. <br>4. InspectTempArtifacts for candidate temp copies; compare temp checksums to expectedChecksum. <br>5. Restore serialized RNG state from evidenceRef and re-run PrepareExportPayload and PackageExportArtifact in reproduce mode to check packaging parity. <br>6. If reproduction matches original artifactChecksum, suspect transport corruption; if reproduction differs, investigate canonicalization or packagingVersion changes. <br>7. Package forensic_manifest with artifact, temp artifacts, diagnostics, and audits; escalate to compliance if regulated. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Appendix — PQ & DAX short checklists for template authors and report builders</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> in template metadata. <br>2. Mark templates requiring strict numeric fidelity as <code>requiresHighPrecision</code>. <br>3. Parameterize preview seeds and emit preview audit. <br>4. Avoid embedding credentials in templates; reference connection descriptors only. <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> table for run provenance and artifactChecksum. <br>2. Avoid performing allocation or rounding residuals in DAX; use ETL SafeRound flows. <br>3. Use deterministic hashed keys for sampling filters in model. </td></tr><tr><td data-label="PQ_Export — Per-function Expert Technical Breakdown"> <strong>Final non-negotiable constraints (firm):</strong><br>1. All artifacts consumed by other processes must be persisted using AtomicExport semantics; static analysis enforces. <br>2. Sensitive parameters must be stored encrypted in evidence store and referenced by evidenceRef; do not place raw PII in top-level audits. <br>3. DeterministicRNG seeded from correlationId must be used for any sampling or tie-breakers in export flows; serialize state when exact replay required. <br>4. Numeric-sensitive transforms must be performed by worker SafeRound flows and recorded in artifact diagnostics; do not rely on host M numeric semantics for regulated outputs. <br>5. Every export attempt emits at least one audit row anchored to correlationId and paramsHash. </td></tr></tbody></table></div><div class="row-count">Rows: 35</div></div><div class="table-caption" id="Table2" data-table="Docu_0181_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Audit — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Audit — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_AUDIT recorded in OWNERS.md, release manifests, and deployment notes. <br><strong>Public API:</strong> AppendAuditRow, AppendChainedAudit, RotateAndSignAuditTail, VerifyAuditChain, QueryAuditRows, ExportAuditTail, CompactAuditTail, AuditReplay, AuditTailReader, AuditTailStreamer, AuditFlush, AuditRetentionSweep, ArchiveAuditSegment, AuditEvidenceStoreWrite, AuditEvidenceStoreRead, AuditEmitUserAction, AuditEmitSystemEvent, AuditMetricsSnapshot, AuditRepairTempRecords, AuditTailIndexRepair, AuditTailPrune, AuditTailSnapshot, AuditTailDiff. <br><strong>Audits emitted:</strong> pq.audit.append.start, pq.audit.append.complete, pq.audit.append.failure, pq.audit.chained.append.start, pq.audit.chained.append.complete, pq.audit.rotate.start, pq.audit.rotate.complete, pq.audit.verify.start, pq.audit.verify.result, pq.audit.export.attempt, pq.audit.export.complete, pq.audit.compact.start, pq.audit.compact.complete, pq.audit.replay.start, pq.audit.replay.complete, pq.audit.retention.sweep, pq.audit.evidence.written, pq.audit.evidence.read, pq.audit.stream.connect, pq.audit.stream.disconnect, pq.audit.flush.attempt, pq.audit.flush.complete, pq.audit.atomic.repair. Every audit row includes correlationId, module=PQ_Audit, procedure, paramsHash, and resultHash when applicable. <br><strong>Purpose and intended use:</strong> authoritative, append-only audit store for Power Query lifecycle events: preview, inject, refresh, diagnostics, template management, export, and governance operations. Provide cryptographic chaining, rotation signing, atomic export, compact archival, deterministic replayability, and fine-grained streaming for UI and operators. Fast paths are lightweight (local buffer append) and avoid network I/O; heavy operations (rotation signing, export with evidence) run in background workers. <br><strong>Non-goals / constraints:</strong> avoid embedding raw PII into top-level audit rows; store full payloads and sensitive parameters in the evidence store. Do not attempt distributed two-phase commit across unrelated artifact stores; instead rely on higher-level orchestrators for multi-artifact transaction semantics. Avoid requiring HSM keys on every client host; provide clear fallback patterns for offline signing. Do not attempt to replicate primary data persistence responsibilities—PQ_Audit records metadata, checksums, and evidence pointers only. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Append-only invariant: once AppendChainedAudit returns success, that row is durable and part of canonical tail unless explicit retention/revocation operations occur with audit records. <br>2. Cryptographic chain: rotation manifests include prevRotationHash and rotationSequenceNumber producing an ordered, tamper-evident chain. <br>3. Replayability: audit rows plus evidenceRef entries provide sufficient inputs (parameters, seeds, canonicalized decimals, RNG state) to deterministically reproduce operator-visible artifacts. <br>4. UI thread safety: ribbon calls must use low-latency append path that returns quickly; long durability work deferred to worker processes. <br>5. Retention compliance: hot/warm/cold retention boundaries enforced and verified monthly; proofs-of-delete retained as audit artifacts when deletion occurs. <br>6. Observability: every long-lived or critical operation must emit start/complete/failure audit rows and buffered metrics for CORE_Telemetry. <br><strong>Performance SLOs:</strong> median buffered AppendAuditRow latency <15ms; synchronous durable append latency <200ms on local SSD; rotation signing for 10k rows <2s end-to-end; export throughput ≥500MB/min compressed. <br><strong>CI / acceptance gates:</strong> chain verification unit tests, rotation signature goldens across languages, retention simulation, atomic export failure injection, static analyzer checks for UI-thread blocking. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AppendAuditRow(correlationId, rowPayload, evidenceRef=null, synchronous=false, maxAttempts=3)</strong> — exhaustive technical breakdown<br><strong>Purpose & contract:</strong> primary low-latency append API for UI and background tasks to record audit rows. Must be safe to call from ribbon handlers with synchronous=false. For regulated operations or when immediate durability is required, synchronous=true can be used but must be scheduled from a worker to avoid UI blocking. <br><strong>Parameters & returns:</strong> parameters: correlationId (string), rowPayload (structured object sanitized to remove PII), evidenceRef (opaque pointer), synchronous (bool), maxAttempts (int). Returns {success:boolean, appendPosition:<code>int|null</code>, rowHash:<code>string|null</code>, paramsHash:string, status:<code>&quot;buffered&quot;|&quot;durable&quot;|&quot;duplicate&quot;|&quot;failed&quot;</code>, errorCode:<code>null|string</code>}. <br><strong>Primary invariants (must/shall):</strong><br>1. Idempotency: repeated calls with identical correlationId and paramsHash must be deduplicated; AppendAuditRow must return existing appendPosition and status "duplicate" for such calls. <br>2. PII protection: if rowPayload contains PII per policy, function must reject or require evidenceRef linking to encrypted evidence. <br>3. Local durability for synchronous=true: success indicates data is persisted to local storage and will be included in the next rotation. <br><strong>Algorithm & implementation notes:</strong><br>1. Canonicalize rowPayload to deterministic JSON: stable key ordering, normalized numeric formats, UTC timestamps, and deterministic nonce generation derived from correlationId if necessary. <br>2. Compute paramsHash = SHA256(canonicalPayload). Compute tentative row envelope containing timestamp, correlationId, module, procedure, paramsHash, evidenceRef. <br>3. Duplicate detection: check in-memory LRU index of recent paramsHash->appendPosition. If present, return duplicate with existing appendPosition. <br>4. Buffering: if synchronous=false, append to in-memory circular buffer and mark as buffered. Background flusher will persist using AtomicWrite semantics to a tail segment file. <br>5. Synchronous persist: if synchronous=true, write to temp file and fsync (where supported), append to tail using atomic replace semantics, fsync parent dir, compute rowHash from prevRowHash and paramsHash, and return durable appendPosition. <br>6. Error handling & retry: on transient FS errors, apply Retry wrapper with deterministic_jitter option in CI to ensure reproducible timing in tests. On persistent final failure emit pq.audit.append.failure with diagnostics and a deterministic errorCode. <br><strong>Edge cases & invalid inputs:</strong><br>1. Missing or empty correlationId: return PQ_AUDIT_MISSING_CORRELATION with remediation instructions. <br>2. Oversized payload exceeding configured evidence threshold: return PQ_AUDIT_PAYLOAD_TOO_LARGE and instruct caller to write to evidence store first. <br>3. Non-serializable types: PQ_AUDIT_SERIALIZATION_FAIL and provide parameter schema hints. <br><strong>Observability & audit fields emitted:</strong> pq.audit.append.start(correlationId, paramsHash, evidenceRefPresent) pq.audit.append.complete(correlationId, paramsHash, rowHash, appendPosition, durationMs) pq.audit.append.duplicate(correlationId, paramsHash, existingPosition) pq.audit.append.failure(correlationId, paramsHash, errorCode). <br><strong>Tests & CI vectors:</strong> canonicalization golden vectors for varied payloads; duplicate append tests under concurrency; buffer flush crash-and-recover tests; large payload rejection; ENOSPC and EPERM simulations. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AppendChainedAudit(rowPayload, evidenceRef=null, signerKeyId=null, synchronous=false)</strong> — chaining primitive for cryptographic continuity<br><strong>Purpose & contract:</strong> append an audit row that includes prevHash to form an unbroken chained ledger. Required for critical flows where tamper-evidence is needed (template inject, export, refresh completion). AppendChainedAudit may accept signerKeyId to mark rows for immediate signing in rotation or to include signature metadata if local signing is permitted. <br><strong>Parameters & return:</strong> rowPayload, evidenceRef optional, signerKeyId optional, synchronous flag. Returns {success, chainIndex, rowHash, <code>signedEnvelopeHash|null</code>, <code>errorCode|null</code>}. <br><strong>Primary invariants (must/shall):</strong><br>1. PrevHash continuity: the prevHash included must equal the current tail lastRowHash at append time; if a conflict exists due to concurrent appends or rotation, the call should retry deterministically up to maxAttempts then fail with PQ_AUDIT_CHAIN_CONFLICT. <br>2. Signing discipline: rows intended for immediate trust must be signed in the rotation that includes them; if signerKeyId is not available, row is marked unsigned and scheduled for RotateAndSign. Unsigned critical rows impede exports until signed and recorded with an explicit audit operator override. <br>3. Atomicity: chained append must commit atomically with respect to tail updates to avoid orphan rows; atomic file append or atomic replace strategies with commit markers are required. <br><strong>Algorithm & implementation notes:</strong><br>1. Read lastRowHash atomically from tail metadata. Build envelope = {prevHash, timestamp, paramsHash, evidenceRef, module, procedure, appendContext}. <br>2. Optionally compute local signature over envelope if signerKeyId present and key available. Include signature metadata in envelope and persist via AppendAuditRow synchronous semantics. <br>3. Handle concurrent rotation or tail advancement by retrying after a small deterministic backoff; if rotation occurred between read and append, recompute prevHash and try again. <br><strong>Edge cases:</strong> signer key unavailable for required-signing flow: mark envelope as unsigned, append but emit pq.audit.chained.append.unsigned and schedule out-of-band signing. Multiple append actors on separate hosts require optimistic concurrency resolution via deterministic retry. <br><strong>Observability:</strong> pq.audit.chained.append.start, pq.audit.chained.append.complete, pq.audit.chained.append.retry, pq.audit.chained.append.failure. <br><strong>Tests & CI:</strong> concurrent chained append simulation, unsigned-row handling tests, out-of-band signing reconciliation tests. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>RotateAndSignAuditTail(rotationWindowSeconds=3600, signerKeyId, maxRowsPerRotation=10000, force=false)</strong> — rotation & signing workflow<br><strong>Purpose & contract:</strong> gather pending tail rows into a rotation segment, compute rotationRootHash, sign rotation bundle using signerKeyId (prefer HSM), and publish rotation manifest used by VerifyAuditChain. Rotation snapshots improve verification efficiency and provide signed checkpoints for regulatory submission. <br><strong>Parameters & return:</strong> rotationWindowSeconds, signerKeyId (identifier mapping to key store/HSM policy), maxRowsPerRotation, force. Returns rotationManifest {rotationSequence, rotationHash, signedBy, rowCount, artifactRef, timestamp} or error. <br><strong>Primary invariants (must/shall):</strong><br>1. Monotonic rotationSequence numbering maintained across all controllers. <br>2. Rotation manifest must include prevRotationHash linking to prior rotationRootHash, enabling a chain-of-rotation continuity check. <br>3. Signed manifest cannot be re-signed with differing contents; idempotent rotation of identical content returns same manifest. <br><strong>Algorithm & implementation notes:</strong><br>1. Determine rotation cut point deterministically (time-based or row-count) using tail snapshot to avoid including rows appended after rotation started. <br>2. Serialize rotationSegment as canonical binary (CBOR/Protobuf canonical encoding) containing ordered rowHashes and minimal projection, optionally including signed envelopes for row-level proofs. <br>3. Compute rotationRootHash via Merkle tree over rowHashes or deterministic digest of rotationSegment bytes. <br>4. Create rotationManifest with rotationSequenceNumber, prevRotationHash, rotationRootHash, rowRange, signerKeyId reference, and timestamp. Sign manifest using signerKeyId for production flows; include signer certificate chain or reference to release manifest. <br>5. Persist rotationSegment and signed manifest atomically using AtomicWrite; update rotation registry. <br>6. Publish pointer to rotation manifest registry and emit pq.audit.rotate.complete with manifestHash and rotationSequence. <br><strong>Cross-platform & operational notes:</strong> use canonical encodings for cross-language verification; HSM or KMS integration preferred for regulated flows; when HSM is unavailable implement an offline signing workflow with documented out-of-band signing and evidenceRef recorded in audits. <br><strong>Edge cases:</strong> leader election or collision when multiple controllers attempt rotation—resolve via deterministic policy (e.g., controller with lowest controllerId wins) or optimistic commit with retries. Partial rotation artifacts should be quarantined and repairable via AuditRepairTempRecords. <br><strong>Observability:</strong> pq.audit.rotate.start, pq.audit.rotate.complete, pq.audit.rotate.failure, pq.audit.rotate.conflict. <br><strong>Tests & CI:</strong> rotation signature goldens across multiple languages, leader collision injection, offline signing and later verification tests, rotation manifest replay tests. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>VerifyAuditChain(knownRotationManifests[], verifyKeys=trustedKeys)</strong> — chain verification primitive<br><strong>Purpose & contract:</strong> verify cryptographic continuity and integrity of audit rotations and optionally row-level hashes. Used in CI, daily monitoring, and for forensic verification. Returns detailed verificationReport enumerating passes and anomalies. <br><strong>Parameters & return:</strong> list of rotation manifests or registry pointer, verifyKeys set. Returns {passed:boolean, anomalies:[{rotationSequence,error}], verifiedRowsCount:int, verificationDurationMs:int}. <br><strong>Primary invariants (must/shall):</strong><br>1. Signature verification must validate certificate chain and check revocation status as configured. <br>2. PrevRotationHash continuity strictly enforced. Any mismatch triggers immediate alert and forensics. <br>3. Verification should be non-destructive and able to run against archives or live tail. <br><strong>Algorithm & notes:</strong><br>1. Iterate rotation manifests in sequence: validate signature using verifyKeys, re-compute rotationRootHash from rotationSegment and compare, ensure prevRotationHash equals previous rotationRootHash. <br>2. Optionally recompute rowHashes from canonicalized payloads stored in evidence to do row-level verification. This is expensive and may be limited to random sampling or targeted investigations. <br>3. Produce anomaly report linking to evidenceRefs for each mismatch. <br><strong>Edge cases:</strong> key rotation requires a key-rotation manifest mapping old signerKeyId to verification keys; missing rotation segment necessitates a forensic_manifest with missing ranges. <br><strong>Observability:</strong> pq.audit.verify.start, pq.audit.verify.result, pq.audit.verify.detail per anomaly. <br><strong>Tests & CI:</strong> signature verification with current and historical keys, partial archive simulation, cross-language signature verification goldens. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>QueryAuditRows(filters={correlationId,module,procedure,timeRange,paramsHash}, paging={cursor,limit}, compact=true)</strong> — query API for UI and operator consumption<br><strong>Purpose & contract:</strong> read-only query interface returning ordered minimal projections for rows that match filters. Exposes evidenceRef pointers but not raw PII. Must be low-latency for hot window and gracefully degrade to archive-backed reads. <br><strong>Parameters & return:</strong> filters object, paging cursor, limit. Returns {rows:[{timestamp,module,procedure,paramsHash,rowHash,evidenceRef,appendPosition}], nextCursor, totalEstimate}. <br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic ordering by appendPosition ensures consistent paging. <br>2. No raw PII in top-level fields; evidenceRef used to fetch sanitized payload when needed. <br><strong>Algorithm & implementation notes:</strong><br>1. Query hot in-memory index for recent rows; for older ranges, consult compacted archives and rehydrate minimal projection. <br>2. Provide a consistency watermark indicating the last fully-signed rotation included in the results to help operators reason about tamper-evidence. <br>3. If query spans rotation boundary, return metadata indicating which rotations are partial and whether verification is pending. <br><strong>Edge cases:</strong> cross-archive queries may return partial results and a nextCursor to resume; UI must present "consistent to rotation X" markers. <br><strong>Observability:</strong> pq.audit.query.start and pq.audit.query.complete with row counts and elapsed time. <br><strong>Tests:</strong> hot-window performance tests, archive-backed query path tests, paging cursor correctness tests. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>ExportAuditTail(outputPath, includeEvidenceRefs=false, compress=true, checksumAlgorithm=sha256, maxAttempts=3)</strong> — atomic export with checksum and staged fallback<br><strong>Purpose & contract:</strong> produce a deterministically serialized, signed, and checksummed export containing a contiguous range of audit rows and optionally embedded evidence blobs (when policy permits). Exports intended for regulator submission must reference release-manifest and signerKeyId. Exports must be atomic and verified by checksum. <br><strong>Parameters & return:</strong> outputPath (URI or local path), includeEvidenceRefs bool, compress bool, checksumAlgorithm, maxAttempts. Returns {success, artifactUri, artifactChecksum, attempts, elapsedMs, <code>errorCode|null</code>}. <br><strong>Detailed behavior (must/shall):</strong><br>1. Validate destination and export policy; regulated exports require manifest and signerKeyId for signed export manifest. <br>2. Collate rotation manifests and row segments for requested time range; include rotation signatures and chain-of-rotation metadata. <br>3. If includeEvidenceRefs true and evidence blobs are permitted for export, embed encrypted evidence or include a zipped bucket of evidence files; otherwise produce an evidence manifest mapping evidenceRefs to archive URIs. <br>4. Stream serialize export deterministically while computing checksum; write to local tempPath using AtomicWrite semantics to prevent truncated artifacts. <br>5. On success, rename tempPath to final outputPath atomically; compute and store artifactChecksum and emit pq.audit.export.complete with artifact checksum and destination. <br>6. If remote upload fails, attempt staged local fallback and emit pq.audit.export.degraded with reason; if fallback used, ensure operator notified and SRE alerted for persistent failures. <br><strong>Cross-platform & governance notes:</strong> output container must preserve signing metadata; produce both machine-readable and human-readable manifest for regulator packages. Use canonical encodings to allow cross-language verification. <br><strong>Recovery & runbook:</strong> on verification failure, rerun ExportAuditTail with verifyOnly mode to detect transient corruption; run AtomicWriteRepair if temp artifacts remain. <br><strong>Observability:</strong> pq.audit.export.attempt, pq.audit.export.complete, pq.audit.export.failure, pq.audit.export.degraded. <br><strong>Tests & CI:</strong> export parity tests, signed manifest verification, network failure injection, staged fallback validation. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>CompactAuditTail(compactionStrategy="time-window", windowSeconds=86400, maxSegmentSize=50MB, retainIndex=true)</strong> — compaction & archival primitive<br><strong>Purpose & contract:</strong> compact older tail rows into archive segments to reduce hot index size while preserving provenance and rehydration capability. Compaction reduces operational cost while keeping chain verifiability. <br><strong>Behavior & steps:</strong><br>1. Identify candidate row ranges older than windowSeconds and not under legal hold or flagged for immediate replay. <br>2. Produce compactSegment containing rowHashes, minimal projections (timestamp,module,procedure,paramsHash,rowHash,evidenceRef), and a mapping to evidenceRef for large payloads; compress segment with deterministic compressor. <br>3. Persist compactSegment using AtomicWrite and update index mapping to point queries to compactSegment. <br>4. Emit pq.audit.compact.start and pq.audit.compact.complete with segmentChecksum, rowRange, and indexUpdate. <br><strong>Edge cases & failover:</strong> if compaction interrupted, temp artifact left must be handled by AuditRepairTempRecords; do not delete hot tail rows until rotation manifest confirmed and compactSegment verified. <br><strong>Tests:</strong> rehydration parity test: rehydrate compact segment and verify top-level projection matches original tail rows; compaction concurrency tests ensuring no data loss. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditReplay(correlationId, evidenceFetchPolicy="local-first", dryRun=true, deterministic=true)</strong> — deterministic replay engine for forensic analysis<br><strong>Purpose & contract:</strong> reconstruct and re-execute recorded operator actions using persisted audit rows and evidence artifacts to reproduce observable outputs deterministically. Supports dry-run verification producing diffs, and full-run sandbox execution for non-production reproductions. <br><strong>Parameters & return:</strong> correlationId, evidenceFetchPolicy, dryRun, deterministic. Returns replayReport {replayedSteps, producedArtifactChecksums, diffs, success, diagnostics}. <br><strong>Algorithm & notes:</strong><br>1. Query audit rows by correlationId; fetch required evidenceRef artifacts via AuditEvidenceStoreRead following evidenceFetchPolicy and enforcing ACL and two-person approval for regulated data if required. <br>2. Restore RNG serialized state, SafeRound canonical inputs, parameter snapshots, and environment configuration from evidence. <br>3. Execute pipeline in a sandbox with deterministic RNG and SafeRound algorithm configured to match production algorithm version. Capture produced artifacts and checksums. <br>4. Compare produced checksums with archived artifactChecksum values in audit rows and produce diff report identifying byte-level or semantic differences. <br>5. Emit pq.audit.replay.start and pq.audit.replay.complete with outcome and evidence pointers. <br><strong>Operator guidance:</strong> prefer dryRun mode for routine forensic checks; only perform non-dry replays in controlled sandbox to avoid accidental re-injection. <br><strong>Tests & CI:</strong> golden replay tests across language runtimes; RNG and SafeRound parity checks; replay under altered evidence to affirm mismatch detection is precise. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditTailReader(streamSliceSize=1000, backpressure=true)</strong> — streaming reader for UI and diagnostics<br><strong>Purpose & contract:</strong> provide streaming consumption of the hot audit tail to UIs and monitoring tools. Supports resumption via cursor, long-poll for new rows, and consistent markers across rotation boundaries. Must support backpressure so slow consumers do not overwhelm buffer. <br><strong>API and behavior:</strong> subscribe(cursor=null) returns a stream of rowSummaries with heartbeats; pause/resume and checkpointing supported; reconnect attempts resume from last cursor if within retention horizon. <br><strong>Implementation notes:</strong> maintain in-memory circular queue for last N rows and a compact persistent cursor index for resume; use long-polls when socket streams unavailable; expose a watermark for last signed rotation included. <br><strong>Observability:</strong> pq.audit.stream.connect, pq.audit.stream.disconnect, pq.audit.stream.lag metrics. <br><strong>Tests:</strong> long-poll fallback tests, resume across rotation tests, backpressure and slow-consumer scenarios. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditFlush(correlationId=null, force=false, flushTimeoutMs=5000)</strong> — flush buffered audit tail to durable storage<br><strong>Purpose & contract:</strong> force immediate persist of in-memory buffer to tail segment using AtomicWrite semantics. Use prior to critical operations (job persistence, export) to ensure appended rows are durable. If force=true perform synchronous flush with blocking semantics (must be executed off UI thread or scheduled). <br><strong>Return object:</strong> {queued:boolean, flushedRows:int, durationMs:int, <code>errorCode|null</code>}. <br><strong>Edge cases:</strong> flushTimeout exceeded returns partialFlush with details and schedules retry; emit pq.audit.flush.attempt and pq.audit.flush.complete. <br><strong>Tests:</strong> flush under sustained append rates and crash recovery ensuring no dropped rows. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditRetentionSweep(policyName="hot-warm-cold", retentionConfig)</strong> — retention & archival enforcement<br><strong>Purpose & contract:</strong> enforce retention policies by moving compacted archives to warm or cold storage, deleting hot data per policy, and producing proofs-of-delete for regulatory audits. Legal holds and regulator orders override deletion. <br><strong>Behavior & steps:</strong><br>1. Determine candidate artifacts per retention policy and exclude items under legal hold. <br>2. Validate artifact integrity by checksum prior to transfer. <br>3. Transfer artifacts to warm/cold storage and update retention index. <br>4. For hot deletions, create proof-of-delete artifacts and retention manifest, then emit pq.audit.retention.sweep with summary and forensic_manifest pointer. <br><strong>Edge cases:</strong> legal hold detection and skip logic must be robust and audited; failed transfer must trigger retry policy and operator alert. <br><strong>Observability:</strong> pq.audit.retention.sweep rows with counts and URIs. <br><strong>Tests:</strong> legal hold scenarios, proof-of-delete verification, cross-region archival transfer tests. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditEvidenceStoreWrite(evidencePayload, correlationId, encrypt=true, aclPolicy)</strong> — evidence persistence primitive<br><strong>Purpose & contract:</strong> persist sanitized or full evidence artifacts (parameter sets, RNG state, SafeRound canonical decimals, traces) to encrypted evidence store and return evidenceRef pointer for use in top-level audit rows. Evidence store enforces ACLs, PII detection, redaction, and retention metadata. <br><strong>Parameters & return:</strong> evidencePayload (JSON/binary), correlationId, encrypt boolean, aclPolicy. Returns {evidenceRef, evidenceHash, storageUri, expiryPolicy}. <br><strong>Primary invariants:</strong> evidence persisted encrypted at rest; top-level audit rows only reference evidenceRef, not raw payloads; PII detection enforced. <br><strong>Edge cases & mitigation:</strong> if PII present and policy forbids storing it in evidence store, return PQ_EVIDENCE_PII_REJECT and provide guidance on allowed redaction or privacy-safe summarization. <br><strong>Observability:</strong> pq.audit.evidence.written(correlationId, evidenceHash, storageUri). <br><strong>Tests:</strong> write/read parity, PII detection tests, ACL enforcement tests including two-person access gating for regulated evidence. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditEvidenceStoreRead(evidenceRef, authorizationToken, redactPolicy="safe")</strong> — evidence read primitive for replay and verification<br><strong>Purpose & contract:</strong> read evidence artifacts enforcing ACLs and redaction policies. Each read must produce an access audit record (who, when, why). Evidence reads for regulated content may require two-person approval and off-line key release. <br><strong>Return:</strong> sanitizedPayload or fullPayload when authorized. <br><strong>Security notes:</strong> evidence store must never leak raw PII in logs; all reads recorded for chain-of-custody. <br><strong>Observability:</strong> pq.audit.evidence.read(correlationId, evidenceRefFingerprint, requesterId, outcome). <br><strong>Tests:</strong> access control enforcement tests, two-person approval workflows, read logging verification. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditEmitUserAction(correlationId, operatorId, module, procedure, paramsHash, uiContext=null)</strong> — standardized user action emitter<br><strong>Purpose & contract:</strong> capture ribbon-driven operator actions in a normalized schema for PQ flows: preview, inject, export, refresh. Sanitizes params and delegates full payload persistence to evidence store when required. Ensures operatorId and correlationId presence for governance. <br><strong>Fields & invariants:</strong> include operatorId (or operator-presence marker), module, procedure, paramsHash, evidenceRef pointer if full params stored. UI context must avoid raw PII. <br><strong>Operator guidance:</strong> call at ribbon handler entry before performing downstream operations; ensures immediate user-action audit exists even if downstream operations later fail. <br><strong>Tests:</strong> UI instrumentation tests verifying emission for all ribbon controls. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditEmitSystemEvent(correlationId, module, procedure, level, message, diagnosticRef=null)</strong> — system event audit emitter<br><strong>Purpose & contract:</strong> record non-user events: background refresh completions, connector dependency results, ensureDeps findings, plugin load errors. Levels: info, warn, error, critical. DiagnosticRef points to evidence for deep diagnostics when permitted. High severity events trigger metrics and alerting. <br><strong>Observability:</strong> pq.audit.systemevent rows and optional SRE alert triggers for critical events. <br><strong>Tests:</strong> severity to alert mapping, diagnosticRef linking. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditMetricsSnapshot(correlationId, metricSet, timestamp)</strong> — local metrics snapshot for telemetry uplink<br><strong>Purpose & contract:</strong> snapshot metrics like append latency histograms, rotation durations, export throughput, verify success rate; persist snapshot via AtomicWrite for CORE_Telemetry upload. Avoid network I/O in fast paths. Emit pq.audit.metrics.snapshot referencing snapshot artifact. <br><strong>Tests:</strong> snapshot integrity and periodic upload registration tests. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>AuditRepairTempRecords(tempPaths[], correlationId, force=false)</strong> — repair utility for leftover temp artifacts<br><strong>Purpose & contract:</strong> inspect leftover temp artifacts from failed AtomicWrite or rotation, verify payloads against evidenceHash, and either finalize atomic rename under maintenance or quarantine with forensic_manifest for operator action. Returns repairReport enumerating actions and outcomes. <br><strong>Behavior:</strong> validate temp artifact checksum; attempt atomic rename if safe and if target path free; otherwise quarantine and produce forensic_manifest. Emit pq.audit.atomic.temp.inspect and pq.audit.atomic.repair.*. <br><strong>Edge cases:</strong> mismatched payloads require quarantine and SRE escalation. <br><strong>Tests:</strong> ENOENT, ENOSPC, permission denied repair flows. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog:</strong><br><strong>Audit schema mandatory fields:</strong> timestamp, correlationId, module=PQ_Audit, procedure, operatorId optional, paramsHash, rowHash, evidenceRef optional, prevHash optional, rotationSequence optional, appendPosition, metadata object with duration_ms, attempts, artifactChecksum, tempPathList, errorCode optional. <br><strong>PII policy:</strong> top-level audit rows must never contain raw PII; sanitized full params stored encrypted in evidence store and referenced by evidenceRef. <br><strong>Representative ErrorCodes:</strong> PQ_AUDIT_MISSING_CORRELATION, PQ_AUDIT_SERIALIZATION_FAIL, PQ_AUDIT_DUPLICATE, PQ_AUDIT_APPEND_ENOSPC, PQ_AUDIT_APPEND_EPERM, PQ_AUDIT_ROTATE_CONFLICT, PQ_AUDIT_ROTATE_SIGN_FAIL, PQ_AUDIT_VERIFY_FAIL, PQ_AUDIT_EXPORT_FAIL, PQ_EVIDENCE_PII_REJECT, PQ_AUDIT_REPLAY_MISMATCH. Each maps to remediation guidance in PQ_Error. <br><strong>Metrics names:</strong> pq.audit.append.latency_ms, pq.audit.append.success_rate, pq.audit.rotate.duration_ms, pq.audit.verify.success_rate, pq.audit.export.throughput_bytes_s, pq.audit.replay.time_ms. Metrics are buffered locally and uploaded in audited batches by CORE_Telemetry. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-language golden governance:</strong><br><strong>Unit tests (must include):</strong><br>1. Append idempotency and duplicate detection with varied payload permutations and correlationIds. <br>2. Chained append concurrency tests verifying monotonic appendPosition under parallel writers. <br>3. Rotation signing goldens across Python, VBA, JS implementations. <br>4. Export atomicity tests with induced rename/fsync failures using FS mocks and staged fallback validation. <br>5. Evidence store PII detection and ACL enforcement tests. <br><strong>Integration tests:</strong><br>1. End-to-end PQ_Ribbon -> AppendChainedAudit -> RotateAndSign -> ExportAuditTail -> VerifyAuditChain CI pipeline test. <br>2. AuditReplay validation: generate test inject run, persist evidence, and replay to verify checksum parity. <br>3. Retention sweep simulation with legal hold scenarios. <br><strong>Property tests:</strong><br>1. Chain invariants: recomputing rotation root from archived rows must equal manifest root. <br>2. Replay determinism for seeded RNG and persisted evidence. <br><strong>CI golden gating:</strong> rotation signature parity, canonical encoding tests, static analyzer blocking forbidden UI-thread FS operations. Changes to audit schema require migration manifest and owner approvals. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns:</strong><br><strong>Required usage patterns:</strong><br>1. Always use AuditEmitUserAction for every ribbon-driven operation that will produce artifacts downstream. <br>2. Persist full parameters, RNG seeds, or large payloads with AuditEvidenceStoreWrite and reference via evidenceRef. <br>3. Use AppendChainedAudit for regulated or tamper-evident flows. <br>4. RotateAndSignAuditTail regularly; do not leave unsigned tail entries for prolonged periods. <br><strong>Forbidden practices:</strong><br>1. Do not embed raw PII in top-level audit rows. <br>2. Do not perform blocking fsync operations on the UI thread. <br>3. Do not export evidence unencrypted to third-party endpoints without governance approval. <br>4. Do not rely on global non-deterministic RNG for operator-visible sampling. <br><strong>Code-review checklist:</strong> verify AuditEmitUserAction use at UI entry points, evidenceRef usage for large payloads, AppendChainedAudit for regulated flows, RotateAndSign included in release manifest, and static analyzer checks for forbidden patterns. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable steps):</strong><br><strong>Audit append ENOSPC runbook:</strong><br>1. Query pq.audit.append.failure rows for ENOSPC with correlationId and target path. <br>2. Collect disk metrics for target mount (df -h, iostat, vmstat) and attach to incident. <br>3. Use AuditFlush to persist buffered rows to alternate local volume (--stage-local) and run AuditRepairTempRecords to finalize artifacts. <br>4. If capacity cannot be freed, escalate to SRE with forensic_manifest and audit_tail excerpt. <br><strong>Rotation verification anomaly triage:</strong><br>1. Run VerifyAuditChain to localize rotation anomaly. <br>2. Retrieve implicated rotation manifests and segments; verify signature chain against release manifest. <br>3. If signature invalid, place rotation on legal hold and escalate to security; issue freeze on exports dependent on the corrupted rotation. <br><strong>Non-deterministic replay complaint triage:</strong><br>1. Pull pq.audit.evidence.written and pq.audit.evidence.read entries for correlationId to find RNG serialized state and SafeRound inputs. <br>2. Execute AuditReplay deterministic dry-run and compare produced checksums; if mismatch persists, collect cross-language golden vectors and escalate to implementation owners. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples (multiple scenarios):</strong><br><strong>Scenario 1 — Template injection audit & deterministic replay (complete trace):</strong><br>1. Operator clicks Inject in PQ_Ribbon with correlationId p-20260117-abc. PQ_Ribbon calls AuditEmitUserAction which appends a minimal useraction row with paramsHash and evidenceRef placeholder. <br>2. PQ_Injector serializes full parameter set including previewSeed, numeric fidelity flags, and canonical decimal snapshots and calls AuditEvidenceStoreWrite. Evidence store returns evidenceRef e-123 and evidenceHash. pq.audit.evidence.written emitted. <br>3. PQ_Injector constructs a chained envelope {prevHash, timestamp, paramsHash, evidenceRef e-123, module=PQ_Injector, procedure=inject} and calls AppendChainedAudit. AppendChainedAudit writes the row to the tail (buffered or durable per context) and returns appendPosition and rowHash. pq.audit.chained.append.complete emitted. <br>4. Rotation executes within configured window: RotateAndSignAuditTail snapshots rows up to the cut, builds rotationSegment, computes rotationRootHash and signs rotationManifest with signerKeyId release-key-v3. Signed manifest and rotationSegment persisted via AtomicWrite and pq.audit.rotate.complete emitted. <br>5. ExportAuditTail creates a regulator package including rotationManifests, evidenceRef map, and an export manifest signed by the release signing key. Export persisted atomic and pq.audit.export.complete emitted with artifactChecksum and destinationUri. <br>6. Later, compliance requests deterministic replay: operator triggers AuditReplay(correlationId p-20260117-abc) with authorized evidence access. AuditReplay fetches evidenceRef e-123 (AuditEvidenceStoreRead with two-person approval if required), restores RNG state and canonical decimals, executes deterministic pipeline in sandbox reproducing artifactChecksum identical to archived artifactChecksum. pq.audit.replay.complete emitted with producedArtifactChecksums. <br><strong>Narrative takeaway:</strong> full chain from UI action → persisted parameters → chained append → rotation signing → export → replay demonstrates reproducibility and tamper-evidence with minimal PII exposure. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Scenario 2 — Preview with seeded sampling and audit linkage:</strong><br>1. Operator requests Preview; PQ_Ribbon computes previewSeed = HMAC_SHA256(<code>correlationId | &quot;preview-v2&quot;</code>) and packages seed and sampling parameters into evidence payload. <br>2. Call AuditEvidenceStoreWrite to persist seed and sampling metadata; receive evidenceRef pseed-01. <br>3. AuditEmitUserAction appends a user action row referencing pseed-01 and paramsHash; pq.audit.append.complete emitted. <br>4. Preview engine receives seed as parameter and performs deterministic sampling producing preview set; preview metadata (mChecksum) appended to audit tail. <br>5. If operator disputes sample selection, AuditReplay rehydrates seed and selection algorithm from evidenceRef to reproduce exact preview selection for forensic review. <br><strong>Narrative takeaway:</strong> seeding previews and persisting seeds to the evidence store enables reproducible previews across sessions and hosts. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Scenario 3 — Refresh diagnostics & export pipeline:</strong><br>1. Operator triggers Refresh; AuditEmitUserAction records the refresh intent with job descriptor paramsHash and evidenceRef referencing connector config. <br>2. Background refresh worker logs step-level events: pq_refresh.start, pq_refresh.conn.resolve, pq_refresh.query.exec, pq_refresh.collect.diagnostics; each step references evidenceRef to large diagnostic traces stored in evidence store. <br>3. On completion, ExportAuditTail packages M text and diagnostics, produces artifactChecksum and persists via AtomicWrite. pq.audit.export.complete emitted. <br>4. If export fails due to network, ExportAuditTail attempts staged local fallback and emits pq.audit.export.degraded. Operator UI displays degraded export status with a link to retry or download the local artifact. <br><strong>Narrative takeaway:</strong> fine-grained step-level audits plus archived diagnostics enable SRE to triage provider-level failures and reproduce full diagnostic contexts for root-cause analysis. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Scenario 4 — Template update governance for regulated templates:</strong><br>1. Template author opens PR modifying a regulated template tagged requiresHighPrecision. CI runs static checks ensuring mChecksum updated and no removal of requiresHighPrecision. <br>2. The PR approval actions (owner approvals, test signatures) are captured by AppendChainedAudit rows with evidenceRef pointing to PR diff and approval notes. <br>3. Release proceeds only after two-person approval recorded as chained audit rows and RotateAndSignAuditTail includes those approvals in a signed rotation manifest. <br>4. The signed release manifest acts as regulator-evidence that owner approvals and golden tests passed prior to release. <br><strong>Narrative takeaway:</strong> governance enforced by chained audit rows and signed rotations provides regulator-proof change history. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Scenario 5 — MatchMerge deterministic tie-breaking & audit trail:</strong><br>1. MatchMerge runs as a background job with correlationId mm-20260117-9; worker seeds DeterministicRNG(seed_source=correlationId, salt="matchmerge-v1") and persists serialized RNG state via AuditEvidenceStoreWrite to evidenceRef rng-evidence. <br>2. Match candidate tie-break ordering performed using deterministic shuffle keyed by tieBreakerKeys plus RNG-derived ordering; proposed merges persisted as merge proposal artifacts via AtomicWrite and recorded in AppendChainedAudit rows referencing proposal artifact checksum and RNG evidenceRef. <br>3. Operator reviews proposal; accept action recorded via AppendChainedAudit and saved apply plan persisted by AtomicWrite. If inline-apply chosen, additional two-person approvals captured in chained audits. <br>4. Forensics: AuditReplay can restore RNG state, reproduce candidate ordering, and reproduce exact merge proposals for audit. <br><strong>Narrative takeaway:</strong> deterministic RNG and persisted RNG state plus chained audit entries ensure reproducible matching decisions and auditable merge proposals. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — mapping PQ_Audit principles to PQ workflows (expanded):</strong><br><strong>Context:</strong> M runtime differences across hosts, decimal fidelity variability, and limited file-system guarantees require orchestrated helpers around M to achieve PQ_Audit guarantees. <br><strong>Patterns & recommended practices:</strong><br>1. <strong>Preview seeding pattern:</strong> compute previewSeed in ribbon layer; persist seed to evidence store and include seed fingerprint in preview audit. For simple preview selections, pass seed into template as parameter. For larger sampling, perform sampling in worker using DeterministicRNG and store selection snapshot as evidenceRef. <br>2. <strong>Injection atomicity pattern:</strong> M cannot guarantee atomic replace semantics on all hosts. Produce authoritative M query artifact in a trusted helper (signed XLAM or worker) that writes artifact to disk using AtomicWrite and emits a chained audit row with artifactChecksum. The injector then calls workbook.Queries.Add with the persisted artifact to ensure the injected query exactly matches audited artifact. <br>3. <strong>High-precision numeric pattern:</strong> mark templates requiring strict rounding as requiresHighPrecision. For such templates, offload numeric aggregation and rounding to worker-side SafeRound flows. Template should emit canonicalized numeric payload and evidenceRef; worker returns final rounded artifact persisted via AtomicWrite and recorded by AppendChainedAudit. <br>4. <strong>Retry & idempotency mapping:</strong> M refresh orchestration should be handled outside M by the add-in or a worker that applies Retry with idempotent tokens. M templates should remain declarative and stateless. <br>5. <strong>Diagnostics & traces pattern:</strong> M diagnostics can be large; store them in evidence store with evidenceRef and emit minimal diagnostic pointers in PQ_Audit rows. This keeps top-level rows lightweight and non-PII. <br><strong>Operator guidance:</strong> prefer worker-side finalization for numeric-critical or auditable steps; treat M templates as deterministic transformations parametrized by persisted seeds and canonical inputs; use evidenceRefs liberally for snapshots needed in replay. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Audit to semantic model governance (expanded):</strong><br><strong>Context:</strong> DAX is read-time expression language and cannot perform side-effects or persist external artifacts. ETL must handle rounding and chain-of-custody. <br><strong>Patterns & recommendations:</strong><br>1. <strong>RunMetadata table pattern:</strong> ETL writes an atomic RunMetadata record persisted with AtomicWrite and referenced by AppendChainedAudit including fields correlationId, configHash, artifactChecksum, runTimestamp, auditStatus. DAX measures can reference RunMetadata to display run provenance and verification status in reports. <br>2. <strong>Offload rounding/residuals to ETL:</strong> perform SafeRoundResiduals in ETL and store resolved cents as integers. DAX consumes pre-rounded values ensuring model logic remains deterministic and avoids cumulative rounding bias. <br>3. <strong>Deterministic sampling for model surfaces:</strong> compute a stable HashKey in ETL (e.g., HMAC(<code>primaryKey | runSeed</code>)) and persist sampling selection criteria with correlationId; DAX can use HashKey MOD N < k to present deterministic cohort selections. <br>4. <strong>Model-level checksum reconciliation:</strong> ETL writes datasetChecksum to artifact manifest and model RunMetadata; DAX measure exposes a ReconciliationFlag comparing current model checksum to expected artifactChecksum for downstream consumer confidence. <br><strong>Narrative takeaway:</strong> DAX should be a deterministic read surface referencing ETL-persisted audit metadata rather than performing transformational or cryptographic responsibilities. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded):</strong><br><strong>Minimum forensic artifacts to collect for PQ incidents:</strong><br>1. audit_tail.csv excerpt containing useraction and pq.audit.* rows spanning the correlationId timeframe. <br>2. rotation manifests and rotationSegment archives, including signer certificate chain and prevRotationHash chain. <br>3. evidence blobs referenced by evidenceRef such as serialized RNG state, canonical decimal snapshots, parameter sets, and diagnostic traces. <br>4. exported artifacts (M files, diagnostics bundle) with recorded artifactChecksum and export manifest. <br>5. jobDescriptor persisted via AtomicWrite with jobId and correlationId. <br>6. AuditReplay report and diff output showing producedArtifactChecksums and delta analysis. <br>7. AtomicWrite temp artifact listing and any atomic repair logs. <br><strong>Evidence storage & retention patterns:</strong><br>1. Hot evidence store: \\evidence\hot\<module>\<correlationId>\; retain 30 days with restricted access for rapid replay. <br>2. Warm encrypted archive: secure long-term store for regulatory retention (7 years) with access controls and chain-of-custody metadata. <br>3. Cold archive: immutable storage per regulatory schedule with signed manifests proving content integrity. <br><strong>Forensic_manifest contents:</strong> the forensic_manifest enumerates artifacts, rotation manifests, signer certificates, evidenceRef URIs, checksums, and access instructions for decryption keys (key IDs not secrets). <br><strong>Retention verification cadence:</strong> monthly AuditRetentionSweep with pq.audit.retention.sweep row; proof-of-delete artifacts preserved for compliance. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before PQ_Audit release (detailed):</strong><br>1. OWNERS listed and contactable in OWNERS.md. <br>2. Public API stable and documented with backward-compatible versioning and changelog. <br>3. Unit, integration, and golden tests for chaining and rotation signing pass across supported languages. <br>4. EvidenceStore encryption, ACL, and PII detection tests pass and security review completed. <br>5. Static analyzer prohibits UI-thread blocking FS operations and raw PII in top-level rows. <br>6. Release manifest includes signer keys, and injection helpers are code-signed where required. <br><strong>Blocking conditions:</strong> missing audit emits on PQ_Ribbon flows, rotation signature verification failures, or top-level PII leakage detected by static analysis. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & scripts (explicit, conceptual):</strong><br><strong>Unit tests:</strong><br>1. Append idempotency: call AppendAuditRow concurrently with identical payloads and verify single canonical appendPosition returned. <br>2. Chained append concurrency: multiple writers append chained rows concurrently; verify monotonic appendPosition ordering and prevHash continuity maintained. <br>3. Evidence store PII detection: supply payloads containing simulated PII patterns and verify rejection or required redaction. <br>4. Rotate signing: mock HSM signing and validate verifier implementations in multiple languages can validate signature. <br><strong>Integration tests:</strong><br>1. Full pipeline: PQ_Ribbon user action → AppendChainedAudit → RotateAndSignAuditTail → ExportAuditTail → VerifyAuditChain. Validate artifactChecksum parity and rotation signature verification. <br>2. Export failure injection: simulate remote storage failure and ensure staged local fallback and pq.audit.export.degraded emitted. <br>3. AuditReplay roundtrip: build a complex inject run, persist RNG and SafeRound inputs, replay deterministically and compare artifact checksums. <br><strong>Performance tests:</strong><br>1. Append throughput: synthetic stress test with 10k concurrent append producers; measure median append latency and flush behavior. <br>2. Rotation signing throughput: sign 100k rows and measure rotation duration; ensure it meets performance SLOs. <br>3. Export throughput with compression vs. no-compression under constrained network conditions. <br><strong>CI gating:</strong> no merge to main until unit, integration, golden signatures, and static analyzer checks pass; performance regressions require owner sign-off. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (concise and prescriptive):</strong><br>1. diagnostics collect --correlation p-YYYYMMDD-abc — collects audit_tail excerpt, rotation manifests, evidenceRef snapshots, and forensic_manifest.json. <br>2. audit export --range start,end --dest /secure/share/pq-audit --include-evidence true — create signed export for regulator submission and store artifactChecksum for reconciliation. <br>3. audit replay --correlation p-... --dry-run — deterministic replay for operator verification; returns diffs and producedArtifactChecksums. <br>4. audit repair-temp --temp /tmp/pq-audit.part.* — attempt to repair leftover temp artifacts using AtomicWriteRepair and produce pq.audit.atomic.repair entries. <br>5. audit flush --force — synchronous flush to ensure rows are persisted before scheduling critical jobs. <br><strong>When to call SRE:</strong> repeated pq.audit.export.failure with staged fallback used, rotation verification anomalies, evidence store key access failures, or repeated ENOSPC on append persistence. Provide forensic_manifest and rotation manifests in SRE ticket. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Final notes, governance & mandatory constraints (firm):</strong><br>1. Never place raw PII in top-level audit rows; use evidenceRef to reference encrypted evidence. <br>2. AppendChainedAudit is mandatory for regulated outputs and artifacts consumed by downstream services; unsigned tails are unacceptable for production exports. <br>3. Deterministic RNG seeds for operator-visible sampling must be persisted to evidence store and evidenceRef recorded in top-level audit rows. <br>4. Offload numeric-sensitive transforms to worker SafeRound flows and persist inputs to evidence store for reproduction. <br>5. All critical operations must emit audit rows and attach evidenceRef where necessary for forensics. <br>6. Periodic chain verification must run in CI and monitoring; verification failures open automated incidents and require forensics per runbook. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive, not a code snippet):</strong><br><strong>Fields required for PQ_Audit rows:</strong> timestamp, correlationId, module, procedure, operatorId optional, paramsHash, rowHash, evidenceRef optional, prevHash optional, rotationSequence optional, appendPosition, metadata object with duration_ms, attempts, artifactChecksum, tempPathList. <br><strong>Policy note:</strong> top-level audit rows must not contain PII; sanitized full params stored in evidence store and referenced by evidenceRef. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded):</strong><br><strong>Failure mode: partial tail write observed</strong><br>1. Cause: non-atomic append or host-specific rename semantics differing from POSIX; remote filesystem edge cases. <br>2. Mitigation: enforce AtomicWrite on persistence, run AuditRepairTempRecords to inspect temp files and finalize safe renames; add host compatibility checks and recommend same-volume writes where possible. <br><strong>Failure mode: rotation signature verification failure</strong><br>1. Cause: signer key rotated without publishing verification keys, rotation artifact corruption, or HSM failure. <br>2. Mitigation: place rotation on legal hold, disable exports associated with suspect rows, retrieve historical key manifest and verify mapping; if needed, restore from last verified rotation and escalate to security owners. <br><strong>Failure mode: non-deterministic replay</strong><br>1. Cause: RNG state not persisted, SafeRound inputs missing, cross-host decimal normalisation differences, or evidenceRef missing. <br>2. Mitigation: persist RNG serialize_state and SafeRound canonical inputs to evidence store; maintain cross-language golden vectors and implement canonical decimal normalization library in all runtimes. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests for any new behavior, golden vectors if deterministic sequences or encodings changed, and audit emission verification. <br>2. Changes to rotation or signature algorithm require migration manifest, owner approvals, and cross-language goldens. <br>3. Evidence store modifications require security review and tests ensuring PII not surfaced in top-level rows. <br>4. Release manifest must be updated and OWNERS approval acquired for production changes affecting injection or regulated outputs. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix D — Long-form incident reconstruction example (ordered):</strong><br><strong>Incident synopsis:</strong> "Injected query mismatch for correlation p-20260112-455" — artifact differs from expected template output observed by operator. <br><strong>Forensic reconstruction steps (ordered):</strong><br>1. Retrieve useraction and pq.audit.* rows for correlationId from audit_tail to build timeline. <br>2. Pull evidenceRef blobs for parameter sets and serialized RNG state via AuditEvidenceStoreRead with proper authorization. <br>3. Execute AuditReplay in deterministic dry-run mode restoring RNG and SafeRound state to produce replay artifacts and producedArtifactChecksums. <br>4. Compare producedArtifactChecksums to archived artifactChecksum from pq.audit.append.complete; if mismatch found, check atomic_write.verification_failed and rotation manifests for corruption. <br>5. Inspect AtomicWrite temp artifacts and run AuditRepairTempRecords to finalize or quarantine items. <br>6. If difference due to numeric rounding, restore canonical decimal snapshots and run SafeRoundResiduals reproduction; produce granular diff report showing where rounding diverged and why. <br>7. Package forensic_manifest.json enumerating rotation manifests, evidence blobs, artifact checksums, and replay logs; escalate to compliance if regulated. <br><strong>Outcome:</strong> reproduction yields validation that M runtime decimal handling differed; mitigation included marking template requiresHighPrecision, shifting final rounding to worker SafeRound, adding cross-language golden vectors, and releasing a signed update with AppendChainedAudit recorded approvals. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ & DAX short checklists for template authors and report builders:</strong><br><strong>PQ Template author checklist:</strong><br>1. Include mChecksum and templateVersion in metadata. <br>2. Mark requiresHighPrecision for templates with regulated numeric requirements. <br>3. Parameterize previewSeed and ensure previewSeed persisted via evidence store and recorded in preview audit. <br>4. Offload final numeric aggregation to worker SafeRound when requiresHighPrecision true. <br>5. Emit audit hooks for major template actions and link to correlationId. <br><strong>DAX/report builder checklist:</strong><br>1. Consume RunMetadata table for run provenance and artifactChecksum. <br>2. Avoid allocation or rounding residual logic in DAX; perform in ETL and persist resolved integers. <br>3. Use RunMetadata.auditStatus to display verification badges and guide downstream consumers. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix F — Example operator scenarios & sample playbooks (expanded):</strong><br><strong>Operator scenario: "Export failed — staged fallback used"</strong><br>1. Operator sees PQ UI indicating export degraded. <br>2. Run diagnostics collect --correlation <id> to gather audit_tail, export failure row, and forensic_manifest. <br>3. If staged local artifact present, download and verify artifact checksum with local copy. <br>4. Re-run ExportAuditTail to alternate destination or rerun after network recovery; attach forensic_manifest and pq.audit.export.failure to SRE ticket if repeated. <br><strong>Operator scenario: "Need to reproduce a preview selection"</strong><br>1. Use audit query to find pq_preview row and evidenceRef containing previewSeed. <br>2. Request AuditReplay with deterministic=true and dryRun to reproduce preview in sandbox; present produced selection to stakeholder. <br>3. If reproduced selection differs, escalate to platform parity owners with evidenceRef and replay logs. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Appendix G — Implementation notes & recommended library contracts (conceptual):</strong><br><strong>Canonical JSON rules for audit payloads:</strong><br>1. Sort object keys lexicographically. <br>2. Represent numbers in normalized decimal string form for canonicalization of SafeRound inputs. <br>3. Use RFC3339 UTC timestamps and avoid locale-dependent formatting. <br><strong>EvidenceRef format:</strong> evidenceRef should be an opaque URI-like token referencing encrypted evidence store object and include a short fingerprint to allow verification without revealing the payload. <br><strong>Rotation manifest format:</strong> include rotationSequence, prevRotationHash, rotationRootHash, rotationRowRange, signerKeyId, signingCertFingerprint, timestamp, and optional human-readable summary; manifest signed with signerKeyId. <br><strong>AtomicWrite contract with audit:</strong> AtomicWrite must return artifactChecksum and tempPaths inspected in pq.audit.atomic.repair entries when failures occur. Evidence store writes must return evidenceHash used in top-level audit rows as paramsHash. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Closing operational constraint (must not be bypassed):</strong><br>All PQ operations that produce artifacts consumed by downstream systems must: emit a user action audit row, persist full parameters and seeds to evidence store via AuditEvidenceStoreWrite, append a chained audit row using AppendChainedAudit, ensure rotation signing via RotateAndSignAuditTail, and export only signed artifacts. This chain is mandatory for regulated outputs, PII-touching workflows, and artifacts requiring downstream trust. </td></tr><tr><td data-label="PQ_Audit — Per-function Expert Technical Breakdown"> <strong>Final verification note:</strong> The PQ_Audit design above is intentionally prescriptive: it enforces deterministic chaining, evidence-backed replay, atomic persistence semantics, rotation signing, and strict PII handling. Implementations must provide cross-language canonical encodings and golden vectors to ensure parity across Excel/VBA, worker runtimes, and CI verification. </td></tr></tbody></table></div><div class="row-count">Rows: 44</div></div><div class="table-caption" id="Table3" data-table="Docu_0181_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by REG_Config — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">REG_Config — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_REG_CONFIG (recorded in OWNERS.md; primary and secondary on-call owners included in release manifests).<br><strong>Purpose:</strong> authoritative runtime configuration manager for add-ins and worker processes: deterministic load/validate/hash/migrate/persist flows; secure secret handling (decrypt-on-demand); remote overlay resolution (template repositories, feature flags); subscription/change-notify semantics; evidence-backed snapshot/export for forensic replay; policy-enforced gating for regulated outputs; integration points with REG_Utilities, REG_Audit, PQ_Library, PQ_Injector, CORE_JobScheduler, and CORE_ExecutionWorker. <br><strong>Public API (surface):</strong> Load_Config, Load_Config_From_Path, Load_Config_From_Embedded, Load_Config_From_Snapshot, Validate_Config_Schema, Compute_Config_Hash, Migrate_Config_If_Needed, Apply_Migration_Step, Persist_Config, Resolve_Remote_Config, Resolve_TemplateRepo_Config, Get_Runtime_Config, Get_Config_Value, Set_Config_Value, Subscribe_Config_Changes, Unsubscribe_Config_Changes, Reload_Config, Export_Config_Snapshot, Import_Config_Snapshot, Securely_Decrypt_Secrets, Serialize_Config_State, Restore_Config_State, Inspect_Config_Evidence, List_Config_Versions, Promote_Config_Version, Demote_Config_Version, Inspect_Temp_Artifacts. <br><strong>Audits emitted (MUST):</strong> config.load.started, config.load.completed, config.load.failed, config.validate.started, config.validate.completed, config.validate.failed, config.hash.computed, config.migration.started, config.migration.step_applied, config.migration.completed, config.migration.failed, config.persist.attempt, config.persist.completed, config.persist.failed, config.remote.resolve.attempt, config.remote.resolve.completed, config.remote.resolve.failed, config.resolve.template_repo, config.subscribe.added, config.subscribe.removed, config.reload.triggered, config.secret.access, config.secret.access_denied, config.export.snapshot, config.export.snapshot.failed. Each audit row MUST include: correlationId, module=REG_Config, procedure, paramsHash, config.hash (if available), evidenceRef (if heavy or sensitive payload persisted), durationMs, attempts (when retries occur), operatorId (if operator-initiated), migrationManifestRef (when applicable), and a minimal metadata object for quick triage. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Deterministic config.hash: identical logical configuration inputs produce identical config.hash across supported host implementations and languages. <br>2. Idempotent migrations: re-applying migration steps yields no further modifications after first success; migrationManifest captures applied steps and checksums. <br>3. Atomic persistence: persisted config artifacts use AtomicWrite semantics; consumers never observe truncated artifacts. <br>4. Audit-anchored transitions: any mutation of durable state (persist, migration, export, secret access) emits audit rows referencing correlationId and evidenceRef where applicable. <br>5. UI-thread safety: no long-running IO or network calls in UI bootstrap; deferred initialization on idle or worker contexts is required. <br>6. Secrets lifecycle: secrets decrypted only on-demand, kept in memory briefly, zeroized after use, and never logged or included in audits. <br>7. Observability: start/complete audits for long-running operations; include durationMs, attempts, errorCode and minimal diagnostics in failure audits. <br><strong>Performance SLOs (illustrative):</strong> median embedded config load <50ms; Validate_Config_Schema <30ms for typical config; Compute_Config_Hash <20ms for 200KB JSON; Resolve_Remote_Config under normal network conditions <=2s (subject to remote latency). <br><strong>CI / acceptance gates:</strong> canonicalization parity golden vectors, migration idempotency tests, audit emission checks, static analyzer enforcement for forbidden patterns (no UI-thread FS/network calls in bootstrap), and performance smoke tests. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>High-level design principles & constraints (immutable):</strong><br>1. Canonicalization-first: canonicalize input before computing config.hash, comparing versions, or producing artifacts. <br>2. Least trust: verify remote payloads (checksum or signature) before merge; do not auto-apply remote overlays for regulated fields. <br>3. Snapshot-before-mutate: always persist a snapshot prior to performing migrations or durable state changes. <br>4. Determinism: avoid locale-dependent formatting; use explicit decimal rules and Unicode normalization (NFC). <br>5. Fail-safe defaults: on remote resolution failure, fall back to last-known-good local snapshot and emit degraded audit. <br>6. Approval gating: irreversible or high-impact migrations require two-person approvals recorded in migrationManifest and validated by Set_Config_Value or Migrate_Config_If_Needed API preconditions. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Canonicalization rules (Compute_Config_Hash canonicalization):</strong><br>1. Sort object keys lexicographically at every object level. <br>2. Preserve array order unless schema explicitly marks array as unordered; when unordered, sort deterministically by schema-provided key. <br>3. Strings: escape per JSON spec, normalize Unicode to NFC, and use deterministic escaping for control characters. <br>4. Numbers: represent as decimal text with minimal necessary digits preserving exact value; if a schema field includes <code>scale</code>, format numbers to fixed decimal places per <code>scale</code>. <br>5. Booleans and null: represented with canonical literals <code>true</code>, <code>false</code>, <code>null</code>. <br>6. Exclude ephemeral metadata fields (timestamps, temporaryIds) from hash computation; record such fields in sidecar evidence metadata instead. <br>7. Produce canonical bytes UTF-8 encoded, without indentation or optional whitespace, feed into SHA256 to compute config.hash. <br><strong>Parity enforcement:</strong> provide canonicalization test vectors and cross-language golden tests for VBA/Python/C#/JS to be enforced by CI. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Load_Config(source, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> load configuration from source and return parsed canonicalized config plus config.hash. Sources: embedded hidden-sheet, file path on disk, snapshot artifacts, streams, or last-known-cache. Must be non-blocking in UI fast path (defer file/network IO). Emits config.load.started and config.load.completed/failed. <br><strong>Inputs & options:</strong> <code>source</code>: {type:<code>&quot;embedded&quot;|&quot;file&quot;|&quot;snapshot&quot;|&quot;stream&quot;|&quot;cache&quot;</code>, path?, stream?, descriptor?}; <code>options</code>: {allowPartial:false, requireSchema:false, schemaRef:null, correlationId, operatorId, readOnly:true, maxSizeBytes:10485760}. <br><strong>Returns:</strong> {configObject, configHash, canonicalBytesRef, sourceFingerprint, loadDurationMs, warnings[]}. On failure return structured error with ErrorCode and diagnosticsRef. <br><strong>Step-by-step:</strong><br>1. Emit config.load.started(correlationId, sourceFingerprint, paramsHash). <br>2. Read bytes from source, normalize encoding to UTF-8 (handle BOMs), fail with CONFIG_LOAD_ENCODING_ERROR when normalization impossible. <br>3. Parse JSON with tolerant parser that preserves token-level metadata required for canonicalization (exact numbers, escape sequences). <br>4. Canonicalize parsed object -> canonicalBytes via Compute_Config_Hash routine and compute configHash (SHA256). <br>5. If options.requireSchema true -> call Validate_Config_Schema(configObject, schemaRef). If validation fails -> emit config.load.failed with CONFIG_SCHEMA_INVALID. <br>6. If allowPartial true and parse failed due to truncation, attempt salvage heuristics (controlled) and persist partial snapshot with audit config.load.partial_recover and diagnostics. <br>7. Return parsed object, configHash, canonicalBytesRef and emit config.load.completed(correlationId, configHash, durationMs). <br><strong>Edge cases & policies:</strong><br>1. Large payloads (>maxSizeBytes): stream parse and canonicalize; if streaming not possible fail and emit CONFIG_LOAD_TOO_LARGE. <br>2. Missing embedded sheet -> fallback to packaged default config and emit config.load.fallback. <br>3. Corrupted snapshot -> fail with CONFIG_LOAD_CORRUPT and attach forensic evidence. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Validate_Config_Schema(configJson, schemaSpec, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> perform deterministic JSON Schema v7 validation; produce deterministic sorted error lists and stable ErrorCodes. Pure computation; emits config.validate.* audits around invocation. <br><strong>Inputs & options:</strong> <code>configJson</code>, <code>schemaSpec</code> (inline or ref), <code>options</code>: {collectAllErrors:true, failFast:false, allowUnknownKeywords:false, schemaCacheTTL:86400}. <br><strong>Return:</strong> {valid:bool, errors:[{path, code, message, schemaKeyword}], durationMs}. <br><strong>Implementation notes:</strong><br>1. Use a <code>$ref</code>-resolving validator that inlines remote schema fragments with TTL-based caching. <br>2. Numeric constraints evaluated using decimal arithmetic to avoid binary float differences. <br>3. Deterministic error ordering: sort errors by JSON Pointer asc then schemaKeyword asc. <br>4. Map each failure to stable ErrorCodes (CONFIG_SCHEMA_MISSING_FIELD, CONFIG_SCHEMA_TYPE_MISMATCH, CONFIG_SCHEMA_ENUM_MISMATCH, CONFIG_SCHEMA_PATTERN_FAIL, CONFIG_SCHEMA_MINIMUM_FAIL, CONFIG_SCHEMA_ONEOF_AMBIGUOUS). <br><strong>Edge & failure handling:</strong><br>1. Unsupported keywords -> CONFIG_SCHEMA_UNSUPPORTED_KEYWORD with schemaFingerprint and evidenceRef. <br>2. Circular <code>$ref</code> unresolved -> CONFIG_SCHEMA_CIRCULAR_REF with diagnosticsRef. <br>3. When collectAllErrors=false return the first deterministic error; when true return full set. <br><strong>Audits:</strong> config.validate.started(correlationId, schemaHash, paramsHash) config.validate.completed(correlationId, schemaHash, resultHash, durationMs) config.validate.failed(correlationId, schemaHash, errorCode, diagnosticsRef). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Compute_Config_Hash(configJson, canonicalizationRules)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> produce canonical byte sequence and compute authoritative SHA256 fingerprint (config.hash) deterministically across languages and hosts. Provide canonicalBytes for evidence storage or streaming. <br><strong>Return:</strong> {configHash, canonicalBytesRef, canonicalSize, durationMs}. <br><strong>Algorithmic specifics:</strong><br>1. Depth-first traversal, visiting object keys in lexicographic order. <br>2. Emit primitives via canonical rules: strings escaped per JSON spec, numbers normalized to decimal textual format per <code>scale</code> when present, booleans/null as <code>true</code>/<code>false</code>/<code>null</code>. <br>3. Arrays: preserve order unless schema marks unordered; do not attempt to sort arrays unless explicit. <br>4. Stream canonical bytes into incremental SHA256 to handle large payloads efficiently. <br>5. Provide canonicalization pseudocode, sample vectors, and cross-language test harness. <br><strong>Parity & CI:</strong> canonicalization golden vectors and cross-language test harness must be included in repo and used by CI parity tests. <br><strong>Audits:</strong> config.hash.computed(correlationId, configHash, canonicalSize, durationMs). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Migrate_Config_If_Needed(configObject, migrationsRegistry, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> determine whether migrations are required to bring configObject to current targetVersion; apply ordered, idempotent migrations; persist migrationManifest and pre/post snapshots; emit detailed audits for each applied step. <br><strong>Inputs & options:</strong> <code>configObject</code>, <code>migrationsRegistry</code> (map: version->migrationDescriptor), <code>options</code>: {dryRun:false, autoApprove:false, operatorApproval:null, correlationId, timeoutMsPerStep:30000}. <br><strong>Return:</strong> {migratedConfig, migrationsApplied:[{from,to,migrationId,scriptHash,intermediateHash}], migrationManifestRef, durationMs}. <br><strong>Detailed flow & constraints:</strong><br>1. Determine currentVersion from configObject.schemaVersion (default 0) and targetVersion from registry.latest. <br>2. If currentVersion == targetVersion -> emit config.migration.completed (no steps) and return. <br>3. Persist pre-migration snapshot (Persist_Config snapshotPre) and include snapshotRef in migrationManifest. <br>4. For each sequential migration step: <br>&nbsp;&nbsp;&nbsp;&nbsp;a. Validate preconditions (presence/shape of expected keys). <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Execute migration in sandboxed, resource-limited interpreter (no network unless explicit operator approval); each migration script must be idempotent and declare "reversible" if an undo is available. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. Validate post-state against next-version schema using Validate_Config_Schema. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. Compute intermediate config.hash and append to migrationsApplied with scriptHash, step duration. <br>5. After all steps applied successfully, persist migrationManifest atomically with applied steps and signatures (if operator approvals required). <br>6. Emit config.migration.completed with migrationManifestRef. <br><strong>Governance & high-risk migrations:</strong><br>1. Migrations that change regulated numeric behavior or outputs must be classified high-impact and require two-person approval recorded in migrationManifest; API enforces approval check before execution. <br>2. For irreversible migrations, record explicit "nonReversible=true" and store extra evidence and approvals. <br><strong>Failure & rollback policies:</strong><br>1. If any step fails, restore pre-migration snapshot (Persist_Config snapshotPre) and emit config.migration.failed with forensic_manifestRef and error details. <br>2. If restore fails, escalate to SRE with full evidence bundle. <br><strong>Audits:</strong> config.migration.started(correlationId, currentVersion, targetVersion, snapshotRef) config.migration.step_applied(correlationId, migrationId, from, to, intermediateHash, durationMs) config.migration.completed(correlationId, migrationManifestRef) config.migration.failed(correlationId, errorCode, forensicManifestRef). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Persist_Config(targetPath, configObject, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> durable atomic persistence of canonicalized configuration artifact and associated sidecar metadata; ensure crash-safety and verifiable checksums; integrate REG_Utilities.AtomicWrite and optional artifact signing. <br><strong>Inputs & options:</strong> <code>targetPath</code>, <code>configObject</code>, <code>options</code>: {tmpSuffix:".part", fsyncFile:true, fsyncParent:true, signArtifact:false, signatureKeyRef:null, maxAttempts:3, correlationId}. <br><strong>Return:</strong> {success, artifactPath, artifactChecksum, attempts, elapsedMs}. <br><strong>Detailed steps & guarantees:</strong><br>1. Canonicalize configObject via Compute_Config_Hash -> canonicalBytes and configHash. <br>2. Create sidecar metadata JSON: {configHash, schemaVersion, correlationId, releaseManifestHash, migrationManifestRef, producedBy}. <br>3. Write canonicalBytes to tempPath while computing artifactChecksum (sha256). <br>4. Use REG_Utilities.AtomicWrite to atomically rename tempPath to targetPath; on platforms or filesystems where atomic rename is degraded (NFS, SMB), fall back to two-phase approach and emit util.atomic_write.degraded with rationale. <br>5. Optionally sign artifact using signatureKeyRef; persist signature sidecar. <br>6. Re-open targetPath and verify checksum equals computed artifactChecksum; if mismatch attempt repair as per AtomicWriteRepair policy; otherwise emit config.persist.failed. <br>7. Emit config.persist.completed on success. <br><strong>Failure modes & runbook:</strong><br>1. ENOSPC -> config.persist.failed with CONFIG_PERSIST_ENOSPC and mount-path diagnostics; attempt stage-local fallback if configured. <br>2. EPERM -> config.persist.failed with CONFIG_PERSIST_EPERM and ACL snapshot evidence. <br>3. Verification mismatch -> config.persist.failed with util.atomic_write.verification_failed; attempt repair or escalate. <br><strong>Observability & audit fields:</strong> config.persist.attempt(correlationId, targetPath, configHash, tempPath) config.persist.completed(correlationId, artifactPath, artifactChecksum, durationMs, attempts) config.persist.failed(correlationId, targetPath, errorCode, diagnosticsRef). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Resolve_Remote_Config(remoteDescriptor, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> securely fetch, validate, and merge remote overlays (feature flags, template indexes) into local config while preserving operator overrides; produce deterministically ordered mergeTrace for audits and forensic replay. <br><strong>Descriptor fields:</strong> {uri, expectedChecksum (optional), authRef (optional), priority (int)}. <br><strong>Options:</strong> {mergeStrategy:<code>&quot;overlay&quot;|&quot;merge_deep&quot;|&quot;replace&quot;</code>, timeoutMs:30000, allowFallback:true, strict:false, correlationId}. <br><strong>Return:</strong> {mergedConfig, remoteFingerprint, mergeTrace, durationMs}. <br><strong>Detailed steps & policies:</strong><br>1. Emit config.remote.resolve.attempt(correlationId, remoteUri, expectedChecksum). <br>2. Fetch remote payload using secure transport; apply certificate pinning if configured and use authRef (decrypted via Securely_Decrypt_Secrets) when necessary. <br>3. Compute remote checksum and compare to expectedChecksum; if mismatch and strict true -> fail with CONFIG_REMOTE_CHECKSUM_MISMATCH; if mismatch and allowFallback true -> use cached remote artifact and emit degraded audit. <br>4. Merge per mergeStrategy: overlay (shallow), merge_deep (recursive with local precedence unless remote forces), replace (remote subtree replaces local subtree — requires explicit approval for regulated fields). Provide deterministic mergeTrace: list of applied overlays in canonical order with sourceHash and appliedPaths. <br>5. Persist merged configuration artifact via Persist_Config and emit config.remote.resolve.completed with mergeTrace and persisted artifact checksum. <br><strong>Failure & fallback rules:</strong><br>1. Fetch errors -> config.remote.resolve.failed with CONFIG_REMOTE_FETCH_ERROR and diagnosticsRef. <br>2. Auth failures -> CONFIG_REMOTE_AUTH_ERROR and guidance to update credentials. <br>3. Remote checksum mismatch in strict mode -> fail and block merge until manual remediation. <br><strong>Audits:</strong> config.remote.resolve.attempt(correlationId, remoteUri, expectedChecksum) config.remote.resolve.completed(correlationId, remoteFingerprint, mergeTrace) config.remote.resolve.failed(correlationId, remoteUri, errorCode, diagnosticsRef). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Resolve_TemplateRepo_Config(templateRepoDescriptor, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> specialized resolver for Power Query template repositories: fetch manifest and template index, verify per-template mChecksums and signatures, compute deterministic templateRepoHash, and produce authoritative templateIndex for PQ_Library/PQ_Injector. <br><strong>Descriptor fields:</strong> {repoUri, strict:boolean (require mChecksums), verifySignatures:boolean, cacheTTL:3600}. <br><strong>Return:</strong> {templateIndex, templateRepoHash, templateCount, evidenceRefs, durationMs}. <br><strong>Detailed workflow & guarantees:</strong><br>1. Fetch repository manifest and index with bounded concurrency respecting allowedHosts and TLS policies. <br>2. For each template entry fetch metadata and M content; compute per-template artifact checksum and verify mChecksum and optional signature; persist per-template evidenceRef for forensic retrieval. <br>3. Compute templateRepoHash by deterministic serialization over sorted template metadata entries and canonicalization rules. <br>4. If strict=true and any template lacks mChecksum or fails signature verification -> fail with CONFIG_TEMPLATE_REPO_STRICT_MISSING and abort repository application. <br>5. Persist template index artifact via Persist_Config or REG_Export and emit config.resolve.template_repo(correlationId, repoUri, templateRepoHash, templateCount). <br><strong>PQ policy:</strong> PQ_Injector must refuse injecting a template whose mChecksum does not appear in the authoritative templateIndex persisted by REG_Config and referenced by current config.hash in regulated environments. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Get_Runtime_Config(), Get_Config_Value(path, default), Set_Config_Value(path, value, persist=false)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> provide safe read-only runtime snapshots and controlled mutation API for in-memory changes and optional persistence; enforce optimistic concurrency on persisted updates; segregate secret fields as secretRefs rather than plaintext. <br><strong>Semantics & invariants:</strong><br>1. <code>Get_Runtime_Config()</code> returns an immutable read-only snapshot with associated configHash and asOf timestamp. <br>2. <code>Get_Config_Value(path, default)</code> resolves JSON Pointers and returns {value, found}. <br>3. <code>Set_Config_Value(path, value, persist=false, priorConfigHash=null)</code> updates in-memory snapshot immediately and notifies subscribers; when persist=true, requires priorConfigHash for optimistic concurrency to prevent lost updates and calls Persist_Config to durable storage. <br>4. Secret keys return secretRef placeholders; to use secrets call Securely_Decrypt_Secrets with secretRef. <br>5. Protected keys (releaseManifestId, systemOwner) are read-only and Set attempts return CONFIG_MOD_READONLY. <br><strong>Concurrency & conflict handling:</strong><br>1. When persist=true and priorConfigHash mismatches with current persisted hash -> return CONFIG_CONFLICT and provide merge hints. <br>2. Large payloads set via Set_Config_Value schedule persistence to worker threads and return changeId with pendingPersist flag to avoid UI blocking; emit config.set.pending_persist audit. <br><strong>Audits:</strong> config.get.value(correlationId, path, resultHash) config.set.value(correlationId, path, previousHash, newHash, persistFlag) config.set.conflict(correlationId, path, expectedHash, actualHash). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Subscribe_Config_Changes(handler, filters, options)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> in-process subscription registration for config change notifications; provide deterministic ordering, debouncing, persistence of subscription descriptors when requested, and robust handler isolation. <br><strong>Parameters:</strong> handler(callable), filters {pathPrefixes, modules, changeTypes}, options {persistSubscription:false, deliveryGuarantee:<code>&quot;at_least_once&quot;|&quot;best_effort&quot;</code>, debounceMs:200, correlationId}. Returns subscriptionId. <br><strong>Semantics & constraints:</strong><br>1. Notifications delivered asynchronously off UI thread; handler exceptions are isolated and recorded via config.subscribe.handler_error audit. <br>2. Deterministic ordering: when changes are persisted notifications reflect persistence ordering; for transient in-memory changes ordering follows mutation order. <br>3. Debounce semantics batch changes into deterministic windows; deterministic jitter uses correlationId-seeded DeterministicRNG when configured to avoid systemic correlation. <br>4. Persisted subscriptions rehydrate on process restart and receive missed persisted changes based on lastProcessedHash recorded with subscription descriptor. <br><strong>Failure & scaling behavior:</strong><br>1. Slow handlers apply backpressure policy: queue up to N events (config.push.queueMax), then apply drop or escalate policy. <br>2. If handler repeatedly fails -> mark subscription unhealthy and notify operator via config.subscribe.handler_error audit. <br><strong>Audits:</strong> config.subscribe.added(correlationId, subscriptionId, filters) config.subscribe.removed(correlationId, subscriptionId) config.subscribe.handler_error(correlationId, subscriptionId, errorCode, diagnosticsRef). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Securely_Decrypt_Secrets(secretRefs[], decryptContext)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> decrypt secret references referenced in config using platform KMS/modSecurity; return ephemeral in-memory tokens or signed short-lived references for cross-process use; avoid plaintext persistence or exposure in audits. <br><strong>Inputs:</strong> secretRefs[], decryptContext {correlationId, purpose, operatorId, ttlMs}. <br><strong>Return:</strong> {ephemeralTokens: map(secretRef -> ephemeralToken), evidenceRef}. <br><strong>Security invariants & behavior:</strong><br>1. Decrypted plaintext must exist only in secure memory; zeroize on TTL expiry or explicit dispose. <br>2. Audit records secret access (config.secret.access) with secretFingerprint and evidenceRef but never plaintext. <br>3. Cross-process usage yields signed short-lived delegation tokens referencing secretRef not plaintext. <br>4. RBAC enforced: unauthorized attempts return CONFIG_SECRET_REVOKED or CONFIG_SECRET_ACCESS_DENIED and emit evidenceRef. <br><strong>Edge cases:</strong><br>1. Key material unavailable -> CONFIG_SECRET_KEY_UNAVAILABLE and operator guidance to check KMS. <br>2. Secret revoked -> CONFIG_SECRET_REVOKED with evidenceRef. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong><code>Export_Config_Snapshot(evidencePath, includeSecrets=false, operatorApproval=null)</code> — technical breakdown:</strong><br><strong>Purpose & contract:</strong> create a forensic snapshot of current config for audits or incident response; default redacts secrets; includeSecrets requires two-person approval and explicit justification. <br><strong>Parameters:</strong> evidencePath, includeSecrets (bool), operatorApproval {approverIds, signatures, justification, timestamp}. <br><strong>Return:</strong> {artifactPath, artifactChecksum, evidenceRef}. <br><strong>Rules & safeguards:</strong><br>1. Default snapshot redacts secret fields with <code>&lt;&lt;REDACTED&gt;&gt;</code>. <br>2. includeSecrets true requires operatorApproval with at least two approvers recorded and signature evidence; otherwise fail with CONFIG_EXPORT_SECRETS_FORBIDDEN. <br>3. Snapshot persisted atomically via Persist_Config and include sidecar metadata listing redacted fields, approvers, and evidenceRef for KMS operations. <br><strong>Audits:</strong> config.export.snapshot(correlationId, artifactChecksum, evidenceRef) config.export.snapshot.failed(correlationId, errorCode). </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog:</strong><br><strong>Audit row schema (required fields):</strong> timestamp, correlationId, module=REG_Config, procedure, operatorId (optional), paramsHash, configHash (optional), resultHash/evidenceRef (optional), durationMs, metadata (e.g., sourcePath, schemaVersion, migrationStepsApplied, artifactChecksum). <br><strong>ErrorCodes (representative):</strong> CONFIG_LOAD_FAIL, CONFIG_LOAD_ENCODING_ERROR, CONFIG_LOAD_TRUNCATED, CONFIG_SCHEMA_MISSING, CONFIG_SCHEMA_TYPE_MISMATCH, CONFIG_SCHEMA_UNSUPPORTED_KEYWORD, CONFIG_SCHEMA_CIRCULAR_REF, CONFIG_MIGRATION_FAILED, CONFIG_PERSIST_ENOSPC, CONFIG_PERSIST_EPERM, CONFIG_REMOTE_AUTH_ERROR, CONFIG_REMOTE_CHECKSUM_MISMATCH, CONFIG_TEMPLATE_REPO_STRICT_MISSING, CONFIG_SECRET_REVOKED, CONFIG_CONFLICT, CONFIG_EXPORT_SECRETS_FORBIDDEN. <br><strong>Metrics (local buffered):</strong> config.load.latency_ms, config.validate.count, config.validate.error_rate, config.hash.computation_ms, config.migration.count, config.persist.latency_ms, config.remote.resolve.latency_ms, config.subscribe.handler_error_count. <br><strong>Evidence policy:</strong> sensitive or large payloads stored encrypted in evidence store and referenced by evidenceRef; top-level audit rows must not contain secrets or PII. Evidence stores support hot (30 days), warm (7 years), and cold (regulatory) tiers with automated retention verification. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Testing matrix: unit tests, integration tests, property tests & golden parity:</strong><br><strong>Unit tests (required):</strong><br>1. Load_Config: embedded hidden-sheet, file path, snapshot, stream, BOM/encoding handling, truncated JSON salvage path. <br>2. Validate_Config_Schema: missing fields, type mismatches, pattern errors, <code>$ref</code> resolution, circular refs, deterministic error ordering. <br>3. Compute_Config_Hash: canonicalization vectors for escaped strings, Unicode normalization, numeric formatting and array behavior. <br>4. Migrate_Config_If_Needed: idempotency tests (apply twice no-op), rollback tests, timeout enforcement, reversible vs irreversible migration handling. <br>5. Persist_Config: atomic replace semantics, ENOSPC and EPERM simulation, verification mismatch handling, signature sidecar tests. <br>6. Secret workflows: KMS mock, evidenceRef mapping, export snapshot redaction tests. <br><strong>Integration tests (required):</strong><br>1. End-to-end pipeline: Load -> Validate -> Migrate -> Persist -> Resolve remote overlays -> subscription notifications -> PQ injection referencing artifactChecksum and evidenceRef. <br>2. TemplateRepo strict mode: missing per-template mChecksums cause failure. <br>3. Concurrency stress tests: high-frequency Set_Config_Value, subscription fanout, and deterministic ordering verification. <br><strong>Property & performance tests:</strong><br>1. Canonicalization idempotence: canonicalize(canonicalize(x)) == canonicalize(x) on random inputs. <br>2. Migration monotonicity and deterministic intermediate hashes. <br>3. Performance: canonicalize and compute hash for >10MB config in worker environment within budget. <br><strong>Golden parity:</strong><br>1. Canonicalization goldens and schema validation error templates verified across O/S and language implementations; CI must block merges if parity vectors diverge. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Developer guidance & forbidden patterns (explicit):</strong><br><strong>Required patterns:</strong><br>1. Always compute config.hash immediately after load and before applying migrations. <br>2. Always persist snapshots and migration manifests via Persist_Config (AtomicWrite) to ensure durability and forensic traceability. <br>3. Use REG_Utilities.DeterministicRNG seeded with correlationId for any tie-breaker or non-deterministic decision during merges. <br>4. Validate remote payload checksums or signatures before application; do not auto-apply remote overlays for regulated fields. <br><strong>Forbidden patterns:</strong><br>1. Do not perform network or heavy filesystem IO on the UI main thread during bootstrap; static analyzer rejects such code paths. <br>2. Do not log or emit plaintext secrets in audits or telemetry; use evidenceRef to reference encrypted artifacts. <br>3. Do not rely on host locale-dependent formatting in canonicalization or numeric normalization. <br>4. Do not auto-apply irreversible migrations touching regulated outputs without recorded two-person approval. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (practical executable steps):</strong><br><strong>Config load parse/truncation failure runbook:</strong><br>1. Query audit_tail for config.load.failed for the correlationId and retrieve diagnosticsRef and temp artifacts list. <br>2. Fetch last-known-good snapshot (evidenceRef) and compute/compare config.hash; if matching artifacts exist, restore snapshot via Import_Config_Snapshot. <br>3. If salvage attempted (allowPartial=true) compare partial snapshot artifactChecksum to original and escalate if checksums mismatch. <br>4. If persistent corruption exists escalate to SRE with forensic_manifest and include temp artifacts, parser logs, and canonicalBytes. <br><strong>Migration failure runbook:</strong><br>1. Locate config.migration.failed audit and migrationManifestRef. <br>2. Restore pre-migration snapshot persisted prior to migration attempt; validate pre-snapshot config.hash. <br>3. Re-run migration in a controlled worker environment with debug logging enabled; if failing deterministically, capture stack traces and include in incident package for migration author review. <br>4. If migration touched regulated outputs and is irreversible, pause downstream exports, notify compliance, and assemble regulatory package. <br><strong>Remote integrity mismatch runbook:</strong><br>1. For config.remote.resolve.failed due to checksum mismatch, quarantine remote repo and block auto-merge. <br>2. Retrieve fetched payload and compute local checksum; if mismatch, treat remote as compromised and notify owners and SRE; attach forensic_manifest with evidenceRef. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & scenario walkthroughs (multiple):</strong><br><strong>Scenario 1 — Add-in startup with embedded config and deferred remote overlay (complete trace):</strong><br>1. CORE_Bootstrap initializes correlationId generator and schedules deferred REG_Config init on UI idle. {audit: bootstrap.started} <br>2. REG_Config.Load_Config(type=embedded, correlationId=r-20260120-abc) reads hidden-sheet, canonicalizes, computes config.hash -> emit config.load.completed(correlationId, configHash). <br>3. Validate_Config_Schema against local schema bundle -> emit config.validate.completed(schemaHash). <br>4. REG_Config defers Resolve_Remote_Config; remote fetch fails checksum -> config.remote.resolve.failed and system continues using embedded-only config with degraded audit. <br>5. PQ_Ribbon obtains Get_Runtime_Config and includes config.hash in pq_preview and pq_inject audit rows so injected artifacts can be traced. <br><strong>Takeaway:</strong> canonicalization and config.hash early in chain enable deterministic traceability; remote overlays are deferred to protect UI responsiveness. <br><strong>Scenario 2 — Operator-proposed config change and required migration with two-person approval:</strong><br>1. Operator uploads config_v2.json; REG_Config.Load_Config computes configHash_v2 and Validate_Config_Schema passes. <br>2. Migrate_Config_If_Needed detects schema bump requiring high-risk migration steps (changes rounding semantics). API requires operatorApproval; system persists pre-migration snapshot via Persist_Config(snapshot_pre). <br>3. Two approvers provide operatorApproval with approverIds and signatures; migration executes in sandbox step-by-step; each step validates against intermediate schemas and computes intermediate hashes appended to migrationManifest. <br>4. Final config persisted via Persist_Config; config.migration.completed with migrationManifestRef and config.persist.completed with artifact checksum are emitted. <br>5. Compliance reviews migrationManifest and evidenceRef to verify approvals and deterministic transformations. <br><strong>Takeaway:</strong> snapshots, audits, and migration manifests create a deterministic, auditable chain enabling compliance and replay. <br><strong>Scenario 3 — PQ template injection for <code>requiresHighPrecision</code> template:</strong><br>1. Template index includes <code>requiresHighPrecision=true</code>; REG_Config.Resolve_TemplateRepo_Config indexes templates, verifies mChecksums and computes templateRepoHash. <br>2. Operator previews template; PQ_Ribbon queries REG_Config for metadata and deterministically seeds preview using correlationId-derived seed; preview audit records seed and config.hash. <br>3. On inject, PQ_Injector fetches authoritative artifact via evidenceRef; heavy numeric transforms performed by worker using REG_Utilities.SafeRoundResiduals; final M query text assembled and persisted via Persist_Config/REG_Export. <br>4. PQ_Injector injects the persisted authoritative artifact into workbook; pq_inject audit references config.hash and artifactChecksum ensuring injected M matches audited artifact. <br><strong>Takeaway:</strong> worker-side numeric processing and atomic persistence ensure numeric fidelity and auditability across hosts where M numeric semantics vary. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) mapping — deep operational guidance:</strong><br><strong>Context constraints & rationale:</strong><br>1. M runtime differs between Excel versions and may not provide consistent decimal behavior; file system semantics vary and trusted atomic rename may not be available in all hosts. <br>2. REG_Config provides authoritative template index, injection policies, and flags (requiresHighPrecision) and orchestrates worker-side transforms when client-side M is insufficient. <br><strong>Mapping patterns & guidance:</strong><br>1. <strong>Template provenance:</strong> maintain authoritative template index in REG_Config with per-template mChecksum, templateRepoHash and evidenceRef; PQ_Library must display only audited templates and PQ_Injector must refuse injection when a template's mChecksum does not match authoritative index in regulated contexts. <br>2. <strong>Preview determinism & sampling:</strong> compute preview seed in REG_Config using HMAC(<code>correlationId | templateId</code>) or DeterministicRNG and pass seed as parameter into M preview functions; alternatively perform sampling in worker using DeterministicRNG and return sampled preview artifact; persist seed and config.hash in preview audit to enable replayability. <br>3. <strong>Numeric fidelity:</strong> templates with requiresHighPrecision should offload final aggregation and SafeRound-based rounding to worker flows; persist authoritative artifact via Persist_Config and inject the persisted artifact rather than relying on host M numeric behavior. <br>4. <strong>Connection & refresh defaults:</strong> store provider defaults and robust retry/backoff policy in REG_Config for PQ refresh orchestration to consult; ensure PQ refresh orchestration uses REG_Utilities.Retry with idempotent asserts and deterministic_jitter for CI. <br>5. <strong>Injection enforcement:</strong> PQ_Injector must require artifactChecksum verification and optional signature verification before injecting; for regulated templates require persisted artifact evidenceRef and config.hash linkage. <br><strong>Operational PQ example (end-to-end):</strong><br>1. User previews template -> PQ_Ribbon requests template metadata and deterministic seed from REG_Config; preview runs and returns preview artifact; audit includes seed and config.hash. <br>2. User injects template -> PQ_Injector verifies mChecksum against REG_Config persisted index and artifactChecksum against persisted artifact; injects audited artifact into workbook and emits pq_inject audit referencing config.hash and artifactChecksum. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX & semantic model mapping — deep operational guidance:</strong><br><strong>Context & constraints:</strong><br>1. DAX is read-time only and cannot perform side-effects; ETL must implement deterministic transforms and persist authoritative artifacts for DAX consumption. <br>2. REG_Config supplies ETL parameters, rounding policy, sampling salts, and run metadata requirements to enable deterministic model builds and auditability. <br><strong>Mapping patterns & recommendations:</strong><br>1. <strong>RunMetadata table & reconciliation:</strong> ETL writes RunMetadata (runId, correlationId, configHash, artifactChecksum, runTs) atomically; DAX measures reference RunMetadata to show verification status and provenance in reports. <br>2. <strong>Rounding & allocations:</strong> perform SafeRoundResiduals in ETL according to rounding policy stored in REG_Config and persist integer-cent outputs for DAX to present without re-rounding. <br>3. <strong>Deterministic sampling:</strong> ETL uses DeterministicRNG seeded from correlationId and config salt to tag sampled rows persistently; DAX uses persisted sample flags for reproducible dashboards and comparability across runs. <br>4. <strong>Model checksum verification:</strong> ETL writes expected artifactChecksum in model metadata; DAX measure compares stored expected checksum to actual to provide verification indicators in the report. <br><strong>DAX operational narrative:</strong><br>1. ETL runs with configHash r-YYYYMMDD-abc and writes artifactChecksum s-zzz; RunMetadata persisted. <br>2. Report refresh loads RunMetadata; DAX measure <code>IsVerified</code> evaluates artifactChecksum==expected and displays verification. <br>3. Compliance can reconstruct lineage via correlationId -> config.hash -> migrationManifestRef -> artifactChecksum chain described in audit rows. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Forensic artifacts, evidence paths & retention policy (expanded):</strong><br><strong>Minimum forensic artifacts:</strong><br>1. persisted config artifact(s) with artifactChecksum and config.hash. <br>2. migrationManifest.json with applied steps, pre/post hashes, snapshotRef. <br>3. audit_tail.csv with required config.* events for the affected timeframe. <br>4. serialized RNG state when deterministic decisions used. <br>5. KMS operation logs and evidenceRef for secrets access (encrypted). <br>6. temp artifacts created by failed AtomicWrite attempts with tempPath lists. <br><strong>Evidence storage & retention tiers:</strong><br>1. Hot evidence store: \\evidence\hot\REG_Config\<correlationId>\ retained 30 days and available for daily operations. <br>2. Warm archive: secure encrypted archive for regulatory retention (7 years) with chain-of-custody metadata. <br>3. Cold archive: retained per regulation and legal holds; access via compliance request. <br><strong>Forensic manifest required fields:</strong> correlationId, artifacts:[{path,artifactChecksum,configHash}], migrationManifestRef, auditTailPath, rngStateRef, secretAccessEvidenceRefs, retentionTier. <br><strong>Retention verification cadence:</strong> monthly automated retention verification job emitting housekeeping.audit and providing proof-of-delete logs for expired artifacts. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (exhaustive):</strong><br>1. Owners listed in OWNERS.md and contactable. <br>2. Public API stable and fully documented. <br>3. JSON Schema validator integrated with parity vectors. <br>4. Compute_Config_Hash parity vectors across supported languages validated. <br>5. Migration registry with idempotent migrations and coverage tests. <br>6. All durable artifacts persisted via AtomicWrite and verified in integration tests. <br>7. Audit hooks validated end-to-end (config.load<em>, config.validate</em>, config.migration<em>, config.persist</em>). <br>8. Secrets handling validated with KMS integration and redaction tested. <br>9. CI gates include forbidden-API static checks and performance budgets. <br><strong>Blocking conditions:</strong> missing audit emits, canonicalization parity failures, non-idempotent migrations, or missing two-person approvals for regulated changes. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Extensive test plan & example scripts (explicit deliverables):</strong><br><strong>Unit tests:</strong><br>1. Load_Config: test embedded hidden-sheet, file path, BOM handling, encoding, truncated JSON, and partial recovery heuristics. <br>2. Validate_Config_Schema: tests for missing fields, type mismatches, pattern errors, <code>$ref</code> resolution, and circular refs. <br>3. Compute_Config_Hash: canonicalization tests for strings, Unicode escapes, numeric formats, arrays, and nested structures. <br>4. Migrate_Config_If_Needed: idempotency tests (apply twice yields identical final hash), rollback tests, permission gating, and timeout enforcement. <br>5. Persist_Config: test atomic replace semantics and simulation of ENOSPC/EPERM and verification mismatch reactions. <br>6. Secrets: KMS mock integration tests ensuring no plaintext in audits and evidenceRef correctness. <br><strong>Integration tests:</strong><br>1. Full pipeline: load -> validate -> migrate -> persist -> remote resolve -> subscription notifications -> PQ injection referencing artifactChecksum. <br>2. TemplateRepo strict mode: missing mChecksums cause resolution to fail. <br>3. Concurrency: stress test Set_Config_Value and many subscribers verifying deterministic ordering. <br><strong>Property & performance tests:</strong><br>1. Canonicalization idempotence and streaming for very large configs (>10MB). <br>2. Migration monotonicity and deterministic intermediate hashes. <br>3. Persist_Config performance under SSD and network FS with acceptable degraded reporting. <br><strong>Golden parity enforcement:</strong> cross-language canonicalization parity tests must pass for all commit gates. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands, examples & templates (prescriptive):</strong><br>1. <code>config load --source embedded --correlation &lt;id&gt;</code> — load embedded config and emit config.load.* audit rows. <br>2. <code>config validate --artifact &lt;path&gt; --schema &lt;ref&gt;</code> — deterministic validation with stable error codes and diagnosticsRef. <br>3. <code>config migrate --snapshot-pre --apply --correlation &lt;id&gt;</code> — persist pre-migration snapshot, run migrations with approvals, persist migrationManifest. <br>4. <code>config export-snapshot --evidence &lt;path&gt; [--include-secrets]</code> — export forensic snapshot; include-secrets requires two-person approval with operatorApproval evidence. <br>5. <code>config resolve-remote --uri &lt;repo&gt; --strict</code> — refresh template repo in strict mode; fail on missing mChecksums. <br><strong>When to call SRE:</strong> after two Persist_Config ENOSPC retries for critical artifacts or when migration rollback fails; attach forensic_manifest and audit_tail in SRE ticket. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (required fields and guidance):</strong><br><strong>Fields required:</strong> timestamp, correlationId, module, procedure, operatorId (optional), paramsHash, configHash (optional), resultHash (optional), evidenceRef (optional), prevHash (optional), migrationManifestRef (optional), metadata object with keys {duration_ms, attempts, artifactChecksum, tempPathList, errorCode}. <br><strong>Policy:</strong> do not include PII or secret content in top-level audit rows; sanitized params may be stored in evidence store and referenced by evidenceRef. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes, diagnostics & mitigations (expanded):</strong><br><strong>Failure mode: partial/truncated write observed by worker</strong><br>1. Cause: caller bypassed AtomicWrite or rename semantics failed on network FS. <br>2. Diagnostics: check util.atomic_write.<em> audits and temp artifact lists; run InspectTempArtifacts to find temp files. <br>3. Mitigation: AtomicWriteRepair to rename verified temp payloads under maintenance window, or restore last-known-good snapshot and re-run persistence. <br><strong>Failure mode: non-deterministic sampling reported by operator</strong><br>1. Cause: global RNG used or seed not propagated. <br>2. Diagnostics: inspect config.seed audit and evidenceRef for serialized RNG state; confirm seed used in run. <br>3. Mitigation: require DeterministicRNG seeded from correlationId in preview and ETL flows; persist RNG state in evidence store when deterministic replay is required. <br><strong>Failure mode: rounding bias detected across runs</strong><br>1. Cause: repeated non-conservative rounding (awayFromZero) applied repeatedly. <br>2. Diagnostics: inspect util.saferound.</em> audits, rounding policy in config, and migration manifests if rounding policy changed. <br>3. Mitigation: adopt bankers or residual_distribute strategies; update migration manifest and re-run reconciliation flows; require two-person approval for regulated numeric policy changes. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests and integration tests for changed behavior and golden vector updates if canonicalization or RNG changed. <br>2. Changes to canonicalization or RNG algorithms require OWNER approvals and updated migration manifest if schema semantics depend on them. <br>3. Changes to persistence semantics require cross-platform regression tests and SRE sign-off. <br>4. Migration changes affecting regulated outputs require two-person approval and updated migration manifest in PR. <br>5. Static analyzer must pass to ensure no UI-thread IO or forbidden APIs are introduced. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Appendix D — Long-form incident reconstruction example (executable ordered steps):</strong><br><strong>Incident synopsis:</strong> "Discrepancy in allocation for run r-20260112-455." <br><strong>Reconstruction steps:</strong><br>1. Collect audit_tail rows for correlationId r-20260112-455 covering REG_Config, REG_Utilities, and PQ artifacts. <br>2. Retrieve persisted config artifact referenced in config.persist.completed with artifactChecksum and migrationManifestRef. <br>3. Pull serialized RNG state (evidenceRef) if deterministic sampling or tie-breakers used. <br>4. Re-run allocation pipeline in reproduce mode using canonical decimals, RNG serialized state, and SafeRoundResiduals; compute produced artifactChecksum. <br>5. Compare produced artifactChecksum to original artifactChecksum; if mismatch, inspect atomic_write.verification_failed audits and temp artifacts to detect IO-level anomalies. <br>6. Package forensic_manifest including audit_tail, persisted artifacts, RNG state, jobDescriptor, and migrationManifest and escalate to compliance/SRE if regulated outputs impacted. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ template author & DAX report builder checklists (concise & prescriptive):</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> field in template metadata. <br>2. Mark <code>requiresHighPrecision</code> when precise numeric fidelity and SafeRound guarantees required. <br>3. Parameterize seed for preview and ensure preview audit records seed and config.hash. <br>4. Avoid client-side final rounding for regulated flows; offload to worker SafeRound flows and persist authoritative artifact. <br><strong>DAX/report builder checklist:</strong><br>1. Consume RunMetadata table for run provenance and artifactChecksum. <br>2. Avoid allocation or rounding in DAX; rely on ETL-applied integer-cent outputs. <br>3. Use persisted hashed stable keys for deterministic sampling filters. </td></tr><tr><td data-label="REG_Config — Per-function Expert Technical Breakdown"> <strong>Final mandatory constraints & closing invariants (non-negotiable):</strong><br>1. Every authoritative config artifact MUST have a computed and persisted config.hash before being used by other systems. <br>2. All durable artifacts consumed by other processes MUST be persisted using AtomicWrite to guarantee consumers never see partial artifacts; CI enforces this via static checks. <br>3. Secrets MUST never appear in audit rows or top-level telemetry; only evidenceRef and secretFingerprint are recorded. <br>4. Numeric-sensitive transforms that affect regulated outputs MUST be executed in worker SafeRound flows with evidence persisted; client-side M numeric transforms are not authoritative for regulated outputs. <br>5. Audit rows and evidenceRef chains (correlationId -> config.hash -> migrationManifest -> artifactChecksum) MUST be present for any run touching regulated outputs or PII. <br><strong>Assurance:</strong> repeated reviews and cross-checks required during PR and release; canonicalization, migration idempotency, atomic persistence, and audit emission are blocking checks enforced in CI. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>