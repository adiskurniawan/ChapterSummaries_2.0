<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1766902581">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li>
<li class="toc-item"><a class="toc-link" href="#Table10">Table 10</a></li>
<li class="toc-item"><a class="toc-link" href="#Table11">Table 11</a></li>
<li class="toc-item"><a class="toc-link" href="#Table12">Table 12</a></li>
<li class="toc-item"><a class="toc-link" href="#Table13">Table 13</a></li>
<li class="toc-item"><a class="toc-link" href="#Table14">Table 14</a></li>
<li class="toc-item"><a class="toc-link" href="#Table15">Table 15</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0162_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> <strong>Component â†’ Responsibility</strong><br><br><strong>config/</strong> â†’ runtime settings loader, active rule version, feature flags, environment configuration<br><br><strong>src/pph21_v1/io/</strong> â†’ input parsing (CSV/Excel), column mapping, schema validation, canonical payroll record creation<br><br><strong>src/pph21_v1/rules/</strong> â†’ pure tax calculation logic (PTKP, TER, progressive, DTP) with deterministic decision traces<br><br><strong>src/pph21_v1/audit/</strong> â†’ append-only audit recording, verification, evidence and retention packaging<br><br><strong>src/pph21_v1/export/</strong> â†’ Bukti Potong & SPT Masa exporters, manifest generation, checksum and schema validation<br><br><strong>src/pph21_v1/reconcile/</strong> â†’ reconciliation of internal results vs external filings/sources, exception detection<br><br><strong>src/pph21_v1/integrations/</strong> â†’ adapters/connectors for CSV, SAP, Workday, and other payroll systems<br><br><strong>src/pph21_v1/api/</strong> â†’ FastAPI service layer exposing ingest, simulate, export, and reconcile endpoints<br><br><strong>worker pool</strong> â†’ executes CPU/IO-bound background jobs (calculation, export, reconciliation)<br><br><strong>{metadata DB}</strong> â†’ job metadata, idempotency keys, audit indexes, processing state<br><br><strong><object_store></strong> â†’ immutable snapshots, export bundles, archived audit artifacts </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ“ <strong>Directory Overview</strong><br><br><code>pph21_v1</code><br>â”œâ”€â”€ LICENSE<br>â”œâ”€â”€ README.md<br>â”œâ”€â”€ pyproject.toml<br>â”œâ”€â”€ requirements.txt<br>â”œâ”€â”€ .env.example<br>â”œâ”€â”€ .gitignore<br>â”œâ”€â”€ config\<br>â”‚  â”œâ”€â”€ settings.py<br>â”‚  â”œâ”€â”€ default_rules\<br>â”‚  â”‚  â”œâ”€â”€ ptkp.yml<br>â”‚  â”‚  â”œâ”€â”€ progressive_brackets_v1.yml<br>â”‚  â”‚  â””â”€â”€ dtp_rules_v1.yml<br>â”‚  â”œâ”€â”€ rules_migrations\<br>â”‚  â”‚  â””â”€â”€ README.md<br>â”‚  â””â”€â”€ schema\<br>â”‚     â””â”€â”€ rule_schema.json<br>â”œâ”€â”€ src\<br>â”‚  â””â”€â”€ pph21_v1\<br>â”‚     â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”œâ”€â”€ app.py<br>â”‚     â”œâ”€â”€ cli.py<br>â”‚     â”œâ”€â”€ settings.py<br>â”‚     â”œâ”€â”€ constants.py<br>â”‚     â”œâ”€â”€ utils\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ file_ops.py<br>â”‚     â”‚  â”œâ”€â”€ paths.py<br>â”‚     â”‚  â”œâ”€â”€ imports.py<br>â”‚     â”‚  â”œâ”€â”€ log.py<br>â”‚     â”‚  â””â”€â”€ crypto.py<br>â”‚     â”œâ”€â”€ io\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ parsers.py<br>â”‚     â”‚  â”œâ”€â”€ csv_mapper.py<br>â”‚     â”‚  â”œâ”€â”€ excel_reader.py<br>â”‚     â”‚  â””â”€â”€ validators.py<br>â”‚     â”œâ”€â”€ rules\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ progressive.py<br>â”‚     â”‚  â”œâ”€â”€ ter.py<br>â”‚     â”‚  â”œâ”€â”€ ptkp.py<br>â”‚     â”‚  â””â”€â”€ dtp_engine.py<br>â”‚     â”œâ”€â”€ export\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ bukti_potong_csv.py<br>â”‚     â”‚  â”œâ”€â”€ bukti_potong_xml.py<br>â”‚     â”‚  â”œâ”€â”€ spt_masa_prefill.py<br>â”‚     â”‚  â””â”€â”€ manifest.py<br>â”‚     â”œâ”€â”€ audit\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ recorder.py<br>â”‚     â”‚  â”œâ”€â”€ auditor.py<br>â”‚     â”‚  â””â”€â”€ retention.py<br>â”‚     â”œâ”€â”€ reconcile\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ recon_service.py<br>â”‚     â”‚  â””â”€â”€ exception_queue.py<br>â”‚     â”œâ”€â”€ integrations\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ adapter_base.py<br>â”‚     â”‚  â”œâ”€â”€ csv_adapter.py<br>â”‚     â”‚  â”œâ”€â”€ sap_adapter.py<br>â”‚     â”‚  â””â”€â”€ workday_adapter.py<br>â”‚     â”œâ”€â”€ api\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ server.py<br>â”‚     â”‚  â”œâ”€â”€ routes\<br>â”‚     â”‚  â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”‚  â”œâ”€â”€ health.py<br>â”‚     â”‚  â”‚  â”œâ”€â”€ upload.py<br>â”‚     â”‚  â”‚  â”œâ”€â”€ simulate.py<br>â”‚     â”‚  â”‚  â””â”€â”€ export.py<br>â”‚     â”‚  â””â”€â”€ auth.py<br>â”‚     â”œâ”€â”€ ml\<br>â”‚     â”‚  â”œâ”€â”€ <strong>init</strong>.py<br>â”‚     â”‚  â”œâ”€â”€ pipeline.py<br>â”‚     â”‚  â”œâ”€â”€ models\<br>â”‚     â”‚  â”‚  â””â”€â”€ anomaly_model.py<br>â”‚     â”‚  â””â”€â”€ explainability.py<br>â”‚     â””â”€â”€ tests\<br>â”‚        â”œâ”€â”€ <strong>init</strong>.py<br>â”‚        â”œâ”€â”€ conftest.py<br>â”‚        â”œâ”€â”€ test_progressive.py<br>â”‚        â”œâ”€â”€ test_ter.py<br>â”‚        â”œâ”€â”€ test_dtp.py<br>â”‚        â””â”€â”€ test_export.py<br>â”œâ”€â”€ scripts\<br>â”‚  â”œâ”€â”€ run_local.bat<br>â”‚  â”œâ”€â”€ migrate_rules.bat<br>â”‚  â””â”€â”€ generate_fixture.py<br>â”œâ”€â”€ examples\<br>â”‚  â”œâ”€â”€ sample_payroll.csv<br>â”‚  â”œâ”€â”€ sample_payroll.xlsx<br>â”‚  â””â”€â”€ sample_bukti_manifest.json<br>â”œâ”€â”€ docs\<br>â”‚  â”œâ”€â”€ architecture.md<br>â”‚  â”œâ”€â”€ operations.md<br>â”‚  â”œâ”€â”€ api.md<br>â”‚  â””â”€â”€ rules_update_guide.md<br>â”œâ”€â”€ deployments\<br>â”‚  â”œâ”€â”€ docker\<br>â”‚  â”‚  â”œâ”€â”€ Dockerfile<br>â”‚  â”‚  â””â”€â”€ docker-compose.yml<br>â”‚  â”œâ”€â”€ k8s\<br>â”‚  â”‚  â”œâ”€â”€ deployment.yaml<br>â”‚  â”‚  â”œâ”€â”€ service.yaml<br>â”‚  â”‚  â””â”€â”€ secrets.example.yaml<br>â”‚  â””â”€â”€ helm\<br>â”‚     â””â”€â”€ Chart.yaml<br>â”œâ”€â”€ ci\<br>â”‚  â”œâ”€â”€ actions.yaml<br>â”‚  â””â”€â”€ pre-commit-config.yaml<br>â””â”€â”€ data\<br>   â”œâ”€â”€ fixtures\<br>   â”‚  â”œâ”€â”€ golden_case_1.json<br>   â”‚  â””â”€â”€ golden_case_2.json<br>   â””â”€â”€ archives\<br>      â””â”€â”€ README.md </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ“¦ <strong>config/</strong><br><br>Centralized configuration and versioned rule files:<br>â€¢ <b>settings.py</b> â€“ typed loader (env + file) for runtime parameters.<br>â€¢ <b>default_rules/</b> â€“ canonical rule files (PTKP, progressive brackets, DTP) used by the rules engine.<br>â€¢ <b>rules_migrations/</b> â€“ migration notes and scripts for rule updates.<br>â€¢ <b>schema/rule_schema.json</b> â€“ JSON schema for validating rule files. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ§° <strong>src/pph21_v1/utils/</strong><br><br>Infrastructure helpers reused from your PTT codebase:<br>â€¢ <b>file_ops.py</b> â€“ atomic write/read, deterministic filenames, safe temp-swaps.<br>â€¢ <b>paths.py</b> â€“ normalized safe joins and path sanitizers.<br>â€¢ <b>imports.py</b> â€“ lazy/fallback imports for optional heavy libs.<br>â€¢ <b>log.py</b> â€“ structured logging with batch/request IDs.<br>â€¢ <b>crypto.py</b> â€“ checksum and manifest helpers. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ“¥ <strong>src/pph21_v1/io/</strong><br><br>Input parsing and validation:<br>â€¢ <b>parsers.py</b> â€“ CSV/Excel/markdown parsers and schema mapping.<br>â€¢ <b>csv_mapper.py</b> â€“ client CSV â†’ canonical record mapping.<br>â€¢ <b>excel_reader.py</b> â€“ robust Excel ingestion (sheets, types).<br>â€¢ <b>validators.py</b> â€“ NPWP/PTKP/component validation rules. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> âš–ï¸ <strong>src/pph21_v1/rules/</strong><br><br>Domain tax logic (data-driven):<br>â€¢ <b>progressive.py</b> â€“ annual progressive calculator.<br>â€¢ <b>ter.py</b> â€“ TER monthly withholding implementation.<br>â€¢ <b>ptkp.py</b> â€“ PTKP determination and exemptions.<br>â€¢ <b>dtp_engine.py</b> â€“ PMK/DTP eligibility evaluator (reads rule files). </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ“¤ <strong>src/pph21_v1/export/</strong><br><br>Report & file generation (atomic, schema-validated):<br>â€¢ <b>bukti_potong_csv.py</b> â€“ CSV bukti potong generator.<br>â€¢ <b>bukti_potong_xml.py</b> â€“ XML output per PER-11 schema (validator hook).<br>â€¢ <b>spt_masa_prefill.py</b> â€“ SPT Masa prefill export.<br>â€¢ <b>manifest.py</b> â€“ bundle manifests, checksums, rule-version tags. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ›¡ï¸ <strong>src/pph21_v1/audit/</strong><br><br>Audit trail and retention:<br>â€¢ <b>recorder.py</b> â€“ append-only audit entries for each calculation/export.<br>â€¢ <b>auditor.py</b> â€“ verification checks and evidence bundling.<br>â€¢ <b>retention.py</b> â€“ retention/rotation policies and secure deletion helpers. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ” <strong>src/pph21_v1/reconcile/</strong><br><br>Reconciliation & exceptions:<br>â€¢ <b>recon_service.py</b> â€“ reconcile internal withholdings vs SPT Masa/DJP responses.<br>â€¢ <b>exception_queue.py</b> â€“ queue of exceptions with suggested automated fixes and approval metadata. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ”Œ <strong>src/pph21_v1/integrations/</strong><br><br>Adapters for payroll systems and connectors:<br>â€¢ <b>adapter_base.py</b> â€“ adapter interface and helpers.<br>â€¢ <b>csv_adapter.py</b> â€“ generic CSV connector.<br>â€¢ <b>sap_adapter.py</b> â€“ SAP integration scaffold.<br>â€¢ <b>workday_adapter.py</b> â€“ Workday integration scaffold. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸŒ <strong>src/pph21_v1/api/</strong><br><br>Service layer and routes:<br>â€¢ <b>server.py</b> â€“ FastAPI app factory.<br>â€¢ <b>routes/</b> â€“ health, upload, simulate, export endpoints.<br>â€¢ <b>auth.py</b> â€“ token-based auth and rate-limiting. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ¤– <strong>src/pph21_v1/ml/</strong><br><br>Optional ML for anomaly detection (isolated):<br>â€¢ <b>pipeline.py</b> â€“ ETL & model orchestration.<br>â€¢ <b>models/anomaly_model.py</b> â€“ trained model interface.<br>â€¢ <b>explainability.py</b> â€“ SHAP-like explain outputs for alerts. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ§ª <strong>src/pph21_v1/tests/</strong><br><br>Test coverage and golden cases:<br>â€¢ unit tests for progressive/TER/ DTP logic.<br>â€¢ export/golden fixtures used for schema validation and CI. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ› ï¸ <strong>scripts/</strong>, <strong>examples/</strong>, <strong>docs/</strong>, <strong>deployments/</strong>, <strong>ci/</strong>, <strong>data/</strong><br><br>Operational tooling and examples:<br>â€¢ <b>scripts/</b> â€“ run_local.bat, migrate_rules.bat, fixture generators.<br>â€¢ <b>examples/</b> â€“ sample_payroll.csv/xlsx and manifest examples.<br>â€¢ <b>docs/</b> â€“ architecture, operations runbook, API and rules update guide.<br>â€¢ <b>deployments/</b> â€“ Docker, Kubernetes, and Helm manifests.<br>â€¢ <b>ci/</b> â€“ actions.yaml and pre-commit config.<br>â€¢ <b>data/</b> â€“ golden fixture cases and archived exports. </td></tr><tr><td data-label="PROJECT STRUCTURE â€” D:\Dropbox\Projects\pph21_v1"> ğŸ§­ <strong>Functional summary</strong><br><br>Single repository that separates: infrastructure & safety utilities (atomic I/O, path sanitizers, lazy imports), canonical parsers, data-driven tax rules, DTP eligibility & policy engine, export & reconciliation pipelines, append-only audit trails, pluginized integrations, and optional ML anomaly detection. Rule files are versioned under <code>config/default_rules</code> so legal updates do not require code changes; all exports are produced atomically with manifests and rule-version evidence. </td></tr></tbody></table></div><div class="row-count">Rows: 15</div></div><div class="table-caption" id="Table2" data-table="Docu_0162_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"> <strong>9) Reconciliation & exception handling (process + data model)</strong><br><br>- Reconciliation scheduled (post-export) and on-demand: compare internal withholdings vs external sources, produce discrepancy reports.<br>- Reconciliation report groups: <code>company_id</code>, <code>period</code>, <code>discrepancy_class</code> (amount_mismatch, missing_record, duplicate_record), suggested_adjustment, risk_score.<br>- Exception queue model: <code>exception_id</code>, <code>snapshot_ref</code>, <code>discrepancy</code>, <code>suggested_fix</code>, <code>risk_score</code>, <code>status</code> (<code>open | triage | approved | applied | rejected</code>), <code>approval_chain</code> (actors + timestamps).<br>- Human-in-the-loop for high-risk items; low-risk can be auto-applied per policy with audit trail. </td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr><tr><td data-label="Project 1 â€” Payroll Compliance Engine for PPh 21 v1 â€” Overview"></td></tr></tbody></table></div><div class="row-count">Rows: 23</div></div><div class="table-caption" id="Table3" data-table="Docu_0162_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” settings.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” settings.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” settings.py"> <strong>File-level responsibilities</strong><br><br>This module defines the single canonical <code>Settings</code> object and the small set of helpers used to construct, validate, and present configuration for the entire service. Design goals: <strong>import-time safety</strong> (no network I/O, no opening secret stores, no heavy SDK imports), <strong>idempotence</strong> (repeated construction with the same environment must be deterministic), <strong>least-privilege defaults</strong> (safe, locked-down production defaults), and <strong>secrets hygiene</strong> (never reveal raw secrets in <code>repr()</code> / logs / manifests). Keep this file focused: complex parsing or secret-provider adapters belong in separate modules. Document operational knobs (<code>env</code>, <code>strict</code>, <code>startup_mode</code>, <code>middleware_mode</code>) at the top of the file with short examples. Attach a <code>runtime_fingerprint</code> helper that is stable for non-secret settings and is used in <code>app.state</code> and manifests. Provide a tiny <code>build_test_settings</code> helper for unit tests that returns a <code>Settings</code> with dry-run secret resolver and dry-run logging. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>@dataclass class Settings</code></strong><br><br><strong>Signature / shape:</strong> a typed dataclass or very-small <code>pydantic.BaseModel</code>-equivalent containing grouped fields. Example groups: <code>meta</code> (<code>env</code>, <code>service_name</code>, <code>version</code>, <code>strict</code>), <code>server</code> (<code>host</code>, <code>port</code>, <code>workers</code>, <code>limit_concurrency</code>, <code>proxy_headers</code>), <code>storage</code> (<code>object_store_url</code>, <code>bucket</code>), <code>db</code> (<code>dsn</code>, <code>pool_min</code>, <code>pool_max</code>), <code>security</code> (<code>allowed_origins</code>, <code>rate_limit</code>), <code>secrets</code> (<code>secrets_backend</code>, <code>secrets_opts</code>), <code>timeouts</code> (<code>startup_timeout</code>, <code>shutdown_grace_period</code>). Prefer immutability (<code>frozen=True</code> or manual <code>__post_init__</code> freeze).<br><br><strong>Responsibilities:</strong> single source-of-truth for runtime configuration. Keep it minimal: avoid runtime behavior in attribute getters. Provide <code>asdict()</code>/<code>to_safe_dict()</code> methods (see below) and a <code>replace(**overrides)</code> or factory helper to create modified copies. Document which fields are "critical" vs "optional" for <code>strict</code> semantics. Provide clear docstrings for each field including default and expected type. Unit tests should assert pickling/serialization and equality semantics (two <code>Settings</code> with same values compare equal). </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>load_settings_from_env(prefix: str = &#x27;PPH21_&#x27;) -&gt; Dict[str, Any]</code></strong><br><br><strong>Signature:</strong> <code>load_settings_from_env(prefix: str = &#x27;PPH21_&#x27;) -&gt; Dict[str, Any]</code> â€” returns a plain mapping used by the <code>Settings</code> factory.<br><br><strong>Responsibilities:</strong> map environment variables into typed values (no direct construction of <code>Settings</code> to keep separation of concerns). Implementation notes: (1) use a canonical mapping table (<code>ENV_VAR_NAME -&gt; settings.field.path</code>); (2) perform lightweight, deterministic coercion (<code>&quot;true&quot; -&gt; True</code>, numeric parsing, comma-separated lists); (3) do not call external systems; (4) support common prefixes and optional <code>.env</code>-style overrides for local dev when explicitly asked by CLI; (5) place minimal guards for missing but optional values. Provide clear tests for boolean and list coercion and for prefix behavior. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>load_settings_from_file(path: str, format: Literal[&#x27;env&#x27;,&#x27;yaml&#x27;,&#x27;json&#x27;]=&#x27;env&#x27;) -&gt; Dict[str, Any]</code></strong><br><br><strong>Signature:</strong> <code>load_settings_from_file(path: str, format: Literal[&#x27;env&#x27;,&#x27;yaml&#x27;,&#x27;json&#x27;]=&#x27;env&#x27;) -&gt; Dict[str, Any]</code> â€” parse an on-disk settings file into a mapping.<br><br><strong>Responsibilities:</strong> read developer or CI supplied settings manifests. Must be explicit about file permissions and not automatically load files on import. Supported formats: <code>.env</code> (simple KEY=VAL), YAML, JSON. Validation: fail-fast on parse errors, warn (or fail under <code>strict</code>) if file contains secrets in cleartext. If file contains secret references (e.g., <code>secrets.backend=vault</code>, <code>secrets.db_pw=secret://...</code>) preserve them as <code>SecretRef</code> markers rather than resolving them. Tests: invalid yaml/json, duplicated keys, and permission warnings. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>merge_settings(base: Settings, overrides: Dict[str, Any]) -&gt; Settings</code></strong><br><br><strong>Signature:</strong> <code>merge_settings(base: Settings, overrides: Dict[str, Any]) -&gt; Settings</code> â€” pure function returning a new <code>Settings</code> instance.<br><br><strong>Responsibilities:</strong> deterministic precedence: <code>explicit CLI &gt; file &gt; env &gt; defaults</code>. Never mutate <code>base</code>. Preserve <code>SecretRef</code> wrappers if overrides use secret references. When merging nested mappings, do deep merge only for explicitly supported namespaces (e.g., <code>db</code>, <code>server</code>) to avoid surprising behavior. Provide unit tests for precedence, secret preservation, and immutability. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>validate_settings(settings: Settings, strict: Optional[bool] = None) -&gt; None</code></strong><br><br><strong>Signature:</strong> <code>validate_settings(settings: Settings, strict: Optional[bool] = None) -&gt; None</code> â€” raises <code>ConfigurationError</code> on fatal issues (or returns None if OK).<br><br><strong>Responsibilities:</strong> central place for configuration invariants. Examples of checks: <code>port</code> in 1â€“65535, <code>workers &gt;= 1</code>, timeouts positive, required DSNs present when relevant features enabled (<code>export</code>/<code>db</code>), bucket names match expected pattern, <code>allowed_origins</code> entries valid URIs or <code>[]</code>. Behavior: if <code>strict</code> is None take <code>settings.strict</code>; when <code>strict==True</code> raise on missing critical fields; when <code>strict==False</code> emit structured warnings and set <code>settings._startup_degraded = True</code> (or return a <code>ValidationResult</code> object for tests). Timebox expensive external validations (like probing an S3 bucket) behind an explicit <code>--validate-external</code> flag. Provide mocks/tests for both fail-fast and degraded modes. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>get_secret_resolver(secrets_backend: str, **backend_opts) -&gt; Callable[[SecretRef], Awaitable[str]]</code></strong><br><br><strong>Signature:</strong> <code>get_secret_resolver(secrets_backend: str, **backend_opts) -&gt; Callable[[SecretRef], Awaitable[str]]</code> â€” returns an async-compatible resolver closure.<br><br><strong>Responsibilities:</strong> create a lazy resolver function that reveals secrets only when invoked (typically during startup handlers). Implementations: <code>env</code> (reads env var at reveal time), <code>noop</code> (for tests, raises if secret not provided), <code>aws_ssm</code>, <code>vault</code> (import heavy SDKs inside their branches). Requirements: (1) never log secrets in clear; (2) attach sensible caching and TTL (avoid repeated remote requests); (3) be resilient to transient errors (backoff, but surface failure to startup handlers which can decide strict vs degraded). Provide synchronous shim for code paths that expect sync call sites but prefer async where secret backends are networked. Unit tests: <code>noop</code>, <code>env</code>, and a fake backend that simulates transient failures. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>to_safe_dict(settings: Settings, redact_keys: Optional[Iterable[str]] = None) -&gt; Dict[str, Any]</code></strong><br><br><strong>Signature:</strong> <code>to_safe_dict(settings: Settings, redact_keys: Optional[Iterable[str]] = None) -&gt; Dict[str, Any]</code> â€” produce a serializable manifest safe for logs and CI.<br><br><strong>Responsibilities:</strong> return settings with secrets and sensitive keys redacted. Default redact list: <code>password</code>, <code>passwd</code>, <code>secret</code>, <code>token</code>, <code>key</code>, <code>ssn</code>, <code>db.dsn</code>, <code>s3_key</code>. Respect <code>SecretRef</code> markers: replace with <code>{&quot;__secret__&quot;: &quot;&lt;ref name&gt;&quot;}</code> or <code>&lt;REDACTED len=N&gt;</code>. Guarantee deterministic key ordering (canonical JSON) for fingerprinting. Include metadata: <code>env</code>, <code>service_name</code>, <code>applied_rule_version</code> (if present), and omit ephemeral or PII fields. Provide unit tests asserting no secret substrings leak into stringified output. Provide <code>dry_run</code> mode used by <code>build_test_settings</code>. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>runtime_fingerprint(settings: Settings, code_version: Optional[str] = None) -&gt; str</code></strong><br><br><strong>Signature:</strong> <code>runtime_fingerprint(settings: Settings, code_version: Optional[str] = None) -&gt; str</code> â€” stable short hash used for manifests and <code>app.state.runtime_fingerprint</code>.<br><br><strong>Responsibilities:</strong> compute a compact identifier (e.g., 12â€“16 hex chars) from canonicalized, non-secret parts of <code>Settings</code> plus an optional <code>code_version</code>. Implementation guidance: canonical JSON serialization of a filtered <code>to_safe_dict()</code> excluding runtime-only fields, then <code>sha256</code> truncated to N chars. Use this fingerprint in manifests, logs, and to correlate audits and exported bundles. Write unit tests to ensure changing only secret values does not change fingerprint. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>configure_logging_defaults(settings: Settings) -&gt; Dict[str, Any]</code></strong><br><br><strong>Signature:</strong> <code>configure_logging_defaults(settings: Settings) -&gt; Dict[str, Any]</code> â€” returns a <code>logging</code> config dict or attaches handlers when applied.<br><br><strong>Responsibilities:</strong> provide consistent, idempotent logging setup used by server bootstrap. Requirements: structured JSON lines in production, console-friendly human lines in dev, integration of <code>trace_id</code>/<code>request_id</code> fields, and a redaction filter that uses the same redaction core as <code>to_safe_dict</code>. Do not call <code>logging.basicConfig</code> on module import. Provide a <code>dry_run</code> memory handler used by tests (captures logs for assertions). Ensure handlers are tolerant of transient sink failures (do not block startup). Unit tests: assert redaction and trace fields present. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>get_uvicorn_config(settings: Settings) -&gt; Dict[str, Any]</code></strong><br><br><strong>Signature:</strong> <code>get_uvicorn_config(settings: Settings) -&gt; Dict[str, Any]</code> â€” translates server settings into uvicorn parameters.<br><br><strong>Responsibilities:</strong> encapsulate ASGI server options: <code>host</code>, <code>port</code>, <code>workers</code> (document CPU heuristic vs explicit override), <code>limit_concurrency</code>, <code>proxy_headers=True</code>, <code>loop=&quot;auto&quot;</code>, <code>log_config</code> referencing logging defaults, timeouts. Validate numeric ranges and return a compact dict suitable for <code>uvicorn.run(...)</code>. Tests: assert different <code>env</code> (dev/prod) produce expected defaults and that overrides are honored. Include docstring advising production deployments to prefer external process managers (systemd/k8s) and health probes. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>settings_cli_main(argv: Optional[List[str]] = None) -&gt; int</code></strong><br><br><strong>Signature:</strong> <code>settings_cli_main(argv: Optional[List[str]] = None) -&gt; int</code> â€” small CLI used for local dev and CI config checks.<br><br><strong>Responsibilities:</strong> parse args (<code>--env-file</code>, <code>--validate-external</code>, <code>--check</code>, <code>--reload</code>, <code>--dump-safe</code>), build settings (<code>load_settings_from_env</code> + optional <code>load_settings_from_file</code> + <code>merge_settings</code>), call <code>validate_settings</code>, print <code>to_safe_dict()</code> (redacted) when requested, and exit with status <code>0</code> on success or <code>&gt;0</code> on validation errors. Important: do not start network listeners during <code>--check</code>. Provide a <code>--dry-run</code> mode that uses <code>noop</code> secret resolver and <code>dry_run</code> logging for CI. Tests: <code>--check</code> success/failure codes and <code>--dump-safe</code> output snapshot. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>_coerce_types(value: Any, target_type: Type) -&gt; Any</code> (internal)</strong><br><br><strong>Signature:</strong> <code>_coerce_types(value: Any, target_type: Type) -&gt; Any</code> â€” deterministic conversion helper.<br><br><strong>Responsibilities:</strong> used by environment/file loaders to coerce strings into boolean/int/float/list/<code>timedelta</code>. Behavior: raise <code>ValueError</code> on ambiguous input rather than silently falling back. Examples: <code>&#x27;true&#x27;|&#x27;1&#x27;|&#x27;yes&#x27;</code> â†’ <code>True</code>, <code>&#x27;1,2,3&#x27;</code> â†’ <code>[&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;]</code> for <code>List[str]</code>, <code>&#x27;30s&#x27;</code> or <code>&#x27;30&#x27;</code> to <code>timedelta(seconds=30)</code> depending on convention. Unit tests should cover expected conversions and failure cases. Keep logic minimal to avoid surprising coercions. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong><code>_mask_secret(value: Any) -&gt; str</code> (internal)</strong><br><br><strong>Signature:</strong> <code>_mask_secret(value: Any) -&gt; str</code> â€” core redaction formatting rule.<br><br><strong>Responsibilities:</strong> produce canonical masked representation for secrets: e.g., <code>&quot;&lt;REDACTED len=12&gt;&quot;</code> or <code>{&quot;__secret__&quot;:&quot;ref-name&quot;}</code> for <code>SecretRef</code>. Centralize formatting to ensure logs, <code>to_safe_dict</code>, and CLI all produce identical masked strings. Tests: deterministic output length and idempotence. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong>Testing & CI recommendations</strong><br><br>â€” <code>tests/test_settings.py</code> should include unit tests for: env parsing (prefix handling), file parsing (json/yaml/env), coercions, <code>merge_settings</code> precedence, <code>to_safe_dict</code> redaction, <code>runtime_fingerprint</code> stability, and <code>get_uvicorn_config</code> mappings. <br>â€” Integration: a <code>ci/settings-check</code> job that runs <code>python -m myproject.settings_cli_main --check --env-file=.ci/test.env</code> and asserts exit code 0 for golden fixture and non-zero for broken fixtures. <br>â€” Security tests: automated grep of test logs and captured <code>to_safe_dict()</code> output to assert no raw secrets present. <br>â€” Mocks: provide <code>FakeSecretResolver</code> and <code>FakeStorage</code> fixtures to avoid network calls. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong>Operational guardrails & patterns</strong><br><br>â€” <strong>Lazy imports</strong>: import heavy SDKs (boto3/vault clients) only inside <code>get_secret_resolver</code> or other explicit factory functions. <br>â€” <strong>Idempotence</strong>: all public factory functions (<code>load_*</code>, <code>merge_*</code>, <code>get_secret_resolver</code>) must be side-effect free so unit tests can call them repeatedly. <br>â€” <strong>Secrets</strong>: represent secrets as <code>SecretRef</code>/<code>SecretHandle</code> and only <code>reveal()</code> during controlled startup handlers. Never include secrets in <code>repr()</code> or unit test snapshots. <br>â€” <strong>Fail-fast vs degraded</strong>: document which services are critical (DB, object store) and controlled via <code>settings.strict</code>. Use <code>settings._startup_degraded</code> or a <code>ValidationResult</code> to represent non-fatal degraded startup. <br>â€” <strong>Observability</strong>: emit metrics/structured logs for: <code>settings_loaded</code> durations, number of configured routes, <code>runtime_fingerprint</code>, and <code>applied_rule_version</code>. </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong>Common pitfalls & review checklist</strong><br><br>1. <strong>No network I/O on import</strong> â€” ensure all IO is behind explicit functions. <br>2. <strong>Secrets never logged</strong> â€” unit tests must assert no secret substrings. <br>3. <strong>Deterministic fingerprint</strong> â€” changing a secret must not change <code>runtime_fingerprint</code>. <br>4. <strong>Idempotent builders</strong> â€” repeated <code>load_settings_from_env()</code> and <code>Settings()</code> construction must be stable. <br>5. <strong>Clear strict semantics</strong> â€” document which fields cause startup to abort under <code>strict=True</code>. <br><br>Add a short <code>README</code> snippet adjacent to <code>settings.py</code> that documents common workflows (dev, CI, prod) and examples of how to provide secrets safely (SSM/Vault references). </td></tr><tr><td data-label="Technical Breakdown â€” settings.py"> <strong>Maintenance note</strong><br><br>If you add new extension clients (e.g., new notification sink), ensure the corresponding configuration fields are added under <code>Settings</code> and included in <code>to_safe_dict</code> redaction lists. Add unit tests that exercise <code>validate_settings</code> and the <code>settings_cli_main --check</code> path for the new fields. Keep <code>settings.py</code> focused â€” move any substantial parsing, migration, or secret-provider logic into small companion modules (e.g., <code>secrets/*.py</code>, <code>config/parsers.py</code>). </td></tr></tbody></table></div><div class="row-count">Rows: 18</div></div><div class="table-caption" id="Table4" data-table="Docu_0162_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” src/pph21_guard/app.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” src/pph21_guard/app.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong>File-level responsibilities</strong><br><br>This module is the single authoritative place that assembles the PPh21 ASGI application from configuration. Its responsibilities go beyond "wiring": it codifies operational expectations (idempotence, import-time safety), security posture (secrets handling, least-privilege defaults), observability contracts (trace-id propagation, structured logs), and lifecycle behavior (deterministic startup/shutdown with clear degraded-vs-fatal semantics). Keep this file small: every helper should be trivially testable and side-effect free at import time. Prefer composition over inheritance: factory functions return configured components rather than using global mutable state. Document the operational knobs (<code>settings.strict</code>, <code>settings.startup_mode</code>, feature flags) at the head of the file with explicit examples of how they change runtime behavior. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>create_app(settings: Settings) -&gt; FastAPI</code></strong><br><br><code>create_app</code> is the canonical entrypoint used by tests and the ASGI server. The factory must <em>only</em> perform synchronous, CPU-bound wiring and must not attempt network I/O. The function should: validate the <code>Settings</code> object surface area, guard against missing critical values (respecting <code>settings.strict</code>), and then call the smaller registration functions in a deterministic order: <code>configure_logging</code>, <code>init_extensions</code>, <code>register_middlewares</code>, <code>register_routes</code>, <code>configure_error_handlers</code>, <code>register_startup_handlers</code>, <code>register_shutdown_handlers</code>, and finally <code>start_background_workers</code> (if <code>startup_mode</code> allows in-process workers). It should attach a short, stable <code>runtime_fingerprint</code> (hash of non-secret settings and code version) to <code>app.state</code> for correlation. Avoid embedding secrets â€” instead attach accessor closures to <code>app.state</code> that fetch secrets from the secret provider lazily. Unit tests should construct a minimal "golden" <code>Settings</code> and assert <code>create_app</code> returns a <code>FastAPI</code> instance with expected <code>routes</code> and idempotent behavior when called repeatedly. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>register_middlewares(app, settings) -&gt; None</code></strong><br><br>Middleware ordering matters. This function is responsible for registering request-scoped cross-cutting concerns in a strictly-documented order: (1) inbound trace/request-id injection (normalize <code>traceparent</code>), (2) request parsing/size guards, (3) auth introspection shim / permission gate (fast path only), (4) structured request/response logging (non-blocking), (5) rate-limiter/quotas, (6) CORS (restrictive defaults), (7) GZip compression, then (8) a final error mapping middleware for last-resort transformation. Each middleware registration must be idempotent (check <code>app.state._registered_middleware</code>). For test harnesses, provide a <code>noop</code> or <code>stub</code> middleware set via <code>settings.middleware_mode</code>. Important implementation note: heavy operations (token validation, JWKS fetching) must be async and cached externally â€” the middleware only performs the verification step and must never block longer than a configured per-request timeout. When logging request bodies for debugging, ensure sampling and redaction rules apply. Include explicit unit tests that exercise header normalization, token hashing in logs, rate-limit enforcement, and that the registration is no-op on repeated calls. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>register_routes(app) -&gt; None</code></strong><br><br>Routes should be organized by surface: <code>api.v1.*</code> for public endpoints, <code>internal.*</code> for diagnostic/admin surfaces (mounted under <code>/internal</code> or a separate host), and <code>health</code> endpoints. This function must import router modules that are pure â€” router definitions only, no side-effectful connection attempts. When including routers conditionally (dev-only debug routes, experimental features), gate inclusion by explicit <code>settings</code> flags and document that these flags are disabled in production defaults. Enforce route-level dependency injection for auth scopes instead of ad-hoc checks inside handlers. Tests should assert that the OpenAPI schema generated from <code>create_app</code> matches expectations for the current environment (e.g., debug routes absent in production settings). Provide a short list of endpoints with example payloads in a docstring to aid reviewers. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>init_extensions(app, settings) -&gt; None</code></strong><br><br>This function registers client factories and lightweight adapter objects on <code>app.state</code> (for example <code>db_factory</code>, <code>cache_client_factory</code>, <code>s3_client_factory</code>, <code>mq_client_factory</code>, <code>telemetry_exporter</code>). It must <strong>not</strong> open persistent connections. Each extension entry should be a factory function or a wrapper object exposing explicit <code>connect()</code> and <code>close()</code> (or async <code>aclose()</code>) methods; those methods are invoked by startup/shutdown handlers. Maintain an <code>app.state._extensions</code> registry mapping names to objects to enable tests to inject fakes (<code>app.state._extensions[&#x27;db&#x27;] = FakeDb</code>). When configuration is incomplete and <code>settings.strict</code> is false, populate <code>app.state._extensions</code> with <code>NullClient</code> objects that raise on use and emit clear diagnostic messages. Unit tests should assert that <code>app.state</code> contains expected keys and that <code>startup</code> actually calls the <code>connect()</code> method on the provided factories. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>configure_logging(app, settings) -&gt; None</code></strong><br><br>Logging must be structured and idempotent. This function sets a global logging configuration (preferably JSON lines format in prod) and attaches a redaction filter that replaces configured sensitive keys with placeholders. The logger must integrate with trace context (W3C <code>traceparent</code>) and include <code>trace_id</code>, <code>request_id</code>, and <code>service</code> fields on each record. Prefer the <code>logging.getLogger(&quot;pph21&quot;)</code> namespaced logger rather than root logger changes. Support a <code>dry_run</code> mode for unit tests which configures a <code>MemoryHandler</code> capturing logs for assertions. Document how to extend the redaction list and include a unit test that ensures tokens/SSNs are redacted in a logged dictionary. In cloud environments where logs stream to a remote sink, ensure handler initialization is tolerant to transient network errors (backoff) and does not block app startup. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>register_startup_handlers(app) -&gt; None</code></strong><br><br>Attach concise, robust startup handlers. Each handler should be small, idempotent, and timeboxed via an <code>asyncio.wait_for</code> wrapper using configured per-service timeouts. Typical steps: 1) validate <code>app.state</code> has required factories, 2) sequentially call <code>connect()</code> on required clients (with per-client timeouts and circuit-breaker semantics), 3) optionally warm caches or precompile rule indices (if <code>settings.startup_mode == &quot;full&quot;</code>), 4) run light runtime invariants (schema migrations check, config checksum validation), and 5) emit a sanitized <code>startup</code> audit event. Handlers must respect <code>skip_external_checks</code> and <code>settings.strict</code> flags. If <code>strict</code> is true and a critical client fails, raise so ASGI server startup fails; otherwise log a degraded state and set <code>app.state._startup_degraded = True</code>. Provide tests that simulate partial failure and assert behavior under strict/lenient modes. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>register_shutdown_handlers(app) -&gt; None</code></strong><br><br>Shutdown handlers must close resources in reverse order of startup, flush telemetry, and ensure no blocking longer than <code>settings.shutdown_grace_period</code>. Typical sequence: 1) stop in-process workers (signal + wait with timeout), 2) flush audit buffers and telemetry exporters, 3) close MQ/write clients, 4) close DB connections, and 5) final checkpointing of important metrics/state (if applicable). Always catch and log exceptions â€” avoid re-raising during shutdown. Provide a <code>force</code> test hook to simulate unclean shutdown where some tasks are terminated; use integration tests that exercise TestClient's lifespan context to confirm the shutdown path executes. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>configure_error_handlers(app) -&gt; None</code></strong><br><br>Map domain-specific exceptions to stable error envelopes of the shape <code>{ &quot;code&quot;: &quot;&lt;machine&gt;&quot;, &quot;message&quot;: &quot;&lt;user-facing&gt;&quot;, &quot;trace_id&quot;: &quot;&lt;id&gt;&quot;, &quot;hint&quot;: &quot;&lt;optional actionable&gt;&quot; }</code>. Avoid embedding stack traces except when <code>settings.env == &quot;dev&quot;</code> and the requester is authenticated as a developer. Specific mappings: <code>pydantic.ValidationError -&gt; 400</code>, <code>AuthError -&gt; 401/403</code>, <code>NotFound -&gt; 404</code>, <code>RateLimitExceeded -&gt; 429</code>, all uncaught exceptions -> <code>500</code> with minimal message. The error handler must scrub PII from exception messages and avoid echoing request bodies. Add tests that raise each exception within a route to verify the HTTP status and sanitized body. Also add telemetry hooks to record error rate histograms and sample error traces for SRE. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>make_health_handler(app) -&gt; Callable</code></strong><br><br>Create two thin handlers backed by the same logic: <code>/health</code> (liveness/light checks) and <code>/deep-health</code> (readiness/deeper probes). The returned callable should collect results from <code>app.state.health_checks</code> (a list of callables each returning <code>{name, ok, ts, meta}</code>), compute an aggregate <code>status</code> (<code>ok|degraded|fail</code>), and include <code>runtime_fingerprint</code> and <code>applied_rule_version</code>. For <code>/health</code> avoid contacting databases or external services â€” return <code>ok</code> if the process is alive and essential subsystems are available. For <code>/deep-health</code> perform short async checks with timeouts and degrade if any required external service fails. Tests: mock <code>health_checks</code> entries and assert aggregate behavior. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>start_background_workers(app) -&gt; None</code></strong><br><br>Prefer external worker systems (Celery, RQ, cloud tasks) in production. When in-process workers are allowed (dev or single-replica mode), start asyncio tasks or threads with careful lifecycle management: attach cancellation tokens, register task supervision (watchdog), limit concurrency, and ensure durable work is acknowledged only after persistence to an external queue. Workers should be resilient: implement exponential backoff on transient errors, health probes, and a restart cap to avoid tight crash loops. Track workers in <code>app.state._workers</code> and ensure <code>shutdown</code> cancels/awaits them. Tests: integration tests that enqueue sample jobs on an in-memory queue consumed by the worker and assert completion. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>get_uvicorn_config(settings) -&gt; Dict[str,Any]</code></strong><br><br>Encapsulate ASGI server parameters derived from <code>Settings</code>. Key mappings: host/port, <code>workers</code> (document CPU heuristic vs environment override), <code>limit_concurrency</code>, <code>proxy_headers=True</code>, <code>loop=&quot;auto&quot;</code>, <code>log_config</code> referencing the same logger config, and sensible timeouts. Validate numeric ranges (ports 1â€“65535, worker count â‰¥1). Provide an override channel for process managers. Tests should verify expected config values for <code>dev</code> and <code>prod</code> fixture <code>Settings</code>. Include recommended production docstring recommending using an external process manager (systemd/k8s) with health/liveness probes wired to <code>/health</code> and <code>/deep-health</code>. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong><code>settings_cli_main(argv: Optional[List[str]] = None) -&gt; int</code></strong><br><br>A small CLI wrapper used in local development and CI checks. It must parse arguments for env files, validation-only modes, <code>--reload</code> dev flag, and <code>--check</code> exit-only validation mode. The function should: build settings (redacting secrets), run validations (schema rules, optional sample external checks if <code>--validate-external</code>), print a safe settings manifest (<code>to_safe_dict()</code>), and either exit with an appropriate code or call <code>uvicorn.run(app, **get_uvicorn_config(settings))</code>. Tests: run the CLI with <code>--check</code> and assert exit codes for valid and invalid configurations. Avoid starting network listeners in test runs unless explicitly requested. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong>Implementation patterns & guardrails</strong><br><br>â€” <strong>Lazy imports</strong>: SDKs and heavy dependencies must be imported inside the factory that builds them, not at module top-level. <br>â€” <strong>Idempotence</strong>: Every register function should check <code>app.state._registered</code> set. <br>â€” <strong>Secrets</strong>: Use <code>SecretHandle</code> or <code>SecretRef</code> pattern; <code>reveal()</code> only during startup and only when necessary. <br>â€” <strong>Observability</strong>: Record startup duration, number of routes, and number of loaded rules in metrics. <br>â€” <strong>Fail-fast vs degraded</strong>: <code>settings.strict</code> controls whether missing critical services abort startup. Document which services are critical vs optional. <br>â€” <strong>Testing hygiene</strong>: Provide <code>build_test_app</code> helper that returns a <code>create_app</code> with fakes injected and <code>dry_run</code> logging. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong>Recommended tests & CI checks</strong><br><br>1. <strong>Unit</strong>: helpers (UVicorn config, small pure helpers).<br>2. <strong>Integration (fast)</strong>: <code>TestClient</code> lifecycle confirming startup/shutdown run handlers and resources closed.<br>3. <strong>Middleware contract</strong>: header propagation, token redaction, rate-limit bursts simulated.<br>4. <strong>E2E smoke</strong>: containerized DB or sqlite, run minimal flow (ingest â†’ read).<br>5. <strong>Chaos</strong>: startup dependency failures toggling <code>strict</code> vs <code>lenient</code>.<br>6. <strong>Security</strong>: automated test to ensure no secrets leak into logs or <code>app.state</code>.<br>7. <strong>Performance</strong>: a lightweight benchmark for request logging overhead and median latency under typical middleware.<br><br>Automate these in CI gating. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong>Operational & security checklist</strong><br><br>Before flipping to production: ensure <code>strict=True</code>, CORS is locked to allowed origins, rate limiting of public endpoints is configured, telemetry destinations are verified (Sentry/OTel endpoints), logging redaction rules include all sensitive keys, and the CI pipeline runs the startup <code>--check</code> and sample external checks. Document runbooks for failover and degraded mode handling. Validate that <code>/health</code> and <code>/deep-health</code> responses differ by level of detail and that only <code>deep-health</code> requires strong auth if run in a shared environment. </td></tr><tr><td data-label="Technical Breakdown â€” src/pph21_guard/app.py"> <strong>Maintenance & developer notes</strong><br><br>â€” Avoid changing tokenizer/serialization semantics without migration. <br>â€” When adding a new extension client, add it to <code>app.state._extensions</code> and include connect/close semantics. <br>â€” If adding worker types, document whether they are safe for in-process execution or require externalization. <br>â€” Keep the file small; complex behaviors belong in small focused modules. Add <code># smoke</code> integration tests for any new external dependency wiring. </td></tr></tbody></table></div><div class="row-count">Rows: 17</div></div><div class="table-caption" id="Table5" data-table="Docu_0162_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” cli.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” cli.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr><tr><td data-label="Technical Breakdown â€” cli.py"></td></tr></tbody></table></div><div class="row-count">Rows: 21</div></div><div class="table-caption" id="Table6" data-table="Docu_0162_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” constants.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” constants.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>File-level responsibilities</strong><br><br>This module is the canonical, minimal, well-documented place for application-wide static values and their safe construction. It must <em>only</em> hold deterministic, side-effect-free expressions and tiny pure helpers for deriving constant values (no I/O, no network, no DB). Responsibilities: (1) declare stable constants (feature flags, default timeouts, canonical filenames, export MIME types, common cache keys, well-known route fragments, rule versions); (2) provide a single, clearly-named public accessor surface (e.g., <code>get()</code> / <code>as_dict()</code> or a read-only <code>CONSTANTS</code> object); (3) offer robust validation and environment-overrides that are explicit, non-surprising, and secure (no automatic secret injection); (4) record source-of-truth metadata (value origin: built-in default / env / override file) for observability; (5) provide deprecation shims and migration mapping for renamed constants; (6) remain tiny â€” complex transformations belong in a different module. Keep module top-level imports minimal and lazy if required by derived helpers. Unit-test every constant that encodes policy or algorithmic thresholds. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Naming & grouping conventions</strong><br><br>Group constants by logical surface and prefix group names with an uppercase noun: <code>EXPORT_*</code>, <code>INGEST_*</code>, <code>RULES_*</code>, <code>AUDIT_*</code>, <code>RETENTION_*</code>, <code>HTTP_*</code>. Each group should appear in a small contiguous block with a one-line comment describing where the value is authoritative. Avoid ambiguous names (<code>TIMEOUT</code> â†’ <code>EXPORT_UPLOAD_TIMEOUT_MS</code>). Represent durations using typed units (seconds, milliseconds) with suffixes in the name and an accompanying comment specifying units. Use small immutable containers (<code>frozenset</code>, <code>tuple</code>) for collections. Provide an explicit <code>__all__</code> exposing only intended symbols. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>DEFAULTS: Mapping[str, Any]</code> (or <code>*_DEFAULTS</code> group)</strong><br><br>Purpose: centralize builtin defaults that can be overridden by environment or runtime flags. Keep these values conservative and secure (e.g., small rate limits, strict CORS defaults). Document each entry with rationale, expected units, and the risk if changed. Unit-tests: assert that <code>DEFAULTS</code> contains required keys and that each default falls within an allowed numeric range. Do NOT store secrets here. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>ENV_OVERLIDABLE_KEYS: Set[str]</code></strong><br><br>Purpose: enumeration of constants that may be safely overridden by environment variables or config loader. This list must <em>explicitly</em> exclude secrets and cryptographic material. Implementation note: when building overrides, only consider keys in this whitelist to avoid accidental override of sensitive constants or structural names. Unit-tests: assert this set is a subset of <code>DEFAULTS.keys()</code> and that each listed key has explicit documentation. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>load_from_env(env: Mapping[str,str]) -&gt; Dict[str,Any]</code></strong><br><br>Pure helper that applies a <em>strict</em>, opt-in mapping from environment variables to constant names. Responsibilities: parse typed values (ints, floats, duration strings like <code>30s</code>), validate against allowed ranges, record the override source in metadata, and return a <em>new</em> dict merging defaults with overrides (do not mutate module-level defaults). Must: reject unknown keys, coerce safely, and raise descriptive <code>ValueError</code> on malformed inputs. Security: never accept inline JSON that could embed secrets; keep parsing simple. Tests: fuzz malformed values, out-of-range boundaries, and type mismatches. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>resolve_paths(base_dir: str, *relative_paths) -&gt; Tuple[str,...]</code></strong><br><br>Small pure utility for canonicalizing path constants (export directories, temp staging). Behavior: join with <code>os.path.abspath</code> and normalize separators. Must be deterministic and not perform filesystem checks. If the result must be used for file IO elsewhere, callers are responsible for permission and existence checks. Tests: relative/absolute inputs, trailing slash normalization, Windows/Posix separators (if cross-platform support required). </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>compile_patterns(patterns: Iterable[str]) -&gt; Tuple[Pattern,...]</code></strong><br><br>Pure helper to precompile regular expressions used as constants (filename validation, allowed MIME patterns). Responsibilities: compile with explicit flags (e.g., <code>re.ASCII</code> / <code>re.UNICODE</code>), validate that patterns are anchored if appropriate, and raise on insecure patterns (e.g., catastrophic backtracking risk if pattern is user-provided). Keep precompilation cost at module import small â€” prefer lazy compilation or compile-on-first-use for large lists. Tests: anchoring checks, invalid regex error handling, cross-Python-versions sanity. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>freeze_constants(mapping: Mapping[str,Any]) -&gt; types.MappingProxyType</code></strong><br><br>Purpose: produce an immutable, runtime-safe view of computed constants to prevent accidental mutation by other modules. Requirements: shallow freeze is acceptable for simple values; for nested structures, produce recursively immutable equivalents (<code>tuple</code>/<code>frozenset</code>/<code>MappingProxyType</code>). Attach provenance metadata in a separate read-only mapping (never embed it directly inside frozen values). Tests: attempt mutation should raise, identity/difference checks for nested containers. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>validate_constants(constants: Mapping[str,Any]) -&gt; None</code></strong><br><br>Pure validator that enforces internal invariants and operational constraints (positive timeouts, allowed port ranges, whitelisted MIME types, mutually-exclusive flags). Should raise <code>ValueError</code> with exact failure messages to aid CI diagnostics. The function must be safe to call at import time for fast-failing misconfigurations in CI, but be opt-in in runtime startup to avoid surprising side-effects. Tests: assert all invariants, include negative tests for each rule. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>get_constant(name: str, *, default: Any = _MISSING) -&gt; Any</code></strong><br><br>Small read accessor that centralizes lookup semantics and deprecation warnings. Behavior: return value if present, else either return <code>default</code> or raise <code>KeyError</code> if <code>_MISSING</code>. When a constant is deprecated, emit a single-shot <code>warnings.warn(..., DeprecationWarning)</code> with replacement guidance. Avoid dynamic computation inside this accessor â€” keep it a thin guard. Tests: missing-key behavior, deprecation emission (cap warning to once per process). </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>as_dict(constants: Mapping[str,Any], redact: Optional[Iterable[str]] = None) -&gt; Dict[str,Any]</code></strong><br><br>Utility to serialize constants for diagnostics and <code>--check</code> CLI commands. Must redact keys explicitly listed (never guess). Never include secrets or secret-derived values; the docstring must state that secrets live elsewhere and are not safe to show. The function should produce a stable alphabetical ordering for deterministic snapshots in tests/CI. Tests: redaction correctness, stable ordering. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong><code>apply_deprecation_map(constants: Dict[str,Any], mapping: Mapping[str,str]) -&gt; Dict[str,Any]</code></strong><br><br>Helper to support renames/migrations of constant names. Behavior: for each <code>(old -&gt; new)</code> pair, if <code>old</code> exists and <code>new</code> does not, copy the value and emit a <code>DeprecationWarning</code> advising timeline and replacement; if both exist, prefer <code>new</code> and emit a <code>UserWarning</code> about ignoring <code>old</code>. Keep this idempotent. Tests: combinations of present/absent keys and repeated calls. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>File-level metadata: <code>__version__</code>, <code>__generated_by__</code>, <code>SOURCE_MAP</code></strong><br><br>Store a tiny metadata object describing the constants module version or generation timestamp (useful when constants are produced by a build). Keep metadata non-sensitive and immutable. Use this in diagnostic endpoints (<code>/health</code> deep probe) to correlate applied rule or generator versions. Tests: presence and format checks. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Observability hooks</strong><br><br>Expose <em>read-only</em> metadata about constant origins: <code>{name: {&quot;value&quot;: v, &quot;origin&quot;: &quot;default|env|file&quot;, &quot;source&quot;: &quot;ENV_KEY or filename&quot;}}</code>. This must be produced by pure helpers and not perform I/O. Use this structure in debug CLI (<code>--dump-constants</code>) and CI checks. Ensure telemetry systems only accept sanitized exports. Tests: metadata completeness and redaction when required. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Security & secrets guardrail</strong><br><br>Absolute rule: constants.py must not contain plaintext secrets, private keys, passwords, tokens, or secret-loading logic. If a value must be secret-derived (HMAC key, signing key), constants.py should only contain a <code>SECRET_REF_&lt;NAME&gt;</code> sentinel and a documented accessor elsewhere that fetches secrets securely during startup. Add a unit test that scans the constants file for suspicious substrings (e.g., <code>-----BEGIN</code>, <code>AKIA</code>, long base64 blobs) to catch accidental secret commits. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Performance & import-time cost</strong><br><br>Make import extremely cheap. Defer expensive operations (pattern compilation for large lists, heavy validation) behind lazy helpers or callables. Keep the top-level module size small (<200 lines of constant declarations + short helpers). For very large static tables use compressed / generated vendored files loaded by explicit functions. Provide a test asserting import time under a configured threshold in CI. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Idempotence & deterministic behavior</strong><br><br>All functions must be idempotent and deterministic given the same inputs. Avoid reading <code>os.environ</code> directly at import time â€” require callers to pass in the env mapping for <code>load_from_env</code> to make behavior testable. Document the deterministic fingerprint procedure (hash of sorted non-secret constants + module <code>__version__</code>). </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Recommended tests & CI checks</strong><br><br>1. <strong>Unit</strong>: validation invariants, <code>load_from_env</code> parsing & failure modes, <code>apply_deprecation_map</code> semantics, redaction of <code>as_dict</code>.<br>2. <strong>Safety</strong>: static-scan test that rejects secret-like blobs in source. <br>3. <strong>Determinism</strong>: snapshot test of <code>as_dict()</code> output for golden fixture. <br>4. <strong>Import perf</strong>: lightweight test ensuring import < X ms. <br>5. <strong>Deprecation window</strong>: test that deprecation warnings are emitted and bounded (once). Automate these in CI gating. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Implementation patterns & guardrails</strong><br><br>â€” <strong>Pure functions</strong>: all helpers must be pure given explicit inputs. <br>â€” <strong>No I/O at import</strong>: disallow file/network/DB operations. <br>â€” <strong>Explicit env mapping</strong>: <code>load_from_env(env)</code> instead of reading <code>os.environ</code>. <br>â€” <strong>Typed values</strong>: parse and validate types early; prefer small, explicit conversion helpers (<code>_parse_duration</code>, <code>_parse_int</code>) tested separately. <br>â€” <strong>Single source of truth</strong>: encourage other modules to <code>from constants import CONSTANTS</code> (frozen) rather than importing many names to make future refactors safer. <br>â€” <strong>Backward compatibility</strong>: add <code>DEPRECATIONS</code> map and tests verifying replacement guidance. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Operational & security checklist before production</strong><br><br>â€” Confirm no secrets are present. <br>â€” Ensure all defaults are conservative and documented. <br>â€” Ensure <code>ENV_OVERLIDABLE_KEYS</code> reflects policy. <br>â€” Add a CI rule to fail on accidental secret patterns. <br>â€” Ensure <code>as_dict(redact=...)</code> has redaction coverage for any value that could indirectly reveal secrets. <br>â€” If constants influence external protocols (export formats, filenames), include checksum/versioning to avoid cross-version incompatibilities. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Maintenance & developer notes</strong><br><br>â€” When adding a new constant: add it to <code>DEFAULTS</code>, document rationale, add to <code>ENV_OVERLIDABLE_KEYS</code> only if safe, add unit tests. <br>â€” When renaming: add <code>DEPRECATIONS</code> entry rather than deleting; keep old name returning a wrapped <code>DeprecationWarning</code> for at least one release. <br>â€” For large enumerations (e.g., MIME types), consider generating from a canonical source file and expose via an explicit loader function, not at import time. <br>â€” Keep the module < 1 file of focused responsibility â€” move growth to <code>constants_impl.py</code> and expose a small facade in <code>constants.py</code>. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Example runtime usage guidance</strong><br><br>â€” For startup checks, call <code>consts = freeze_constants(load_from_env(os.environ)); validate_constants(consts);</code> and pass the frozen mapping to other subsystems. <br>â€” For CLI <code>--check</code>, call <code>as_dict(consts, redact=REDACT_KEYS)</code> to produce a deterministic manifest. <br>â€” For metrics/health: export only <code>__version__</code> and non-sensitive thresholds; do not dump full constants in production logs. </td></tr><tr><td data-label="Technical Breakdown â€” constants.py"> <strong>Edge cases & failure modes to defend</strong><br><br>â€” Malformed numeric env overrides (raise explicit <code>ValueError</code>). <br>â€” Conflicting overrides (both old and new names present) â€” prefer explicit <code>new</code> and warn. <br>â€” Large lists causing import slowness â€” convert to lazy loader. <br>â€” Regex patterns that cause catastrophic backtracking â€” validate or compile lazily with safe flags. <br>â€” Accidental secret commits â€” CI static-scan fails fast. </td></tr></tbody></table></div><div class="row-count">Rows: 23</div></div><div class="table-caption" id="Table7" data-table="Docu_0162_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” file_ops.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” file_ops.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>File-level responsibilities</strong><br><br>The file_ops module is the single authoritative place for safe, testable filesystem and object-store interactions used by the ingestion/export pipeline. Its responsibilities are: canonicalizing filesystem operations (reads/writes, moves, deletes), providing atomic write/publish primitives, computing content-identifiers (checksums), offering small, composable retry-and-timeout wrappers for I/O, and exposing light-weight concurrency primitives (file locks) for cross-process coordination. Keep this module pure and small: functions must not perform heavy business logic, must avoid network I/O at import time, and must return deterministic results for the same inputs. All public functions should be documented with preconditions, side-effects, and observable invariants (atomicity, idempotency, permissions). Prefer composition (small helpers) so higher-level orchestration (snapshots, uploads, manifests) composes these primitives. Unit-test every function under normal, transient-error, and permission-failure scenarios. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>ensure_parent_dir(path, mode=0o755, exist_ok=True) -> None</strong><br><br>Ensure the parent directory of path exists with safe defaults and explicit permission handling. Must: validate that path is not empty, create parents with os.makedirs(parents=True, exist_ok=exist_ok), apply os.chmod if mode differs, and avoid following symlinks when creating directories. Failures to create due to permissions should raise a clear, typed exception (e.g., FileOpsPermissionError) so callers can differentiate transient vs fatal. Idempotent: calling repeatedly has no additional side effects. Tests: simulate missing parents, concurrent creators (race), and permission-denied. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>atomic_write(path, data_bytes, tmp_suffix='.tmp', mode=0o644, fsync=True) -> None</strong><br><br>Write arbitrary bytes to path atomically. Contract: write to a sibling temporary file (same directory), optionally fsync file and directory (if fsync=True) to ensure durability, then rename (os.replace) to final path. Guarantee: either the pre-existing file remains unchanged or the final file is fully written. Must preserve umask/permissions according to provided mode. Must avoid cross-filesystem rename (raise a clear error if tmp on different mount). Failure handling: on exception, attempt to remove temp file and propagate a typed error. Tests: interrupted write (simulate exception before rename), concurrent readers (verify no partial files visible), fsync disabled path behavior. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>write_text(path, text, encoding='utf-8', atomic=True, </strong>kwargs) -> None**<br><br>High-level convenience over atomic_write. Converts text to bytes with encoding and delegates to atomic_write when atomic is True; otherwise performs a direct open(..., 'w', encoding=...). Do not swallow UnicodeEncodeErrors â€” let caller handle or wrap with a descriptive error. Preserve newline semantics when required (explicit param). Tests: large text, different encodings, atomic vs non-atomic paths. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>read_text(path, encoding='utf-8', errors='strict') -> str</strong><br><br>Read full file as text. Validate path exists and is a regular file (no directories). Provide an option to stream large files via a separate streaming helper. For small files this returns str; for large files callers should use read_stream to limit memory. Behavior on missing file: raise FileNotFoundError. Tests: binary content read with strict vs replace error policies. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>write_bytes(path, data, atomic=True, mode=0o644, fsync=True) -> None</strong><br><br>Binary counterpart to write_text. Must ensure atomic semantics via atomic_write if requested. If data is an iterator/generator, the function should use an incremental write path (writing chunks to temp file) to avoid loading whole payload into memory. Tests: streaming generator, zero-byte files, concurrent readers. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>read_bytes(path, chunk_size=8192) -> bytes</strong><br><br>Read whole file as bytes (for small files). For large files prefer read_stream. Be explicit about memory usage in docstring. Tests: binary files, empty files. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>read_stream(path, chunk_size=8192) -> Iterator[bytes]</strong><br><br>Generator yielding file chunks. Safe for large files and network upload pipelines. Must open file with 'rb' and yield until exhaustion, closing the file in finally. Consumers must be reminded to exhaust the iterator or explicitly close the generator. Tests: streaming interruption, chunk-size correctness. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>list_files(directory, pattern=None, recursive=False, follow_symlinks=False) -> Iterator[pathlib.Path]</strong><br><br>Enumerate files under directory with optional glob pattern and recursion. Normalizes results to pathlib.Path objects, sorts deterministically (lexicographic) before yielding to ensure stable test behavior. Do not follow symlinks by default. Errors: if directory missing, either raise or return empty depending on strict flag (documented). Tests: nested directories, symlink loops, pattern matching. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>move_file(src, dst, overwrite=False, atomic=True) -> None</strong><br><br>Move/rename a file. Preferred path: attempt os.replace for atomic rename when src and dst are on the same filesystem. If filesystems differ and atomic=True, implement copy+fsync+os.replace into dst directory (i.e., stage tmp then os.replace) to emulate atomic publish; document that cross-device moves are not truly atomic across processes. If overwrite=False and dst exists, raise FileExistsError. Ensure metadata (permissions + mtime) are preserved when requested. Tests: cross-filesystem move, overwrite False/True, concurrent readers. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>copy_file(src, dst, follow_symlinks=False, preserve_mode=True) -> None</strong><br><br>Copy file contents reliably. Use shutil.copyfileobj with configurable buffer sizes; optionally preserve file mode and mtime (shutil.copystat). Do not leak file descriptors. If source is missing, raise FileNotFoundError. Tests: large file copy, permission errors, symlink handling. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>remove_file(path, missing_ok=True) -> None</strong><br><br>Remove file or empty directory (document behavior clearly â€” prefer separate remove_dir). If missing_ok is True, silently return when path does not exist. On permission errors or non-empty directory, raise a clear error. Provide a safe path-check to avoid removing root or user-homedir by accident (reject dangerous patterns like / or empty path). Tests: missing_ok behavior, permission-denied. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>compute_hash(path, algo='sha256', chunk_size=65536) -> hexstr</strong><br><br>Return cryptographic hash of file contents using a streaming read. Must not load entire file into memory. Use hashlib with selectable algorithms and normalize output to lowercase hex. This function is critical for idempotency (snapshot content-hash). Document and test for stable outputs and for very large files; assert identical results across repeated reads. Tests: known vectors, small and large files, different algorithms. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>get_metadata(path) -> dict</strong><br><br>Return file metadata: size, mtime (RFC 3339 or unix epoch), mode (octal), uid/gid, is_symlink, checksum optional (controlled by parameter). Keep metadata structure stable across versions (add new keys only in backward-compatible way). Do not include PII in metadata. Tests: correctness on different platforms (POSIX/Windows) where possible. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>set_permissions(path, mode, *, recursive=False) -> None</strong><br><br>Set permissions safely. Validate mode is an int and within reasonable ranges. When recursive=True, walk the tree and set permissions only on files (and optionally directories) with try/except to collect errors rather than fail fast. Document behavior on Windows where POSIX modes may not apply. Tests: permission changes, failure collection. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>file_lock(path, timeout=None) -> contextmanager</strong><br><br>Cross-process advisory lock implemented either with fcntl (POSIX) or portalocker/Win32 equivalents. The context manager acquires the lock on a dedicated .lock file associated with path and yields control; must support blocking and timeout semantics. The implementation must be re-entrant-safe for the same process (document scope) or provide a non-reentrant warning. On failing to acquire within timeout raise FileLockTimeout. Tests: concurrent lock contention, timeouts, lock release on exceptions. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>retry_with_backoff(fn, retries=3, initial=0.2, max_interval=10.0, on_retry=None, retry_on=Exception) -> wrapper</strong><br><br>Small, deterministic retry wrapper used by higher-level I/O ops that perform transient network or filesystem operations. Behavior must be configurable (jitter, backoff factor, max_retries). Do not swallow fatal exceptions (provide a way to opt-out for certain exception types). Log each retry at debug level and surface aggregated error including the number of attempts. Tests: transient-fail then success, permanent failure does not loop, jitter stability. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>stream_to_store(path_or_stream, store_client_factory, bucket, key, *, chunked=False, retries=3, timeout_seconds=60) -> upload_result</strong><br><br>High-level helper to upload a file or stream to an object store. Important design guardrails: the module must not create a network client at import time â€” accept a store_client_factory (callable that returns a client) or a client object. The function should: 1) compute a content-hash (if required), 2) support multipart/chunked uploads with resumability (if store supports), 3) perform retries with backoff on transient errors, 4) optionally fsync the source file before upload to ensure durability if upload is triggered right after write, 5) write to a staging key and then rename/publish atomically (if store supports copy/rename), and 6) return a stable metadata object (url, etag, checksum). Never log secrets; redact sensitive metadata. Tests: simulate transient network errors, ensure staging â†’ publish atomicity, verify idempotency via checksum. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>download_to_path(url_or_client, dest_path, *, atomic=True, timeout_seconds=60, retries=3) -> None</strong><br><br>Download from an external object store or URL into a local path. Accept either a client+key pair or a signed URL. Stream to a temporary file then atomically move into place. Validate content-length when available and compute checksum if requested. On partial downloads, leave temp file for resume or remove temp if resumability not supported (configurable). Tests: interrupted download, content-length mismatch, checksum verification. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>save_snapshot(obj, path, serializer='json', compress=False, checksum=True, metadata_path=None) -> dict</strong><br><br>High-level utility that serializes an in-memory snapshot (canonical record set) to disk and optionally writes metadata alongside it. Responsibilities: choose serializer deterministically (stable JSON with sorted keys, reproducible floats), write atomically, optional compression (gzip) without changing the computed logical checksum (i.e., checksum should be of the uncompressed canonical bytes unless caller requests otherwise), and write a small metadata file including checksum, size, serialization version, and generator_version. Return a metadata dict used by enqueuing and idempotency checks. Tests: canonical reproducibility, compression on/off parity, metadata correctness. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>publish_bundle_atomic(staging_path, public_path) -> None</strong><br><br>Atomic publish primitive that moves a prepared staging directory/tree to a public path. Implement as rename/os.replace when on same filesystem; if cross-filesystem, copy-then-atomic-rename and validate checksums of all files before committing. Provide a safety check that ensures the public path is not partially replaced â€” implement a two-phase commit: create new name, validate, move final name into expected location, and optionally set an atomic symlink swap. Failures must leave either old bundle intact or a clean rollback path. Tests: interrupted publish, partial validation failure, concurrent publishers. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>validate_safe_path(path, base_dir=None) -> pathlib.Path</strong><br><br>Utility to canonicalize and validate that path is contained in base_dir, preventing directory traversal attacks. Resolve symlinks only after checking that the resolved path is still within allowed base. Reject suspicious inputs and raise a clear ValidationError. Tests: .., symlink escape attempts. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>helpers: open_tempfile_in_dir(dir, prefix='tmp', delete_on_close=False) -> NamedTemporaryFile</strong><br><br>Small helper to create temp files in the same directory as the target to ensure atomic rename compatibility. Document platform differences and resource cleanup semantics. Tests: temp file lifetime, behavior under umask. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Observability & logging expectations</strong><br><br>All functions must emit structured debug-level events (operation, path, duration_ms, bytes, result) without including sensitive data or secrets. Error logs should include sanitized path (no user IDs) and a retained correlation id when available. Instrument critical path durations (write, upload, download, compute_hash) as metrics. Provide a dry-run mode for tests where operations are simulated and metrics/logs are captured. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Concurrency, atomicity & idempotency rules</strong><br><br>â€” Favor write-then-rename for atomicity. <br>â€” Use content-hash based idempotency (compute_hash) to deduplicate snapshots before enqueue. <br>â€” Protect shared artifacts with file_lock where cross-process races are possible. <br>â€” Never assume filesystem guarantees across network mounts; document these boundaries. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Error model & exception classes</strong><br><br>Provide a small hierarchy: FileOpsError(base), FileOpsPermissionError, FileLockTimeout, FileNotFoundError (re-export), AtomicWriteError, UploadError, ValidationError. Functions should raise typed exceptions, not raw OSError, to make upstream error handling precise. Map common errno values to specific exceptions when re-raising. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Security considerations</strong><br><br>â€” Never log file contents or secrets. <br>â€” Set secure defaults for file permissions (mode 0o640/0o644 as appropriate). <br>â€” When writing files that will be published publicly, explicitly set public mode only at publish time. <br>â€” Validate user-supplied paths to prevent traversal. <br>â€” For uploads, require callers to provide a client factory; the module must not hardcode credentials. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Testing matrix & recommendations</strong><br><br>Create unit tests (fast) that use temporary directories and a fake store client to simulate network behavior. Integration tests should run against a local object-store emulator (minio) to validate multipart uploads, staging â†’ publish, and resumption. Add chaos tests for partial failures and validate rollback behavior. Include property tests for compute_hash (idempotence) and atomic_write (durability under simulated crashes). Mock fsync to surface behavior on platforms that do not support it. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Documentation & versioning</strong><br><br>Document each public function with clear signature, side-effects, expected exceptions, and platform notes. Maintain stable API: add new optional parameters only with backward-compatible defaults. Keep a brief "safety checklist" at the top of the file: do not import network SDKs at module scope, prefer factories, and never mutate global state. </td></tr><tr><td data-label="Technical Breakdown â€” file_ops.py"> <strong>Recommended tests to add to CI</strong><br><br>1) atomic_write durability: simulate crash before/after rename. <br>2) compute_hash vs known vectors. <br>3) file_lock contention across processes. <br>4) cross-filesystem move and publish behavior. <br>5) stream_to_store retry/backoff with injected transient errors. <br>6) path validation / directory traversal attack vectors. </td></tr></tbody></table></div><div class="row-count">Rows: 30</div></div><div class="table-caption" id="Table8" data-table="Docu_0162_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” paths.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” paths.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” paths.py"> <strong>File-level responsibilities</strong><br><br>This module centralizes filesystem and object-path logic used across ingestion, snapshotting, export, and worker pipelines. Its responsibilities are: (1) canonicalizing paths and URIs so callers need not duplicate normalization logic; (2) enforcing sandboxing / base-root constraints to prevent directory traversal and accidental writes outside permitted stores; (3) providing small, side-effect-light helpers for path composition, validation, and checksumming that are safe to call at import time; (4) providing a small surface of IO-primitive wrappers (atomic write, safe remove) that encapsulate best-practice semantics (atomicity, fsync/flush when required, temp-file staging, durable rename when publishing); and (5) translating between local filesystem paths and object-store keys/URIs. Keep this file minimal and purely deterministic: heavy IO (network/object-store calls) must live in <code>file_ops.py</code> or adapter modules; <code>paths.py</code> should only compute strings, test for local FS state, and perform local, short-lived filesystem operations. Document configuration knobs at the top (e.g. <code>BASE_ROOT</code>, <code>TMP_SUBDIR</code>, <code>EXPORT_STAGING_SUFFIX</code>, <code>CHECKSUM_ALGO</code>) and note how they affect safety and deployment (k8s, shared volumes, object store staging). Unit tests should target every pure helper and exercise the sandboxing rules thoroughly. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>normalize_path(p: str) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Return a canonical, OS-normalized absolute path suitable for comparisons and storage. Normalize separators, collapse <code>.</code>/<code>..</code>, remove duplicate slashes, and on Windows normalize drive-letter casing and UNC path nuances if the code runs there.<br><br><strong>Inputs / outputs:</strong> accepts any user-provided path-like string; returns an absolute, normalized string (no trailing slash except root). Should never return <code>None</code> â€” raise <code>ValueError</code> on invalid input types.<br><br><strong>Safety & security:</strong> must <em>not</em> resolve symlinks (do not call <code>realpath</code>) unless caller explicitly requests <code>resolve_symlinks=True</code>. Default behavior avoids following symlinks to prevent bypass of sandbox checks. If symlink resolution is offered, document that it can expose resources outside <code>BASE_ROOT</code> and must be gated behind explicit, reviewed code paths.<br><br><strong>Edge cases:</strong> empty path, <code>~</code> expansion, Windows drive relative paths; resolve <code>~</code> to homedir only when explicitly allowed by higher-level callers. For reproducibility, do not include process-dependent temporary directories unless explicitly requested.<br><br><strong>Tests:</strong> assert idempotence (<code>normalize_path(normalize_path(x)) == normalize_path(x)</code>), relative-to-absolute conversions, and behavior with duplicate separators and <code>..</code>. Include cross-platform fixtures or skip Windows-specific assertions on non-Windows test runners. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>safe_join(base: str, *parts: str) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Compose <code>base</code> with <code>parts</code> and assert the resulting path remains inside <code>base</code> after normalization (prevent directory traversal). Return an absolute normalized path inside <code>base</code> or raise a well-defined <code>SecurityError</code> / <code>ValueError</code> if the result would escape the <code>base</code>.<br><br><strong>Semantics:</strong> Perform strict canonical normalization <strong>without</strong> resolving symlinks by default. Compare path prefixes using normalized path strings and a clear boundary rule (e.g., append a trailing separator when comparing prefixes) to avoid false positives (<code>/data/evil</code> vs <code>/data/ev</code>). Optionally accept an allowlist of subdirectories or a <code>follow_symlinks</code> boolean.<br><br><strong>Failure modes:</strong> On escape attempts (e.g., <code>../../etc/passwd</code>), raise an explicit exception and log the offending candidate path and normalized base (redact any usernames or secrets). Do not auto-create missing directories â€” caller decides whether to create.<br><br><strong>Tests:</strong> cases that would escape base using <code>..</code>, absolute <code>parts</code>, leading slashes, symlink-like names. Tests should assert the error message is informative and that repeated calls are idempotent. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>is_within_base(candidate: str, base: str) -&gt; bool</code></strong><br><br><strong>Responsibility:</strong> Pure predicate used by higher layers and security checks. Must return <code>True</code> only when <code>candidate</code> (after normalization, not resolving symlinks) is a descendant of <code>base</code> or equals it. Keep it deterministic and cheap.<br><br><strong>Notes:</strong> Avoid <code>os.path.commonpath</code> pitfalls by normalizing both inputs to absolute paths and enforcing trailing separator rules or path-component comparisons. Document the difference between this function and symlink-following checks. Unit tests should include tricky cases (same prefix different component names, unicode in filenames). </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>relpath_from_base(path: str, base: str) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Return the normalized relative path from <code>base</code> to <code>path</code>. If <code>path</code> is not under <code>base</code>, raise <code>ValueError</code> (do not silently return an absolute path). This function supports manifest generation and stable keys.<br><br><strong>Behavioral guarantees:</strong> When <code>path == base</code>, return <code>.</code> or empty string depending on project convention â€” document which and keep consistent. Prefer returning a component-only path (no leading slash). Tests should assert invertibility with <code>safe_join(base, relpath_from_base(p, base)) == normalize_path(p)</code>. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>join_uri(*parts: str) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Compose object-store or http URIs safely (handles trailing slashes, URL-encoding segments when needed, and enforces no accidental <code>//</code> that changes semantics). Use for building <code>s3://bucket/prefix/...</code> or <code>gs://</code> keys and for canonicalizing internal object-store keys. <em>Do not</em> perform network I/O. Support both <code>scheme://host</code> and plain key composition.<br><br><strong>Security notes:</strong> When constructing signed or published URIs, ensure secrets are not embedded; provide guidance to attach signer wrappers in <code>file_ops.py</code> or the adapter layer.<br><br><strong>Tests:</strong> assert stable output for mixed trailing/leading slash inputs and preservation of percent-encoded segments. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>path_to_object_key(base_prefix: str, path: str, checksum: Optional[str]=None) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Convert a filesystem <code>path</code> (typically a relpath from project root or snapshot root) into a canonical object-store key under <code>base_prefix</code>. Optionally append checksum or version suffix for content-addressed storage. This function codifies the naming schema for snapshots, manifests, and exports so that other modules can rely on stable key patterns.<br><br><strong>Contract:</strong> Pure transformer â€” no IO. Document the exact template (e.g., <code>{base_prefix}/{applied_rule_version}/{relpath}{:checksum-suffix}</code>) and any allowed characters. If checksum is provided, include a stable separator (e.g., <code>--h=</code>) to enable easy parsing. Provide a companion <code>parse_object_key</code> to reverse the mapping. Unit tests must validate round-trip <code>parse_object_key(path_to_object_key(...)) -&gt; original pieces</code>. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>parse_object_key(key: str) -&gt; Dict[str,str]</code></strong><br><br><strong>Responsibility:</strong> Reverse <code>path_to_object_key</code>. Extract known metadata (prefix, applied rule version, relpath, checksum) using deterministic parsing rules rather than guessed token splitting. Return a structured dict with clearly documented optional/required fields. Validate and raise <code>ValueError</code> on malformed keys. Tests should include historical/legacy keys to ensure backward-compatible parsing when possible. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>atomic_write(path: str, data: bytes|str, fsync: bool = False, mode: int = 0o644) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Provide a safe, cross-platform atomic file writer: write to a temp file in the same directory, <code>fsync</code> the file (and directory optionally) if <code>fsync=True</code>, then perform an atomic <code>os.replace</code>/<code>rename</code> to the final path. Create parent directories atomically when necessary (with race-safe checks). Ensure correct file permissions and ownership semantics and avoid exposing partial files to readers. Document when <code>fsync</code> is required (critical metadata like manifests) and the performance cost.<br><br><strong>Error handling:</strong> On write or fsync failures attempt to clean up temp files but never swallow IO exceptions silently. If replacement fails due to permission or cross-device rename, perform a safe fallback (copy-and-rename) only after logging the precise fallback reason. Provide clear exceptions (<code>AtomicWriteError</code>) to let callers decide retry policy. Tests: simulate interrupted writes (using temp files and mocked exceptions), cross-device rename errors, and concurrent writers. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>read_text_file(path: str, encoding: str = &quot;utf-8&quot;) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Small wrapper to read text files with standardized error semantics: raise <code>FileNotFoundError</code> if missing, wrap parsing/decoding errors with <code>UnicodeDecodeError</code> preserved, and optionally return default values when caller provides <code>default=</code> (explicit). Keep it tiny and testable. Avoid implicit binary handling; provide <code>read_bytes</code> for binary consumers. Tests should validate expected exceptions for missing and truncated files. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>iter_files(root: str, pattern: Optional[str]=None, recursive: bool=True) -&gt; Iterator[str]</code></strong><br><br><strong>Responsibility:</strong> Deterministically yield normalized absolute paths under <code>root</code>. When <code>pattern</code> is provided, match only component or name-level patterns (document glob or regex semantics). Always enforce that yielded paths are within <code>root</code> using <code>is_within_base</code>. Order results lexicographically for stable processing in pipelines (important for reproducible snapshots and checksums). Do not follow symlinks unless explicitly requested. Tests: ensure stable ordering, correct pattern filtering, and security checks for symlinked directories that point outside <code>root</code>. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>compute_checksum(path: str, algo: str = &quot;sha256&quot;, chunk_size: int = 64*1024) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Compute a hex checksum for a file using a specified algorithm. This function is pure IO but small and used widely for deduplication and manifest generation. Read in fixed-size chunks to bound memory use. If the file is large, ensure the implementation is streaming-friendly and returns a consistent hex digest; if <code>path</code> is a directory, raise <code>IsADirectoryError</code>. Expose <code>chunk_size</code> for tests but default to production-safe sizes. Document algorithm support and provide a clear exception (<code>UnsupportedAlgorithmError</code>) for unknown algorithms. Tests: verify stable digests for canonical fixture files and that chunk-size changes do not affect digest. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>safe_makedirs(path: str, exist_ok: bool = True, mode: int = 0o755) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Create directories in a race-tolerant manner. Wrap <code>os.makedirs</code> but handle race conditions (another process creating the dir concurrently). When <code>exist_ok</code> is False raise if path exists and is a file. Ensure final directory permissions match requested mode where possible; if underlying FS or umask prevents exact match, log the delta at debug level but do not fail. For shared NFS volumes, warn in docs about potential inode-level races and advise higher-level locks for critical operations. Tests: concurrent creation simulation, permission errors. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>safe_remove(path: str, ignore_missing: bool = True, recursive: bool = False) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Remove files or directories with controlled semantics. For files remove atomically; for directories optionally perform recursive removal but only after an explicit confirmation flag to avoid accidental mass deletion. If <code>ignore_missing</code> is True, succeed silently when the path does not exist. Always prevent removal of the configured <code>BASE_ROOT</code> or other protected roots â€” raise if attempted. Log removals at debug level and emit an audit event via <code>app.state</code> or the auditor layer for deletions of exported artifacts. Tests: deletion of files, missing files, directory deletion with nested files. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>rotate_path(path: str, keep: int = 5, pattern: str = &quot;{path}.{idx}&quot;) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Maintain a small rotation/backups for path-based artifacts (logs, snapshots) using a deterministic naming pattern. Implement rotation by renaming older versions (<code>N-1</code> -> <code>N</code>) and removing the oldest beyond <code>keep</code>. Use atomic renames and ensure concurrency safety via an optional lock file. Never rotate into <code>BASE_ROOT</code> incorrectly â€” validate both source and target. Tests: ensure rotation maintains <code>keep</code> items and recovers gracefully when intermediate entries are missing. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>sanitize_filename(name: str, allow_unicode: bool = False, max_length: int = 255) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Produce a safe filename by removing or replacing path separators and control characters. Truncate to <code>max_length</code> preserving file extension if present. This helper is used before writing user-derived filenames to disk or object stores. Document normalization decisions (replace spaces with <code>_</code> or <code>-</code>) and ensure the result is reversible where necessary only via a stored manifest mapping. Tests should validate behavior with unicode, long names, and names containing path traversal sequences. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>manifest_path_for(snapshot_relpath: str, version: str, staging: bool = True) -&gt; str</code></strong><br><br><strong>Responsibility:</strong> Centralize naming for manifests associated with snapshots/exports. Return a stable path (local or object-key) that encodes <code>snapshot_relpath</code> and <code>version</code>. If <code>staging</code> is True, produce a staging path (e.g., suffix or separate staging prefix) used to publish atomically later. Document invariants so other modules can detect staging vs final manifests. Tests must assert stable, predictable naming and parseability by manifest parsing functions. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>parse_manifest_path(path: str) -&gt; Dict[str,str]</code></strong><br><br><strong>Responsibility:</strong> Reverse <code>manifest_path_for</code>. Validate required components (version, snapshot id) and raise on malformed inputs. Provide helpful error messages that include the offending path but redact any secrets if present. Useful for ingestion of third-party bundles and reconciliation logic. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>lock_for_path(path: str, timeout: Optional[float]=None) -&gt; contextmanager</code></strong><br><br><strong>Responsibility:</strong> Provide a small file-locking context manager used by higher-level operations needing mutual exclusion when writing/rotating/exporting artifacts. Prefer non-blocking advisory locks when supported (fcntl on UNIX) and fall back to a lockfile + atomic creation with TTL metadata on filesystems without fcntl semantics (clustered locks). Always document cross-process semantics and failure modes: advisory locks provide best-effort guarantees only and should not be used for security-critical invariants. The context manager should release reliably on exit and on signals where possible. Tests: simulate concurrent lock attempts with threads/processes and assert timeout behavior. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>validate_export_path(path: str, allowed_bases: Iterable[str]) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Ensure that an export target path lies under one of the configured <code>allowed_bases</code> and that it meets naming conventions (no control chars, allowed suffixes). Raise <code>ValidationError</code> with clear remediation hints on failure. This is a deployment safety guard to prevent accidental publishes to arbitrary locations. Tests should include attempts to point at <code>/</code> or cloud bucket keys not in the allowlist. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>archive_staging_to_public(staging_path: str, public_path: str, atomic_publish: bool = True) -&gt; None</code></strong><br><br><strong>Responsibility (small local-only variant):</strong> Provide a deterministic local publish step for staged bundles: validate both paths, compute checksums (or rely on provided manifest), and perform an atomic rename (or copy+rename) to <code>public_path</code>. If <code>atomic_publish</code> is False, perform a best-effort copy and document race conditions. For cross-device publishes, fallback to copy+fsync. This helper should be light â€” heavy object-store publishes belong in <code>file_ops.py</code> / adapters. Log publish duration and bytes transferred for observability.<br><br><strong>Error handling:</strong> On checksum mismatch raise <code>IntegrityError</code> and revert partial publishes when possible. Tests should simulate cross-device rename errors and checksum mismatches. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>path_from_uri(uri: str, allowed_schemes: Optional[Iterable[str]] = None) -&gt; Tuple[str,str]</code></strong><br><br><strong>Responsibility:</strong> Parse a URI into <code>(scheme, path_or_key)</code>, normalize the key portion for object-store schemes, and validate scheme allowlist. Where scheme is absent, treat as local filesystem path. This small utility centralizes URI parsing rules and percent-decoding behavior. Tests: s3://, gs://, file://, http(s) edge cases, odd percent-encoding, and illegal schemes. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong><code>ensure_parent_dir(path: str) -&gt; None</code></strong><br><br><strong>Responsibility:</strong> Ensure the parent directory of <code>path</code> exists using <code>safe_makedirs</code> and race-tolerant semantics. Use before <code>atomic_write</code> or when callers intend to create a file at a new location. Keep idempotence guarantees and test concurrency. </td></tr><tr><td data-label="Technical Breakdown â€” paths.py"> <strong>Implementation patterns & guardrails (module-level)</strong><br><br>â€” <strong>Pure vs IO:</strong> Keep pure path transforms separate from functions that perform disk IO. Prefer <code>compute_*</code>, <code>parse_*</code>, <code>join_*</code> for pure helpers and suffix <code>_fs</code> or place in <code>file_ops.py</code> for heavier FS/adapters functions. <br>â€” <strong>Idempotence:</strong> All registration-style helpers (e.g., naming templates) are pure and idempotent. IO helpers are safe-to-retry where feasible and document when they are NOT retryable. <br>â€” <strong>Security:</strong> Enforce sandboxing by default (no automatic <code>~</code> expansion, no symlink following). Provide explicit flags for callers that need to deviate, and mark those call sites for review. Avoid exposing secrets in path strings â€” if a path embeds secrets, callers should pass an opaque handle instead. <br>â€” <strong>Observability:</strong> Functions that perform operations with measurable cost (compute_checksum, atomic_write, archive_staging_to_public) should optionally accept a <code>logger</code> or emit structured debug/info events via the app's telemetry layer (duration, bytes, error). Keep logging redaction in caller code (e.g., <code>log.py</code>). <br>â€” <strong>Performance:</strong> For heavy directories or large-file operations prefer streaming and chunking. Document complexity: <code>compute_checksum</code> O(n) in file size, <code>iter_files</code> O(n) in number of files; callers should avoid calling these in tight loops. <br>â€” <strong>Cross-platform:</strong> Avoid Windows/UNIX specific behavior unless guarded. Document behavior differences and provide CI matrix tests where appropriate. <br>â€” <strong>Testing hygiene:</strong> Provide small fixtures (temporary directories with known layouts) and property tests (round-trips, invariants). Provide golden keys for object-key naming to detect accidental template changes. <br><br><strong>Recommended tests & CI checks</strong><br><br>1. <strong>Unit:</strong> pure helpers (normalize_path, safe_join, join_uri, parse_object_key).<br>2. <strong>Integration (fast):</strong> atomic_write + compute_checksum round-trip in a tmpfs-backed directory to validate fsync semantics. <br>3. <strong>Security:</strong> attempts to escape base with <code>..</code>, absolute parts, symlinks (both followed and unfollowed).<br>4. <strong>Race:</strong> concurrent <code>safe_makedirs</code>, <code>atomic_write</code>, and <code>rotate_path</code> operations simulated with threads/processes. <br>5. <strong>Cross-platform:</strong> run a subset of path tests on Windows runners if project supports Windows. <br>6. <strong>Backward-compatibility:</strong> parsing tests that include legacy object-key formats. <br><br><strong>Maintenance & developer notes</strong><br><br>â€” When adding new naming conventions, add a <code>parse_*</code> counterpart and include migration notes in the module docstring. <br>â€” Prefer conservative changes: renaming templates must update manifest/version rotation and include migration code for old keys. <br>â€” If adding a function that follows symlinks or accesses networked filesystems, clearly mark it and move it to <code>file_ops.py</code> or an adapter with explicit integration tests. <br>â€” Keep the module focused on deterministic, testable, and reviewable functions only; complex publish logic, retries, and networked stores belong to adapter layers. </td></tr></tbody></table></div><div class="row-count">Rows: 24</div></div><div class="table-caption" id="Table9" data-table="Docu_0162_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” imports.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” imports.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>File-level responsibilities</strong><br><br><code>imports.py</code> centralizes robust, auditable import utilities for the project: thin wrappers around <code>importlib</code>/<code>importlib.metadata</code> that provide consistent behavior for lazy imports, optional dependency handling, plugin/entry-point discovery, helpful error messages, deterministic ordering, import-time telemetry, and test-friendly hooks. The module must <em>never</em> perform network I/O at import time, must minimise import-time side effects, and must be safe to call from library import-time code. Keep surface area small and well-documented: prefer a few small, well-tested helpers rather than many ad-hoc import snippets scattered through the codebase. Expose a compact public API (e.g. <code>import_module</code>, <code>import_from_string</code>, <code>import_optional</code>, <code>require_package</code>, <code>load_plugins</code>) and keep experimental helpers private (leading underscore). Document intended semantics (strict vs lenient), thread-safety, and recommended usage patterns at the top of the file. </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Design constraints & global guards</strong><br><br>â€” Avoid top-level heavy imports; import optional SDKs inside helper functions.<br>â€” Provide an environment/config switch (e.g. <code>IMPORTS_STRICT</code> or <code>settings.imports.strict</code>) that controls whether missing optional packages raise or return <code>None</code>/fallback.<br>â€” Maintain an import cache / registry and protect it with a reentrant lock when mutations are possible in multi-threaded contexts.<br>â€” Record lightweight observability (counts of missing optional imports, plugin discovery duration) but keep telemetry opt-in and non-blocking.<br>â€” Fail fast with helpful messages when a required package is missing; for optional packages log or return <code>None</code>.                                                                                                                                                                                                                                                                                                           </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>import_module(name: str) -&gt; types.ModuleType</code></strong><br><br>Canonical thin wrapper over <code>importlib.import_module</code>. Responsibilities: validate <code>name</code> is a non-empty string, convert relative names to absolute if a <code>package</code> parameter is later added, call <code>importlib.import_module(name)</code>, and return the module. On error, raise a <code>ModuleNotFoundError</code> with an enhanced message that includes the attempted name, <code>sys.path</code> hint (short), and a suggestion for <code>pip install &lt;package&gt;</code> when the missing name matches a well-known mapping. Must be idempotent and not mutate <code>sys.modules</code> beyond normal import semantics. Add unit tests that assert the returned module is <code>sys.modules[name]</code> and that an obviously-missing name yields the enhanced error message.                                                                                                                                                                                                                                                         </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>import_from_string(dotted_path: str) -&gt; Any</code></strong><br><br>Resolve a dotted path (module.sub:attr or module.sub.Class) into the referenced object. Responsibilities: parse the path robustly, try progressively shorter module imports and attribute access, give precise <code>ImportError</code> messages (whether module import failed vs attribute missing), and avoid swallowing the original traceback â€” attach the cause but rephrase a developer-friendly hint. Edge-cases: names that collide with packages or modules, attributes that are properties vs callables. Tests: valid function, class and constant resolution; missing attribute vs missing module distinction; ensure side-effect-free in attribute access (only attribute lookup, not execution).                                                                                                                                                                                                                                                                         </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>import_optional(name: str, fallback: Optional[Any] = None, hint: Optional[str] = None) -&gt; Any</code></strong><br><br>Safely import optional dependencies. Responsibilities: attempt to import <code>name</code>, return the module/object if present; if missing, return <code>fallback</code> (default <code>None</code>) and emit a single logged warning with a structured payload (<code>package</code>, <code>reason</code>, <code>hint</code>) and increment a missing-optional metric. If <code>IMPORTS_STRICT</code> is true then escalate to raising a <code>MissingOptionalDependencyError</code> with a clear message and suggested install command. Ensure this function is cheap and can be called repeatedly (use memoization). Tests: present and missing package behavior, <code>fallback</code> correctness, memoization behavior, and that logs contain the expected structured fields.                                                                                                                                                                                                                                        </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>require_package(name: str, min_version: Optional[str] = None, reason: Optional[str] = None) -&gt; None</code></strong><br><br>Assert a required dependency is available and meets version constraints. Responsibilities: import the module, check its <code>__version__</code> (or use <code>importlib.metadata.version()</code>), and if version is insufficient raise a <code>RuntimeError</code> with explicit remediation steps. If the module is absent, raise <code>ModuleNotFoundError</code> with install hints. Avoid import-time side effects (do not import heavyweight subsystems just to read <code>__version__</code> â€” prefer <code>importlib.metadata</code> when available). Tests: missing package raises, older version raises with message containing both required and found versions, passing version is no-op.                                                                                                                                                                                                                                                                              </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>lazy_import(name: str, attr: Optional[str] = None) -&gt; Proxy</code></strong><br><br>Create a proxy object that defers the actual import until first attribute access or call. Responsibilities: provide a drop-in replacement that preserves <code>__name__</code>, <code>__doc__</code> where practical, raises the same ImportError if the underlying import fails on first access (not at proxy creation), and supports <code>isinstance</code>/<code>issubclass</code> checks only when possible (document limitations). Use <code>types.ModuleType</code> subclassing or a small proxy class; ensure <code>repr()</code> helps debugging (<code>&lt;LazyImport &#x27;pkgname&#x27;-&gt;None&gt;</code>). Use for expensive optional SDKs used deep in code paths. Tests: attribute access triggers import exactly once; exceptions propagate at access time; proxies are pickle-safe only if underlying module is pickleable (document this).                                                                                                                                                                                             </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>load_plugins(entry_point_group: str, validate: Optional[Callable]=None) -&gt; Dict[str, Any]</code></strong><br><br>Discover and load plugins via entry points (PEP 517/518 style). Responsibilities: use <code>importlib.metadata.entry_points()</code> (with fallback to <code>pkg_resources</code> on older Python) to list candidates, deterministically sort them (by name and package) to ensure reproducible load order, attempt to load each entry point with error handling that isolates failing plugins (log structured failure with traceback, do not abort the whole discovery), optionally validate returned objects via <code>validate</code>, and return a nameâ†’callable/object mapping for successful entries. Security: treat plugins as untrusted code â€” do not call plugin methods at discovery time beyond what is necessary to import, and document that plugin discovery runs arbitrary install-time code. Tests: success path, failing plugin logged but discovery continues, deterministic ordering, and validate hook exercised.                        </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>find_spec(name: str) -&gt; Optional[importlib.machinery.ModuleSpec]</code></strong><br><br>Wrapper for <code>importlib.util.find_spec</code> that standardizes behavior across Python versions and returns <code>None</code> for missing specs. Use this when checking availability without importing. Responsibilities: return <code>ModuleSpec</code> for the name or <code>None</code>, and translate exceptions into <code>None</code>. Tests: present module returns spec with loader, missing module returns <code>None</code>.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>import_with_fallbacks(candidates: Iterable[str], fallback: Optional[Any] = None) -&gt; Tuple[str, Any]</code></strong><br><br>Try a list of candidate module names in order, returning the first successful import as <code>(name, module)</code>. Responsibilities: avoid raising on intermediate failures (log them at debug), support a <code>preferred</code> param, memoize the chosen winner for this process so repeated lookups are cheap, and on total failure either return <code>(None, fallback)</code> or raise depending on <code>IMPORTS_STRICT</code>. Tests: first-present candidate chosen, memoization confirmed, debug logs appear for failed attempts.                                                                                                                                                                                                                                                                                                                                                                                                                  </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>resolve_name(name: str, package: Optional[str] = None) -&gt; str</code></strong><br><br>Resolve relative dotted names to absolute module paths similar to <code>pkgutil.resolve_name</code> behavior. Responsibilities: validate and convert names like <code>..module</code> into absolute dotted paths given <code>package</code>, raise helpful <code>ValueError</code> when resolution is impossible, and avoid importing. Tests: relative-to-absolute resolution cases, invalid resolution raises with clear message.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>get_module_version(module_or_name: Union[str, ModuleType]) -&gt; Optional[str]</code></strong><br><br>Return the version string for a module or distribution: prefer <code>importlib.metadata.version(distribution_name)</code> where possible, fall back to <code>module.__version__</code> if present, and return <code>None</code> if unknown. Be tolerant of <code>DistributionNotFound</code> and other metadata lookup failures. Tests: return correct version for known module, return <code>None</code> for stdlib modules with no version metadata.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>format_import_error(err: Exception, attempted_name: str, hint: Optional[str] = None) -&gt; str</code></strong><br><br>Construct single-line and multi-line user-friendly diagnostics wrapping an underlying <code>ImportError</code>/<code>ModuleNotFoundError</code>. Responsibilities: include attempted name, short <code>sys.path</code> snippet or virtualenv detection hint, pip install command suggestion when a mapping from package name to distribution name is known, and optional hint text. Use this helper consistently across other functions so error messages are uniform and testable. Tests: format contains key fields and includes hint when supplied.                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>safe_reload(module: ModuleType) -&gt; ModuleType</code></strong><br><br>Reload a module in a safe, explicit manner. Responsibilities: call <code>importlib.reload</code> but document and test that reloading may not reinitialise state cleanly; use a lock around reloads to be thread-safe; emit a warning in logs that reloading is a risky operation and recommend process restart in production. Tests: reload a simple module that exposes a mutable global and assert the new attribute value.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>is_available(name: str) -&gt; bool</code></strong><br><br>Non-importing availability check. Responsibilities: use <code>find_spec(name)</code> to check presence without importing; return <code>True</code> for packages and modules resolvable on <code>sys.path</code>, <code>False</code> otherwise. Use in runtime guards before attempting heavy imports. Tests: known present/absent modules.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong><code>clear_import_cache(names: Optional[Iterable[str]] = None) -&gt; None</code></strong><br><br>Utility to remove modules from <code>sys.modules</code> and any module-level memo caches used by this file â€” useful for tests. Responsibilities: accept <code>None</code> to clear the module's own memoization map, or a list of module names to remove from <code>sys.modules</code> (and close resources if possible). Must only be used in test or controlled contexts â€” document this clearly. Tests: after clearing, <code>import_module</code> reimports fresh module object.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Observability & logging</strong><br><br>â€” All public helpers must log structured messages (<code>logger.debug/info/warning/error</code>) rather than ad-hoc prints. Include fields: <code>package</code>, <code>attempted_name</code>, <code>reason</code>, <code>strict_mode</code>, and <code>duration_ms</code> for plugin discovery. <br>â€” Emit a single counter metric for â€œoptional import missedâ€ and a histogram for plugin discovery duration if metrics plumbing is available; make metrics optional and non-blocking.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Thread-safety & idempotence</strong><br><br>â€” Use a <code>threading.RLock</code> to protect any mutable caches or state. <br>â€” All register/discovery operations must be idempotent and safe to call repeatedly; maintain an <code>_initialized</code> sentinel as needed. <br>â€” Document known non-idempotent operations (module reload) and discourage their use except in tests.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Security considerations</strong><br><br>â€” When loading plugins from entry points treat them as arbitrary code â€” never run plugin callbacks at discovery time. <br>â€” Validate plugin metadata and (optionally) enforce a whitelist or signature verification for high-security deployments. <br>â€” Avoid constructing import paths from untrusted user input; if unavoidable, validate against an allow-list and normalise paths.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Testing guidance</strong><br><br>â€” Unit tests should fake <code>sys.modules</code> and <code>importlib</code> behaviours using monkeypatch fixtures (e.g., replace <code>importlib.import_module</code>, patch <code>importlib.metadata.entry_points</code>). <br>â€” Add integration tests that exercise real optional imports using lightweight stub packages in <code>tests/fixtures</code> so you can validate <code>import_optional</code> behaviour without network installs. <br>â€” CI checks: ensure deterministic plugin discovery order (repeat tests across Python versions), assert messages include install hints, and run a lint that flags any top-level imports of heavy dependencies.                                                                                                                                                                                                                                                                                                                                                                                                        </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Error classes & public API</strong><br><br>â€” Define small, explicit exceptions (<code>MissingOptionalDependencyError</code>, <code>PluginLoadError</code>) for callers to catch. <br>â€” Keep the public API minimal and stable: <code>import_module</code>, <code>import_from_string</code>, <code>import_optional</code>, <code>require_package</code>, <code>load_plugins</code>, <code>lazy_import</code>, <code>is_available</code>. Mark helpers as private with leading <code>_</code> if not intended for external use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Maintenance notes & migration</strong><br><br>â€” When adding new functions: preserve backwards-compatibility of error types and messages for a minor version. <br>â€” If switching discovery backend (e.g., <code>pkg_resources</code> â†’ <code>importlib.metadata</code>), keep a compatibility layer and add fallback logic; add deprecation warnings for older behaviour. <br>â€” Document when code in this module must be updated if packaging metadata conventions change (PEP changes).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Recommended tests & CI checks</strong><br><br>1. <strong>Unit</strong>: each functionâ€™s success and failure modes (including formatted messages).<br>2. <strong>Integration (fast)</strong>: plugin discovery against <code>tests/fixtures</code> entry points; optional import telemetry. <br>3. <strong>Determinism</strong>: repeated runs of <code>load_plugins</code> produce identical ordering. <br>4. <strong>Security</strong>: test that plugin exceptions do not prevent discovery of other plugins and that invalid entry points are logged, not executed. <br>5. <strong>Contract</strong>: ensure no heavy SDK is imported at module import time (enforce via a small static check or a <code>pytest</code> fixture).                                                                                                                                                                                                                                                                                                                                                                                                        </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Example usage patterns (documented, not implemented here)</strong><br><br>â€” Use <code>import_optional</code> near call sites for rarely-used SDKs.<br>â€” Use <code>lazy_import</code> to bundle optional heavy dependencies into objects returned by factory functions so they only load when used.<br>â€” Use <code>load_plugins</code> at application startup (not import time) and cache results on <code>app.state</code> or <code>settings</code> so the rest of the system depends on a deterministic plugin map.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr><tr><td data-label="Technical Breakdown â€” imports.py"> <strong>Final guardrails</strong><br><br>â€” Keep the module small and well-tested. Avoid reimplementing <code>importlib</code> functionality unnecessarily; prefer small, composable wrappers that add (a) clearer error messages, (b) optional/strict modes, (c) deterministic plugin discovery, and (d) test helpers. Every new advisory string or install hint must be unit-tested to avoid regressions in CLI or CI parsing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             </td></tr></tbody></table></div><div class="row-count">Rows: 25</div></div><div class="table-caption" id="Table10" data-table="Docu_0162_10" style="margin-top:2mm;margin-left:3mm;"><strong>Table 10</strong></div>
<div class="table-wrapper" data-table-id="table-10"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” log.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” log.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” log.py"> <strong>File-level responsibilities</strong><br><br>This module centralizes logging, redaction, and telemetry-shipping configuration for the application. It provides a single, testable surface for: (1) establishing structured (JSON) logging and human-friendly fallback formats, (2) applying consistent redaction rules and sampling, (3) attaching request/trace context (W3C <code>traceparent</code> / <code>trace_id</code> / <code>request_id</code>) to records, (4) integrating with external error/telemetry systems (Sentry/OTel) via small, isolated hooks, and (5) offering test-friendly primitives (in-memory handlers, <code>dry_run</code> mode). Keep this file narrow: every non-trivial helper should be independently unit-testable and import-safe (no network I/O at module import). Top-level variables should be minimal and immutable; heavy SDK imports must be lazy. Document cfg knobs (<code>settings.log_level</code>, <code>settings.log_format</code>, <code>settings.log_redact_keys</code>, <code>settings.dry_run</code>) at the head of the file. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>configure_logging(settings: Settings) -&gt; None</code></strong><br><br>Primary entrypoint used at process startup. Responsibilities: validate <code>settings</code> (ensure <code>log_format</code>/<code>log_level</code> acceptable), set global/loggers config idempotently, attach platform adapters (uvicorn/gunicorn) and register diagnostic handlers. Must not open network connections. Steps: (1) early-validate redaction keys and sample rate, (2) build formatter(s) via <code>_build_formatter</code>, (3) create and attach top-level handlers (console, file optional, memory for tests when <code>settings.dry_run</code>), (4) add global filters (<code>_make_redaction_filter</code>, <code>RequestIdFilter</code>, <code>TraceContextFilter</code>), (5) call <code>configure_external_integrations(settings)</code> to register but not initialize shipping clients. Idempotence: check and set <code>logging.getLogger().manager.__dict__[&#x27;_configured_by_app&#x27;]</code> or <code>app_state._logging_configured</code> to avoid reconfiguration. Unit tests should assert the global logger has the expected handlers and that repeated calls do not duplicate handlers. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>_build_formatter(settings) -&gt; logging.Formatter</code></strong><br><br>Factory that returns a <code>Formatter</code> instance appropriate for <code>settings.log_format</code> (<code>json | console | compact</code>). Keep heavy dependencies (ujson/rapidjson) lazy-imported inside this function. The JSON formatter must include a stable schema: <code>ts, level, logger, msg, service, trace_id, request_id, pid, tid, extra</code> and should accept <code>serialize_time=True</code> to canonicalize timestamps (ISO 8601 with ms). When <code>settings.env == &quot;dev&quot;</code> provide a human-friendly pretty printer. Unit tests should verify all expected fields appear and that the formatter gracefully handles non-serializable objects by falling back to <code>repr</code>. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>_make_redaction_filter(redact_keys: Iterable[str], placeholder: str = &quot;[REDACTED]&quot;) -&gt; logging.Filter</code></strong><br><br>Produces an idempotent <code>Filter</code> that scans record <code>msg</code> and <code>record.__dict__[&#x27;extra&#x27;]</code> (or <code>record.__dict__</code> entries) and replaces sensitive values whose keys match any pattern in <code>redact_keys</code> (support exact keys, dotted paths, and simple regex). Design decisions: operate on <code>record</code> <em>before</em> formatters run; do not mutate the original input objects (clone shallow maps), redact lazily to avoid memory copying overhead for non-PII records. Ensure the filter does not drop records. Tests: keys redacted in nested maps, sample large objects to ensure acceptable performance, and confirm placeholder length does not reveal secret length. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>RequestIdFilter(request_id_header: str = &quot;X-Request-Id&quot;) -&gt; logging.Filter</code></strong><br><br>A request-scoped filter that ensures <code>request_id</code> is set on every log record. API: if context-local storage (contextvars) contains <code>request_id</code>, use it; otherwise, generate a stable fallback (UUIDv4). Do <strong>not</strong> create race conditions across threads â€” use <code>contextvars.ContextVar</code>. The filter must be cheap and idempotent. Tests: concurrent worker simulation preserves unique request ids per context, records missing <code>request_id</code> get auto-filled, filter is no-op when a valid <code>request_id</code> already present. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>TraceContextFilter() -&gt; logging.Filter</code></strong><br><br>Adds <code>trace_id</code>/<code>span_id</code> to records by reading a trace context provider (preferably from <code>opentelemetry.trace.get_current_span()</code> or a lightweight shim if OTel not installed). Behavior: if OTel present attach <code>trace_id</code> hex; otherwise rely on W3C header propagated into contextvars. Must be lazy with imports and tolerant to missing instrumentation. Tests: verify <code>trace_id</code> added when OTel present and omitted (or empty) when not available. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>configure_external_integrations(settings: Settings) -&gt; None</code></strong><br><br>Register adapters for Sentry/OTel/third-party logging sinks. <strong>Important</strong>: do not open connections or initialize exporters at import/configure time; instead register factories on <code>app.state</code> or return a registry of <code>init()</code> and <code>shutdown()</code> callables. The function should: validate DSNs and sampling rates, add an error capture hook that calls <code>capture_exception()</code> (below), and add any required event processors (to attach <code>trace_id</code>). Tests: ensure that with <code>settings.dry_run</code> no network clients are created and that <code>init()</code>/<code>close()</code> are idempotent. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>capture_exception(exc: BaseException, *, extra: Optional[Dict]=None, level: str = &quot;error&quot;) -&gt; None</code></strong><br><br>Thin wrapper used by the app to synchronously log an exception and forward it to configured external systems conditionally. Behavior: log the exception via <code>logger.exception()</code> (structured fields), apply sampling/throttling (configurable), and, if <code>settings.send_errors</code> is true, enqueue the exception to the telemetry integrator but <strong>do not</strong> block the caller â€” prefer background/async handoff patterns (task queue, background thread) implemented elsewhere. The function must redact any PII from exception metadata and attach <code>trace_id</code>/<code>request_id</code>. Tests: confirm redaction, sampling, and that a failing telemetry client does not raise. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>get_logger(name: Optional[str] = None) -&gt; logging.Logger</code></strong><br><br>Convenience accessor that returns a configured logger; ensures name normalization (e.g., <code>app.&lt;module&gt;</code> prefix), applies module-level log level overrides from <code>settings.log_overrides</code>, and attaches a <code>LoggerAdapter</code> that always injects <code>service</code> and environment tags into <code>extra</code>. Keep the function pure and fast. Tests: verify that returned logger emits structured records containing <code>service</code>, honors overrides, and is safe to call during tests (uses memory handler when <code>dry_run</code>). </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>add_memory_handler_for_tests(capacity: int = 1000) -&gt; logging.handlers.MemoryHandler</code></strong><br><br>Creates and attaches an in-memory handler useful for unit tests. It must be toggled by <code>settings.dry_run</code> or a <code>TESTING</code> flag and expose a simple API to pull/reset captured records. This handler should use a lightweight formatter identical to production JSON so tests validate shape. Tests: ensure no file/socket I/O, captured records count matches expectations, and handler is removed/cleared between tests to avoid leak. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>integrate_uvicorn_logging()</code></strong><br><br>Adapter that aligns <code>uvicorn</code>/<code>gunicorn</code> logging into the app's structured logging pipeline. Responsibilities: (1) capture and re-route uvicorn loggers (<code>uvicorn.access</code>, <code>uvicorn.error</code>) to the application logger using a specially tuned formatter (access logs should include <code>method</code>, <code>path</code>, <code>status_code</code>, <code>latency_ms</code>), (2) ensure access logs follow sampling and redaction rules, (3) avoid double-formatting by replacing uvicorn handlers rather than adding duplicates. Tests: simulate uvicorn log emission and assert a single structured record is produced with expected fields. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>set_log_level(logger_name: str, level: Union[int,str]) -&gt; None</code></strong><br><br>Dynamic helper used by runtime admin endpoints or CLI to change logger levels atomically. Should validate level, coerce strings to ints, and update both logger and any handler filters that depend on level. Must document that changing levels at runtime affects only the process memory (not persisted across restarts). Tests: set and reset levels; ensure handlers respect the change immediately. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong><code>validate_logging_config(settings: Settings) -&gt; List[str]</code></strong><br><br>Lightweight validator used by a <code>--check</code> CLI path. It verifies the logging-related settings: <code>log_format</code> allowed values, <code>log_level</code> valid, secrets not present in <code>redact_keys</code> mistaken forms, file path writability (if file handler enabled), and that external DSNs look well-formed. Return a list of human-friendly error/warning strings. CLI should call this and fail-fast if <code>strict</code> is true. Tests: exercise invalid/valid config permutations. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong>Implementation patterns & guardrails</strong><br><br>â€” <strong>Lazy imports</strong>: heavy SDKs (Sentry, OTel) imported only inside the functions that use them. <br>â€” <strong>Idempotence</strong>: every public configure function should be safe to call multiple times; guard with a small module-level flag or registrar on <code>app.state</code>. <br>â€” <strong>Non-blocking integration</strong>: external transports must be initialized but not synched on the configure path â€” actual connect/shutdown actions belong to explicit <code>init()</code>/<code>close()</code> lifecycle handlers. <br>â€” <strong>Redaction-first</strong>: apply redaction before serialization to avoid leaking secrets into log streams or structured fields. <br>â€” <strong>Context propagation</strong>: use <code>contextvars</code> for <code>request_id</code> & trace context, never thread-locals. <br>â€” <strong>Observability</strong>: attach <code>service</code>, <code>env</code>, <code>runtime_fingerprint</code>, and <code>git_sha</code>/<code>version</code> fields to every record for correlation. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong>Recommended tests & CI checks</strong><br><br>1. <strong>Unit</strong>: formatter produces required schema fields; redaction filter removes sensitive keys and preserves non-sensitive data. <br>2. <strong>Concurrency</strong>: RequestIdFilter + TraceContextFilter maintain isolation across async tasks. <br>3. <strong>Integration (fast)</strong>: <code>configure_logging(settings)</code> + <code>integrate_uvicorn_logging()</code> produce one structured access log for a simulated request. <br>4. <strong>Dry-run</strong>: <code>settings.dry_run</code> uses <code>MemoryHandler</code> and no network clients are created. <br>5. <strong>Failure-resilience</strong>: failing telemetry client should not raise when <code>capture_exception()</code> is called. <br>6. <strong>Idempotence</strong>: repeated <code>configure_logging()</code> calls do not duplicate handlers or filters. Automate these as part of CI gating. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong>Operational & security checklist</strong><br><br>- Ensure <code>settings.log_redact_keys</code> includes all PII and secrets (tokens, SSNs, account numbers). <br>- Confirm <code>settings.strict</code> blocks startup if required log sinks are unreachable only when explicitly desired. <br>- Validate that <code>log_level</code> and <code>log_format</code> are overridable per environment (CI/dev/prod). <br>- Verify logs do not inadvertently include secrets in exception tracebacks; configure exception processors to scrub frames/locals as needed. <br>- Confirm slow or blocking telemetry clients use non-blocking exporters (batch + background thread) and have circuit-breakers and backoff. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong>Maintenance & developer notes</strong><br><br>â€” When adding a new external sink, implement a factory that returns <code>{init(), capture(), close()}</code> rather than performing side-effects at import. <br>â€” If you add new redaction keys, include unit tests with fixture payloads that assert removal. <br>â€” When changing the output schema (adding/removing top-level fields), bump <code>runtime_fingerprint</code> and communicate the change to downstream consumers. <br>â€” Keep the module small: move complex formatters, filters, or integrations into <code>log/formatters.py</code>, <code>log/filters.py</code>, <code>log/integrations.py</code> as needed. <br>â€” Provide a <code>build_test_logger()</code> helper in tests that constructs a logger with a <code>MemoryHandler</code> and deterministic <code>request_id</code>/<code>trace_id</code> for reproducible asserts. </td></tr><tr><td data-label="Technical Breakdown â€” log.py"> <strong>Common pitfalls & mitigations</strong><br><br>â€” <em>Accidental blocking on startup</em>: avoid calling <code>sentry_sdk.init()</code> or OTel exporters synchronously in <code>configure_logging</code>; instead register an <code>init_external()</code> to be run at startup. <br>â€” <em>Double-formatting from third-party servers</em> (gunicorn/uvicorn): replace their handlers rather than add to avoid duplicate JSON wrappers. <br>â€” <em>Redaction edge-cases</em>: ensure nested structures and stringified JSON inside messages are handled or flagged in tests. <br>â€” <em>Secret leakage in tests</em>: ensure test fixtures do not contain real secrets and that <code>dry_run</code> prevents accidental telemetry shipping. </td></tr></tbody></table></div><div class="row-count">Rows: 18</div></div><div class="table-caption" id="Table11" data-table="Docu_0162_11" style="margin-top:2mm;margin-left:3mm;"><strong>Table 11</strong></div>
<div class="table-wrapper" data-table-id="table-11"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” src/crypto.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” src/crypto.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr><tr><td data-label="Technical Breakdown â€” src/crypto.py"></td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table12" data-table="Docu_0162_12" style="margin-top:2mm;margin-left:3mm;"><strong>Table 12</strong></div>
<div class="table-wrapper" data-table-id="table-12"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” parsers.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” parsers.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>File-level responsibilities</strong><br><br><code>parsers.py</code> is the canonical, small-and-focused translation layer that accepts raw uploads (file-like objects, HTTP body streams, adapter payloads) and produces <em>canonical, schema-aligned record streams plus structured diagnostics</em>. Its responsibilities are orchestration and defensive normalization â€” <strong>not</strong> domain rule calculation, heavy IO (object-store writes), or persistence. Keep this module pure-ish: expose composable parser factories and streaming iterators; delegate CSV dialect sniffing, Excel details, and column-mapping rules to helper modules (<code>csv_mapper.py</code>, <code>excel_reader.py</code>, <code>validators.py</code>). At import time this module must do zero network I/O and minimal CPU work. Document the public entrypoints (what types they accept) and the shape of returned iterators/tuples (e.g., <code>(record: dict, meta: Meta)</code> or <code>(ok: bool, canonical: dict|None, diagnostics: List[Diag])</code>). </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Operational contract (summary)</strong><br><br>1. <strong>Streaming-first</strong>: APIs return iterators / async iterators to avoid OOM on large uploads. <br>2. <strong>Idempotent & deterministic</strong>: same input bytes â†’ same canonical records and same diagnostics (modulo timestamps). <br>3. <strong>Safe defaults</strong>: strict parsing off by default, size/time limits enforced, CSV injection prevented by redaction hooks. <br>4. <strong>Observability</strong>: expose metrics (rows read, malformed rows, bytes, parse latency), and structured diagnostics that include <code>trace_id</code>, <code>row_index</code>, <code>original_bytes_snippet</code> (redacted), and <code>hint</code>. <br>5. <strong>Fail-fast vs degraded</strong>: support <code>strict=True</code> to convert parsing errors into raise/abort; otherwise surface them as diagnostics and continue. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>parse(stream: BinaryIO | TextIO, source_meta: Dict, mapping: MappingRules, *, strict: bool=False) -&gt; Iterator[ParseResult]</code></strong><br><br>Primary orchestrator used by upload endpoints and adapters. Responsibilities: <br>â€” Validate <code>stream</code> type and wrap into a buffered, seekable wrapper if needed (for sniffing) without reading whole file. <br>â€” Call <code>detect_format</code> to select <code>csv</code>, <code>excel</code>, <code>jsonl</code>, or <code>unknown</code>. <br>â€” Use format-specific parser (<code>parse_csv_with_fallbacks</code>, <code>excel_reader</code>) and <code>map_columns</code> to produce canonical records. <br>â€” Emit <code>ParseResult</code> objects: <code>{ok: bool, row_index: int, canonical: dict | None, diagnostics: List[Diag], original: RawRowMeta}</code>. <br>â€” Enforce global limits (max_rows, max_bytes, per-row_byte_limit) and timeouts; when limits are exceeded, produce a deterministic <code>LimitExceeded</code> diagnostic and stop iteration. <br><br>Testing: unit tests should feed streams of varying encodings/BOMs, thousands-of-rows streams to validate streaming semantics, and assert idempotent results for repeated reads of identical streams (using in-memory bytes). </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>detect_format(peekable_stream) -&gt; Literal[&#x27;csv&#x27;,&#x27;excel&#x27;,&#x27;jsonl&#x27;,&#x27;auto&#x27;,&#x27;unknown&#x27;]</code></strong><br><br>Lightweight detector that peeks at the first N bytes (configurable, default 8192) and decides parser. Heuristics: BOM & file signature (PK for XLSX), presence of <code>&lt;xml</code> or <code>&lt;?xml</code>, first non-empty non-comment line JSON (<code>{</code> or <code>[</code>), presence of multiple delimiters vs consistent line-breaks for CSV. MUST not consume the stream permanently â€” use buffered wrapper or <code>io.BufferedReader</code> + <code>peek</code>. Edge cases: aggregated multi-file uploads (zip) should be detected and surfaced as <code>error: archive</code> (parsers.py may choose to reject or hand to adapter). Diagnostics: return confidence score and the bytes used for diagnosis (redacted). </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>parse_csv_with_fallbacks(stream, encoding_hints=None, delimiters=None, quotechars=None, *, max_sniff_bytes=8192) -&gt; Iterator[RowMeta]</code></strong><br><br>CSV parser which: <br>â€” First performs an <em>encoding sniff</em> (BOM, chardet/charset hints or best-effort UTF-8 fallback). <br>â€” Uses a dialect-sniffing stage that tries a prioritized list of delimiters and quote characters, running small sanity checks (consistent field counts for N lines, header plausibility). <br>â€” Applies progressive fallbacks: strict csv module dialect â†’ fallback with <code>escapechar=&#x27;\\&#x27;</code> â†’ fallback to manual split only if quoting impossible and <code>settings.allow_loose_csv</code>. <br>â€” Emits rows as <code>(row_index:int, raw_cells: List[str], byte_offsets)</code> where raw cell strings are in normalized <code>str</code> (unicode) and trimmed only if mapping rules require. <br><br>Performance & safety: read in configurable row-chunks (e.g., 4096 lines) to limit memory; enforce per-row byte limits; protect against huge single-field attacks by truncating and adding a <code>TruncatedField</code> diagnostic. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>read_headers_and_map(headers: List[str], mapping_rules, header_policy=&#x27;auto&#x27;) -&gt; ColumnMap</code></strong><br><br>Responsibilities: canonicalize incoming header names (normalize whitespace, unicode normalization NFKC, lowercase, remove BOM remnants), optionally unify duplicate names (<code>name</code>, <code>name_1</code>), and resolve mapping rules (explicit mapping table, fuzzy matcher, synonyms dictionary). Behavior notes: <br>â€” If <code>header_policy==&#x27;positional&#x27;</code>, map purely by index and ignore header text. <br>â€” If mapping ambiguity remains, return <code>ColumnMap</code> with <code>unmapped</code> list and attach <code>MappingAmbiguity</code> diagnostics. <br>â€” Preserve original header order in <code>ColumnMap.order</code>. Tests should assert fuzzy matching thresholds and deterministic tie-breakers (prefer exact match, then longest common subsequence, then config-provided priority list). </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>row_to_canonical(raw_cells: List[str], col_map: ColumnMap, schema: SchemaHints, *, tz: ZoneInfo|str=None) -&gt; Tuple[dict, List[Diag]]</code></strong><br><br>Map a parsed row to the canonical record shape: <br>â€” Use <code>col_map</code> to assign values to canonical keys. <br>â€” Coerce types via <code>coerce_types</code> using <code>schema</code> hints (numeric, decimal with scale, date with format list, enum sets). <br>â€” Run light normalization: trim unless <code>keep_whitespace=True</code>, collapse repeated spaces, normalize unicode, sanitize CSV-injection values (leading <code>=</code>, <code>+</code>, <code>-</code>, <code>@</code> in spreadsheets) by prefixing safe marker or marking <code>suspicious</code>. <br>â€” Return canonical dict and non-fatal diagnostics (coercion warnings, missing required field warnings). In <code>strict</code> mode any coercion failure becomes an error diagnostic that causes upstream to mark row as invalid. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>coerce_types(value: str, target: TypeHint, *, formats: Optional[List[str]]=None, decimal_ctx: Optional[DecimalContext]=None) -&gt; (coerced_value, Diag|None)</code></strong><br><br>Pure conversion helper with careful edge-case handling: <br>â€” Numeric: strip thousands separators (configurable), reject over-precise decimals beyond allowed scale (return <code>PrecisionLoss</code> diag). <br>â€” Dates: try provided list of formats, then fallback to ISO parsing and smart day-month ambiguity heuristics respecting <code>settings.date_order</code>. Return timezone-aware datetimes when timezone provided or assume <code>source_meta.timezone</code> otherwise. <br>â€” Enums: case-insensitive match + fuzzy (levenshtein) suggestions but never auto-normalize unless <code>auto_fix</code> enabled and audit logged. <br>â€” On ambiguous conversions return structured <code>Diag</code> with <code>suggested_value</code> where safe. Unit tests: include ambiguous dates (03/04/05), large integers, localized decimal points, and malformed numerics. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>parse_excel(stream, source_meta, mapping_rules, *, strict=False) -&gt; Iterator[ParseResult]</code></strong><br><br>High-level orchestration for Excel inputs (delegates exact cell reading to <code>excel_reader.py</code>): responsibilities include sheet selection policy (first sheet by default, or explicit <code>source_meta.sheet_name</code>), handling of merged cells (expand or ignore via config), and detection of header rows that are multi-row (multi-line header). Must protect against formula-injection (cells containing formulas) and large embedded objects. Emit both row-level diagnostics and sheet-level metadata (sheet_name, dimensions, scanned_nrows, scanned_ncols). </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>stream_parser(stream, parser_fn, chunk_size=1024) -&gt; Iterator</code></strong><br><br>A small generic helper that wraps any row-generator (CSV/Excel/JSONL) and enforces: <br>â€” Backpressure-friendly yield semantics for worker pools. <br>â€” Per-chunk metrics emission (rows processed, bytes read). <br>â€” Graceful cancellation: honor an external <code>stop_event</code> or <code>asyncio.CancelledError</code> in async variant. <br>â€” Converts exceptions into <code>ParseException</code> diagnostics unless <code>strict=True</code>. Tests: assert that <code>stream_parser</code> closes the underlying stream on completion/exception and that backpressure does not buffer more than <code>chunk_size</code> rows. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong><code>diagnostics infrastructure (Diag, ParseResult, Meta)</code></strong><br><br>Define small immutable dataclasses for diagnostics and result envelopes that include: <code>code</code> (machine id), <code>severity</code> (<code>error|warning|info</code>), <code>message</code>, <code>row_index</code> (optional), <code>field</code> (optional), <code>hint</code>, <code>fingerprint</code> (stable hash to dedupe identical diagnostics), and <code>sample</code> (redacted literal). Parsers must produce consistent <code>code</code> values and use canonical codes from <code>constants.py</code>. Provide helpers to <code>aggregate_diagnostics(iterable)</code> that produce summary counts used by API responses. Tests: ensure serialization is stable and fingerprints are stable across equivalent errors. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Edge cases & defensive programming</strong><br><br>â€” <strong>BOMs & multi-encoding</strong>: never assume bytes are UTF-8; always sniff and have deterministic fallback. <br>â€” <strong>Huge fields / zip bombs</strong>: enforce per-row/per-field byte caps; detect archive files and reject or hand to dedicated processors. <br>â€” <strong>Malformed CSV</strong>: prefer tolerance but record diagnostics; do not silently drop columns â€” either align by position or produce an explicit <code>column_mismatch</code> diag. <br>â€” <strong>CSV injection</strong>: redact or neutralize cells starting with <code>=</code>, <code>+</code>, <code>-</code>, <code>@</code> when output is destined for Excel/CSV consumers unless opt-in. <br>â€” <strong>Timezones & dates</strong>: require explicit timezone in metadata or document assumed timezone; always store normalized ISO+TZ in canonical records. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Security & privacy guardrails</strong><br><br>â€” Limit in-memory buffering; prefer streaming to temp files with safe permission bits. <br>â€” Sanitize any paths from uploaded metadata to avoid path traversal. <br>â€” Do not log raw field values; logs may contain redacted <code>sample</code> values and a hashed content fingerprint for dedupe. <br>â€” Avoid naive eval/parsing of user-provided format strings; whitelist safe tokens. <br>â€” When handing data to downstream rule engines, ensure types are canonical and that any field-level PII redaction policy is applied if <code>source_meta.pii_mode</code> is enabled. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Observability & metrics</strong><br><br>Emit these metrics per-parse run: <code>parse.rows_read</code>, <code>parse.rows_valid</code>, <code>parse.rows_invalid</code>, <code>parse.bytes_read</code>, <code>parse.duration_ms</code>, <code>parse.malformed_rate</code>. Also emit histograms for <code>row_parse_latency_ms</code> and counters for each diagnostic code. Correlate with <code>trace_id</code> and include <code>runtime_fingerprint</code> (parser version + mapping version + applied_rule_version if present). Provide a <code>dry_run</code> mode capturing diagnostics into memory for unit tests. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Testing strategy & suggested test cases</strong><br><br>Unit tests (fast): header normalization, mapping ambiguity tie-breaks, <code>coerce_types</code> permutations, CSV quoting edge cases, date ambiguities with <code>settings.date_order</code>. Integration tests (CI): end-to-end parse of representative fixture payloads (CSV/Excel/JSONL), asserting canonical output, diagnostic summaries, and idempotent results for a repeated stream. Fuzz tests: random binary blobs to ensure no uncontrolled exceptions. Performance test: streaming 1M-row CSV with memory < X MB. Security tests: CSV injection propagation checks, archive/zip-bomb rejection. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>API ergonomics & public contracts</strong><br><br>â€” Export a minimal stable public surface: <code>parse</code>, <code>detect_format</code>, <code>ColumnMap</code> and diagnostic types. <br>â€” Guarantee that <code>ParseResult</code> is JSON-serializable and stable across versions (add new fields as optional with clear migration notes). <br>â€” Provide <code>parse_to_snapshot(stream, mapping, storage, *, chunked=True)</code> helper in a separate util module â€” <code>parsers.py</code> should not perform large object-store writes directly but may offer a thin wrapper delegating to <code>file_ops.py</code>. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Implementation patterns & guardrails</strong><br><br>â€” <strong>Lazy imports</strong>: heavy deps (openpyxl, pandas, chardet) imported inside the specific function that needs them. <br>â€” <strong>Idempotence</strong>: use content hash of the first <code>N</code> bytes + mapping version to build idempotency keys for upstream dedupe. <br>â€” <strong>Small pure helpers</strong>: keep parsing helpers pure (no global state) to ease unit testing. <br>â€” <strong>Config-driven behavior</strong>: expose <code>settings.parse.{max_rows,max_bytes,allow_loose_csv,date_order}</code>. <br>â€” <strong>Errors vs diagnostics</strong>: raise only for programmer errors; use diagnostics for data faults unless <code>strict=True</code>. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Maintenance & developer notes</strong><br><br>â€” When adding new format support (e.g., fixed-width), add a new <code>detect_format</code> heuristic and a format-specific parser module; keep <code>parsers.py</code> orchestrator unchanged. <br>â€” When changing the canonical schema, add a migration test fixture and document <code>mapping_rules</code> version bump behavior. <br>â€” Keep the file small â€” heavy logic should live in focused modules (<code>csv_mapper.py</code>, <code>excel_reader.py</code>, <code>validators.py</code>). <br>â€” Add golden fixtures for each major upload source (ERP CSV exports, vendor Excel) to catch real-world irregularities. </td></tr><tr><td data-label="Technical Breakdown â€” parsers.py"> <strong>Recommended CI checks</strong><br><br>1. Unit tests for pure helpers. 2. Integration parse for each fixture (assert row counts, canonical fields, diagnostic counts). 3. Fuzz/robustness job that runs random binary inputs to ensure no crash. 4. Performance smoke (streaming memory regression). 5. Security checks (injection leakage, archive detection). 6. API contract test ensuring <code>ParseResult</code> JSON schema compatibility. </td></tr></tbody></table></div><div class="row-count">Rows: 19</div></div><div class="table-caption" id="Table13" data-table="Docu_0162_13" style="margin-top:2mm;margin-left:3mm;"><strong>Table 13</strong></div>
<div class="table-wrapper" data-table-id="table-13"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” csv_mapper.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” csv_mapper.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong>File-level responsibilities</strong><br><br>This module is the authoritative translator that turns heterogeneous CSV inputs into the project's canonical <em>ingest</em> record shape. It lives at the boundary between raw parsing (file/stream/adapter) and business validation (validators.py). Responsibilities: robust dialect & encoding detection; deterministic header normalization and mapping; stable, testable field-level transformations (type coercion, normalization, canonical IDs); generation of per-row metadata and diagnostics; streaming-friendly operation with bounded memory; clear observability hooks (per-file stats, sampled row traces, error counters); and idempotent mapping operations (same input â†’ same canonical output and same content-hash). The file must avoid opening persistent connections, must accept injected configuration objects (mapping templates, locale rules, logger), and expose both streaming and batch entrypoints. Document operational knobs (max_rows_in_memory, dialect_sniff_bytes, mapping_mode: <code>strict|lenient</code>, sampling_rate_for_traces) at the top of the file. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>sniff_dialect_and_encoding(source: IO, sample_bytes: int) -&gt; (dialect, encoding, bom, has_header)</code></strong><br><br>Non-blocking heuristic that reads a bounded prefix to detect CSV dialect (delimiter, quotechar, escapechar), text encoding (utf-8/utf-16/latin1 variants), BOM presence, and whether a header row appears present. Must be conservative: prefer <code>utf-8</code> when ambiguous but supply the detected encoding. Must never consume the stream irreversibly â€” return a resettable wrapper or an offset to rewind. Behavior: try standard <code>csv.Sniffer</code>-like heuristics + fallback rules (common delimiters: ,;<code>\t|</code>) and small heuristics for consistent column counts across sampled lines. Edge cases: malformed multi-line fields, binary content, variable-column files. Tests: feed many real-world samples (Windows Excel output, exported reports, pipe-delimited, concatenated CSVs). Observability: emit a diagnostic event with the sniff sample and decisions (redacted). </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>normalize_headers(raw_headers: List[str], mapping_config: MappingConfig) -&gt; List[NormalizedHeader]</code></strong><br><br>Canonicalizes header names into normalized identifiers used downstream. Steps: strip control chars and BOMs, unify whitespace & punctuation to snake_case, fold Unicode compatibility forms (NFKC), normalize casing according to project rules, resolve duplicates deterministically (append suffix or prefer mapping_config priority), and apply header aliases from mapping_config. Must be idempotent (re-running yields same result) and stable across Python versions. Return structured <code>NormalizedHeader</code> objects: <code>{original, normalized, aliases[], index}</code>. Important: do not mutate mapping_config; treat it as read-only. Provide explicit logging for ambiguous header merges and return warnings for manual review. Unit tests: check collisions, alias resolution, Unicode handling, and repeated application. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>load_mapping_config(source: Path|Dict|bytes) -&gt; MappingConfig</code></strong><br><br>Load a mapping template used to transform headers/values to canonical fields. Support JSON/YAML dict, and an older legacy INI-style mapping (with clear upgrade path). Validate the loaded mapping against a strict JSON schema: required mapping keys, allowed transformers, and version field. On version mismatch, return a <code>MappingCompatibility</code> object that lists incompatible rules and suggested migrations. Never mutate the original file; return an in-memory validated configuration object. Tests: schema validation, failing-fast for malformed entries, and compatibility warnings for older mapping versions. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>compile_field_map(mapping_config: MappingConfig, canonical_schema: Schema) -&gt; FieldMap</code></strong><br><br>Prepares an efficient, pre-validated mapping structure used while streaming rows. Responsibilities: resolve headerâ†’canonical_field rules, compile transformation pipelines (parsers, regexes, enumerations), attach default values and null-handling strategies, and mark required vs optional fields from the canonical schema. Validate that mapped canonical fields actually exist in canonical_schema; produce warnings for unmapped required fields (when mapping_mode != strict). The returned <code>FieldMap</code> must be serializable (for caching) and small. Tests: ensure compiled transformers match expected behavior and are safe for repeated calls. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>parse_csv_stream(source: IO, dialect, encoding, has_header, max_rows: Optional[int]) -&gt; Iterator[List[str]]</code></strong><br><br>Lightweight CSV iterator that yields raw row lists. Guarantees: memory-bounded (reads line-by-line or uses a streaming buffer), respects <code>max_rows</code> for sampling, honors <code>dialect</code> and <code>encoding</code>, and returns stable row widths (pad/truncate rows to header length with explicit diagnostics). Behavior for malformed rows: emit a <code>RowParseError</code> diagnostic and continue or raise depending on <code>mapping_mode</code>. Must expose hooks to collect parse-level stats (rows_read, parse_errors, avg_field_count). Tests: very large files, inconsistent column counts, embedded newlines, different encodings. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>map_row_to_canonical(raw_row: List[str], headers: List[NormalizedHeader], field_map: FieldMap, context: MapContext) -&gt; (canonical_record: Dict, diagnostics: List[Diag])</code></strong><br><br>Core per-row mapping function. Responsibilities: align raw fields with normalized headers, apply per-field transformers in deterministic order (trim â†’ normalize_unicode â†’ coerce_type â†’ apply_business_transformers), populate missing canonical fields with defaults or <code>None</code> per <code>field_map</code>, attach source metadata (<code>_source_index</code>, <code>_raw_headers</code>, <code>_row_number</code>), and return a list of deterministic diagnostics (warnings vs errors). Must be pure and side-effect free except for optional metrics emission through provided <code>context</code>. Deterministic decisions (e.g., date heuristics) must be driven by config in <code>field_map</code> rather than runtime environment. Performance: optimize hot-paths (common types: date, int, decimal) to avoid repeated regex compilation. Tests: golden fixtures mapping to canonical JSON for varied inputs, and property-based tests for idempotence. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>coerce_value(value: str, target_type: str, rules: TypeRules, locale: Locale) -&gt; ParsedValue</code></strong><br><br>Robust, well-tested coercion utility used by mapping pipelines. Must support at minimum: <code>string</code>, <code>int</code>, <code>decimal</code>, <code>date</code>, <code>datetime</code>, <code>boolean</code>, <code>enum</code>, <code>list</code> (multivalue), and <code>json</code> types. Responsibilities: apply locale-aware parsing (decimal/ thousands separators), safe decimal math (use Decimal with configured context), strict/lenient parsing modes (fail vs null), numeric bounds checks, timezone normalization for datetimes, and consistent timezone-less semantics for dates when required. Return a typed value and optional normalization metadata (original, parsed, format_used). Edge cases: enormous numbers, scientific notation, negative zeros, ambiguous date orders. Tests: fuzz inputs, locale permutations, and overflow behavior. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>apply_transformers(value, transformers: List[Transformer], ctx) -&gt; Any</code></strong><br><br>Applies a small pipeline of deterministic, side-effect-free transformers: regex captures, map tables (valueâ†’canonical), enrichment via lookup tables (in-memory only), normalization functions (normalize_name, normalize_tax_id), and anonymizers (redaction for logs). Transformers must be composable and order-sensitive; validate each transformer at compile time and provide helpful error messages. Time-consuming transforms (network lookups) must not be part of this pipeline. Tests: transformer composition cases, transformer error isolation (failure in one transformer should yield a diagnostic but not crash the mapper in lenient mode). </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>handle_multivalue_field(raw_value: str, sep: str|List[str], rules: MultiValueRules) -&gt; List[str]</code></strong><br><br>Deterministically splits and normalizes multi-value fields (e.g., "a; <code>b | c</code>"). Responsibilities: support multiple separators, quoted elements, trimming, deduplication (stable order with config choice), and empties handling. Return canonical list and diagnostics on suspicious patterns (e.g., separators inside an unclosed quote). Tests: ensure consistent splitting for complex nested separators and CSV-escaped values. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>resolve_header_conflicts(normalized_headers: List[NormalizedHeader], strategy: str) -&gt; List[NormalizedHeader]</code></strong><br><br>Policy-driven resolution for duplicated or ambiguous headers. Strategies: <code>first-wins</code>, <code>index-suffix</code>, <code>mapping-priority</code>, <code>merge-into-list</code>. Must be deterministic and clearly logged. For <code>merge-into-list</code>, produce a combined field and update <code>FieldMap</code> expectation accordingly. Tests: header collision examples and verification of chosen strategy. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>infer_schema_from_sample(rows: Iterator[List[str]], sample_size: int, locale: Locale) -&gt; InferredSchema</code></strong><br><br>Heuristic schema inference used for auto-mapping and helpful CLI previews. Responsibilities: sample rows up to <code>sample_size</code>, infer types and nullability with confidence scoring, detect enumerations and value patterns, and record ambiguous columns for manual review. Must never write inferred schema to persistent storage; return an object the caller can examine. Tests: diverse fixture sets, ensure deterministic inference when sampling seed is fixed. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>compute_row_hash(canonical_record: Dict, algorithm: str = &#x27;sha256&#x27;) -&gt; str</code></strong><br><br>Deterministic content hashing for idempotency and snapshot deduplication. Rules: canonicalize record ordering (sort keys), normalize value representations (dates to ISO8601, decimals to normalized string), and exclude non-deterministic runtime metadata unless explicitly requested. Provide stable output across Python versions and locales. Allow salt injection for namespace separation (but default to no salt). Tests: ensure identical inputs produce identical hashes and that harmless ordering changes do not change hash. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>stream_map_csv(source: IO, mapping_config, canonical_schema, out: Callable[[Dict],None], diagnostics_collector: DiagnosticsCollector, context: MapContext) -&gt; MappingSummary</code></strong><br><br>High-level streaming orchestrator used by API endpoints and adapters. Responsibilities: sniff input, load/compile mapping, stream parse rows, map rows via <code>map_row_to_canonical</code>, call <code>out</code> per valid row (could be append-to-snapshot, queue, or in-memory list), collect diagnostics for invalid rows, and return a summary (rows_read, rows_mapped, errors_count, sample_hashes). Must be resilient: timeboxed per-file process with configurable max runtime and memory caps. Provide back-pressure / chunking hooks for downstream consumers. Tests: end-to-end streaming on large test files, failure injection for transform errors, and idempotence checks. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>map_csv_file(path: Path, ...) -&gt; MappingSummary</code></strong><br><br>Convenience wrapper that opens files safely, manages file handles, enforces process-level resource limits, and calls <code>stream_map_csv</code>. Ensure compliance with expected file encodings and BOM handling. Must not leak file handles under any error path. Tests: file permission errors, large-file behaviour, and correct summary returned. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>export_mapping_preview(mapping_config, infer_result, n: int) -&gt; MappingPreview</code></strong><br><br>Produce a compact preview used by UI/CLI: shows first <code>n</code> mapped canonical rows (or sampled rows), mapping coverage (columns mapped/unmapped), inferred confidence, and suggested mapping fixes. Must redact sensitive values in preview unless <code>user_is_trusted</code> flag is set. Tests: preview content correctness and redaction behavior. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>emit_metrics(summary: MappingSummary, ctx: MapContext) -&gt; None</code></strong><br><br>Unified metrics emission for Prometheus/OTel: counters for rows_read, mapped, parse_errors, transform_errors; histograms for row_processing_duration; and gauges for in-flight files. Must be non-blocking and tolerant to missing exporters (no exception). Include sampled structured logs for high-severity row errors including <code>trace_id</code>. Tests: ensure metrics are emitted and do not throw when exporter is missing. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>serialize_mapping_cache(field_map: FieldMap, cache_path: Path) -&gt; None</code></strong><br><br>Optional performance optimization: persist compiled FieldMap to disk for repeated mappings. Must include versioning and checksum to avoid deserialization incompatibilities. Safe-write semantics: write to temp-file then atomic rename. On load failure, fall back to compile. Tests: cache validity across process restarts and format migrations. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong><code>exceptions and diagnostics model</code></strong><br><br>Define a small taxonomy: <code>RowParseError</code> (row-level parse), <code>TransformError</code> (field transformer failed), <code>MappingConfigError</code> (invalid mapping), <code>DialectError</code>, and <code>FatalMappingError</code> (abort pipeline). Diagnostics must be serializable and include: <code>kind</code>, <code>severity</code> (<code>error|warning|info</code>), <code>row_number</code> (optional), <code>field</code> (optional), <code>message</code>, <code>hint</code>, and <code>sample_value</code> (redacted). Logging must redact PII and sensitive tokens. Tests: ensure errors are emitted with consistent schema and redaction works. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong>Error handling & strict vs lenient modes</strong><br><br>Expose <code>mapping_mode</code> configurables: <code>strict</code> (any parse or transform error aborts mapping), <code>lenient</code> (log diagnostics, emit <code>null</code>/default for failed fields), and <code>report-only</code> (collect errors but continue). Document expected behavior for each mode and recommended CI gate (<code>strict</code> for prod ingestion). Unit tests must assert behaviors under each mode. </td></tr><tr><td data-label="Technical Breakdown â€” csv_mapper.py"> <strong>Performance & memory</strong><br><br>Design for streaming large files (10s of GB). Hot-paths must avoid temporary Python objects per field where possible (use precompiled regex and Decimal contexts). Provide explicit memory cap knobs and backpressure integration. Benchmarks: rows/sec for typical 20-column salary-report CSVs; guidelines for chunk sizes and worker concurrency. Provide notes on when to offload heavy transforms to worker pool (e.g., external lookups). </td></tr></tbody></table></div><div class="row-count">Rows: 21</div></div><div class="table-caption" id="Table14" data-table="Docu_0162_14" style="margin-top:2mm;margin-left:3mm;"><strong>Table 14</strong></div>
<div class="table-wrapper" data-table-id="table-14"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” excel_reader.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” excel_reader.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Module-level responsibilities</strong><br><br>This module provides the canonical, production-quality implementation for reading Excel spreadsheets (XLS/XLSX) into the project's canonical row format. It is responsible for safe, memory-efficient streaming of rows, robust header/sheet detection, deterministic type coercion, merge-cell handling, locale-aware date parsing, PII-safe sanitization, integration hooks for mapping/validation, and producing compact, stable file metadata (content-hash, sheet manifest). The module must perform no network I/O at import time, lazy-load heavy dependencies (openpyxl / xlrd / pyxlsb / pandas) inside factories, and expose both a synchronous, thoroughly-tested API and a non-blocking-friendly iterator compatible with async workers (i.e., a sync iterator that can be consumed in threads or an async adapter). Instrumentation hooks (logger, trace_id, progress callback) and strict safety controls (no macro execution, safe formula handling) are required. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>open_workbook(path: Path, *, engine: Optional[str] = None, read_only: bool = True) -&gt; WorkbookLike</code></strong><br><br><strong>Responsibilities:</strong> open an Excel file handle safely with a chosen engine and options appropriate for production (prefer streaming/read-only modes). Should choose engine heuristically if <code>engine</code> is None (pyxlsb for .xlsb, openpyxl for .xlsx, xlrd for .xls fallback) and surface a thin adapter implementing the minimal workbook API used elsewhere (<code>sheet_names</code>, <code>get_sheet(name)</code>, <code>close()</code>).<br><br><strong>Contract / invariants:</strong> must not evaluate macros; must open in read-only/streaming mode by default; must raise a small set of well-documented exceptions (<code>ExcelOpenError</code>, <code>UnsupportedFormatError</code>, <code>WorkbookCorruptError</code>). Must be idempotent when passed the same path (i.e., repeated opens return independent handles). Must not mutate the file on disk. Lazy-import heavy engine libraries inside function body.<br><br><strong>Implementation notes & guardrails:</strong> wrap engine-specific errors into module-level exceptions; record detected engine and bytes read metrics; protect from zip bombs by checking uncompressed size for .xlsx containers when possible; set strict timeouts if engine supports them; prefer <code>openpyxl</code> <code>read_only=True</code> or similar streaming APIs; fall back to incremental binary readers for .xlsb.<br><br><strong>Failure modes:</strong> unsupported file extension, corrupt archive, memory blowup for small-sheet reads when engine mis-selected. Provide actionable diagnostics in exception messages (sheet names, sample bytes, engine attempted).<br><br><strong>Tests:</strong> fixture files (.xlsx, .xls, .xlsb, purposely corrupted zip, password-protected) asserting correct exception mapping, engine selection, and that workbook handles close without leaking file descriptors. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>list_sheets(path: Path, *, engine: Optional[str] = None) -&gt; List[str]</code></strong><br><br><strong>Responsibilities:</strong> cheaply enumerate sheet names without fully materializing sheets. Used by upload UI, CLI preview, and routing logic. Should be a thin wrapper that opens workbook in minimal mode and returns sheet list plus basic per-sheet stats (row_count if cheap to get).<br><br><strong>Contract:</strong> must be fast for large files (avoid loading cell data); must never evaluate formulas; must return stable order matching file. Return type may include tuples <code>(name, estimated_row_count, has_merged_cells)</code> if available.<br><br><strong>Implementation notes:</strong> use streaming API of engine; set an internal read-row-limit to estimate rows if engine can't cheaply provide row counts; instrument latency. Provide a <code>strict</code> flag to fail on ambiguous sheets or hidden/protected sheets if caller requires.<br><br><strong>Tests:</strong> large-sheet fixture to ensure enumeration completes quickly; hidden/protected sheet behavior tests. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>select_sheet(workbook, sheet_name: Optional[str] = None, sheet_index: Optional[int] = None) -&gt; SheetLike</code></strong><br><br><strong>Responsibilities:</strong> choose the correct sheet to read when caller provides a name or index, with heuristics for common ambiguities (single-sheet files, first visible sheet, fallback order). Should also provide a deterministic error when selection is ambiguous.<br><br><strong>Contract:</strong> if both <code>sheet_name</code> and <code>sheet_index</code> are provided, <code>sheet_name</code> wins; if neither is provided and workbook has multiple visible sheets, raise <code>AmbiguousSheetSelection</code> unless <code>allow_first_sheet=True</code>. Must return a sheet adapter object with consistent cell iteration semantics used by readers.<br><br><strong>Edge cases:</strong> non-existent name, negative indices, hidden sheets. Provide a <code>visibility_policy</code> option (<code>visible_only|all|first_visible</code>).<br><br><strong>Tests:</strong> ambiguous workbook with multiple sheets; selecting by negative index; selecting hidden sheet under different <code>visibility_policy</code> settings. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>detect_header_row(sheet, sample_rows: int = 30) -&gt; HeaderDetectionResult</code></strong><br><br><strong>Responsibilities:</strong> robustly identify the row that contains column headers (if any). Should support: entirely headerless sheets, multi-row headers, misaligned headers, and sheets where the first data row looks like a header (heuristics). Return detailed detection result: <code>header_row_index</code>, <code>header_rows</code> (list of header strings per column), <code>confidence_score</code>, and <code>issues</code> (merged cells in header, blank-leading-columns).<br><br><strong>Algorithm & heuristics:</strong> examine first <code>sample_rows</code>, compute per-column type distributions, token patterns (alpha-heavy suggests header), presence of reserved keywords (id, date, name, amount), percent blankness, and merged-cell patterns. Prefer higher precision (avoid false positives) â€” low-confidence results must be marked so caller can force headerless mode.<br><br><strong>Contract:</strong> must be deterministic; must never modify sheet; should be cheap (bounded by <code>sample_rows</code>). Provide <code>force_header_row</code> override to bypass heuristics.<br><br><strong>Tests:</strong> spreadsheets with: explicit header row, two-row header, header-like data in first row, and completely headerless numeric matrices. Assert confidence levels and correctness. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>normalize_header(header_cells: Iterable[str], *, case: str = &#x27;snake&#x27;, dedupe: bool = True, max_len: int = 120) -&gt; List[str]</code></strong><br><br><strong>Responsibilities:</strong> convert raw header cell texts into stable canonical column keys used downstream by <code>csv_mapper</code>/mapping layer. Normalize whitespace, strip PII-like tokens, collapse multi-row headers if present, convert to snake_case or caller-specified style, and ensure unique names (append suffixes like <code>_1</code>, <code>_2</code> deterministically). Trim very long names and record original mapping in metadata.<br><br><strong>Contract:</strong> output length and character-set must be safe for DB column names and object-store keys; preserve original header->key mapping in metadata for audit. If dedupe is True, ensure deterministically stable suffixing. Must handle non-string headers gracefully by coercing to string using safe formatter.<br><br><strong>Tests:</strong> header collisions, headers with control characters, multi-row headers, blank headers, headers with identical normalized forms. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>iter_rows_stream(sheet, start_row: int = 1, chunk_size: int = 1000, *, yield_raw: bool = False, progress_callback: Optional[Callable[[int], None]] = None) -&gt; Iterator[List[CellLike]]</code></strong><br><br><strong>Responsibilities:</strong> memory-safe streaming iterator yielding rows (lists of cell objects or raw values) from <code>start_row</code> onward. Supports chunked iteration, optional progress callback (called with number of rows read), and optional early-cancel mechanism (stop if callback returns special sentinel or raises <code>StopIteration</code>). Must efficiently handle large sheets (millions of rows) and merged-cell semantics.<br><br><strong>Contract:</strong> yields rows in file order; chunking must not change row boundaries; must be repeatable for same sheet handle only if workbook reopened (streaming readers rarely support rewind). Must raise <code>ReaderCancelled</code> if progress callback signals cancellation. Provide clear semantics for partial reads (metadata must indicate truncated read).<br><br><strong>Implementation notes:</strong> avoid converting each cell to Python objects eagerly; coerce values lazily only when <code>normalize_row</code> or <code>coerce_types</code> is invoked. Record per-chunk timings and emit metrics. Ensure underlying workbook <code>close()</code> is called if iteration is not exhausted and an error occurs. <br><br><strong>Tests:</strong> very-large streaming fixture, cancellation via callback, chunk boundaries, correctness of row ordering. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>parse_cell(cell, *, detect_date_formats: bool = True, locale: Optional[str] = None, tz: Optional[str] = None) -&gt; ParsedValue</code></strong><br><br><strong>Responsibilities:</strong> convert engine-specific cell objects into normalized Python primitives: <code>None</code>, <code>str</code>, <code>Decimal</code>, <code>int</code>, <code>bool</code>, timezone-aware <code>datetime</code>, or error sentinel. Must respect Excel number formats and locale when parsing dates/numbers stored as strings; must handle Excel serial dates correctly given workbook epoch and potential timezone hints. Avoid evaluating formulas; if cell is a formula, return the cached value if present and <code>allow_cached_formulas=True</code> else return a <code>FormulaCell</code> sentinel with metadata.<br><br><strong>Contract:</strong> deterministic mapping for same engine cell objects; small and well-documented set of output types; include <code>raw</code> (original value), <code>display</code> (string shown in UI), and <code>coerced</code> (typed value) where helpful. Must never execute VBA or external code. Provide hooks for custom parse extension points for domain-specific parsing.<br><br><strong>Edge cases & failure modes:</strong> ambiguous numeric strings, locale decimal separators, very large integers exceeding safe floats. Prefer <code>Decimal</code> for financial columns. Record parsing warnings and attach to row-level diagnostics.<br><br><strong>Tests:</strong> date serial tests (1900 vs 1904 epoch), numeric strings with comma separators for different locales, formula cells with/without cached values. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>handle_merged_cells(sheet) -&gt; MergedCellMap</code></strong><br><br><strong>Responsibilities:</strong> produce a mapping from merged-cell anchors to their effective value so that row iteration can yield the merged value for cells within the span. Optionally detect semantically problematic merges (e.g., header row merges that hide column names) and surface warnings. The map should be small (only merged ranges) and efficient to query during row iteration.<br><br><strong>Contract:</strong> must not modify the workbook; must be computed lazily or once upfront depending on sheet size; queries <code>get_effective_value(row, col)</code> should be O(1) amortized. Document behavior for merged range having empty anchor â€” treat as blank and emit a warning.<br><br><strong>Tests:</strong> files with merged headers, merged data cells, nested merges (if engine allows), merged empty anchors. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>infer_types_from_sample(rows: Iterable[List[ParsedValue]], max_columns: int = 200, sample_size: int = 500) -&gt; ColumnTypeHints</code></strong><br><br><strong>Responsibilities:</strong> analyze a sample of rows and return per-column type hints (preferred type: decimal/int/str/datetime/bool), nullability, and a confidence score. Provide best-effort categorization for money vs plain numeric and detect columns that should use Decimal (financial) vs float.<br><br><strong>Contract:</strong> stateless deterministic behavior given the same sample; must cap analysis to <code>sample_size</code> to bound CPU; expose <code>mixed_type_ratio</code> per column for downstream validation decisions. Should be conservative: prefer <code>str</code> over ambiguous numeric when confidence low. Return metadata to help mapping layer choose coercion strategies.<br><br><strong>Tests:</strong> columns with mixed types, columns with numeric-looking strings, currency columns. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>coerce_row_to_schema(raw_row: List[ParsedValue], schema: Schema, *, on_error: str = &#x27;collect&#x27;) -&gt; Tuple[CanonicalRow, List[RowIssue]]</code></strong><br><br><strong>Responsibilities:</strong> take a raw row and a target schema (from <code>csv_mapper</code> or canonical schema) and produce a canonical row with coerced types, normalized names, defaults filled, and per-field diagnostics. Must support coercion strategies: strict (raise on first coercion error), collect (return list of issues), best-effort (drop problematic columns), and fallback values. Should centralize numeric rounding rules, timezone normalization for datetimes, and decimal scale enforcement for money fields.<br><br><strong>Contract:</strong> must be pure (no global side-effects) and deterministic; returned <code>CanonicalRow</code> must align with schema column order and types; <code>RowIssue</code> entries should include machine code, severity (error/warn/info), and a user-facing hint. When <code>on_error=&#x27;raise&#x27;</code>, raise a <code>RowCoercionError</code> with all issues aggregated.<br><br><strong>Tests:</strong> schema mismatch cases, missing columns, numeric overflow, date parsing failures, optional fields absent. Validate stability across repeated runs. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>validate_row(canonical_row: CanonicalRow, validators: Iterable[Validator], *, context: Optional[Dict] = None) -&gt; List[ValidationIssue]</code></strong><br><br><strong>Responsibilities:</strong> run zero-or-more validator callables against a canonical row and return structured validation issues (codes, messages, remediation hints). Validators will include value range checks, consistency checks (e.g., date_before(date1, date2)), business logic (e.g., NPWP format), and custom domain checks. Validation must be fast and safe to call per-row and able to short-circuit for fatal errors if desired.<br><br><strong>Contract:</strong> validators should be deterministic and pure; function returns list sorted by severity then code; must never mutate the <code>canonical_row</code>. Provide an option <code>fail_fast=True</code> to abort on first fatal issue. Integrate with metrics to count rows passing vs failing and sample failing rows to a small in-memory buffer for diagnostics.<br><br><strong>Tests:</strong> validators that intentionally fail; cross-field validators; large-batch validations to measure throughput. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>map_row_to_canonical(raw_row: List[ParsedValue], header_mapping: HeaderMap, mapper: CsvMapper, *, metadata: Dict = None) -&gt; Tuple[CanonicalRow, MappingDiagnostics]</code></strong><br><br><strong>Responsibilities:</strong> apply header mapping and domain-level column mapping rules (from <code>csv_mapper</code>) to transform the physical row into canonical field names expected by the rules engine. This function is the integration point between the sheet parsing layer and the rest of the pipeline. It must handle missing mapped columns, multi-column joins (concatenation), default values, and multi-valued fields (e.g., address lines). Also produce detailed mapping diagnostics for audit and automated troubleshooting.<br><br><strong>Contract:</strong> should preserve data provenance (include original header, original cell coordinate, original raw value) for every field in the returned <code>CanonicalRow</code> metadata. Deterministic mapping and stable behavior for repeated runs. When a mapped required field is missing, include a <code>MappingMissing</code> diagnostic. Provide <code>mapping_mode</code> options such as <code>strict|lenient|heuristic</code>.<br><br><strong>Tests:</strong> mapping with header synonyms, mapping where multiple candidate columns exist, and mapping with multi-column aggregation rules. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>compute_content_hash(path: Path, *, algorithm: str = &#x27;sha256&#x27;, sample_bytes: Optional[int] = None) -&gt; str</code></strong><br><br><strong>Responsibilities:</strong> compute a stable content hash for an uploaded Excel file used for deduplication and idempotency keys. For very large files the function should support streaming hashing and an optional <code>sample_bytes</code> mode that mixes head+tail bytes with total size to produce a stable fingerprint while bounding cost. Hash metadata should be deterministic and include engine-detected file type and size.<br><br><strong>Contract:</strong> identical input should produce identical hash; document implications of using <code>sample_bytes</code> (not cryptographic uniqueness but fast). Expose both raw hex and <code>algorithm://hex</code> forms. Use a secure algorithm for canonical idempotency by default. Tests must include identical-file, slightly-modified-file cases to ensure desirable collision behavior. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>read_excel(path: Path, *, sheet_name: Optional[str] = None, mapper: Optional[CsvMapper] = None, schema: Optional[Schema] = None, chunk_size: int = 1000, progress_cb: Optional[Callable] = None, strict: bool = False, instrument: Optional[Instrumentation] = None) -&gt; Iterator[ProcessingResult]</code></strong><br><br><strong>Responsibilities:</strong> the single high-level convenience function used by most callers: orchestrates opening the workbook, selecting the sheet, detecting header rows, streaming rows, mapping to canonical schema, coercing types, running validation, emitting per-row diagnostics, and yielding <code>ProcessingResult</code> objects (either <code>ValidRow</code> or <code>InvalidRow</code> with attached metadata). Must provide deterministic error handling depending on <code>strict</code> flag: in strict mode, raise on first fatal error; in lenient mode collect errors and continue. Should support <code>chunk_size</code> to yield batches as well as metrics integration through <code>instrument</code> (timings, counts).<br><br><strong>Contract:</strong> must be implemented as a generator that is safe to consume in workers; must not swallow unexpected exceptions (bubble up as <code>ReaderFatalError</code> with attached context). Must honor cancellation from <code>progress_cb</code> and ensure workbook is closed on generator exit. Must never leak file handles. Provide a <code>dry_run</code> mode that performs all processing without producing side-effects and returns summary diagnostics only.<br><br><strong>Tests:</strong> end-to-end fixtures across small and large spreadsheets asserting correctness, resource cleanup, strict vs lenient modes, progress callback cancellation, and integration with <code>csv_mapper</code> and <code>validators</code>. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>read_excel_to_dataframe(path: Path, *, sheet_name: Optional[str] = None, nrows: Optional[int] = None, engine: Optional[str] = None, dtype_overrides: Optional[Dict[str,Any]] = None) -&gt; pandas.DataFrame</code></strong><br><br><strong>Responsibilities:</strong> convenience function for small/medium files to materialize sheet content into a <code>pandas.DataFrame</code> for downstream tools, diagnostics, and interactive workflows. Must be explicit about resource limits and raise <code>TooLargeForDataFrame</code> for files exceeding configured row/byte thresholds. Use <code>dtype_overrides</code> to avoid pandas inference pitfalls for financial columns.<br><br><strong>Contract:</strong> synchronous and eager; never used in heavy production ingestion; document that it uses more memory and is not suitable for very large files. Provide <code>low_memory</code> compatibility flags. Tests should assert dtype overrides and behavior under small/large boundaries. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>close_workbook(workbook)</code></strong><br><br><strong>Responsibilities:</strong> safe close/cleanup of engine-specific workbook resources; ensure file descriptors are closed and any temporary files removed. Must be idempotent (calling multiple times is safe) and resilient to partially-constructed workbook objects.<br><br><strong>Contract & tests:</strong> must be called in finally blocks or generator cleanup paths; add test that ensures file descriptor count returns to baseline after repeated open/read/close cycles. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>excel_reader_factory(*, default_chunk_size: int, allowed_engines: List[str], default_locale: str, decimal_context: DecimalContext) -&gt; ExcelReader</code></strong><br><br><strong>Responsibilities:</strong> provide a configurable builder that returns a configured <code>ExcelReader</code> object or a set of functions bound with sensible defaults for the project. This factory centralizes defaults (chunk size, allowed engines, locale) so integration tests can inject test-friendly settings. The factory must avoid imports at module import time and must create closures that capture config for DI in tests.<br><br><strong>Contract:</strong> pure factory (no side-effects). Tests should create readers with non-default settings and assert behavior (e.g., small <code>default_chunk_size</code> leads to more progress callbacks). </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong><code>make_progress_callback(logger, sample_rate: float = 0.01, statsd: Optional[StatsClient] = None) -&gt; Callable</code></strong><br><br><strong>Responsibilities:</strong> produce a standardized callback used by iterators to emit progress metrics (rows read, rows/sec, last-row-index) and sampled debug logs for large uploads. The callback should be lightweight and tolerant to exceptions (never propagate). Provide options to collect sample rows for post-mortem (kept bounded) and to surface sampled failing rows to telemetry. Avoid logging raw PIIâ€”use a redaction hook before log emission.<br><br><strong>Contract:</strong> must be re-entrant and efficient; must not block the main iteration; optional offload to background writer in production via <code>instrument</code>. Tests: assert callback does not raise when logger fails and that sampling behaves as configured. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Error & exception types</strong><br><br><strong>Responsibilities:</strong> the module defines a small, well-documented hierarchy of exceptions used by callers: <code>ExcelReaderError</code> (base), <code>ExcelOpenError</code>, <code>UnsupportedFormatError</code>, <code>WorkbookCorruptError</code>, <code>AmbiguousSheetSelection</code>, <code>HeaderDetectionError</code>, <code>RowCoercionError</code>, <code>ReaderCancelled</code>, <code>ReaderFatalError</code>, <code>TooLargeForDataFrame</code>. Each exception should include structured context (file path, sheet name, row index, underlying engine error) to be machine-readable for the upper layers and safe for logging (no secret leakage). Unit tests should assert that engine-level exceptions are converted to these types with context. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Observability / instrumentation hooks</strong><br><br><strong>Responsibilities:</strong> every function that performs I/O or heavy CPU must accept optional <code>instrument</code> or <code>logger</code> parameters. Instrumentation points to provide: open latency, per-chunk read time, per-row coercion time (sampled), validation error counters, row throughput, memory high-water marks, and content-hash computation time. Tracing integration should accept a <code>trace_id</code> and propagate it into logs and metrics. Implement a lightweight <code>instrument</code> interface (timers, counters, gauge) so tests can inject mocks. Document required metric names and labels for SRE. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Security & safety guardrails</strong><br><br><strong>Requirements:</strong> never execute macros or evaluate formulas; redact sensitive-looking content from logs (SSNs, card numbers, NPWP) using a configurable redaction list; expose a <code>max_rows</code> and <code>max_bytes</code> setting to defend against accidental very large uploads; implement a zip-bomb check for .xlsx; treat password-protected files as <code>UnsupportedFormatError</code> and do not attempt to brute-force. Provide a strict PII-handling policy and tests verifying no PII is written to plain logs when <code>dry_run=False</code>. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>API ergonomics & integration contract</strong><br><br><strong>Responsibilities:</strong> the module must present a small, consistent surface used across the project: <code>excel_reader_factory(...)</code> â†’ <code>reader.read_excel(...)</code> generator + <code>reader.list_sheets()</code> + <code>reader.read_excel_to_dataframe()</code> + <code>reader.compute_content_hash()</code>. Document thread-safety (workbook handles are not thread-safe; each thread must call <code>open_workbook</code>) and provide explicit guidance in top-of-file docstring on how the module interacts with <code>parsers.py</code>, <code>csv_mapper.py</code>, and <code>validators.py</code>. Provide <code>build_test_reader()</code> helper returning reader with <code>dry_run</code> instrumentation and <code>MemoryHandler</code> log capture to simplify unit/integration tests. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Performance & scaling guidance</strong><br><br>â€” Prefer streaming read for files > 10k rows; use chunk sizes ~1kâ€“10k depending on average columns. <br>â€” Use <code>Decimal</code> for money to avoid float precision issues; provide per-column scale enforcement during coercion. <br>â€” If using multi-threaded ingestion, open independent workbook handles; avoid sharing engine objects. <br>â€” Provide a mechanism to pause-resume by recording the last processed row index in metadata for very large uploads. <br>â€” When integrating with object store snapshots, read from stream provided by storage SDK directly (support file-like objects) to avoid local disk when possible. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Testing matrix & recommended tests</strong><br><br>Unit tests: header detection, merged cell handling, parse_cell for all value classes, compute_content_hash invariants, normalize_header collisions, coercion behaviors. Integration tests: end-to-end read -> map -> validate with representative production fixtures (financial sheets, payroll exports, SAP extracts). Fuzz tests: malformed XLSX, non-UTF8 text, huge compressed archives. Performance tests: single-run throughput for 100k rows x 50 columns. Security tests: zip-bomb, password-protected file handling, PII redaction asserts. Lifespan tests: open/read/close repeated 1000x without FD leaks. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Operational notes & runbook snippets</strong><br><br>â€” When file ingest fails with <code>WorkbookCorruptError</code>, surface a user-facing guidance: "please re-export from source system and try again" and capture sample bytes for engineering. <br>â€” For high-volume uploads, enable <code>compute_content_hash</code> early to deduplicate before heavy processing; emit <code>duplicate_detected</code> metric and short-circuit processing. <br>â€” If <code>header_detection</code> is low-confidence, emit an interactive preview (first N rows) to the caller so they can override headers in UI/CLI. <br>â€” Keep audit trail: record header mapping, content hash, applied detection heuristics, and parser version in the upload metadata for reproducibility. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Extensibility & maintenance guidance</strong><br><br>â€” Keep parsing logic thin and pluggable: cell parsing rules should be registered via strategy objects so new formats/locales can be added without touching core loops. <br>â€” If additional heavy engines are required (commercial SDKs), add them behind explicit feature flags and lazy imports only in the factory. <br>â€” Avoid adding business rules to this module; mapping and domain validation belong to <code>csv_mapper</code> and <code>validators.py</code>. <br>â€” Maintain a small ID/version string in metadata for each run so rule regressions can be traced. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Backward compatibility & migration notes</strong><br><br>â€” When changing normalization (header naming) keep a migration shim that accepts old keys to avoid breaking stored manifests. <br>â€” Any change to default date parsing or decimal behavior must bump the parser version exported in metadata. Provide compatibility toggles for legacy uploads during rollout. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Deliverables & checklist for code reviewers</strong><br><br>1. verify lazy imports and no network I/O at import time. <br>2. confirm exported exceptions are comprehensive and documented. <br>3. run FD-leak test and memory benchmark. <br>4. confirm PII redaction in logs and in-sample telemetry. <br>5. ensure all public functions accept <code>instrument</code> and <code>logger</code> hooks. <br>6. verify deterministic header normalization and mapping metadata persisted to manifest. </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Recommended unit/integration test list (short)</strong><br><br>â€” <code>test_open_workbook_engine_selection</code> <br>â€” <code>test_list_sheets_large_xlsx</code> <br>â€” <code>test_detect_header_row_multi_row_header</code> <br>â€” <code>test_iter_rows_stream_cancellation</code> <br>â€” <code>test_parse_cell_date_serials_1900_1904</code> <br>â€” <code>test_coerce_row_to_schema_decimal_scale</code> <br>â€” <code>test_mapping_preserves_provenance</code> <br>â€” <code>test_content_hash_stability</code> <br>â€” <code>test_no_fd_leak_on_error</code> <br>â€” <code>test_pii_redaction_in_logs</code> </td></tr><tr><td data-label="Technical Breakdown â€” excel_reader.py"> <strong>Summary: single-sentence architectural intent</strong><br><br>Excel reader code must be a small, testable, well-instrumented streaming parser that converts messy Excel inputs into deterministic canonical rows while enforcing security, memory safety, auditability, and clear integration contracts with the mapping and validation layers. </td></tr></tbody></table></div><div class="row-count">Rows: 31</div></div><div class="table-caption" id="Table15" data-table="Docu_0162_15" style="margin-top:2mm;margin-left:3mm;"><strong>Table 15</strong></div>
<div class="table-wrapper" data-table-id="table-15"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical Breakdown â€” validators.py"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical Breakdown â€” validators.py</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical Breakdown â€” validators.py"> <strong>File-level responsibilities</strong><br><br>This module centralizes row- and file-level validation for ingested datasets. Responsibilities: (1) provide deterministic, side-effect-free validation primitives that turn a parsed/canonical row into an immutable <code>ValidationResult</code> (errors, warnings, normalized values); (2) orchestrate multi-pass validations (schema/type checks â†’ normalization/coercion â†’ domain/business rules â†’ cross-row checks like duplicates/totals); (3) expose compact helpers to produce machine- and human-friendly validation reports used by the ingest pipeline and UI; (4) surface clear, actionable diagnostics (field, code, severity, hint, suggested_fix); (5) enforce data privacy â€” never log raw sensitive values; (6) document observability hooks (metrics, histogram of error types, sample traces) and performance budgets for large files. Implementation guardrails: keep pure functions pure, do heavy I/O (DB/lookups) outside this module, make each function idempotent, and provide small seam points to inject fakes for unit tests. Verification note: design and tests assume repeated automated checks (10Ã— verification passes) for correctness, edge-cases, and performance regressions. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>load_validation_schema(path_or_obj) -&gt; ValidationSchema</code></strong><br><br>Load and canonicalize a declarative validation schema (fields, types, rules, aliases, required flags, ranges, enumerations, format regexes, cross-field rules). Must accept either a path, dict, or already-parsed object. Responsibilities: validate the schema itself (schema-smithing), normalize legacy/compat aliases to current schema model, and return an immutable <code>ValidationSchema</code> data structure that validation functions consume. Errors: raise <code>SchemaError</code> on malformed definitions with location info. Implementation notes: perform only CPU-bound parsing and validation; do not access network. Provide deterministic resolution for conflicting rule versions (prefer explicit <code>meta.version</code>, otherwise fallback to parsed file mtime with a warning). Unit tests: schema edge cases (missing required field metadata, conflicting aliases, numeric range inversions). </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_headers(headers: Sequence[str], schema: ValidationSchema) -&gt; HeaderValidationResult</code></strong><br><br>Validate incoming file headers against the canonical schema: detect missing required fields, unknown/unmapped columns, duplicate column names, and ambiguous aliases. Return an object that describes: <code>missing_required: List[field]</code>, <code>unknown: List[column]</code>, <code>duplicates: List[column]</code>, and <code>mapping: Dict[input_column -&gt; canonical_field]</code>. Behavior: tolerant-by-default with configurable strictness (<code>settings.strict_headers</code>) â€” in strict mode unknown columns raise a fatal error; in lenient mode they are recorded as warnings and ignored. Idempotence: pure function. Tests: header permutations, alias resolution, case-insensitivity, whitespace trimming. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>normalize_and_coerce(row: Mapping[str,Any], mapping: Dict, schema: ValidationSchema) -&gt; NormalizedRow</code></strong><br><br>Perform deterministic normalization: trim strings, unify unicode normal forms, coerce numeric strings to numbers, parse booleans and enums, canonicalize date/time to ISO8601 (with timezone handling rules), and apply field-level transformations specified in schema (e.g., remove punctuation from tax IDs). Responsibilities: return a <code>NormalizedRow</code> separate from input but preserving original values in diagnostics only when permitted. Failures: return field-level <code>coercion_error</code> diagnostics, not exceptions. Security: redact PII in any returned diagnostic unless explicit <code>reveal=True</code> is used by trusted internal callers. Performance: implement fast-paths (no-op) when a row already matches expected types. Tests: culture/locale numeric formats, timezone edge-cases, very long strings, invalid unicode. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_field_types(normalized_row: NormalizedRow, schema: ValidationSchema) -&gt; List[FieldDiagnostic]</code></strong><br><br>Ensure each field conforms to declared type and constraints (length, pattern, enum membership). Produce <code>FieldDiagnostic</code> entries with machine codes (e.g., <code>TYPE_MISMATCH</code>, <code>PATTERN_MISMATCH</code>, <code>VALUE_OUT_OF_RANGE</code>) and severity (<code>error|warning|info</code>). Behavior: treat null/empty according to <code>nullable</code> flag in schema. Implementation: avoid exceptions â€” collect diagnostics; raise only on catastrophic schema mismatch. Tests: boundary values, null handling, large numerics that overflow target types. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_business_rules(normalized_row: NormalizedRow, schema: ValidationSchema, context: Optional[ValidationContext]) -&gt; List[FieldDiagnostic]</code></strong><br><br>Evaluate domain-specific, per-row business rules that are expressed in the validation schema or injected as small pure callables. Examples: <code>gross &gt;= 0</code>, <code>employment_status in { &#x27;FT&#x27;,&#x27;PT&#x27; } implies monthly_income$field exists</code>, cross-field comparisons like <code>start_date &lt;= end_date</code>, and tax-specific rules (e.g., presence/format of NPWP / tax ID according to country rules). Contract: functions must be pure, deterministic, and timeout or short-circuit on ambiguous inputs. Context parameter allows passing ephemeral values (file-level metadata, declared rule-version) but must not be used for I/O. Diagnostics should include actionable hints and <code>suggested_fix</code> where possible. Tests: contradictory rules, missing prerequisites, null propagation. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_cross_row_constraints(rows: Iterable[NormalizedRow], schema: ValidationSchema) -&gt; CrossRowReport</code></strong><br><br>Perform cross-row checks that require the whole file or a window (dedupe detection, aggregate totals, unique-key enforcement, sequential continuity). This function must be streaming-friendly for large files (support chunked/streamed execution) and return a <code>CrossRowReport</code> containing per-row pointers to diagnostics (e.g., duplicate_of_row_id). Implementation contract: operate in O(n log n) memory/time depending on constraint types; provide configurable memory budget and offer a "bounded" mode that uses external storage when budgets exceeded (externalization must be orchestrated by caller). Tests: duplicates across millions of rows (simulate), rolling windows, aggregate tolerance thresholds. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_row(row: Mapping[str,Any], schema: ValidationSchema, context: Optional[ValidationContext]) -&gt; ValidationResult</code></strong><br><br>Canonical single-entry API used by parsers and adapters. Pipeline: (1) normalize/coerce, (2) type checks, (3) business rules. Return <code>ValidationResult</code> with: <code>normalized_row</code>, <code>is_valid</code> boolean, <code>errors: List[Diagnostic]</code>, <code>warnings: List[Diagnostic]</code>, and <code>meta</code> (e.g., applied_rule_version). Must be pure and safe to call concurrently. Errors: raise only for unrecoverable internal faults (invalid schema object), otherwise always return structured diagnostics. Tests: nil/empty rows, malformed inputs, concurrency safety. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>row_is_valid(validation_result: ValidationResult, policy: ValidationPolicy) -&gt; bool</code></strong><br><br>Policy-driven decision function that maps diagnostics to acceptance/rejection. <code>ValidationPolicy</code> encodes which severities or codes are tolerable (e.g., allow <code>MISSING_OPTIONAL_FIELD</code> but reject <code>TYPE_MISMATCH</code>). This separation enables different ingest modes (strict vs ingest-with-warnings). Must be pure and deterministic. Tests: multiple policy permutations and ensuring idempotence. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>make_validation_report(results: Iterable[ValidationResult], file_meta: FileMeta, summary_options: Optional[SummaryOptions]) -&gt; ValidationReport</code></strong><br><br>Aggregate row results into a compact report for storage and user display. Responsibilities: compute totals (rows, valid, invalid, warnings), top-N error causes, sample invalid rows with context (apply redaction rules), and produce machine-friendly payloads (JSONL or protobuf-ready) and a light human-readable summary. Performance: streaming-friendly; avoid holding entire result set in memory unless <code>summary_options.sample_all=True</code>. Observability: emit metrics (error_rate, median_errors_per_row) via provided hooks. Tests: large-file sampling fidelity, redaction correctness, report deterministic ordering. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>serialize_diagnostics_for_ui(diagnostics: Iterable[Diagnostic], redact: bool=True) -&gt; List[UIDiagnostic]</code></strong><br><br>Map internal diagnostics to UI-friendly shapes: localized messages, field labels (not internal keys), severity badges, and suggested quick-fixes. Must apply redaction and sampling (do not expose PII; sample a bounded number of example rows). Keep localization out of core logic â€” accept a <code>locale</code> parameter and a translation map provided by caller. Tests: localization fallback, redaction, and size-limited output. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>compile_error_codes(schema: ValidationSchema) -&gt; Dict[str, ErrorMetadata]</code></strong><br><br>Return canonical mapping of error codes to structured metadata (title, description, severity, remediation_hint). Used by reporting UI and by external monitoring to group and alert on stable machine codes. This mapping must be stable across minor schema changes; prefer canonicalization by <code>meta.error_codes</code> in the schema. Tests: backward-compatibility, missing codes, duplicate codes detection. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_file(stream: Iterator[Mapping[str,Any]], schema: ValidationSchema, policy: ValidationPolicy, metrics: Optional[MetricsCollector]=None) -&gt; Iterator[ValidationResult]</code></strong><br><br	>High-level orchestrator used by ingest pipelines. Responsibilities: drive per-row <code>validate_row</code>, feed <code>validate_cross_row_constraints</code> in a streaming-aware manner, update metrics, emit backpressure signals when downstream is slow (if running in async wrapper), and produce <code>ValidationResult</code> iterator. Must not perform I/O other than what the caller provides; support early-cancellation when <code>policy.stop_on_first_fatal</code> and fatal encountered. Performance: tuned for chunked processing; recommend chunk size heuristics and concurrency knobs. Tests: end-to-end integration with parsers/csv_mapper, cancellation, and backpressure simulation. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>redact_value(value: Any, field_meta: FieldMeta, mode: RedactionMode=&#x27;default&#x27;) -&gt; str</code></strong><br><br>Utility to consistently redact PII (tax IDs, emails, bank accounts) when producing logs, diagnostics, or reports. Must be deterministic (same input â†’ same redacted token) when <code>deterministic=True</code> (useful for deduplication), and nondeterministic otherwise. Ensure no partial leaks (e.g., last-4 preservation should be opt-in via schema). Implementations must avoid reversible transformations (no reversible hashing without a key) and must not write secrets to logs. Tests: verify non-reversibility, consistent masking rules, and configuration toggles. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>validate_external_lookup(key: str, lookup_type: str, cache: Optional[Mapping]=None) -&gt; LookupResult</code></strong><br><br>Optional helper to validate fields against external authoritative lists (e.g., tax ID registry). IMPORTANT: this function must be designed as an adapter that <strong>does not</strong> perform network calls itself unless the caller provides a pluggable <code>lookup_fn</code> or an injected <code>client</code>. By default it performs purely local cached checks and returns <code>LookupResult</code> indicating <code>status: {unknown, valid, invalid}</code> and <code>confidence</code>. Caller responsibility: supply an async/sync client and manage retries/timeouts. Tests: injection of fake lookup client, cache-miss behavior, timeout simulation. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong><code>export_error_summary(report: ValidationReport, out_path: str, format: Literal[&#x27;json&#x27;,&#x27;csv&#x27;,&#x27;xlsx&#x27;]=&#x27;json&#x27;) -&gt; str</code></strong><br><br>Small utility to write a validation report to disk/object store; returns the final artifact path. Implementation note: this module should offer the transformation (report â†’ canonical dict/rows) but the actual I/O writer should be a thin adapter passed in by the caller â€” keep this function as a serializer/formatter only and avoid direct network/storage calls inside core validation logic. Tests: format fidelity and file-rotation edge cases delegated to adapter tests. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong>Implementation patterns & guardrails</strong><br><br>â€” <strong>Pure functions</strong>: Prefer pure per-row validators returning <code>ValidationResult</code>. <br>â€” <strong>No network at import</strong>: All external interactions must be injection points. <br>â€” <strong>Idempotence</strong>: Re-running validation on the same input must produce identical <code>ValidationResult</code> (given same schema & policy). <br>â€” <strong>Redaction-first</strong>: Diagnostics and logging must redact PII by default. <br>â€” <strong>Observability</strong>: Provide metric hooks (counters for error codes, latency histograms) and correlate validation failures with an ingest <code>trace_id</code>. <br>â€” <strong>Streaming</strong>: Support chunked streaming for <code>validate_file</code> and <code>validate_cross_row_constraints</code> to handle large files without OOM. <br>â€” <strong>Extensibility</strong>: Allow schema to register small, pure plugin callables for business rules; disallow plugins that perform I/O during validation. <br>â€” <strong>Testing hygiene</strong>: Provide <code>build_test_schema</code> and <code>build_test_row</code> helpers and unit tests that exercise type coercions, locale edge-cases, and cross-row constraints in-memory. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong>Recommended tests & CI checks</strong><br><br>1. Unit tests for each validator function covering happy path + edge cases (empty, nulls, out-of-range, malformed).<br>2. Property tests (fuzz) for normalization/coercion routines to catch unicode/locale parsing errors.<br>3. Integration tests: parsers â†’ validators â†’ report generation using golden fixtures.<br>4. Performance tests: validate files of increasing size; assert memory and time budgets; ensure streaming path scales.<br>5. Security tests: assert no PII in logs, reports properly redact unless explicitly allowed.<br>6. Contract tests: injected lookup clients and cross-row adapters behave correctly under simulated failures and timeouts. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong>Operational & security checklist</strong><br><br>â€” Ensure <code>settings.redaction_policy</code> is configured and enforced. <br>â€” Expose metrics for error categories and file-level rejection rates. <br>â€” Configure validation <code>policy</code> for dev/prod (dev: <code>allow_warnings=true</code>, prod: <code>strict=true</code>). <br>â€” Make sure schema version is recorded in validation reports and manifests. <br>â€” Add alerting on sudden spikes of a single error code (possible upstream format change). <br>â€” Audit and rotate any reversible hashing keys used by deterministically masked values; prefer one-way salted hashes where necessary. </td></tr><tr><td data-label="Technical Breakdown â€” validators.py"> <strong>Maintenance & developer notes</strong><br><br>â€” When adding a new validation rule, add its machine code to <code>compile_error_codes</code> and include migration notes. <br>â€” Keep business-rule implementations pure; if a rule needs external reference data, require a pre-loaded read-only cache injected by the caller. <br>â€” Prefer small, focused helper functions over monolithic validators; each helper should have a unit test. <br>â€” If a performance regression appears, profile the coercion/normalization path first â€” it's the most frequently executed. <br>â€” Document any schema-driven extension points clearly (example rule signature, expected exceptions). </td></tr></tbody></table></div><div class="row-count">Rows: 20</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>