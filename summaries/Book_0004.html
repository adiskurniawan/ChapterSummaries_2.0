<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;}</style>
<link rel="stylesheet" href="assets/style.css?v=1759433634">
<link rel="stylesheet" href="assets/overrides.css?v=1759433634">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header"><div><h1>Tables Viewer v2.1</h1></div><div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" type="search" placeholder="Search" aria-label="Search tables" style="min-width:420px; width:44ch;"/>
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllMdBtn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy all tables as markdown">Copy All Tables (Markdown)</button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset all tables">Reset All Tables</button>
</div></div>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#table-1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#table-2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#table-3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#table-4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#table-5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#table-6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#table-7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#table-8">Table 8</a></li></ul></div></div>
<div class="tv-fragment" id="frag-1">
<div class="table-wrapper" data-table-id="table-1"><h3 id="table-1">Table 1</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Quotes / Examples**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Quotes / Examples</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>Algorithms are now ubiquitous</strong> — They silently operate in banks, homes, cars, hospitals, logistics, power grids. If they all stopped, civilization would grind to a halt. </td><td data-label="Supporting Details / Quotes / Examples">Quote: <em>“We live in an algorithmic society. From the thermostat that controls your furnace to the software that schedules airline crews, algorithms invisibly orchestrate our lives.”</em> Even ATMs, credit checks, and factory robots depend on algorithmic processes.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>What is an algorithm?</strong> Precise set of instructions for solving a problem; unlike a recipe, it must specify every step unambiguously.                                      </td><td data-label="Supporting Details / Quotes / Examples">Algorithms rely on fundamental logical operations: AND, OR, NOT. A single bit flip is the simplest algorithm. Complex algorithms emerge by combining these building blocks.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Recipe vs Algorithm</strong> — recipes are vague (what is a “dash of salt”?). Algorithms require precision down to the smallest unit.                                             </td><td data-label="Supporting Details / Quotes / Examples">Example: “Stir until golden brown” means nothing to a robot that cannot sense color. A cooking robot would fail without exact specifications. Algorithms must instead specify: <em>“Heat pan to 180°C, rotate stirrer at 30 rpm for 120 seconds, measure reflectance at wavelength 580nm…”</em></td></tr><tr><td data-label="Summary / Core Concepts"><strong>Tic-Tac-Toe algorithm</strong> — Example of a simple but perfect algorithm that guarantees not to lose.                                                                           </td><td data-label="Supporting Details / Quotes / Examples">Rules spelled out stepwise: <br>1. If opponent has two in a row, block. <br>2. If you can make two in a row, do so. <br>3. Otherwise, take center. <br>4. If center filled, take corner. <br>5. Otherwise, take any empty square. This rule set produces unbeatable play, demonstrating how an algorithm can be exhaustively specified.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Algorithm vs Program</strong> — Algorithms are abstract; programs are concrete realizations.                                                                                      </td><td data-label="Supporting Details / Quotes / Examples">Example: The Tic-Tac-Toe rules become a <em>program</em> once coded in Python, Java, or C. Programming adds debugging, handling of user input, formatting, error checking, optimization. The same algorithm may have many program implementations.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>The Complexity Monster</strong> — As algorithms scale up, three monsters grow: time, space, human comprehension.                                                                  </td><td data-label="Supporting Details / Quotes / Examples"><em>Time complexity</em>: algorithms differ in efficiency — sorting 1000 items with Bubble Sort (O(n²)) vs QuickSort (O(n log n)). <em>Space complexity</em>: how much memory needed. <em>Human complexity</em>: code so convoluted it cannot be understood or maintained. The book stresses that <em>“Complexity is the enemy of reliability.”</em></td></tr><tr><td data-label="Summary / Core Concepts"><strong>Machine Learning defined:</strong> algorithms that write algorithms. Instead of hand-coding rules, we feed the system data + outcomes and it generates rules itself.              </td><td data-label="Supporting Details / Quotes / Examples">Quote: <em>“Machine learning is the automation of discovery: programs that improve themselves with experience.”</em> ML replaces manual programming with statistical inference.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Analogy: Farming vs Programming</strong> — Traditional programming = hand-crafted building. ML = farming: plant seeds (data), cultivate (training), harvest (trained model).      </td><td data-label="Supporting Details / Quotes / Examples">Quote: <em>“When we farm, we do not design each ear of corn. We create conditions for growth. Machine learning works the same way.”</em> Data = soil, algorithm = seed, computing resources = water and fertilizer.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Explosion of data fuels ML</strong> — Sensors, cameras, smartphones, transaction records, satellites provide torrents of data.                                                    </td><td data-label="Supporting Details / Quotes / Examples">Examples: social networks generate billions of posts per day; GPS and IoT sensors stream continuous data. “Just add data” principle: better results with more examples, even if algorithm is simple.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Economics & Competition</strong> — Firms that exploit ML dominate markets.                                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">Examples: Google vs Yahoo in ad prediction; Amazon’s product suggestions drive sales; Netflix recommendations based on collaborative filtering; Facebook’s News Feed ranking. Winner-take-all dynamics emerge because more users → more data → better models → more users.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Case: Obama 2012 campaign</strong> — Used ML to target voters with unprecedented precision.                                                                                       </td><td data-label="Supporting Details / Quotes / Examples">Campaign built individual voter models from demographic + behavioral data, predicting who was persuadable. Resources were directed to “persuadable swing voters,” improving efficiency of canvassing and ads. Quote: <em>“The campaign built millions of voter dossiers, then simulated election outcomes millions of times a day.”</em></td></tr><tr><td data-label="Summary / Core Concepts"><strong>Robot scientist “Adam”</strong> — University of Manchester, 2000s. First robot to autonomously generate hypotheses, design experiments, execute, analyze, and learn.              </td><td data-label="Supporting Details / Quotes / Examples">Adam studied yeast genes. It hypothesized functions of orphan genes, designed growth experiments, executed them using lab robotics, analyzed results, updated its hypotheses. It successfully identified genes encoding certain enzymes — without human intervention.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Risks: opacity & bias</strong> — ML systems can behave unpredictably, reflecting dataset biases.                                                                                  </td><td data-label="Supporting Details / Quotes / Examples">Example: self-driving cars mistaking plastic bags for animals. Example: image recognition misclassifying minorities due to biased training data. Quote: <em>“Learning systems can inherit the prejudices of their data, reinforcing unfairness.”</em></td></tr><tr><td data-label="Summary / Core Concepts"><strong>Political & social effects</strong> — ML transforms governance, elections, surveillance.                                                                                          </td><td data-label="Supporting Details / Quotes / Examples">Predictive policing directs police disproportionately to minority neighborhoods; social media ML amplifies polarization by optimizing engagement. Cambridge Analytica scandal later highlighted dangers of psychometric targeting.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Privacy & Concentration of power</strong> — Data is a strategic asset. Whoever controls massive datasets gains dominance.                                                         </td><td data-label="Supporting Details / Quotes / Examples">Example: Google’s data on search queries reveals intimate patterns; Facebook knows social graphs and behavior. This concentration leads to monopolistic tendencies.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Interpretability challenge</strong> — Unlike Tic-Tac-Toe rules, ML models are often inscrutable black boxes.                                                                      </td><td data-label="Supporting Details / Quotes / Examples">Deep neural networks with millions of parameters are not human-interpretable. This complicates accountability: <em>“If an algorithm denies you a mortgage, can anyone explain why?”</em></td></tr><tr><td data-label="Summary / Core Concepts"><strong>Future trajectory</strong> — Recursive self-improvement possible: ML used to improve ML itself.                                                                                   </td><td data-label="Supporting Details / Quotes / Examples"><em>“When learning systems are deployed to discover new learning systems, progress can accelerate beyond human comprehension.”</em> Anticipated effects: AI developing new scientific theories, automating engineering, designing new drugs.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Governance needed</strong> — Ethical and policy challenges require foresight.                                                                                                     </td><td data-label="Supporting Details / Quotes / Examples">Risks include job displacement, algorithmic discrimination, runaway financial trading, autonomous weapons. Recommendations: regulation, transparency, audit trails, algorithmic accountability.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Broader reflection</strong> — ML is not just another technology; it is a meta-technology, automating the creation of new technologies.                                            </td><td data-label="Supporting Details / Quotes / Examples"><em>“Machine learning is a general-purpose method of invention. To control it wisely may be the most important governance challenge of our era.”</em></td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-2">
<div class="table-wrapper" data-table-id="table-2"><h3 id="table-2">Table 2</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Quotes / Examples**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Quotes / Examples</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>Thesis — a single, universal learner (the “Master Algorithm”) could in principle induce all useful knowledge from data.</strong>                                                                                                                                                            </td><td data-label="Supporting Details / Quotes / Examples">The chapter opens with the central hypothesis: <em>All knowledge—past, present, and future—can be derived from data by a single, universal learning algorithm.</em> If such an algorithm exists, it would be the “Master Algorithm” capable of learning vision from video, reading from libraries, and discovering physics from experiments. This claim is defended by three converging arguments (neuroscience, evolution, and physics). </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Why one algorithm matters:</strong> Machine learning already uses very few algorithms to solve many tasks; the same learners (Naïve Bayes, nearest-neighbor, decision trees, Bayesian networks) power spam filters, medical diagnosis, handwriting recognition, and recommendation systems. </td><td data-label="Supporting Details / Quotes / Examples">Examples given: Naïve Bayes can take patient records and learn diagnoses; the same algorithm family can learn spam filtering. Nearest-neighbor methods have been used for handwriting recognition, robot control, and recommender systems. Decision trees decide credit applications, find DNA splice junctions, and pick chess moves—showing that a few simple learners account for most applications. The chapter asks: could we push this economy of algorithms to its limit—a single algorithm that, given the right data and modest assumptions, learns everything? </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Universality caveat — “enough data” and assumptions:</strong> Major learners are universal in the sense they can approximate any function given infinite data; with finite data we must encode assumptions, and different learners embody different inductive biases.                       </td><td data-label="Supporting Details / Quotes / Examples">The text explains the tradeoff: universality requires either infinite data or embedding assumptions. Practical learning requires assumptions (priors, model classes). The Master Algorithm thesis asks how weak those assumptions can be while still recovering relevant knowledge from finite, real-world data. The book frames this as discovering the deepest regularities of our universe and computationally efficient ways to combine them with data. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Argument from neuroscience — the brain looks like one learner wired to different inputs.</strong>                                                                                                                                                                                           </td><td data-label="Supporting Details / Quotes / Examples">Rewiring experiments (MIT, April 2000): directing visual inputs to auditory cortex caused that cortex to process visual maps; auditory cortex learned to “see.” Similarly, visual cortex can take over somatosensory roles; in congenitally blind people the visual cortex repurposes for other senses. The cortex’s repeating microcircuitry (six layers, columns, recurrent loops, consistent inhibitory/excitatory patterns) suggests a common learning algorithm instantiated with different parameters and inputs. In short: the brain appears to implement a single, highly general learning procedure applied to varied modalities. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Neuroscience implies an engineering route: reverse-engineer the brain.</strong>                                                                                                                                                                                                             </td><td data-label="Supporting Details / Quotes / Examples">If the brain is indeed a universal learner, implementing its algorithm in silicon could approximate our learning capabilities. The chapter cites Jeff Hawkins and Ray Kurzweil as proponents of this route. It also notes caution: the brain is phenomenally complex and reverse engineering it is hard; but if successful it would be a direct path to the Master Algorithm. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Argument from evolution — evolution is itself an algorithm that “learned” life.</strong>                                                                                                                                                                                                    </td><td data-label="Supporting Details / Quotes / Examples">Evolution is framed as an iterative search algorithm: generate variants, select the fittest, repeat. Darwinian search produced enormous complexity (endless forms most beautiful) from simple rules applied over billions of years. The chapter notes that if an evolutionary algorithm running on Earth produced humans and all biological complexity, then simulating or re-implementing analogous search processes on powerful computers suggests another possible route to a universal learner. Evolution demonstrates how much a simple mechanism can realize given massive computation and data (Earth’s environmental history). </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Evolution vs brain — complementary pathways:</strong>                                                                                                                                                                                                                                       </td><td data-label="Supporting Details / Quotes / Examples">The book positions evolution and brain-like learning as two promising but distinct routes: evolution is slow but explosive given huge search, while the brain demonstrates efficient, sample-efficient learning in a lifetime. The Master Algorithm may combine elements of both (nature + nurture): the best universal learner might hybridize iterative search with powerful inductive structures learned from data. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Argument from physics & mathematical regularities — the world obeys compact laws that a universal learner could exploit.</strong>                                                                                                                                                           </td><td data-label="Supporting Details / Quotes / Examples">Wigner’s “unreasonable effectiveness of mathematics” is invoked: why do simple mathematical laws describe complex phenomena? If nature’s behaviors are generated by a few underlying regularities, a Master Algorithm need only find those regularities as shortcuts that replace lengthy derivations. The chapter points to universality in physics and the recurrence of similar equations across domains as evidence that a single learning mechanism could generalize widely. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Optimization as a unifying idea:</strong> Many scientific problems reduce to optimization; different domains optimize different objective functions under constraints.                                                                                                                      </td><td data-label="Supporting Details / Quotes / Examples">The chapter explains that optimization recurs from physics (principles like least action) to biology (evolution optimizing fitness) to economics (firms maximizing profit). If the world is largely solutions to layered optimization problems, a general learner that discovers effective optimization mappings could capture vast swathes of knowledge. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Practical limits — computational efficiency & inductive bias tradeoffs:</strong>                                                                                                                                                                                                            </td><td data-label="Supporting Details / Quotes / Examples">Even if universality holds in principle, doing it efficiently matters. The Master Algorithm might be less efficient than specialized learners; it may require more data. The book asks how weak the inductive assumptions can be while still enabling learning from finite, noisy, real-world datasets—this is the core technical challenge. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Concrete learner types surveyed (context for later chapters):</strong>                                                                                                                                                                                                                      </td><td data-label="Supporting Details / Quotes / Examples">The chapter previews the main learner families explored throughout the book: symbolists (inverse deduction), connectionists (neural nets), evolutionaries (genetic algorithms), Bayesians (probabilistic inference), and analogizers (nearest-neighbor). Each family embodies distinct assumptions and strengths; the Master Algorithm might unify or subsume these approaches. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Examples that illustrate breadth & simplicity:</strong>                                                                                                                                                                                                                                     </td><td data-label="Supporting Details / Quotes / Examples">Short learners can replace massive handcrafted programs: many learners fit into a few hundred or thousand lines of code versus the hundreds of thousands of lines of hand-coded systems they replace. The chapter emphasizes surprise: simple learner families can induce an unlimited number of different programs given data. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Empirical signposts & evidence:</strong>                                                                                                                                                                                                                                                    </td><td data-label="Supporting Details / Quotes / Examples">Rewiring experiments, cross-species cortical similarity, success of simple learners in industry (spam filters, recommender systems), and wide applicability of mathematical physics are presented as converging evidence. None is decisive alone, but together they suggest the plausibility of a Master Algorithm. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>What “assumptions” might be allowed as input?</strong>                                                                                                                                                                                                                                      </td><td data-label="Supporting Details / Quotes / Examples">The book proposes constraining the Master Algorithm by limiting the strength of assumptions—e.g., restricting the complexity or expressiveness of priors so that the algorithm can’t be handed the answer. The challenge is formalizing useful but weak inductive biases that permit learning from realistic finite datasets. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Philosophical & practical implications if the Master Algorithm is realized:</strong>                                                                                                                                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">Inventing it would be a watershed: “the last thing we’ll have to invent” in the sense that it could then discover remaining inventions by learning from data. Given a universal learner, providing the right data could generate vision, language, physics, and biology knowledge—the book frames this as the route to sweeping automation of scientific and engineering discovery. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Caveats & humility:</strong>                                                                                                                                                                                                                                                                </td><td data-label="Supporting Details / Quotes / Examples">The chapter stresses caution: the brain is messy, evolution is slow, and there are computational constraints. The Master Algorithm is a strong hypothesis, not a proven theorem. Practical realization could be centuries away or take unexpected hybrid forms; yet the hypothesis is valuable as a unifying research target. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Closing: the road map for the book</strong>                                                                                                                                                                                                                                                 </td><td data-label="Supporting Details / Quotes / Examples">The remainder of the book explores the five tribes of machine learning (symbolists, connectionists, evolutionaries, Bayesians, analogizers), evaluates their inductive biases and strengths, and searches for a synthesis that could realize the Master Algorithm. The chapter ends by inviting the reader to examine the evidence, hold an open mind, and consider both engineering and philosophical consequences. </td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-3">
<div class="table-wrapper" data-table-id="table-3"><h3 id="table-3">Table 3</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Notes**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Notes</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary"><strong>Emotions as Biological Intelligence</strong>                                 </td><td data-label="Notes">The CEO had climbed from summer intern to the head of a corporation generating half a trillion dollars in revenue. Despite his success, he realized his team—managers, employees, and C-suite—relied on data and metrics, not intuition. Traditional EQ courses failed to instill change, highlighting a gap between logical understanding of emotion and its biological function.</td></tr><tr><td data-label="Summary"><strong>EQ vs Biological Emotion</strong>                                            </td><td data-label="Notes">EQ teaches identifying others’ emotions through analogies to personal experiences, e.g., “That man is scared; I can empathize.” However, behavior rarely changes because human brains evolved to use emotion internally to monitor and correct mental life narratives, not just to read others. The CEO remained frustrated: empathy alone did not improve communication, decision-making, or strategic execution.</td></tr><tr><td data-label="Summary"><strong>Singletons: Emotion-Driven Self-Assessment</strong>                          </td><td data-label="Notes">Lucy Gray, a Special Operations singleton, exemplifies mastery of self-assessment through “feel.” She operates solo in hostile environments, adjusting plans instantly based on emotional feedback rather than pre-defined metrics. Gray’s decision-making relies on an internal sensor: when “feel” indicates wrongness, she adapts; when it indicates rightness, she commits. Her biological system constantly checks the alignment of her actions with her narrative objectives.</td></tr><tr><td data-label="Summary"><strong>Mental Life Narrative & Emotion</strong>                                     </td><td data-label="Notes">Optimal mental narratives integrate past experiences and allow future options to branch. Emotions signal deviations, acting as feedback loops for course correction. Visual example (image\page\53): past integrated, future branching. Emotions serve as early-warning systems, flashing alerts when plans or intentions diverge from desired trajectories.</td></tr><tr><td data-label="Summary"><strong>Fear as Smart Biological Warning</strong>                                    </td><td data-label="Notes">Fear evolved not as irrational, but as a mechanism to indicate absence of a plan or strategy. It triggers action, learning, and receptiveness to guidance, especially when immediate options are unclear. If plans fail or are absent, fear signals: “You have passed beyond the edge of your intelligence and risk being captive to events.” Children’s boldness allows exploration; fear keeps them receptive to adult guidance.</td></tr><tr><td data-label="Summary"><strong>Combat Example: Horizon-Focus</strong>                                       </td><td data-label="Notes">Operators trapped in fear boxes extend their gaze to the horizon to regain situational awareness, analogous to recalling strategic objectives in modern life. Narrow vision caused by fear contracts options. Looking beyond the immediate threat expands future possibilities, enabling exit from panic and recovery of initiative.</td></tr><tr><td data-label="Summary"><strong>First-Step Plan</strong>                                                     </td><td data-label="Notes">The “first-step plan” is a concrete, initial action under stress that restores agency. Visualization of tangible objectives (e.g., “write a novel,” “launch product”) primes the brain for rapid execution. Medal of Honor recipient recalled target under mortal threat, moving decisively; similar approach works for executives and children under stress. Abstract goals (“success”) are ineffective compared to concrete goals.</td></tr><tr><td data-label="Summary"><strong>Anger as Focused Execution</strong>                                          </td><td data-label="Notes">Anger signals a single viable plan and drives assertive execution, focusing the brain on the one actionable path. Fear narrows gaze; anger constricts future options to one branch. Operators, paramedics, and leaders report that anger energizes action and intensifies focus during crises.</td></tr><tr><td data-label="Summary"><strong>Operational Flexibility & Second Plans</strong>                              </td><td data-label="Notes">Anger’s benefits are maximized when paired with second-plan flexibility. Recognizing exceptional information generates alternative paths, reducing risk and enhancing outcomes. Operators gather exceptional intelligence to create backup options. Recalling previous successful improvisations (“hasty plans”) releases intuition and reduces over-aggression.</td></tr><tr><td data-label="Summary"><strong>Emotion Reset</strong>                                                       </td><td data-label="Notes">Emotion Reset calms anger by recalling prior adaptive responses under stress, allowing intuitive decision-making. Professionals (traders, first responders, managers) reduce stress impact by reflecting on past problem-solving successes. Example: recalling improvisation under pressure restores confidence.</td></tr><tr><td data-label="Summary"><strong>Grief & Shame: Indicators of Past Fracture</strong>                          </td><td data-label="Notes">Grief signals unresolved trauma; shame signals misalignment with values or social norms. Both fragment narrative coherence, weakening energy, strategic purpose, and effectiveness. Primordial story: “I am a good person in a good world.” Fractures produce dual narratives ([good/bad person], [good/bad world]), dispersing energy.</td></tr><tr><td data-label="Summary"><strong>Managing Grief & Shame</strong>                                              </td><td data-label="Notes">Identify the source: for grief, reconcile past traumatic events with overall purpose; for shame, distinguish between social judgment and misalignment with personal path. Use overarching purpose to guide corrective action. Reflection transforms negative experiences into learning; addressing grief/shame in advance prevents emotional paralysis during crises.</td></tr><tr><td data-label="Summary"><strong>Dumb Pride: Internal Validation</strong>                                     </td><td data-label="Notes">Dumb pride celebrates past actions the world deems foolish but personally meaningful. It signals alignment with one’s true mission and reinforces autonomy. Lucy Gray reflects on military decisions others might see as reckless but personally fulfilling. Childhood example: refusing to sit on an unsafe bus demonstrates instinctive alignment with self-directed purpose.</td></tr><tr><td data-label="Summary"><strong>Maverick Gratitude: Recognition of Purpose</strong>                          </td><td data-label="Notes">Gratitude that matters is the recognition of advancing personal mission rather than social expectation. It validates the fight undertaken against odds or norms. Medals or formal recognition may be disregarded; small, unexpected thanks can emotionally resonate, guiding future actions and persistence.</td></tr><tr><td data-label="Summary"><strong>Primal Intelligence: Integration of Emotion, Intuition, Imagination</strong> </td><td data-label="Notes">Emotion diagnoses current or past failures; intuition and imagination generate potential “what if” strategies. External environment and commonsense evaluation determine which actions to pursue. Pre-mission mental rehearsal, historical reflection, and proactive anticipation of setbacks help mitigate panic, shame, or grief, enabling deliberate, adaptive responses.</td></tr><tr><td data-label="Summary"><strong>Emotion as a Diagnostic Tool</strong>                                        </td><td data-label="Notes">Negative signals (fear, anger, grief, shame) indicate plan failure or misalignment; positive signals (pride, gratitude) point to effective actions aligned with purpose. Use these signals proactively: envision future steps and review past experiences to anticipate stressors, maintaining clarity and momentum.</td></tr><tr><td data-label="Summary"><strong>Synthesis: Emotional Intelligence as Internal Compass</strong>               </td><td data-label="Notes">Emotional intelligence is internal, not merely social. It functions as a compass for strategic, adaptive action, guiding the individual through uncertainty and reinforcing personal growth. Fear → first-step plans; anger → operational flexibility; grief/shame → narrative repair; dumb pride/maverick gratitude → mission alignment. Together, they sustain initiative, resilience, and purpose-driven action.</td></tr><tr><td data-label="Summary"><strong>Practical Recommendations</strong>                                           </td><td data-label="Notes">1. Before action, identify primary objective and visualize first-step plan.<br>2. Reflect on past adaptive actions to enable Emotion Reset.<br>3. Track negative signals to preempt failures.<br>4. Use pride and gratitude to confirm personal purpose.<br>5. Integrate emotion, intuition, imagination, and commonsense for complex decisions.<br>Executives, military operators, children, and professionals alike can apply these methods. Example: stress-box at work → recall long-term strategy, identify tangible first step, act, then adjust iteratively.</td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-4">
<div class="table-wrapper" data-table-id="table-4"><h3 id="table-4">Table 4</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Quotes / Examples**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Quotes / Examples</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>Opening claim — learning is wiring: “neurons that fire together wire together.”</strong>                                                                                                                                                                       </td><td data-label="Supporting Details / Quotes / Examples">Donald Hebb’s rule: <em>“When an axon of cell A is near enough cell B and repeatedly or persistently takes part in firing it, some growth process… takes place… A’s efficiency… is increased.”</em> The chapter frames connectionism around this simple association principle and uses it as the mechanistic core for distributed representations. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Connectionist vs symbolist representations:</strong> Brains use distributed representations (cell assemblies) where each concept is stored across many neurons; symbolist systems store one-to-one symbol locations.                                           </td><td data-label="Supporting Details / Quotes / Examples">In a connectionist model “the answer is ‘it’s stored a little bit everywhere.’” Cell assemblies overlap (e.g., “leg” overlaps “foot”); this supports robustness and generalization but complicates pinpointing where any single concept “is.” </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Brains = massively parallel, low-frequency components vs computers = serial, high-frequency components.</strong>                                                                                                                                               </td><td data-label="Supporting Details / Quotes / Examples">Neurons fire at \~1kHz max while transistors switch billions of times per second; brains compensate via massive connectivity (each neuron thousands of synapses) enabling rich parallelism and associative search in \~0.1s for face recognition—scanning memory, matching, and adapting to context quickly. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Perceptron: the first formal neuron model — linear separators and limits.</strong>                                                                                                                                                                             </td><td data-label="Supporting Details / Quotes / Examples">McCulloch–Pitts neurons modeled logic gates; Rosenblatt’s perceptron added learnable weights and thresholding to detect linearly separable patterns. Perceptrons map inputs to hyperplanes; they can learn many tasks but fail on nonlinearly separable problems (XOR), revealing a crucial limitation. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>The perceptron’s promise and the Minsky–Papert critique:</strong> Early excitement around perceptrons (pattern recognition) crashed when <em>Perceptrons</em> showed fundamental limits—no method then existed to train hidden layers, producing a research slowdown. </td><td data-label="Supporting Details / Quotes / Examples">Minsky & Papert’s demonstration that perceptrons cannot learn XOR (no linear separator) convinced many funders and researchers to favor knowledge engineering over learning for nearly two decades. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Credit-assignment problem:</strong> Learning deep, layered models requires assigning “blame” or credit to hidden units — who changed to cause an error?                                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">In multilayer networks each hidden neuron influences outputs via many paths; earlier methods couldn’t adjust hidden weights effectively because errors at output didn’t clearly attribute responsibility to internal units. Solving credit assignment is central to scalable learning. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Spin-glass & statistical physics revival (Hopfield):</strong> Analogies between spin glasses and neural networks opened new ways to analyze learning and memory as energy landscapes with attractors.                                                          </td><td data-label="Supporting Details / Quotes / Examples">Hopfield mapped networks to energy-minimizing dynamical systems: memories = low-energy attractors with basins of attraction; distorted inputs relax into nearest memory. This connection drew physicists into ML and suggested rigorous tools for studying networks. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Boltzmann machines & stochastic networks:</strong> Introducing probabilistic neurons and “dreaming” phases gave an algorithmic route to learn internal representations by matching day/night statistics.                                                       </td><td data-label="Supporting Details / Quotes / Examples">Boltzmann machines alternate waking (driven by data) and sleeping (free dynamics) phases; weight updates push model-generated statistics toward data statistics. This solved credit-assignment in principle by using global statistical matching, but was slow in practice. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Backpropagation: the practical breakthrough for deep learning.</strong>                                                                                                                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">Replace binary step functions with smooth S-curves (sigmoids) so errors become differentiable; propagate error gradients backward through layers and update weights via gradient descent. This allowed multilayer networks to learn complex, highly non-linear functions, making backprop the connectionists’ effective master algorithm. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>S-curve (sigmoid) as the “most important curve”:</strong> Smooth activation functions turn all-or-none signals into graded signals that permit gradient-based credit assignment.                                                                               </td><td data-label="Supporting Details / Quotes / Examples">The logistic/S curve models neuron firing probability / frequency as a continuous function of input voltage; this continuity yields meaningful error magnitudes (how wrong/how right) that can be propagated inward to update hidden weights. The chapter emphasizes the ubiquity of S-curves (phase transitions, learning curves, adoption curves) as a modeling motif. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Gradient descent & local minima:</strong> Backprop uses gradient methods (climb/descend slopes), but hyperspace contains many local minima; initial conditions and architecture matter.                                                                        </td><td data-label="Supporting Details / Quotes / Examples">A small network may converge to global optimum, but high-dimensional networks can get stuck in poor local minima (backprop can roll into a bad valley). Practical training uses heuristics (random restarts, momentum, regularization, large datasets) to mitigate but not eliminate this challenge. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Computational tradeoffs: connectivity vs speed vs energy:</strong> A computer can simulate high connectivity with speed but at energy cost; brains are energy-efficient—simulating them requires much more power.                                              </td><td data-label="Supporting Details / Quotes / Examples">The brain’s wiring is dense and nonplanar; chips are planar and have sparser direct connectivity. Simulation trades time for wiring: reuse wires many times but consume energy. The brain’s efficiency (small lightbulb power) contrasts with large datacenter costs for comparable simulation. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>From models to practice: early neural nets recognized letters/speech but then hit practical learning roadblocks; physics and new algorithms reignited research.</strong>                                                                                       </td><td data-label="Supporting Details / Quotes / Examples">Despite perceptron successes (letters, speech), Minsky–Papert stalled progress; Hopfield’s physics perspective and Hinton/Ackley/Sejnowski’s probabilistic models (and later backprop) reawakened connectionism into a dominant paradigm. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Role of stochasticity and sleep/dream phases:</strong> Probabilistic dynamics (Boltzmann machines) invoked learning by contrasting waking vs dreaming statistics — an appealing biological metaphor.                                                           </td><td data-label="Supporting Details / Quotes / Examples">During “wake” the network matches sensory-driven statistics; during “sleep” it samples free dynamics; weight adjustments reduce divergence. This dream/awake contrast aligns with hypotheses about biological sleep’s role in consolidation and replay. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>S-curves and phase transitions: how sudden qualitative change emerges from gradual parameter shifts.</strong>                                                                                                                                                  </td><td data-label="Supporting Details / Quotes / Examples">The logistic/S curve models many phenomena: neuron firing rates, technology adoption, learning progress, and phase transitions. The book uses S-curves to explain why progress appears slow then suddenly rapid (and why exponential growth often plateaus). Understanding S-curves helps temper expectations about singularities and informs training/regime-change strategies. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Practical implications for ML engineers & neuroscientists:</strong> Use distributed representations, smooth activations, gradient-based optimization, and probabilistic modeling while being mindful of energy, connectivity, and local optima.                </td><td data-label="Supporting Details / Quotes / Examples">The chapter’s engineering takeaway: emulate the brain’s representational principles (distributed assemblies, overlapping codes), adopt continuous activations for learnability, and expect to combine statistical physics insights with algorithmic heuristics to scale learning in practice. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Closing orientation:</strong> Chapter 4 shows how connectionist ideas matured to solve the credit-assignment problem, setting the stage for deep learning’s later practical successes; it also cautions about limits and tradeoffs.                            </td><td data-label="Supporting Details / Quotes / Examples">The narrative arc: Hebb → perceptron → Minsky critique → Hopfield/Boltzmann revival → backprop/S-curve → gradient methods and practical heuristics. This technical history explains why current deep methods work and where their vulnerabilities originate. </td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-5">
<div class="table-wrapper" data-table-id="table-5"><h3 id="table-5">Table 5</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Quotes / Examples**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Quotes / Examples</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>Thought experiment — “Robotic Park”:</strong> Robots evolve in a walled enclosure; best performers spawn through 3D printers; invisible wall, sentries, danger, survival, death — evolution optimized for “deadliness” or fitness.         </td><td data-label="Supporting Details / Quotes / Examples"><em>“Robotic Park is a massive robot factory surrounded by ten thousand square miles of jungle… the winning robots get to spawn, their reproduction accomplished by programming the banks of 3-D printers inside.”</em> The park’s inhabitants, millions of robots battling for survival and control, illustrate evolution’s pressures and fitness selection.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Definition & origins of Darwin’s Algorithm:</strong> Nature’s process (variation, selection, reproduction) recast as algorithm; John Holland formulated genetic algorithms building on Fisher’s statistical foundations.                   </td><td data-label="Supporting Details / Quotes / Examples">Holland read Fisher’s <em>The Genetical Theory of Natural Selection</em>; saw that genes interacting produce complex fitness functions; he formalized algorithms mimicking selection, mutation, crossover. Evolutionary computation emerges.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Genetic algorithms:</strong> Key mechanisms (mutation, crossover, fitness functions, reproduction) operate on program representations; highly parallel search across populations rather than single hypothesis.                            </td><td data-label="Supporting Details / Quotes / Examples">Example: each candidate program is encoded as a string of bits; “fitness function” scores correctness (e.g. spam filter accuracy); reproduction via mutation/crossover; better solutions emerge over generations.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Building blocks and schemas:</strong> Genetic algorithms exploit schemas—subsets of bits that encode useful features—and crossover recombines them; this allows genetic algorithms to explore exponentially many schemata implicitly.      </td><td data-label="Supporting Details / Quotes / Examples">Explanation: string bits, schemas represented with “<em>” placeholders; e.g. schemas like </em>10 or 11* represent large sets of programs; fitter schemas increase in frequency, enabling efficient search through structures.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Evolutionary vs neural learning contrast:</strong>                                                                                                                                                                                         </td><td data-label="Supporting Details / Quotes / Examples">- Backprop (connectionist) searches within parameter space of fixed architectures; genetic evolves structure + parameters. <br> <br>- Genetic algorithms consider populations of hypotheses; make big jumps via crossover; better at exploration but more computationally expensive. <br> <br>- Backprop is smoother, more local; genetic algorithms offer greater variation and innovation potential.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>The exploration–exploitation dilemma:</strong> Evolutionary methods must balance continuing to exploit high-fitness individuals vs exploring new, potentially better ones.                                                                 </td><td data-label="Supporting Details / Quotes / Examples">Examples: slot machine metaphor; in genetic algorithms sometimes mutation or crossover provides stepping stones off local maxima. The higher the current peak, the harder to leave without exploration.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>The Baldwin Effect:</strong> Learning in individuals can guide evolution; traits that were once learned can become instinctual over generations.                                                                                           </td><td data-label="Supporting Details / Quotes / Examples">Example: neural learning + genetic structure search: organisms that learn quickly have evolutionary advantage; traits shift from learned to inherited. Geoff Hinton & Steven Nowlan demonstrated this effect computationally: when evolution allows learning, overall fitness improves faster than with fixed structures.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Limits & criticisms of evolution-based methods:</strong>                                                                                                                                                                                   </td><td data-label="Supporting Details / Quotes / Examples">- Genetic algorithms are slow and resource-intensive. <br> <br>- Crossover sometimes disrupts useful building blocks. <br> <br>- Many successes are shallow or small-scale; large-scale program trees tend to bloat. <br> <br>- In comparison, hill-climbing methods often match or outperform GA for certain circuit design tasks.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Case studies & historical results:</strong>                                                                                                                                                                                                </td><td data-label="Supporting Details / Quotes / Examples">- Samuel Koza’s genetic programming: evolving program trees, electronic circuits, symbolic functions; “humie awards.” <br> <br>- ICML 1995: hill climbing beating genetic programming on Boolean circuit problems. <br> <br>- Evolved robot designs from simulation to real world via 3D printing in experiments.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Nature vs Nurture reinterpreted:</strong> Structural priors (evolved architectures) and learning (data, experience) both matter; evolution builds brain architecture, learning fills in with data. This alternation shapes performance.    </td><td data-label="Supporting Details / Quotes / Examples">E.g. evolved cortical structure in sensory areas for visual feature extraction; subsequent training with raw image data refinements. Evolution sets priors; learning sets parameters.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Genetic programming & program trees:</strong> Representing programs not as bit strings but trees (with subtrees crossed over), enabling more natural code evolution; operations like “if-then,” loops, recursion allowed.                  </td><td data-label="Supporting Details / Quotes / Examples">Example: evolving a program to compute planetary orbital period via tree operations (multiplication, square root) joining subtrees. Genetic programming can re-invent known mathematical relationships given correct representation and data.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Practical takeaways for ML design:</strong>                                                                                                                                                                                                </td><td data-label="Supporting Details / Quotes / Examples">- Use population-based search when exploring structure matters. <br> <br>- Incorporate both mutation and recombination where possible. <br> <br>- Maintain diversity in the population to avoid premature convergence. <br> <br>- Combine evolutionary structure search with parameter learning (backprop, Bayesian methods).</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Caution: evolution’s “messy” solutions:</strong> Nature is constrained: architectures are often imperfect (optic nerve blind spot, developmental messiness). Just because something evolved doesn’t make it the most efficient or elegant. </td><td data-label="Supporting Details / Quotes / Examples">Example: the mammalian retina's blind spot is a byproduct of evolutionary wiring; developmental biology has many non-optimized, kludgy mechanisms. Machine learners might invent cleaner designs.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>The speed imperative:</strong> Evolution is slow; neural learning is faster; culture and technology accelerate learning much further; Master Algorithm desires learning in seconds/minutes not generations/millennia.                      </td><td data-label="Supporting Details / Quotes / Examples">Quote: <em>“He who learns fastest wins, whether it’s the Baldwin effect speeding up evolution… or computers discovering patterns at the speed of light.”</em> Learning rate becomes central metric.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Hybrid learning algorithms:</strong> Combining evolution and brain-like learning may yield better learners: structure search + parameter learning, crossover + gradient descent, evolutionary priors feeding into neural nets.             </td><td data-label="Supporting Details / Quotes / Examples">The chapter argues that neither pure evolution nor pure neural methods suffice; hybrids (evolutionary structure plus parameter fine-tuning) seem promising.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Closing: evolution’s lessons for the Master Algorithm project:</strong>                                                                                                                                                                    </td><td data-label="Supporting Details / Quotes / Examples">The evolutionary paradigm shows how good learners can arise via variation + selection; shows importance of fitness functions; warns of tradeoffs between exploration and exploitation; highlights role of structural prior; and foreshadows that a Master Algorithm will likely adopt evolutionary ideas.</td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-6">
<div class="table-wrapper" data-table-id="table-6"><h3 id="table-6">Table 6</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Quotes / Examples**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Quotes / Examples</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>What the Analogizer tribe is</strong> — Learners who use similarity judgments: classify new items based on how similar they are to past examples.                                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">The analogizers encompass methods like nearest-neighbor, support vector machines, kernel machines, and more broadly all “learning by analogy.” In Domingos’s taxonomy, they are less cohesive than other tribes but united by reliance on similarity. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Key algorithm examples</strong> — Nearest-neighbor as prototype; SVMs as more sophisticated analogizers.                                                                                                                                                 </td><td data-label="Supporting Details / Quotes / Examples">Nearest-neighbor: simply find the closest labeled example to make predictions. Support Vector Machines: advanced analogizers that find decision boundaries maximizing margins, often in high-dimensional feature spaces. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>When analogical learning works well</strong> — Helpful in domains where similarity metrics are meaningful and there is enough data to store and compare examples.                                                                                        </td><td data-label="Supporting Details / Quotes / Examples">For tasks like image recognition, recommendation systems (“people similar to you liked this”), or link prediction, analogizers shine especially when feature extraction is good and when examples are abundant. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Advantages of analogizers</strong> — Intuitive, often simple, can start working with modest assumptions, often strong when new instances are near known instances.                                                                                       </td><td data-label="Supporting Details / Quotes / Examples">Because they don’t necessarily build heavy models, they’re robust in irregular, noisy settings; can capture fine-grained distinctions based on example similarity. May require little feature engineering beyond a good metric. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Challenges and limitations</strong> — Curse of dimensionality; inefficient at test-time; similarity metric choice matters a lot; generalization beyond stored examples is weak.                                                                          </td><td data-label="Supporting Details / Quotes / Examples">Nearest-neighbor’s prediction time may grow linearly with stored data (scanning many examples). In high dimensions (“many features”), distance metrics become less discriminative (“everything looks equally distant”). Choosing a bad metric degrades performance sharply. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Role in the Master Algorithm thesis</strong> — Analogizers offer a slice of what a universal learner must do: use similarity, generalize from few examples, adapt quickly.                                                                               </td><td data-label="Supporting Details / Quotes / Examples">Domingos suggests that the Master Algorithm will likely borrow from analogizers—perhaps integrating nearest-neighbor-like components or similarity kernels—especially for tasks where new, rare instances appear and data for them is sparse. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Hybridizing analogizers with other methods</strong> — Combining similarity-based learning with Bayesian priors, neural architectures, kernel methods, or evolutionary searches to improve performance.                                                   </td><td data-label="Supporting Details / Quotes / Examples">For instance, kernel methods embed similarity judgments implicitly in high-dimensional feature spaces; SVMs combine margin maximization (geometric bias) with kernel tricks. One can imagine analogizer modules inside larger architectures. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Real-world applications & analogizing</strong> — Recommendations, classification, clustering, anomaly detection.                                                                                                                                         </td><td data-label="Supporting Details / Quotes / Examples">Netflix/Amazon recommendations (“if you liked this, you’ll like that”) are analogizer use cases. Face recognition can use distance in embedding space. Clustering similar patients in medical datasets to predict outcomes. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Similarity measurement: crucial design decision</strong> — The choice of metric (Euclidean, cosine, learned embedding, kernel) often determines success.                                                                                                 </td><td data-label="Supporting Details / Quotes / Examples">If embedding is poor, “similar” may mean irrelevant. Metric learning becomes important: methods that learn distance functions so that similar items are close, dissimilar far. SVMs implicitly do this via kernel design; other analogizers explicitly learn metrics. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Memory and computation trade-offs</strong> — Storing many examples uses memory; comparing to many examples costs time; approximation + indexing techniques are needed.                                                                                   </td><td data-label="Supporting Details / Quotes / Examples">KD-trees, ball trees, locality sensitive hashing (LSH) help speed nearest-neighbor queries. Support Vector Machines reduce dependency on raw example storage by summarizing with support vectors. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Generalization outside stored examples</strong> — Extrapolation vs interpolation: analogizers better at interpolation (new cases close to known examples) but struggle with dramatically new cases unless metric or features capture relevant structure. </td><td data-label="Supporting Details / Quotes / Examples">Example: nearest‐neighbor will misclassify a novel type if no close stored example exists. SVM kernels can help if kernel encodes relevant features. Hybrid learners are needed to extrapolate. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Scaling analogizers</strong> — Strategies to make them efficient & robust in big data settings: compressed storage, approximate nearest-neighbor, kernel approximations.                                                                                 </td><td data-label="Supporting Details / Quotes / Examples">Methods include LSH, product quantization, dimensionality reduction, embedding techniques (Word2Vec, etc.), support vector machine approximations (kernel trick, random Fourier features). </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Evaluation & model selection</strong> — Need cross-validation, hold-out examples, and careful metric evaluation since similarity methods risk overfitting to the metric or features.                                                                     </td><td data-label="Supporting Details / Quotes / Examples">Evaluate analogizer generalization by measuring performance on new, unseen input distributions; adversarial examples; check that similarity function aligns with task; tune hyperparameters (number of neighbors, kernel width, regularization). </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Analogizer’s future role in AGI/hybrid systems</strong> — Potential component of a Master Algorithm: fast adaptation, few-shot learning, similarity-based memory modules, instance-based reasoning.                                                      </td><td data-label="Supporting Details / Quotes / Examples">Domingos speculates that analogizers may help AGI in areas where massive data is unavailable, where fast adaptation is needed, or where explainability demands tracing to examples. Hybrid systems combining analogizers + neural nets etc. are promising. </td></tr><tr><td data-label="Summary / Core Concepts"><strong>Closing reflection</strong> — Analogizers illustrate both simplicity and weakness: when used well, they are powerful; but alone they are insufficient. For universal learning we need multiple tribes.                                                   </td><td data-label="Supporting Details / Quotes / Examples">The chapter ends by arguing that the analogizer tribe’s strengths and limitations teach us what the Master Algorithm must include: similarity, memory, metric learning—but also structural bias, feature learning, extrapolation from few examples. </td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-7">
<div class="table-wrapper" data-table-id="table-7"><h3 id="table-7">Table 7</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Notes**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Notes</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary"><strong>Decision-Making Under Uncertainty</strong>             </td><td data-label="Notes">Chapter 7 explores how humans make intelligent decisions under volatile and unpredictable conditions.<br>Astronauts noticed a paradox: the more they trained in simulators, the better their performance in controlled scenarios—but the more prone they became to catastrophic failure in real-life emergencies.<br>Training that optimized performance introduced unforeseen vulnerabilities.</td></tr><tr><td data-label="Summary"><strong>Optimization Trap</strong>                             </td><td data-label="Notes">The optimization trap occurs when a system becomes highly specialized for current conditions but fails under new or shifting environments.<br>For AI, more data improves accuracy and speed until sudden environmental changes make the accumulated data a liability, leading to catastrophic errors: <em>“dumps commodities at fire-sale prices, diagnoses healthy newborns with brain tumors, and pilots cargo planes into mountainsides.”</em></td></tr><tr><td data-label="Summary"><strong>Biology and Maximum Adequacy</strong>                  </td><td data-label="Notes">Biological systems illustrate the value of generalist adaptation over hyperspecialization.<br>Maximum adequacy is a survival trait:<br>- The human hand is competent at countless tasks but not perfectly optimized for any single one.<br>- The human brain is satisfactory across many domains, combining logic, creativity, and commonsense to avoid the rigidity of AI over-optimization.</td></tr><tr><td data-label="Summary"><strong>Commonsense as a Guide</strong>                        </td><td data-label="Notes">Army Special Operators discovered that commonsense is the key to surviving uncertainty.<br>Commonsense operates by detecting unknown unknowns and enabling two forms of decision-making:<br>1) Recognizing when to switch plans (Chapter 4: tuning anxiety)<br>2) Deciding which new plan to adopt<br>The principle for plan selection is: <em>Match the newness of your plan to the newness of your environment.</em></td></tr><tr><td data-label="Summary"><strong>Ambush Training Example</strong>                       </td><td data-label="Notes">Recruits in ambush scenarios initially freeze or take poor actions like dropping prone, leaving themselves vulnerable.<br>Operators teach attacking into the ambush, which simultaneously regains initiative and disrupts the enemy’s decision-making.<br>Memorized programs fail under novelty; commonsense-based, self-discovered lessons succeed in unpredictable situations.</td></tr><tr><td data-label="Summary"><strong>Step 1 – George Marshall</strong>                      </td><td data-label="Notes">Rule: <em>When fundamentals change, junk your most successful plans.</em><br>Marshall, upon becoming U.S. Army Chief of Staff in 1939, force-retired generals whose experience was outdated for modern warfare.<br>Expertise is valuable for recognizing novelty, not for confirming past rules.<br>Army Special Ops pairs young lieutenants with seasoned sergeants to detect unprecedented situations and prompt plan adaptation.<br>History and democracy function similarly: surprise or disruption signals that old norms no longer apply.</td></tr><tr><td data-label="Summary"><strong>Step 2 – Thomas Paine</strong>                         </td><td data-label="Notes">Rule: <em>New plans require boldness.</em><br>Paine’s pamphlet <em>Common Sense</em> encouraged revolutionary action despite uncertainty.<br>New plans often appear incomplete or peculiar; hesitation can lead to discarding valuable innovation due to expert bias.<br>Boldness preserves and accelerates innovation by embracing the unconventional elements of novel plans.<br>Retreating to familiar comfort zones in chaotic moments ensures failure; boldness matches the rhythm of the environment.</td></tr><tr><td data-label="Summary"><strong>Step 3 – George Washington</strong>                    </td><td data-label="Notes">Rule: <em>Be as bold as the situation is uncertain.</em><br>Washington adjusted his strategy according to context:<br>- Routine logistical operations were conservative.<br>- High-risk operations (e.g., crossing the Delaware, guerrilla warfare, transporting cannons) leveraged daring improvisation.<br>Commonsense required acting decisively under uncertainty, calibrating risk-taking to match volatility.</td></tr><tr><td data-label="Summary"><strong>Integrated Decision Rule</strong>                      </td><td data-label="Notes">Combining Marshall, Paine, and Washington: <em>Match plan novelty to situation novelty.</em><br>- Use familiar plans for familiar contexts.<br>- Use moderately novel plans for new contexts.<br>- Use highly novel plans for unprecedented situations.<br>This ensures both adaptive capacity and optimal execution.</td></tr><tr><td data-label="Summary"><strong>Modern Life Applications</strong>                      </td><td data-label="Notes">Modern humans often misapply risk:<br>- Taking unnecessary gambles in secure circumstances.<br>- Retreating under real volatility.<br>Practicing commonsense involves monitoring loss of effectiveness as an indicator for environmental change.<br>Gradual deterioration of a plan’s success signals the need to develop new strategies before stakes escalate.</td></tr><tr><td data-label="Summary"><strong>Commonsense in Action – Neil Armstrong</strong>        </td><td data-label="Notes">Armstrong exemplified rapid commonsense decision-making.<br>His dual background as a test pilot and engineer allowed him to respect SOPs while improvising when conditions deviated.<br><em>Gemini 8</em> (March 1966): When the module began rolling uncontrollably, Armstrong exited SOPs, disabled the orbital system, engaged reentry thrusters, and stabilized the craft—actions no astronaut had performed before, saving his life.</td></tr><tr><td data-label="Summary"><strong>Lunar Landing Example</strong>                         </td><td data-label="Notes">During the Apollo 11 moon landing (July 20, 1969), Armstrong initially used autopilot but rapidly switched to manual control upon detecting unexpected boulders.<br>He devised a novel flight path, toggling between automated instructions and adaptive intuition to ensure a successful landing.</td></tr><tr><td data-label="Summary"><strong>Expert Consultation Technique</strong>                 </td><td data-label="Notes">Special Operators’ technique: <em>“Go Where Experts Can’t Say No.”</em><br>Present your plan to an expert asking only: <em>“Can you prove this plan will fail?”</em><br>- If yes, invent a new plan.<br>- Ignore advice on alternative plans that could work; focus solely on eliminating guaranteed failure.<br>This maximizes adaptive decision-making while avoiding paralysis or unnecessary interference.</td></tr><tr><td data-label="Summary"><strong>Avoiding the Optimization Trap</strong>                </td><td data-label="Notes">Commonsense training allows humans to escape over-reliance on repetitive or programmed responses.<br>By cultivating adaptive improvisation and rapid evaluation of novelty, individuals and organizations can respond effectively to unforeseen circumstances.</td></tr><tr><td data-label="Summary"><strong>Training Your Brain</strong>                           </td><td data-label="Notes">Train for proactive adaptation:<br>- Monitor effectiveness.<br>- Detect environmental change.<br>- Develop innovative plans in low-pressure settings.<br>This method prevents panic, preserves initiative, and aligns decision-making speed with environmental volatility.</td></tr><tr><td data-label="Summary"><strong>Historical & Operational Analogies</strong>            </td><td data-label="Notes">- Marshall: discard outdated expertise.<br>- Paine: boldness ensures innovation survives novelty.<br>- Washington: calibrate risk to uncertainty.<br>- Armstrong: rapid toggling between SOPs and improvisation saves lives.</td></tr><tr><td data-label="Summary"><strong>Key Takeaway</strong>                                  </td><td data-label="Notes">Effective decision-making integrates three principles:<br>1) Recognize when old plans no longer apply.<br>2) Act boldly on new or partial plans.<br>3) Calibrate risk-taking to uncertainty.<br>Following this framework ensures plan selection aligns with the novelty of the environment, maximizing adaptive success.</td></tr><tr><td data-label="Summary"><strong>Commonsense Indicator – Loss of Effectiveness</strong> </td><td data-label="Notes">Monitor small declines in performance as early signals of environmental change. For example:<br>- Battle strategy still gains ground but at higher cost.<br>- Product sales slow despite stable operations.<br>- Employee engagement wanes while burnout rises.<br>Early detection allows plan adaptation before crises escalate.</td></tr><tr><td data-label="Summary"><strong>Outcome for Learners</strong>                          </td><td data-label="Notes">Individuals trained in these principles gain the ability to:<br>- Adapt rapidly to new conditions.<br>- Act boldly and proportionally to risk.<br>- Avoid frozen indecision.<br>- Apply expert advice selectively.<br>- Escape the optimization trap and ambush back.</td></tr></tbody></table></div><div class='row-count'></div></div>
</div><div class="tv-fragment" id="frag-8">
<div class="table-wrapper" data-table-id="table-8"><h3 id="table-8">Table 8</h3><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th style="width:28.57%;" role="button" aria-label="Sort by **Summary / Core Concepts**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Summary / Core Concepts</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th><th style="width:71.43%;" role="button" aria-label="Sort by **Supporting Details / Examples / Verbatim Quotes**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>Supporting Details / Examples / Verbatim Quotes</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Summary / Core Concepts"><strong>Personal Data Banks</strong>                          </td><td data-label="Supporting Details / Examples / Verbatim Quotes">The text envisions a company that acts as a personal data bank, analogous to how banks handle money. It would store all user data, from online interactions to potential future 24/7 video streams, anonymize activity, and create a complete model of the individual to act on their behalf. “The company's basic commitment to you is that your data and your model will never be used against your interests.” Current cloud providers and startups either lock users in or exploit their data, but the envisioned model prioritizes user control and trust.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Data Unions & Collective Control</strong>             </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Users can join data unions to pool data and increase bargaining power with companies. These unions allow members to share the <strong>models learned from pooled data</strong>, not raw personal information. Labor unions could initiate this for their members. The author emphasizes that privacy is just one part of a larger data ecosystem: “Privacy is only one aspect of the larger issue of data sharing, and if we focus on it to the detriment of the whole...we risk reaching the wrong conclusions.”</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Job Automation & Human-Machine Collaboration</strong> </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Automation affects narrowly defined tasks first, while jobs requiring broad skills remain human-dominated. Examples: robots assemble cars but don’t replace construction workers; credit analysts and direct marketers have been replaced by algorithms. Automating one’s own job improves productivity and allows humans to focus on uniquely human tasks. H\&R Block employees now leverage computers to automate grunt work. Centaur chess players exemplify human + machine collaboration, combining intuition and computation.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Future of Employment & Society</strong>               </td><td data-label="Supporting Details / Examples / Verbatim Quotes">The boundary between automatable and non-automatable jobs will expand, creating temporary unemployment, downward wage pressure, and concentrated rewards for the remaining human-unique tasks. Eventually, democratic processes will support <strong>lifetime unemployment benefits</strong> or universal basic income. Humans will pursue meaning in creativity, relationships, and self-actualization rather than labor: “The need to earn a living will be a distant memory, another piece of humanity's barbaric past that we rose above.” Automation unlocks wealth, but humans decide its social distribution.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Robot Armies & Military Ethics</strong>               </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Robots are already deployed in dangerous military roles: bomb defusal, drone surveillance, self-driving supply trucks. Ethical challenges arise when robots must make shoot/don’t shoot decisions. Proposed solutions include teaching robots via machine learning on curated ethical examples. Potential benefits include drastically reducing human casualties. “If a war is fought by machines, with humans only in command positions, no one is killed or wounded.” Concerns include confusion due to conflicting human ethics and the potential for a robot arms race, but such a race may ultimately reduce casualties and make war safer.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>AI & Human Control</strong>                           </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Intelligent machines are extensions of human engineering, not autonomous agents with will. They execute goals humans assign via representation, evaluation, and optimization. Misalignment arises when humans incorrectly program AI, give excessive autonomy, or fail to oversee outputs. “The third and perhaps biggest worry is that, like the proverbial genie, the machines will give us what we ask for instead of what we want.” Current examples include Amazon recommendations and credit scoring errors. Vigilant oversight, analogous to democracy, is required to ensure AI serves human intentions.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Intelligence Explosion & Singularity</strong>         </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Concerns about a Singularity—where AI surpasses human intelligence uncontrollably—are critiqued. Technological progress follows <strong>S-curves</strong>, not infinite exponentials. Kurzweil’s predictions are overfitted. The Turing point occurs when machine learning overtakes natural intelligence. This is framed as a <strong>phase transition</strong>, not a singularity. Humans will coevolve with machines, shaping and understanding the world within our cognitive reach. “The world beyond the Turing point will not be incomprehensible to us, any more than the Pleistocene was.”</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Human-Directed Evolution & Homo Technicus</strong>    </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Machine learning and computational design allow humans to engineer biology, e.g., design DNA, synthesize cells, cure disease instantly, and optimize human bodies. Craig Venter’s work is cited as a first step. This evolution produces diverse intelligent species instead of a simple haves/have-nots divide: “Natural evolution did not result in just two species, one subservient to the other, but in an infinite variety of creatures and intricate ecosystems. Why would artificial evolution, building on it but less constrained, do so?” This ushers in <strong>Homo technicus</strong>, coevolving with machines and biology.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Phase Transitions & Future Outlook</strong>           </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Human-directed evolution and machine learning represent a <strong>critical phase transition</strong> in Earth’s history. Each bottleneck overcome leads to the next, creating successive limits rather than infinite growth. Over the next thousand years, life on Earth could experience the most dramatic transformations in its history. Humans will remain active participants, not passive observers. “The next thousand years could well be the most amazing in the life of planet Earth.”</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Ethics, Oversight, and Learning</strong>              </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Teaching robots ethics forces humans to examine and resolve contradictions in our own moral systems. Robots learn from curated examples to generalize ethical decision-making. Human oversight ensures alignment: if a robot errs, humans can correct it. Similarly, as machine learning permeates society, humans must monitor AI decisions collectively. Intelligence without will prevents AI from autonomous tyranny, but humans must avoid delegating decision-making blindly.</td></tr><tr><td data-label="Summary / Core Concepts"><strong>Machine Learning as Extension of Humanity</strong>    </td><td data-label="Supporting Details / Examples / Verbatim Quotes">Machine learning accelerates cultural and biological evolution by removing human bottlenecks. Computers design solutions faster than humans can, while humans retain judgment and oversight. This coevolution is natural: fire and spears shaped Homo sapiens, and AI will shape Homo technicus. Computers serve as extensions of human problem-solving, exponentially amplifying our capabilities.</td></tr></tbody></table></div><div class='row-count'></div></div>
</div><script src="assets/xlsx.full.min.js?v=1759433634" defer></script>
<script src="assets/inlineblock_guard.js?v=1759433634" defer></script>
<script src="assets/script.js?v=1759433634" defer></script>
<script src="assets/worker.js?v=1759433634" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
</script>

<script>
  (function(){
    function startGuard() {
      try {
        if (window.inlineBlockGuard) {
          window.inlineBlockGuard({ root: document.body, maxRetries: 3, retryDelay: 100, observeDynamic: true, telemetry: function(r){ try{ console.info('inlineBlockGuard report', r); }catch(e){} }});
        } else if (window.inlineBlockObserver) {
          try { window.inlineBlockObserver(document.body); } catch(e) {}
        }
      } catch(e) {}
    }
    if (document.readyState === 'loading') document.addEventListener('DOMContentLoaded', startGuard);
    else startGuard();
  })();
</script>

</div>
</body>
</html>