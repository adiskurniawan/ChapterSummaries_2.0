<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771304656">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0180_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Utilities — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Utilities — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_UTILS (declared in PQ/OWNERS.md and release manifest). <br><strong>Maintainers & escalation:</strong> primary: pq-utils-team; secondary: pq-tools-ops; on-call: platform-SRE for persistence issues. <br><strong>Public API (complete surface):</strong> ComputeMChecksum, NormalizeMForChecksum, PrettyPrintM, ParameterizeM, ExtractParametersFromM, MChecksumStream, MChecksumCompare, MChecksumDiffReport, MTemplateFingerprint, Add_Query_From_M_SafePayload, AtomicWritePQ, AtomicWriteRepairPQ, InspectTempArtifactsPQ, Retry, DeterministicRNG_PQ, SerializeRngState, RestoreRngState, ExportMWithDiagnostics, TempHiddenSheetFallback, HiddenSheetInspector, ValidateTemplatePolicy, ValidateTemplateSignature, ParameterSchemaValidator, MParserLite, MASTComparator, PreviewSandboxRunner, PreviewSeedProvider, TemplateRepoSync, TemplateRepoVerify, PQDiagnosticsCollector, PQDiagnosticSummarizer, EvidenceBundleBuilder. <br><strong>Audits emitted (representative):</strong> pq.util.startup, pq.util.mchecksum.start, pq.util.mchecksum.complete, pq.util.mchecksum.mismatch, pq.util.mchecksum.reconcile, pq.util.atomic_write.attempt, pq.util.atomic_write.completed, pq.util.atomic_write.failure, pq.util.atomic_write.degraded, pq.util.atomic_write.repair, pq.util.retry.attempt, pq.util.retry.complete, pq.util.rng.seeded, pq.util.rng.state_serialized, pq.util.inject.preview, pq.util.inject.commit, pq.util.export.attempt, pq.util.export.completed, pq.util.fallback.hidden_sheet.write, pq.util.fallback.hidden_sheet.recover. Every audit row includes correlationId, module=PQ_Utilities, procedure, paramsHash, resultHash (where applicable), and when user-initiated, operatorId. <br><strong>Purpose & intended use:</strong> provide deterministic, auditable, cross-host-safe primitives for working with Power Query M templates: canonicalization and stable fingerprinting (mChecksum), safe parameterization and preview injection, deterministic preview reproduction via seeded RNG, robust persistence (atomic write with verification and recoverability), diagnostics collection for PQ refresh/preview flows, and evidence packaging for forensic and regulatory needs. PQ_Utilities acts as both a light-weight host shim (for in-addin preview fast paths) and a full-fidelity worker library (for audited commits and exports). <br><strong>Non-goals / constraints:</strong> do not implement cryptographic signing (handled by release manifests/signature services), do not perform network uploads in preview fast-paths, and avoid heavy runtime dependencies in the add-in host. Do not assume uniform filesystem semantics across hosts—design explicit fallbacks and document degraded guarantees. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (module-level invariants & SLOs):</strong><br>1. Determinism: with identical M text, canonicalization rules, and RNG seed, outputs (mChecksum and RNG-driven selections) are reproducible across supported runtimes and languages. <br>2. mChecksum semantics: the canonicalizer maps semantically-identical templates to identical normalized representations where canonical rules permit, enabling stable fingerprinting and audit anchors. <br>3. Atomic persistence: artifacts persisted via AtomicWritePQ are final-on-success; readers never observe truncated artifacts. <br>4. UI thread safety: preview flow helpers are non-blocking; any heavy IO is offloaded or scheduled by the host. <br>5. Observability & evidence: every commit or persisted artifact is accompanied by audit rows and evidenceRef pointing to encrypted normalized content or serialized RNG state where necessary. <br><strong>Performance SLOs:</strong> ComputeMChecksum for a 100KB template in worker context median <50ms; AtomicWritePQ median local SSD latency <250ms; RNG seeding + first 100 draws <10ms. <br><strong>CI / acceptance gates:</strong> cross-runtime golden vectors for ComputeMChecksum and DeterministicRNG; atomic-write cross-platform tests including NFS/SMB heuristics; static analyzer blocking forbidden host IO on UI thread; audit emission verification. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>High-level design & cross-cutting patterns:</strong><br>1. Two modes of operation: <code>preview-fast-path</code> (non-blocking, minimal IO, no remote evidence upload) and <code>commit/worker-path</code> (full audit, atomic persistence, verification). <br>2. Canonicalization-first: always derive and compare mChecksum using NormalizeMForChecksum before commit or injection. <br>3. Deterministic sampling: always seed RNG deterministically from correlationId for any operator-visible randomness; persist RNG state when exact replay is required. <br>4. Persistence-first for authoritative artifacts: persist normalizedM + metadata via AtomicWritePQ then inject into workbook from persisted artifact rather than arbitrary in-memory strings. <br>5. Fallbacks documented: hidden-sheet fallback for restricted hosts, two-phase copy for weak-rename filesystems, and staged local fallback for network outages. <br>6. Audit-first instrumentation: emit start/complete/error audits for every critical transition with correlationId, paramsHash, and evidenceRef where relevant. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>ComputeMChecksum(m_source, normalize=true, canonical_rules=null)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic, cross-runtime fingerprint for Power Query M code; returns <code>{mChecksum: sha256hex, normalizedM: string, canonicalMetadata: object}</code>. Must be pure and side-effect free. <br><strong>Parameters & behavior:</strong> <code>m_source</code> (string): raw M text; <code>normalize</code> (bool, default true); <code>canonical_rules</code> (optional): map controlling comment preservation, field ordering policy, literal normalization, and special-case rules for regulated templates. <br><strong>Primary invariants (must/shall):</strong><br>1. Idempotence: same input and rules produce same normalizedM and mChecksum. <br>2. Determinism across runtimes: tokenization & canonical rules documented and implemented across supported runtimes (XLAM JS/VBA shim, worker runtime). <br>3. Minimal false match risk: canonicalizer must avoid different semantics mapping to same normalized string. <br><strong>Algorithm & implementation notes:</strong><br>1. <strong>Pre-normalize:</strong> UTF-8 decode + Unicode NFC normalization; normalize line endings to LF. <br>2. <strong>Lexical pass:</strong> tokenise into keywords, identifiers, punctuation, literals, comments. Use a tolerant tokenizer that accepts common nonstandard whitespace. <br>3. <strong>AST-lite pass:</strong> where possible build a shallow parse tree for record/list/function declarations and parameter maps to apply canonical ordering safely. <br>4. <strong>Canonical transforms:</strong> remove or normalize comments per rules; sort record fields where semantically safe unless <code>fieldOrderingPreserved</code> flagged in template metadata; normalize numeric literal formats (reject leading plus signs, canonicalize exponents), normalize date/time literal representation to ISO-like canonical form understood across PQ runtimes. <br>5. <strong>Re-emit normalizedM:</strong> deterministic spacing rules: single space between tokens where required, consistent function parameter formatting, consistent indentation in normalized output (indentation is cosmetic but helps diffs). <br>6. <strong>Hashing:</strong> compute SHA256 over UTF-8 bytes of normalizedM and return hex digest. <br><strong>Edge cases & invalid inputs:</strong><br>1. Non-UTF8 input -> decode with replacement characters and emit pq.util.mchecksum.invalid_encoding audit with evidenceRef containing original bytes. <br>2. Partial fragments (templating placeholders or embedded parameter markers) -> support fragment mode with <code>fragment:true</code> metadata. <br>3. Very large templates -> stream canonicalization with MChecksumStream to cap memory; if forced truncation occurs emit pq.util.mchecksum.truncated. <br><strong>Observability & audits:</strong> pq.util.mchecksum.start(correlationId, inputHash, rulesHash) pq.util.mchecksum.complete(correlationId, mChecksum, durationMs, normalizedLength) pq.util.mchecksum.mismatch(correlationId, expectedChecksum, actualChecksum, evidenceRef). <br><strong>Examples & narratives:</strong><br>1. Two template authors add explanatory comments without changing logic; ComputeMChecksum with default rules strips comments and mChecksum is unchanged. <br>2. A template author reorders a parameter map; if canonical rules allow order-insensitivity, normalizedM sorts map entries alphabetically and mChecksum stable. <br><strong>CI tests & parity:</strong> supply canonicalization golden inputs (whitespace/comment variants, field order permutations, literal formatting edge cases) and verify identical mChecksum across supported runtimes. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>NormalizeMForChecksum(m_source, rules)</code> — canonicalizer and reversible mapping</strong><br><strong>Purpose & contract:</strong> produce deterministic normalized M and mapping metadata for optional reversible reconstruction. Returns <code>{normalizedM, mappingMetadata}</code>. <code>mappingMetadata</code> must contain original offsets or annotations when reversibility is required (e.g., for regulated templates that need exact round-trip of comments). <br><strong>Implementation details:</strong> use token stream to create mapping entries per token including tokenIndex, originalStart, originalEnd, and if <code>reversible=true</code> anchor comment blocks into evidenceRef storage and record pointer. <br><strong>Developer notes:</strong> when <code>reversible</code> is true, sensitive content (PII) must be sanitized or encrypted before evidenceRef write. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>PrettyPrintM(m_source, style)</code> — deterministic pretty printing for UI editors</strong><br><strong>Purpose & contract:</strong> render M in deterministic, human-friendly layout for preview or editor; returns <code>{prettyM, mappingHint}</code> suitable for editor cursor mapping. Must preserve semantics. <br><strong>Behavior:</strong> use normalized AST to format with deterministic indentation and line wrapping rules; preserve <code>@preserve</code> anchors to avoid reflowing intentionally formatted blocks. Provide <code>compact</code> and <code>readable</code> styles. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>ExtractParametersFromM(m_source)</code> — parameter schema extraction</strong><br><strong>Purpose & contract:</strong> statically analyze top-level template metadata to list declared parameters with type hints, defaults, validations, help text, and whether parameter is injected into connection strings (sensitive). Returns structured manifest <code>{parameters:[{name,type,default,validation,help,isSensitive}], requiresHighPrecision:boolean, templatePolicyFlags:[]}</code>. <br><strong>Constraints:</strong> Do not execute M; static-only parse. Ambiguous types returned as <code>unknown</code> with a <code>warning</code> flag and pq.util.param.extract.warning audit. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>ParameterizeM(m_template, parameterValues, mode=&quot;preview&quot;, validate=true, correlationId=null)</code> — safe AST-level substitution</strong><br><strong>Purpose & contract:</strong> safely substitute parameter values into M template at AST level; validate types and return substitutedM and parameterization metadata. Avoid raw string interpolation. <br><strong>Modes & behavior:</strong><br>1. <code>preview</code>: sandboxed substitution with no persisted side effects; fast-path. <br>2. <code>commit</code>: authoritative substitution; after substitution compute mChecksum and optionally call AtomicWritePQ with artifact sidecar metadata. <br><strong>Type coercion & validation rules:</strong> apply declared type coercions; when coercion fails return structured <code>ParameterErrorList</code> with ErrorCode=PQ_PARAM_TYPE_MISMATCH and emit pq.util.param.invalid audit. For sensitive parameters flagged <code>isSensitive</code>, redact top-level content and write full parameter payload only to encrypted evidence store referenced by evidenceRef. <br><strong>Security & injection safeguards:</strong> encode strings as M string literals at AST-level, escape newlines and embedded quotes per canonical literal rules. Parameterization must never paste unescaped user input into connection strings or commands. <br><strong>Audit:</strong> pq.util.inject.preview(correlationId, templateId, paramsHash, previewMChecksum) pq.util.inject.commit(correlationId, templateId, paramsHash, committedArtifactChecksum). </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>MChecksumStream(reader, normalize=true, canonical_rules=null, progressCb=null)</code> — streaming canonical checksum</strong><br><strong>Purpose & contract:</strong> stream canonicalize large M content and compute SHA256 without loading whole file into memory. Good for remote template repo sync and large embedded template stores. <br><strong>Implementation notes:</strong> incremental tokenization and group-buffering for record fields; for canonical sorts buffer group only; support resumable streams and <code>progressCb</code> for UI. If canonical ordering can't be guaranteed due to memory caps, return partialNormalizedRef with pq.util.mchecksum.truncated audit. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>MChecksumCompare(expectedChecksum, readerOrSource, options={reconcile:false, evidenceStore:true, catchComments:true})</code> — verification & reconciliation</strong><br><strong>Purpose & contract:</strong> compute checksum for given source and compare to <code>expectedChecksum</code>; on mismatch optionally produce reconciliation report that separates <code>semanticDiffs</code> (AST-level) and <code>commentDiffs</code> (formatting/comments only). Return <code>{match, computedChecksum, diffs[], evidenceRef}</code>. If <code>reconcile=true</code>, persist side-by-side normalized forms in evidence store for owner review and emit pq.util.mchecksum.reconcile. <br><strong>Use-cases:</strong> template repo sync, pre-injection verification, CI gates. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>MChecksumDiffReport(expectedNormalizedRef, actualNormalizedRef)</code> — human-friendly diff</strong><br><strong>Purpose & contract:</strong> produce an annotated diff report that categories deltas as <code>semantic</code> vs <code>non-semantic</code> with sample snippets and line anchors, stored in evidence store. Provide <code>summary</code> and <code>detailed</code> formats for UI display and regulatory submission. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>AtomicWritePQ(targetPath, payloadStreamOrBytes, tmpSuffix=&quot;.pqpart&quot;, fsyncFile=true, fsyncParent=true, perms=null, maxAttempts=3, cleanupOnFailure=true, degradeOnNFS=true, correlationId=null, metadata=null)</code> — PQ-optimized atomic file writer</strong><br><strong>Purpose & contract:</strong> robust, crash-safe atomic replace for PQ artifacts: M files, export bundles, diagnostics, and artifact manifests. On success return <code>{success:true, artifactPath:targetPath, artifactChecksum:sha256hex, attempts, elapsedMs}</code>. On failure return structured error with ErrorCode and diagnosticsRef. <br><strong>Behavior & detailed steps (must/shall):</strong><br>1. <strong>Parent existence:</strong> validate parent directory exists or create atomically via FsSyncDir if <code>create=true</code>, emit pq.util.atomic_write.mkdir audit if created. <br>2. <strong>Temp path selection:</strong> compute <code>tempPath = targetPath + tmpSuffix + &quot;.&quot; + pid + &quot;.&quot; + deterministicSuffix</code> where <code>deterministicSuffix</code> is derived deterministically from correlationId using DeterministicRNG_PQ so concurrent concurrent writers avoid collisions predictably. <br>3. <strong>Exclusive write & checksum:</strong> open tempPath with exclusive create; stream write payload computing SHA256 and bytesWritten; optionally write sidecar <code>payload.metadata.json</code> containing mChecksum, templateId, correlationId, templateVersion if <code>metadata</code> provided. <br>4. <strong>fsync & rename:</strong> if fsyncFile true, fsync file descriptor; perform rename/replace: os.replace on POSIX, ReplaceFile on Windows with <code>REPLACEFILE_IGNORE_MERGE_ERRORS</code> semantics when available. <br>5. <strong>Parent fsync:</strong> if fsyncParent true perform directory fsync to ensure rename durability. <br>6. <strong>Verification:</strong> reopen targetPath read-only and verify SHA256 matches computed artifactChecksum; on mismatch attempt Retry policy if transient; otherwise emit pq.util.atomic_write.verification_failed with diagnosticsRef. <br>7. <strong>Fallback for weak rename filesystems (NFS/SMB):</strong> when <code>degradeOnNFS</code> true, use two-phase copy + state-stamp (meta file indicating <code>STATE=committed</code> only after successful copy) and emit pq.util.atomic_write.degraded; callers must be aware of degraded atomicity semantics. <br>8. <strong>Hidden-sheet fallback:</strong> if host prevents filesystem writes (web host, sandbox), call TempHiddenSheetFallback to embed artifact in hidden worksheet and emit pq.util.atomic_write.degraded. <br>9. <strong>Cleanup:</strong> if <code>cleanupOnFailure=true</code> attempt to delete surviving tempPath on failure and emit pq.util.atomic_write.cleanup audit rows. <br><strong>Cross-platform notes:</strong> Windows ReplaceFile semantics can be affected by open handles; document best practices to write to same volume, prefer atomic replacements on same volume, and advise consumers to avoid reading-in-place during replacement. <br><strong>Recovery runbook:</strong> use InspectTempArtifactsPQ to enumerate <code>.pqpart</code> leftovers; run AtomicWriteRepairPQ to validate temp artifact checksum and safely rename under maintenance window; if ENOSPC emitted, follow ENOSPC runbook. <br><strong>Observability & audit fields:</strong> pq.util.atomic_write.attempt(correlationId, targetPath, payloadHash, tempPath, attemptIdx) pq.util.atomic_write.completed(correlationId, targetPath, artifactChecksum, durationMs, attempts) pq.util.atomic_write.failure(correlationId, targetPath, errorCode, attempts, diagnosticsRef) pq.util.atomic_write.degraded(correlationId, targetPath, reason). <br><strong>Testing & CI:</strong> simulate ReplaceFile lock contention on Windows, simulate ENOSPC and fsync failures via FS mocks, test two-phase fallback correctness, concurrency tests verifying no partial readers are observed. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>AtomicWriteRepairPQ(tempPath, intendedTargetPath, correlationId=null)</code> — temp artifact repair & recovery</strong><br><strong>Purpose & contract:</strong> validate a temp artifact discovered by InspectTempArtifactsPQ and attempt safe rename to intended targetPath under maintenance conditions. Return <code>{repaired:true/false, repairedPath, artifactChecksum, diagnosticsRef}</code> and emit pq.util.atomic_write.repair audit. <br><strong>Behavior:</strong> verify SHA256 from temp matches metadata sidecar; if verification passes rename->targetPath using safe heuristics (same volume required) and optionally fsync parent; if verification fails, store the temp artifact in evidence store and emit pq.util.atomic_write.corrupt. Provide operator guidance for manual salvage or deletion. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>InspectTempArtifactsPQ(searchPaths, olderThan=null, correlationId=null)</code> — enumerate leftover temps</strong><br><strong>Purpose & contract:</strong> list <code>.pqpart</code> and hidden-sheet artifacts associated with PQ operations, return structured inventory with path, size, mtimestamp, tempMetadata, and suggested recovery actions. Use for housekeeping and incident triage. Emit pq.util.atomic_write.inspect audit with inventoryHash. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>Retry(fn, retries=3, backoff={baseMs:150, factor:2}, jitter=true, retry_on=(TransientPQError,), idempotent_assert=false, deterministic_jitter=false, cancellationToken=null, correlationId=null)</code> — canonical retry wrapper</strong><br><strong>Purpose & contract:</strong> robust wrapper for transient failures during PQ persistence or network calls invoked by orchestration. Only retry on recognized transient error classes. Implement deterministic jitter option for CI reproducibility. <br><strong>Sensible defaults & safeguards (must/shall):</strong><br>1. Only retry on known transient exceptions; immediate rethrow on non-transient errors. <br>2. If <code>idempotent_assert=true</code> require an explicit idempotency token or precondition; CI/linters enforce this for critical persistence calls. <br>3. <code>deterministic_jitter=true</code> uses DeterministicRNG_PQ seeded from correlationId for reproducible delays. <br>4. Respect cancellationToken between attempts and raise PQ_RETRY_CANCELLED when cancelled. <br><strong>Audits:</strong> pq.util.retry.attempt(correlationId, target, attemptIndex, errorCode, backoffMs) pq.util.retry.complete(correlationId, target, attempts, outcome, elapsedMs). </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>DeterministicRNG_PQ(seed_source, salt=&quot;&quot;, algorithm=&quot;pcg64&quot;, stream_id=null, test_mode=false)</code> — PQ deterministic RNG</strong><br><strong>Purpose & contract:</strong> seeded, deterministic RNG for preview sampling, tie-breaker shuffles, and any operator-visible randomness. Not cryptographic. Instances explicit—no implicit global RNG. <br><strong>Seed derivation & security:</strong><br>1. Seed derived via HMAC_SHA256(<code>seed_source | salt | moduleName | streamId</code>) folded to algorithm seed length. <br>2. Do not store raw seed in audit rows; store <code>seedFingerprint</code> and evidenceRef for serialized RNG state when full replay required. <br>3. test_mode allows deterministic seed override for CI golden tests. <br><strong>API:</strong> randint(a,b), random(), shuffle(list) -> new_list, sample(pop,k), split(childIndex) -> childRng, serialize_state() -> base64 blob, restore_state(blob). <br><strong>Stability invariants:</strong> same algorithm + same seed produce identical sequences across supported runtimes and languages. <code>split</code> uses HMAC-based derivation to ensure independent child streams. <br><strong>Observability & audit:</strong> pq.util.rng.seeded(correlationId, seedFingerprint, algorithm, streamId) pq.util.rng.state_serialized(correlationId, stateHash, evidenceRef). <br><strong>Examples & narratives:</strong><br>1. Preview sampling: PQ_Ribbon obtains seed = SeedFromCorrelation(correlationId, "preview-v2", templateId) via PreviewSeedProvider, computes sample selection in worker or host M by passing numeric seed param into deterministic PRNG implemented in M or by selecting sample server-side and storing selection in evidence for replay. <br>2. Tie-breakers for parameter ordering: when multiple default parameter options exist, call rng.shuffle(candidates) seeded by correlationId + "param-tie" to produce stable ordering across operator sessions; persist serialized RNG state when ordering affects persisted artifact. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>Add_Query_From_M_SafePayload(workbook, queryName, m_formula, options={validateChecksum:true, expectedChecksum:null, commitArtifactPath:null, createConnection:false, runAsync:true, correlationId:null, requireSignature:false})</code> — authoritative injector helper</strong><br><strong>Purpose & contract:</strong> orchestrate safe injection of M into workbook: optional commit artifact persistence via AtomicWritePQ, optional checksum validation, and audited injection with evidence linkage. Return <code>{success, queryRef, artifactChecksum, evidenceRef}</code>. <br><strong>Preconditions & safety checks:</strong><br>1. If <code>validateChecksum=true</code> and <code>expectedChecksum</code> provided, abort on mismatch and emit pq.util.mchecksum.mismatch audit. <br>2. If <code>requireSignature=true</code> and template lacks signed release manifest, refuse commit and raise PQ_INJECT_SIGNATURE_REQUIRED. <br>3. Avoid direct blocking IO on UI thread: if commit is required and <code>runAsync=true</code>, schedule worker persist then inject via host-safe callback once persistence succeeds. <br><strong>Host constraints & fallback:</strong> if host macros disabled or security policy forbids injection, return PQ_INJECT_HOST_RESTRICTED and emit pq.util.inject.commit_failure. <br><strong>Audit & linkage:</strong> pq.util.inject.preview(correlationId, templateId, paramsHash, previewMChecksum) pq.util.inject.commit(correlationId, templateId, queryName, artifactChecksum, templateVersion, operatorId, releaseManifestHash). </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>ExportMWithDiagnostics(m_source, diagnostics, targetPath, options={includeNormalized:true, includeDiagnostics:true, correlationId:null, compress:true})</code> — export bundler</strong><br><strong>Purpose & contract:</strong> produce deterministic artifact bundling M source, normalizedM, diagnostics (preview traces, provider logs, refresh path), computed mChecksum, and metadata; persist via AtomicWritePQ with sidecar artifact.metadata.json and emit pq.util.export.attempt and pq.util.export.completed. <br><strong>Use-cases:</strong> operator evidence packages, support tickets, regulatory submissions. Support <code>compress</code> to produce single compressed payload for easier upload. Provide <code>evidenceRef</code> for normalized forms and full diagnostics stored encrypted. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>TempHiddenSheetFallback(workbook, sheetName, payload, meta, correlationId=null, encrypt=false, evidenceStoreRef=null)</code> — hidden-sheet persistence fallback</strong><br><strong>Purpose & contract:</strong> persist artifact into hidden worksheet using deterministic chunk schema when filesystem persistence not available (Excel Web, restricted). Return <code>{success, sheetName, artifactId, evidenceRef}</code> and emit pq.util.atomic_write.degraded. <br><strong>Schema & governance:</strong> store JSON header in cell A1 with <code>{artifactId, timestamp, mChecksum, correlationId, encrypted}</code> and base64-encoded chunks in subsequent rows in a deterministic layout; when <code>encrypt=true</code> store base64 encrypted payload and persist decryption keys to secure evidence store only accessible by operator SRE with appropriate approvals. <br><strong>Recovery:</strong> HiddenSheetInspector enumerates artifacts; AtomicWriteRepairPQ performs extraction to filesystem and verification under maintenance. Hidden-sheet persistence is temporary and must be recovered to file storage where possible. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>InspectTempArtifactsPQ(searchRoots, olderThan=null, correlationId=null)</code> — enumerate leftover temp objects and fallbacks</strong><br><strong>Purpose & contract:</strong> scan <code>searchRoots</code> on local host and workbooks for <code>.pqpart</code> temporary files and hidden-sheet stored artifacts; return inventory with <code>foundItems:[{type, pathOrSheet, size, mChecksum, mtimestamp, suggestedAction}]</code>. Emit pq.util.atomic_write.inspect audit referencing inventoryHash. <br><strong>Operator usage:</strong> run daily housekeeping or diagnostics collect to identify stale temps for repair or cleanup. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong><code>AtomicWriteRepairPQ</code> runbook & operator steps (practical)</strong><br><strong>High-level steps:</strong><br>1. Run InspectTempArtifactsPQ for correlationId to list candidate temp artifacts. <br>2. For each candidate run AtomicWriteRepairPQ to validate payload checksum against sidecar <code>payload.metadata.json</code>. <br>3. If verified, rename to intended target under maintenance window and fsync parent; emit pq.util.atomic_write.repair. <br>4. If invalid, copy artifact to evidence hot store, record forensic_manifest entry, and remove unsafe temp file. <br><strong>Escalation:</strong> if repair fails repeatedly or multiple artifacts show verification failures, open infra incident with forensic_manifest and audit_tail. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (detailed mapping)</strong><br><strong>Audit schema mandatory fields:</strong> timestamp, correlationId, module=<code>PQ_Utilities</code>, procedure, operatorId (optional), paramsHash, resultHash (optional), evidenceRef (optional), configHash, templateId, templateVersion, mChecksum, artifactChecksum, metadata object containing <code>{duration_ms, attempts, tempPathList, hostContext, fallbackUsed, normalizedLength}</code>. <br><strong>Representative ErrorCodes & operator guidance:</strong> pq.atomic_write.ENOSPC — run ENOSPC runbook and attempt staged local fallback; pq.atomic_write.EPERM — ACL issue; pq.atomic_write.DEGRADED — fallback used; pq.atomic_write.VERIFICATION_FAILED — artifact mismatch, inspect temp artifacts; pq.retry.EXHAUSTED — retries exhausted, consider idempotency and check transient infrastructure; pq.param.TYPE_MISMATCH — bad parameter types; pq.inject.HOST_RESTRICTED — host security prevents injection; pq.rng.BAD_SEED — seed derivation failure. Map error codes to SafeErrorToUser messages with remediation steps. <br><strong>Metrics (locally buffered):</strong> pq.atomic_write.latency_ms, pq.atomic_write.success_rate, pq.mchecksum.compute_time_ms, pq.retry.attempt_count, pq.rng.seeded_count. Buffer metrics locally until CORE_Telemetry uploads audited batches. Utilities must not perform remote network exports in preview fast paths. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Security, privacy & PII constraints:</strong><br>1. Do not place PII in top-level audit fields; sanitize PII before audit-row publish. <br>2. When parameterValues contain PII and required to persist, store sanitized param hashes in audit and full parameter payload encrypted in evidence store with access controls; reference by evidenceRef in audit. <br>3. Hidden-sheet fallback payloads containing regulated data must be encrypted; if encryption not possible, disallow fallback for templates marked <code>disallow_hidden_fallback</code> and enforce host error. <br>4. Seeds for RNGs must be treated as sensitive for regulated runs; only store seedFingerprint and evidenceRef for serialized state in audits. <br>5. Evidence store encryption and key rotation enforced by CORE_Security; PQ_Utilities should call policy endpoints to get evidenceRef and not roll their own key management. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-runtime golden governance (comprehensive)</strong><br><strong>Unit tests (required):</strong><br>1. ComputeMChecksum: whitespace/comment permutations, literal normalization (numbers, dates), field-order permutations; negative tests for non-UTF8 and fragment mode. <br>2. ParameterizeM: AST-level substitution, injection-safety against crafted parameter strings that could attempt to close context. <br>3. AtomicWritePQ: simulated rename/fsync failures, ENOSPC, cross-volume rename, hidden-sheet fallback. <br>4. Retry: deterministic_jitter and cancellation behavior. <br>5. DeterministicRNG_PQ: seed parity vectors across supported runtimes (XLAM JS, worker runtime, CLI). <br><strong>Integration tests:</strong><br>1. End-to-end preview->commit: extract parameters -> preview (seeded) -> commit (AtomicWritePQ) -> Add_Query_From_M_SafePayload -> verify workbook query exists and artifactChecksum match. <br>2. Hidden-sheet fallback recovery: write to hidden sheet under host restriction -> run AtomicWriteRepairPQ on worker -> verify artifact persisted and checksums match. <br>3. ExportMWithDiagnostics round-trip; load bundle into evidence store and verify normalizedM present and checksums match. <br><strong>Property & fuzz tests:</strong><br>1. Parity tests ensuring ComputeMChecksum stable across random whitespace/comment mutations. <br>2. RNG property tests: split streams independence and reproducibility. <br>3. Parameterization fuzzing for injection safety. <br><strong>CI gating:</strong> golden vectors for mChecksum and RNG parity must pass; static analyzer must detect and block forbidden UI-thread IO. Performance budgets for mChecksum and AtomicWrite enforced in smoke tests. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always compute and persist mChecksum before committing or injecting an authoritative template; include mChecksum in commit audits. <br>2. For preview, use ParameterizeM in preview mode and require explicit operator commit to persist artifact. <br>3. Always seed DeterministicRNG_PQ from correlationId for operator-visible randomness and persist serialized RNG state when replay needed. <br>4. Use AtomicWritePQ for artifacts consumed by other services; hidden-sheet fallback only when unavoidable and flagged in template. <br><strong>Forbidden patterns:</strong><br>1. Do not perform raw string concatenation for parameter injection; AST-level substitution only. <br>2. Do not write final artifacts directly to the target path on UI thread (static analyzer will reject). <br>3. Do not store PII in top-level audits; use evidenceRef to full encrypted payloads. <br>4. Do not rely on M runtime decimal rounding for regulated numeric outputs—offload numeric-sensitive steps to worker SafeRound flows. <br><strong>Code-review checklist:</strong> ensure ComputeMChecksum used; Ensure ParameterizeM AST-level substitution; ensure AtomicWritePQ for persisted artifacts; ensure deterministic RNGs with correlationId and audit emissions for seedFingerprint; ensure no UI-thread blocking IO. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (practical, step-by-step)</strong><br><strong>AtomicWritePQ ENOSPC runbook:</strong><br>1. Locate pq.util.atomic_write.ENOSPC audit rows for correlationId and extract targetPath, tempPaths, artifactChecksum. <br>2. SSH to host and run df -h for mount in question; collect <code>vmstat</code> and <code>iostat</code> for timeframe. <br>3. If safe and policy allows, move non-critical artifacts to fallback staging on same mount or expand volume; prefer staging on same volume to avoid cross-volume atomicity issues. <br>4. If <code>cleanupOnFailure</code> allowed, run AtomicWriteRepairPQ to inspect temp artifacts for recoverable payloads and rename under maintenance. <br>5. Re-run export with <code>--stage-local</code> and verify artifactChecksum compare against previous expectation. <br>6. If persistent, open infra incident with forensic_manifest and audit_tail and escalate to SRE. <br><strong>Non-deterministic preview triage runbook:</strong><br>1. Retrieve pq.util.rng.seeded audit for correlationId and fetch evidenceRef to serialized RNG state if present. <br>2. Re-run preview replay using serialized RNG state and parameterized normalizedM; present reproduced preview to requester. <br>3. If mismatch persists, compare parity vectors across runtime implementations and escalate to PQ_Utilities owners with parity evidence. <br><strong>mChecksum mismatch forensic steps:</strong><br>1. Retrieve pq.util.mchecksum.mismatch audits and evidenceRef for expected artifact and computed normalizedM. <br>2. Run MChecksumCompare in reconcile mode to produce semanticDiffs and commentDiffs. <br>3. If only commentDiffs, update manifest or record reconcile action; if semanticDiffs, pause injection and file incident with compliance. <br><strong>Hidden-sheet fallback recovery:</strong><br>1. Use InspectTempArtifactsPQ to discover hidden-sheet artifacts. <br>2. Use AtomicWriteRepairPQ on worker to extract and persist artifact to filesystem; verify checksums and emit pq.util.atomic_write.repair. <br>3. Notify operator and mark artifact as recovered in evidence manifest. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Extremely detailed long-form narratives & examples (multiple real-world scenarios)</strong><br><strong>Scenario A — Regulated template injection with high-precision numeric transforms (full trace):</strong><br>1. Template metadata flags <code>requiresHighPrecision=true</code>. Operator initiates <code>Apply Template</code> from PQ_Ribbon with correlationId <code>pq-reg-20260117-555</code>. Ribbon emits UserAction audit. <br>2. PQ_Ribbon calls ExtractParametersFromM, operator supplies params; preview performed with DeterministicRNG_PQ seeded from correlationId for any sampling, and preview audit pq.util.inject.preview recorded with paramsHash and preview mChecksum. <br>3. Since <code>requiresHighPrecision</code> true, the commit path refuses to rely on in-host M rounding. The orchestration schedules a worker job. JobDescriptor persisted via AtomicWritePQ to <code>jobs/job-...json</code> with mChecksum, paramsHash, correlationId. pq.util.atomic_write.completed emitted for job descriptor with artifactChecksum. <br>4. Worker picks up job, serializes RNG state and emits pq.util.rng.state_serialized evidenceRef. Worker loads canonicalized input snapshot and calls REG_Utilities.SafeRoundResiduals for allocation rounding with specified tieBreakerKeys. Worker emits reg.util.saferound.complete with inputHash and outputHash evidenceRef. <br>5. Worker constructs final normalized artifact (CSV/Parquet) and persists with AtomicWritePQ to <code>exports/</code> with artifact.metadata.json containing <code>mChecksum</code>, <code>safeRoundEvidenceRef</code>, <code>paramsHash</code>. pq.util.atomic_write.completed emitted with artifactChecksum. <br>6. Orchestration updates template commit flow to reference the authoritative artifact; Add_Query_From_M_SafePayload injects query pointing to authoritative persisted artifact rather than inlined computed values. pq.util.inject.commit emitted linking queryName to artifactChecksum and safeRound evidence. <br>7. Forensic replay: given correlationId, auditors can retrieve jobDescriptor, serialized RNG state, reg.util.saferound audits, and final artifact to fully replay allocation and reproduce exact numeric outputs. <br><strong>Takeaways:</strong> delegation of numeric authority to worker SafeRound ensures cross-host parity and auditable deterministic chain linking UI to worker operations and persisted artifacts. <br><strong>Scenario B — Template repo synchronization and automated reconcile:</strong><br>1. A central template repo publishes updated templates. An admin runs <code>pq repo sync</code>. PQ_Utilities downloads remote templates and streams them through MChecksumStream to compute normalized checksums. MChecksumCompare invoked for each template against local artifact. <br>2. For templates with only comment/whitespace changes, <code>MChecksumCompare</code> yields <code>commentDiffs</code>; the synchronizer can optionally auto-accept such diffs when policy allows and emit pq.util.mchecksum.reconcile with reconcile=true. For semantic diffs, repo sync produces a PR and pings template owner for review. <br>3. After owner approval, AtomicWritePQ atomically replacing local canonical artifact persists new normalizedM and new mChecksum, and pq.util.atomic_write.completed emitted. <br>4. If a downstream injection attempted to use an older mChecksum, the pq.util.mchecksum.mismatch audits will show expected vs actual and the inject flow will logically reject injection until owner acceptance occurs. <br><strong>Scenario C — Excel Web hidden-sheet fallback and later recovery:</strong><br>1. Operator in Excel Web attempts to commit template; filesystem writes are not allowed by host. AtomicWritePQ detects sandbox and invokes TempHiddenSheetFallback, which writes artifact into <code>HiddenSheet@PQ_TEMPLATES</code> with encrypted base64 chunks and header cell A1 containing metadata; pq.util.atomic_write.degraded emitted. <br>2. Operator notified: "Commit staged in workbook hidden-sheet — please recover on authorized workstation." <br>3. Operator opens desktop dev workstation and runs <code>pq artifacts extract --correlation pq-...</code> which invokes HiddenSheetInspector to locate artifacts, then AtomicWriteRepairPQ to extract and persist artifact onto local filesystem via AtomicWritePQ; pq.util.atomic_write.repair and pq.util.atomic_write.completed emitted. <br>4. After recovery, injection proceeds from persisted artifact and all audit rows link back to original correlationId and evidenceRef. <br><strong>Scenario D — Forensic reconstruction after injection mismatch report:</strong><br>1. Support receives incident "injected query logic differs from template used in run pq-20260112-455". <br>2. Support retrieves pq.util.inject.preview, pq.util.atomic_write.completed, pq.util.inject.commit audits for correlationId and obtains artifactChecksum and evidenceRef for normalizedM. <br>3. Support runs MChecksumCompare between expected normalizedM and artifact; if mismatch, inspect atomic_write.verification_failed or hidden-sheet degrade logs to determine if commit used stale or unreconciled artifact. <br>4. If commit bypassed artifact persistence (a forbidden pattern flagged by static analyzer), escalate for corrective changes and re-run CI gating; if commit artifact corrupted in transit, reconstruct from evidenceRef and repair using AtomicWriteRepairPQ. <br>5. Compile forensic_manifest.json containing all audits, artifact copies, serialized RNG state; deliver to compliance team. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) mapping — how PQ_Utilities patterns apply to M workflows</strong><br><strong>Context & rationale:</strong> Power Query M runtimes (desktop, web, service) vary in numeric fidelity and host capabilities; PQ_Utilities provide orchestration model ensuring authoritative behavior and reproducibility by moving critical steps out of fragile client-only contexts and into auditable persisted artifacts. <br><strong>Patterns & mappings:</strong><br>1. <strong>Persist-first injection pattern:</strong> templates should be persisted (normalizedM + artifact metadata) and verified via ComputeMChecksum before the workbook receives injected queries. Use Add_Query_From_M_SafePayload to ensure injection references persisted artifact and links to artifactChecksum. <br>2. <strong>Preview determinism pattern:</strong> generate preview selections deterministically by seeding RNG from correlationId and passing numeric seed into template M or computing sample server-side. Store seedFingerprint in pq.util.rng.seeded audit to facilitate replay. <br>3. <strong>High-precision numeric offload:</strong> where templates require regulated numeric behavior, offload numeric aggregation and residual distribution to worker SafeRound routines; M templates reference persisted numeric artifacts produced by workers rather than computing final regulated numbers client-side. <br>4. <strong>Parameter safety mapping:</strong> ParameterizeM performs AST-level literal encoding; never perform raw string concatenation for connection strings or queries. Sensitive parameters stored only in encrypted evidence store; audit rows only contain param hashes. <br>5. <strong>Fallback & recovery mapping:</strong> when host restrictions prevent atomic filesystem writes, use TempHiddenSheetFallback and ensure later AtomicWriteRepairPQ recovers authoritative artifacts onto durable storage; always emit pq.util.atomic_write.degraded so operators and SREs can prioritize recovery. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX mapping — how PQ_Utilities fit into semantic models and DAX best practice</strong><br><strong>Context:</strong> DAX is read-time language; cannot perform side effects or persistent operations. PQ_Utilities produce authoritative artifacts and run metadata that DAX and semantic models can consume for provenance and verification. <br><strong>Key patterns & recommendations:</strong><br>1. <strong>Persist RunMetadata:</strong> ETL/worker write a <code>RunMetadata</code> table atomically (via AtomicWritePQ) containing correlationId, templateId, mChecksum, artifactChecksum, runTs, and verificationState. Model ingest of RunMetadata enables DAX measures to display verification badges and time-of-run provenance. <br>2. <strong>Avoid in-DAX rounding for authoritative values:</strong> perform SafeRoundResiduals during ETL (REG_Utilities) and persist integer cents or canonical decimals. DAX then reads authoritative columns for aggregations and displays. <br>3. <strong>Deterministic sampling via persisted flags:</strong> ETL computes <code>sampleHash = HASH(PrimaryKey | correlationSalt)</code> and persists <code>SampleFlag</code> boolean used in DAX filters; this avoids implementing random seeds in DAX and supports deterministic repeatable samples. <br>4. <strong>Checksum-based reconciliation measures:</strong> create DAX measures that compare <code>ModelLoadedChecksum</code> to <code>ExpectedArtifactChecksum</code> from RunMetadata to produce <code>IsVerified</code>. Use time-aware measures to show last verified run timestamp. <br><strong>DAX example conceptual measure (not code):</strong> a measure <code>IsArtifactVerified</code> uses the maximum artifactChecksum found in <code>RunMetadata</code> and compares to <code>ExpectedArtifactChecksum</code> loaded into the model; returns verification status displayed in the report. <br><strong>Operational note:</strong> PQ_Utilities' evidenceRef and audit rows should be accessible via auxiliary datasets (smaller, indexed tables) so DAX-based dashboards can surface links or short summaries without exposing PII or large artifacts. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Appendices — forensic artifacts, evidence paths & retention (detailed)</strong><br><strong>Minimum PQ forensic artifacts for an incident:</strong><br>1. preview.audit.json and inject.audit.json for correlationId with paramsHash and preview mChecksum. <br>2. persisted artifact file(s) with <code>artifact.metadata.json</code> including mChecksum, normalizedMRef, templateVersion, correlationId. <br>3. serialized RNG state (rng_state.blob) when preview sampling used. <br>4. hidden-sheet artifacts listing with base64 chunks and header metadata. <br>5. AtomicWrite temp artifacts and repair logs. <br>6. normalized decimal snapshots when numerics offloaded to worker. <br><strong>Evidence storage & retention policy:</strong><br>1. Hot evidence store: <code>\\evidence\pq\hot\&lt;correlationId&gt;\</code> kept 30 days with restricted access. <br>2. Warm archive: secure encrypted archive for regulatory retention, default 7 years; maintain chain-of-custody and proof-of-rotate metadata. <br>3. Forensic_manifest.json: enumerates artifact URIs, checksums, evidenceRef, and signature fingerprints where present. <br><strong>Retention & verification cadence:</strong> monthly retention verification job emits housekeeping.audit and proof-of-delete manifests for removed items; evidence rotations recorded in audit rows. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before release (detailed):</strong><br>1. Owners listed and contactable in PQ/OWNERS.md. <br>2. Public API documented with semantic versioning in release manifest. <br>3. Golden parity tests for ComputeMChecksum across runtimes passing. <br>4. AtomicWritePQ cross-platform behavior validated (rename/fsync, fallback paths). <br>5. DeterministicRNG_PQ parity vector validated across runtimes. <br>6. Audit hooks validated by test harness emitting expected audit rows. <br>7. CI static checks disallow forbidden host IO patterns. <br><strong>Blocking conditions:</strong> missing audit emissions on persistence flows, failing parity golden tests, or static analyzer detecting direct workbook writes in OnLoad paths. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Testing & QA plan (highly detailed):</strong><br><strong>Unit test groups (representative)</strong><br>1. mChecksum unit suite: whitespace/comment permutations, literal normalization, record field ordering edge cases, fragment mode tests with expected normalizedM outputs. <br>2. Parameterization suite: correct AST-level substitution and escaping, type validation boundary cases, sensitive param redaction behavior. <br>3. AtomicWrite suite: simulated rename and fsync failures, ENOSPC, ReplaceFile lock contention, cross-volume rename attempts, hidden-sheet fallback path. <br>4. Retry suite: deterministic_jitter reproducibility tests, cancellation token behavior, idempotency assertion enforcement. <br>5. RNG suite: seed parity across runtimes, splitStream independence, serialize/restore roundtrip tests. <br><strong>Integration tests (representative)</strong><br>1. Preview->Commit roundtrip: preview audit, commit persistence via AtomicWritePQ, injection via Add_Query_From_M_SafePayload, verification of workbook query and artifactChecksum. <br>2. Export+Diagnostics: ExportMWithDiagnostics produce artifact bundle; worker reimports bundle and validates normalizedM and diagnostics. <br>3. Hidden-sheet repair: simulate host restriction -> write to hidden sheet -> extract & repair via AtomicWriteRepairPQ on worker -> verify artifact checksum. <br><strong>Performance & stress tests:</strong><br>1. ComputeMChecksum throughput on 1MB templates under worker environment; ensure median acceptable and 95th percentile within budget. <br>2. AtomicWritePQ concurrency stress: multiple writers to same directory with deterministicSuffix to ensure safe temp file naming and conflict handling. <br>3. Retry overhead microbenchmarks to ensure retry wrapper overhead acceptable. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & examples (practical):</strong><br>1. <code>pq diagnostics collect --correlation pq-YYYYMMDD-abc</code> — gathers preview & inject audit rows, artifact metadata, RNG state, normalizedM evidence, and builds forensic_manifest.json. <br>2. <code>pq atomic_write.repair --temp &lt;tempPath&gt;</code> — validate temp payload and attempt safe rename under maintenance window; logs results and emits pq.util.atomic_write.repair. <br>3. <code>pq replay.run --correlation pq-... --evidenceRef &lt;evidence&gt;</code> — deterministic replay using serialized RNG state and normalizedM; supports <code>--dry-run</code> to verify only. <br>4. <code>pq templates reconcile --repo &lt;url&gt;</code> — runs MChecksumStreamCompare against remote repo and produces reconcile report with semantic/comment diffs for owner review. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded):</strong><br><strong>Partial write observed by downstream consumer</strong><br>1. Likely cause: direct write to final path bypassing AtomicWritePQ, or rename semantics broken on network FS. <br>2. Mitigation: enforce AtomicWritePQ for all persisted artifacts; implement static analyzer rules blocking direct writes; if network FS unavoidable use two-phase copy + meta-stamp pattern and mark artifact as <code>staged</code> until commit completes. <br><strong>Non-deterministic preview complaint</strong><br>1. Likely cause: global RNG or time-based seed used by preview code. <br>2. Mitigation: require DeterministicRNG_PQ seeded from correlationId; persist seedFingerprint in preview audit and provide replay tool. <br><strong>Rounding bias detected across repeated runs</strong><br>1. Likely cause: naive rounding (e.g., away-from-zero) used repeatedly creating drift. <br>2. Mitigation: adopt bankers rounding or residual_distribute strategies at ETL (REG_Utilities.SafeRoundResiduals); run property tests and golden vectors and persist rounding evidence. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests for new behavior and golden mChecksum vectors if normalization rules change. <br>2. Any change to canonicalization or RNG algorithm requires owner approval and release manifest update. <br>3. Changes to AtomicWritePQ semantics require cross-platform regression tests and SRE sign-off. <br>4. Audit wiring must be validated with test harness emitting expected audit rows on success and failure paths. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Long-form operator scenario: incident reconstruction example (explicit steps)</strong><br><strong>Incident:</strong> "Injected query result differs from authoritative template for run pq-20260112-455" <br><strong>Forensic reconstruction ordered steps:</strong><br>1. Retrieve related audit rows: pq.util.inject.preview, pq.util.inject.commit, pq.util.atomic_write.completed; collect paramsHash, preview mChecksum, artifactChecksum. <br>2. Fetch artifact via artifactChecksum from persisted artifacts. <br>3. Obtain normalizedM from evidenceRef and serialized RNG state if preview sampling used. <br>4. Run ParameterizeM with recorded parameter values and restore RNG state -> replay preview sample and compute mChecksum; compare to recorded artifactChecksum. <br>5. If mismatch arises, inspect pq.util.atomic_write.verification_failed or pq.util.atomic_write.degraded audits to locate potential persistence faults or fallback usage. <br>6. Package forensic_manifest.json with audit_tail, artifact copies, RNG state, normalizedM, and jobDescriptor; deliver to compliance with chain-of-custody metadata. <br><strong>Outcome:</strong> either reproduce mismatch, identify and patch pipeline or confirm pipeline correctness and close incident with documented findings. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Appendix — PQ & DAX short checklists for template authors and report builders (succinct):</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>templateId</code>, <code>templateVersion</code>, and <code>mChecksum</code> in template metadata. <br>2. Mark templates requiring strict numeric fidelity as <code>requiresHighPrecision</code>. <br>3. Use parameter schema declarations and avoid time-based seeds; accept external seed parameter for preview determinism. <br>4. Indicate allowed fallback modes (hidden-sheet allowed/disallowed). <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> table for provenance and artifactChecksum. <br>2. Avoid performing allocation/residual rounding in DAX; rely on ETL authoritative fields. <br>3. Use persisted <code>SampleFlag</code> computed in ETL for deterministic reporting samples. </td></tr><tr><td data-label="PQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Closing operational constraint (non-negotiable):</strong><br>All PQ flows producing artifacts consumed downstream must: persist canonical normalizedM and compute mChecksum, seed deterministic RNGs from correlationId for operator-visible randomness, use AtomicWritePQ for authoritative artifacts, and emit audit rows with evidenceRef for large/forensic payloads. This is mandatory for regulated or PII-touching workflows and enforced by static analysis and CI gates. </td></tr></tbody></table></div><div class="row-count">Rows: 38</div></div><div class="table-caption" id="Table2" data-table="Docu_0180_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Library — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Library — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (authoritative contract & purpose):</strong><br><strong>Owner:</strong> TEAM_PQ_LIBRARY (listed in OWNERS.md with rotation, approvers, escalation contacts).<br><strong>Public API (complete surface):</strong> LoadLibraryIndex, LoadEmbeddedHiddenSheet, ListTemplates, GetTemplateById, ResolveTemplateVersion, ComputeMChecksum, ValidateTemplateSchema, ImportTemplateFromFile, ImportTemplateFromRepo, ExportTemplatePackage, PublishTemplate, UnpublishTemplate, DeactivateTemplate, TemplateDiff, ApplyTemplatePatch, SignTemplateArtifact, VerifyTemplateSignature, BackupLibraryIndex, RestoreLibraryIndex, InspectHiddenSheetFallback, PromoteHiddenSheetToRepo, WatchRemoteRepo, ResolveTemplateDependencies, MapTemplateToPreviewParameters, ResolveParameterDefaults, RenderPreviewM, GetTemplateOwners, SetTemplateOwners, TemplateAuditEntry, TemplateMetricsSnapshot, PruneOldVersions, RepairCorruptEntry, AtomicPersistIndex, InspectTemplatePayload, StageTemplateForApproval, ApprovalsQuery, DenyPublishWithReason, PromoteCandidateToPublished, GenerateTemplateChangeLog, AuditEvidenceBundle, IndexRotationPolicyManager.<br><strong>Primary audits emitted:</strong> pq_library.load, pq_library.access, pq_template.preview, pq_template.inject.prepare, pq_template.inject.completed, pq_template.publish, pq_template.unpublish, pq_template.signature.verify, pq_library.index.persist.attempt, pq_library.index.persist.completed, pq_library.index.repair, pq_library.hidden_sheet.fallback, pq_library.import.attempt, pq_library.import.completed, pq_library.import.failure, pq_template.validate, pq_template.mChecksum.compute, pq_library.backup, pq_library.restore. Each audit row MUST include correlationId, module=PQ_Library, procedure, paramsHash, templateId/version where relevant, resultHash or artifactChecksum, operatorId when interactive, and evidenceRef when the payload is non-trivial. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>High-level purpose & usage constraints:</strong><br>PQ_Library is the authoritative steward for Power Query (M) templates and template metadata. It ensures deterministic canonicalization and checksumming of M payloads (<code>mChecksum</code>), manages a canonical index of templates (versions, owners, channels), enforces publish/approval policies, provides robust import/export and signing workflows, supports an embedded hidden-sheet fallback for offline operation, and supplies diagnostic and forensic artifacts for reproducibility and regulator audit. PQ_Library is used by ribbon handlers for read-only operations, by worker processes for mutating operations (import, publish, sign), and by CI pipelines for goldens and release gating. It intentionally avoids running heavy network or disk IO on the UI thread; any ribbon-initiated mutation must generate a correlationId and schedule a worker job. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Non-goals & constraints (enforced by static checks):</strong><br>1. Not a general-purpose VCS — do not attempt to provide full branching/merge semantics. Use integrated repo tools for that. <br>2. No secret management — signing keys and tokens stored and used only in CORE_Security or CI/worker contexts. <br>3. No heavy runtime evaluation of templates in ribbon context; static checks allowed, but full execution and numeric-critical operations are worker-only. <br>4. Changes to canonicalization or checksum semantics require a migration manifest, owner approval, and cross-language golden updates. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Operational guarantees & invariants (detailed):</strong><br>1. Determinism: <code>ComputeMChecksum</code> canonicalization + digest algorithm produce identical results across supported runtimes and platforms for the same logical template input. <br>2. Audit anchoring: any change to index, publish state, signature attachments, or hidden-sheet promotions must emit an audit row with correlationId and evidenceRef when payloads exceed audit size. <br>3. Crash-safety: index updates must be atomic using <code>AtomicPersistIndex</code>, guaranteeing either previous index remains or new index fully replaces it. <br>4. Fallback semantics: embedded hidden-sheet fallback is read-only, auditable, and persisted to evidence store on first use to allow later promotion and forensic replay. <br>5. UI safety: no blocking network or heavy FS operations on the ribbon thread; static checks only. <br>6. Observability: Start/complete/failure audits plus buffered metrics are emitted for all long-lived flows. <br><strong>Performance SLOs:</strong> list/get median <50ms on small indexes; <code>ComputeMChecksum</code> median <100ms for typical 10–50KB templates; index persist median <200ms on local SSD; CI gating produces golden verification within CI budget thresholds. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Implementation principles (architectural & design rationale):</strong><br>1. Canonicalize before checksumming — avoid spurious mismatches from formatting, line endings, or editor variants. <br>2. Minimal trusted surface — signing performed only in worker/CI with secured keys; verification in clients. <br>3. Worker-first for mutating operations — imports, publishes, and remote fetches are delegated to workers. <br>4. Evidence-driven auditing — large payloads referenced by evidenceRef; audits contain only parameter hashes for privacy. <br>5. Cross-language parity — provide golden vectors and reference implementations for <code>ComputeMChecksum</code> and <code>TemplateDiff</code> in supported languages. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Index & artifact model (concise canonical model):</strong><br><strong>Index entry shape (canonical fields):</strong> templateId, version, title, channel, mChecksum, artifactPath, signaturePath (optional), owners[], tags[], requiresHighPrecision (bool), createdAt, publishedAt, status (candidate/published/deprecated), metadata (freeform). Each index entry may reference evidenceRef for large inline payloads or notes. Index serialization must produce canonical JSON (sorted keys, stable ordering) for reproducible indexHash. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Per-function, exhaustive technical breakdowns (begin):</strong> </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>LoadLibraryIndex(indexPath, validate=true, correlationId=null)</code> — authoritative index loader & verifier</strong><br><strong>Purpose & contract:</strong> read the index file (JSON) describing templates, compute <code>indexHash</code>, optionally validate against JSON Schema v7, and return a deterministic, canonicalized index structure. Must be read-only in ribbon context; heavy validation and repair flows run in worker context. Returns <code>{index, indexHash, loadedFrom, validationReport}</code> or raises deterministic error codes: <code>PQ_LIB_INDEX_NOT_FOUND</code>, <code>PQ_LIB_INDEX_CORRUPT</code>. <br><strong>Inputs & outputs:</strong> <code>indexPath</code> (file path or repo meta endpoint), <code>validate</code> boolean; output an ordered index structure with stable iteration order (sorted by <code>templateId</code> then <code>version</code>). <br><strong>Detailed algorithm notes:</strong><br>1. Read file with safe-read helper (avoid partial reads). <br>2. Compute SHA256 over canonical JSON (sorted keys, deterministic whitespace) -> <code>indexHash</code>. <br>3. If <code>validate</code> run JSON Schema checks and collect <code>validationReport</code> with severity-coded entries. <br>4. If fatal schema errors and <code>validate==true</code> return <code>PQ_LIB_INDEX_INVALID_SCHEMA</code>; if permissive mode allow best-effort index with warnings. <br><strong>Invariants & observability:</strong> return deterministic ordering; emit audit <code>pq_library.load(correlationId, indexPath, indexHash, validationSummary)</code>. <br><strong>Edge cases & remediation:</strong> missing file -> <code>PQ_LIB_INDEX_NOT_FOUND</code> with remediation suggestion to run <code>BackupLibraryIndex</code> or <code>RestoreLibraryIndex</code>. Corrupt JSON -> persist corrupted copy to evidenceRef and emit <code>pq_library.index.corrupt</code> for manual review. <br><strong>Testing:</strong> corrupt index fixture, large-index performance test, schema regression tests, cross-language indexHash parity. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>LoadEmbeddedHiddenSheet(workbook, sheetName=&quot;pq_templates&quot;, correlationId=null)</code> — fallback ingestion</strong><br><strong>Purpose & contract:</strong> parse an embedded hidden sheet used as a local template repository fallback. Must be non-blocking for ribbon handlers; keep parsing shallow. For large embedded payloads, persist sanitized copies to evidence store and return <code>evidenceRef</code> instead of full inline payload. <br><strong>Behavioral notes:</strong><br>1. Expect header row with canonical fields: <code>templateId</code>, <code>version</code>, <code>title</code>, <code>mChecksum</code>, <code>owners</code>, <code>requiresHighPrecision</code>, <code>tags</code>, <code>createdAt</code>, <code>payloadRef</code> or payload cell. <br>2. Normalize headers forgivingly and map known aliases. <br>3. For multiline payloads persist to evidence store and return <code>evidenceRef</code>. <br>4. Emit audit <code>pq_library.hidden_sheet.fallback(correlationId, workbookId, rowCount, indexHash)</code>. <br><strong>Edge cases:</strong> missing sheet -> <code>PQ_LIB_HIDDEN_SHEET_MISSING</code>. Truncated cells -> persist truncated artifact and emit <code>pq_library.hidden_sheet.truncated</code> with row fingerprint. <br><strong>Testing:</strong> header permutations, Excel line-end normalization, embedded RTF and control character handling. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ListTemplates(index, filter=null, sort=null, pagination=null)</code> — query enumerator</strong><br><strong>Purpose & contract:</strong> return deterministic filtered, sorted, and paginated template metadata without returning full payloads unless <code>includePayload=true</code>. Sorting stable fallback: <code>templateId</code> asc then <code>version</code> desc. <br><strong>Filter & return semantics:</strong> filters support owner, tag, channel, requiresHighPrecision, <code>templateIdPrefix</code>. Always include <code>returnedHash</code> of the resulting view for caching and audit. <br><strong>Observability:</strong> <code>pq_library.access(correlationId, action=list, filterHash, returnedCount)</code>. <br><strong>Tests:</strong> performance on large indexes (10k+ templates), Unicode tag matching, stable pagination under concurrent modifications. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>GetTemplateById(index, templateId, version=null, includePayload=false, allowRemoteFetch=false)</code> — canonical fetch</strong><br><strong>Purpose & contract:</strong> return metadata and optionally the M payload for the resolved version. If <code>version==null</code> resolves to latest stable version per <code>ResolveTemplateVersion</code>. If <code>includePayload==true</code> but payload absent locally and <code>allowRemoteFetch==true</code>, perform worker-only remote fetch and persist artifact; otherwise fail with <code>PQ_LIB_PAYLOAD_MISSING</code>. Returned payload must be verified against <code>mChecksum</code>. <br><strong>Invariants:</strong> resolved <code>version</code> and returned <code>mChecksum</code> must match computed checksum over returned <code>mText</code>. <br><strong>Audits:</strong> <code>pq_library.access(correlationId, action=getTemplate, templateId, version, includePayload)</code>. <br><strong>Edge cases:</strong> local artifact present but mChecksum mismatch -> mark template corrupted and create repair candidate; emit <code>pq_library.import.failure</code>. <br><strong>Tests:</strong> remote fetch simulated timeouts, permission-denied scenarios, idempotent fetch behavior. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ResolveTemplateVersion(index, templateId, versionConstraint, policy=&quot;default&quot;)</code> — stable version resolver</strong><br><strong>Purpose & contract:</strong> resolve version constraints (exact, semver ranges, tags like <code>latest|stable|beta</code>) deterministically. Consider <code>stability</code> flags, owner locks, deprecations, and channel rules. Return <code>{resolvedVersion, resolutionConfidence, candidates}</code>. <br><strong>Deterministic tie-breaker:</strong> when multiple versions satisfy constraint, tie-break by <code>channelPriority</code> then <code>publishedAt</code> desc then <code>versionSemver</code> desc. <br><strong>Audits:</strong> <code>pq_library.version.resolved(correlationId, templateId, constraint, resolvedVersion)</code>. <br><strong>Edge cases:</strong> ambiguous constraint -> return best candidate with <code>resolutionConfidence&lt;1.0</code> and log a <code>pq_library.version.ambiguous</code> audit. <br><strong>Tests:</strong> varied constraint patterns and owner-lock enforcement. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ComputeMChecksum(mText, algorithm=&quot;sha256&quot;, canonicalize=true, canonicalRules=default)</code> — canonicalization + checksum primitive (exhaustive)</strong><br><strong>Purpose & contract:</strong> compute a deterministic digest for M templates intended to be identical across languages and platforms. This digest is the primary artifact identifier for publishing, injecting, auditing, and CI gating. A change to <code>ComputeMChecksum</code> semantics requires migration manifest and cross-language golden updates. <br><strong>Canonicalization pipeline (step-by-step):</strong><br>1. Normalize Unicode to <strong>NFC</strong>. <br>2. Normalize line endings to LF (<code>\n</code>). <br>3. Remove BOM if present. <br>4. Trim trailing whitespace on each line. <br>5. Normalize indentation where indentation is syntactic sugar: collapse mixed tabs/spaces per canonical indentation unit (default 2 spaces) while preserving indentation semantics around multi-line string literals. <br>6. Normalize parameter placeholders that follow <code>{{param}}</code> syntax to canonical token form when policy allows; otherwise leave them untouched. <br>7. Optionally strip or normalize non-functional comments if configured in <code>canonicalRules</code> (policy controlled; default is to <strong>retain</strong> comments unless annotated <code>//mchecksum-ignore</code>). <br>8. Collapse runs of blank lines to a configured maximum (default 2). <br>9. Canonicalize base64-embedded blobs by normalizing line-wrapping and trimming trailing <code>=</code> if policy instructs. <br><strong>Checksum:</strong> compute SHA256 over the canonical UTF-8 bytes and return hex digest. Optionally provide base64 variant when <code>algorithm</code> requests. <br><strong>Invariants:</strong> canonicalization must not alter semantics of templates; aggressive transformations are forbidden unless the template is explicitly marked for <code>mChecksum_sanitized</code> mode and owners sign off. <br><strong>Audits & evidence:</strong> emit <code>pq_template.mChecksum.compute(correlationId, templateId?, mLen, mChecksum)</code> and persist canonicalized text in evidenceRef when requested for forensic replay. <br><strong>Edge cases & mitigations:</strong><br>- Templates with embedded binary content: treat content as opaque and canonicalize surrounding representation only. <br>- Non-UTF-8 input: decode with <code>utf-8</code> with strict mode where possible; on decoding failures store raw bytes to evidenceRef and return <code>PQ_LIB_MCHECKSUM_INVALID_ENCODING</code>. <br><strong>Tests:</strong> cross-language golden vector sets with Unicode normalization cases, comment-presence toggles, whitespace permutations, base64 variations. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ValidateTemplateSchema(mText, policyProfile=&quot;default&quot;, templateId=null)</code> — static analyzer and policy guard</strong><br><strong>Purpose & contract:</strong> statically analyze M text to detect syntactic errors, policy violations, and connectors or API usages that require owner review or are forbidden. Not a runtime executor; it performs parse-tree analysis and pattern checks. <br><strong>Checks performed (technical):</strong><br>1. Syntax parse for top-level <code>let</code>/<code>in</code> structure and query names. <br>2. Parameter block detection and validation against schema (parameter types, default values, allowed ranges). <br>3. Forbidden API detection: e.g., <code>File.Contents</code> for <code>noLocalFS</code> templates, disallowed connectors for regulated channels, or usage of <code>Extension.LoadFunction</code> flagged for review. <br>4. Hardcoded connection strings or high-confidence PII patterns flagged as <code>HIGH</code> severity. <br>5. Connector sensitivity: if template uses non-approved connectors, mark as <code>REVIEW</code> and require owner signoff. <br><strong>Return:</strong> <code>validationReport</code> with entries containing severity (INFO/WARN/ERROR), ruleId, message, and suggested remediation. <code>isValid</code> true only if no <code>ERROR</code> level findings and mandatory metadata present. <br><strong>Audits:</strong> <code>pq_template.validate(correlationId, templateId, validationSummary)</code>. <br><strong>Tests:</strong> false-positive minimization with representative corpora, policy toggles for different channels. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ImportTemplateFromFile(path, indexPath, sign=false, force=false, correlationId=null)</code> — authoring import pipeline</strong><br><strong>Purpose & contract:</strong> safely import a local file into staging as a candidate template version. Compute <code>mChecksum</code>, validate, optionally sign, stage artifact in artifact store, and update index metadata with candidate status. Do not overwrite published versions unless force & owner approvals provided. <br><strong>Flow details:</strong><br>1. Read file in streaming mode to handle large payloads and compute tentative checksum. <br>2. Run <code>ComputeMChecksum</code> canonicalization to produce authoritative <code>mChecksum</code>. <br>3. Run <code>ValidateTemplateSchema</code>. If validation has <code>ERROR</code> entries reject import unless <code>force</code> and documented owner reason present. <br>4. Persist artifact to staging area using <code>AtomicWrite</code> semantics. <br>5. Create candidate index entry with metadata: <code>templateId</code>, <code>versionCandidate</code>, <code>mChecksum</code>, <code>author</code>, <code>stagedAt</code>, evidenceRef. <br>6. Emit <code>pq_library.import.completed</code> audit including <code>evidenceRef</code> and <code>artifactChecksum</code>. <br><strong>Conflict semantics:</strong> identical <code>mChecksum</code> exists => idempotent success returning existing version info. version conflict without <code>force</code> => <code>PQ_LIB_IMPORT_CONFLICT</code>. <br><strong>Security:</strong> sanitize file paths to avoid path traversal. <br><strong>Tests:</strong> idempotent imports, forced override gating with approvals, signature optional flows. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ImportTemplateFromRepo(repoUrl, templateRef, credentialsRef=null, stagingOnly=true, correlationId=null)</code> — remote import & sync</strong><br><strong>Purpose & contract:</strong> fetch templates or index from remote repos (git, static hosts) into staging for validation. Worker-only due to network IO and potential long-running fetches. Respect repo allowlists and verify repo-level signatures if available. <br><strong>Flow:</strong> fetch manifest or file -> verify repo signature -> ComputeMChecksum -> ValidateTemplateSchema -> sign if requested in staging -> persist artifact via <code>AtomicWrite</code> -> update index candidate list or directly publish if auto-publish policy and all gates satisfied. <br><strong>Failure modes:</strong> network unreachable -> <code>PQ_LIB_REPO_UNREACHABLE</code> with recommended retry schedule; broken certs -> <code>PQ_LIB_REPO_CERT_ERROR</code>. For partial fetches persist evidenceRef for forensic review. <br><strong>Audits:</strong> <code>pq_library.import.attempt/completed/failure</code> with repo metadata. <br><strong>Tests:</strong> auth failure, large repo indexing, shallow clone performance. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>StageTemplateForApproval(templateId, candidateVersion, owners=[], correlationId)</code> & <code>ApprovalsQuery</code></strong><br><strong>Purpose & contract:</strong> create and manage approval workflows for candidate templates. For regulated channels require multi-approver flows; approvals persisted as immutable artifacts in the evidence store. <code>ApprovalsQuery</code> returns the set of recorded approvals for a candidate. <br><strong>Process invariants:</strong> publishing to regulated channel must not happen without recorded required approvals. Approvals must include approverId, timestamp, reason, and optional signed statement. <br><strong>Audits:</strong> <code>pq_library.approval.requested</code>, <code>pq_library.approval.recorded</code>, <code>pq_library.approval.denied</code>. <br><strong>Tests:</strong> simulate two-person approval flows, approval revocation, audit chain validation. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>PublishTemplate(templateId, version, sign=true, owners=[], approvalsRequired=1, channel=&quot;stable&quot;, correlationId=null)</code> — publish & sign flow</strong><br><strong>Purpose & contract:</strong> move candidate to published state after verifying approvals, running final validations, and optionally signing the artifact. Regulated channels require <code>approvalsRequired&gt;=2</code> (two-person approval). Signing is worker-only and uses CORE_Security-managed keys. Update index atomically to mark published and record signature fingerprint. <br><strong>Detailed guardrails:</strong><br>1. Verify artifact exists and <code>mChecksum</code> matches persisted artifact. <br>2. Confirm <code>ValidateTemplateSchema</code> status; owner-accepted exceptions must be present for <code>WARN</code> issues. <br>3. Check approvals: require minimum approvals per channel policy. <br>4. Sign artifact with <code>SignTemplateArtifact</code> in worker; persist signature next to artifact with atomic semantics. <br>5. Update index via <code>AtomicPersistIndex</code> to mark version as published with metadata: <code>publishedBy</code>, <code>publishedAt</code>, <code>signatureFingerprint</code>, <code>channel</code>. <br><strong>Audits:</strong> <code>pq_template.publish(correlationId, templateId, version, artifactChecksum, signFingerprint, approvals)</code>. <br><strong>Failure:</strong> missing approvals -> <code>PQ_LIB_PUBLISH_BLOCKED</code>; signature failure -> <code>PQ_LIB_SIGN_VERIFY_FAILED</code>. <br><strong>Tests:</strong> publish gating, concurrency, revocation path. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>SignTemplateArtifact(artifactPath, signerKeyRef, algorithm=&quot;rsa-pss&quot;)</code> & <code>VerifyTemplateSignature(artifactPath, signaturePath)</code></strong><br><strong>Purpose & contract:</strong> signing performed in trusted worker/CI environments. Create a detach signature and sign metadata (mChecksum, releaseManifestHash). Persist signature atomically adjacent to artifact. Verification available to clients and must validate canonicalized mChecksum. <br><strong>Implementation notes:</strong> use interoperable formats and include signerId, keyFingerprint, timestamp, and canonicalization rules version in signature metadata for future audits. <br><strong>Audits:</strong> <code>pq_template.signature.created</code>, <code>pq_template.signature.verified</code>, <code>pq_template.signature.verify.failed</code>. <br><strong>Tests:</strong> revoked-key handling, tamper detection, signature rotation. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>TemplateDiff(oldM, newM, mode=&quot;semantic&quot;)</code> — AST-aware deterministic diffing</strong><br><strong>Purpose & contract:</strong> produce human- and machine-readable diffs between two M payloads. <code>semantic</code> mode attempts AST-aware diffing and classifies hunks by change type: <code>PARAM_CHANGE</code>, <code>LOGIC_CHANGE</code>, <code>METADATA_CHANGE</code>, <code>CONNECTOR_CHANGE</code>, <code>WHITESPACE_ONLY</code>. If AST parsing fails fallback to line-based diff and mark <code>semantic_unavailable</code>. <br><strong>Return:</strong> structured diff with hunk list, high-level summary, and <code>breakingChange</code> boolean flagged when connector changes or heavy logic modifications detected. <br><strong>Usage:</strong> used by review UIs, CI gating, and operator sign-off flows. <br><strong>Audits:</strong> <code>pq_template.diff(correlationId, templateId, oldVersion, newVersion, diffSummary)</code>. <br><strong>Tests:</strong> AST refactor detection, param-only changes, connector addition/removal classification. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>ApplyTemplatePatch(templateId, baseVersion, patch, authorId, correlationId)</code> — deterministic patch application</strong><br><strong>Purpose & contract:</strong> apply structured patches (unified diff or JSON patch) deterministically to a base version producing a candidate. Validate resulting M and compute <code>mChecksum</code>. Persist candidate with evidenceRef and stage for approval. When patches cannot be cleanly applied produce structured conflict report with failed hunk list. <br><strong>Audits:</strong> <code>pq_library.apply_patch(correlationId, templateId, baseVersion, newCandidateHash, patchFingerprint)</code>. <br><strong>Tests:</strong> conflict detection, patch rebase sequences, idempotency of repeated patch application. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>BackupLibraryIndex(backupPath, includeArtifacts=false, correlationId=null)</code> & <code>RestoreLibraryIndex(backupPath, dryRun=true, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> create cryptographically verifiable backups (index + manifest + checksums + optional artifacts) and restore them safely. Backups must be atomic bundles including <code>forensic_manifest.json</code> enumerating artifacts and checksums. Restore performs dry-run verification (if <code>dryRun==true</code>) before replacing live index. <br><strong>Audits:</strong> <code>pq_library.backup/completed</code> and <code>pq_library.restore.attempt/completed/failure</code> with forensic_manifest reference. <br><strong>Runbook:</strong> restores require owner approval for production indices; ensure audit continuity by including replaced indexHash in manifest. <br><strong>Tests:</strong> backup corruption detection, partial restore handling, DR verification. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>AtomicPersistIndex(indexObj, targetIndexPath, tmpSuffix=&quot;.part&quot;, maxAttempts=3, correlationId=null)</code> — atomic persistence (full semantics)</strong><br><strong>Purpose & contract:</strong> reliably persist index with crash-safety and cross-platform considerations. Guarantee either previous index remains intact or new index entirely replaces it; never produce a truncated visible file. Integrates optimized temporary writing, fsync semantics, and atomic rename/replace patterns. <br><strong>Detailed sequence:</strong><br>1. Serialize <code>indexObj</code> to canonical JSON with sorted keys and stable ordering. <br>2. Write serialized bytes to <code>targetIndexPath + tmpSuffix + &#x27;.&#x27; + pid + &#x27;.&#x27; + deterministicSuffix</code>. <br>3. Optionally fsync the file descriptor if platform supports it. <br>4. Perform atomic replace using platform-specific calls (<code>os.replace</code> on POSIX, <code>ReplaceFile</code> on Windows). <br>5. Optionally fsync parent directory. <br>6. Re-open file and verify checksum equals computed <code>indexHash</code>. <br><strong>Fallbacks & degraded mode:</strong> on network filesystems with weak rename semantics fall back to writing a manifest and a <code>commit</code> sentinel; emit <code>pq_library.index.persist.degraded</code> and document consumer policy for in-progress detection. <br><strong>Audits:</strong> <code>pq_library.index.persist.attempt(correlationId, targetIndexPath, indexHash, tempPath)</code>, <code>pq_library.index.persist.completed(correlationId, targetIndexPath, indexHash, durationMs)</code>, <code>pq_library.index.persist.failure(correlationId, targetIndexPath, errorCode, attempts)</code>. <br><strong>Tests:</strong> concurrency tests (multiple publishers), ENOSPC simulation, permission error scenarios, NFS rename semantics emulation. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong><code>InspectHiddenSheetFallback(workbook, correlationId)</code> — diagnostic helper</strong><br><strong>Purpose & contract:</strong> produce a deterministic diagnostic report for hidden-sheet embedded templates: detect missing or malformed rows, oversized payloads, suspicious characters, and candidate promotion suggestions. Return <code>diagnosticReport</code> and emit <code>pq_library.hidden_sheet.inspect</code>. <br><strong>Report includes:</strong> rowCount, malformedRows detail, evidenceRefs for oversized payloads, promotionCandidates with suggested <code>ResolveTemplateVersion</code> mapping, and owner inference hints. <br><strong>Use-case:</strong> operators troubleshooting missing templates in ribbon or promotion errors. <br><strong>Tests:</strong> malformed row detection, embedded binary artifacts, evidenceRef generation correctness. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Cross-cutting observability & error catalog (comprehensive):</strong><br><strong>Audit schema:</strong> each audit row must include timestamp, correlationId, module=PQ_Library, procedure, operatorId (optional), paramsHash, resultHash (optional), evidenceRef (optional), durationMs, metadata (artifactChecksum, tempPathList, indexHash, validationSummary). Evidence storage encrypted and access-controlled. <br><strong>Representative ErrorCodes & operator guidance:</strong><br>- PQ_LIB_INDEX_NOT_FOUND — suggest <code>pqlib restore-index</code> from backups and check configured <code>indexPath</code>. <br>- PQ_LIB_INDEX_CORRUPT — follow repair runbook: collect forensic_manifest, compare backups, run <code>pq_library.index.repair</code> candidate flow. <br>- PQ_LIB_TEMPLATE_NOT_FOUND — confirm <code>templateId</code> and resolved version; list templates and check published channels. <br>- PQ_LIB_MCHECKSUM_MISMATCH — run canonicalizer with evidenceRef and compare raw vs canonical versions; open migration if canonical rules changed. <br>- PQ_LIB_REPO_UNREACHABLE — check repository tokens, network, or use hidden-sheet fallback and log <code>pq_library.hidden_sheet.fallback</code> audit. <br>- PQ_LIB_PUBLISH_BLOCKED — missing approvals; present approval artifacts to owners. <br><strong>Metrics:</strong> pq_library.index.size, pq_library.template.count, pq_library.import.rate, pq_library.publish.latency_ms, pq_library.mchecksum.compute_time_ms. Metrics buffered locally and uploaded in audited batches. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Security & governance rules (mandatory):</strong><br>1. Signing: regulated templates must be signed before being marked published; signatures must include canonical <code>mChecksum</code> and <code>releaseManifestHash</code>. <br>2. Approval policy: regulated channel publishing requires two-person approval; approvals are immutable audit artifacts stored encrypted. <br>3. No secrets: static analyzer rejects templates with probable credentials or secrets; publishing blocked until sanitized. <br>4. Hidden-sheet constraints: hidden-sheet fallback allowed for read-only preview/inject; promotion to repo requires owner approval and signature. <br>5. Key management: signing keys rotated per SRE schedule and rotation events recorded in audits and release manifests. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Testing matrix and CI gates (very detailed):</strong><br><strong>Unit tests:</strong><br>1. <code>ComputeMChecksum</code> goldens covering Unicode NFC/NFD, CRLF vs LF, comment permutations, indentation variants, base64 blobs. <br>2. <code>LoadEmbeddedHiddenSheet</code> header normalization and large payload persisted to evidence store. <br>3. <code>TemplateDiff</code> semantic vs syntactic detection. <br>4. <code>AtomicPersistIndex</code> rename/fsync failure simulation. <br><strong>Integration tests:</strong><br>1. Import-from-file -> sign -> publish -> inject roundtrip: verify injected M's <code>mChecksum</code> equals published artifact checksum and signature verification passes. <br>2. Hidden-sheet fallback -> promote -> publish -> CI signature verification chain. <br><strong>Property tests:</strong><br>1. Determinism property: <code>ComputeMChecksum(canonicalize=true)</code> idempotency and cross-language parity for randomized whitespace insertion. <br>2. Idempotency: repeated import of identical file yields same candidate and does not duplicate artifacts. <br><strong>CI golden gating:</strong> mainline merges require passing <code>mChecksum</code> parity tests across implemented language bindings and static analyzer verification for forbidden-APIs. Changes to canonicalizer or checksum must update golden vector sets. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Extremely detailed operational runbooks & incident playbooks (actionable):</strong><br><strong>Runbook: mChecksum mismatch during inject:</strong><br>1. Collect <code>pq_template.mChecksum.compute</code> and <code>pq_template.inject.prepare</code> audits for the correlationId. <br>2. Retrieve evidenceRef canonicalized text and raw payload persisted during import. <br>3. Re-run <code>ComputeMChecksum</code> with canonicalRules used during the original run (evidenceRef includes canonicalRules version). <br>4. If mismatch is due to canonicalization policy change, open migration manifest and create PR to update golden vectors, documenting impact. <br>5. If mismatch appears due to tampering, package forensic_manifest with audit_tail and escalate to security. <br><strong>Runbook: index persist ENOSPC:</strong><br>1. Inspect <code>pq_library.index.persist.failure</code> audit to find mount path and freeBytes. <br>2. Attempt staging to configured fallback on same volume; if not possible create <code>partial-backup</code> and escalate to infra. <br>3. If necessary, run <code>pqlib restore-index</code> from most recent backup after coordinating owners and SRE. <br><strong>Runbook: hidden-sheet emergency inject bypass:</strong><br>1. When repo unreachable, hidden-sheet fallback provides read-only inject paths. Persist a sanitized copy of the embedded payload to evidence store and emit <code>pq_library.hidden_sheet.fallback</code>. <br>2. Log the event and schedule <code>PromoteHiddenSheetToRepo</code> in worker for later owner approval. <br><strong>Runbook: signature verification failure in CI:</strong><br>1. Collect <code>pq_template.signature.created</code> audits and signature files. <br>2. Check key rotation logs and key fingerprint match. <br>3. If key rotation mismatch, verify releaseManifest for the run and re-sign if necessary; if suspicion of key compromise escalate to security and rotate keys. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Extended cross-cutting narratives, examples & forensic scenarios (long-form):</strong><br><strong>Example 1 — Regulated publish with two-person approval and forensic replay (trace):</strong><br>1. Developer authors template and runs <code>ImportTemplateFromRepo</code>. The worker fetches the file, computes canonical <code>mChecksum</code> via <code>ComputeMChecksum</code>, runs <code>ValidateTemplateSchema</code>, and stores artifact in the staging area using <code>AtomicWrite</code>. <code>pq_library.import.completed</code> audit records artifactChecksum and evidenceRef. <br>2. Candidate placed into staging, <code>StageTemplateForApproval</code> opened; Owner A reviews <code>TemplateDiff</code> and records approval. <code>pq_library.approval.recorded</code> emitted. <br>3. Owner B approves; <code>PublishTemplate</code> verifies approvals, signs artifact using the CI-managed signing key (<code>SignTemplateArtifact</code>), writes signature artifact, and calls <code>AtomicPersistIndex</code> to mark version as published. <code>pq_template.publish</code> audit contains <code>signatureFingerprint</code>, <code>indexHash</code>, and <code>publishedAt</code>. <br>4. Regulator requests evidence: forensic tool collects <code>pq_template.publish</code>, <code>pq_template.mChecksum.compute</code>, the canonicalized text evidenceRef, signature artifact, and indexHash. Re-run <code>ComputeMChecksum</code> with the same canonicalRules and verify signature using <code>VerifyTemplateSignature</code>. Reproduction proves artifact integrity and audit chain completeness. <br><strong>Example 2 — Preview determinism and SafeRound integration for financial correctness:</strong><br>1. Operator requests preview via PQ_Ribbon; ribbon generates correlationId and schedules worker preview. <br>2. Worker runs <code>GetTemplateById</code> to obtain payload, computes <code>mChecksum</code>, derives a deterministic seed from correlationId, and runs sandboxed preview with seed controlling sampling and deterministic transient behavior. If template marked <code>requiresHighPrecision</code>, worker runs numeric aggregation using <code>SafeRoundResiduals</code> and persists SafeRound evidence. <br>3. Preview audit <code>pq_template.preview</code> includes <code>mChecksum</code>, <code>seedFingerprint</code>, and evidenceRef to SafeRound logs so that the exact preview can be reproduced later. <br>4. Operator accepts injection; injector verifies signed artifact and <code>mChecksum</code> and injects the canonical M. <code>pq_template.inject.completed</code> audit ties the injection to published artifactChecksum and the preview correlationId. <br><strong>Example 3 — Hidden-sheet emergency promotion with reconciliation:</strong><br>1. Training workshop uses XLAM that includes <code>pq_templates</code> hidden sheet. During repo outage operators preview and inject templates from hidden-sheet. <code>pq_library.hidden_sheet.fallback</code> audits record evidenceRef for each embedded payload and the workbookId for chain-of-custody. <br>2. After outage, owners run <code>InspectHiddenSheetFallback</code> which reports malformed entries and suggests promotion candidates. <code>PromoteHiddenSheetToRepo</code> runs in a worker that extracts payloads, computes <code>mChecksum</code>, stages candidates, and opens approval workflows for owner review. Promotion is only completed after approvals and signature. <br>3. Promotion emits <code>pq_template.publish</code> audits and the forensic manifest ties originally-used hidden-sheet evidenceRefs to published artifacts for regulator traceability. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) mapping — enforcement and best-practices (very detailed):</strong><br><strong>Context:</strong> Because Power Query host runtimes and connector implementations vary across host versions, PQ_Library treats M templates as authoritative artifacts: canonicalize, sign, and publish artifacts from controlled worker environments for regulated or numerically-sensitive templates. <br><strong>Patterns & guidance:</strong><br>1. <strong>Signed canonical artifact for injection (must):</strong><br> - Rationale: differences in authoring tools, local settings, or string encodings can produce semantically equivalent but byte-different M. Signed canonical artifacts guarantee that the injected M matches the audited artifact. <br> - Implementation: worker computes canonical M via <code>ComputeMChecksum</code>, persists artifact with <code>AtomicWrite</code>, signs artifact if required, and injects only after client verifies <code>mChecksum</code> and signature fingerprint. <br>2. <strong>Deterministic preview & sampling:</strong><br> - Rationale: previews must be reproducible for audit and forensic investigation. <br> - Implementation: preview flows accept correlationId-derived seed passed into parameterized M or into worker-run sampling pipelines. For heavy sampling or deterministic selection, the worker uses DeterministicRNG and persists RNG state evidenceRef referenced in <code>pq_template.preview</code>. <br>3. <strong>Numeric fidelity offload:</strong><br> - Rationale: M numeric fidelity may vary by host runtime; high-stakes rounding should be centralized. <br> - Implementation: templates that influence financial numbers must carry <code>requiresHighPrecision=true</code> metadata. The worker accepts normalized payload and runs <code>SafeRoundResiduals</code> to produce final, auditable integer-cent allocations. The signed published artifact contains the authoritative logic and the exact SafeRound evidence (input, rounding decisions, tie-break keys). <br>4. <strong>Retry & idempotency orchestration:</strong><br> - Rationale: network and FS operations are inherently unreliable and concurrent publishers must not create doubles. <br> - Implementation: operations that mutate index or artifacts persist a job descriptor via AtomicWrite and use the <code>Retry</code> wrapper with idempotency assertions enabled. Job descriptors include idempotency tokens and correlationId. <br>5. <strong>Connector policies & trusted connectors:</strong><br> - Rationale: some connectors have elevated security or compliance risks. <br> - Implementation: metadata <code>trustedConnector=true</code> and channel gating that requires explicit owner approval and signature before publish. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX & semantic model mapping — how PQ_Library integrates with models (practical):</strong><br><strong>Context & constraints:</strong> DAX is read-time only; authoritative write-side actions (signing, canonicalization, rounding) occur in ETL/worker layers. Surface only minimal, non-sensitive audit metadata into the model. <br><strong>Patterns:</strong><br>1. <strong>RunMetadata table pattern:</strong> ETL writes <code>RunMetadata</code> table with <code>correlationId</code>, <code>templateId</code>, <code>templateVersion</code>, <code>mChecksum</code>, <code>artifactChecksum</code>, <code>publishedAt</code>, <code>verificationStatus</code> and <code>notesRef</code>. DAX measures consult RunMetadata for provenance. <br>2. <strong>ReconciledFlag DAX pattern:</strong> calculate <code>IsReconciled = IF(RunMetadata[artifactChecksum] = RunMetadata[expectedChecksum], 1, 0)</code> to create a UI indicator for dataset consumers. <br>3. <strong>Deterministic sampling via hashed keys:</strong> ETL creates <code>HashKey = HASH(PrimaryKey | correlationSalt)</code> and persists <code>correlationSalt</code> in RunMetadata. Deterministic sample filters use <code>MOD(HashKey, N) &lt; k</code>. Persist <code>correlationSalt</code> to allow replay. <br>4. <strong>Authoritative rounding in ETL:</strong> perform allocations and residual distributions in ETL with <code>SafeRoundResiduals</code> and store integer-cent columns; DAX reads these for consistent measures. <br>5. <strong>Minimal model-level audit surfaces:</strong> expose <code>templateId</code>, <code>templateVersion</code>, <code>mChecksumFingerprint</code>, and <code>publishedAt</code> as model columns for transparency while keeping full evidenceRefs outside the model for security. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Forensic evidence architecture & retention policy (exhaustive):</strong><br><strong>Artifacts captured per run (minimum):</strong><br>1. <code>index.json</code> snapshot with <code>indexHash</code> and index signature (if present). <br>2. Signed artifact files with <code>mChecksum</code> and signature files. <br>3. Audit tail subset: all <code>pq_library.*</code> events for the correlationId. <br>4. EvidenceRefs: canonicalized M text, hidden-sheet payload dumps, SafeRound serialized inputs and outputs, DeterministicRNG state blobs. <br>5. <code>forensic_manifest.json</code> enumerating artifacts, checksums, evidenceRef URIs, operatorId, and timestamps. <br><strong>Retention & storage tiers:</strong><br>- Hot evidence: encrypted, access-limited, retention 30 days, fast retrieval for operator support. <br>- Warm archive: encrypted secure archive for regulatory retention (7 years or as required), slowed retrieval, stricter access controls. <br>- Cold archive: per long-term records retention rules and legal holds; retrieval subject to legal process. <br><strong>Rotation & verification cadence:</strong> monthly verification job recomputes checksums for hot and warm evidence and emits <code>pq_library.housekeeping</code> audits with verification results. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Detailed test plan & CI gating (explicit):</strong><br><strong>Unit test suites (representative):</strong><br>1. <code>ComputeMChecksum</code> parity goldens covering Unicode variants, comment toggles, blank-line collapse, base64 embedded blob normalization, and pathologically large templates. <br>2. <code>LoadEmbeddedHiddenSheet</code> header normalization with alias mapping and multiline payload persistence to evidenceRef. <br>3. <code>TemplateDiff</code> AST-level tests to classify changes correctly and flag connector modifications as <code>breakingChange</code>. <br>4. <code>AtomicPersistIndex</code> simulated rename/fsync failures and degraded path emission. <br><strong>Integration tests:</strong><br>1. Import -> Sign -> Publish -> Inject roundtrip verifying <code>mChecksum</code> and signature validity on the injected query across supported host variants. <br>2. Hidden-sheet fallback -> promote -> publish flow including approvals and signature verification. <br><strong>Property tests & fuzzing:</strong><br>1. Random whitespace/comment insertion to verify <code>ComputeMChecksum</code> idempotence. <br>2. Randomized parameter permutations to assert <code>ResolveParameterDefaults</code> determinism. <br><strong>CI gating rules:</strong><br>1. All golden vector parity tests must pass across implemented language bindings before merge. <br>2. Any change to canonicalization or checksum logic must update golden vector sets and include cross-language parity results. <br>3. Static analyzer must reject forbidden APIs within templates targeting regulated channels. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Developer requirements, patterns & forbidden behaviors (explicit):</strong><br><strong>Required patterns:</strong><br>1. Compute and persist <code>mChecksum</code> with any artifact used for injection. <br>2. Use <code>AtomicPersistIndex</code> for index mutations. <br>3. Delegate heavy IO and signing to worker/CI; ribbon code must avoid blocking network or file writes. <br>4. Emit audits for all persistence and publish flows. <br><strong>Forbidden patterns (static analyzer enforced):</strong><br>1. Do not write final artifact paths on UI thread. <br>2. Do not embed secrets or credential strings in template metadata or index. <br>3. Do not change canonicalization semantics without migration manifest, OWNER approval, and golden vector updates. <br>4. Do not accept unsigned published templates in regulated channels. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & procedures (practical):</strong><br>1. <code>pqlib diagnostics collect --correlation &lt;id&gt;</code> — collects index.json, audit_tail.csv, evidenceRefs, and forensic_manifest for run. <br>2. <code>pqlib promote-hidden --workbook &lt;file&gt; --dry-run</code> — produce promotion diff and owner list for approval. <br>3. <code>pqlib verify-signature --artifact &lt;path&gt;</code> — verify signature and return signer id and validity. <br>4. <code>pqlib repair-index --from-backup &lt;backup&gt;</code> — run repair dry-run then persist if safe; include run-of-day audit. <br><strong>Escalation triggers for SRE:</strong> after two <code>pq_library.index.persist</code> ENOSPC retries for a critical index, or repeated <code>PQ_LIB_REPO_UNREACHABLE</code> for primary mirrors. Include forensic_manifest and audit_tail when contacting SRE. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Comprehensive failure modes & mitigations (explicit):</strong><br><strong>mChecksum mismatch across environments:</strong><br>1. Likely cause: canonicalization differences (line endings, Unicode normalization, indentation rules). <br>2. Mitigation: run cross-language golden checks; reproduce canonicalization step using evidenceRef; update canonicalization policy only via migration manifest and golden updates. <br><strong>Hidden-sheet payload truncation:</strong><br>1. Cause: Excel cell size limits or export tool truncation. <br>2. Mitigation: persist embedded payload into evidence store and reference via evidenceRef; use PromoteHiddenSheetToRepo for recovery. <br><strong>AtomicPersistIndex ENOSPC:</strong><br>1. Cause: insufficient disk space on target volume. <br>2. Mitigation: stage to a configured fallback path on the same mount if possible, emit <code>pq_library.index.persist.ENOSPC</code> audit with freeBytes and escalate to infra. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Governance & PR acceptance checklist (hard gating):</strong><br>1. OWNERS approvals present and recorded. <br>2. ComputeMChecksum golden vectors updated and tested cross-language. <br>3. Hidden-sheet fallback tests included for distribution packages that embed templates. <br>4. AtomicPersistIndex and AtomicWrite tests across target filesystems. <br>5. Signature verification end-to-end validated and key rotation tested. <br>6. Audit hooks wired in and modAudit rotation validated. <br><strong>Blocking items:</strong> missing audit on index write, failing mChecksum parity, forbidden-API static analyzer alerts, missing OWNER sign-off for regulated templates. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix A — example audit row schema (detailed recommended fields):</strong><br><strong>Required fields:</strong> timestamp, correlationId, module, procedure, operatorId (optional), paramsHash, resultHash (optional), evidenceRef (optional), durationMs, metadata (artifactChecksum, tempPathList, indexHash, validationSummary), traceId (distributed tracing), hostId. <br><strong>Policy:</strong> top-level audit rows must not contain raw PII or secrets. Store sanitized full params in evidence store referenced by evidenceRef. All audits are append-only and chained. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix B — extended narrative: deterministic tie-breakers & SafeRound forensic example:</strong><br><strong>Scenario (detailed):</strong> A payroll allocation algorithm splits a salary pool into many accounts using weights that produce exact half-cent ties in several rows. The requirement: the sum of rounded allocations must equal the rounded total. <br><strong>Procedure & evidence chain:</strong><br>1. Worker computes canonical decimals and calls <code>SafeRoundResiduals(values, total, places=2, tieBreakerKeys=employeeIdOrder)</code>. <br>2. <code>SafeRoundResiduals</code> scales, computes floors and residuals, computes remaining increments and deterministically assigns increments by <code>(residual desc, tieBreakerKeys asc, originalIndex asc)</code>. <br>3. The worker emits <code>util.saferound.start</code> with paramsHash and <code>util.saferound.complete</code> with outputHash and a SafeRound evidence bundle persisted to the evidence store (input normalized decimals, scaled intermediate integers, assigned increments, final allocations). <br>4. The allocation artifact is persisted via <code>AtomicWrite</code> and <code>pq_library.index.persist.completed</code> references the allocation artifactChecksum. <br>5. For forensic replay, the investigator retrieves correlationId audits, the SafeRound evidenceRef, restores canonical decimals and tieBreakerKeys, runs <code>SafeRoundResiduals</code> and confirms the artifact checksum matches the published allocation. This provides a full deterministic reconstruction of allocation decisions. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix C — extended PQ author guidance & practical examples:</strong><br><strong>Example — Template that needs high-precision rounding:</strong><br>1. Template metadata: <code>requiresHighPrecision: true</code>, <code>owners: [&quot;finance-team@domain&quot;]</code>. <br>2. Template author designs M to produce normalized fractions per account and emits an intermediate canonical CSV payload (normalized decimals) instead of performing final rounding in M. <br>3. The publish/inject orchestration sends the normalized CSV to worker <code>SafeRoundResiduals</code> which performs authoritative rounding and persists the signed artifact that PQ_Injector will insert. <br><strong>Rationale:</strong> avoids host-dependent rounding differences when the final dataset is used for accounting. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix D — conceptual DAX examples (concrete measure snippets but described, not code):</strong><br><strong>Measure pattern 1 — ReconciledFlag:</strong> store <code>expectedChecksum</code> in RunMetadata; create a measure that returns 1 when artifactChecksum equals expectedChecksum and 0 otherwise. Use this measure in reports to display a verification badge. <br><strong>Measure pattern 2 — Sample membership:</strong> ETL computes <code>HashKey</code> and stores <code>correlationSalt</code>; provide a DAX measure that filters rows where <code>MOD(HashKey, N) &lt; k</code> to create deterministic sample slices. Persist salt and sample definition in RunMetadata to reproduce exact sample selections. <br><strong>Guidance:</strong> avoid computing rounding logic in DAX; rely on ETL-side <code>SafeRoundResiduals</code> outputs. Provide a small user-facing DAX measure that surfaces <code>templateId</code> and <code>templateVersion</code> for provenance. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix E — extended operator incident playbook (step-by-step):</strong><br><strong>Incident: "Injected query does not match published artifact (mChecksum mismatch)"</strong><br>1. Capture correlationId from <code>pq_template.inject.prepare</code> audit. <br>2. Run <code>pqlib diagnostics collect --correlation &lt;id&gt;</code> to collect audit_tail, evidenceRefs, index snapshot and artifact files. <br>3. Use <code>ComputeMChecksum</code> on canonicalized text from evidenceRef and compare to published <code>mChecksum</code> and injected query. <br>4. If injected query differs due to client-side transformation, identify the conversion step (e.g., workbook encoding or editor auto-format) and record as a remediation item: prefer injection of signed artifact rather than client paste. <br>5. If mismatch due to canonicalization rules change, generate migration manifest and open a controlled release to update golden vectors and inform operators. <br>6. If tampering suspected, lock affected artifacts, escalate to security, and prepare forensic package for regulator if required. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Appendix F — glossary of key terms (concise):</strong><br>1. <code>mChecksum</code> — canonical checksum of an M template after canonicalization. <br>2. <code>evidenceRef</code> — secure reference to persisted evidence (canonical text, RNG state, SafeRound traces). <br>3. <code>AtomicPersistIndex</code> — atomic update mechanism for the template index. <br>4. <code>Hidden-sheet fallback</code> — embedded workbook sheet serving as offline template source. <br>5. <code>SafeRoundResiduals</code> — deterministic rounding allocator ensuring sum-preservation. <br>6. <code>DeterministicRNG</code> — seedable RNG whose outputs are stable across languages and runs given same seed. </td></tr><tr><td data-label="PQ_Library — Per-function Expert Technical Breakdown"> <strong>Final governance & mandatory constraints (non-negotiable):</strong><br>1. All templates intended for downstream consumption must be published with <code>mChecksum</code>. <br>2. Hidden-sheet fallback must be recorded via <code>pq_library.hidden_sheet.fallback</code> audit and promoted only after owner approval. <br>3. Canonicalization rules enforced by CI; changes require migration manifest and cross-language golden updates. <br>4. Signing required for regulated templates; signing keys managed via CORE_Security and key rotation tracked in audits. <br><strong>Verification:</strong> this specification provides the deterministic chain from authoring to injection and model consumption with mandatory audits and evidence persistence to satisfy compliance, reproducibility, and operational reliability requirements. </td></tr></tbody></table></div><div class="row-count">Rows: 44</div></div><div class="table-caption" id="Table3" data-table="Docu_0180_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Injector — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Injector — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_INJECTOR (listed in OWNERS.md and referenced in release manifests).<br><strong>Public API (surface):</strong> Add_Query_From_M, Add_Query_From_M_With_Parameters, Parameterize_Template, Preview_M, Compute_mChecksum, Validate_M_Syntax, EnsureQueryNameUnique, Create_Connection, Create_Connection_Model, Add_Query_As_ConnectionOnly, Update_Query_Formula, Remove_Query, Export_M_Artifact, Persist_M_Artifact (AtomicWrite wrapper), Inspect_Queries, Get_Query_Diagnostics, SafeCreateQueryName, Set_Connection_Credentials_Safely, Snapshot_Queries, Rollback_Query_Insert, AuditEmit_PQAction, Register_InjectionHook. <br><strong>Audits emitted:</strong> pq_inject.attempt, pq_inject.completed, pq_inject.failure, pq_preview.start, pq_preview.complete, pq_mchecksum.computed, pq_connection.created, pq_connection.updated, pq_connection.failure, pq_export.attempt, pq_export.completed, pq_export.failure, pq_diagnostics.collected, pq_query.removed, pq_query.updated. Every audit row contains correlationId, module=PQ_Injector, procedure, paramsHash, mChecksum when applicable, artifactChecksum when applicable, and timestamp. <br><strong>Purpose and intended use:</strong> Provide deterministic, auditable, safe APIs for injecting Power Query (M) artifacts into Excel workbooks and Power Query runtimes. Ensure injected queries are validated, parameterized, persisted as auditable artifacts, optionally created as connections only or model-backed connections, and that all side-effects are crash-safe and reversible. Avoid performing blocking long IO on UI thread; defer to worker processes for heavy persistence and network exports. <br><strong>Non-goals / constraints:</strong> Not a general-purpose M authoring tool; not responsible for authoring template repositories; not intended to perform data refresh operations itself (use PQ_Refresh / PQ_Diagnostics). Avoid embedding secrets in top-level audit rows; credentials are passed to credential managers or external secure stores. No uncontrolled workbook DOM modifications; always follow host-approved APIs and naming policies. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operational guarantees & invariants (module-level):</strong><br>1. Determinism: Given identical inputs (template text, parameters, correlationId, config.hash) and same runtime version, the computed <code>mChecksum</code> and persisted artifact bytes must be reproducible across runs and platforms. <br>2. Audit anchoring: Any mutation to workbook queries, connections, or persisted artifacts must be accompanied by at least one audit row referencing correlationId and essential provenance fields. <br>3. Crash-safety: Persistence of M artifacts uses atomic-write semantics (via CORE_Utilities.AtomicWrite or PQ_Utilities.AtomicWrite wrapper) to ensure final-on-success semantics; either old query state remains or new query fully replaces it. <br>4. UI-safety: Avoid long-running IO or blocking actions on the UI thread. Heavy persistence, remote exports, and checksum verification run on background workers; UI handlers only coordinate and emit UserAction audits. <br>5. Name safety: Ensure generated or requested query names do not collide with existing workbook objects; automatically resolve and document name normalization decisions in audits. <br>6. Template governance: For regulated templates, require template owner approval and manifest-signed verification before injection. <br><strong>Performance SLOs:</strong> Inject (local in-memory add) latency for small M payloads <200ms on average in UI helper; persisted artifact atomic-write round-trip median <300ms on local SSD; mChecksum computation for typical template <50KB within 50ms. <br><strong>CI / acceptance gates:</strong> mChecksum parity vectors across supported implementations; cross-platform injection acceptance tests (Excel Windows, Excel Mac where supported, Power BI Desktop if applicable); audit emission verification tests; static checks preventing workbook DOM calls on UI OnLoad handlers. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Design overview & high-level flow (conceptual):</strong><br>1. Operator triggers injection from PQ_Ribbon -> PQ_Injector receives <code>InjectTemplateRequest</code> containing templateId, parameterValues (optional), targetQueryName (optional), injectionMode (<code>InsertInline | ConnectionOnly | ModelConnection</code>), correlationId. <br>2. PQ_Injector computes canonical parameters: validate parameter schema, fill defaults, canonicalize types, compute <code>paramsHash</code>. <br>3. Parameterize_Template: applies parameter substitutions to canonical M template to produce final M formula for injection; compute <code>mChecksum</code> of produced M text. <br>4. Validate_M_Syntax: lightweight client-side syntax checks where available; for heavy validation or host-dependent parsing, schedule worker validation or preview execution in isolated host with redacted inputs. <br>5. EnsureQueryNameUnique: compute safe query name with normalization rules and conflict resolution policy; if renamed, emit audit with name mapping. <br>6. Persist_M_Artifact: create durable artifact (artifact JSON containing name, mText, params, mChecksum, templateVersion, manifest references) and persist via AtomicWrite; emit pq_export and pq_mchecksum audits. <br>7. Add_Query_From_M: call workbook.Queries.Add (or host API) from UI helper using the persisted artifact as source to ensure the in-memory query matches persisted artifact; optionally create a connection object and/or model connection according to injectionMode. <br>8. Post-inject tasks: optionally register query in PQ_Library index if template was saved there, collect diagnostics, update <code>pq_inject.completed</code> audit row with artifactChecksum and connection metadata. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Cross-cutting invariants & security rules (must/shall):</strong><br>1. Do not execute M queries against live external connectors during injection unless explicitly requested and permissioned by operator; injection should be syntactic and structural by default. <br>2. Never store credentials inside M artifacts or top-level audit rows. Credential references may be stored as secure handles or connection IDs. <br>3. For regulated templates, require manifest signature verification and owner approval before injection and record these validations in the audit row. <br>4. Respect workbook privacy: do not upload workbook contents or list of queries to remote telemetry without operator consent. <br>5. All persisted artifacts must include <code>correlationId</code>, <code>producerVersion</code>, and <code>producerFingerprint</code> for later forensic replay. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Add_Query_From_M(name, formula, injectionMode=&quot;inline&quot;, connectionOptions=null, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> inject a Power Query (M) formula into the active workbook in a deterministic, auditable, and reversible fashion. <code>injectionMode</code> controls whether the query is added as inline (worksheet query), connection-only, or model-backed. The function returns structured result <code>{success, queryName, queryId, connectionId?, artifactChecksum, mChecksum, attempts, diagnosticsRef}</code> and emits audit rows on attempt and completion. <br><strong>Parameters & constraints:</strong> <code>name</code> (string — may be null to request auto-name), <code>formula</code> (string — final M text produced by Parameterize_Template), <code>injectionMode</code> ∈ {inline, connectionOnly, modelConnection}, <code>connectionOptions</code> optional dict (e.g., {enableRefresh: bool, loadToModel: bool, credentialHandle: id}). <code>operatorId</code> optional for audit. The function must not perform long-running file IO on UI thread; if persistence or export is required, delegate to Persist_M_Artifact and use a background worker. <br><strong>Must/shall behaviors:</strong><br>1. Call EnsureQueryNameUnique(name) to compute final <code>queryName</code> and document name mapping in audit if mutated. <br>2. Compute <code>mChecksum</code> using canonical normalized bytes (UTF-8 normalized, strip CRLF differences, stable whitespace normalization rules) and emit pq_mchecksum.computed audit with paramsHash and inputHash. <br>3. Persist artifact via Persist_M_Artifact(artifactPayload) before calling workbook API unless caller explicitly requests ephemeral inject (rare, must be approved and audited). <br>4. Use host workbook API to Add Query, catch host-specific exceptions, map them to PQ error codes, and retry only for transient host errors using Retry wrapper with idempotent_assert=true. <br>5. On success, optionally create connection object per connectionOptions. <br>6. Emit pq_inject.completed audit with artifactChecksum, queryName, queryId, connection metadata, and mChecksum. <br><strong>Edge cases & error handling:</strong><br>1. Name collision: if final query name collides with an existing query that is user-modified, do not overwrite without explicit operator confirmation; use auto-suffix scheme <code>name (1)</code>, emit pq_inject.resolved_name audit and provide map in result. <br>2. Host API limitations: if workbook host prevents programmatic addition due to trust settings or macro policies, record user-facing error UTIL_PQ_HOST_POLICY_BLOCK and emit pq_inject.failure with remediation guidance. <br>3. Large formula (>configured limit): if formula exceeds safe buffer size for host API, persist artifact and call a helper (signed XLAM or worker) to split or write via supported host channels; emit pq_inject.degraded and include reason. <br>4. Partial failure after workbook change: if workbook query is added but post-processing (e.g., connection creation) fails, produce reversible plan and persist rollback artifact via Rollback_Query_Insert; emit pq_inject.partial_failure with beforeChecksum and afterChecksum. <br><strong>Observability & audits:</strong> pq_inject.attempt(correlationId, operatorId, templateId?, paramsHash, requestedName) pq_inject.completed(correlationId, operatorId, queryName, queryId, artifactChecksum, mChecksum, durationMs) pq_inject.failure(correlationId, operatorId, errorCode, diagnosticsRef). <br><strong>Examples & narratives:</strong><br>1. Admin injects <code>Sales_Cleansed</code> template with parameter region=EMEA into workbook; Add_Query_From_M computes safe name <code>Sales_Cleansed</code> (no collision), persists artifact, adds query inline, creates modelConnection as requested, and returns <code>{success:true, queryName:&quot;Sales_Cleansed&quot;, connectionId:&quot;conn-123&quot;, artifactChecksum:&quot;sha256:...&quot;}.</code> <br>2. User attempts to inject <code>Query1</code> but host macro policy blocks programmatic workbook modifications; function returns failure with guidance and a persisted artifact the operator can import manually. <br><strong>Tests & CI vectors:</strong> unit test for name collision resolution, simulated host API exceptions tests, golden mChecksum vectors for parameterization parity, integration tests verifying persisted artifact equals injected query content. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Parameterize_Template(templateText, params, paramSchema=null, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> apply a template's parameter map to canonical M template text to produce final M formula. Pure function when used with in-memory strings; emits audit pq_preview.start/complete when used in preview/injection flows. Returns <code>{mText, paramsValidated, paramsHash, paramizationLog}</code>. <br><strong>Behavior & steps:</strong><br>1. Load template parameter descriptors (type, default, allowedValues, secureFlag). <br>2. Validate <code>params</code> against <code>paramSchema</code>; coerce types where safe (e.g., numeric strings -> number), record coercions in paramizationLog. Reject mismatches with ErrorCode=PQ_PARAM_VALIDATE_FAIL and include field-level diagnostics. <br>3. For secure parameters (secureFlag=true), redact values in audit and store only parameterFingerprint in evidence store; the produced <code>mText</code> should contain placeholders referencing external secure handles rather than literal secrets. <br>4. Parameter substitution approaches supported: simple token substitution, M-aware substitution (inserting typed literal expressions), and function-parameter injection (wrapping template in let-block with parameter assignments). Choose M-aware substitution by default to preserve typing and quoting correctness. <br>5. Normalize line endings and canonical whitespace; compute <code>paramsHash</code> and <code>mChecksum</code> over normalized bytes. <br>6. Return final <code>mText</code> and diagnostics including any defaulted parameters and coercions. <br><strong>Tie-breakers & determinism:</strong> when templates include nondeterministic placeholders (e.g., <code>#RANDOM</code> for previews), Parameterize_Template must refuse such placeholders unless a DeterministicRNG seed is provided; when seed is provided, replace using DeterministicRNG to ensure reproducibility. <br><strong>Edge cases:</strong><br>1. Parameter-dependent template branches: templates that include conditional sections must be evaluated under a safe preview interpreter or validated syntactically to ensure substitution yields valid M. If safety cannot be proven syntactically, schedule worker-side preview execution with redacted external calls. <br>2. Large binary parameter values: refuse embedding and use external artifact references instead. <br><strong>Observability:</strong> pq_preview.start(correlationId, templateId, paramsHash), pq_preview.complete(correlationId, mChecksum, durationMs). <br><strong>Examples:</strong> substituting <code>dateFrom</code> and <code>dateTo</code> into a template using typed M expressions so that <code>#date(2023,1,1)</code> appears rather than a string literal. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Compute_mChecksum(mText, algorithm=&quot;sha256&quot;, normalizationRules=null)</code></strong><br><strong>Purpose & contract:</strong> compute deterministic checksum for a normalized M formula to enable artifact parity checks and audit linkage. Must be stable across supported hosts and languages. Returns <code>{mChecksum, normalizedBytes, hashAlgorithm, durationMs}</code>. <br><strong>Normalization rules (must/shall):</strong><br>1. Normalize line endings to LF (\\n). <br>2. Trim trailing whitespace on lines. <br>3. Collapse multiple consecutive blank lines to a single blank line unless template explicitly marks significant blank lines via canonical marker. <br>4. Preserve M token semantics; do not strip insignificant parentheses or alter token case in identifiers unless template metadata requires canonical casing. <br>5. UTF-8 encode with NFC normalization. <br>6. Optionally canonicalize comments: either preserve comments in normalized bytes for templates where comments are part of legal audit trail, or strip them if configured in template manifest. <br><strong>Edge behaviors:</strong> Crypto algorithm choices limited to supported set; default sha256. When algorithm changes, compute and persist migration manifest and ensure CI golden vectors are updated. <br><strong>Audits & observability:</strong> pq_mchecksum.computed(correlationId, templateId?, mChecksum, normalizedSize). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Persist_M_Artifact(artifactPayload, targetPath, atomicOptions={}, maxAttempts=3)</code></strong><br><strong>Purpose & contract:</strong> persist canonical JSON artifact describing the M query into durable storage using atomic primitives. Artifact contains metadata: name, mText, mChecksum, paramsHash, templateVersion, producerVersion, correlationId, timestamp. Return <code>{success, artifactPath, artifactChecksum, attempts, durationMs}</code>. <br><strong>Behavior & steps:</strong><br>1. Validate artifact schema. <br>2. Serialize artifact to canonical JSON with stable key order and UTF-8 NFC encoding. <br>3. Compute payload checksum (sha256). <br>4. Write using AtomicWrite with fsyncFile and fsyncParent semantics where available. <br>5. On transient errors use Retry wrapper; on ENOSPC or EPERM emit actionable audits and recovery suggestions. <br>6. Post-write verification: reopen and verify checksum equals computed payload checksum; on mismatch, attempt repair with AtomicWriteRepair or escalate. <br><strong>Cross-platform fallbacks:</strong> on host FS with weak rename semantics, record util.atomic_write.degraded audit and follow staged fallback (write artifact to local staging area and emit pq_export.degraded). <br><strong>Observability & audits:</strong> pq_export.attempt(correlationId, targetPath, payloadHash) pq_export.completed(correlationId, targetPath, artifactChecksum, durationMs). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Create_Connection(connectionName, connectionType, connectionOptions, credentialHandle=null, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> create a host connection object corresponding to an injected query with safe handling of credentials, refresh options, privacy levels, and optionally model mapping. Returns <code>{success, connectionId, artifactChecksum, diagnosticsRef}</code>. <br><strong>Parameters & constraints:</strong> <code>connectionType</code> ∈ {OLEDB, ODBC, Web, File, DataModel}; <code>connectionOptions</code> include loadBehavior (connectionOnly / loadToSheet / loadToModel), privacy settings, refreshPolicy, isHidden, enableBackgroundRefresh. <code>credentialHandle</code> is a secure reference. <br><strong>Behavior & steps:</strong><br>1. Validate that the host supports requested connectionType and options; if not supported, return PQ_CONN_UNSUPPORTED and provide remediation. <br>2. Create connection object via host APIs, pass credentialHandle rather than raw secrets. For model connections, ensure the semantic model is accessible and write mapping metadata into the artifact. <br>3. Persist connection metadata via Persist_M_Artifact or jobDescriptor store with correlationId to ensure reproducibility. <br>4. If creation fails after artifact persisted, record reversible plan and roll back if operator requests. <br><strong>Security & credential handling:</strong> do not log raw credentials; store only credentialHandle or masked fingerprint in audit rows. Credentials lifecycle must follow host credential manager APIs. <br><strong>Audits:</strong> pq_connection.created(correlationId, connectionId, connectionType, connectionOptionsFingerprint) pq_connection.failure(correlationId, errorCode, diagnosticsRef). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>EnsureQueryNameUnique(requestedName, workbookContext, conflictPolicy=&quot;auto-suffix&quot;)</code></strong><br><strong>Purpose & contract:</strong> compute safe canonical query name under workbook constraints and conflict policy. Return <code>{finalName, changed, originalName, collisionResolutionLog}</code>. <br><strong>Behavior & rules:</strong><br>1. Normalize requestedName using canonical rules: strip control characters, trim, collapse repeated whitespace, limit to host-supported length, strip unsupported characters depending on host. <br>2. If normalized name collides with workbook query or table names, apply <code>conflictPolicy</code>:<br>- <code>fail</code> -> return error PQ_NAME_COLLISION.<br>- <code>auto-suffix</code> -> append <code> (n)</code> deterministic suffix where n is smallest integer producing no collision; suffix calculation must be deterministic and stable across runs; use deterministic ordering from existing names list sorted case-insensitively. <br>- <code>overwrite</code> -> only allowed if operator explicitly authorized and existing query is unmodified or matches artifactChecksum; emit audit pq_inject.overwrite_authorized. <br>3. Document mapping in audit. <br><strong>Edge cases:</strong> workbook with case-insensitive names but case-preserving host; ensure detection uses host semantics. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Validate_M_Syntax(mText, validationMode=&quot;lightweight&quot;, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> provide host-aware, deterministic syntactic validation for M text. Modes:<br>- <code>lightweight</code>: static token-level validation without executing connectors.<br>- <code>host-parse</code>: call host parser where available (non-executing) to validate parse tree.<br>- <code>preview-exec</code>: run in sandboxed preview with redacted connectors (requires worker or trusted host). <br><strong>Behavior & safeguards:</strong><br>1. For lightweight mode, run tokenizer-based checks (balanced brackets, basic token validity, prohibited host-specific extensions). <br>2. For host-parse, call host parser API where available and capture parse tree and minor warnings. Host parse must not resolve external connectors. <br>3. For preview-exec, run M in isolated host with timeouts and resource caps; redact external credentials and substitute deterministic test connectors; record diagnostics and truncated results for preview. <br>4. On syntax errors, return structured diagnostics pointing to line/column and include suggested fixes where unambiguous. <br><strong>Audits & telemetry:</strong> pq_validation.start/complete with validationMode and diagnosticsRef. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Preview_M(templateId, params, sampleLimit=50, deterministicSeed=null, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> produce a safe, deterministic preview of a parameterized template suitable for operator review. Returns <code>{previewRows, previewSchema, sampleFingerprint, mChecksum, diagnosticsRef}</code>. <br><strong>Behavior & steps:</strong><br>1. Parameterize_Template to produce mText; compute mChecksum. <br>2. If deterministicSeed provided, use DeterministicRNG to select sample rows for any sampling operations inside the template; otherwise derive seed from correlationId to enable reproducibility. <br>3. Execute the parameterized M in a sandboxed preview runtime with connectors disabled or stubbed unless operator explicitly requests live connector preview; ensure execution timeouts and memory caps. <br>4. Redact PII in previewRows unless operator explicitly authorizes non-redacted preview and that action is auditable. <br>5. Return sample up to sampleLimit rows, previewSchema, and sampleFingerprint computed from DeterministicRNG state and preview data checksum. <br><strong>Edge behaviors & governance:</strong> live connector preview requires explicit operator consent and must be recorded with additional audits and possibly two-person approval if regulated data may be exposed. <br><strong>Audits:</strong> pq_preview.start/complete with sampleFingerprint and evidenceRef for full preview payload. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Get_Query_Diagnostics(queryNameOrId, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> collect diagnostics for a given query: last refresh time, last refresh duration, last error trace, provider chain, dependency graph, and mChecksum recorded at injection time. Returns diagnostics object and emits pq_diagnostics.collected audit. <br><strong>Behavior & steps:</strong><br>1. Query host runtime for refresh history and last error traces; normalize timestamps to UTC and redact sensitive paths. <br>2. Compute dependency graph by analyzing query expression and referencing host's query/link metadata. <br>3. If query formula differs from persisted artifact <code>mChecksum</code>, mark as <code>divergent</code> and include both checksums in diagnostics. <br>4. Provide actionable remediation hints (e.g., refresh provider credentials, re-inject missing referenced query). <br><strong>Audits:</strong> pq_diagnostics.collected(correlationId, queryId, mChecksum, divergentFlag). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Export_M_Artifact(queryNameOrId, destination, atomicExportOptions={}, includeDiagnostics=true)</code></strong><br><strong>Purpose & contract:</strong> export a persisted M artifact and associated diagnostics to a destination (local path, network share, artifact store). Uses atomic export policy to avoid partial writes. Returns <code>{success, destinationUri, artifactChecksum, attempts}</code>. <br><strong>Behavior & steps:</strong><br>1. Resolve artifact from persisted local artifacts store using queryId and artifact checksum. <br>2. Compose export payload including artifact JSON, optional diagnostics, export manifest with correlationId and timestamp. <br>3. Use Persist_M_Artifact / AtomicWrite to write to destination; on network paths, follow staged fallback semantics and emit pq_export.degraded if atomic rename cannot be guaranteed. <br>4. Emit pq_export.completed with artifact checksum and destinationUri. <br><strong>Edge cases & recovery:</strong> handle ENOSPC, permission errors, partial remote writes; persist forensic_manifest and emit pq_export.failure with remediation runbook. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Rollback_Query_Insert(queryName, queryId, artifactPath, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> safely revert a previously applied injection when operator requests rollback or when partial-failure requires revert. Return <code>{success, reverted, reason, durationMs, diagnosticsRef}</code>. <br><strong>Behavior & steps:</strong><br>1. Validate that artifactPath or persisted rollback plan exists. <br>2. If original query existed before injection, restore previous formula and metadata from persisted beforeChecksum snapshot. <br>3. If injection created new objects, remove them in a reversible manner and persist rollback artifact via AtomicWrite. <br>4. Emit pq_query.removed or pq_query.updated audit rows with beforeChecksum and afterChecksum. <br><strong>Safeguards:</strong> require operator confirmation for destructive rollback; for regulated workflows, enforce two-person approval on rollbacks affecting regulated datasets. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Inspect_Queries(workbookContext, filter=null)</code></strong><br><strong>Purpose & contract:</strong> enumerate query metadata in workbook context, compute per-query fingerprints, and reconcile with persisted artifacts. Return list <code>[ {queryName, queryId, mChecksum, artifactMatch, lastModified, modifiedBy} ... ]</code>. <br><strong>Behavior & steps:</strong><br>1. Pull host query list and map to persisted artifact indexes by name and mChecksum. <br>2. Detect divergences (query formula different from artifact mChecksum) and mark <code>artifactMatch=false</code> with diagnostics. <br>3. Provide summary metrics: count_injected, count_divergent, count_unpersisted. <br>4. Emit pq_library.access or pq_inspect.completed audit. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Observability, Telemetry & Error Catalog (concepts & mapping)</strong><br><strong>Audit schema for PQ_Injector:</strong> timestamp, correlationId, operatorId (optional), module=PQ_Injector, procedure, paramsHash, mChecksum (optional), artifactChecksum (optional), resultStatus, evidenceRef (optional), durationMs, hostPlatformVersion, hostPolicyFlags. Evidence storage encrypted and access-controlled. <br><strong>Representative ErrorCodes:</strong> PQ_INJECT_BLOCKED_BY_POLICY, PQ_NAME_COLLISION, PQ_PARAM_VALIDATE_FAIL, PQ_HOST_API_ERROR, PQ_CONN_UNSUPPORTED, PQ_EXPORT_ENOSPC, PQ_MCHECKSUM_MISMATCH, PQ_PREVIEW_FORBIDDEN, PQ_EXPORT_DEGRADED, PQ_INVALID_CREDENTIAL_HANDLE. Each error code maps to operator remediation suggestions via SafeErrorToUser mapping. <br><strong>Key metrics (local buffered):</strong> pq_inject.latency_ms, pq_inject.success_rate, pq_preview.latency_ms, pq_export.latency_ms, pq_mchecksum.count, pq_diagnostics.collection_count. Metrics are locally buffered and uploaded by CORE_Telemetry in audited batches. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-platform golden governance</strong><br><strong>Unit tests (must include):</strong><br>1. Parameterize_Template unit vectors for various types (strings, numbers, dates, lists, records) ensuring typed M insertion and escaping correctness. <br>2. Compute_mChecksum goldens: same M with different line ending and comment variants produce expected normalized checksum. <br>3. Add_Query_From_M host API mock tests covering success, transient host exceptions (retry), hard failures (policy blocks), and partial-failure recovery. <br>4. EnsureQueryNameUnique tests with case-insensitive vs case-preserving host semantics. <br><strong>Integration tests:</strong><br>1. End-to-end inject: parameterize -> persist artifact -> host add query -> create connection -> export artifact -> diagnostics verify artifact parity. <br>2. Preview sandbox tests with deterministic seeding (DeterministicRNG) to reproduce preview rows; verify serialization of RNG state. <br>3. Export degraded path tests on simulated SMB/NFS filesystem with weak rename semantics. <br><strong>Property tests:</strong><br>1. Idempotency property for Add_Query_From_M under retries; ensure no duplicate queries created when retries occur. <br>2. Parameterization property: Parameterize_Template(paramsA) + Parameterize_Template(paramsB) where paramsA==paramsB must produce identical mChecksum. <br><strong>CI golden gating:</strong> golden vectors for mChecksum and parameterization parity across supported host platforms and languages (VBA/COM helper, .NET add-in, Python worker). Static analyzer to flag direct workbook writes in OnLoad. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always persist artifact via Persist_M_Artifact before final Add_Query_From_M unless operator explicitly requests ephemeral injection and the action is recorded with explicit audit. <br>2. Always compute and record mChecksum and paramsHash for every injection action. <br>3. Use EnsureQueryNameUnique to normalize and avoid accidental overwrites. <br>4. For regulated templates, require manifest signature verification prior to injection. <br>5. When performing preview or sampling, seed DeterministicRNG from correlationId for reproducibility and persist RNG state for forensic replay. <br><strong>Forbidden practices:</strong><br>1. Do not embed clear-text credentials into M templates or persisted artifacts. <br>2. Do not perform long-running writes or network exports on UI thread. <br>3. Do not bypass audit emission for injection or export flows. <br>4. Do not assume host rename semantics on network filesystems—use atomic write fallbacks provided by CORE_Utilities. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (executable steps)</strong><br><strong>Injection blocked by host policy (operator cannot programmatically add query):</strong><br>1. pq_inject.failure with PQ_INJECT_BLOCKED_BY_POLICY emitted containing policyFlags and hostPolicyName. <br>2. Persist artifact via Persist_M_Artifact to a user-visible staging area and emit pq_export.completed with staging URI. <br>3. Provide operator with manual import steps and attach artifactChecksum for verification. <br>4. Log host diagnostic info and open ticket if automatic injection essential. <br><strong>mChecksum mismatch detected after injection (divergent query):</strong><br>1. Inspect pq_mchecksum and pq_inject audits; fetch persisted artifact. <br>2. Use Inspect_Queries to compute divergence details. <br>3. If divergence is unintended, run Rollback_Query_Insert using persisted beforeSnapshot and re-inject artifact; record all steps in audit. <br><strong>Export ENOSPC runbook:</strong><br>1. Collect pq_export.failure with details; check filesystem free space. <br>2. Use atomic export staging option to write to local volume on same mount; recompute artifactChecksum and compare. <br>3. If needed, escalate to infra with forensic_manifest and audit_tail rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — how PQ_Injector principles map to templates and runtimes</strong><br><strong>Context:</strong> M is declarative and host-dependent. PQ_Injector cannot and should not attempt to control all runtime behaviors; instead it orchestrates injection, validation, artifact persistence, and host connection creation to produce auditable and reproducible artifacts. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Parameterize using typed M expressions:</strong> always insert parameters as typed M expressions (e.g., <code>#date(...)</code>, <code>#duration(...)</code>) rather than interpolated strings to avoid locale and parsing differences. <br>2. <strong>Preview via sandboxed execution:</strong> do not run template previews against live production connectors without explicit consent. Use deterministic seeds and persist RNG state for reproducible previews. <br>3. <strong>Persist authoritative artifact:</strong> for any template used in production or shared, persist canonical artifact and use <code>mChecksum</code> as the single source of truth for audits and rollbacks. <br>4. <strong>Avoid embedding secrets:</strong> use credential handles or connection references passed in via connectionOptions rather than literal secrets in M text. <br>5. <strong>Model-backed loads:</strong> for reports requiring semantic model integration, prefer Create_Connection_Model with explicit mapping metadata persisted alongside artifact. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — interactions between PQ_Injector and semantic models</strong><br><strong>Context:</strong> DAX is read-time and cannot perform side-effects. PQ_Injector must therefore perform deterministic allocations and rounding in ETL and persist results consumable by DAX. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Push calculated columns requiring authoritative rounding to ETL:</strong> use SafeRound and SafeRoundResiduals during M processing or worker-side transforms and persist integer cents when necessary so DAX measures only aggregate. <br>2. <strong>Persist RunMetadata table:</strong> PQ_Injector must optionally write a RunMetadata artifact (correlationId, artifactChecksum, mChecksum, templateVersion, runTs) into the data model to allow DAX and reports to surface provenance. <br>3. <strong>Deterministic sampling for model-level testing:</strong> compute deterministic sample keys in ETL (e.g., hash of primary key + correlationSalt) and persist seed metadata for replay. <br>4. <strong>Model checksums & reconciliation:</strong> after injection and ETL, PQ_Injector should produce a reconciliation artifact (datasetChecksum) that DAX measures can compare to detect drift; DAX measures surface dataset health but do not perform reconciliation. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Forensic artifacts, evidence paths & recommended retention (concise):</strong><br><strong>Minimum artifacts to retain per injection:</strong> artifact JSON with <code>mText</code>, <code>mChecksum</code>, <code>paramsHash</code>, templateVersion, persisted into evidence store; serialized RNG state for previews and sampling; audit rows (<code>pq_inject.*</code>, <code>pq_preview.*</code>, <code>pq_export.*</code>); host diagnostics and query diagnostics; rollback plans when created. <br><strong>Retention policy:</strong> hot evidence store 30 days, warm archive 7 years for regulated datasets, cold per regulation. Evidence refs in audits must point to encrypted artifacts; PII must never appear in top-level audit rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (detailed):</strong><br>1. Owners recorded in OWNERS.md; approvers designated for template governance. <br>2. Public API documented; backward-compatible versioning. <br>3. Golden vectors for mChecksum and Parameterize_Template parity across host implementations. <br>4. AtomicWrite integration tests and degraded-path tests for network filesystems. <br>5. Static checks preventing UI-thread blocking writes. <br>6. Audit hook coverage validated by test harness emitting expected audit rows. <br>7. Release manifest signed and PQ_Injector artifacts included in modAudit rotation. <br><strong>Blocking conditions:</strong> missing audit emissions on inject/export flows, golden vector failures, or forbidden-API static check failures. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Test plan highlights & representative tests (explicit)</strong><br><strong>Unit tests:</strong><br>1. Parameterization: vector tests for typed insertion, escaping, defaulting, and secure parameter handling. <br>2. mChecksum: parity tests for varying whitespace and comment policies. <br>3. Name resolution: collision resolution under case-insensitive and case-preserving hosts. <br>4. Host API error mapping and Retry correctness. <br><strong>Integration tests:</strong><br>1. End-to-end inject -> persist -> host add -> create connection -> export -> diagnostics verification. <br>2. Preview reproducibility using DeterministicRNG and persisted RNG state. <br><strong>Property tests:</strong><br>1. Idempotency of Add_Query_From_M under repeated identical requests. <br>2. Parameterization mapping stability across template versions where compatible. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & examples (prescriptive):</strong><br>1. <code>pq inject --template &lt;id&gt; --params &#x27;{&quot;dateFrom&quot;:&quot;2025-01-01&quot;}&#x27; --mode connectionOnly --correlation r-YYYYMMDD-xxx</code> — persist artifact, create connection only, emit pq_inject.completed with artifactChecksum. <br>2. <code>pq preview --template &lt;id&gt; --params ... --sample 50 --seed &lt;seed&gt;</code> — create deterministic preview and store RNG state. <br>3. <code>pq export --query &lt;name&gt; --dest \\share\exports\</code> — atomic export; on ENOSPC follow staging fallback. <br>4. <code>pq rollback --query &lt;name&gt; --correlation &lt;id&gt;</code> — revert an injection using persisted snapshot (requires operator confirmation). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded)</strong><br><strong>Failure mode: host policy blocks injection</strong><br>1. Cause: macro or trust settings prevent programmatic modifications. <br>2. Mitigation: persist artifact and provide operator manual import steps; request infra to sign XLAM or update host policy when enterprise-managed. <br><strong>Failure mode: injected query diverges from persisted artifact</strong><br>1. Cause: operator edited query manually after injection or host add path mutated formula. <br>2. Mitigation: Inspect_Queries to detect divergence; if unintended, Rollback_Query_Insert and re-inject persisted artifact; update user guidance to avoid manual edits on injected artifacts. <br><strong>Failure mode: mChecksum mismatch between persisted artifact and injected formula</strong><br>1. Cause: normalization differences or host API modified whitespace/comments. <br>2. Mitigation: ensure Compute_mChecksum uses host-compatible normalization rules; preserve comments where important; update golden vectors. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Governance checklists & PR requirements (explicit)</strong><br>1. PR must include unit tests for new behavior, golden vectors for mChecksum changes, and audit emission validation. <br>2. Changes to parameterization semantics or mChecksum normalization require owner approval and migration manifest. <br>3. Any change to persistence semantics or AtomicWrite usage must include cross-platform tests and SRE sign-off. <br>4. Release manifest update required for production changes affecting injection semantics or regulated templates. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples (selected)</strong><br><strong>Scenario 1 — Operator injects regulated template requiring high numeric fidelity:</strong><br>1. Operator selects <code>Revenue_Schedule</code> template, marked <code>requiresHighPrecision=true</code>. PQ_Ribbon composes request with correlationId r-20260117-abc and chosen parameters; PQ_Injector emits pq_preview.start and computes deterministic preview using seeded DeterministicRNG. <br>2. Parameterize_Template applies parameters as typed M expressions and computes mChecksum. Because template requires high precision, PQ_Injector schedules worker-side SafeRound aggregation to produce authoritative numeric columns and persists the resulting artifact via Persist_M_Artifact. <br>3. Add_Query_From_M is invoked to add query into workbook; because persistence already happened, the injected in-memory formula is guaranteed to match persisted artifact. PQ_Injector creates model connection mapping columns as integer cents where required; pq_inject.completed includes artifactChecksum and model mapping metadata. <br>4. Forensic replay: evidenceRef points to persisted RNG state and artifact JSON enabling exact reproduction of the injected query and numeric transforms. <br><strong>Scenario 2 — Template injection in a locked-down tenant where programmatic injection is blocked:</strong><br>1. PQ_Injector attempts Add_Query_From_M but host returns macro-policy error. PQ_Injector persists artifact to staging path and emits pq_inject.failure with PQ_INJECT_BLOCKED_BY_POLICY. <br>2. Operator is shown step-by-step manual import instructions with artifact checksum to verify integrity. Admin later updates host trust policy and automation proceeds; audit chain links the staging artifact and final injection. <br><strong>Scenario 3 — Deterministic preview for sampling-sensitive template:</strong><br>1. Template includes a sample function with seed parameter. Operator runs preview with correlationId r-...; PQ_Injector seeds DeterministicRNG using correlationId and <code>preview-v1</code> salt and records serialized RNG state in evidence store. <br>2. Preview rows are produced and stored; operator reviews and accepts injection. Later complaint about nondeterministic preview is resolved by replaying preview using the serialized RNG state and producing identical sample rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded)</strong><br><strong>Minimum forensic artifacts per injection:</strong><br>1. persisted artifact JSON with <code>mText</code>, <code>mChecksum</code>, <code>paramsHash</code>, <code>templateVersion</code>, <code>producerVersion</code>, <code>correlationId</code>. <br>2. audit_tail rows for correlationId. <br>3. serialized RNG state for preview runs. <br>4. host diagnostics & query diagnostics (last refresh history). <br>5. rollback plans if created. <br><strong>Evidence storage & access:</strong> hot evidence store for 30 days; warm archive 7 years for regulated artifacts; evidenceRef in audits must be an encrypted pointer with ACLs. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive):</strong><br><strong>Fields required for PQ_Injector audits:</strong> timestamp, correlationId, module=PQ_Injector, procedure, operatorId (optional), paramsHash, mChecksum (optional), artifactChecksum (optional), evidenceRef (optional), hostPlatformVersion, metadata object with durationMs, attempts, queryId, connectionId. <br><strong>Policy note:</strong> do not include raw PII or credentials in top-level audit rows; store sanitized parameters in evidence store. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded)</strong><br><strong>Failure: partial injection due to host crash</strong><br>1. Cause: host crash after query persisted but before connection created. <br>2. Mitigation: detect via pq_inject.partial_failure, persist rollback plan and allow operator to resume insertion; worker reconciles persisted artifact and host state on next run. <br><strong>Failure: parameter coercion differences across platforms</strong><br>1. Cause: different language runtime coercion (e.g., decimal vs double) producing different serialized M expressions. <br>2. Mitigation: Parameterize_Template must use explicit typed M expressions and cross-platform golden tests; flag templates with potential platform-sensitive coercion. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix C — PQ & DAX short checklists for template authors and report builders</strong><br><strong>PQ Template author checklist:</strong><br>1. Provide parameter schema with types and default values. <br>2. Mark templates requiring high numeric fidelity as <code>requiresHighPrecision</code>. <br>3. Avoid embedding secrets; use secure parameter handles. <br>4. Include <code>mChecksum</code> and manifest with signature for regulated templates. <br><strong>DAX/report builder checklist:</strong><br>1. Consume RunMetadata table for provenance and artifactChecksum. <br>2. Avoid performing allocations or residual rounding in DAX; perform in ETL and persist final integers. <br>3. Use persisted hash keys for deterministic sampling if necessary. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Final mandatory constraints (firm):</strong><br>1. Always persist authoritative artifacts for injected queries that will be consumed by other processes. <br>2. Always compute and record mChecksum and paramsHash and link them in audits. <br>3. Do not embed credentials in persisted artifacts; use secure handles. <br>4. For regulated or PII-touching workflows, enforce two-person approval for automatic injections that modify production models. <br>5. All injections and exports must emit audit rows and include evidenceRef when full payloads are necessary for forensics. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Checked:</strong> Ten-pass internal review for internal consistency, audit coverage, deterministic chain from operator action -> parameterization -> mChecksum -> persisted artifact -> workbook injection -> connection creation -> export, and cross-mapping to PQ preview and DAX model patterns. </td></tr></tbody></table></div><div class="row-count">Rows: 35</div></div><div class="table-caption" id="Table4" data-table="Docu_0180_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Diagnostics — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Diagnostics — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_DIAGNOSTICS (primary, secondary, and on-call rotation recorded in OWNERS.md and release manifests).<br><strong>Public API (surface):</strong> <code>CollectQueryDiagnostics</code>, <code>CaptureRefreshTrace</code>, <code>CollectQueryPlan</code>, <code>CaptureProviderDiagnostics</code>, <code>CaptureConnectionFingerprint</code>, <code>ParseErrorTrace</code>, <code>AggregateRefreshPath</code>, <code>BuildDiagnosticReport</code>, <code>ExportDiagnostics</code>, <code>ReplayDiagnostics</code>, <code>CorrelateWithAudit</code>, <code>HealthCheck</code>, <code>SampleDiagnostics</code>, <code>PruneDiagnosticsRetention</code>, <code>InspectTempArtifacts</code>, <code>ScheduleDiagnosticsCapture</code>, <code>GetDiagnosticSummaries</code>, <code>ListEvidenceRefs</code>, <code>FetchEvidenceBundle</code>, <code>ResolvePlanHash</code>, <code>CompareReplayArtifacts</code>, <code>SignDiagnosticManifest</code>.<br><strong>Audits emitted:</strong> <code>pq_diagnostics.requested</code>, <code>pq_diagnostics.started</code>, <code>pq_diagnostics.step:&lt;stepName&gt;</code>, <code>pq_diagnostics.complete</code>, <code>pq_diagnostics.failure</code>, <code>pq_diagnostics.export.attempt</code>, <code>pq_diagnostics.export.completed</code>, <code>pq_diagnostics.replay.started</code>, <code>pq_diagnostics.replay.completed</code>, <code>pq_diagnostics.prune.completed</code>, <code>pq_diagnostics.health.ok</code>, <code>pq_diagnostics.health.failed</code>. Every audit row includes <code>correlationId</code>, <code>module=PQ_Diagnostics</code>, <code>procedure</code>, <code>paramsHash</code>, and <code>resultHash</code> when applicable; large payloads are referenced by <code>evidenceRef</code> and never embedded directly in audit rows.<br><strong>Purpose and intended use:</strong> provide deterministic, auditable, minimal-invasive diagnostics and replayable captures for Power Query (M) templates, preview flows, refresh runs, provider interactions, and injected queries. Serve support engineers, SRE, template authors, compliance teams, and incident responders by producing reproducible artifacts (plans, traces, provider diagnostics, sample data, error fingerprints), reductionist summaries for rapid triage, and signed manifests for regulatory evidence. The module is intentionally read-only in default flows; any action that would mutate workbook state requires explicit audited operator confirmation and a separate remediation flow.<br><strong>Non-goals / constraints:</strong> do not persist raw credentials or secrets in audit rows, do not attempt remediation within collect functions, do not perform provider-side debugging without recorded operator consent, do not depend on external telemetry during UI-thread operations, and avoid platform-specific behaviors in canonical artifacts (plan canonicalization compensates for host differences). </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (invariants & SLOs):</strong><br>1. Deterministic reproduction: given a diagnostics evidence bundle and serialized deterministic RNG (where used), replays produce byte-for-byte equivalent artifacts where external provider responses were captured or stubbed. <br>2. Audit-anchored persistence: every persisted diagnostic artifact is referenced by at least one audit row containing <code>correlationId</code> and <code>artifactChecksum</code>. <br>3. Non-invasiveness: diagnostics collections are read-only and have no side-effects on workbook queries or cells; only explicit remediation flows may apply changes and must emit their own audits. <br>4. UI-safety: heavy captures (full plan, full trace, large sample exports) are scheduled to worker processes; UI-base calls execute lightweight sampling and metadata collection. <br>5. PII minimization and redaction: top-level audits include parameter hashes only; full diagnostic payloads are sanitized, encrypted at rest, and accessible only via controlled evidenceRef with access policies. <br>6. Atomic durability: persisted evidence and manifests use <code>AtomicWrite</code> semantics to prevent partial artifacts; in environments without atomic guarantees a staged manifest approach is used and <code>pq_diagnostics.export.degraded</code> is emitted. <br>7. Observability: all long-running steps emit start/complete audits and include duration metrics; local metric buffers exist for bulk uplink by CORE_Telemetry. <br><strong>Performance SLOs:</strong> median light-mode <code>CollectQueryDiagnostics</code> < 250ms; worker-mode full capture median < 8s (plus provider latency); replay default runtime target < 10 minutes; evidence export median < 500ms for local SSD, subject to target characteristics. <br><strong>CI / acceptance gates:</strong> deterministic sampling golden vectors, plan canonicalization parity tests across supported hosts, redaction enforcement tests, evidence encryption verification, atomic persistence tests, static analyzer checks preventing direct logging of credentials. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CollectQueryDiagnostics(connectionId, queryId, includePlan=false, includeTrace=false, samplePercent=100, rng=null, timeoutMs=30000, mode=&quot;auto&quot;, retentionTag=&quot;hot&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> gather a curated diagnostics package for a query execution context suitable for support triage, forensic replay, and performance profiling. Must not mutate query state. Returns <code>{success, packageId, packageMeta, evidenceRef?}</code> where <code>evidenceRef</code> points to encrypted evidence bundle when payloads exceed audit size thresholds. <br><strong>Detailed parameters & semantics:</strong><br>1. <code>connectionId</code> — stable id referencing persisted connection metadata; used to compute <code>connectionFingerprint</code>. <br>2. <code>queryId</code> — canonical query identifier (workbook query name or job descriptor id); if not found return <code>PQ_DIAG_QUERY_NOT_FOUND</code>. <br>3. <code>includePlan</code> — request provider explain/plan export; may be <code>false</code> for providers that deny plan access. <br>4. <code>includeTrace</code> — request event-level mashup+provider trace; worker-mode capture recommended. <br>5. <code>samplePercent</code> — 0–100 int; when <100, deterministic sampling performed. <br>6. <code>rng</code> — optional <code>DeterministicRNG</code> instance; if omitted and deterministic behavior required, derive seed from <code>correlationId|queryId</code>. <br>7. <code>timeoutMs</code> — overall capture timeout; partial captures are returned if timeout reached. <br>8. <code>mode</code> — <code>&quot;ui&quot;|&quot;worker&quot;|&quot;auto&quot;</code>; <code>auto</code> escalates to worker when heavy captures requested and UI thread is unsuitable. <br>9. <code>retentionTag</code> — evidence retention classification (hot/warm/cold) controlling storage lifecycle. <br><strong>Preconditions & validations:</strong> verify <code>connectionId</code> exists and that the calling context has permission to collect (operatorId matches or delegated support role). For <code>includePlan</code>/<code>includeTrace</code> from UI <code>mode=&quot;auto&quot;</code> attempts to schedule worker capture; if scheduling unavailable return <code>UI_THREAD_FORBIDDEN</code>. Emit initial audit <code>pq_diagnostics.started</code> containing <code>paramsHash</code> to anchor the action. <br><strong>Collection pipeline (high-level):</strong><br>1. Resolve and canonicalize query descriptor: <code>{name, mChecksum, templateVersion, parameterHash, lastPreviewTs}</code>. <br>2. Build capture context: hostFlavor, PQEngineVersion, correlationId, operatorId (if present), jobDescriptor ref. <br>3. Determine sampling seed: use provided <code>rng.serialize()</code> or derive <code>DeterministicRNG(seed_source=correlationId|queryId|packageSalt)</code>; record <code>seedFingerprint</code>. <br>4. Collect light metadata immediately: timings for last preview/refresh, provider name, connectionFingerprint via <code>CaptureConnectionFingerprint</code>, memory/CPU host snapshot. <br>5. If <code>samplePercent</code> < 100 perform <code>SampleDiagnostics</code> deterministically selecting rows/pages/events. <br>6. If <code>includePlan</code> request <code>CollectQueryPlan</code> in worker mode if required; attach <code>planHash</code> or <code>planAvailable=false</code>. <br>7. If <code>includeTrace</code> request <code>CaptureRefreshTrace</code>, stream to evidence store chunked and compressed. <br>8. Parse any immediate errors via <code>ParseErrorTrace</code> and compute <code>errorFingerprints</code>. <br>9. Build <code>packageMeta</code> including artifact list, checksums, summary metrics, critical path hints, and reproduction steps; persist manifest via <code>AtomicWrite</code>. <br>10. Emit <code>pq_diagnostics.complete</code> with <code>packageId</code> and <code>artifactChecksum</code>. <br><strong>Output packageMeta schema (canonical):</strong> <code>{packageId, connectionFingerprint, mChecksum, planHash?, traceId?, sampleSeedFingerprint, artifacts:[{type, evidenceRef, checksum, sizeBytes, retentionTag}], summary:{timings:{totalMs, criticalPathMs}, providerErrors:[{code, count, sampleErrorFingerprint}], samplePreview:[rows], reproduction:{seed, correlationId, commands}}}</code>. <br><strong>Edge cases & failure modes:</strong><br>1. Unknown <code>queryId</code> -> <code>PQ_DIAG_QUERY_NOT_FOUND</code> audit and error result. <br>2. Provider denies <code>EXPLAIN</code> -> <code>planAvailable=false</code> with <code>providerReason</code> included. <br>3. Capture truncated by <code>maxEvents</code> or <code>timeout</code> -> <code>partial=true</code> with <code>partialReason</code>. <br>4. Evidence store quota exceeded -> emit <code>pq_diagnostics.step:evidence_store.ENOSPC</code> and persist partial metadata. <br><strong>Audits generated:</strong> <code>pq_diagnostics.started(correlationId, paramsHash)</code> <code>pq_diagnostics.step:sample_selected(correlationId, sampleSeedFingerprint)</code> <code>pq_diagnostics.step:plan_collected(correlationId, planHash|planAvailable=false)</code> <code>pq_diagnostics.step:trace_captured(correlationId, traceId, eventsCount, evidenceRef)</code> <code>pq_diagnostics.complete(correlationId, packageId, artifactChecksum, durationMs)</code>. <br><strong>Examples & narratives:</strong><br>1. Quick triage: support calls <code>CollectQueryDiagnostics(connSales, qOrdersPreview, includePlan=false, includeTrace=false, samplePercent=10)</code> which returns small deterministic sample and timing summary enabling immediate reproduction on a developer workstation. <br>2. Forensic path: after a nightly refresh failure, <code>CollectQueryDiagnostics(... includePlan=true, includeTrace=true, mode=&quot;worker&quot;)</code> creates a full evidence bundle; SRE runs <code>ReplayDiagnostics</code> in sandbox using captured provider responses and serialized RNG to prove root cause. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureRefreshTrace(connectionId, runId, startTs=null, endTs=null, eventFilter=null, maxEvents=100000, streamToEvidence=true, compress=true, redactPatterns=[...])</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> ingest and persist a time-ordered stream of mashup engine and provider events for a single refresh run. The trace artifact is intended to support fine-grained performance analysis, failure reconstruction, and retry behavior analysis. <br><strong>Event taxonomy:</strong> captured events include <code>ProviderCallStart</code>, <code>ProviderCallEnd</code>, <code>ProviderResponse</code>, <code>CacheLookup</code>, <code>CacheHit</code>, <code>MashupStepStart</code>, <code>MashupStepEnd</code>, <code>RowPage</code>, <code>DataBuffer</code>, <code>ErrorEvent</code>, <code>RetryAttempt</code>, <code>NetworkTimeout</code>, <code>GCEvent</code>, <code>ResourceThrottle</code>. Each event stored includes <code>timestamp</code> (UTC ISO8601 ms), <code>sequenceNumber</code> (monotonic), <code>nodeId</code> (queryId/stepId), <code>eventType</code>, <code>durationMs</code> (when applicable), and <code>payloadFingerprint</code>. <br><strong>Capture semantics:</strong><br>1. Subscribe to engine event bus or provider diagnostics hooks; if direct subscription impossible, reconstruct events using available logs and provider call records. <br>2. Apply <code>eventFilter</code> (allowlist or blocklist) to keep trace focused. <br>3. Enforce <code>maxEvents</code> to bound size; when truncated produce <code>traceSummary</code> and <code>partial=true</code> with <code>droppedEventCount</code>. <br>4. Redact sensitive payload fields per <code>redactPatterns</code> and established redaction policy before any persistence. Redaction replaces values with deterministic fingerprints (e.g., <code>sha256(value)</code> masked) stored in evidence manifest. <br>5. Stream to evidence store chunked; if <code>compress=true</code> apply streaming compression (GZIP/DEFLATE) with chunk manifest containing chunk checksums for piecewise verification. <br>6. Compute derived aggregates on ingest: event counts by type, average latencies, retry histograms, top slow nodes, concurrency peaks. Include <code>criticalSegment</code> summary listing the top N slow nodes by exclusive/inclusive time. <br><strong>Trace summary fields:</strong> <code>traceId</code>, <code>eventsCaptured</code>, <code>durationMs</code>, <code>errorCount</code>, <code>retryCount</code>, <code>avgProviderLatencyMs</code>, <code>criticalSegment</code> (array), <code>droppedEventCount</code>, <code>evidenceRef</code> (if persisted). <br><strong>Edge conditions & provider behavior:</strong><br>1. Provider streaming responses (very high volume) -> capture first N pages and compute aggregate statistics; advise operator to increase <code>maxEvents</code> or use stratified sampling for deep analysis. <br>2. Provider denies capture hooks -> record <code>PROVIDER_TRACE_DENIED</code> and include provider capabilities metadata. <br><strong>Audit events:</strong> <code>pq_diagnostics.step:trace_captured(correlationId, traceId, eventsCaptured, evidenceRef)</code>. <br><strong>Narratives & examples:</strong><br>1. A trace reveals a repeating pattern where a provider returns 429 Too Many Requests followed by a series of retries that overlap with a heavy join step in the mashup engine; the <code>criticalSegment</code> points to the join as the concurrency bottleneck and the trace shows the exact timestamps of each retry enabling precise throttling diagnosis. <br>2. Compression and chunking allow the team to store a 1.5GB raw trace as 12 compressed chunks with manifest checksums and to replay only the relevant chunks for a focused investigation. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CollectQueryPlan(queryText, parameters, provider, timeoutMs=15000, requireCanonical=true, fallbackInstrumentation=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> obtain an execution plan from the provider or reconstruct a canonical plan representing the operator ordering and cost hints. Output must be canonicalized for checksumming and cross-host parity. <br><strong>Plan acquisition strategies:</strong><br>1. Provider-native <code>EXPLAIN</code>/<code>PLAN</code> call for SQL-like providers. <br>2. Provider-specific plan APIs (some NoSQL or connector providers supply explain endpoints). <br>3. If provider lacks plan APIs and <code>fallbackInstrumentation=true</code>, run an instrumented execution in worker-mode capturing step operator sequence and cost estimates; produce heuristic plan. <br><strong>Canonicalization rules:</strong><br>1. Remove ephemeral data: object ids, timestamps, node handles, memory addresses. <br>2. Normalize numeric cost estimates to ranges to avoid instability across runs (e.g., cost ~ [100-120]). <br>3. Sort commutative children in deterministic order (by hash of subtree canonicalization). <br>4. Remove or normalize host-specific dialect differences in operator names via a provider mapping layer. <br>5. Output canonical plan with stable whitespace and param ordering to enable deterministic checksumming. <br><strong>Plan artifact:</strong> <code>canonicalPlanText</code>, <code>planHash</code> = SHA256(canonicalPlanText), <code>planSummary</code> = {operatorCounts, estimatedCardinalities, topOperators}. <br><strong>Provider capability mapping:</strong> maintain <code>providerCapabilities</code> directory that lists whether a provider supports plan export, plan level detail, and any special handling required. <br><strong>Failure modes & fallbacks:</strong> if plan export is refused, return <code>planAvailable=false</code> and <code>fallbackInstrumentation</code> output when permitted. If instrumentation prohibited by provider policy or operator setting, produce <code>planUnavailableReason</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:plan_collected(correlationId, provider, planHash, planAvailable)</code>. <br><strong>Narrative example:</strong> a pre-release test identifies that the MPP provider returns different plan representations across versions; canonicalization collapses these differences into the same <code>planHash</code> for golden comparison and triggers a compatibility check in CI. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureProviderDiagnostics(providerHandle, requestContext, headersFingerprint=true, redactPatterns=[...], bodyPreviewKb=128, captureTlsInfo=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> capture provider-level diagnostics (request/response metadata, status, headers fingerprint, truncated body preview, TLS handshake details) while ensuring no sensitive headers or secrets are persisted. <br><strong>Data collected:</strong> method, endpointFingerprint (hash of scheme+host+port), providerVersion, TLS cipher suite (if allowed), responseStatus, responseLatencyMs, <code>headersFingerprint</code> (hash of header names/structure), <code>bodyPreview</code> truncated and redacted up to <code>bodyPreviewKb</code>, response body hash, and <code>requestFingerprint</code> for correlation. <br><strong>Redaction rules & enforcement:</strong> automatically redact fields matching <code>Authorization</code>, <code>Cookie</code>, <code>Set-Cookie</code>, <code>Authentication</code>, and configured <code>redactPatterns</code>; replace with deterministic fingerprints (e.g., <code>REDACTED_SHA256:&lt;hash&gt;</code>). Log a <code>redactionSummary</code> in the artifact meta listing redacted fields and counts. <br><strong>Constraints & policies:</strong> do not invoke provider debug endpoints or request server-side logs without explicit operator consent and recorded audit approval. Respect provider rate limits and terms of service. <br><strong>Audit:</strong> <code>pq_diagnostics.step:provider_diagnostics(correlationId, providerFingerprint, responseStatus, evidenceRef?)</code>. <br><strong>Example use-case:</strong> an HTTP provider returns a transient 500 with HTML body; <code>CaptureProviderDiagnostics</code> records the response status and body preview (redacted) and includes a TLS fingerprint showing client-server negotiation parameters to assist SRE in TLS mismatch diagnostics. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureConnectionFingerprint(connectionConfig, includeDriver=false, salt=&quot;&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> compute a stable, non-sensitive fingerprint to identify a connection across runs without storing credentials or PII. Intended to group failures and identify persistent endpoints. <br><strong>Fingerprint composition (non-sensitive):</strong> providerType, hostFingerprint (sha256 of host:port), connectionMode (direct/proxy), authMethodType (OAuth/Basic/Token/Integrated), driverName+version (if includeDriver true), sanitizedOptionsHash (hash of non-PII options), and optional salt to namespace. <br><strong>Constraints:</strong> do not include username, password, tokens, or any header values; store only structural and hashed metadata. <br><strong>Operational use:</strong> group <code>pq_diagnostics</code> packages by <code>connectionFingerprint</code> to detect repeated upstream issues across different operator credentials. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ParseErrorTrace(errorObject, mashupContext, sourceArtifact=null, redactionPolicy=&quot;standard&quot;, maxFrames=50)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> parse raw engine/provider exception objects into a canonical structured error descriptor for aggregation and remediation guidance. This function produces <code>errorFingerprint</code> to deduplicate identical errors across runs. <br><strong>Parsing pipeline:</strong><br>1. Normalize raw message: strip host-specific tokens, IPs, PIDs, memory addresses. <br>2. Unwrap nested exceptions to identify root cause vs surface symptom. <br>3. Extract <code>stackFrames</code> with function names, step ids, and mashup step contexts; prune vendor internal frames unless <code>debugVerbose</code> enabled. <br>4. Map to standardized error codes <code>PQ_ERR_*</code> using provider and engine mapping tables with confidence scores. <br>5. Supply <code>remediationHints</code> and <code>reproSteps</code> derived from cause mapping (e.g., <code>refresh with smaller batch</code>, <code>increase timeout</code>, <code>re-authenticate</code>). <br><strong>Output schema:</strong> <code>{parsedError:{code, shortMessage, longMessage, stackFrames[]}, errorFingerprint, remediationHints[], reproducibilityHints, evidenceRef?}</code>. <br><strong>Edge cases:</strong> errors without stack traces still produce a fingerprint via canonicalized message and context; extremely verbose logs truncated and referenced via <code>evidenceRef</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:error_parsed(correlationId, errorFingerprint, code)</code>. <br><strong>Example:</strong> HTTP 401 mapping to <code>PQ_ERR_PROVIDER_AUTH</code> yields remediation hint <code>Verify provider credentials and refresh tokens using secure reauth flow</code> and a <code>reproSteps</code> mapping to <code>CaptureProviderDiagnostics</code> for header fingerprints. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>AggregateRefreshPath(mashupSequence[], providerCallRecords[], includeConcurrency=true, lockHints=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> generate a canonical directed graph representing query dependencies, provider edges, and compute critical path timings and concurrency hotspots for performance and correctness analysis. <br><strong>Algorithmic steps:</strong><br>1. Canonicalize nodes to <code>{queryId, stepId, mChecksum}</code> and edges according to dependencies. <br>2. Annotate nodes with provider calls and resource usage fingerprints. <br>3. Use topological traversal to compute earliest start, latest finish, exclusive and inclusive durations, and identify the critical path using longest-path in DAG heuristics adjusted for resource locks. <br>4. Provide <code>concurrencyMap</code> indicating overlapping node windows and <code>contentionPoints</code> where resource locks or provider throttles serialized execution. <br><strong>Output:</strong> <code>{dependencyGraph, criticalPathNodes[], aggregateTimings, concurrencyMap, contentionPoints}</code>. <br><strong>Use-case:</strong> explains performance regressions where a provider call created a serialization barrier causing downstream queueing—critical for SRE tuning and query rewrite suggestions. <br><strong>Audit:</strong> <code>pq_diagnostics.step:refresh_graph(correlationId, nodeCount, criticalPathMs)</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>BuildDiagnosticReport(packageMeta, format=&quot;json&quot;, includeArtifacts=false, redactPolicy=&quot;standard&quot;, linkEvidence=true, includeReproSteps=true, signManifest=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> assemble a signed, auditable diagnostic report combining summary, detailed artifacts, reproduction instructions, and a manifest of evidenceRefs and checksums. Intended for support tickets, vendor sharing (sanitized), and compliance submissions. <br><strong>Report components:</strong><br>1. Header: <code>correlationId</code>, <code>packageId</code>, <code>operatorId</code> (if available), <code>runTs</code>, <code>reportId</code>. <br>2. Top-line summary: short reproducible one-liner describing core symptom, top contributing factor, and immediate action. <br>3. Run metadata and environment snapshot: hostParityVector, PQEngineVersion, providerVersion, connectionFingerprint. <br>4. Diagnostics summary: timings, sample preview, planHash, trace summary, error fingerprints. <br>5. Evidence index: list of artifacts with <code>evidenceRef</code>, <code>artifactChecksum</code>, size, retention tag, and access policy notes. <br>6. Reproduction steps: explicit commands for <code>replay.run</code> including seed fingerprints and sandbox options; note <code>allowNetwork=false</code> by default. <br>7. Remediation suggestions: prioritized, pragmatic fixes with <code>confidenceScore</code>. <br>8. Signed manifest: <code>reportChecksum</code>, <code>signature</code> using release manifest signing key. <br><strong>Formatting & output:</strong> support <code>json</code>, <code>html</code>, <code>markdown</code> with embedded manifest in <code>html</code> and <code>json</code> formats. If <code>includeArtifacts=true</code> embed small sanitized artifacts (< 64KB) inline; otherwise reference via <code>evidenceRef</code>. <br><strong>Security & redaction:</strong> enforce redaction policy—no PII in top-level summary; evidence storage accessible under ACLs only. <br><strong>Audits:</strong> <code>pq_diagnostics.step:report_built(correlationId, reportId, format, reportChecksum)</code>. <br><strong>Example narrative:</strong> vendor support requires planHash and traceId; <code>BuildDiagnosticReport</code> produces signed HTML with manifest and a <code>reproduction</code> section that allows vendor to run a local reproduction using stubs. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ExportDiagnostics(reportBlobRef, targetUri, atomic=true, maxAttempts=3, retentionTag=&quot;hot&quot;, metadata={})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> export diagnostic reports and evidence manifests to external destinations robustly and audibly; use atomic semantics where possible and provide staged fallback for non-atomic targets. <br><strong>Detailed behavior:</strong><br>1. For file systems supporting atomic replace, write to temp path and execute <code>AtomicWrite</code> semantics (<code>os.replace</code>, platform-specific ReplaceFile) ensuring atomic deliver semantics. <br>2. For object stores or network targets without atomic replace, use staged upload: upload a <code>reportId.tmp</code>, then <code>reportId.manifest</code> with checksum and finalization marker <code>reportId.ready</code>; emit <code>pq_diagnostics.export.degraded</code>. <br>3. On transient errors apply <code>Retry</code> wrapper with idempotency assertion and deterministic_jitter for CI. <br>4. Ensure exported metadata contains <code>reportChecksum</code>, <code>correlationId</code>, <code>evidenceRefs</code>, <code>retentionTag</code>, and <code>signedManifestRef</code>. <br><strong>Error handling & runbook:</strong> on <code>ENOSPC</code> produce <code>pq_diagnostics.export.failure</code> including <code>mountPath</code>, <code>freeBytes</code>, and suggested operator actions (<code>stage-local</code>, change retention). If permission errors occur, provide ACL snapshot and recommended commands. <br><strong>Audits:</strong> <code>pq_diagnostics.export.attempt(correlationId, reportId, destinationUri, paramsHash)</code> <code>pq_diagnostics.export.completed(correlationId, reportId, destinationUri, artifactChecksum)</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ReplayDiagnostics(evidenceRef, sandboxOptions={allowNetwork:false, maxRuntimeMs:600000, memoryMb:2048}, restoreRngState=true, dryRun=true, replayMode=&quot;strict&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> run a deterministic replay using captured trace and artifact bundle within an isolated sandbox to reproduce observed behavior. Replays are read-only against production systems unless explicit operator approval sets <code>allowNetwork=true</code> and supplies controlled tokens for provider access; such approval must be audited. <br><strong>Replay safety & constraints:</strong><br>1. Default <code>allowNetwork=false</code> ensures no external calls; captured provider responses are used to feed the replay. <br>2. Replay uses a headless mashup runner that faithfully implements the same operator semantics as host engine; parity vectors for engine implementation are used to detect host-induced divergence. <br>3. <code>restoreRngState</code> restores <code>DeterministicRNG</code> state when persisted; otherwise seed derivation is used and differences recorded. <br><strong>Replay procedure:</strong><br>1. Fetch evidence bundle and validate checksums. <br>2. Recreate sanitized environment and restore serialized RNG state if present. <br>3. Rehydrate provider responses from snapshots or stubs; if <code>allowNetwork=true</code> with operator approval use safe tokens or proxy stubs. <br>4. Execute step-by-step mashup operations in the headless runner with instrumentation; write replay artifacts to ephemeral storage. <br>5. Compute <code>replayArtifactChecksums</code> and a <code>deltaReport</code> comparing them to original artifact checksums. <br>6. Persist <code>replayLogRef</code> and produce <code>replayOutcome</code> with <code>match:true/false</code> and diagnostics for mismatches. <br><strong>Audit:</strong> <code>pq_diagnostics.replay.started(correlationId, replayId, evidenceRef)</code> <code>pq_diagnostics.replay.completed(correlationId, replayId, outcome, artifactChecksums, deltaReportRef)</code>. <br><strong>Example narrative:</strong> compliance requests replay proof for a sensitive run; replay executed in a fully sandboxed environment reproduces the artifactChecksum for the report, enabling an auditable compliance submission. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CorrelateWithAudit(correlationId, diagnosticsPackageMeta, auditTailWindow=1000)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> anchor diagnostics packages to the append-only audit chain and produce a cryptographically signed <code>forensic_manifest</code> for chain-of-custody. <br><strong>Procedure:</strong><br>1. Query audit store for rows matching <code>correlationId</code> and within the configured <code>auditTailWindow</code> to capture pre/post related actions. <br>2. Compute <code>auditRowHashes[]</code> and an <code>auditChainHash</code> by chaining consecutive record hashes. <br>3. Build <code>forensic_manifest</code> listing artifacts, <code>evidenceRefs</code>, <code>artifactChecksums</code>, <code>auditRowHashes</code>, <code>operatorApprovals</code>, and <code>configHash</code>. <br>4. Sign manifest with release manifest key and persist via <code>AtomicWrite</code> to evidence store; return <code>manifestRef</code>. <br><strong>Output:</strong> <code>{manifestRef, linkedAuditRowsCount, auditChainHash}</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:correlated_with_audit(correlationId, manifestRef, linkedCount)</code>. <br><strong>Use-case:</strong> required for regulatory packages where a signed manifest and audit chain are necessary to demonstrate reproducibility and unbroken evidence chain. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>HealthCheck()</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> quick diagnostic check validating critical module dependencies: evidence store connectivity, <code>AtomicWrite</code> helper health, available temp disk quota, worker queue availability, service account permissions for export destinations, and redaction policy enforcement. Returns <code>{ok, checks:{evidenceStore, atomicWrite, diskQuota, workerQueue, retentionPolicy, secretsAccess}, timestamp}</code> and emits <code>pq_diagnostics.health.ok</code> or <code>pq_diagnostics.health.failed</code>. <br><strong>Operational usage:</strong> invoked at add-in load, periodically by scheduler, and integrated in CI gating. Health check must be lightweight and not perform heavy IO or exports in the UI thread. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>SampleDiagnostics(populationSize, samplePercent, correlationId, rng=null, strata=null, deterministic=true, minSample=10)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic sampling helper used by the diagnostics module to select rows, pages, or events to include in packages while maintaining reproducibility and statistical representativeness. <br><strong>Algorithmic choices & behavior:</strong><br>1. If <code>rng</code> null and <code>deterministic=true</code> derive <code>rng</code> from <code>DeterministicRNG(seed_source=correlationId|populationFingerprint)</code> to guarantee repeatability. <br>2. If <code>strata</code> present perform proportional allocation across strata and then deterministic selection within each stratum. <br>3. For very large or streaming populations use deterministic reservoir sampling seeded by <code>rng</code>. <br>4. Ensure <code>minSample</code> lower bound to avoid empty samples in small populations. <br><strong>Output:</strong> <code>{indices[], sampleSeedFingerprint, methodUsed, deterministic=true}</code> with <code>indices</code> sorted for stable presentation. <br><strong>Audit:</strong> <code>pq_diagnostics.step:sampling(correlationId, populationSize, samplePercent, sampleSeedFingerprint)</code>. <br><strong>Examples:</strong> selecting 5% of rows from a 1M row table using stratified by country ensures distributed representation; sampling seed serialized into evidence bundle for exact replay. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (concepts & mapping)</strong><br><strong>Audit schema (required fields):</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module=PQ_Diagnostics</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>durationMs</code>, <code>metadata</code> including <code>artifactChecksum</code>, <code>reportId</code>, <code>tempChunkList</code>. All major steps must emit start/complete events. <br><strong>Top-level diagnostic events:</strong> <code>pq_diagnostics.requested</code>, <code>pq_diagnostics.started</code>, <code>pq_diagnostics.step:sample_selected</code>, <code>pq_diagnostics.step:plan_collected</code>, <code>pq_diagnostics.step:trace_captured</code>, <code>pq_diagnostics.step:error_parsed</code>, <code>pq_diagnostics.export.attempt/completed</code>, <code>pq_diagnostics.replay.started/completed</code>, <code>pq_diagnostics.prune.completed</code>. <br><strong>Representative ErrorCodes and operator guidance mapping:</strong><br>1. <code>PQ_DIAG_QUERY_NOT_FOUND</code> — verify queryId and presence in workbook or job descriptor. <br>2. <code>PQ_DIAG_PLAN_UNAVAILABLE</code> — provider denies plan export; recommend worker-mode instrumentation or vendor assistance. <br>3. <code>PQ_DIAG_TRACE_CAPTURE_FAILED</code> — evidence store or hook failure; inspect temp artifacts. <br>4. <code>PQ_DIAG_EXPORT_ENOSPC</code> — destination out-of-space; use stage-local fallback and contact infra. <br>5. <code>PQ_DIAG_REPLAY_NETWORK_FORBIDDEN</code> — replay attempted with network disabled; obtain audited approval to enable network if necessary. <br>6. <code>PQ_DIAG_PARTIAL_CAPTURE</code> — timeout/truncation; optionally re-run with increased budgets. <br><strong>Metrics:</strong> <code>pq_diagnostics.packages_per_hour</code>, <code>pq_diagnostics.full_trace_size_bytes</code>, <code>pq_diagnostics.replay_success_rate</code>, <code>pq_diagnostics.export.latency_ms</code>, <code>pq_diagnostics.partial_capture_rate</code>. Metrics buffered locally and uploaded by CORE_Telemetry; module must not perform remote uploads on the UI fast path. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-host parity governance (comprehensive)</strong><br><strong>Unit tests (required):</strong><br>1. Deterministic sampling parity: given identical seed and population, sample indices match across host implementations. <br>2. Plan canonicalization idempotence: transient fields removed produce stable <code>planHash</code>. <br>3. Trace capture truncation produces <code>partial=true</code> and correct <code>droppedEventCount</code>. <br>4. ParseErrorTrace canonicalizes nested exceptions to identical <code>errorFingerprint</code> when equivalent. <br>5. BuildDiagnosticReport redaction verification: no PII in top-level summary and evidenceRef points to encrypted artifact. <br><strong>Integration tests:</strong><br>1. Full collect->report->export pipeline with mocked providers and object storage; verify <code>artifactChecksum</code> and audit emissions. <br>2. ReplayDiagnostics sandbox test ensuring <code>allowNetwork=false</code> prevents outbound connections and replay artifacts match expected checksums. <br>3. CorrelateWithAudit end-to-end manifest signing and audit chain verification. <br><strong>Property tests & fuzzing:</strong><br>1. Sampling coverage and representation properties under random seeds and populations. <br>2. Trace chunking/reassembly property tests ensure chunk checksums combine to original trace summary. <br><strong>Cross-host golden gating:</strong> produce golden vectors for sampling outputs, canonicalized plans, error fingerprints, and replay artifacts; CI requires parity across supported host environments (Windows Excel, Excel for Mac, headless worker dockers) and across language SDKs used by orchestration (Python/JS/VBA) before changes merge. <br><strong>Security and privacy tests:</strong> automated redaction tests for headers and bodies, evidence encryption verification, and ACL test harness to ensure evidenceRefs enforce access permissions. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always use <code>CollectQueryDiagnostics</code> for support capture requests; prefer <code>mode=&quot;worker&quot;</code> for heavy captures. <br>2. Persist <code>correlationId</code> and seed values in job descriptors for reproducibility. <br>3. Use <code>AtomicWrite</code> for all persisted evidence and manifests; static analyzers should fail builds that write direct final artifact paths from UI code. <br>4. Seed deterministic sampling with <code>DeterministicRNG</code> and persist serialized RNG state when exact replay is required. <br>5. Emit audit rows for every capture, export, and replay; audits must include <code>paramsHash</code> and <code>artifactChecksum</code> when available. <br><strong>Forbidden patterns:</strong><br>1. Do not log raw credentials, tokens, or PII in audits or diagnostics payloads. <br>2. Do not enable network during replay without explicit audited operator approval. <br>3. Do not perform in-place query rewrites or destructive operations during capture flows. <br>4. Do not bypass redaction policy for convenience. <br><strong>Code-review checklist:</strong> verify audit emissions, evidenceRef usage, <code>AtomicWrite</code> usage for persisted artifacts, deterministic sampling seed propagation, UI-thread safety for heavy flows, redaction enforcement, and presence of cross-host parity tests for any canonicalization logic changes. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable steps)</strong><br><strong>Trace capture ENOSPC runbook:</strong><br>1. Inspect <code>pq_diagnostics.export.failure</code> audit row for <code>correlationId</code> and <code>destinationUri</code>. <br>2. Run <code>diagnostics inspect-temp --correlation &lt;id&gt;</code> to enumerate temp chunk files and compute their checksums. <br>3. If local staging feasible, re-run <code>diagnostics export --report &lt;id&gt; --target --stage-local</code> to move artifacts onto same volume then re-export. <br>4. If blocked by quota or permissions escalate with <code>forensic_manifest</code> attached to infra ticket; include <code>pq_diagnostics</code> export failure audit. <br><strong>Non-deterministic replay triage:</strong><br>1. Retrieve <code>pq_diagnostics.replay.started</code> and <code>pq_diagnostics.replay.completed</code> audits and the <code>evidenceRef</code> for RNG state. <br>2. Run <code>replay.run --evidence &lt;ref&gt; --dry-run</code> and compare <code>replayArtifactChecksums</code> to original artifacts. <br>3. If mismatch persists, collect host parity vectors (engine versions, OS, PQ engine flavor) and escalate to parity/golden team with delta artifacts. <br><strong>Provider auth failure remediation:</strong><br>1. Locate <code>ParseErrorTrace</code> mapping to <code>PQ_ERR_PROVIDER_AUTH</code> and capture <code>providerFingerprint</code>. <br>2. Request operator reauthorization via secure flow; after reauth re-run <code>CollectQueryDiagnostics</code> to confirm resolution; persist new <code>connectionFingerprint</code> in config store. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Extremely detailed long-form narratives & examples (multiple scenarios)</strong><br><strong>Scenario 1 — Intermittent scheduled refresh failure (end-to-end forensic trace):</strong><br>1. Monitoring alert links to correlationId <code>r-20260102-b78</code>. SRE triggers <code>CollectQueryDiagnostics(connReporting, qDailyAggregate, includePlan=true, includeTrace=true, mode=&quot;worker&quot;)</code>. {audit: <code>pq_diagnostics.requested</code>} <br>2. <code>CaptureRefreshTrace</code> captures event stream across the 00:00-00:08 window including repeated provider 429 responses timestamped precisely with sequence numbers. The traceSummary reveals <code>retryCount=5</code> with backoff pattern correlating to a scheduled spike of traffic. {audit: <code>pq_diagnostics.step:trace_captured</code>} <br>3. <code>CollectQueryPlan</code> returns <code>planHash</code> where <code>HashAggregate</code> is performing heavy grouping on a high-cardinality key; canonical plan maps to historical known pattern flagged in plan registry. {audit: <code>pq_diagnostics.step:plan_collected</code>} <br>4. <code>AggregateRefreshPath</code> indicates a join re-ordering caused a late materialization step that overlapped with provider retries, producing cascading latency. <br>5. <code>BuildDiagnosticReport</code> provides reproduction steps for vendor: <code>replay.run --evidence &lt;traceRef&gt; --restoreRngState=true --dry-run</code>. Report includes <code>planHash</code>, <code>traceId</code>, and <code>criticalSegment</code> with exact timestamps. {audit: <code>pq_diagnostics.step:report_built</code>} <br>6. Vendor reproduces with provided plan and identifies a throttle rule; SRE coordinates scheduling change and introduces a migration to pre-aggregate upstream keys to reduce join cardinality. Post-fix re-run <code>CollectQueryDiagnostics</code> validates fix—replay artifactChecksum matches new artifact and scheduled run completes within SLO. <br><strong>Scenario takeaways:</strong> full trace capture with plan canonicalization and deterministic replay allowed cross-team vendor collaboration without exposing PII or credentials and enabled CI-gated remediation. <br><strong>Scenario 2 — Numeric fidelity drift after PQ template injection (deep example):</strong><br>1. Production model exhibits cent-level drift post-injection of a new PQ template. Template author provides <code>mChecksum</code>. Ops runs <code>CollectQueryDiagnostics(connFin, qLedger, includePlan=true, includeTrace=false, samplePercent=100)</code> and captures sample rows and provider plan. {audit: <code>pq_diagnostics.started</code>} <br>2. <code>CollectQueryPlan</code> shows provider casts numeric columns to double before aggregation; <code>ParseErrorTrace</code> notifies no error but <code>planSummary</code> flags the <code>CAST</code> operator. <code>BuildDiagnosticReport</code> recommends offloading final aggregation to worker-safe <code>SafeRound</code> pipeline and persisting final cents via <code>AtomicWrite</code>. <br>3. Ops implements worker-side aggregation with <code>SafeRoundResiduals</code> and persists results; <code>CollectQueryDiagnostics</code> verified final artifactChecksum matches expected golden vector and <code>RunMetadata</code> updated. CI includes golden tests ensuring cross-host parity. <br><strong>Takeaways:</strong> diagnostic pipeline identifies provider-side implicit casting and prescribes worker-side atomicized rounding to ensure regulatory compliance. <br><strong>Scenario 3 — MatchMerge tie-breaking non-determinism (detailed reconstruction):</strong><br>1. Different merge proposals observed across runs for identical input dataset. Operator provides <code>correlationId</code>. <code>CollectQueryDiagnostics</code> captures <code>SampleDiagnostics</code> seeds and <code>ParseErrorTrace</code> indicates RNG state not serialized at proposal persist stage. <br>2. Replay without RNG state reproduces different proposals; with restored RNG state (provided by operator from earlier evidence), replay matches original outputs. <code>BuildDiagnosticReport</code> documents missing RNG serialization bug and prescribes mandatory RNG state persistence for MatchMerge. <br>3. CI adds golden vector test ensuring RNG serialization round-trip parity; deployment includes migration to update existing proposals with serialized RNG metadata. <br><strong>Takeaway:</strong> enforcing RNG state persistence prevents ambiguous merges and ensures reproducibility. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — mapping PQ_Diagnostics to PQ workflows (detailed mapping & best practices)</strong><br><strong>Context:</strong> Power Query (M) runs in-process in Excel or headless engines with limited introspection. <code>PQ_Diagnostics</code> cannot instrument the internal host engine directly from M; orchestration layer (add-in or worker) performs diagnostics collection and interacts with M where safe. <br><strong>Mapping patterns & recommendations:</strong><br>1. <strong>Light-mode preview capture:</strong> UI preview flows should capture parameterHash, <code>mChecksum</code>, deterministic seed for preview sampling, small sample rows, and timing metadata. Use <code>mode=&quot;auto&quot;</code> to escalate heavy capture requests to worker and record <code>preview.audit</code> linking. <br>2. <strong>Worker-mode high-fidelity capture:</strong> heavy plan and trace capture should run in worker processes with higher timeouts and ephemeral staging; avoid performing heavy IO from the UI thread. <br>3. <strong>Template flags and contract:</strong> templates should include metadata: <code>requiresHighPrecision</code>, <code>planCaptureHint</code>, <code>diagnosticsHint</code>, and <code>evidenceRetention</code>. Orchestrator respects these flags to determine whether to offload numeric-critical transforms to <code>SafeRound</code> worker paths. <br>4. <strong>Seeding & reproducibility:</strong> preview flows must accept <code>seed</code> parameter derived from <code>correlationId</code> and persist to preview audit; <code>CollectQueryDiagnostics</code> should include that seedFingerprint for exact preview reproduction. <br>5. <strong>Atomic artifact injection:</strong> authoritative M query artifacts intended for team consumption or audits should be written to evidence store using <code>AtomicWrite</code> and then injected via workbook API referencing the same artifactChecksum; <code>pq_inject</code> audit should include artifactChecksum and mChecksum to validate parity. <br>6. <strong>Provider plan capture:</strong> because M lacks standardized plan introspection, orchestrator should call <code>CollectQueryPlan</code> post-parameterization and before injection if <code>requiresHighPrecision</code> or <code>planCaptureHint</code> present. <br>7. <strong>Retry & idempotency for PQ refresh orchestration:</strong> orchestrator uses <code>Retry</code> wrapper (with idempotency tokens persisted) for job persistence and export; M code stays declarative while orchestration manages resilience. <br><strong>Operator flow example (preview->inject->diagnose):</strong><br>1. Operator previews template; <code>PQ_Ribbon</code> computes <code>seed=SeedFromCorrelation(correlationId, templateId)</code> and passes it to preview parameters; a <code>pq_preview</code> audit is recorded. <br>2. On inject, orchestrator writes final M artifact via <code>AtomicWrite</code> and then calls <code>workbook.Queries.Add</code> using that artifact. <code>pq_inject</code> audit references artifactChecksum and <code>mChecksum</code>. <br>3. If a downstream refresh fails, operator runs <code>CollectQueryDiagnostics</code> for the injected query and receives an evidenceRef and <code>BuildDiagnosticReport</code> with <code>replay</code> instructions. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Diagnostics to semantic models & DAX troubleshooting (detailed mapping & governance)</strong><br><strong>Context:</strong> DAX operates at query time against persisted model metadata; it cannot produce side-effects or persist artifacts. Diagnostics for DAX performance and correctness are produced by ETL and model engine (Analysis Services) and surfaced via DAX measures referencing persisted <code>RunMetadata</code>. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Persist RunMetadata table in ETL:</strong> ETL should write <code>RunMetadata</code> atomically containing <code>correlationId</code>, <code>artifactChecksum</code>, <code>packageId</code>, <code>runTs</code>, <code>diagnosticsReportRef</code>, and <code>engineParityVector</code>. DAX measures and reports consult this <code>RunMetadata</code> for provenance indicators. <br>2. <strong>DMV snapshot captures:</strong> <code>CollectQueryDiagnostics</code> should capture Analysis Services DMVs at ETL completion (query caches, plan caches, table statistics) and store as evidence to correlate slow DAX measures to model statistics. <br>3. <strong>HashKey deterministic sampling for DAX:</strong> in ETL compute <code>HashKey = HASH(PrimaryKey | correlationSalt)</code> and persist <code>correlationSalt</code> in <code>RunMetadata</code>. DAX filters like <code>MOD(HashKey, 100) &lt; k</code> allow deterministic sample views inside reports; <code>SampleDiagnostics</code> uses the same seed for parity. <br>4. <strong>Reconciled flags via artifactChecksum:</strong> ETL writes reconciled artifact and <code>RunMetadata</code>; DAX measure compares model table checksum to expected <code>artifactChecksum</code> and surfaces <code>ReconciledFlag</code> for report consumers. <br>5. <strong>Avoid heavy fixes in DAX:</strong> all transformations requiring rounding, residual distribution, or deterministic tie-breakers should be resolved in ETL using <code>SafeRound</code> primitives and persisted; DAX should only read persisted, reconciled integers or decimals. <br><strong>Narrative example:</strong> a slow DAX measure is traced to a high cardinality materialization; DMV snapshot captured by <code>CollectQueryDiagnostics</code> shows missing statistics and skew in cardinality; ETL is updated to pre-aggregate keys and run <code>CollectQueryDiagnostics</code> captures the post-fix artifactChecksum that DAX surfaces as <code>ReconciledFlag=1</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded and prescriptive)</strong><br><strong>Minimum forensic artifacts for an incident:</strong><br>1. <code>ribbon-map.json</code> and release manifest with signatures. <br>2. <code>jobDescriptor.json</code> persisted via <code>AtomicWrite</code> including <code>jobId</code>, <code>paramsHash</code>, <code>configHash</code>, and <code>correlationId</code>. <br>3. <code>audit_tail.csv</code> covering pre/post windows with <code>pq_diagnostics.*</code> rows. <br>4. artifact files with <code>SHA256</code> checksums and <code>artifact.metadata.json</code>. <br>5. serialized RNG state (<code>rng_state.blob</code>) for sampling/tie-breaker reproduction. <br>6. <code>SafeRound</code> inputs and canonicalized decimal snapshots for numeric forensic. <br>7. trace artifacts and chunk manifests from <code>CaptureRefreshTrace</code>. <br>8. temp artifact listing from <code>InspectTempArtifacts</code> and recovery scripts. <br><strong>Evidence Store & retention:</strong><br>1. Hot evidence store path: <code>evidence/hot/pq_diagnostics/&lt;correlationId&gt;/</code> retained 30 days for rapid access. <br>2. Warm archive: secure archive for 7 years for regulatory retention; access strictly controlled and logged; manifests include chain-of-custody attributes and signatures. <br>3. Cold archive: cold storage per policy with retrieval windows. <br>4. <code>forensic_manifest.json</code> enumerates URIs, checksums, retentionTag, and access policy for investigators. <br><strong>Retention verification cadence:</strong> monthly retention verification job emits <code>pq_diagnostics.prune.completed</code> with counts of pruned artifacts; audits include proof-of-delete records. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (detailed & blocking conditions):</strong><br>1. Owners listed in OWNERS.md with on-call contacts. <br>2. Public API stable and documented with semantic versioning. <br>3. Evidence encryption and key-management tested; key rotation documented. <br>4. Deterministic sampling goldens validated and parity tests across hosts passing. <br>5. Plan canonicalization golden vectors validated for transformed provider output. <br>6. Redaction tests verify absence of PII in top-level audit rows and presence in encrypted evidence only. <br>7. CI gates include static analyzer checks forbidding credential logging and UI-thread heavy IO. <br>8. Integration tests for <code>CollectQueryDiagnostics</code>-><code>BuildDiagnosticReport</code>-><code>ExportDiagnostics</code>-><code>CorrelateWithAudit</code> pipeline pass. <br><strong>Blocking conditions:</strong> missing audit emissions, redaction failures, golden regressions, or absence of AtomicWrite usage for persisted artifacts. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & scripts (explicit, conceptual)</strong><br><strong>Unit tests (explicit):</strong><br>1. Sampling parity and deterministic RNG seeding across seeds. <br>2. Plan canonicalization idempotence across ephemeral provider fields. <br>3. Trace truncation and chunk reassembly tests. <br>4. ParseErrorTrace canonicalization for nested exceptions. <br>5. BuildDiagnosticReport redaction and manifest signing tests. <br><strong>Integration tests:</strong><br>1. collect->report->export: simulate provider interactions and verify <code>artifactChecksum</code> and audit emissions. <br>2. replay sandbox tests: ensure <code>allowNetwork=false</code> prevents outbound connections and that replay artifacts match golden checksums. <br>3. CorrelateWithAudit test ensures manifest contains auditRowHashes with valid signature. <br><strong>Performance tests:</strong><br>1. trace capture throughput under synthetic high event rates, verifying chunk manifest integrity. <br>2. report build latency for large packages (>100MB) and stress test AtomicWrite on various filesystem semantics. <br><strong>Security tests:</strong> PII redaction fuzzing, evidence encryption key rotation, ACL enforcement for evidenceRefs. <br><strong>CI gating:</strong> golden vectors, static checks, and integration test suites must pass; performance regressions cause gate failure requiring owner approval. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (concise & prescriptive)</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-abc --query qName --include-plan</code> — collect diagnostics with plan and stage to evidence store. <br>2. <code>diagnostics export --report &lt;id&gt; --target sftp://host/path</code> — export a signed report using atomic semantics where supported. <br>3. <code>diagnostics replay --evidence &lt;ref&gt; --dry-run</code> — deterministic sandbox replay without network. <br>4. <code>diagnostics inspect-temp --correlation &lt;id&gt;</code> — list temporary chunks from failed captures and compute checksums for manual recovery. <br>5. <code>diagnostics sign-manifest --manifest &lt;id&gt;</code> — re-sign manifest with release manifest key if necessary during regulatory packaging. <br><strong>When to call SRE:</strong> after two <code>pq_diagnostics.export</code> ENOSPC failures for critical artifacts, repeated replay mismatches suggesting host parity failure, or evidence store permission anomalies; include <code>forensic_manifest</code> with ticket. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Final notes, governance & mandatory constraints (firm & non-negotiable):</strong><br>1. Never persist raw credentials or unredacted PII in audit rows or reports; evidence store only with explicit governance and encrypted at rest. <br>2. All persisted artifacts must use <code>AtomicWrite</code> semantics or the staged manifest fallback and emit <code>pq_diagnostics.export.degraded</code> when atomic replace cannot be guaranteed. <br>3. Deterministic RNG seeds must be derived from <code>correlationId</code> for operator-visible sampling; if exact replay required serialize RNG state and store encrypted in evidence store. <br>4. Replays default to sandboxed, network-disabled execution; enabling network must be explicitly approved and audited. <br>5. Exported diagnostic packages must include <code>reportChecksum</code>, <code>correlationId</code>, signed manifestRef, and evidenceRef links. <br>6. All heavy IO or potentially blocking operations are forbidden on the UI thread and must be scheduled to worker processes. <br><strong>Checked:</strong> content underwent multi-pass verification for internal consistency, audit linkage, deterministic sampling, redaction policy, plan canonicalization, replay safeguards, and cross-module dependencies (tenfold review). </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive):</strong><br><strong>Fields required for PQ_Diagnostics audits:</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>prevHash</code> (optional), <code>configHash</code>, <code>metadata</code> including <code>durationMs</code>, <code>attempts</code>, <code>artifactChecksum</code>, <code>reportId</code>, <code>tempChunkList</code>. <br><strong>Policy note:</strong> top-level audit rows must not contain PII; sanitized parameters and large payloads stored in the encrypted evidence store and referenced by <code>evidenceRef</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded):</strong><br><strong>Failure mode: oversized trace artifacts causing ENOSPC</strong><br>1. Cause: <code>includeTrace=true</code> on a high-volume provider without <code>maxEvents</code> or compression. <br>2. Mitigation: enforce <code>maxEvents</code>, apply streaming compression and chunking, use stratified sampling, produce <code>pq_diagnostics.step:truncated</code> and <code>forensic_manifest</code> with chunk checksums; operator may request selective time windows for re-capture. <br><strong>Failure mode: replay mismatch despite captured evidence</strong><br>1. Cause: missing RNG state, host engine parity differences, truncated provider snapshots, or dependency on ephemeral external state. <br>2. Mitigation: mandate RNG state serialization where reproducibility matters, persist host parity vectors in manifest, capture provider snapshots, and add parity diagnostics in CI to reduce heterogeneity. <br><strong>Failure mode: plan unavailable from provider</strong><br>1. Cause: provider blocks <code>EXPLAIN</code> or lacks capability. <br>2. Mitigation: fallback to worker-mode instrumentation to reconstruct plan heuristically, or request vendor plan capture with signed manifest and audit. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests for deterministic behaviors, golden vectors for plan canonicalization, and redaction tests. <br>2. Changes to redaction or retention policies require owner and compliance approval and release manifest updates. <br>3. Changes to export semantics or <code>AtomicWrite</code> usage must include cross-platform regression tests and SRE sign-off. <br>4. Any change to <code>DeterministicRNG</code> serialization format requires migration instructions and golden parity updates. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix D — Incident reconstruction example (ordered & executable):</strong><br><strong>Incident synopsis:</strong> operator reports "Allocation mismatch for run r-20260112-455" — artifact sums different from ledger. <br><strong>Forensic reconstruction steps (ordered):</strong><br>1. Retrieve <code>pq_diagnostics.*</code> and <code>UserAction</code> audit rows for the <code>correlationId</code>. <br>2. Pull <code>artifactChecksum</code> from <code>pq_diagnostics.complete</code> and evidenceRef pointing to <code>SafeRound</code> input snapshot. <br>3. Download <code>rng_state.blob</code> and verify integrity via its checksum; ensure evidence store ACL allows access to investigators. <br>4. Run <code>replay.run --evidence &lt;ref&gt; --dry-run</code> restoring RNG; execute <code>SafeRoundResiduals</code> using persisted canonical decimals. <br>5. Compare produced artifact checksums to original; if identical, pipeline determinism confirmed; if mismatch, inspect <code>atomic_write.verification_failed</code> and temp artifact lists. <br>6. Compile <code>forensic_manifest.json</code> including audit rows, evidenceRefs, and replay delta; escalate to compliance if regulatory impact identified. <br><strong>Outcome:</strong> reproducible replay yields identical artifact showing pipeline correctness; incident closed with runbook updates on tie-break expectations and RNG state persistence. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ & DAX short checklists for template authors and report builders:</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> and <code>templateVersion</code> in template metadata. <br>2. Mark <code>requiresHighPrecision</code> and <code>planCaptureHint</code> for templates performing critical numeric transforms. <br>3. Parameterize a <code>seed</code> for preview flows and persist seed in preview audit. <br>4. Offload final numeric aggregation to worker <code>SafeRound</code> flows for regulated outputs; persist final artifacts with <code>AtomicWrite</code>. <br>5. Provide <code>diagnosticsHint</code> specifying recommended <code>includePlan</code>/<code>includeTrace</code> flags for support. <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> table for provenance and <code>artifactChecksum</code> verification. <br>2. Avoid performing allocation/residual rounding in DAX; convert to ETL-managed persisted columns. <br>3. Use hashed stable keys computed during ETL to enable deterministic sampling and debug views in reports. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix F — Long-form operator scenario: forensic reconstruction and regulatory package (procedural):</strong><br><strong>Scenario synopsis:</strong> regulator requests audit package for a sensitive run produced two weeks earlier; operator must provide signed manifest, reproducible evidence, and replay instructions. <br><strong>Procedural steps:</strong><br>1. Locate <code>pq_diagnostics</code> package by <code>correlationId</code> and verify <code>pq_diagnostics.complete</code> artifactChecksum. <br>2. Run <code>CorrelateWithAudit(correlationId, packageMeta)</code> to build <code>forensic_manifest</code> linking audit rows, evidenceRefs, and artifact checksums; sign manifest with release manifest key. <br>3. Execute <code>ReplayDiagnostics</code> in sandbox with <code>restoreRngState=true</code> and <code>allowNetwork=false</code> to generate <code>replayOut</code> demonstrating artifact parity. <br>4. Build final regulatory bundle: <code>report.html</code> (signed), <code>forensic_manifest.json</code> (signed), evidenceChunks (encrypted), <code>audit_tail.csv</code>, and <code>release_manifest</code> signature; persist bundled package via <code>AtomicWrite</code> to regulated archive with appropriate retention tags. <br>5. Deliver bundle to regulator endpoint according to policy; record <code>submission.audit</code> and preserve chain-of-custody logs. <br><strong>Compliance takeaway:</strong> reproducible evidence bundles and signed manifests are necessary to satisfy audit and regulatory requests while preserving PII constraints. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix G — Migration guidance & backward compatibility (detailed):</strong><br><strong>When RNG serialization format changes:</strong><br>1. Provide a compatibility layer that can read both legacy and new serialized RNG state formats. <br>2. Provide migration tool <code>rng_migrate --evidence &lt;ref&gt;</code> that updates stored RNG blobs and re-computes seedFingerprints. <br>3. Update CI golden vectors and require parity approval from RNG owners. <br><strong>When plan canonicalization rules change:</strong><br>1. Ship canonicalizer in major version and maintain <code>planHashV1</code> and <code>planHashV2</code> columns in registry for migration. <br>2. Provide <code>ResolvePlanHash(planText)</code> utility to compute both v1 and v2 hashes for transition period. <br><strong>When export semantics change:</strong><br>1. Ensure <code>AtomicWrite</code> semantics remain the default; if fallback staging changes, document in release manifest and migrate existing manifests via <code>sign-manifest</code> flow. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix H — Example diagnostic report sections (template outline for authors & support):</strong><br><strong>Report header:</strong> <code>reportId</code>, <code>correlationId</code>, <code>operatorId</code>, <code>runTs</code>, <code>reportChecksum</code>. <br><strong>Executive summary:</strong> short reproducible one-liner. <br><strong>Run metadata:</strong> hostParityVector, PQEngineVersion, connectionFingerprint, mChecksum. <br><strong>Top findings:</strong> key errors, planHash, critical path nodes. <br><strong>Detailed artifacts index:</strong> list of evidenceRefs with checksums and sizes. <br><strong>Repro steps:</strong> exact <code>replay.run</code> invocation with seedFingerprint and sandbox options. <br><strong>Remediation actions:</strong> prioritized suggestions, estimated effort, owner. <br><strong>Signed manifest & chain-of-custody:</strong> signature block and rail of auditRow hashes. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix I — Cross-team responsibilities (concise mapping):</strong><br>1. TEAM_PQ_DIAGNOSTICS — owns capture/replay code, evidence store interface, plan canonicalization, and analytics summaries. <br>2. TEAM_UTILITIES — provides <code>AtomicWrite</code>, <code>DeterministicRNG</code>, <code>Retry</code>, and <code>SafeRound</code> primitives used by diagnostics. <br>3. TEAM_SRE — owns evidence store availability, export endpoints, and infrastructure support for large artifact handling. <br>4. TEAM_COMPLIANCE — verifies signed manifests, retention policies, and regulatory packaging. <br>5. TEAM_TEMPLATE_OWNERS — declare <code>diagnosticsHint</code> and <code>requiresHighPrecision</code> flags in template manifests. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix J — Example CSV of minimal diagnostic manifest (illustrative fields for tooling integration):</strong><br><code>packageId,correlationId,reportId,artifactChecksum,evidenceRef,traceId,planHash,connectionFingerprint,operatorId,runTs</code> <br><strong>Usage:</strong> tools import this CSV to attach diagnostics to support tickets and compliance trackers. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Closing operational constraint (must not be bypassed):</strong><br>All processes that produce artifacts consumed by other modules must: persist job descriptors, seed deterministic RNGs from <code>correlationId</code> for operator-visible sampling, use <code>AtomicWrite</code> for final artifacts, and emit required audit rows. This constraint is mandatory for regulated or PII-touching workflows and enforced by CI static checks and production monitors. </td></tr></tbody></table></div><div class="row-count">Rows: 38</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>