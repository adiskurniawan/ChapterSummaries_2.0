<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1768667116">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0180_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Injector — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Injector — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_INJECTOR (listed in OWNERS.md and referenced in release manifests).<br><strong>Public API (surface):</strong> Add_Query_From_M, Add_Query_From_M_With_Parameters, Parameterize_Template, Preview_M, Compute_mChecksum, Validate_M_Syntax, EnsureQueryNameUnique, Create_Connection, Create_Connection_Model, Add_Query_As_ConnectionOnly, Update_Query_Formula, Remove_Query, Export_M_Artifact, Persist_M_Artifact (AtomicWrite wrapper), Inspect_Queries, Get_Query_Diagnostics, SafeCreateQueryName, Set_Connection_Credentials_Safely, Snapshot_Queries, Rollback_Query_Insert, AuditEmit_PQAction, Register_InjectionHook. <br><strong>Audits emitted:</strong> pq_inject.attempt, pq_inject.completed, pq_inject.failure, pq_preview.start, pq_preview.complete, pq_mchecksum.computed, pq_connection.created, pq_connection.updated, pq_connection.failure, pq_export.attempt, pq_export.completed, pq_export.failure, pq_diagnostics.collected, pq_query.removed, pq_query.updated. Every audit row contains correlationId, module=PQ_Injector, procedure, paramsHash, mChecksum when applicable, artifactChecksum when applicable, and timestamp. <br><strong>Purpose and intended use:</strong> Provide deterministic, auditable, safe APIs for injecting Power Query (M) artifacts into Excel workbooks and Power Query runtimes. Ensure injected queries are validated, parameterized, persisted as auditable artifacts, optionally created as connections only or model-backed connections, and that all side-effects are crash-safe and reversible. Avoid performing blocking long IO on UI thread; defer to worker processes for heavy persistence and network exports. <br><strong>Non-goals / constraints:</strong> Not a general-purpose M authoring tool; not responsible for authoring template repositories; not intended to perform data refresh operations itself (use PQ_Refresh / PQ_Diagnostics). Avoid embedding secrets in top-level audit rows; credentials are passed to credential managers or external secure stores. No uncontrolled workbook DOM modifications; always follow host-approved APIs and naming policies. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operational guarantees & invariants (module-level):</strong><br>1. Determinism: Given identical inputs (template text, parameters, correlationId, config.hash) and same runtime version, the computed <code>mChecksum</code> and persisted artifact bytes must be reproducible across runs and platforms. <br>2. Audit anchoring: Any mutation to workbook queries, connections, or persisted artifacts must be accompanied by at least one audit row referencing correlationId and essential provenance fields. <br>3. Crash-safety: Persistence of M artifacts uses atomic-write semantics (via CORE_Utilities.AtomicWrite or PQ_Utilities.AtomicWrite wrapper) to ensure final-on-success semantics; either old query state remains or new query fully replaces it. <br>4. UI-safety: Avoid long-running IO or blocking actions on the UI thread. Heavy persistence, remote exports, and checksum verification run on background workers; UI handlers only coordinate and emit UserAction audits. <br>5. Name safety: Ensure generated or requested query names do not collide with existing workbook objects; automatically resolve and document name normalization decisions in audits. <br>6. Template governance: For regulated templates, require template owner approval and manifest-signed verification before injection. <br><strong>Performance SLOs:</strong> Inject (local in-memory add) latency for small M payloads <200ms on average in UI helper; persisted artifact atomic-write round-trip median <300ms on local SSD; mChecksum computation for typical template <50KB within 50ms. <br><strong>CI / acceptance gates:</strong> mChecksum parity vectors across supported implementations; cross-platform injection acceptance tests (Excel Windows, Excel Mac where supported, Power BI Desktop if applicable); audit emission verification tests; static checks preventing workbook DOM calls on UI OnLoad handlers. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Design overview & high-level flow (conceptual):</strong><br>1. Operator triggers injection from PQ_Ribbon -> PQ_Injector receives <code>InjectTemplateRequest</code> containing templateId, parameterValues (optional), targetQueryName (optional), injectionMode (<code>InsertInline | ConnectionOnly | ModelConnection</code>), correlationId. <br>2. PQ_Injector computes canonical parameters: validate parameter schema, fill defaults, canonicalize types, compute <code>paramsHash</code>. <br>3. Parameterize_Template: applies parameter substitutions to canonical M template to produce final M formula for injection; compute <code>mChecksum</code> of produced M text. <br>4. Validate_M_Syntax: lightweight client-side syntax checks where available; for heavy validation or host-dependent parsing, schedule worker validation or preview execution in isolated host with redacted inputs. <br>5. EnsureQueryNameUnique: compute safe query name with normalization rules and conflict resolution policy; if renamed, emit audit with name mapping. <br>6. Persist_M_Artifact: create durable artifact (artifact JSON containing name, mText, params, mChecksum, templateVersion, manifest references) and persist via AtomicWrite; emit pq_export and pq_mchecksum audits. <br>7. Add_Query_From_M: call workbook.Queries.Add (or host API) from UI helper using the persisted artifact as source to ensure the in-memory query matches persisted artifact; optionally create a connection object and/or model connection according to injectionMode. <br>8. Post-inject tasks: optionally register query in PQ_Library index if template was saved there, collect diagnostics, update <code>pq_inject.completed</code> audit row with artifactChecksum and connection metadata. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Cross-cutting invariants & security rules (must/shall):</strong><br>1. Do not execute M queries against live external connectors during injection unless explicitly requested and permissioned by operator; injection should be syntactic and structural by default. <br>2. Never store credentials inside M artifacts or top-level audit rows. Credential references may be stored as secure handles or connection IDs. <br>3. For regulated templates, require manifest signature verification and owner approval before injection and record these validations in the audit row. <br>4. Respect workbook privacy: do not upload workbook contents or list of queries to remote telemetry without operator consent. <br>5. All persisted artifacts must include <code>correlationId</code>, <code>producerVersion</code>, and <code>producerFingerprint</code> for later forensic replay. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Add_Query_From_M(name, formula, injectionMode=&quot;inline&quot;, connectionOptions=null, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> inject a Power Query (M) formula into the active workbook in a deterministic, auditable, and reversible fashion. <code>injectionMode</code> controls whether the query is added as inline (worksheet query), connection-only, or model-backed. The function returns structured result <code>{success, queryName, queryId, connectionId?, artifactChecksum, mChecksum, attempts, diagnosticsRef}</code> and emits audit rows on attempt and completion. <br><strong>Parameters & constraints:</strong> <code>name</code> (string — may be null to request auto-name), <code>formula</code> (string — final M text produced by Parameterize_Template), <code>injectionMode</code> ∈ {inline, connectionOnly, modelConnection}, <code>connectionOptions</code> optional dict (e.g., {enableRefresh: bool, loadToModel: bool, credentialHandle: id}). <code>operatorId</code> optional for audit. The function must not perform long-running file IO on UI thread; if persistence or export is required, delegate to Persist_M_Artifact and use a background worker. <br><strong>Must/shall behaviors:</strong><br>1. Call EnsureQueryNameUnique(name) to compute final <code>queryName</code> and document name mapping in audit if mutated. <br>2. Compute <code>mChecksum</code> using canonical normalized bytes (UTF-8 normalized, strip CRLF differences, stable whitespace normalization rules) and emit pq_mchecksum.computed audit with paramsHash and inputHash. <br>3. Persist artifact via Persist_M_Artifact(artifactPayload) before calling workbook API unless caller explicitly requests ephemeral inject (rare, must be approved and audited). <br>4. Use host workbook API to Add Query, catch host-specific exceptions, map them to PQ error codes, and retry only for transient host errors using Retry wrapper with idempotent_assert=true. <br>5. On success, optionally create connection object per connectionOptions. <br>6. Emit pq_inject.completed audit with artifactChecksum, queryName, queryId, connection metadata, and mChecksum. <br><strong>Edge cases & error handling:</strong><br>1. Name collision: if final query name collides with an existing query that is user-modified, do not overwrite without explicit operator confirmation; use auto-suffix scheme <code>name (1)</code>, emit pq_inject.resolved_name audit and provide map in result. <br>2. Host API limitations: if workbook host prevents programmatic addition due to trust settings or macro policies, record user-facing error UTIL_PQ_HOST_POLICY_BLOCK and emit pq_inject.failure with remediation guidance. <br>3. Large formula (>configured limit): if formula exceeds safe buffer size for host API, persist artifact and call a helper (signed XLAM or worker) to split or write via supported host channels; emit pq_inject.degraded and include reason. <br>4. Partial failure after workbook change: if workbook query is added but post-processing (e.g., connection creation) fails, produce reversible plan and persist rollback artifact via Rollback_Query_Insert; emit pq_inject.partial_failure with beforeChecksum and afterChecksum. <br><strong>Observability & audits:</strong> pq_inject.attempt(correlationId, operatorId, templateId?, paramsHash, requestedName) pq_inject.completed(correlationId, operatorId, queryName, queryId, artifactChecksum, mChecksum, durationMs) pq_inject.failure(correlationId, operatorId, errorCode, diagnosticsRef). <br><strong>Examples & narratives:</strong><br>1. Admin injects <code>Sales_Cleansed</code> template with parameter region=EMEA into workbook; Add_Query_From_M computes safe name <code>Sales_Cleansed</code> (no collision), persists artifact, adds query inline, creates modelConnection as requested, and returns <code>{success:true, queryName:&quot;Sales_Cleansed&quot;, connectionId:&quot;conn-123&quot;, artifactChecksum:&quot;sha256:...&quot;}.</code> <br>2. User attempts to inject <code>Query1</code> but host macro policy blocks programmatic workbook modifications; function returns failure with guidance and a persisted artifact the operator can import manually. <br><strong>Tests & CI vectors:</strong> unit test for name collision resolution, simulated host API exceptions tests, golden mChecksum vectors for parameterization parity, integration tests verifying persisted artifact equals injected query content. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Parameterize_Template(templateText, params, paramSchema=null, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> apply a template's parameter map to canonical M template text to produce final M formula. Pure function when used with in-memory strings; emits audit pq_preview.start/complete when used in preview/injection flows. Returns <code>{mText, paramsValidated, paramsHash, paramizationLog}</code>. <br><strong>Behavior & steps:</strong><br>1. Load template parameter descriptors (type, default, allowedValues, secureFlag). <br>2. Validate <code>params</code> against <code>paramSchema</code>; coerce types where safe (e.g., numeric strings -> number), record coercions in paramizationLog. Reject mismatches with ErrorCode=PQ_PARAM_VALIDATE_FAIL and include field-level diagnostics. <br>3. For secure parameters (secureFlag=true), redact values in audit and store only parameterFingerprint in evidence store; the produced <code>mText</code> should contain placeholders referencing external secure handles rather than literal secrets. <br>4. Parameter substitution approaches supported: simple token substitution, M-aware substitution (inserting typed literal expressions), and function-parameter injection (wrapping template in let-block with parameter assignments). Choose M-aware substitution by default to preserve typing and quoting correctness. <br>5. Normalize line endings and canonical whitespace; compute <code>paramsHash</code> and <code>mChecksum</code> over normalized bytes. <br>6. Return final <code>mText</code> and diagnostics including any defaulted parameters and coercions. <br><strong>Tie-breakers & determinism:</strong> when templates include nondeterministic placeholders (e.g., <code>#RANDOM</code> for previews), Parameterize_Template must refuse such placeholders unless a DeterministicRNG seed is provided; when seed is provided, replace using DeterministicRNG to ensure reproducibility. <br><strong>Edge cases:</strong><br>1. Parameter-dependent template branches: templates that include conditional sections must be evaluated under a safe preview interpreter or validated syntactically to ensure substitution yields valid M. If safety cannot be proven syntactically, schedule worker-side preview execution with redacted external calls. <br>2. Large binary parameter values: refuse embedding and use external artifact references instead. <br><strong>Observability:</strong> pq_preview.start(correlationId, templateId, paramsHash), pq_preview.complete(correlationId, mChecksum, durationMs). <br><strong>Examples:</strong> substituting <code>dateFrom</code> and <code>dateTo</code> into a template using typed M expressions so that <code>#date(2023,1,1)</code> appears rather than a string literal. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Compute_mChecksum(mText, algorithm=&quot;sha256&quot;, normalizationRules=null)</code></strong><br><strong>Purpose & contract:</strong> compute deterministic checksum for a normalized M formula to enable artifact parity checks and audit linkage. Must be stable across supported hosts and languages. Returns <code>{mChecksum, normalizedBytes, hashAlgorithm, durationMs}</code>. <br><strong>Normalization rules (must/shall):</strong><br>1. Normalize line endings to LF (\\n). <br>2. Trim trailing whitespace on lines. <br>3. Collapse multiple consecutive blank lines to a single blank line unless template explicitly marks significant blank lines via canonical marker. <br>4. Preserve M token semantics; do not strip insignificant parentheses or alter token case in identifiers unless template metadata requires canonical casing. <br>5. UTF-8 encode with NFC normalization. <br>6. Optionally canonicalize comments: either preserve comments in normalized bytes for templates where comments are part of legal audit trail, or strip them if configured in template manifest. <br><strong>Edge behaviors:</strong> Crypto algorithm choices limited to supported set; default sha256. When algorithm changes, compute and persist migration manifest and ensure CI golden vectors are updated. <br><strong>Audits & observability:</strong> pq_mchecksum.computed(correlationId, templateId?, mChecksum, normalizedSize). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Persist_M_Artifact(artifactPayload, targetPath, atomicOptions={}, maxAttempts=3)</code></strong><br><strong>Purpose & contract:</strong> persist canonical JSON artifact describing the M query into durable storage using atomic primitives. Artifact contains metadata: name, mText, mChecksum, paramsHash, templateVersion, producerVersion, correlationId, timestamp. Return <code>{success, artifactPath, artifactChecksum, attempts, durationMs}</code>. <br><strong>Behavior & steps:</strong><br>1. Validate artifact schema. <br>2. Serialize artifact to canonical JSON with stable key order and UTF-8 NFC encoding. <br>3. Compute payload checksum (sha256). <br>4. Write using AtomicWrite with fsyncFile and fsyncParent semantics where available. <br>5. On transient errors use Retry wrapper; on ENOSPC or EPERM emit actionable audits and recovery suggestions. <br>6. Post-write verification: reopen and verify checksum equals computed payload checksum; on mismatch, attempt repair with AtomicWriteRepair or escalate. <br><strong>Cross-platform fallbacks:</strong> on host FS with weak rename semantics, record util.atomic_write.degraded audit and follow staged fallback (write artifact to local staging area and emit pq_export.degraded). <br><strong>Observability & audits:</strong> pq_export.attempt(correlationId, targetPath, payloadHash) pq_export.completed(correlationId, targetPath, artifactChecksum, durationMs). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Create_Connection(connectionName, connectionType, connectionOptions, credentialHandle=null, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> create a host connection object corresponding to an injected query with safe handling of credentials, refresh options, privacy levels, and optionally model mapping. Returns <code>{success, connectionId, artifactChecksum, diagnosticsRef}</code>. <br><strong>Parameters & constraints:</strong> <code>connectionType</code> ∈ {OLEDB, ODBC, Web, File, DataModel}; <code>connectionOptions</code> include loadBehavior (connectionOnly / loadToSheet / loadToModel), privacy settings, refreshPolicy, isHidden, enableBackgroundRefresh. <code>credentialHandle</code> is a secure reference. <br><strong>Behavior & steps:</strong><br>1. Validate that the host supports requested connectionType and options; if not supported, return PQ_CONN_UNSUPPORTED and provide remediation. <br>2. Create connection object via host APIs, pass credentialHandle rather than raw secrets. For model connections, ensure the semantic model is accessible and write mapping metadata into the artifact. <br>3. Persist connection metadata via Persist_M_Artifact or jobDescriptor store with correlationId to ensure reproducibility. <br>4. If creation fails after artifact persisted, record reversible plan and roll back if operator requests. <br><strong>Security & credential handling:</strong> do not log raw credentials; store only credentialHandle or masked fingerprint in audit rows. Credentials lifecycle must follow host credential manager APIs. <br><strong>Audits:</strong> pq_connection.created(correlationId, connectionId, connectionType, connectionOptionsFingerprint) pq_connection.failure(correlationId, errorCode, diagnosticsRef). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>EnsureQueryNameUnique(requestedName, workbookContext, conflictPolicy=&quot;auto-suffix&quot;)</code></strong><br><strong>Purpose & contract:</strong> compute safe canonical query name under workbook constraints and conflict policy. Return <code>{finalName, changed, originalName, collisionResolutionLog}</code>. <br><strong>Behavior & rules:</strong><br>1. Normalize requestedName using canonical rules: strip control characters, trim, collapse repeated whitespace, limit to host-supported length, strip unsupported characters depending on host. <br>2. If normalized name collides with workbook query or table names, apply <code>conflictPolicy</code>:<br>- <code>fail</code> -> return error PQ_NAME_COLLISION.<br>- <code>auto-suffix</code> -> append <code> (n)</code> deterministic suffix where n is smallest integer producing no collision; suffix calculation must be deterministic and stable across runs; use deterministic ordering from existing names list sorted case-insensitively. <br>- <code>overwrite</code> -> only allowed if operator explicitly authorized and existing query is unmodified or matches artifactChecksum; emit audit pq_inject.overwrite_authorized. <br>3. Document mapping in audit. <br><strong>Edge cases:</strong> workbook with case-insensitive names but case-preserving host; ensure detection uses host semantics. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Validate_M_Syntax(mText, validationMode=&quot;lightweight&quot;, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> provide host-aware, deterministic syntactic validation for M text. Modes:<br>- <code>lightweight</code>: static token-level validation without executing connectors.<br>- <code>host-parse</code>: call host parser where available (non-executing) to validate parse tree.<br>- <code>preview-exec</code>: run in sandboxed preview with redacted connectors (requires worker or trusted host). <br><strong>Behavior & safeguards:</strong><br>1. For lightweight mode, run tokenizer-based checks (balanced brackets, basic token validity, prohibited host-specific extensions). <br>2. For host-parse, call host parser API where available and capture parse tree and minor warnings. Host parse must not resolve external connectors. <br>3. For preview-exec, run M in isolated host with timeouts and resource caps; redact external credentials and substitute deterministic test connectors; record diagnostics and truncated results for preview. <br>4. On syntax errors, return structured diagnostics pointing to line/column and include suggested fixes where unambiguous. <br><strong>Audits & telemetry:</strong> pq_validation.start/complete with validationMode and diagnosticsRef. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Preview_M(templateId, params, sampleLimit=50, deterministicSeed=null, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> produce a safe, deterministic preview of a parameterized template suitable for operator review. Returns <code>{previewRows, previewSchema, sampleFingerprint, mChecksum, diagnosticsRef}</code>. <br><strong>Behavior & steps:</strong><br>1. Parameterize_Template to produce mText; compute mChecksum. <br>2. If deterministicSeed provided, use DeterministicRNG to select sample rows for any sampling operations inside the template; otherwise derive seed from correlationId to enable reproducibility. <br>3. Execute the parameterized M in a sandboxed preview runtime with connectors disabled or stubbed unless operator explicitly requests live connector preview; ensure execution timeouts and memory caps. <br>4. Redact PII in previewRows unless operator explicitly authorizes non-redacted preview and that action is auditable. <br>5. Return sample up to sampleLimit rows, previewSchema, and sampleFingerprint computed from DeterministicRNG state and preview data checksum. <br><strong>Edge behaviors & governance:</strong> live connector preview requires explicit operator consent and must be recorded with additional audits and possibly two-person approval if regulated data may be exposed. <br><strong>Audits:</strong> pq_preview.start/complete with sampleFingerprint and evidenceRef for full preview payload. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Get_Query_Diagnostics(queryNameOrId, correlationId=null)</code></strong><br><strong>Purpose & contract:</strong> collect diagnostics for a given query: last refresh time, last refresh duration, last error trace, provider chain, dependency graph, and mChecksum recorded at injection time. Returns diagnostics object and emits pq_diagnostics.collected audit. <br><strong>Behavior & steps:</strong><br>1. Query host runtime for refresh history and last error traces; normalize timestamps to UTC and redact sensitive paths. <br>2. Compute dependency graph by analyzing query expression and referencing host's query/link metadata. <br>3. If query formula differs from persisted artifact <code>mChecksum</code>, mark as <code>divergent</code> and include both checksums in diagnostics. <br>4. Provide actionable remediation hints (e.g., refresh provider credentials, re-inject missing referenced query). <br><strong>Audits:</strong> pq_diagnostics.collected(correlationId, queryId, mChecksum, divergentFlag). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Export_M_Artifact(queryNameOrId, destination, atomicExportOptions={}, includeDiagnostics=true)</code></strong><br><strong>Purpose & contract:</strong> export a persisted M artifact and associated diagnostics to a destination (local path, network share, artifact store). Uses atomic export policy to avoid partial writes. Returns <code>{success, destinationUri, artifactChecksum, attempts}</code>. <br><strong>Behavior & steps:</strong><br>1. Resolve artifact from persisted local artifacts store using queryId and artifact checksum. <br>2. Compose export payload including artifact JSON, optional diagnostics, export manifest with correlationId and timestamp. <br>3. Use Persist_M_Artifact / AtomicWrite to write to destination; on network paths, follow staged fallback semantics and emit pq_export.degraded if atomic rename cannot be guaranteed. <br>4. Emit pq_export.completed with artifact checksum and destinationUri. <br><strong>Edge cases & recovery:</strong> handle ENOSPC, permission errors, partial remote writes; persist forensic_manifest and emit pq_export.failure with remediation runbook. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Rollback_Query_Insert(queryName, queryId, artifactPath, operatorId=null)</code></strong><br><strong>Purpose & contract:</strong> safely revert a previously applied injection when operator requests rollback or when partial-failure requires revert. Return <code>{success, reverted, reason, durationMs, diagnosticsRef}</code>. <br><strong>Behavior & steps:</strong><br>1. Validate that artifactPath or persisted rollback plan exists. <br>2. If original query existed before injection, restore previous formula and metadata from persisted beforeChecksum snapshot. <br>3. If injection created new objects, remove them in a reversible manner and persist rollback artifact via AtomicWrite. <br>4. Emit pq_query.removed or pq_query.updated audit rows with beforeChecksum and afterChecksum. <br><strong>Safeguards:</strong> require operator confirmation for destructive rollback; for regulated workflows, enforce two-person approval on rollbacks affecting regulated datasets. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong><code>Inspect_Queries(workbookContext, filter=null)</code></strong><br><strong>Purpose & contract:</strong> enumerate query metadata in workbook context, compute per-query fingerprints, and reconcile with persisted artifacts. Return list <code>[ {queryName, queryId, mChecksum, artifactMatch, lastModified, modifiedBy} ... ]</code>. <br><strong>Behavior & steps:</strong><br>1. Pull host query list and map to persisted artifact indexes by name and mChecksum. <br>2. Detect divergences (query formula different from artifact mChecksum) and mark <code>artifactMatch=false</code> with diagnostics. <br>3. Provide summary metrics: count_injected, count_divergent, count_unpersisted. <br>4. Emit pq_library.access or pq_inspect.completed audit. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Observability, Telemetry & Error Catalog (concepts & mapping)</strong><br><strong>Audit schema for PQ_Injector:</strong> timestamp, correlationId, operatorId (optional), module=PQ_Injector, procedure, paramsHash, mChecksum (optional), artifactChecksum (optional), resultStatus, evidenceRef (optional), durationMs, hostPlatformVersion, hostPolicyFlags. Evidence storage encrypted and access-controlled. <br><strong>Representative ErrorCodes:</strong> PQ_INJECT_BLOCKED_BY_POLICY, PQ_NAME_COLLISION, PQ_PARAM_VALIDATE_FAIL, PQ_HOST_API_ERROR, PQ_CONN_UNSUPPORTED, PQ_EXPORT_ENOSPC, PQ_MCHECKSUM_MISMATCH, PQ_PREVIEW_FORBIDDEN, PQ_EXPORT_DEGRADED, PQ_INVALID_CREDENTIAL_HANDLE. Each error code maps to operator remediation suggestions via SafeErrorToUser mapping. <br><strong>Key metrics (local buffered):</strong> pq_inject.latency_ms, pq_inject.success_rate, pq_preview.latency_ms, pq_export.latency_ms, pq_mchecksum.count, pq_diagnostics.collection_count. Metrics are locally buffered and uploaded by CORE_Telemetry in audited batches. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-platform golden governance</strong><br><strong>Unit tests (must include):</strong><br>1. Parameterize_Template unit vectors for various types (strings, numbers, dates, lists, records) ensuring typed M insertion and escaping correctness. <br>2. Compute_mChecksum goldens: same M with different line ending and comment variants produce expected normalized checksum. <br>3. Add_Query_From_M host API mock tests covering success, transient host exceptions (retry), hard failures (policy blocks), and partial-failure recovery. <br>4. EnsureQueryNameUnique tests with case-insensitive vs case-preserving host semantics. <br><strong>Integration tests:</strong><br>1. End-to-end inject: parameterize -> persist artifact -> host add query -> create connection -> export artifact -> diagnostics verify artifact parity. <br>2. Preview sandbox tests with deterministic seeding (DeterministicRNG) to reproduce preview rows; verify serialization of RNG state. <br>3. Export degraded path tests on simulated SMB/NFS filesystem with weak rename semantics. <br><strong>Property tests:</strong><br>1. Idempotency property for Add_Query_From_M under retries; ensure no duplicate queries created when retries occur. <br>2. Parameterization property: Parameterize_Template(paramsA) + Parameterize_Template(paramsB) where paramsA==paramsB must produce identical mChecksum. <br><strong>CI golden gating:</strong> golden vectors for mChecksum and parameterization parity across supported host platforms and languages (VBA/COM helper, .NET add-in, Python worker). Static analyzer to flag direct workbook writes in OnLoad. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always persist artifact via Persist_M_Artifact before final Add_Query_From_M unless operator explicitly requests ephemeral injection and the action is recorded with explicit audit. <br>2. Always compute and record mChecksum and paramsHash for every injection action. <br>3. Use EnsureQueryNameUnique to normalize and avoid accidental overwrites. <br>4. For regulated templates, require manifest signature verification prior to injection. <br>5. When performing preview or sampling, seed DeterministicRNG from correlationId for reproducibility and persist RNG state for forensic replay. <br><strong>Forbidden practices:</strong><br>1. Do not embed clear-text credentials into M templates or persisted artifacts. <br>2. Do not perform long-running writes or network exports on UI thread. <br>3. Do not bypass audit emission for injection or export flows. <br>4. Do not assume host rename semantics on network filesystems—use atomic write fallbacks provided by CORE_Utilities. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operational runbooks & incident playbooks (executable steps)</strong><br><strong>Injection blocked by host policy (operator cannot programmatically add query):</strong><br>1. pq_inject.failure with PQ_INJECT_BLOCKED_BY_POLICY emitted containing policyFlags and hostPolicyName. <br>2. Persist artifact via Persist_M_Artifact to a user-visible staging area and emit pq_export.completed with staging URI. <br>3. Provide operator with manual import steps and attach artifactChecksum for verification. <br>4. Log host diagnostic info and open ticket if automatic injection essential. <br><strong>mChecksum mismatch detected after injection (divergent query):</strong><br>1. Inspect pq_mchecksum and pq_inject audits; fetch persisted artifact. <br>2. Use Inspect_Queries to compute divergence details. <br>3. If divergence is unintended, run Rollback_Query_Insert using persisted beforeSnapshot and re-inject artifact; record all steps in audit. <br><strong>Export ENOSPC runbook:</strong><br>1. Collect pq_export.failure with details; check filesystem free space. <br>2. Use atomic export staging option to write to local volume on same mount; recompute artifactChecksum and compare. <br>3. If needed, escalate to infra with forensic_manifest and audit_tail rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — how PQ_Injector principles map to templates and runtimes</strong><br><strong>Context:</strong> M is declarative and host-dependent. PQ_Injector cannot and should not attempt to control all runtime behaviors; instead it orchestrates injection, validation, artifact persistence, and host connection creation to produce auditable and reproducible artifacts. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Parameterize using typed M expressions:</strong> always insert parameters as typed M expressions (e.g., <code>#date(...)</code>, <code>#duration(...)</code>) rather than interpolated strings to avoid locale and parsing differences. <br>2. <strong>Preview via sandboxed execution:</strong> do not run template previews against live production connectors without explicit consent. Use deterministic seeds and persist RNG state for reproducible previews. <br>3. <strong>Persist authoritative artifact:</strong> for any template used in production or shared, persist canonical artifact and use <code>mChecksum</code> as the single source of truth for audits and rollbacks. <br>4. <strong>Avoid embedding secrets:</strong> use credential handles or connection references passed in via connectionOptions rather than literal secrets in M text. <br>5. <strong>Model-backed loads:</strong> for reports requiring semantic model integration, prefer Create_Connection_Model with explicit mapping metadata persisted alongside artifact. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — interactions between PQ_Injector and semantic models</strong><br><strong>Context:</strong> DAX is read-time and cannot perform side-effects. PQ_Injector must therefore perform deterministic allocations and rounding in ETL and persist results consumable by DAX. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Push calculated columns requiring authoritative rounding to ETL:</strong> use SafeRound and SafeRoundResiduals during M processing or worker-side transforms and persist integer cents when necessary so DAX measures only aggregate. <br>2. <strong>Persist RunMetadata table:</strong> PQ_Injector must optionally write a RunMetadata artifact (correlationId, artifactChecksum, mChecksum, templateVersion, runTs) into the data model to allow DAX and reports to surface provenance. <br>3. <strong>Deterministic sampling for model-level testing:</strong> compute deterministic sample keys in ETL (e.g., hash of primary key + correlationSalt) and persist seed metadata for replay. <br>4. <strong>Model checksums & reconciliation:</strong> after injection and ETL, PQ_Injector should produce a reconciliation artifact (datasetChecksum) that DAX measures can compare to detect drift; DAX measures surface dataset health but do not perform reconciliation. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Forensic artifacts, evidence paths & recommended retention (concise):</strong><br><strong>Minimum artifacts to retain per injection:</strong> artifact JSON with <code>mText</code>, <code>mChecksum</code>, <code>paramsHash</code>, templateVersion, persisted into evidence store; serialized RNG state for previews and sampling; audit rows (<code>pq_inject.*</code>, <code>pq_preview.*</code>, <code>pq_export.*</code>); host diagnostics and query diagnostics; rollback plans when created. <br><strong>Retention policy:</strong> hot evidence store 30 days, warm archive 7 years for regulated datasets, cold per regulation. Evidence refs in audits must point to encrypted artifacts; PII must never appear in top-level audit rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (detailed):</strong><br>1. Owners recorded in OWNERS.md; approvers designated for template governance. <br>2. Public API documented; backward-compatible versioning. <br>3. Golden vectors for mChecksum and Parameterize_Template parity across host implementations. <br>4. AtomicWrite integration tests and degraded-path tests for network filesystems. <br>5. Static checks preventing UI-thread blocking writes. <br>6. Audit hook coverage validated by test harness emitting expected audit rows. <br>7. Release manifest signed and PQ_Injector artifacts included in modAudit rotation. <br><strong>Blocking conditions:</strong> missing audit emissions on inject/export flows, golden vector failures, or forbidden-API static check failures. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Test plan highlights & representative tests (explicit)</strong><br><strong>Unit tests:</strong><br>1. Parameterization: vector tests for typed insertion, escaping, defaulting, and secure parameter handling. <br>2. mChecksum: parity tests for varying whitespace and comment policies. <br>3. Name resolution: collision resolution under case-insensitive and case-preserving hosts. <br>4. Host API error mapping and Retry correctness. <br><strong>Integration tests:</strong><br>1. End-to-end inject -> persist -> host add -> create connection -> export -> diagnostics verification. <br>2. Preview reproducibility using DeterministicRNG and persisted RNG state. <br><strong>Property tests:</strong><br>1. Idempotency of Add_Query_From_M under repeated identical requests. <br>2. Parameterization mapping stability across template versions where compatible. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & examples (prescriptive):</strong><br>1. <code>pq inject --template &lt;id&gt; --params &#x27;{&quot;dateFrom&quot;:&quot;2025-01-01&quot;}&#x27; --mode connectionOnly --correlation r-YYYYMMDD-xxx</code> — persist artifact, create connection only, emit pq_inject.completed with artifactChecksum. <br>2. <code>pq preview --template &lt;id&gt; --params ... --sample 50 --seed &lt;seed&gt;</code> — create deterministic preview and store RNG state. <br>3. <code>pq export --query &lt;name&gt; --dest \\share\exports\</code> — atomic export; on ENOSPC follow staging fallback. <br>4. <code>pq rollback --query &lt;name&gt; --correlation &lt;id&gt;</code> — revert an injection using persisted snapshot (requires operator confirmation). </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded)</strong><br><strong>Failure mode: host policy blocks injection</strong><br>1. Cause: macro or trust settings prevent programmatic modifications. <br>2. Mitigation: persist artifact and provide operator manual import steps; request infra to sign XLAM or update host policy when enterprise-managed. <br><strong>Failure mode: injected query diverges from persisted artifact</strong><br>1. Cause: operator edited query manually after injection or host add path mutated formula. <br>2. Mitigation: Inspect_Queries to detect divergence; if unintended, Rollback_Query_Insert and re-inject persisted artifact; update user guidance to avoid manual edits on injected artifacts. <br><strong>Failure mode: mChecksum mismatch between persisted artifact and injected formula</strong><br>1. Cause: normalization differences or host API modified whitespace/comments. <br>2. Mitigation: ensure Compute_mChecksum uses host-compatible normalization rules; preserve comments where important; update golden vectors. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Governance checklists & PR requirements (explicit)</strong><br>1. PR must include unit tests for new behavior, golden vectors for mChecksum changes, and audit emission validation. <br>2. Changes to parameterization semantics or mChecksum normalization require owner approval and migration manifest. <br>3. Any change to persistence semantics or AtomicWrite usage must include cross-platform tests and SRE sign-off. <br>4. Release manifest update required for production changes affecting injection semantics or regulated templates. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Extremely detailed narratives & examples (selected)</strong><br><strong>Scenario 1 — Operator injects regulated template requiring high numeric fidelity:</strong><br>1. Operator selects <code>Revenue_Schedule</code> template, marked <code>requiresHighPrecision=true</code>. PQ_Ribbon composes request with correlationId r-20260117-abc and chosen parameters; PQ_Injector emits pq_preview.start and computes deterministic preview using seeded DeterministicRNG. <br>2. Parameterize_Template applies parameters as typed M expressions and computes mChecksum. Because template requires high precision, PQ_Injector schedules worker-side SafeRound aggregation to produce authoritative numeric columns and persists the resulting artifact via Persist_M_Artifact. <br>3. Add_Query_From_M is invoked to add query into workbook; because persistence already happened, the injected in-memory formula is guaranteed to match persisted artifact. PQ_Injector creates model connection mapping columns as integer cents where required; pq_inject.completed includes artifactChecksum and model mapping metadata. <br>4. Forensic replay: evidenceRef points to persisted RNG state and artifact JSON enabling exact reproduction of the injected query and numeric transforms. <br><strong>Scenario 2 — Template injection in a locked-down tenant where programmatic injection is blocked:</strong><br>1. PQ_Injector attempts Add_Query_From_M but host returns macro-policy error. PQ_Injector persists artifact to staging path and emits pq_inject.failure with PQ_INJECT_BLOCKED_BY_POLICY. <br>2. Operator is shown step-by-step manual import instructions with artifact checksum to verify integrity. Admin later updates host trust policy and automation proceeds; audit chain links the staging artifact and final injection. <br><strong>Scenario 3 — Deterministic preview for sampling-sensitive template:</strong><br>1. Template includes a sample function with seed parameter. Operator runs preview with correlationId r-...; PQ_Injector seeds DeterministicRNG using correlationId and <code>preview-v1</code> salt and records serialized RNG state in evidence store. <br>2. Preview rows are produced and stored; operator reviews and accepts injection. Later complaint about nondeterministic preview is resolved by replaying preview using the serialized RNG state and producing identical sample rows. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded)</strong><br><strong>Minimum forensic artifacts per injection:</strong><br>1. persisted artifact JSON with <code>mText</code>, <code>mChecksum</code>, <code>paramsHash</code>, <code>templateVersion</code>, <code>producerVersion</code>, <code>correlationId</code>. <br>2. audit_tail rows for correlationId. <br>3. serialized RNG state for preview runs. <br>4. host diagnostics & query diagnostics (last refresh history). <br>5. rollback plans if created. <br><strong>Evidence storage & access:</strong> hot evidence store for 30 days; warm archive 7 years for regulated artifacts; evidenceRef in audits must be an encrypted pointer with ACLs. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive):</strong><br><strong>Fields required for PQ_Injector audits:</strong> timestamp, correlationId, module=PQ_Injector, procedure, operatorId (optional), paramsHash, mChecksum (optional), artifactChecksum (optional), evidenceRef (optional), hostPlatformVersion, metadata object with durationMs, attempts, queryId, connectionId. <br><strong>Policy note:</strong> do not include raw PII or credentials in top-level audit rows; store sanitized parameters in evidence store. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded)</strong><br><strong>Failure: partial injection due to host crash</strong><br>1. Cause: host crash after query persisted but before connection created. <br>2. Mitigation: detect via pq_inject.partial_failure, persist rollback plan and allow operator to resume insertion; worker reconciles persisted artifact and host state on next run. <br><strong>Failure: parameter coercion differences across platforms</strong><br>1. Cause: different language runtime coercion (e.g., decimal vs double) producing different serialized M expressions. <br>2. Mitigation: Parameterize_Template must use explicit typed M expressions and cross-platform golden tests; flag templates with potential platform-sensitive coercion. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Appendix C — PQ & DAX short checklists for template authors and report builders</strong><br><strong>PQ Template author checklist:</strong><br>1. Provide parameter schema with types and default values. <br>2. Mark templates requiring high numeric fidelity as <code>requiresHighPrecision</code>. <br>3. Avoid embedding secrets; use secure parameter handles. <br>4. Include <code>mChecksum</code> and manifest with signature for regulated templates. <br><strong>DAX/report builder checklist:</strong><br>1. Consume RunMetadata table for provenance and artifactChecksum. <br>2. Avoid performing allocations or residual rounding in DAX; perform in ETL and persist final integers. <br>3. Use persisted hash keys for deterministic sampling if necessary. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Final mandatory constraints (firm):</strong><br>1. Always persist authoritative artifacts for injected queries that will be consumed by other processes. <br>2. Always compute and record mChecksum and paramsHash and link them in audits. <br>3. Do not embed credentials in persisted artifacts; use secure handles. <br>4. For regulated or PII-touching workflows, enforce two-person approval for automatic injections that modify production models. <br>5. All injections and exports must emit audit rows and include evidenceRef when full payloads are necessary for forensics. </td></tr><tr><td data-label="PQ_Injector — Per-function Expert Technical Breakdown"> <strong>Checked:</strong> Ten-pass internal review for internal consistency, audit coverage, deterministic chain from operator action -> parameterization -> mChecksum -> persisted artifact -> workbook injection -> connection creation -> export, and cross-mapping to PQ preview and DAX model patterns. </td></tr></tbody></table></div><div class="row-count">Rows: 35</div></div><div class="table-caption" id="Table2" data-table="Docu_0180_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by PQ_Diagnostics — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">PQ_Diagnostics — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_PQ_DIAGNOSTICS (primary, secondary, and on-call rotation recorded in OWNERS.md and release manifests).<br><strong>Public API (surface):</strong> <code>CollectQueryDiagnostics</code>, <code>CaptureRefreshTrace</code>, <code>CollectQueryPlan</code>, <code>CaptureProviderDiagnostics</code>, <code>CaptureConnectionFingerprint</code>, <code>ParseErrorTrace</code>, <code>AggregateRefreshPath</code>, <code>BuildDiagnosticReport</code>, <code>ExportDiagnostics</code>, <code>ReplayDiagnostics</code>, <code>CorrelateWithAudit</code>, <code>HealthCheck</code>, <code>SampleDiagnostics</code>, <code>PruneDiagnosticsRetention</code>, <code>InspectTempArtifacts</code>, <code>ScheduleDiagnosticsCapture</code>, <code>GetDiagnosticSummaries</code>, <code>ListEvidenceRefs</code>, <code>FetchEvidenceBundle</code>, <code>ResolvePlanHash</code>, <code>CompareReplayArtifacts</code>, <code>SignDiagnosticManifest</code>.<br><strong>Audits emitted:</strong> <code>pq_diagnostics.requested</code>, <code>pq_diagnostics.started</code>, <code>pq_diagnostics.step:&lt;stepName&gt;</code>, <code>pq_diagnostics.complete</code>, <code>pq_diagnostics.failure</code>, <code>pq_diagnostics.export.attempt</code>, <code>pq_diagnostics.export.completed</code>, <code>pq_diagnostics.replay.started</code>, <code>pq_diagnostics.replay.completed</code>, <code>pq_diagnostics.prune.completed</code>, <code>pq_diagnostics.health.ok</code>, <code>pq_diagnostics.health.failed</code>. Every audit row includes <code>correlationId</code>, <code>module=PQ_Diagnostics</code>, <code>procedure</code>, <code>paramsHash</code>, and <code>resultHash</code> when applicable; large payloads are referenced by <code>evidenceRef</code> and never embedded directly in audit rows.<br><strong>Purpose and intended use:</strong> provide deterministic, auditable, minimal-invasive diagnostics and replayable captures for Power Query (M) templates, preview flows, refresh runs, provider interactions, and injected queries. Serve support engineers, SRE, template authors, compliance teams, and incident responders by producing reproducible artifacts (plans, traces, provider diagnostics, sample data, error fingerprints), reductionist summaries for rapid triage, and signed manifests for regulatory evidence. The module is intentionally read-only in default flows; any action that would mutate workbook state requires explicit audited operator confirmation and a separate remediation flow.<br><strong>Non-goals / constraints:</strong> do not persist raw credentials or secrets in audit rows, do not attempt remediation within collect functions, do not perform provider-side debugging without recorded operator consent, do not depend on external telemetry during UI-thread operations, and avoid platform-specific behaviors in canonical artifacts (plan canonicalization compensates for host differences). </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operational guarantees (invariants & SLOs):</strong><br>1. Deterministic reproduction: given a diagnostics evidence bundle and serialized deterministic RNG (where used), replays produce byte-for-byte equivalent artifacts where external provider responses were captured or stubbed. <br>2. Audit-anchored persistence: every persisted diagnostic artifact is referenced by at least one audit row containing <code>correlationId</code> and <code>artifactChecksum</code>. <br>3. Non-invasiveness: diagnostics collections are read-only and have no side-effects on workbook queries or cells; only explicit remediation flows may apply changes and must emit their own audits. <br>4. UI-safety: heavy captures (full plan, full trace, large sample exports) are scheduled to worker processes; UI-base calls execute lightweight sampling and metadata collection. <br>5. PII minimization and redaction: top-level audits include parameter hashes only; full diagnostic payloads are sanitized, encrypted at rest, and accessible only via controlled evidenceRef with access policies. <br>6. Atomic durability: persisted evidence and manifests use <code>AtomicWrite</code> semantics to prevent partial artifacts; in environments without atomic guarantees a staged manifest approach is used and <code>pq_diagnostics.export.degraded</code> is emitted. <br>7. Observability: all long-running steps emit start/complete audits and include duration metrics; local metric buffers exist for bulk uplink by CORE_Telemetry. <br><strong>Performance SLOs:</strong> median light-mode <code>CollectQueryDiagnostics</code> < 250ms; worker-mode full capture median < 8s (plus provider latency); replay default runtime target < 10 minutes; evidence export median < 500ms for local SSD, subject to target characteristics. <br><strong>CI / acceptance gates:</strong> deterministic sampling golden vectors, plan canonicalization parity tests across supported hosts, redaction enforcement tests, evidence encryption verification, atomic persistence tests, static analyzer checks preventing direct logging of credentials. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CollectQueryDiagnostics(connectionId, queryId, includePlan=false, includeTrace=false, samplePercent=100, rng=null, timeoutMs=30000, mode=&quot;auto&quot;, retentionTag=&quot;hot&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> gather a curated diagnostics package for a query execution context suitable for support triage, forensic replay, and performance profiling. Must not mutate query state. Returns <code>{success, packageId, packageMeta, evidenceRef?}</code> where <code>evidenceRef</code> points to encrypted evidence bundle when payloads exceed audit size thresholds. <br><strong>Detailed parameters & semantics:</strong><br>1. <code>connectionId</code> — stable id referencing persisted connection metadata; used to compute <code>connectionFingerprint</code>. <br>2. <code>queryId</code> — canonical query identifier (workbook query name or job descriptor id); if not found return <code>PQ_DIAG_QUERY_NOT_FOUND</code>. <br>3. <code>includePlan</code> — request provider explain/plan export; may be <code>false</code> for providers that deny plan access. <br>4. <code>includeTrace</code> — request event-level mashup+provider trace; worker-mode capture recommended. <br>5. <code>samplePercent</code> — 0–100 int; when <100, deterministic sampling performed. <br>6. <code>rng</code> — optional <code>DeterministicRNG</code> instance; if omitted and deterministic behavior required, derive seed from <code>correlationId|queryId</code>. <br>7. <code>timeoutMs</code> — overall capture timeout; partial captures are returned if timeout reached. <br>8. <code>mode</code> — <code>&quot;ui&quot;|&quot;worker&quot;|&quot;auto&quot;</code>; <code>auto</code> escalates to worker when heavy captures requested and UI thread is unsuitable. <br>9. <code>retentionTag</code> — evidence retention classification (hot/warm/cold) controlling storage lifecycle. <br><strong>Preconditions & validations:</strong> verify <code>connectionId</code> exists and that the calling context has permission to collect (operatorId matches or delegated support role). For <code>includePlan</code>/<code>includeTrace</code> from UI <code>mode=&quot;auto&quot;</code> attempts to schedule worker capture; if scheduling unavailable return <code>UI_THREAD_FORBIDDEN</code>. Emit initial audit <code>pq_diagnostics.started</code> containing <code>paramsHash</code> to anchor the action. <br><strong>Collection pipeline (high-level):</strong><br>1. Resolve and canonicalize query descriptor: <code>{name, mChecksum, templateVersion, parameterHash, lastPreviewTs}</code>. <br>2. Build capture context: hostFlavor, PQEngineVersion, correlationId, operatorId (if present), jobDescriptor ref. <br>3. Determine sampling seed: use provided <code>rng.serialize()</code> or derive <code>DeterministicRNG(seed_source=correlationId|queryId|packageSalt)</code>; record <code>seedFingerprint</code>. <br>4. Collect light metadata immediately: timings for last preview/refresh, provider name, connectionFingerprint via <code>CaptureConnectionFingerprint</code>, memory/CPU host snapshot. <br>5. If <code>samplePercent</code> < 100 perform <code>SampleDiagnostics</code> deterministically selecting rows/pages/events. <br>6. If <code>includePlan</code> request <code>CollectQueryPlan</code> in worker mode if required; attach <code>planHash</code> or <code>planAvailable=false</code>. <br>7. If <code>includeTrace</code> request <code>CaptureRefreshTrace</code>, stream to evidence store chunked and compressed. <br>8. Parse any immediate errors via <code>ParseErrorTrace</code> and compute <code>errorFingerprints</code>. <br>9. Build <code>packageMeta</code> including artifact list, checksums, summary metrics, critical path hints, and reproduction steps; persist manifest via <code>AtomicWrite</code>. <br>10. Emit <code>pq_diagnostics.complete</code> with <code>packageId</code> and <code>artifactChecksum</code>. <br><strong>Output packageMeta schema (canonical):</strong> <code>{packageId, connectionFingerprint, mChecksum, planHash?, traceId?, sampleSeedFingerprint, artifacts:[{type, evidenceRef, checksum, sizeBytes, retentionTag}], summary:{timings:{totalMs, criticalPathMs}, providerErrors:[{code, count, sampleErrorFingerprint}], samplePreview:[rows], reproduction:{seed, correlationId, commands}}}</code>. <br><strong>Edge cases & failure modes:</strong><br>1. Unknown <code>queryId</code> -> <code>PQ_DIAG_QUERY_NOT_FOUND</code> audit and error result. <br>2. Provider denies <code>EXPLAIN</code> -> <code>planAvailable=false</code> with <code>providerReason</code> included. <br>3. Capture truncated by <code>maxEvents</code> or <code>timeout</code> -> <code>partial=true</code> with <code>partialReason</code>. <br>4. Evidence store quota exceeded -> emit <code>pq_diagnostics.step:evidence_store.ENOSPC</code> and persist partial metadata. <br><strong>Audits generated:</strong> <code>pq_diagnostics.started(correlationId, paramsHash)</code> <code>pq_diagnostics.step:sample_selected(correlationId, sampleSeedFingerprint)</code> <code>pq_diagnostics.step:plan_collected(correlationId, planHash|planAvailable=false)</code> <code>pq_diagnostics.step:trace_captured(correlationId, traceId, eventsCount, evidenceRef)</code> <code>pq_diagnostics.complete(correlationId, packageId, artifactChecksum, durationMs)</code>. <br><strong>Examples & narratives:</strong><br>1. Quick triage: support calls <code>CollectQueryDiagnostics(connSales, qOrdersPreview, includePlan=false, includeTrace=false, samplePercent=10)</code> which returns small deterministic sample and timing summary enabling immediate reproduction on a developer workstation. <br>2. Forensic path: after a nightly refresh failure, <code>CollectQueryDiagnostics(... includePlan=true, includeTrace=true, mode=&quot;worker&quot;)</code> creates a full evidence bundle; SRE runs <code>ReplayDiagnostics</code> in sandbox using captured provider responses and serialized RNG to prove root cause. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureRefreshTrace(connectionId, runId, startTs=null, endTs=null, eventFilter=null, maxEvents=100000, streamToEvidence=true, compress=true, redactPatterns=[...])</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> ingest and persist a time-ordered stream of mashup engine and provider events for a single refresh run. The trace artifact is intended to support fine-grained performance analysis, failure reconstruction, and retry behavior analysis. <br><strong>Event taxonomy:</strong> captured events include <code>ProviderCallStart</code>, <code>ProviderCallEnd</code>, <code>ProviderResponse</code>, <code>CacheLookup</code>, <code>CacheHit</code>, <code>MashupStepStart</code>, <code>MashupStepEnd</code>, <code>RowPage</code>, <code>DataBuffer</code>, <code>ErrorEvent</code>, <code>RetryAttempt</code>, <code>NetworkTimeout</code>, <code>GCEvent</code>, <code>ResourceThrottle</code>. Each event stored includes <code>timestamp</code> (UTC ISO8601 ms), <code>sequenceNumber</code> (monotonic), <code>nodeId</code> (queryId/stepId), <code>eventType</code>, <code>durationMs</code> (when applicable), and <code>payloadFingerprint</code>. <br><strong>Capture semantics:</strong><br>1. Subscribe to engine event bus or provider diagnostics hooks; if direct subscription impossible, reconstruct events using available logs and provider call records. <br>2. Apply <code>eventFilter</code> (allowlist or blocklist) to keep trace focused. <br>3. Enforce <code>maxEvents</code> to bound size; when truncated produce <code>traceSummary</code> and <code>partial=true</code> with <code>droppedEventCount</code>. <br>4. Redact sensitive payload fields per <code>redactPatterns</code> and established redaction policy before any persistence. Redaction replaces values with deterministic fingerprints (e.g., <code>sha256(value)</code> masked) stored in evidence manifest. <br>5. Stream to evidence store chunked; if <code>compress=true</code> apply streaming compression (GZIP/DEFLATE) with chunk manifest containing chunk checksums for piecewise verification. <br>6. Compute derived aggregates on ingest: event counts by type, average latencies, retry histograms, top slow nodes, concurrency peaks. Include <code>criticalSegment</code> summary listing the top N slow nodes by exclusive/inclusive time. <br><strong>Trace summary fields:</strong> <code>traceId</code>, <code>eventsCaptured</code>, <code>durationMs</code>, <code>errorCount</code>, <code>retryCount</code>, <code>avgProviderLatencyMs</code>, <code>criticalSegment</code> (array), <code>droppedEventCount</code>, <code>evidenceRef</code> (if persisted). <br><strong>Edge conditions & provider behavior:</strong><br>1. Provider streaming responses (very high volume) -> capture first N pages and compute aggregate statistics; advise operator to increase <code>maxEvents</code> or use stratified sampling for deep analysis. <br>2. Provider denies capture hooks -> record <code>PROVIDER_TRACE_DENIED</code> and include provider capabilities metadata. <br><strong>Audit events:</strong> <code>pq_diagnostics.step:trace_captured(correlationId, traceId, eventsCaptured, evidenceRef)</code>. <br><strong>Narratives & examples:</strong><br>1. A trace reveals a repeating pattern where a provider returns 429 Too Many Requests followed by a series of retries that overlap with a heavy join step in the mashup engine; the <code>criticalSegment</code> points to the join as the concurrency bottleneck and the trace shows the exact timestamps of each retry enabling precise throttling diagnosis. <br>2. Compression and chunking allow the team to store a 1.5GB raw trace as 12 compressed chunks with manifest checksums and to replay only the relevant chunks for a focused investigation. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CollectQueryPlan(queryText, parameters, provider, timeoutMs=15000, requireCanonical=true, fallbackInstrumentation=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> obtain an execution plan from the provider or reconstruct a canonical plan representing the operator ordering and cost hints. Output must be canonicalized for checksumming and cross-host parity. <br><strong>Plan acquisition strategies:</strong><br>1. Provider-native <code>EXPLAIN</code>/<code>PLAN</code> call for SQL-like providers. <br>2. Provider-specific plan APIs (some NoSQL or connector providers supply explain endpoints). <br>3. If provider lacks plan APIs and <code>fallbackInstrumentation=true</code>, run an instrumented execution in worker-mode capturing step operator sequence and cost estimates; produce heuristic plan. <br><strong>Canonicalization rules:</strong><br>1. Remove ephemeral data: object ids, timestamps, node handles, memory addresses. <br>2. Normalize numeric cost estimates to ranges to avoid instability across runs (e.g., cost ~ [100-120]). <br>3. Sort commutative children in deterministic order (by hash of subtree canonicalization). <br>4. Remove or normalize host-specific dialect differences in operator names via a provider mapping layer. <br>5. Output canonical plan with stable whitespace and param ordering to enable deterministic checksumming. <br><strong>Plan artifact:</strong> <code>canonicalPlanText</code>, <code>planHash</code> = SHA256(canonicalPlanText), <code>planSummary</code> = {operatorCounts, estimatedCardinalities, topOperators}. <br><strong>Provider capability mapping:</strong> maintain <code>providerCapabilities</code> directory that lists whether a provider supports plan export, plan level detail, and any special handling required. <br><strong>Failure modes & fallbacks:</strong> if plan export is refused, return <code>planAvailable=false</code> and <code>fallbackInstrumentation</code> output when permitted. If instrumentation prohibited by provider policy or operator setting, produce <code>planUnavailableReason</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:plan_collected(correlationId, provider, planHash, planAvailable)</code>. <br><strong>Narrative example:</strong> a pre-release test identifies that the MPP provider returns different plan representations across versions; canonicalization collapses these differences into the same <code>planHash</code> for golden comparison and triggers a compatibility check in CI. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureProviderDiagnostics(providerHandle, requestContext, headersFingerprint=true, redactPatterns=[...], bodyPreviewKb=128, captureTlsInfo=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> capture provider-level diagnostics (request/response metadata, status, headers fingerprint, truncated body preview, TLS handshake details) while ensuring no sensitive headers or secrets are persisted. <br><strong>Data collected:</strong> method, endpointFingerprint (hash of scheme+host+port), providerVersion, TLS cipher suite (if allowed), responseStatus, responseLatencyMs, <code>headersFingerprint</code> (hash of header names/structure), <code>bodyPreview</code> truncated and redacted up to <code>bodyPreviewKb</code>, response body hash, and <code>requestFingerprint</code> for correlation. <br><strong>Redaction rules & enforcement:</strong> automatically redact fields matching <code>Authorization</code>, <code>Cookie</code>, <code>Set-Cookie</code>, <code>Authentication</code>, and configured <code>redactPatterns</code>; replace with deterministic fingerprints (e.g., <code>REDACTED_SHA256:&lt;hash&gt;</code>). Log a <code>redactionSummary</code> in the artifact meta listing redacted fields and counts. <br><strong>Constraints & policies:</strong> do not invoke provider debug endpoints or request server-side logs without explicit operator consent and recorded audit approval. Respect provider rate limits and terms of service. <br><strong>Audit:</strong> <code>pq_diagnostics.step:provider_diagnostics(correlationId, providerFingerprint, responseStatus, evidenceRef?)</code>. <br><strong>Example use-case:</strong> an HTTP provider returns a transient 500 with HTML body; <code>CaptureProviderDiagnostics</code> records the response status and body preview (redacted) and includes a TLS fingerprint showing client-server negotiation parameters to assist SRE in TLS mismatch diagnostics. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CaptureConnectionFingerprint(connectionConfig, includeDriver=false, salt=&quot;&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> compute a stable, non-sensitive fingerprint to identify a connection across runs without storing credentials or PII. Intended to group failures and identify persistent endpoints. <br><strong>Fingerprint composition (non-sensitive):</strong> providerType, hostFingerprint (sha256 of host:port), connectionMode (direct/proxy), authMethodType (OAuth/Basic/Token/Integrated), driverName+version (if includeDriver true), sanitizedOptionsHash (hash of non-PII options), and optional salt to namespace. <br><strong>Constraints:</strong> do not include username, password, tokens, or any header values; store only structural and hashed metadata. <br><strong>Operational use:</strong> group <code>pq_diagnostics</code> packages by <code>connectionFingerprint</code> to detect repeated upstream issues across different operator credentials. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ParseErrorTrace(errorObject, mashupContext, sourceArtifact=null, redactionPolicy=&quot;standard&quot;, maxFrames=50)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> parse raw engine/provider exception objects into a canonical structured error descriptor for aggregation and remediation guidance. This function produces <code>errorFingerprint</code> to deduplicate identical errors across runs. <br><strong>Parsing pipeline:</strong><br>1. Normalize raw message: strip host-specific tokens, IPs, PIDs, memory addresses. <br>2. Unwrap nested exceptions to identify root cause vs surface symptom. <br>3. Extract <code>stackFrames</code> with function names, step ids, and mashup step contexts; prune vendor internal frames unless <code>debugVerbose</code> enabled. <br>4. Map to standardized error codes <code>PQ_ERR_*</code> using provider and engine mapping tables with confidence scores. <br>5. Supply <code>remediationHints</code> and <code>reproSteps</code> derived from cause mapping (e.g., <code>refresh with smaller batch</code>, <code>increase timeout</code>, <code>re-authenticate</code>). <br><strong>Output schema:</strong> <code>{parsedError:{code, shortMessage, longMessage, stackFrames[]}, errorFingerprint, remediationHints[], reproducibilityHints, evidenceRef?}</code>. <br><strong>Edge cases:</strong> errors without stack traces still produce a fingerprint via canonicalized message and context; extremely verbose logs truncated and referenced via <code>evidenceRef</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:error_parsed(correlationId, errorFingerprint, code)</code>. <br><strong>Example:</strong> HTTP 401 mapping to <code>PQ_ERR_PROVIDER_AUTH</code> yields remediation hint <code>Verify provider credentials and refresh tokens using secure reauth flow</code> and a <code>reproSteps</code> mapping to <code>CaptureProviderDiagnostics</code> for header fingerprints. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>AggregateRefreshPath(mashupSequence[], providerCallRecords[], includeConcurrency=true, lockHints=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> generate a canonical directed graph representing query dependencies, provider edges, and compute critical path timings and concurrency hotspots for performance and correctness analysis. <br><strong>Algorithmic steps:</strong><br>1. Canonicalize nodes to <code>{queryId, stepId, mChecksum}</code> and edges according to dependencies. <br>2. Annotate nodes with provider calls and resource usage fingerprints. <br>3. Use topological traversal to compute earliest start, latest finish, exclusive and inclusive durations, and identify the critical path using longest-path in DAG heuristics adjusted for resource locks. <br>4. Provide <code>concurrencyMap</code> indicating overlapping node windows and <code>contentionPoints</code> where resource locks or provider throttles serialized execution. <br><strong>Output:</strong> <code>{dependencyGraph, criticalPathNodes[], aggregateTimings, concurrencyMap, contentionPoints}</code>. <br><strong>Use-case:</strong> explains performance regressions where a provider call created a serialization barrier causing downstream queueing—critical for SRE tuning and query rewrite suggestions. <br><strong>Audit:</strong> <code>pq_diagnostics.step:refresh_graph(correlationId, nodeCount, criticalPathMs)</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>BuildDiagnosticReport(packageMeta, format=&quot;json&quot;, includeArtifacts=false, redactPolicy=&quot;standard&quot;, linkEvidence=true, includeReproSteps=true, signManifest=true)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> assemble a signed, auditable diagnostic report combining summary, detailed artifacts, reproduction instructions, and a manifest of evidenceRefs and checksums. Intended for support tickets, vendor sharing (sanitized), and compliance submissions. <br><strong>Report components:</strong><br>1. Header: <code>correlationId</code>, <code>packageId</code>, <code>operatorId</code> (if available), <code>runTs</code>, <code>reportId</code>. <br>2. Top-line summary: short reproducible one-liner describing core symptom, top contributing factor, and immediate action. <br>3. Run metadata and environment snapshot: hostParityVector, PQEngineVersion, providerVersion, connectionFingerprint. <br>4. Diagnostics summary: timings, sample preview, planHash, trace summary, error fingerprints. <br>5. Evidence index: list of artifacts with <code>evidenceRef</code>, <code>artifactChecksum</code>, size, retention tag, and access policy notes. <br>6. Reproduction steps: explicit commands for <code>replay.run</code> including seed fingerprints and sandbox options; note <code>allowNetwork=false</code> by default. <br>7. Remediation suggestions: prioritized, pragmatic fixes with <code>confidenceScore</code>. <br>8. Signed manifest: <code>reportChecksum</code>, <code>signature</code> using release manifest signing key. <br><strong>Formatting & output:</strong> support <code>json</code>, <code>html</code>, <code>markdown</code> with embedded manifest in <code>html</code> and <code>json</code> formats. If <code>includeArtifacts=true</code> embed small sanitized artifacts (< 64KB) inline; otherwise reference via <code>evidenceRef</code>. <br><strong>Security & redaction:</strong> enforce redaction policy—no PII in top-level summary; evidence storage accessible under ACLs only. <br><strong>Audits:</strong> <code>pq_diagnostics.step:report_built(correlationId, reportId, format, reportChecksum)</code>. <br><strong>Example narrative:</strong> vendor support requires planHash and traceId; <code>BuildDiagnosticReport</code> produces signed HTML with manifest and a <code>reproduction</code> section that allows vendor to run a local reproduction using stubs. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ExportDiagnostics(reportBlobRef, targetUri, atomic=true, maxAttempts=3, retentionTag=&quot;hot&quot;, metadata={})</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> export diagnostic reports and evidence manifests to external destinations robustly and audibly; use atomic semantics where possible and provide staged fallback for non-atomic targets. <br><strong>Detailed behavior:</strong><br>1. For file systems supporting atomic replace, write to temp path and execute <code>AtomicWrite</code> semantics (<code>os.replace</code>, platform-specific ReplaceFile) ensuring atomic deliver semantics. <br>2. For object stores or network targets without atomic replace, use staged upload: upload a <code>reportId.tmp</code>, then <code>reportId.manifest</code> with checksum and finalization marker <code>reportId.ready</code>; emit <code>pq_diagnostics.export.degraded</code>. <br>3. On transient errors apply <code>Retry</code> wrapper with idempotency assertion and deterministic_jitter for CI. <br>4. Ensure exported metadata contains <code>reportChecksum</code>, <code>correlationId</code>, <code>evidenceRefs</code>, <code>retentionTag</code>, and <code>signedManifestRef</code>. <br><strong>Error handling & runbook:</strong> on <code>ENOSPC</code> produce <code>pq_diagnostics.export.failure</code> including <code>mountPath</code>, <code>freeBytes</code>, and suggested operator actions (<code>stage-local</code>, change retention). If permission errors occur, provide ACL snapshot and recommended commands. <br><strong>Audits:</strong> <code>pq_diagnostics.export.attempt(correlationId, reportId, destinationUri, paramsHash)</code> <code>pq_diagnostics.export.completed(correlationId, reportId, destinationUri, artifactChecksum)</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>ReplayDiagnostics(evidenceRef, sandboxOptions={allowNetwork:false, maxRuntimeMs:600000, memoryMb:2048}, restoreRngState=true, dryRun=true, replayMode=&quot;strict&quot;)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> run a deterministic replay using captured trace and artifact bundle within an isolated sandbox to reproduce observed behavior. Replays are read-only against production systems unless explicit operator approval sets <code>allowNetwork=true</code> and supplies controlled tokens for provider access; such approval must be audited. <br><strong>Replay safety & constraints:</strong><br>1. Default <code>allowNetwork=false</code> ensures no external calls; captured provider responses are used to feed the replay. <br>2. Replay uses a headless mashup runner that faithfully implements the same operator semantics as host engine; parity vectors for engine implementation are used to detect host-induced divergence. <br>3. <code>restoreRngState</code> restores <code>DeterministicRNG</code> state when persisted; otherwise seed derivation is used and differences recorded. <br><strong>Replay procedure:</strong><br>1. Fetch evidence bundle and validate checksums. <br>2. Recreate sanitized environment and restore serialized RNG state if present. <br>3. Rehydrate provider responses from snapshots or stubs; if <code>allowNetwork=true</code> with operator approval use safe tokens or proxy stubs. <br>4. Execute step-by-step mashup operations in the headless runner with instrumentation; write replay artifacts to ephemeral storage. <br>5. Compute <code>replayArtifactChecksums</code> and a <code>deltaReport</code> comparing them to original artifact checksums. <br>6. Persist <code>replayLogRef</code> and produce <code>replayOutcome</code> with <code>match:true/false</code> and diagnostics for mismatches. <br><strong>Audit:</strong> <code>pq_diagnostics.replay.started(correlationId, replayId, evidenceRef)</code> <code>pq_diagnostics.replay.completed(correlationId, replayId, outcome, artifactChecksums, deltaReportRef)</code>. <br><strong>Example narrative:</strong> compliance requests replay proof for a sensitive run; replay executed in a fully sandboxed environment reproduces the artifactChecksum for the report, enabling an auditable compliance submission. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>CorrelateWithAudit(correlationId, diagnosticsPackageMeta, auditTailWindow=1000)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> anchor diagnostics packages to the append-only audit chain and produce a cryptographically signed <code>forensic_manifest</code> for chain-of-custody. <br><strong>Procedure:</strong><br>1. Query audit store for rows matching <code>correlationId</code> and within the configured <code>auditTailWindow</code> to capture pre/post related actions. <br>2. Compute <code>auditRowHashes[]</code> and an <code>auditChainHash</code> by chaining consecutive record hashes. <br>3. Build <code>forensic_manifest</code> listing artifacts, <code>evidenceRefs</code>, <code>artifactChecksums</code>, <code>auditRowHashes</code>, <code>operatorApprovals</code>, and <code>configHash</code>. <br>4. Sign manifest with release manifest key and persist via <code>AtomicWrite</code> to evidence store; return <code>manifestRef</code>. <br><strong>Output:</strong> <code>{manifestRef, linkedAuditRowsCount, auditChainHash}</code>. <br><strong>Audit:</strong> <code>pq_diagnostics.step:correlated_with_audit(correlationId, manifestRef, linkedCount)</code>. <br><strong>Use-case:</strong> required for regulatory packages where a signed manifest and audit chain are necessary to demonstrate reproducibility and unbroken evidence chain. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>HealthCheck()</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> quick diagnostic check validating critical module dependencies: evidence store connectivity, <code>AtomicWrite</code> helper health, available temp disk quota, worker queue availability, service account permissions for export destinations, and redaction policy enforcement. Returns <code>{ok, checks:{evidenceStore, atomicWrite, diskQuota, workerQueue, retentionPolicy, secretsAccess}, timestamp}</code> and emits <code>pq_diagnostics.health.ok</code> or <code>pq_diagnostics.health.failed</code>. <br><strong>Operational usage:</strong> invoked at add-in load, periodically by scheduler, and integrated in CI gating. Health check must be lightweight and not perform heavy IO or exports in the UI thread. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong><code>SampleDiagnostics(populationSize, samplePercent, correlationId, rng=null, strata=null, deterministic=true, minSample=10)</code> — exhaustive technical breakdown</strong><br><strong>Purpose & contract:</strong> deterministic sampling helper used by the diagnostics module to select rows, pages, or events to include in packages while maintaining reproducibility and statistical representativeness. <br><strong>Algorithmic choices & behavior:</strong><br>1. If <code>rng</code> null and <code>deterministic=true</code> derive <code>rng</code> from <code>DeterministicRNG(seed_source=correlationId|populationFingerprint)</code> to guarantee repeatability. <br>2. If <code>strata</code> present perform proportional allocation across strata and then deterministic selection within each stratum. <br>3. For very large or streaming populations use deterministic reservoir sampling seeded by <code>rng</code>. <br>4. Ensure <code>minSample</code> lower bound to avoid empty samples in small populations. <br><strong>Output:</strong> <code>{indices[], sampleSeedFingerprint, methodUsed, deterministic=true}</code> with <code>indices</code> sorted for stable presentation. <br><strong>Audit:</strong> <code>pq_diagnostics.step:sampling(correlationId, populationSize, samplePercent, sampleSeedFingerprint)</code>. <br><strong>Examples:</strong> selecting 5% of rows from a 1M row table using stratified by country ensures distributed representation; sampling seed serialized into evidence bundle for exact replay. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error catalog (concepts & mapping)</strong><br><strong>Audit schema (required fields):</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module=PQ_Diagnostics</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>durationMs</code>, <code>metadata</code> including <code>artifactChecksum</code>, <code>reportId</code>, <code>tempChunkList</code>. All major steps must emit start/complete events. <br><strong>Top-level diagnostic events:</strong> <code>pq_diagnostics.requested</code>, <code>pq_diagnostics.started</code>, <code>pq_diagnostics.step:sample_selected</code>, <code>pq_diagnostics.step:plan_collected</code>, <code>pq_diagnostics.step:trace_captured</code>, <code>pq_diagnostics.step:error_parsed</code>, <code>pq_diagnostics.export.attempt/completed</code>, <code>pq_diagnostics.replay.started/completed</code>, <code>pq_diagnostics.prune.completed</code>. <br><strong>Representative ErrorCodes and operator guidance mapping:</strong><br>1. <code>PQ_DIAG_QUERY_NOT_FOUND</code> — verify queryId and presence in workbook or job descriptor. <br>2. <code>PQ_DIAG_PLAN_UNAVAILABLE</code> — provider denies plan export; recommend worker-mode instrumentation or vendor assistance. <br>3. <code>PQ_DIAG_TRACE_CAPTURE_FAILED</code> — evidence store or hook failure; inspect temp artifacts. <br>4. <code>PQ_DIAG_EXPORT_ENOSPC</code> — destination out-of-space; use stage-local fallback and contact infra. <br>5. <code>PQ_DIAG_REPLAY_NETWORK_FORBIDDEN</code> — replay attempted with network disabled; obtain audited approval to enable network if necessary. <br>6. <code>PQ_DIAG_PARTIAL_CAPTURE</code> — timeout/truncation; optionally re-run with increased budgets. <br><strong>Metrics:</strong> <code>pq_diagnostics.packages_per_hour</code>, <code>pq_diagnostics.full_trace_size_bytes</code>, <code>pq_diagnostics.replay_success_rate</code>, <code>pq_diagnostics.export.latency_ms</code>, <code>pq_diagnostics.partial_capture_rate</code>. Metrics buffered locally and uploaded by CORE_Telemetry; module must not perform remote uploads on the UI fast path. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Testing matrix, property tests, and cross-host parity governance (comprehensive)</strong><br><strong>Unit tests (required):</strong><br>1. Deterministic sampling parity: given identical seed and population, sample indices match across host implementations. <br>2. Plan canonicalization idempotence: transient fields removed produce stable <code>planHash</code>. <br>3. Trace capture truncation produces <code>partial=true</code> and correct <code>droppedEventCount</code>. <br>4. ParseErrorTrace canonicalizes nested exceptions to identical <code>errorFingerprint</code> when equivalent. <br>5. BuildDiagnosticReport redaction verification: no PII in top-level summary and evidenceRef points to encrypted artifact. <br><strong>Integration tests:</strong><br>1. Full collect->report->export pipeline with mocked providers and object storage; verify <code>artifactChecksum</code> and audit emissions. <br>2. ReplayDiagnostics sandbox test ensuring <code>allowNetwork=false</code> prevents outbound connections and replay artifacts match expected checksums. <br>3. CorrelateWithAudit end-to-end manifest signing and audit chain verification. <br><strong>Property tests & fuzzing:</strong><br>1. Sampling coverage and representation properties under random seeds and populations. <br>2. Trace chunking/reassembly property tests ensure chunk checksums combine to original trace summary. <br><strong>Cross-host golden gating:</strong> produce golden vectors for sampling outputs, canonicalized plans, error fingerprints, and replay artifacts; CI requires parity across supported host environments (Windows Excel, Excel for Mac, headless worker dockers) and across language SDKs used by orchestration (Python/JS/VBA) before changes merge. <br><strong>Security and privacy tests:</strong> automated redaction tests for headers and bodies, evidence encryption verification, and ACL test harness to ensure evidenceRefs enforce access permissions. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Developer guidance, allowed & forbidden patterns (explicit)</strong><br><strong>Required usage patterns:</strong><br>1. Always use <code>CollectQueryDiagnostics</code> for support capture requests; prefer <code>mode=&quot;worker&quot;</code> for heavy captures. <br>2. Persist <code>correlationId</code> and seed values in job descriptors for reproducibility. <br>3. Use <code>AtomicWrite</code> for all persisted evidence and manifests; static analyzers should fail builds that write direct final artifact paths from UI code. <br>4. Seed deterministic sampling with <code>DeterministicRNG</code> and persist serialized RNG state when exact replay is required. <br>5. Emit audit rows for every capture, export, and replay; audits must include <code>paramsHash</code> and <code>artifactChecksum</code> when available. <br><strong>Forbidden patterns:</strong><br>1. Do not log raw credentials, tokens, or PII in audits or diagnostics payloads. <br>2. Do not enable network during replay without explicit audited operator approval. <br>3. Do not perform in-place query rewrites or destructive operations during capture flows. <br>4. Do not bypass redaction policy for convenience. <br><strong>Code-review checklist:</strong> verify audit emissions, evidenceRef usage, <code>AtomicWrite</code> usage for persisted artifacts, deterministic sampling seed propagation, UI-thread safety for heavy flows, redaction enforcement, and presence of cross-host parity tests for any canonicalization logic changes. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable steps)</strong><br><strong>Trace capture ENOSPC runbook:</strong><br>1. Inspect <code>pq_diagnostics.export.failure</code> audit row for <code>correlationId</code> and <code>destinationUri</code>. <br>2. Run <code>diagnostics inspect-temp --correlation &lt;id&gt;</code> to enumerate temp chunk files and compute their checksums. <br>3. If local staging feasible, re-run <code>diagnostics export --report &lt;id&gt; --target --stage-local</code> to move artifacts onto same volume then re-export. <br>4. If blocked by quota or permissions escalate with <code>forensic_manifest</code> attached to infra ticket; include <code>pq_diagnostics</code> export failure audit. <br><strong>Non-deterministic replay triage:</strong><br>1. Retrieve <code>pq_diagnostics.replay.started</code> and <code>pq_diagnostics.replay.completed</code> audits and the <code>evidenceRef</code> for RNG state. <br>2. Run <code>replay.run --evidence &lt;ref&gt; --dry-run</code> and compare <code>replayArtifactChecksums</code> to original artifacts. <br>3. If mismatch persists, collect host parity vectors (engine versions, OS, PQ engine flavor) and escalate to parity/golden team with delta artifacts. <br><strong>Provider auth failure remediation:</strong><br>1. Locate <code>ParseErrorTrace</code> mapping to <code>PQ_ERR_PROVIDER_AUTH</code> and capture <code>providerFingerprint</code>. <br>2. Request operator reauthorization via secure flow; after reauth re-run <code>CollectQueryDiagnostics</code> to confirm resolution; persist new <code>connectionFingerprint</code> in config store. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Extremely detailed long-form narratives & examples (multiple scenarios)</strong><br><strong>Scenario 1 — Intermittent scheduled refresh failure (end-to-end forensic trace):</strong><br>1. Monitoring alert links to correlationId <code>r-20260102-b78</code>. SRE triggers <code>CollectQueryDiagnostics(connReporting, qDailyAggregate, includePlan=true, includeTrace=true, mode=&quot;worker&quot;)</code>. {audit: <code>pq_diagnostics.requested</code>} <br>2. <code>CaptureRefreshTrace</code> captures event stream across the 00:00-00:08 window including repeated provider 429 responses timestamped precisely with sequence numbers. The traceSummary reveals <code>retryCount=5</code> with backoff pattern correlating to a scheduled spike of traffic. {audit: <code>pq_diagnostics.step:trace_captured</code>} <br>3. <code>CollectQueryPlan</code> returns <code>planHash</code> where <code>HashAggregate</code> is performing heavy grouping on a high-cardinality key; canonical plan maps to historical known pattern flagged in plan registry. {audit: <code>pq_diagnostics.step:plan_collected</code>} <br>4. <code>AggregateRefreshPath</code> indicates a join re-ordering caused a late materialization step that overlapped with provider retries, producing cascading latency. <br>5. <code>BuildDiagnosticReport</code> provides reproduction steps for vendor: <code>replay.run --evidence &lt;traceRef&gt; --restoreRngState=true --dry-run</code>. Report includes <code>planHash</code>, <code>traceId</code>, and <code>criticalSegment</code> with exact timestamps. {audit: <code>pq_diagnostics.step:report_built</code>} <br>6. Vendor reproduces with provided plan and identifies a throttle rule; SRE coordinates scheduling change and introduces a migration to pre-aggregate upstream keys to reduce join cardinality. Post-fix re-run <code>CollectQueryDiagnostics</code> validates fix—replay artifactChecksum matches new artifact and scheduled run completes within SLO. <br><strong>Scenario takeaways:</strong> full trace capture with plan canonicalization and deterministic replay allowed cross-team vendor collaboration without exposing PII or credentials and enabled CI-gated remediation. <br><strong>Scenario 2 — Numeric fidelity drift after PQ template injection (deep example):</strong><br>1. Production model exhibits cent-level drift post-injection of a new PQ template. Template author provides <code>mChecksum</code>. Ops runs <code>CollectQueryDiagnostics(connFin, qLedger, includePlan=true, includeTrace=false, samplePercent=100)</code> and captures sample rows and provider plan. {audit: <code>pq_diagnostics.started</code>} <br>2. <code>CollectQueryPlan</code> shows provider casts numeric columns to double before aggregation; <code>ParseErrorTrace</code> notifies no error but <code>planSummary</code> flags the <code>CAST</code> operator. <code>BuildDiagnosticReport</code> recommends offloading final aggregation to worker-safe <code>SafeRound</code> pipeline and persisting final cents via <code>AtomicWrite</code>. <br>3. Ops implements worker-side aggregation with <code>SafeRoundResiduals</code> and persists results; <code>CollectQueryDiagnostics</code> verified final artifactChecksum matches expected golden vector and <code>RunMetadata</code> updated. CI includes golden tests ensuring cross-host parity. <br><strong>Takeaways:</strong> diagnostic pipeline identifies provider-side implicit casting and prescribes worker-side atomicized rounding to ensure regulatory compliance. <br><strong>Scenario 3 — MatchMerge tie-breaking non-determinism (detailed reconstruction):</strong><br>1. Different merge proposals observed across runs for identical input dataset. Operator provides <code>correlationId</code>. <code>CollectQueryDiagnostics</code> captures <code>SampleDiagnostics</code> seeds and <code>ParseErrorTrace</code> indicates RNG state not serialized at proposal persist stage. <br>2. Replay without RNG state reproduces different proposals; with restored RNG state (provided by operator from earlier evidence), replay matches original outputs. <code>BuildDiagnosticReport</code> documents missing RNG serialization bug and prescribes mandatory RNG state persistence for MatchMerge. <br>3. CI adds golden vector test ensuring RNG serialization round-trip parity; deployment includes migration to update existing proposals with serialized RNG metadata. <br><strong>Takeaway:</strong> enforcing RNG state persistence prevents ambiguous merges and ensures reproducibility. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — mapping PQ_Diagnostics to PQ workflows (detailed mapping & best practices)</strong><br><strong>Context:</strong> Power Query (M) runs in-process in Excel or headless engines with limited introspection. <code>PQ_Diagnostics</code> cannot instrument the internal host engine directly from M; orchestration layer (add-in or worker) performs diagnostics collection and interacts with M where safe. <br><strong>Mapping patterns & recommendations:</strong><br>1. <strong>Light-mode preview capture:</strong> UI preview flows should capture parameterHash, <code>mChecksum</code>, deterministic seed for preview sampling, small sample rows, and timing metadata. Use <code>mode=&quot;auto&quot;</code> to escalate heavy capture requests to worker and record <code>preview.audit</code> linking. <br>2. <strong>Worker-mode high-fidelity capture:</strong> heavy plan and trace capture should run in worker processes with higher timeouts and ephemeral staging; avoid performing heavy IO from the UI thread. <br>3. <strong>Template flags and contract:</strong> templates should include metadata: <code>requiresHighPrecision</code>, <code>planCaptureHint</code>, <code>diagnosticsHint</code>, and <code>evidenceRetention</code>. Orchestrator respects these flags to determine whether to offload numeric-critical transforms to <code>SafeRound</code> worker paths. <br>4. <strong>Seeding & reproducibility:</strong> preview flows must accept <code>seed</code> parameter derived from <code>correlationId</code> and persist to preview audit; <code>CollectQueryDiagnostics</code> should include that seedFingerprint for exact preview reproduction. <br>5. <strong>Atomic artifact injection:</strong> authoritative M query artifacts intended for team consumption or audits should be written to evidence store using <code>AtomicWrite</code> and then injected via workbook API referencing the same artifactChecksum; <code>pq_inject</code> audit should include artifactChecksum and mChecksum to validate parity. <br>6. <strong>Provider plan capture:</strong> because M lacks standardized plan introspection, orchestrator should call <code>CollectQueryPlan</code> post-parameterization and before injection if <code>requiresHighPrecision</code> or <code>planCaptureHint</code> present. <br>7. <strong>Retry & idempotency for PQ refresh orchestration:</strong> orchestrator uses <code>Retry</code> wrapper (with idempotency tokens persisted) for job persistence and export; M code stays declarative while orchestration manages resilience. <br><strong>Operator flow example (preview->inject->diagnose):</strong><br>1. Operator previews template; <code>PQ_Ribbon</code> computes <code>seed=SeedFromCorrelation(correlationId, templateId)</code> and passes it to preview parameters; a <code>pq_preview</code> audit is recorded. <br>2. On inject, orchestrator writes final M artifact via <code>AtomicWrite</code> and then calls <code>workbook.Queries.Add</code> using that artifact. <code>pq_inject</code> audit references artifactChecksum and <code>mChecksum</code>. <br>3. If a downstream refresh fails, operator runs <code>CollectQueryDiagnostics</code> for the injected query and receives an evidenceRef and <code>BuildDiagnosticReport</code> with <code>replay</code> instructions. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — mapping PQ_Diagnostics to semantic models & DAX troubleshooting (detailed mapping & governance)</strong><br><strong>Context:</strong> DAX operates at query time against persisted model metadata; it cannot produce side-effects or persist artifacts. Diagnostics for DAX performance and correctness are produced by ETL and model engine (Analysis Services) and surfaced via DAX measures referencing persisted <code>RunMetadata</code>. <br><strong>Patterns & recommendations:</strong><br>1. <strong>Persist RunMetadata table in ETL:</strong> ETL should write <code>RunMetadata</code> atomically containing <code>correlationId</code>, <code>artifactChecksum</code>, <code>packageId</code>, <code>runTs</code>, <code>diagnosticsReportRef</code>, and <code>engineParityVector</code>. DAX measures and reports consult this <code>RunMetadata</code> for provenance indicators. <br>2. <strong>DMV snapshot captures:</strong> <code>CollectQueryDiagnostics</code> should capture Analysis Services DMVs at ETL completion (query caches, plan caches, table statistics) and store as evidence to correlate slow DAX measures to model statistics. <br>3. <strong>HashKey deterministic sampling for DAX:</strong> in ETL compute <code>HashKey = HASH(PrimaryKey | correlationSalt)</code> and persist <code>correlationSalt</code> in <code>RunMetadata</code>. DAX filters like <code>MOD(HashKey, 100) &lt; k</code> allow deterministic sample views inside reports; <code>SampleDiagnostics</code> uses the same seed for parity. <br>4. <strong>Reconciled flags via artifactChecksum:</strong> ETL writes reconciled artifact and <code>RunMetadata</code>; DAX measure compares model table checksum to expected <code>artifactChecksum</code> and surfaces <code>ReconciledFlag</code> for report consumers. <br>5. <strong>Avoid heavy fixes in DAX:</strong> all transformations requiring rounding, residual distribution, or deterministic tie-breakers should be resolved in ETL using <code>SafeRound</code> primitives and persisted; DAX should only read persisted, reconciled integers or decimals. <br><strong>Narrative example:</strong> a slow DAX measure is traced to a high cardinality materialization; DMV snapshot captured by <code>CollectQueryDiagnostics</code> shows missing statistics and skew in cardinality; ETL is updated to pre-aggregate keys and run <code>CollectQueryDiagnostics</code> captures the post-fix artifactChecksum that DAX surfaces as <code>ReconciledFlag=1</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendices: forensic artifacts, evidence paths & recommended retention (expanded and prescriptive)</strong><br><strong>Minimum forensic artifacts for an incident:</strong><br>1. <code>ribbon-map.json</code> and release manifest with signatures. <br>2. <code>jobDescriptor.json</code> persisted via <code>AtomicWrite</code> including <code>jobId</code>, <code>paramsHash</code>, <code>configHash</code>, and <code>correlationId</code>. <br>3. <code>audit_tail.csv</code> covering pre/post windows with <code>pq_diagnostics.*</code> rows. <br>4. artifact files with <code>SHA256</code> checksums and <code>artifact.metadata.json</code>. <br>5. serialized RNG state (<code>rng_state.blob</code>) for sampling/tie-breaker reproduction. <br>6. <code>SafeRound</code> inputs and canonicalized decimal snapshots for numeric forensic. <br>7. trace artifacts and chunk manifests from <code>CaptureRefreshTrace</code>. <br>8. temp artifact listing from <code>InspectTempArtifacts</code> and recovery scripts. <br><strong>Evidence Store & retention:</strong><br>1. Hot evidence store path: <code>evidence/hot/pq_diagnostics/&lt;correlationId&gt;/</code> retained 30 days for rapid access. <br>2. Warm archive: secure archive for 7 years for regulatory retention; access strictly controlled and logged; manifests include chain-of-custody attributes and signatures. <br>3. Cold archive: cold storage per policy with retrieval windows. <br>4. <code>forensic_manifest.json</code> enumerates URIs, checksums, retentionTag, and access policy for investigators. <br><strong>Retention verification cadence:</strong> monthly retention verification job emits <code>pq_diagnostics.prune.completed</code> with counts of pruned artifacts; audits include proof-of-delete records. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (detailed & blocking conditions):</strong><br>1. Owners listed in OWNERS.md with on-call contacts. <br>2. Public API stable and documented with semantic versioning. <br>3. Evidence encryption and key-management tested; key rotation documented. <br>4. Deterministic sampling goldens validated and parity tests across hosts passing. <br>5. Plan canonicalization golden vectors validated for transformed provider output. <br>6. Redaction tests verify absence of PII in top-level audit rows and presence in encrypted evidence only. <br>7. CI gates include static analyzer checks forbidding credential logging and UI-thread heavy IO. <br>8. Integration tests for <code>CollectQueryDiagnostics</code>-><code>BuildDiagnosticReport</code>-><code>ExportDiagnostics</code>-><code>CorrelateWithAudit</code> pipeline pass. <br><strong>Blocking conditions:</strong> missing audit emissions, redaction failures, golden regressions, or absence of AtomicWrite usage for persisted artifacts. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & scripts (explicit, conceptual)</strong><br><strong>Unit tests (explicit):</strong><br>1. Sampling parity and deterministic RNG seeding across seeds. <br>2. Plan canonicalization idempotence across ephemeral provider fields. <br>3. Trace truncation and chunk reassembly tests. <br>4. ParseErrorTrace canonicalization for nested exceptions. <br>5. BuildDiagnosticReport redaction and manifest signing tests. <br><strong>Integration tests:</strong><br>1. collect->report->export: simulate provider interactions and verify <code>artifactChecksum</code> and audit emissions. <br>2. replay sandbox tests: ensure <code>allowNetwork=false</code> prevents outbound connections and that replay artifacts match golden checksums. <br>3. CorrelateWithAudit test ensures manifest contains auditRowHashes with valid signature. <br><strong>Performance tests:</strong><br>1. trace capture throughput under synthetic high event rates, verifying chunk manifest integrity. <br>2. report build latency for large packages (>100MB) and stress test AtomicWrite on various filesystem semantics. <br><strong>Security tests:</strong> PII redaction fuzzing, evidence encryption key rotation, ACL enforcement for evidenceRefs. <br><strong>CI gating:</strong> golden vectors, static checks, and integration test suites must pass; performance regressions cause gate failure requiring owner approval. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Operator runbook quick commands & examples (concise & prescriptive)</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-abc --query qName --include-plan</code> — collect diagnostics with plan and stage to evidence store. <br>2. <code>diagnostics export --report &lt;id&gt; --target sftp://host/path</code> — export a signed report using atomic semantics where supported. <br>3. <code>diagnostics replay --evidence &lt;ref&gt; --dry-run</code> — deterministic sandbox replay without network. <br>4. <code>diagnostics inspect-temp --correlation &lt;id&gt;</code> — list temporary chunks from failed captures and compute checksums for manual recovery. <br>5. <code>diagnostics sign-manifest --manifest &lt;id&gt;</code> — re-sign manifest with release manifest key if necessary during regulatory packaging. <br><strong>When to call SRE:</strong> after two <code>pq_diagnostics.export</code> ENOSPC failures for critical artifacts, repeated replay mismatches suggesting host parity failure, or evidence store permission anomalies; include <code>forensic_manifest</code> with ticket. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Final notes, governance & mandatory constraints (firm & non-negotiable):</strong><br>1. Never persist raw credentials or unredacted PII in audit rows or reports; evidence store only with explicit governance and encrypted at rest. <br>2. All persisted artifacts must use <code>AtomicWrite</code> semantics or the staged manifest fallback and emit <code>pq_diagnostics.export.degraded</code> when atomic replace cannot be guaranteed. <br>3. Deterministic RNG seeds must be derived from <code>correlationId</code> for operator-visible sampling; if exact replay required serialize RNG state and store encrypted in evidence store. <br>4. Replays default to sandboxed, network-disabled execution; enabling network must be explicitly approved and audited. <br>5. Exported diagnostic packages must include <code>reportChecksum</code>, <code>correlationId</code>, signed manifestRef, and evidenceRef links. <br>6. All heavy IO or potentially blocking operations are forbidden on the UI thread and must be scheduled to worker processes. <br><strong>Checked:</strong> content underwent multi-pass verification for internal consistency, audit linkage, deterministic sampling, redaction policy, plan canonicalization, replay safeguards, and cross-module dependencies (tenfold review). </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix A — Example audit row schema (descriptive):</strong><br><strong>Fields required for PQ_Diagnostics audits:</strong> <code>timestamp</code>, <code>correlationId</code>, <code>module</code>, <code>procedure</code>, <code>operatorId</code> (optional), <code>paramsHash</code>, <code>resultHash</code> (optional), <code>evidenceRef</code> (optional), <code>prevHash</code> (optional), <code>configHash</code>, <code>metadata</code> including <code>durationMs</code>, <code>attempts</code>, <code>artifactChecksum</code>, <code>reportId</code>, <code>tempChunkList</code>. <br><strong>Policy note:</strong> top-level audit rows must not contain PII; sanitized parameters and large payloads stored in the encrypted evidence store and referenced by <code>evidenceRef</code>. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix B — Common failure modes & mitigations (expanded):</strong><br><strong>Failure mode: oversized trace artifacts causing ENOSPC</strong><br>1. Cause: <code>includeTrace=true</code> on a high-volume provider without <code>maxEvents</code> or compression. <br>2. Mitigation: enforce <code>maxEvents</code>, apply streaming compression and chunking, use stratified sampling, produce <code>pq_diagnostics.step:truncated</code> and <code>forensic_manifest</code> with chunk checksums; operator may request selective time windows for re-capture. <br><strong>Failure mode: replay mismatch despite captured evidence</strong><br>1. Cause: missing RNG state, host engine parity differences, truncated provider snapshots, or dependency on ephemeral external state. <br>2. Mitigation: mandate RNG state serialization where reproducibility matters, persist host parity vectors in manifest, capture provider snapshots, and add parity diagnostics in CI to reduce heterogeneity. <br><strong>Failure mode: plan unavailable from provider</strong><br>1. Cause: provider blocks <code>EXPLAIN</code> or lacks capability. <br>2. Mitigation: fallback to worker-mode instrumentation to reconstruct plan heuristically, or request vendor plan capture with signed manifest and audit. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix C — Governance checklists & PR requirements (explicit):</strong><br>1. PR must include unit tests for deterministic behaviors, golden vectors for plan canonicalization, and redaction tests. <br>2. Changes to redaction or retention policies require owner and compliance approval and release manifest updates. <br>3. Changes to export semantics or <code>AtomicWrite</code> usage must include cross-platform regression tests and SRE sign-off. <br>4. Any change to <code>DeterministicRNG</code> serialization format requires migration instructions and golden parity updates. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix D — Incident reconstruction example (ordered & executable):</strong><br><strong>Incident synopsis:</strong> operator reports "Allocation mismatch for run r-20260112-455" — artifact sums different from ledger. <br><strong>Forensic reconstruction steps (ordered):</strong><br>1. Retrieve <code>pq_diagnostics.*</code> and <code>UserAction</code> audit rows for the <code>correlationId</code>. <br>2. Pull <code>artifactChecksum</code> from <code>pq_diagnostics.complete</code> and evidenceRef pointing to <code>SafeRound</code> input snapshot. <br>3. Download <code>rng_state.blob</code> and verify integrity via its checksum; ensure evidence store ACL allows access to investigators. <br>4. Run <code>replay.run --evidence &lt;ref&gt; --dry-run</code> restoring RNG; execute <code>SafeRoundResiduals</code> using persisted canonical decimals. <br>5. Compare produced artifact checksums to original; if identical, pipeline determinism confirmed; if mismatch, inspect <code>atomic_write.verification_failed</code> and temp artifact lists. <br>6. Compile <code>forensic_manifest.json</code> including audit rows, evidenceRefs, and replay delta; escalate to compliance if regulatory impact identified. <br><strong>Outcome:</strong> reproducible replay yields identical artifact showing pipeline correctness; incident closed with runbook updates on tie-break expectations and RNG state persistence. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix E — PQ & DAX short checklists for template authors and report builders:</strong><br><strong>PQ Template author checklist:</strong><br>1. Include <code>mChecksum</code> and <code>templateVersion</code> in template metadata. <br>2. Mark <code>requiresHighPrecision</code> and <code>planCaptureHint</code> for templates performing critical numeric transforms. <br>3. Parameterize a <code>seed</code> for preview flows and persist seed in preview audit. <br>4. Offload final numeric aggregation to worker <code>SafeRound</code> flows for regulated outputs; persist final artifacts with <code>AtomicWrite</code>. <br>5. Provide <code>diagnosticsHint</code> specifying recommended <code>includePlan</code>/<code>includeTrace</code> flags for support. <br><strong>DAX/report builder checklist:</strong><br>1. Consume <code>RunMetadata</code> table for provenance and <code>artifactChecksum</code> verification. <br>2. Avoid performing allocation/residual rounding in DAX; convert to ETL-managed persisted columns. <br>3. Use hashed stable keys computed during ETL to enable deterministic sampling and debug views in reports. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix F — Long-form operator scenario: forensic reconstruction and regulatory package (procedural):</strong><br><strong>Scenario synopsis:</strong> regulator requests audit package for a sensitive run produced two weeks earlier; operator must provide signed manifest, reproducible evidence, and replay instructions. <br><strong>Procedural steps:</strong><br>1. Locate <code>pq_diagnostics</code> package by <code>correlationId</code> and verify <code>pq_diagnostics.complete</code> artifactChecksum. <br>2. Run <code>CorrelateWithAudit(correlationId, packageMeta)</code> to build <code>forensic_manifest</code> linking audit rows, evidenceRefs, and artifact checksums; sign manifest with release manifest key. <br>3. Execute <code>ReplayDiagnostics</code> in sandbox with <code>restoreRngState=true</code> and <code>allowNetwork=false</code> to generate <code>replayOut</code> demonstrating artifact parity. <br>4. Build final regulatory bundle: <code>report.html</code> (signed), <code>forensic_manifest.json</code> (signed), evidenceChunks (encrypted), <code>audit_tail.csv</code>, and <code>release_manifest</code> signature; persist bundled package via <code>AtomicWrite</code> to regulated archive with appropriate retention tags. <br>5. Deliver bundle to regulator endpoint according to policy; record <code>submission.audit</code> and preserve chain-of-custody logs. <br><strong>Compliance takeaway:</strong> reproducible evidence bundles and signed manifests are necessary to satisfy audit and regulatory requests while preserving PII constraints. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix G — Migration guidance & backward compatibility (detailed):</strong><br><strong>When RNG serialization format changes:</strong><br>1. Provide a compatibility layer that can read both legacy and new serialized RNG state formats. <br>2. Provide migration tool <code>rng_migrate --evidence &lt;ref&gt;</code> that updates stored RNG blobs and re-computes seedFingerprints. <br>3. Update CI golden vectors and require parity approval from RNG owners. <br><strong>When plan canonicalization rules change:</strong><br>1. Ship canonicalizer in major version and maintain <code>planHashV1</code> and <code>planHashV2</code> columns in registry for migration. <br>2. Provide <code>ResolvePlanHash(planText)</code> utility to compute both v1 and v2 hashes for transition period. <br><strong>When export semantics change:</strong><br>1. Ensure <code>AtomicWrite</code> semantics remain the default; if fallback staging changes, document in release manifest and migrate existing manifests via <code>sign-manifest</code> flow. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix H — Example diagnostic report sections (template outline for authors & support):</strong><br><strong>Report header:</strong> <code>reportId</code>, <code>correlationId</code>, <code>operatorId</code>, <code>runTs</code>, <code>reportChecksum</code>. <br><strong>Executive summary:</strong> short reproducible one-liner. <br><strong>Run metadata:</strong> hostParityVector, PQEngineVersion, connectionFingerprint, mChecksum. <br><strong>Top findings:</strong> key errors, planHash, critical path nodes. <br><strong>Detailed artifacts index:</strong> list of evidenceRefs with checksums and sizes. <br><strong>Repro steps:</strong> exact <code>replay.run</code> invocation with seedFingerprint and sandbox options. <br><strong>Remediation actions:</strong> prioritized suggestions, estimated effort, owner. <br><strong>Signed manifest & chain-of-custody:</strong> signature block and rail of auditRow hashes. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix I — Cross-team responsibilities (concise mapping):</strong><br>1. TEAM_PQ_DIAGNOSTICS — owns capture/replay code, evidence store interface, plan canonicalization, and analytics summaries. <br>2. TEAM_UTILITIES — provides <code>AtomicWrite</code>, <code>DeterministicRNG</code>, <code>Retry</code>, and <code>SafeRound</code> primitives used by diagnostics. <br>3. TEAM_SRE — owns evidence store availability, export endpoints, and infrastructure support for large artifact handling. <br>4. TEAM_COMPLIANCE — verifies signed manifests, retention policies, and regulatory packaging. <br>5. TEAM_TEMPLATE_OWNERS — declare <code>diagnosticsHint</code> and <code>requiresHighPrecision</code> flags in template manifests. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Appendix J — Example CSV of minimal diagnostic manifest (illustrative fields for tooling integration):</strong><br><code>packageId,correlationId,reportId,artifactChecksum,evidenceRef,traceId,planHash,connectionFingerprint,operatorId,runTs</code> <br><strong>Usage:</strong> tools import this CSV to attach diagnostics to support tickets and compliance trackers. </td></tr><tr><td data-label="PQ_Diagnostics — Per-function Expert Technical Breakdown"> <strong>Closing operational constraint (must not be bypassed):</strong><br>All processes that produce artifacts consumed by other modules must: persist job descriptors, seed deterministic RNGs from <code>correlationId</code> for operator-visible sampling, use <code>AtomicWrite</code> for final artifacts, and emit required audit rows. This constraint is mandatory for regulated or PII-touching workflows and enforced by CI static checks and production monitors. </td></tr></tbody></table></div><div class="row-count">Rows: 38</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>