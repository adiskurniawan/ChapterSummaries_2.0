<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771612981">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0202_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by HR-Budget Reconciliation Orchestrator (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">HR-Budget Reconciliation Orchestrator (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Preface (scope & reading notes)</strong><br>This document expands the per-function technical breakdown for the UpdateHR+ solution. It is intended as an implementation-ready spec for senior VBA developers, payroll/finance engineers, and integration owners. Each module entry contains: purpose, inputs/outputs, public functions (with parameter and return semantics), internal helpers, error codes, sample data shapes, audit points, performance notes, test cases, and governance considerations. Numbered lists use <code>&lt;br&gt;</code> line breaks for clipboard-friendly rendering. Use the module names exactly as listed in the code repository. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Glossary (short)</strong><br>- <code>runId</code>: deterministic UUID for each run.<br>- <code>inputRowHash</code>: canonical hash computed on immutable input columns for idempotency.<br>- <code>ApplyDescriptor</code> / <code>ApplyDesc</code>: JSON-like payload describing staged change.<br>- <code>AuditRow</code>: single row in <code>Audit_Log</code> capturing before/after and provenance.<br>- <code>PQ</code>: Power Query transform layer. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modCoreEngine</strong> — Role: orchestrates deterministic read→transform→transactional-write lifecycle; manages Application state and run lifecycle, batching, staging, commit/rollback, run metadata, and high-level telemetry.<br><strong>Primary responsibilities and functions (per-function breakdown):</strong><br>1. <code>RunUpdateHR(staffRangeName As String, runOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — entry-point runner.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>staffRangeName</code> (named range), <code>runOptions</code> keys: <code>dryRun</code>(Boolean), <code>maxRows</code>(<code>Long|Optional</code>), <code>autoApplyThreshold</code>(<code>Double|Optional</code>), <code>userId</code>(String).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Returns: <code>runSummary</code> dictionary with keys <code>runId</code>, <code>status</code>, <code>rowsProcessed</code>, <code>autoApplied</code>, <code>reviewCount</code>, <code>errors</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: Validate preconditions via <code>ValidatePreRun</code>; build <code>runId</code> (GUID + timestamp), persist config snapshot, call <code>PrepareStaging</code>, iterate rows with <code>ProcessStaffRow</code>, buffer telemetry, and call <code>CommitRun</code> if commit conditions met (not dry-run and no blocking material escalations).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Error semantics: returns <code>status=&quot;FAILED&quot;</code> with <code>errors</code> array if fatal; append <code>RunError</code> audit row. <br>2. <code>ProcessStaffRow(rowIndex As Long, rowData As Scripting.Dictionary, stagingWS As Worksheet, resultOut As Scripting.Dictionary) As Long</code> — per-row orchestrator.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>rowIndex</code> (1-based within <code>staffRange</code>), <code>rowData</code> dictionary with canonical keys (name, id, amount, costCenter, orgUnit, postingExample), <code>stagingWS</code> reference.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Outputs: numeric status code: <code>0=OK_AUTO</code>, <code>1=OK_SUGGEST</code>, <code>2=REVIEW_REQUIRED</code>, <code>3=NO_CANDIDATE</code>, <code>9=ERROR</code> and <code>resultOut</code> filled with <code>candidateList</code>, <code>appliedDesc</code>, <code>rationale</code>, <code>timings</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Steps: compute <code>inputRowHash</code>, call <code>CleanName</code>, call matching pipeline via <code>modMatchingEngine.RankCandidates</code>, evaluate <code>Materiality</code> and <code>PolicyChecks</code>, decide <code>autoApply</code> vs <code>suggest</code>, optionally call <code>modGoalSeekController.RunGoalSeek</code> when a numeric balancing is required, produce <code>ApplyDescriptor</code> and stage into <code>stagingWS</code> if chosen for apply. <br>3. <code>PrepareStaging(runId As String) As Boolean</code> — creates staging artifacts.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Creates hidden worksheets: <code>__Stage_Run_&lt;runId&gt;</code>, <code>__Stage_Backup_&lt;runId&gt;</code>, <code>__Stage_Temp</code> (reuse policy), sets headers: <code>rowId</code>, <code>targetAddress</code>, <code>targetSheet</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>status</code>, <code>inputRowHash</code>, <code>candidateId</code>, <code>rationale</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Snapshots current values for target addresses into <code>__Stage_Backup_&lt;runId&gt;</code> for rollback. <br>4. <code>CommitRun(runId As String) As Scripting.Dictionary</code> — atomic apply of staged rows.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: disable <code>ScreenUpdating</code>, <code>EnableEvents=False</code>, set calculation to manual, iterate staged rows grouped by <code>targetSheet</code> and write using <code>Range.Value</code> or <code>Value2</code>. Commit chunks by <code>modConfig.BatchSize</code>. After each chunk write, persist checkpoint in <code>__Run_Status</code> with <code>lastCommittedRow</code> and <code>chunkId</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Post-commit: verify checksums, write <code>Commit</code> entries in <code>Audit_Log</code>, set <code>runStatus</code> to <code>COMMITTED</code> and call <code>FinalizeRun</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Failure: call <code>RollbackRun</code> and include diagnostics. <br>5. <code>RollbackRun(runId As String, reason As String) As Boolean</code> — deterministic rollback using backup snapshot.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Steps: read <code>__Stage_Backup_&lt;runId&gt;</code>, write <code>beforeJSON</code> values back to original addresses, restore named ranges and Calculator cells known to be modified, re-enable application state, append <code>ROLLBACK</code> entry in <code>Audit_Log</code> containing <code>reason</code>, <code>stackTrace</code>, and <code>rollbackTime</code>.<br>6. <code>FinalizeRun(runId As String)</code> — post-commit summary export and housekeeping.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Compute: <code>totalTime</code>, <code>avgTimePerRow</code>, <code>GSStats</code> from <code>__GS_Metrics</code>, <code>telemetrySummary</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Export: run-level CSV/JSON (optionally sign), notify UI. <br>7. <code>ValidatePreRun(runOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — returns <code>validationErrors</code> collection if any.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Checks: presence of named ranges, Calculator cell formulas matching expected regex, no active stale locks, user role valid, config thresholds present. <br>8. <code>LockingAndConcurrency()</code> — lock token management.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Use hidden sheet <code>__Run_Locks</code> storing <code>lockToken</code>, <code>lockedBy</code>, <code>lockedAt</code>(UTC). Provide <code>AcquireLock</code>, <code>RefreshLock</code>, <code>ReleaseLock</code>, and <code>DetectOrphanedLock</code> utilities. <br><strong>Implementation notes & performance:</strong><br>- Keep only minimal row-level I/O per loop; bulk-load staffRange into 2D variant array, operate in-memory and write staging in batch.<br>- Telemetry buffering: write telemetry to in-memory collection and flush to <code>__Telemetry</code> sheet periodically (per N rows or on chunk commit) to reduce sheet writes.<br>- Use <code>Application.StatusBar</code> progress updates and intermittent <code>DoEvents</code> to keep Excel responsive. <br><strong>Audit points:</strong> pre-run snapshot, per-row staged ApplyDescriptor, pre-commit checkpoint, per-chunk commit, post-commit finalization, rollback entries. <br><strong>Test cases:</strong><br>- RunUpdateHR with <code>dryRun=True</code> returns identical <code>Audit_Log</code> sans <code>COMMITTED</code> entries.<br>- Simulate simultaneous two-run attempts: second runner must fail AcquireLock with <code>LOCK_HELD</code> error. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modMatchingEngine</strong> — Role: multi-stage, pluggable matching pipeline (Stage A–D) delivering deterministic candidate lists and confidence scores; supports local algorithms and external scorer integration.<br><strong>Primary functions and behaviour:</strong><br>1. <code>CleanName(rawName As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — canonicalisation engine.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Returns dictionary: <code>raw</code>, <code>clean</code>, <code>tokens</code> (array), <code>tokenKey</code> (ordered string), <code>trigrams</code> (string), <code>hasNumericToken</code>(Boolean).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Rules: NBSP→space, collapse multiple spaces, trim, lowercase, remove control chars, optionally strip accents (unicode normalization NFKD + remove diacritics via VBScript map), remove punctuation except internal apostrophes, remove honorifics/stopwords if configured. Keep deterministic mapping and log both <code>raw</code> and <code>clean</code> for trace. <br>2. <code>StageA_ExactLookup(cleanName As String, dictExact As Scripting.Dictionary) As Collection</code> — exact-match lookup.<br>&nbsp;&nbsp;&nbsp;&nbsp;• dictExact keyed by canonical <code>cleanName</code> → list of employeeIds. Returns candidate objects with <code>candidateId</code>, <code>employeeId</code>, <code>orgUnit</code>, <code>hireDate</code>, <code>source</code> (master/alias/prior).<br>&nbsp;&nbsp;&nbsp;&nbsp;• If >1 match, return <code>AmbiguousExact</code> flag. <br>3. <code>StageB_TokenPhoneticLookup(tokens() As String) As Collection</code> — token overlap & phonetic.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Precomputed index: <code>dictTokenIndex</code> maps token fingerprint → candidate list. Token overlap ratio computed as <code>commonTokens / totalInputTokens</code>. Implement Metaphone (or Double Metaphone) in VBA for phonetic tokens; compute <code>phoneticMatchCount</code>. <br>4. <code>StageC_FuzzyLookup(cleanName As String, candidateSet As Collection) As Collection</code> — fuzzy scoring.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Use <code>modFuzzyScores.NormalizedFuzzyScore</code> combining Levenshtein banded DP and 3-gram Jaccard; cap comparisons at <code>modConfig.MaxFuzzyComparisonsPerRow</code>. Use early-exit if current candidate can't beat top-K threshold. Return <code>fuzzyScore</code> 0..1. <br>5. <code>StageD_MLRanker(featureVector As Scripting.Dictionary, topK As Long) As Collection</code> — optional external ML ranking.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Calls <code>CallExternalScorer</code> with payload: <code>runId</code>, <code>rowId</code>, <code>features[]</code> and receives <code>topK</code> candidates with <code>mlScore</code> and <code>explain</code> (feature importances). If service unavailable, fall back to ensemble weighting. <br>6. <code>RankCandidates(candidateCollection As Collection, policy As Scripting.Dictionary) As Collection</code> — deterministic ensemble ranker.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Composition: <code>finalScore = w_token*TokenSetScore + w_trigram*TrigramJaccard + w_fuzzy*FuzzyScore + w_prior*PriorWeight + w_sameOrg*SameOrgBonus + signatureBonus</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Add tie-break keys: <code>sameEmployeeId</code>, <code>employeeSeniority</code> (hireDate), <code>recentConfirmCount</code>. Rationale string contains component contributions and final score rounding to 4 decimals. <br>7. <code>CallExternalScorer(payload As Scripting.Dictionary) As Scripting.Dictionary</code> — wrapper for REST or COM.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Retries: <code>maxRetries</code> (configurable), exponential backoff; on repeated failure flip circuit to <code>TRIPPED</code> for <code>circuitTimeoutSecs</code>; metric recorded in telemetry. <br>8. <code>PersistMatchDecision(runId As String, rowId As Long, decision As Scripting.Dictionary)</code> — writes to <code>Audit_Log</code> and optionally to <code>ConfirmedMatches</code> for training.<br><strong>Data shapes (candidate object):</strong><br><code>{ candidateId, employeeId, fullName, orgUnit, costCenter, hireDate, tokenOverlap, trigramJaccard, fuzzyScore, phoneticMatchCount, priorConfirmCount, combinedScore, confidenceBand, rationale }</code><br><strong>Performance & tuning:</strong><br>- Precompute tokenIndex and trigramIndex once per run via <code>LoadMasterStore</code> to avoid repeated string processing.<br>- Use memoization in <code>MemoizeCall</code> for repeated fuzzy comparisons of identical strings across rows. <br><strong>Test cases:</strong><br>- Exact match returns single high-confidence candidate.<br>- Phonetic-only match returns candidate with <code>phoneticMatchCount&gt;0</code> and lower weight. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modFuzzyScores</strong> — Role: encapsulate fuzzy string algorithms, provide tunable thresholds and profiling utilities.<br><strong>Functions and detail:</strong><br>1. <code>LevenshteinDistance(sA As String, sB As String, maxDistance As Long) As Long</code> — banded DP.<br>&nbsp;&nbsp;&nbsp;&nbsp;• If partial distance exceeds <code>maxDistance</code> abort early and return large sentinel (>maxDistance). Use variant arrays for performance and treat strings as arrays of Unicode codepoints when accent-stripping disabled. <br>2. <code>NormalizedFuzzyScore(sA As String, sB As String) As Double</code> — compute <code>1 - (lev / maxLen)</code> then apply smoothing (sigmoid or piecewise) to ensure mid-values meaningful.<br>3. <code>NGramFingerprint(s As String, n As Integer) As String</code> — produce sorted unique sliding windows, remove whitespace punctuation first; return concatenated token <code>&quot;|gram1|gram2|...&quot;</code> used for prefiltering. <br>4. <code>ComputeFuzzyBatchScores(target As String, candidates As Collection, maxComparisons As Long, topK As Long) As Collection</code> — perform incremental top-K maintenance using a binary heap data structure implemented as array for top-K retention. If candidate set too large, use trigram prefilter to reduce to subset. <br>5. <code>ProfileFuzzyComparisons(historyRange As Range) As Scripting.Dictionary</code> — compute histograms and ROC-like thresholds: <code>TP</code>, <code>FP</code>, <code>FN</code>, <code>TN</code> at candidate thresholds; recommend <code>autoApplyThreshold</code> to reach target precision (e.g., 98%). <br><strong>UI bindings & tuning:</strong><br>- Expose smoothing factor and n-gram size in <code>modConfig</code> and provide <code>RecommendThresholds()</code> which runs <code>ProfileFuzzyComparisons</code> and produces a small report sheet <code>__Fuzzy_Tuning</code> with recommended thresholds and expected precision/recall. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modGoalSeekController</strong> — Role: robust controlled GoalSeek orchestration with validation, timeouts, retries, fallback search, and telemetry capture.<br><strong>Detailed functions:</strong><br>1. <code>RunGoalSeek(targetCell As Range, changingCell As Range, targetValue As Double, runContext As Scripting.Dictionary) As Scripting.Dictionary</code> — orchestrator.<br>&nbsp;&nbsp;&nbsp;&nbsp;• runContext keys: <code>TimeoutSec</code>, <code>MaxAttempts</code>, <code>Tolerance</code>, <code>SampleRange</code> (optional array).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Return object: <code>Status</code>, <code>SolutionValue</code>, <code>Attempts</code>, <code>FinalResidual</code>, <code>MethodUsed</code>, <code>TraceRef</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Implementation: call <code>PreValidateFunctionShape</code>; attempt <code>Range.GoalSeek</code>, monitor with <code>Timer</code> for <code>TimeoutSec</code>; if fails call <code>IncrementalFallbackSearch</code>; record trace points at regular intervals (x,f(x)).<br>2. <code>PreValidateFunctionShape(targetCell As Range, changingCell As Range, samplePoints As Long) As Scripting.Dictionary</code> — sample at <code>N</code> points across reasonable domain and compute derivative approximations. Return <code>monotonicityScore</code> and recommended <code>action</code> (OK/WARN/FAIL) plus sample array.<br>3. <code>IncrementalFallbackSearch(low As Double, high As Double, evaluateFunc As IUnknown, maxSteps As Long, tolerance As Double)</code> — implement deterministic binary/bounded search with derivative smoothing to avoid oscillation; uses the evaluateFunc callback to compute f(x) and caches results.<br>4. <code>RecordGSMetric(runId As String, rowId As Long, metric As Scripting.Dictionary)</code> — append to <code>__GS_Metrics</code>. <br><strong>Edge cases & mitigations:</strong><br>- Non-smooth functions: pre-validate and escalate to reviewer; provide option to sample curve and attach to audit.<br>- Oscillation: implement step-size shrink and momentum damping in fallback search. <br><strong>Testing:</strong><br>- Synthetic function with known root verify <code>RunGoalSeek</code> returns expected solution within <code>Tolerance</code> and attempts < <code>MaxAttempts</code>. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modSuggestionUI / frmReviewerUI</strong> — Role: reviewer-facing UI providing top-N candidate presentation, contextual information, bulk operations, and feedback capture for ML training.<br><strong>Features & functions (expanded):</strong><br>1. <code>ShowRowSuggestions(runId As String, rowId As Long, candidates As Collection, displayOptions As Scripting.Dictionary)</code> — populates <code>frmReviewerUI</code> controls and metadata pane.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Display includes candidate table with columns: <code>Rank</code>, <code>candidateName</code>, <code>employeeId</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>confidence</code>, <code>componentBreakdown</code>, <code>deltaBudgetImpact</code>, <code>examplePostingRows</code> (expandable), <code>lastConfirmed</code> date, <code>priorConfirmCount</code>, <code>matchedRule</code> (A/B/C/D).<br>2. <code>BulkApplyDialog(summaryMetrics As Scripting.Dictionary)</code> — shows aggregated counts per confidence band, total monetary impact, and allows reviewer to choose bulk operations: <code>ApplyAboveThreshold(X%)</code>, <code>ExportForApproval</code>, <code>HoldForEscalation</code>.<br>3. <code>CaptureReviewerDecision(runId As String, rowId As Long, chosenCandidateId As String, decisionMeta As Scripting.Dictionary)</code> — durable write into <code>Audit_Log</code> and <code>ConfirmedMatches</code> with fields: <code>reviewerId</code>, <code>rationale</code>, <code>decisionToken</code>, <code>signatureHash</code> (lightweight). Enforce idempotency by checking for existing <code>decisionToken</code> for same runId+rowId. <br>4. <code>ShowCandidateDiffs(candidateA As Scripting.Dictionary, candidateB As Scripting.Dictionary)</code> — visual diff view presenting side-by-side field-level comparisons with color-coded differences and scale bars for numeric differences. <br>5. <code>ReviewerFeedbackIngest(decisions As Collection, privacyOptions As Scripting.Dictionary)</code> — batch ingest for ML training export. Privacy options: <code>hashPII = True</code> to replace employee ids and names with salted hash; <code>includeFeatures</code> to include feature vectors. <br><strong>UI governance & security:</strong><br>- Enforce role-based controls defined in <code>modConfig.UserRoles</code> and require reviewer password or MFA token for large-dollar approves (> <code>modConfig.ReviewerHighDollarThreshold</code>).<br>- Every UI action writes an audit row with <code>actionHash=SHA1(runId &amp; rowId &amp; userId &amp; timestamp &amp; action)</code>. (Note: VBA SHA1 approximate implementations exist; for legal-grade signature, integrate with external PKI.)<br><strong>Test cases:</strong><br>- Reviewer approves candidate; check <code>Audit_Log</code> contains <code>APPROVE</code> row and <code>ConfirmedMatches</code> updated; <code>ApplyDescriptor</code> staged. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modAudit</strong> — Role: append-only audit log management, export helpers, integrity checks, and retention handling.<br><strong>Core functions & behavior:</strong><br>1. <code>InitAudit(runId As String, userId As String, metadata As Scripting.Dictionary)</code> — ensure <code>Audit_Log</code> exists and write header run row.<br>2. <code>AppendAuditRow(auditRec As Scripting.Dictionary)</code> — append row in single operation with timestamp and compute row-level pseudo-checksum. Schema (columns): <code>runId</code>, <code>rowId</code>, <code>actionType</code>, <code>inputRowHash</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>confidence</code>, <code>componentBreakdown</code>, <code>gsRef</code>, <code>status</code>, <code>userId</code>, <code>timestamp</code>, <code>rowChecksum</code>.<br>3. <code>SealAuditRun(runId As String)</code> — compute run-level checksum by concatenating rowChecksums and store in <code>__Audit_Seals</code>. Seal prevents UI from allowing further modifications without admin unlock with audit trail. <br>4. <code>ValidateAuditIntegrity()</code> — recompute rolling checksums and compare; if mismatch, mark run <code>SUSPECT</code> and generate <code>ForensicPack</code> automatically. <br>5. <code>ExportAudit(runId As String, exportFormat As String, destPath As String)</code> — perform streaming export to CSV or ndjson; include <code>manifest.json</code> describing <code>codeVersion</code>, <code>configSnapshot</code>, <code>runId</code>, <code>sealChecksum</code>. <br><strong>Schema example for <code>beforeJSON</code> / <code>afterJSON</code>:</strong><br><code>{ &quot;employeeId&quot;: &quot;E123&quot;, &quot;costCenter&quot;: &quot;CC01&quot;, &quot;amount&quot;: 12345.67, &quot;effectiveDate&quot;: &quot;2026-02-01&quot;, &quot;postingIds&quot;: [&quot;P123&quot;,&quot;P124&quot;] }</code><br><strong>Retention & compliance:</strong><br>- Audit retention config stored in <code>modConfig.RetentionDays</code> and export policy <code>modConfig.ExportToCentralAudit = True</code> triggers scheduled push. <br><strong>Test cases:</strong><br>- Export and re-import to Power Query; confirm <code>beforeJSON</code> fields parse and <code>Delta</code> computed as expected. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modBatchProcessing</strong> — Role: handle large-scale runs with chunking, checkpointing, resumability, and cap enforcement.<br><strong>Key functions & flow:</strong><br>1. <code>StartBatch(runOptions As Scripting.Dictionary)</code> — compute <code>chunkCount = ceil(totalRows / BatchSize)</code>, create <code>__Run_Plan</code> listing chunk ranges, pre-allocate <code>chunkId</code> GUIDs, and start first chunk with status <code>IN_PROGRESS</code>.<br>2. <code>ProcessChunk(chunkId As Long)</code> — process rows for chunk, stage results, call <code>CommitChunk(chunkId)</code>, and write checkpoint <code>lastProcessedRow</code>. Use <code>On Error</code> to capture chunk-level failure and allow restart from chunk boundary. <br>3. <code>ResumeBatch(runId As String)</code> — read <code>__Run_Status</code>, verify which chunks are stable, and resume the next <code>PENDING</code> chunk. <br>4. <code>EnforceDailyLimits(runId As String)</code> — aggregate <code>__DailyApplyTotals</code> and compare to <code>DailyAutoApplyCapRows</code> and <code>DailyAutoApplyCapAmount</code>. If exceeded, set <code>runStatus=AWAIT_REVIEW</code> and move remaining staged applies to review queue. <br>5. <code>ParallelizationGuidance()</code> — guidance only: split by orgUnit or costCenter, run independent workbooks on partitioned datasets, and centralize audit exports for consolidation; ensure partitioning keys are disjoint to avoid write conflicts. <br><strong>Operational notes:</strong><br>- Chunk commit size tuned to avoid Excel memory spikes (typical 500–2000 rows depending on row width).<br>- After each chunk commit, run a quick checksum and sample integrity check (first and last committed cell values match staging). </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modAuditExportHelpers</strong> — Role: create SQL-ready inserts, CSV/JSON exports, and compressed bundles for ingestion to external systems.<br><strong>Functions & operational details:</strong><br>1. <code>BuildSQLInsertScript(tableName As String, records As Collection, batchSize As Long) As String</code> — generate parameterized inserts and SQL transaction wrapper.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Escaping: double single-quotes for text; numeric fields left unquoted; JSON fields wrapped in single-quotes with proper escaping.<br>2. <code>WriteCSVFile(fullPath As String, records As Collection, delimiter As String)</code> — streaming writer with buffered IO; include header row and consistent quote handling. For very large records write in chunks and produce <code>part_0001.csv</code> etc.<br>3. <code>WriteJSONFile(fullPath As String, records As Collection)</code> — emit newline-delimited JSON (ndjson) to simplify ingestion by DB loaders.<br>4. <code>PackageExport(exportDir As String, destZip As String)</code> — call OS zip utility (Shell) or Windows COM <code>ICompression</code>. If SHA256 required, call external helper service or lightweight signed PowerShell script (ship with deployment artifacts). <br><strong>Audit contract:</strong><br>- Every exported file includes <code>manifest.json</code> with <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, <code>rowCount</code>, <code>fileChecksum</code>. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modUtilities</strong> — Role: shared helpers—logging, time utilities, user identity, safe range read/write, caching/memoization, regex utilities, and small helpers used across modules.<br><strong>Key utilities & design patterns:</strong><br>1. <code>GetCurrentUserId() As String</code> — attempt resolution in order: workbook property <code>OperatorUserId</code>, OS environment <code>USERNAME</code>, fallback to <code>UnknownUser</code>. Use this for <code>userId</code> audit fields.<br>2. <code>SafeRangeWrite(targetRange As Range, value As Variant, maxRetries As Long) As Boolean</code> — wrap <code>On Error</code> + retry + small delay; capture COM error numbers and map to transient vs fatal categories. Return <code>True</code> on success or <code>False</code> and write <code>SafeWriteFailed</code> audit row. <br>3. <code>SafeRangeRead(sourceRange As Range, defaultValue As Variant) As Variant</code> — similar wrapper for reads. <br>4. <code>MemoizeCall(cacheKey As String, computeFunc As Variant, ttlSeconds As Long) As Variant</code> — simple dictionary keyed by <code>runId &amp; cacheKey</code> storing computed results; clear at run end. <br>5. <code>RegexReplace(pattern As String, input As String, replaceWith As String) As String</code> — wrapper around VBScript <code>RegExp</code>, with precompiled patterns stored in module-level dictionary to reduce object creation overhead. <br>6. <code>FormatTimestamp(ts As Double) As String</code> — format to ISO-8601 <code>YYYY-MM-DDTHH:MM:SSZ</code> using UTC <code>Now</code> conversions. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modConfig</strong> — Role: central config and policy store; supports environment variants (dev/test/prod), export/import, validation, and governance controls.<br><strong>Functions and keys:</strong><br>1. <code>LoadConfig(env As String) As Scripting.Dictionary</code> — loads keys from hidden <code>__Config</code> sheet or external JSON path. Typical keys and defaults:<br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>BatchSize</code> (Default 1000) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>AutoApplyThreshold</code> (Default 0.88) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>ReviewerThreshold</code> (Default 0.70) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>DailyAutoApplyCapRows</code> (Default 1000) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>DailyAutoApplyCapAmount</code> (Default 1000000) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>GS_TimeoutSec</code> (Default 30) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>ExternalScorerUrl</code> (Default blank) <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>UserRoles</code> mapping (Operator/Reviewer/Admin) <br>2. <code>ValidateConfig() As Scripting.Dictionary</code> — returns <code>errors</code> collection if constraints violated (e.g., <code>ReviewerThreshold &lt; AutoApplyThreshold</code> flagged).<br>3. <code>PersistConfigSnapshot(runId As String) As Boolean</code> — write snapshot to <code>__Run_Config</code> with timestamp for reproducibility. <br>4. <code>ConfigUIBindings()</code> — provide helper to bind config sheet controls to live config values and capture change history to <code>Macro_ChangeLog</code>. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modMappingStore</strong> — Role: maintain canonical HR master data, alias table, and historical confirmed match crosswalks used for stage indexing.<br><strong>Functions & patterns:</strong><br>1. <code>LoadMasterStore(masterRange As Range) As Boolean</code> — loads master rows into <code>dictByCleanName</code>, <code>dictByEmployeeId</code>, and <code>dictTokenIndex</code> with value objects containing: <code>employeeId</code>, <code>fullName</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>hireDate</code>, <code>activeFlag</code>, <code>aliases[]</code>.<br>2. <code>ReloadMasterIfStale(thresholdMinutes As Long) As Boolean</code> — check <code>__Master_LastLoaded</code> and reload if older than threshold. <br>3. <code>UpsertAlias(aliasName As String, targetEmployeeId As String, createdBy As String)</code> — append alias and write <code>Alias_Log</code> entry; ensure alias canonical <code>clean</code> does not collide with existing employee <code>cleanName</code> unless explicitly allowed by admin. <br>4. <code>DetectPotentialDuplicateMaster()</code> — run fuzzy grouping across master using <code>NGramFingerprint</code> clustering and return groups for manual consolidation. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modAliasManagement</strong> — Role: reviewer-driven alias lifecycle and governance for mapping corrections.<br><strong>Functions & flows:</strong><br>1. <code>RequestAlias(alias As String, targetId As String, requestedBy As String)</code> — create request row with <code>requestId</code>, sample evidence, and status <code>PENDING</code>. Notify reviewers via UI <code>PendingAliasCount</code>. <br>2. <code>ApproveAlias(requestId As String, approverId As String)</code> — validate no conflicts, call <code>modMappingStore.UpsertAlias</code>, mark <code>APPROVED</code> with approver comment and audit row. <br>3. <code>RejectAlias(requestId As String, approverId As String, reason As String)</code> — mark <code>REJECTED</code> and return explanatory message to requester. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modMigration</strong> — Role: manage workbook schema and audit data migrations across releases; idempotent migration scripts and migration history tracking.<br><strong>Functions & workflow:</strong><br>1. <code>EnsureSchema(targetVersion As String)</code> — compares <code>__Schema_Version</code> and applies migrations from <code>__MigrationScripts</code> folder embedded in workbook or repository. Each migration must record execution in <code>__Migration_History</code>. <br>2. <code>MigrateAuditFormat(oldFormat As String, newFormat As String)</code> — transform legacy flat audit rows into nested JSON schema; create <code>__Migration_Backup_&lt;ts&gt;</code> snapshot. <br>3. <code>RollbackMigration(migrationId As String)</code> — restore snapshot and mark migration <code>REVERTED</code>. Require admin sign-off. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modSignatures</strong> — Role: light-weight provenance hashing and signature-like tokens for run-level and reviewer confirmations.<br><strong>Functions & constraints:</strong><br>1. <code>ComputeRunSignature(runId As String) As String</code> — compute deterministic hash combining <code>runId</code>, <code>userId</code>, <code>rowCount</code>, and <code>sealChecksum</code> using VBA SHA1 or MD5 (non-cryptographic acceptable for internal audit). Note: for legal-grade digital signature integrate external PKI. <br>2. <code>RecordReviewerSignature(runId As String, reviewerId As String, decisionHash As String)</code> — store signature entry in <code>__Signatures</code> sheet with timestamp and associated audit rows. <br>3. <code>VerifyRunSignature(runId As String, signedToken As String) As Boolean</code> — recompute and compare; write mismatch event if failed. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modMateriality</strong> — Role: materiality engine for escalation decisions and per-row special handling when monetary impact exceeds thresholds.<br><strong>Functions & rules:</strong><br>1. <code>EvaluateMateriality(rowData As Scripting.Dictionary) As Scripting.Dictionary</code> — compute absolute delta and relative delta vs <code>baseline</code> (e.g., prior year average), check against <code>modConfig</code> thresholds and return <code>flags</code> (<code>Escalate</code>, <code>ManualSplit</code>, <code>AutoAllowed</code>) with <code>rationale</code> string.<br>2. <code>AggregateMateriality(runId As String)</code> — produce run-level summary by <code>orgUnit</code>, <code>costCenter</code>, and <code>user</code> including <code>TopN</code> material rows. <br>3. <code>MaterialityPolicyEnforcer(runId As String)</code> — pre-commit gate: if <code>EscalateCount &gt; modConfig.MaxEscalationsBeforePause</code> then block commit and assign to reviewer queue. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modImpactSimulation</strong> — Role: simulate proposed changes, produce recon previews, and support what-if scenario exports for reviewers and finance analysts.<br><strong>Functions & usage:</strong><br>1. <code>SimulateRunPreview(runId As String, simulateOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — non-destructive PQ-style preview.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Steps: copy sample postings into <code>__Sim_&lt;runId&gt;</code>, join with <code>ApplyDescriptor</code> table, compute <code>Before</code>, <code>After</code>, <code>Delta</code>, group by <code>DisclosureBucket</code> x <code>Period</code>, mark <code>MaterialFlag</code> where <code>abs(Delta) &gt;= modConfig.MaterialityThreshold</code>.<br>2. <code>RunWhatIfAdjustments(simSheet As Worksheet, adjustments As Collection)</code> — apply ephemeral changes to Calculator, recalc, capture outputs, revert changes. Ensure <code>Application.Calculation</code> mode restored.<br>3. <code>ExportSimulationCSV(runId As String, destPath As String)</code> — create export for BI ingestion; include simulation manifest. <br><strong>Example output columns:</strong> <code>rowOrdinal, postingId, postingDate, originalAmount, adjustedAmount, delta, costCenter, disclosureBucket, evidenceRef</code>. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modBatchUtilities</strong> — Role: scheduling, replay, and automated safe replay for deterministic diagnosis and audit reconciliation.<br><strong>Functions & behaviors:</strong><br>1. <code>ScheduleRun(runOptions As Scripting.Dictionary, scheduledTime As Date)</code> — write to <code>__Run_Schedule</code> and optionally call external automation endpoint to trigger workbook execution. <br>2. <code>ReplayRun(originalRunId As String, replayOptions As Scripting.Dictionary)</code> — perform dry-run using same <code>configSnapshot</code> and <code>codeVersion</code>, compare new <code>Audit_Log</code> to original (ignoring <code>runId</code>, <code>timestamp</code> fields) and produce <code>diffReport</code> with <code>row-level diffs</code>. If identical, mark <code>ReplayVerified</code>. <br>3. <code>CompareRunDiffs(runIdA As String, runIdB As String)</code> — detailed row-level comparator returning <code>mismatchRows</code> with fields showing <code>beforeA</code>, <code>afterA</code>, <code>beforeB</code>, <code>afterB</code>, <code>reason</code>. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modConfigUI</strong> — Role: admin worksheet UI for controlled configuration edits, role mapping, and governance-approved changes.<br><strong>Functions & controls:</strong><br>1. <code>RenderConfigSheet()</code> — draw block UI with grouped controls, data validation lists, and "lock" controls for Admin-only fields. <br>2. <code>ApplyConfigChanges(changes As Scripting.Dictionary, appliedBy As String)</code> — validate, persist through <code>PersistConfigSnapshot</code>, and append <code>Macro_ChangeLog</code> entry with <code>changeId</code>, <code>diff</code>, and <code>signature</code>. <br>3. <code>ExportConfigToJSON(path As String)</code> — generate reproducible JSON. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modTestingHarness</strong> — Role: lightweight unit and regression test framework for deterministic verification in CI and pre-release gates.<br><strong>Capabilities and example tests:</strong><br>1. <code>RunUnitTests()</code> — run test cases for pure functions: <code>CleanName</code>, <code>LevenshteinDistance</code>, <code>NGramFingerprint</code>, <code>TokenKeyGeneration</code>. Results written to <code>__TestResults</code> and return pass/fail count.<br>2. <code>RunRegressionSuite(sampleWorkbookPath As String)</code> — run canonical dataset and compare <code>Audit_Log</code> against golden baseline using <code>CompareRunDiffs</code>. Exit non-zero when unexpected diffs. <br>3. <code>AutoSmokeTests()</code> — quick health checks (named ranges, Calculator cell formula test, PQ refresh) executed post-deploy. <br>4. <code>TestDataGenerator()</code> — generate synthetic edge-case rows: duplicate names, long names, names with diacritics, extreme amount values, postings with missing cost center, and pushing GoalSeek functions into non-convergent shapes. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: modTelemetry</strong> — Role: capture runtime telemetry (non-PII by default), error rates, external service reliability, GoalSeek statistics, and performance metrics for operations dashboards.<br><strong>Functions & patterns:</strong><br>1. <code>RecordTelemetryPoint(category As String, metrics As Scripting.Dictionary)</code> — append to <code>__Telemetry</code> with <code>utcTimestamp</code>, <code>runId</code>, <code>category</code>, <code>metricsJson</code> (hashed PII allowed if <code>modConfig.HashPII=True</code>).<br>2. <code>FlushTelemetryToExternal(endpoint As String)</code> — batched push using simple POST with retry/backoff (circuit breaker). <br>3. <code>TelemetrySummary(startDate As Date, endDate As Date)</code> — aggregate telem into summary metrics: <code>AvgRunDuration</code>, <code>PctGSConverged</code>, <code>ExternalScorerUptime</code>, <code>AutoApplyPrecisionEstimate</code> (if ConfirmedMatches available). </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Module: frmOperatorUI (worksheet UI + macros)</strong> — Role: compact operator interface to run previews, start runs, show last-run summaries, and execute safe rollback flows.<br><strong>Handlers & macros:</strong><br>1. <code>BtnRun_Click()</code> — collect UI options, validate via <code>ValidatePreRun</code>, call <code>modCoreEngine.RunUpdateHR</code> and show modal progress dialog with real-time counts. <br>2. <code>BtnPreview_Click()</code> — call <code>modCoreEngine.SimulateRunPreview</code>, render <code>ImpactReport</code> pane and provide <code>ExportSimulationCSV</code> link. <br>3. <code>BtnRollback_Click()</code> — request runId, show <code>__Stage_Backup_&lt;runId&gt;</code> snapshot preview, require reviewer override if material, call <code>RollbackRun</code>. <br>4. <code>ShowLastRunSummary()</code> — show quick stats from <code>__Run_Summary</code> sheet: rows processed, auto/applied, reviewCount, GSStats. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Operational & governance checklist (critical implementation controls):</strong><br>1. Code signing and release: require signed macro workbook for production; store signed artifacts in secure repo and log release metadata in <code>Macro_ChangeLog</code> including <code>commitHash</code>, <code>releaseTag</code>, <code>signedBy</code> and <code>signatureHash</code>.<br>2. Pre-run checklist enforced in UI: validated named ranges, calculator integrity, operator role, config snapshot, no active locks, PQ refresh success; if any fail show <code>PreRunBlocker</code> with error codes. <br>3. Reviewer gating: runs above row or monetary thresholds require reviewer sign-off before commit; implemented via <code>MaterialityPolicyEnforcer</code> and UI lock. <br>4. Immutable logging: export to central immutable DB recommended; local workbook audit required for operational troubleshooting but considered ephemeral. <br>5. Recovery & replay: chunk-level checkpointing and <code>ReplayRun</code> capability mandatory for production release. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Performance & scaling considerations:</strong><br>1. Hot-path optimization: operate on variant arrays, memoize <code>CleanName</code> and <code>NGramFingerprint</code>, pre-index master store, parallelize non-Excel work (external scorer) where possible. <br>2. Offload heavy scoring: external helper service for ML ranking, bulk fuzzy scoring, and batch GoalSeek offload; design service API careful to accept salted-hashed PII when required. <br>3. Batch sizing: tune <code>modConfig.BatchSize</code> for target hardware; measure memory/heap and reduce batch size if Excel becomes unstable. <br>4. GoalSeek scale: cap concurrent GS and use <code>runContext.TimeoutSec</code>, capture traces for non-convergent cases and escalate. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Testing & acceptance criteria mapping (traceable):</strong><br>1. Unit tests: 100% coverage on pure utilities; automated via <code>modTestingHarness.RunUnitTests</code>. <br>2. Regression tests: golden-run parity enforced via CI using <code>RunRegressionSuite</code>; diffs must be explicable (e.g., due to config changes) and approved. <br>3. Performance tests: full-run on representative hardware completes within <code>SLA</code> (TBD); measure <code>AvgTimePerRow</code> and <code>MaxMemory</code>. <br>4. Accuracy targets: auto-apply precision ≥ configured target (e.g., 98%) validated on held-out sample; record results in telemetry and acceptance report. <br>5. Resilience tests: simulate partial failures (external scorer down, manual calc mode) ensure deterministic rollback and correct audit entries. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Example conceptual Power Query (PQ) transforms (non-executable narrative & step-by-step):</strong><br>1. <strong>Audit ingestion PQ flow</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Source: CSV export from <code>modCoreEngine.GenerateRunReport</code> or <code>modAudit.ExportAudit</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;b) <code>Json.Document</code> parse for <code>beforeJSON</code>/<code>afterJSON</code> fields and <code>Record.FieldValues</code> expansion.<br>&nbsp;&nbsp;&nbsp;&nbsp;c) Expand nested fields to columns: <code>employeeId</code>, <code>costCenter</code>, <code>amountBefore</code>, <code>amountAfter</code>, <code>postingIds</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;d) Add computed column <code>Delta = amountAfter - amountBefore</code> and <code>DeltaPct = DIVIDE(Delta, amountBefore)</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;e) Group by <code>costCenter</code> and <code>period</code> for summarized BI tables. <br>2. <strong>Confirmed match training PQ flow</strong>:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Source: <code>ConfirmedMatches</code> CSV export. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Expand component feature columns (<code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>fuzzyScore</code>, <code>phoneticFlag</code>, <code>priorConfirmCount</code>) and include <code>label</code> (confirmed=1/rejected=0). <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Output flat table ready for ML pipeline export in NDJSON. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Example conceptual DAX measures (BI guidance & expanded):</strong><br>1. <code>AutoApplyRate = DIVIDE([AutoAppliedRows],[TotalProcessedRows])</code>.<br>2. <code>ReviewQueueDepth = COUNTROWS(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[Status]=&quot;REVIEW&quot;))</code>.<br>3. <code>AvgGoalSeekAttempts = AVERAGE(&#x27;GSMetrics&#x27;[Attempts])</code>.<br>4. <code>PctGSConverged = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[Status]=&quot;CONVERGED&quot;), COUNTROWS(&#x27;GSMetrics&#x27;))</code>.<br>5. <code>AutoApplyPrecision = DIVIDE([TruePositives],[TruePositives]+[FalsePositives])</code> where TP/FP derived from <code>ConfirmedMatches</code> ground truth samples. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Appendix: recommended idempotency & provenance patterns (detailed):</strong><br>1. <strong>Input hashing:</strong> compute <code>inputRowHash = SHA1(concat(normalizedKeyFieldsSorted))</code> where <code>normalizedKeyFieldsSorted</code> are the canonical columns that define uniqueness. Persist to <code>Audit_Log</code> before any mutation. <br>2. <strong>Staging-based commit:</strong> always stage <code>beforeJSON</code> + <code>afterJSON</code> into <code>__Stage_Run_&lt;runId&gt;</code>; commit by applying <code>afterJSON</code> values to target addresses during <code>CommitRun</code>. <br>3. <strong>Config & code versioning:</strong> store <code>codeVersion</code> (git commit) and <code>configSnapshot</code> (JSON) in every audit row. <br>4. <strong>Deterministic tie-breaking:</strong> always include tie-break keys in ranking: <code>sameEmployeeId</code> then <code>earliestHireDate</code> then <code>priorConfirmCount</code> then <code>candidateId lexicographic</code> to ensure deterministic ordering across runs. <br>5. <strong>Replay determinism:</strong> enable <code>ReplayRun</code> to reproduce decisions exactly (dry-run) using persisted <code>configSnapshot</code> and <code>codeVersion</code>; <code>inputRowHash</code> detect duplicates and skip repeated applies. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Operational handover deliverables (minimum):</strong><br>1. Signed macro workbook and deployment package with install script and checksums. <br>2. <code>Macro_ChangeLog</code>, release notes, and acceptance test report including test vectors and results. <br>3. Test harness sample workbooks, regression golden datasets, and <code>modTestingHarness</code> outputs. <br>4. Operational runbook: pre-run checklist, rollback instructions, escalation contacts, and troubleshooting steps. <br>5. Training slides and quick reference for operator and reviewer roles. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Risk matrix and mitigations (summary with actions):</strong><br>1. <strong>Data quality:</strong> duplicates/dirty names — mitigation: conservative auto-apply thresholds, alias management, reviewer workflows, and incremental rollout. <br>2. <strong>GoalSeek instability:</strong> pre-validate function shapes; per-row timeout, fallback algorithm, and trace capture. <br>3. <strong>External service dependency:</strong> circuit-breaker, local fallback scorers, telemetry alerting and graceful degradation to pure-VBA ranking. <br>4. <strong>Partial commits:</strong> staging + atomic commit + chunk checkpointing + automatic rollback on failure. <br>5. <strong>Tampering on local audit:</strong> export to central immutable DB; store run manifests and checksums off-workbook. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Helper service API contract (recommended minimal JSON schema)</strong>:<br><strong>POST /score</strong> — request:<br><code>{ &quot;runId&quot;: &quot;uuid&quot;, &quot;rowId&quot;: 123, &quot;features&quot;: { &quot;tokenOverlap&quot;: 0.6, &quot;trigramJaccard&quot;:0.4, &quot;fuzzyScore&quot;:0.85, &quot;phoneticFlag&quot;:1, &quot;priorConfirmCount&quot;:3 }, &quot;candidates&quot;:[ { &quot;candidateId&quot;:&quot;E123&quot;, &quot;employeeId&quot;:&quot;E123&quot;, &quot;orgUnit&quot;:&quot;Sales&quot; }, ... ] }</code><br>response:<br><code>{ &quot;rowId&quot;:123, &quot;topK&quot;:[ { &quot;candidateId&quot;:&quot;E123&quot;, &quot;mlScore&quot;:0.93, &quot;explain&quot;: {&quot;tokenOverlap&quot;:0.34,&quot;fuzzyScore&quot;:0.40} }, ... ], &quot;serviceVersion&quot;:&quot;v1.2.0&quot; }</code><br><strong>POST /bulk-score</strong> — accepts array of payloads for batched scoring. Support compression and authentication (Bearer token). Include <code>rateLimit</code> header in responses. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Sample ApplyDescriptor JSON (canonical order)</strong>:<br><code>{ &quot;runId&quot;:&quot;uuid&quot;, &quot;rowId&quot;:123, &quot;inputRowHash&quot;:&quot;sha1...&quot;, &quot;applyActions&quot;:[ { &quot;targetSheet&quot;:&quot;HR_Calculation&quot;, &quot;targetRange&quot;:&quot;M45&quot;, &quot;beforeValue&quot;:1234.56, &quot;afterValue&quot;:1250.00, &quot;field&quot;:&quot;salary&quot; } ], &quot;candidateId&quot;:&quot;E123&quot;, &quot;rationale&quot;:&quot;tokenOverlap 0.8;lev 0.95&quot;, &quot;userId&quot;:&quot;operator1&quot;, &quot;timestamp&quot;:&quot;2026-02-18T10:00:00Z&quot; }</code> </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Sample AuditRow JSON (single cell)</strong>:<br><code>{ &quot;runId&quot;:&quot;uuid&quot;, &quot;rowId&quot;:123, &quot;actionType&quot;:&quot;APPLY&quot;, &quot;inputRowHash&quot;:&quot;sha1...&quot;, &quot;beforeJSON&quot;:{...}, &quot;afterJSON&quot;:{...}, &quot;candidateId&quot;:&quot;E123&quot;, &quot;confidence&quot;:0.9123, &quot;componentBreakdown&quot;:{&quot;token&quot;:0.5,&quot;trigram&quot;:0.25,&quot;fuzzy&quot;:0.1623}, &quot;gsRef&quot;:&quot;gs_20260218_23&quot;, &quot;status&quot;:&quot;COMMITTED&quot;, &quot;userId&quot;:&quot;operator1&quot;, &quot;timestamp&quot;:&quot;2026-02-18T10:05:00Z&quot;, &quot;rowChecksum&quot;:&quot;crc32...&quot; }</code> </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Acceptance criteria checklist (operator / reviewer sign-off)</strong>:<br>- All pre-run validations pass.<br>- Dry-run simulation produced <code>ImpactReport</code> and reviewer signed if material changes present.<br>- Regression golden pass for CI-run no unexpected diffs.<br>- <code>AutoApplyPrecision</code> measured on sample ≥ configured threshold.<br>- Post-deploy smoke tests pass sample verification rows. </td></tr><tr><td data-label="HR-Budget Reconciliation Orchestrator (VBA)"> <strong>Final notes & recommended next steps for implementers:</strong><br>- Begin with a staged prototype: implement <code>modCoreEngine</code>, <code>modMatchingEngine</code> basic exact/token lookup, <code>modAudit</code>, and <code>modConfig</code>.<br>- Add <code>modFuzzyScores</code> with tuned thresholds and the <code>__Fuzzy_Tuning</code> report for threshold selection.<br>- Pilot external scorer integration with sample dataset and ensure privacy-preserving hashing before sending PII.<br>- Ensure automated unit/regression tests in CI before signing the macro workbook for production.<br>- Document all config keys and provide environment-based config snapshots for reproducibility.<br><strong>End of expanded per-function technical breakdown.</strong> </td></tr></tbody></table></div><div class="row-count">Rows: 36</div></div><div class="table-caption" id="Table2" data-table="Docu_0202_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — modCoreEngine (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — modCoreEngine (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Module: modCoreEngine — High-level purpose & guarantees</strong><br>The <code>modCoreEngine</code> module is the deterministic orchestration layer for UpdateHR+. It coordinates end-to-end runs: input ingest, canonicalisation, multi-stage matching delegation, GoalSeek orchestration when needed, transactional staging, chunked commit with read-back verification, deterministic rollback using pre-commit snapshots, audit/seal exports, telemetry, and interactions with reviewer/operator UI. The module is designed with the following guarantees and design commitments:<br>1. <strong>Determinism:</strong> Given identical inputs, config snapshot and codeVersion, decisions and produced <code>ApplyDescriptor</code> artifacts are reproducible across runs and replayable. <br>2. <strong>Idempotency:</strong> All input rows produce a stable <code>inputRowHash</code> which prevents double-apply and allows safe replay. <br>3. <strong>Atomicity & Recoverability:</strong> Writes are staged in <code>__Stage_Run_&lt;runId&gt;</code> with a full <code>__Stage_Backup_&lt;runId&gt;</code> snapshot; commit executes in well-defined chunks with persistent checkpoints so interrupted commits can be resumed or rolled back deterministically. <br>4. <strong>Provenance:</strong> Every decision and state-change is logged to <code>Audit_Log</code> with runId, userId, codeVersion, componentBreakdown, and checksums for tamper-evidence. <br>5. <strong>Least-privilege & enforced governance:</strong> Reviewer gating, daily caps, and signature capturing are enforced by the core engine before committing material changes. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Context & assumptions</strong><br>This breakdown assumes Desktop Excel VBA environment with signed macro workbook. Required workbook structural items: named range <code>staff_list</code>, <code>HR_Calculation</code> target sheet, <code>Detail_Budget</code> target sheet, <code>Calculator</code> sheet with stable formula cells. Operational hidden sheets used by the module: <code>__Stage_Run_&lt;runId&gt;</code>, <code>__Stage_Backup_&lt;runId&gt;</code>, <code>__Run_Status</code>, <code>__Telemetry</code>, <code>__GS_Metrics</code>, <code>__Run_Config</code>, <code>__Run_Summary</code>, <code>__Run_Locks</code>. <code>modConfig</code> provides tunables (BatchSize, thresholds, timeouts). Optional external helper services (ML scorer, telemetry API) may be available; the module must function fully offline using local algorithms. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: RunUpdateHR(staffRangeName As String, runOptions As Scripting.Dictionary) As Scripting.Dictionary — entry point</strong><br><strong>Purpose:</strong> orchestrate a complete run from ingest to optional commit and artifact export; return a structured runSummary.<br><strong>Inputs (runOptions common keys):</strong> <code>dryRun</code>(Boolean), <code>maxRows</code>(<code>Long|Optional</code>), <code>autoApplyThreshold</code>(<code>Double|Optional</code>), <code>userId</code>(String), <code>batchSize</code>(<code>Long|Optional</code>), <code>requireReviewer</code>(<code>Boolean|Optional</code>), <code>runTag</code>(<code>String|Optional</code>).<br><strong>Return (runSummary):</strong> dictionary includes <code>runId</code>, <code>status</code> (PREPARED/RUNNING/COMMITTED/ROLLED_BACK/FAILED/DRY_RUN_COMPLETE), <code>rowsProcessed</code>, <code>autoApplied</code>, <code>reviewCount</code>, <code>errors</code> (collection), <code>artifactPaths</code>.<br><strong>High-level algorithm (step-by-step):</strong><br>1. <code>ValidatePreRun(runOptions)</code> — check named ranges, calculator keys, workbook state and user role; collect validationErrors. If fatal, write RunError audit and return status=FAILED. <br>2. <code>AcquireLock()</code> — create run-level lock entry in <code>__Run_Locks</code>; fail fast if lock held. <br>3. Create deterministic <code>runId</code> (GUID + timestamp), call <code>modConfig.PersistConfigSnapshot(runId)</code> to freeze policy and settings. <br>4. <code>PrepareStaging(runId)</code> — create <code>__Stage_Run_&lt;runId&gt;</code> and <code>__Stage_Backup_&lt;runId&gt;</code>; support resume semantics if these sheets already exist. <br>5. Bulk load <code>staff_list</code> to a 2D Variant array and call <code>modMappingStore.LoadMasterStore()</code> to populate in-memory indexes. <br>6. Compute chunk plan using BatchSize; iterate rows in memory, call <code>ProcessStaffRow(runId,rowIndex,rowDict,stagingWS,resultOut)</code> for each; buffer staging writes and flush to <code>__Stage_Run_&lt;runId&gt;</code> in batches. <br>7. If <code>dryRun=True</code> or <code>runOptions(&quot;previewOnly&quot;)=True</code> call <code>FinalizeDryRun(runId)</code> and return runSummary with status=DRY_RUN_COMPLETE. <br>8. If commit allowed by policy and no blocking material escalations, call <code>CommitRun(runId)</code> then <code>FinalizeRun(runId)</code>; otherwise set run to AWAIT_REVIEW and surface UI tasks. <br>9. Release lock and return runSummary. <br><strong>Idempotency:</strong> RunUpdateHR computes <code>inputRowHash</code> for each input and checks existing Audit/Stage to skip duplicates; CommitRun checks sealed manifests to avoid double-commits. <br><strong>Telemetry & audit:</strong> run-level header written to <code>Audit_Log</code> with codeVersion, configSnapshotRef, startTime. Per-row telemetry buffered and flushed per chunk. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: ProcessStaffRow(runId As String, rowIndex As Long, rowData As Scripting.Dictionary, stagingWS As Worksheet, resultOut As Scripting.Dictionary) As Long — per-row orchestrator</strong><br><strong>Purpose:</strong> canonicalise input, call matching pipeline, evaluate materiality/policy, optionally run GoalSeek, and either stage an <code>ApplyDescriptor</code> or create a suggestion for UI review. Always generate a compact audit entry. <br><strong>Inputs:</strong> <code>rowIndex</code> (1-based), <code>rowData</code> keys expected: <code>rawName</code>, optional <code>employeeRef</code>, <code>amount</code> (Double), <code>costCenter</code>, <code>orgUnit</code>, <code>postingExample</code> (text), <code>effectiveDate</code>, <code>notes</code>. <br><strong>Outputs:</strong> numeric status code: <code>0=OK_AUTO</code>, <code>1=OK_SUGGEST</code>, <code>2=REVIEW_REQUIRED</code>, <code>3=NO_CANDIDATE</code>, <code>9=ERROR</code>. <code>resultOut</code> returns <code>candidateList</code> (Collection), <code>applyDescriptor</code> (dictionary or JSON), <code>rationale</code>, <code>timings</code> (matchingMs, gsMs). <br><strong>Detailed per-row steps:</strong><br>1. Compute <code>inputRowHash</code> via <code>ComputeInputHash(rowData)</code> using canonical fields sorted — store in resultOut for audit. <br>2. Idempotency: query <code>__Stage_Run_&lt;*any*&gt;</code> and <code>Audit_Log</code> for identical <code>inputRowHash</code>. If found and committed, return SKIPPED and write SKIP audit row. <br>3. Call <code>modMatchingEngine.CleanName(rawName, options)</code> to get <code>clean</code>, <code>tokens()</code>, <code>tokenKey</code>, <code>trigrams</code>. Attach to rowData. <br>4. Call <code>modMatchingEngine.RankCandidates(rowData, policy)</code> which runs Stage A–D (exact → token/phonetic → fuzzy → optional ML ranker) and returns Top-K candidates with componentBreakdown. <br>5. Call <code>modMateriality.EvaluateMateriality(rowData, topCandidate)</code> to compute absolute/relative delta and flags: <code>Escalate</code>, <code>AutoAllowed</code>, <code>ManualSplit</code>. <br>6. Decision logic (deterministic):<br>&nbsp;&nbsp;&nbsp;&nbsp;• If <code>employeeRef</code> strongly matches master => STRONG_MATCH => AUTO if AutoAllowed. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Else if <code>topCandidate.combinedScore &gt;= autoApplyThreshold</code> and AutoAllowed and daily caps OK => AUTO_STAGED. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Else if <code>combinedScore</code> in review band or ambiguous tie or Escalate => SUGGESTION/REVIEW. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Else NO_CANDIDATE. <br>7. If AUTO_STAGED: build <code>ApplyDescriptor</code> = <code>{ runId, rowOrdinal, inputRowHash, applyActions[], candidateId, componentBreakdown, evidenceRef, createdBy, createdAt }</code> where each <code>applyAction</code> is <code>{targetSheet,targetAddress,beforeValue,afterValue,field}</code>. Append to <code>stagingBuffer</code> or write to <code>stagingWS</code> in batch. <br>8. If REVIEW: create Suggestion payload and write to <code>__Suggest_Run_&lt;runId&gt;</code> for <code>frmReviewerUI</code> consumption; include Top-N candidate table and sample posting rows. <br>9. If numeric solve needed, call <code>modGoalSeekController.RunGoalSeek(targetCell, changingCell, targetValue, runContext)</code> and include GS trace reference <code>gsRef</code> in <code>applyDescriptor</code> or suggestion. If GS fails, mark GS_FAIL and route accordingly. <br>10. Append compact PROCESS audit row (status, candidateId summary, combinedScore, brief rationale) and emit telemetry (matchTimeMs, fuzzyComparisons, gsAttempts). <br><strong>Return codes semantics:</strong> 0 -> staged (PENDING commit), 1 -> suggestion created, 2 -> reviewer required, 3 -> no candidate/alias request created, 9 -> error (detailed error info placed in audit and <code>resultOut</code>). <br><strong>Performance notes:</strong> keep string operations and fuzzy comparisons bounded (use <code>modConfig.MaxFuzzyComparisonsPerRow</code>) and memoize repeated canonicalisations to avoid redundant work. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: PrepareStaging(runId As String) As Boolean — staging & backup creation</strong><br><strong>Purpose:</strong> create hidden staging and backup sheets, snapshot existing values for deterministic rollback, and enforce resume policies. <br><strong>Actions & schema:</strong><br>1. Create <code>__Stage_Run_&lt;runId&gt;</code> with explicit schema columns: <code>runId</code>, <code>rowOrdinal</code>, <code>inputRowHash</code>, <code>targetSheet</code>, <code>targetAddress</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>componentBreakdown</code> (JSON), <code>status</code> (PENDING/COMMITTED/FAILED/ROLLED_BACK), <code>applyChunkId</code>, <code>evidenceRef</code>, <code>createdBy</code>, <code>createdAt</code>, <code>rowChecksum</code>. <br>2. Create <code>__Stage_Backup_&lt;runId&gt;</code> containing rows: <code>targetSheet</code>, <code>targetAddress</code>, <code>beforeValueJSON</code>, <code>cellFormula</code> (if any), <code>cellFormatMeta</code> (number format, protection flag), and <code>backupRowChecksum</code>. <br>3. Set sheet visibility to <code>xlSheetHidden</code> and protect workbook if required by policy. <br>4. If a staging sheet already exists (resume case): validate <code>__Run_Status</code> for last checkpoint and return a resume descriptor containing <code>lastCommittedRow</code> and <code>nextRowToProcess</code>. <br><strong>Return:</strong> True if staging prepared or resumed successfully; False and <code>STAGING_FAILED</code> audit entry if workbook protections or other blocking errors prevent staging creation. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: CommitRun(runId As String) As Scripting.Dictionary — atomic apply of staged rows</strong><br><strong>Purpose:</strong> deterministically apply staged <code>afterJSON</code> cell values to workbook target addresses in chunked, checkpointed batches; perform verification and seal the run on success. <br><strong>High-level commit algorithm:</strong><br>1. Preconditions: validate <code>__Stage_Run_&lt;runId&gt;</code> exists and has PENDING rows; check <code>__Stage_Backup_&lt;runId&gt;</code> covers all unique target addresses. <br>2. Acquire commit window and set <code>Application.ScreenUpdating=False</code>, <code>Application.EnableEvents=False</code>, <code>Application.DisplayAlerts=False</code>, <code>Application.Calculation = xlCalculationManual</code> to minimize interruption. <br>3. Compute <code>rowChecksum</code> for each staged row and <code>preRunChecksum</code>; persist pre-commit manifest to <code>__Run_Status</code>. <br>4. Chunked commit loop by <code>modConfig.BatchSize</code>:<br>&nbsp;&nbsp;&nbsp;&nbsp;• Load chunk rows into 2D Variant array; group by <code>targetSheet</code> and contiguous <code>targetAddress</code> ranges to enable bulk Range assignments <code>Range.Value2 = variantArray</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• After each group write, perform optional readback verification: read target Range and compare normalized values to expected <code>afterJSON</code> values; record mismatch if any. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Mark staging rows COMMITTED, set <code>applyChunkId</code>, persist chunk checkpoint to <code>__Run_Status</code>, and optionally save workbook for durability. <br>5. On unrecoverable error (persistent COM exception or repeated mismatch): call <code>RollbackRun(runId, reason)</code> and set commitResult.status=FAILED with diagnostic payload (chunkId, sample rows, Err.Number/Err.Description). <br>6. On success for all chunks: compute final <code>runChecksum</code>, call <code>modAudit.SealAuditRun(runId)</code> to seal run, write <code>COMMITTED</code> manifest to <code>__Run_Status</code>, generate artifact exports via <code>modAuditExportHelpers</code>, and return <code>commitResult</code> with <code>committedCount</code>, <code>committedChunks</code>, <code>runChecksum</code>, and exported artifact paths. <br><strong>Idempotency & safety:</strong> If <code>__Run_Status</code> already shows sealed COMMITTED with <code>runChecksum</code>, CommitRun returns no-op manifest to avoid double-apply. <br><strong>Verification:</strong> verifying via readback reduces risk of data-type conversion mismatches (dates, numeric precision); normalization rules (e.g., rounding to cents, date formatting) must be applied before comparison. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: RollbackRun(runId As String, reason As String, options As Scripting.Dictionary) As Boolean — deterministic rollback</strong><br><strong>Purpose:</strong> restore workbook to pre-run state using <code>__Stage_Backup_&lt;runId&gt;</code>; create ForensicPack if full restore impossible. <br><strong>Steps:</strong><br>1. Preconditions: ensure <code>__Stage_Backup_&lt;runId&gt;</code> exists; otherwise write <code>ROLLBACK_IMPOSSIBLE</code> audit row and escalate. <br>2. Acquire rollback lock; set UI state to minimum; iterate backup rows and for each <code>targetAddress</code> execute <code>SafeRangeWrite(targetRange, beforeValue)</code> with retries. Collect <code>restoreResult</code> array entries <code>{targetSheet,targetAddress,status,errorInfo}</code>. <br>3. If all restores succeed: mark <code>__Stage_Run_&lt;runId&gt;</code> rows <code>ROLLED_BACK</code>, write <code>ROLLBACK_COMPLETED</code> audit row with restore metrics and return True. <br>4. If partial failures occur (cell protected, external link, formula mismatch): mark <code>ROLLBACK_PARTIAL</code>, produce <code>ForensicPack</code> (staging sheet, backup snapshot, <code>restoreResult</code>, <code>__Telemetry</code>, <code>__Run_Status</code>, GS traces) and store it in <code>__Forensics</code> with a manifest. Write <code>ROLLBACK_PARTIAL</code> audit entry and return False. <br><strong>Governance:</strong> material/large rollbacks require reviewer/Admin signature before executing; UI enforces approval gating. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: FinalizeRun(runId As String) As Scripting.Dictionary — sealing & export</strong><br><strong>Responsibilities:</strong> compute run metrics, seal the audit, export artifacts, and publish telemetry and summary to UI and central stores. <br><strong>Tasks:</strong><br>1. Aggregate metrics: <code>totalRows</code>, <code>stagedRows</code>, <code>committedRows</code>, <code>reviewCount</code>, <code>failedRows</code>, <code>avgMatchingMs</code>, <code>avgGSMs</code>, <code>commitTimeMs</code>, <code>runChecksum</code>. <br>2. Call <code>modAudit.SealAuditRun(runId)</code> to finalize the <code>Audit_Log</code> for the run and store <code>runChecksum</code> in <code>__Audit_Seals</code>. <br>3. Export artifacts using <code>modAuditExportHelpers.WriteJSONFile</code> / <code>WriteCSVFile</code> and <code>PackageExport</code> into a signed artifact <code>artifactZip</code> with <code>manifest.json</code> (includes <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, <code>rowCount</code>, <code>sealChecksum</code>). <br>4. Persist artifact paths and checksums in <code>__Run_Summary</code>, append <code>RUN_COMPLETED</code> audit header and write telemetry summary to <code>__Telemetry</code>. <br>5. Notify operator UI and create reviewer follow-up tasks if <code>MaterialityPolicyEnforcer</code> flagged items requiring approval. Return <code>finalReport</code> dictionary containing artifacts and open issues. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: FinalizeDryRun(runId As String) As Scripting.Dictionary — simulation preview</strong><br><strong>Purpose:</strong> apply staged descriptors non-destructively to historical postings inside <code>__Sim_&lt;runId&gt;</code> and produce an <code>ImpactReport</code> that reviewers can examine; do not modify primary sheets. <br><strong>Process:</strong><br>1. Build simulation sheet <code>__Sim_&lt;runId&gt;</code> by joining sample historical postings with <code>ApplyDescriptor</code> records. <br>2. Compute aggregated <code>Before</code>, <code>After</code>, <code>Delta</code>, <code>DeltaPct</code> grouped by <code>DisclosureBucket</code> and <code>Period</code>. Flag <code>MaterialFlag</code> where <code>abs(Delta)</code> exceeds <code>modConfig.MaterialityThreshold</code>. <br>3. Export simulation CSV and write <code>DRY_RUN</code> audit markers; create reviewer tasks linking to <code>__Sim_&lt;runId&gt;</code>. Return simulation artifact paths and metrics. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Public function: ValidatePreRun(runOptions As Scripting.Dictionary) As Collection — pre-flight checks</strong><br><strong>Purpose:</strong> perform comprehensive pre-run validation to reduce risk of mid-run failures. <br><strong>Checks performed (return <code>validationErrors</code> collection with severity):</strong><br>1. Named ranges existence: <code>staffRangeName</code>, <code>HR_Calculation</code> mapping ranges, <code>Detail_Budget</code> target ranges. <br>2. Calculator integrity: key calculator cells exist and their formula strings match expected regex patterns configured in <code>__Config</code>. <br>3. Workbook state: workbook not read-only if commit requested; <code>Application.Calculation</code> mode not Manual unless runOptions permit; no modal dialogs present. <br>4. Lock state: check <code>__Run_Locks</code> for active locks and detect orphaned locks older than <code>LockOrphanThresholdMins</code>. <br>5. Config & role validation: <code>modConfig.ValidateConfig</code> ensures BatchSize positive, thresholds sane, and <code>runOptions.userId</code> mapped in <code>modConfig.UserRoles</code>. <br>6. Run-level caps: check daily auto-apply caps and monetary thresholds to pre-flight block if the run would breach limits. <br><strong>Return:</strong> empty collection if all checks pass; otherwise list of errors/warnings. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Locking & concurrency helpers — AcquireLock / RefreshLock / ReleaseLock / DetectOrphanedLocks</strong><br><strong>Implementation notes:</strong><br>1. Use <code>__Run_Locks</code> hidden sheet to store lock rows: <code>lockToken</code>, <code>lockedBy</code>, <code>lockedAtUTC</code>, <code>expiresAtUTC</code>, <code>runId</code>. <br>2. <code>AcquireLock()</code> writes a lock row with TTL (e.g., 10 minutes) and requires the calling process to <code>RefreshLock</code> periodically (heartbeat). If lock present and not expired, return <code>LOCK_HELD</code> with owner metadata. <br>3. Forced takeover is allowed only for Admin with <code>ForceTakeover</code> path that writes an audit <code>FORCED_TAKEOVER</code> with reason and operatorId. <br>4. <code>DetectOrphanedLocks</code> scans locks with <code>lockedAtUTC</code> older than <code>LockOrphanThresholdMins</code> and flags for admin remediation. Ensure lock operations are atomic by writing a single row and immediately reading back to confirm lockToken presence. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Internal helper: ComputeInputHash(rowData As Scripting.Dictionary) As String — idempotency key</strong><br><strong>Algorithm & constraints:</strong><br>1. Select canonical immutable key fields: normalizedName (from <code>CleanName</code>), employeeRef (if present), costCenter, roundedAmount (cents), effectiveDate (ISO), and a stable postingKey derived from <code>postingExample</code>. <br>2. Sort keys alphabetically and concatenate <code>key=value</code> using <code>|</code> delimiter into stable string. <br>3. Compute SHA1 hex digest (or MD5 fallback in limited VBA environments) and return as <code>inputRowHash</code>. Persist this value to staging and audit for replay detection. <br><strong>Rationale:</strong> deterministic across runs and insensitive to non-essential fields or ordering. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Internal helper: Staging rowChecksum and run-seal model</strong><br><strong>Row checksum:</strong> compute <code>rowChecksum = CRC32(beforeJSON &amp; &quot;|&quot; &amp; afterJSON &amp; &quot;|&quot; &amp; candidateId)</code> and store per staged row. <br><strong>Run checksum:</strong> compute <code>runChecksum = SHA1(concat(sorted(rowChecksums)))</code> during sealing. <code>modAudit.SealAuditRun</code> writes <code>runChecksum</code> to <code>__Audit_Seals</code> and prevents UI from editing sealed runs without admin unseal. Use checksums for tamper evidence and audit integrity validation. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Telemetry & metrics (what modCoreEngine emits)</strong><br><code>__Telemetry</code> row schema: <code>timestampUTC</code>, <code>runId</code>, <code>rowOrdinal</code> (nullable), <code>category</code> (matching, goalseek, commit, chunk), <code>metricKey</code>, <code>metricValue</code>, <code>env</code>. <br>Per-row telemetry produced by <code>ProcessStaffRow</code>: <code>matchTimeMs</code>, <code>fuzzyComparisons</code>, <code>numCandidatesExamined</code>, <code>gsAttempts</code>, <code>gsTimeMs</code>, <code>decisionCode</code>. <br>Run-level telemetry: <code>totalRows</code>, <code>autoAppliedCount</code>, <code>reviewCount</code>, <code>avgMatchTimeMs</code>, <code>commitTimeMs</code>, <code>commitChunkCount</code>, <code>runChecksum</code>. Telemetry is buffered in memory and flushed to <code>__Telemetry</code> per chunk; <code>modTelemetry.FlushTelemetryToExternal</code> optionally posts redacted metrics to telemetry API. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Error taxonomy & canonical codes (used for UI & automation)</strong><br>List of canonical error codes and brief meaning:<br>1. <code>LOCK_HELD</code> — run lock not acquired; another process holds it. <br>2. <code>PRECHECK_FAILED</code> — pre-run validation discovered fatal problems. <br>3. <code>STAGING_FAILED</code> — could not create staging/backup (workbook protected or perms). <br>4. <code>MATCH_NO_CANDIDATE</code> — no candidate found; suggestion created. <br>5. <code>MATCH_AMBIGUOUS_TIE</code> — top candidates within tie window; reviewer selection required. <br>6. <code>GS_PRECHECK_FAIL</code> — GoalSeek pre-check detected unsafe function shape. <br>7. <code>GS_TIMEOUT</code> — GoalSeek timed out per run-level timeout. <br>8. <code>COMMIT_MISMATCH</code> — readback mismatch after write; requires rollback or manual intervention. <br>9. <code>ROLLBACK_PARTIAL</code> — rollback incomplete due to protected cells or external links. <br>10. <code>EXTERNAL_SCORER_UNAVAILABLE</code> — helper service unavailable; local fallback used. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Audit row design & sample shapes</strong><br><strong>Audit row fields (recommended):</strong> <code>runId</code>, <code>rowOrdinal</code>, <code>actionType</code> (PROCESS,SUGGEST,APPLY,COMMIT,ROLLBACK,DRY_RUN), <code>inputRowHash</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>combinedScore</code>, <code>componentBreakdown</code> (JSON), <code>gsRef</code>, <code>status</code>, <code>userId</code>, <code>timestamp</code>, <code>rowChecksum</code>. <br><strong>Sample minimal PROCESS audit (ndjson):</strong><br><code>{ &quot;runId&quot;:&quot;run-20260219-0001&quot;, &quot;rowOrdinal&quot;:5, &quot;actionType&quot;:&quot;PROCESS&quot;, &quot;inputRowHash&quot;:&quot;sha1:abcd...&quot;, &quot;candidateId&quot;:null, &quot;status&quot;:&quot;SUGGESTION_CREATED&quot;, &quot;componentBreakdown&quot;:{&quot;token&quot;:0.52,&quot;trigram&quot;:0.20,&quot;fuzzy&quot;:0.18}, &quot;userId&quot;:&quot;operator1&quot;, &quot;timestamp&quot;:&quot;2026-02-19T10:05:01Z&quot; }</code> <br><strong>ApplyDescriptor sample (staging):</strong> <code>{&quot;runId&quot;:&quot;run-20260219-0001&quot;,&quot;rowOrdinal&quot;:5,&quot;inputRowHash&quot;:&quot;sha1:abcd...&quot;,&quot;applyActions&quot;:[{&quot;targetSheet&quot;:&quot;HR_Calculation&quot;,&quot;targetRange&quot;:&quot;M123&quot;,&quot;before&quot;:50000.00,&quot;after&quot;:50234.00,&quot;field&quot;:&quot;salary&quot;}],&quot;candidateId&quot;:&quot;E123&quot;,&quot;rationale&quot;:&quot;token 0.6;lev 0.95&quot;,&quot;evidenceRef&quot;:&quot;posting-202602&quot;} </code> </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Power Query (PQ) conceptual transformations for modCoreEngine artifacts</strong><br><strong>Audit ingestion PQ flow (conceptual):</strong><br>1. Source: folder of NDJSON <code>Audit_&lt;runId&gt;.ndjson</code> exports. <br>2. PQ Step A: <code>Lines.FromBinary(File.Contents(...))</code> then each line <code>Json.Document()</code> to parse audit rows into records. <br>3. PQ Step B: expand <code>beforeJSON</code> and <code>afterJSON</code> fields with <code>Json.Document</code> into relational columns (<code>employeeId</code>, <code>costCenter</code>, <code>amountBefore</code>, <code>amountAfter</code>, <code>postingIds</code>). <br>4. PQ Step C: add computed columns: <code>Delta = amountAfter - amountBefore</code> and <code>DeltaPct = if amountBefore = 0 then null else Delta / amountBefore</code>. <br>5. PQ Step D: group by <code>DisclosureBucket</code> and <code>Period</code> for aggregated <code>ImpactReport</code>. <br><strong>ConfirmedMatches training PQ flow:</strong><br>1. Source: <code>ConfirmedMatches.csv</code> export or <code>ConfirmedMatches</code> table from audit. <br>2. Expand component features (tokenOverlap, trigramJaccard, fuzzyScore, priorConfirmCount) and label column <code>Confirmed</code> (1/0). <br>3. Output flat table ready for ML training (.ndjson export) or to feed into external model. <br><strong>PQ guidance & best practices:</strong> parse JSON early, promote types explicitly, avoid expensive row-level functions in PQ when possible, include <code>codeVersion</code> in dataset for regression analysis. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Conceptual DAX measures (BI monitoring & quality KPIs)</strong><br>1. <code>AutoApplyRate = DIVIDE( CALCULATE(COUNTROWS(Audit), Audit[ActionType]=&quot;APPLY&quot; &amp;&amp; Audit[Status]=&quot;COMMITTED&quot;), COUNTROWS(Audit) )</code>.<br>2. <code>AvgMatchingTimeMs = AVERAGE(Telemetry[matchTimeMs])</code>.<br>3. <code>GS_TimeoutRate = DIVIDE( CALCULATE(COUNTROWS(GSMetrics), GSMetrics[Status]=&quot;GS_TIMEOUT&quot;), COUNTROWS(GSMetrics) )</code>.<br>4. <code>MaterialEscalationCount = COUNTROWS(FILTER(RunDetail, RunDetail[MaterialFlag]=&quot;Escalate&quot;))</code>.<br>5. <code>CommitMismatchRate = DIVIDE( COUNTROWS(FILTER(Audit, Audit[Status]=&quot;COMMIT_MISMATCH&quot;)), COUNTROWS(FILTER(Audit, Audit[ActionType]=&quot;COMMIT&quot;)) )</code>. <br><strong>BI usage:</strong> combine these measures into dashboards showing run health (AutoApplyRate vs ReviewLoad), GoalSeek reliability, and material exposure by orgUnit/costCenter. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Concrete example walkthrough (narrative)</strong><br><strong>Scenario:</strong> operator runs UpdateHR for 1,850 staff rows with default config <code>BatchSize=500</code>, <code>AutoApplyThreshold=0.88</code>, <code>ReviewerThreshold=0.70</code>.<br>Sequence:<br>1. <code>ValidatePreRun</code> verifies <code>staff_list</code> exists, calculator cells present, user role operator OK. <br>2. <code>AcquireLock</code> obtains run lock and <code>runId=&quot;run-20260219-7283&quot;</code>. <br>3. <code>PrepareStaging</code> creates <code>__Stage_Run_run-20260219-7283</code> and <code>__Stage_Backup_run-20260219-7283</code> capturing <code>before</code> values for 1,200 targeted cells. <br>4. For each of 1,850 rows <code>ProcessStaffRow</code> runs: 1,610 produce <code>combinedScore &gt;= 0.88</code> and are AUTO_STAGED; 180 in review band (0.70–0.88) produce suggestions; 60 have no candidate and generate alias requests. Telemetry records matchTimeMs median 28ms. <br>5. CommitRun begins with 4 chunks (500, 500, 500, 350). Chunk 3 hits an intermittent COM error on a protected cell; commit detects COM error and calls <code>RollbackRun</code>. Rollback restores all cells from <code>__Stage_Backup_run-20260219-7283</code> successfully. <code>ROLLBACK_COMPLETED</code> audit row written. <br>6. Operator addresses protection issue, re-runs RunUpdateHR; resume path detects existing staging and resumes at last checkpoint; commit proceeds successfully and <code>FinalizeRun</code> seals the audit. <br>7. Artifacts exported: <code>Audit_run-20260219-7283.ndjson</code>, <code>ApplyDescriptors.csv</code>, <code>ImpactReport.csv</code>. Telemetry shows <code>PctGSConverged=100%</code> and <code>AutoApplyRate=87%</code> (auto-applies/total). </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Edge cases & mitigation strategies (common failure modes)</strong><br>1. <strong>Duplicate names & ambiguous matches:</strong> detect duplicates via token overlap + employee metadata (orgUnit, hireDate); route ambiguous groups to reviewer UI with side-by-side diffs. <br>2. <strong>Split payments / pooled receipts:</strong> surface multi-target suggestions with allocation options and <code>ManualSplit</code> flag, require reviewer split instructions before commit. <br>3. <strong>GoalSeek non-convergence:</strong> <code>modGoalSeekController.PreValidateFunctionShape</code> samples function; for non-monotonic shapes flag <code>GS_PRECHECK_FAIL</code> and create reviewer task with trace curve. Implement <code>IncrementalFallbackSearch</code> fallback with bounded attempts to avoid long stalls. <br>4. <strong>Workbook left in Manual calc or events disabled:</strong> <code>ValidatePreRun</code> warns and can set <code>Application.Calculation</code> to Automatic if permitted; ErrHandler always restores Application state on unexpected errors. <br>5. <strong>External scorer downtime:</strong> implement circuit-breaker in <code>modMatchingEngine.CallExternalScorer</code> with exponential backoff; fall back to local weighted ensemble ranking and record <code>EXTERNAL_SCORER_UNAVAILABLE</code> telemetry. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Testing strategy & representative test vectors</strong><br><strong>Unit tests (via <code>modTestingHarness</code>):</strong><br>1. <code>CleanName</code> variants: NBSP, diacritics, punctuation, multi-space collapse. <br>2. <code>ComputeInputHash</code> stability: same semantic inputs different order produce same hash. <br>3. <code>Levenshtein</code> banded with early abort tests. <br>4. <code>ProcessStaffRow</code> logic: exact employeeRef -> AUTO, high fuzzy -> AUTO, ambiguous tie -> REVIEW. <br><strong>Integration/regression tests:</strong><br>1. Golden-run parity: run <code>RunUpdateHR(dryRun=True)</code> on canonical sample workbook and compare <code>Audit_Log</code> to golden baseline via <code>ReplayRun</code>. <br>2. Commit-resume: inject simulated COM error during chunk commit and assert <code>RollbackRun</code> restores state and resume works. <br><strong>Performance tests:</strong> synthetic 50k row dataset to validate <code>AvgTimePerRow</code>, memory behavior, and chunk commit latencies; tune <code>BatchSize</code> accordingly. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Forensics & replay support (procedures)</strong><br>1. <strong>ForensicPack:</strong> created by <code>RollbackRun</code> or <code>modAudit.ValidateAuditIntegrity</code> bundling <code>__Stage_Run_&lt;runId&gt;</code>, <code>__Stage_Backup_&lt;runId&gt;</code>, <code>Audit_Log</code> slice, GS traces, telemetry, and manifest JSON; stored in <code>__Forensics</code> with checksum. <br>2. <strong>ReplayRun(originalRunId):</strong> re-run the same inputs against persisted <code>configSnapshot</code> and <code>codeVersion</code> in dry-run mode; compare produced dry-run audit to original audit ignoring runId/timestamps to validate reproducibility. Differences reported with <code>CompareRunDiffs</code>. <br>3. <strong>Incident triage:</strong> mark run <code>INCIDENT</code> in <code>__Run_Status</code>, prevent further commits, generate ForensicPack and open governance incident. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Security, privacy & governance (core rules)</strong><br>1. <strong>Code signing:</strong> production macro workbook must be signed and <code>codeVersion</code> recorded in each run manifest. <br>2. <strong>PII protection:</strong> hash/salt PII before sending to external services; <code>modCoreEngine</code> uses <code>runSalt</code> for memoization caches. <br>3. <strong>RBAC enforcement:</strong> <code>modConfig.UserRoles</code> mapping enforces Operator/Reviewer/Admin capabilities; high-dollar approves require Reviewer signature recorded via <code>modSignatures.RecordReviewerSignature</code>. <br>4. <strong>Audit export:</strong> recommend central immutable audit DB ingestion for long-term retention and tamper evidence; local workbook audit is for operational troubleshooting. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Developer guidance & implementation pitfalls</strong><br>1. Avoid <code>.Select</code> / <code>.Activate</code>; use Range objects and bulk <code>.Value2</code> assignments for speed and stability. <br>2. Use <code>Scripting.Dictionary</code> for in-memory indexes and clear references after chunk flush to avoid memory leaks. <br>3. Implement robust <code>On Error</code> handlers capturing <code>Err.Number</code>, <code>Err.Description</code>, <code>Erl</code> and write to <code>__Diagnostics_&lt;runId&gt;</code>. <br>4. Keep pure decision logic separated from side-effect staging so unit tests can exercise ranking and decision policies easily. <br>5. When comparing numeric or date values during commit verification, apply normalization (rounding to currency cents, ISO date formatting) to avoid false mismatches. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Acceptance criteria for modCoreEngine (traceable checklist)</strong><br>1. Unit tests for all pure functions pass (CleanName, hashing, fuzzy, PQ helpers). <br>2. Regression golden-run parity: canonical runs match golden <code>Audit_Log</code> modulo runId/timestamps. <br>3. Chunked commit + rollback resilience proven by simulated COM faults and successful full recovery. <br>4. Performance SLA: full-run for target volume completes within agreed SLA on representative hardware; <code>AvgTimePerRow</code> documented. <br>5. Accuracy: measured auto-apply precision ≥ configured target (e.g., 98%) on hold-out dataset; results in telemetry and acceptance report. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Implementation roadmap & suggested incremental milestones</strong><br>1. Prototype phase: implement <code>RunUpdateHR</code> skeleton, <code>ValidatePreRun</code>, <code>PrepareStaging</code>, and minimal <code>ProcessStaffRow</code> that calls <code>modMatchingEngine.StageA_ExactLookup</code> only; provide dry-run artifact export. <br>2. Local matching: implement <code>modMatchingEngine</code> Stage B–C with <code>modFuzzyScores</code> and <code>modMappingStore</code> indexes; add <code>ProcessStaffRow</code> decision logic and staging commit dry-run flows. <br>3. Commit & rollback: implement <code>CommitRun</code> chunking, readback verification, and <code>RollbackRun</code> restore. <br>4. UI & reviewer flows: wire <code>frmReviewerUI</code> and <code>modSuggestionUI</code> to present suggestions and capture decisions; integrate <code>modSignatures</code>. <br>5. Hardening & external services: optional ML scorer integration, telemetry flush, automated CI regression gating, code signing, and operational runbook finalization. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Conceptual PQ & DAX examples (copy-ready guidance)</strong><br><strong>PQ (audit ingestion) conceptual steps:</strong><br>1. <code>Source</code> -> From Folder <code>&lt;artifactDir&gt;</code>.<br>2. <code>Transform</code> -> <code>Lines.FromBinary(File.Contents(file))</code> then <code>Json.Document</code> each line. <br>3. <code>Expand</code> -> parse <code>beforeJSON</code> and <code>afterJSON</code> via <code>Json.Document</code> and expand fields to columns. <br>4. <code>AddColumns</code> -> compute <code>Delta = [afterAmount] - [beforeAmount]</code> and <code>DeltaPct = if [beforeAmount] = 0 then null else Delta / [beforeAmount]</code>. <br>5. <code>GroupBy</code> -> <code>DisclosureBucket</code>, <code>Period</code> to create pivot-ready ImpactReport. <br><strong>DAX measures copy-ready examples:</strong><br>1. <code>AutoApplyRate = DIVIDE( CALCULATE(COUNTROWS(Audit), Audit[ActionType]=&quot;APPLY&quot; &amp;&amp; Audit[Status]=&quot;COMMITTED&quot;), COUNTROWS(Audit) )</code>.<br>2. <code>AvgMatchingTimeMs = AVERAGE(Telemetry[matchTimeMs])</code>.<br>3. <code>MaterialEscalationCount = COUNTROWS(FILTER(RunDetail, RunDetail[MaterialFlag]=&quot;Escalate&quot;))</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>Final verification checklist (developer / reviewer)</strong><br>Before first production run, confirm:<br>1. <code>__Config</code> contains correct environment settings and <code>modConfig.PersistConfigSnapshot</code> works. <br>2. <code>staff_list</code> named range and all target mapping ranges exist and sample run passes <code>ValidatePreRun</code> with no FATALs. <br>3. Staging creation works and <code>__Stage_Backup_&lt;runId&gt;</code> contains correct <code>beforeValueJSON</code> for sample target addresses. <br>4. Commit & rollback tested end-to-end on a sanitized sample workbook and forensic packs generated on simulated failure. <br>5. <code>Macro_ChangeLog</code> contains codeVersion and release notes; signed macro artifact stored in secure repo. </td></tr><tr><td data-label="Per-function technical breakdown — modCoreEngine (VBA)"> <strong>If you want me to expand any single subheading above into even more rows (for example: provide 100 concrete test vectors, explicit PQ M code steps, a detailed DAX table with measure definitions and visuals guidance, or a full unit test suite in VBA), tell me which subheading to expand and I will expand that block next.</strong> </td></tr></tbody></table></div><div class="row-count">Rows: 29</div></div><div class="table-caption" id="Table3" data-table="Docu_0202_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modMatchingEngine (VBA)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modMatchingEngine (VBA)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Module purpose & high-level summary</strong><br>This module implements a deterministic, explainable, multi-stage matching pipeline used by UpdateHR+. It converts an input canonical record (staff_list row or posting sample) into an ordered set of candidate master records with component-level scores, textual rationales, and metadata suitable for audit, UI presentation, and ML training. The design emphasizes determinism, explainability, performance, safe fallbacks, and clear telemetry. Implementations must be pure-VBA first-class, with explicit extension points for an external scorer service. This table documents each public function and major internal helper, parameters and returns, expected side-effects, error codes, audit points, performance considerations, testing vectors, PQ integration guidance, and conceptual DAX for monitoring. <br><br> <strong>Core design constraints & invariants enforced by the module</strong><br>1. Deterministic canonicalisation: identical raw input and config produce identical outputs.<br>2. Auditable provenance: every decision emits a structured rationale and componentBreakdown to <code>Audit_Log</code>.<br>3. Idempotency: decisions reference <code>inputRowHash</code> and <code>runId</code>; replays detect duplicates and avoid double-writes.<br>4. Prefilter-first: expensive fuzzy computations are only applied to prefiltered candidate subsets.<br>5. Pluggable ranking: four stages (A exact, B token+phonetic, C fuzzy, D ML/ensemble) with deterministic fallbacks.<br>6. Telemetry-by-run: stage-level timing, counts, and error codes written to <code>__Match_Metrics</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>InitializeMatching(runId As String, config As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: prepare the module for a run by loading and indexing master data, alias/prior mappings, and initializing in-memory caches and runtime config.<br>Inputs: <code>runId</code> (string), <code>config</code> dictionary with keys including <code>MaxFuzzyComparisonsPerRow</code>, <code>TopK</code>, <code>PhoneticAlgorithm</code>, <code>NGramSize</code>, <code>PrefilterTrigramThreshold</code>, <code>UseExternalScorer</code>, <code>ExternalScorerUrl</code>.<br>Outputs: dictionary <code>{ ok:Boolean, errors:Collection, masterCount:Long, aliasCount:Long, initTimeMs:Double }</code>.<br>Behaviour & steps:<br>1. Validate presence of required named ranges: <code>HRMaster</code>, <code>AliasStore</code>, <code>PriorMappings</code>. If missing return <code>ok=False</code> with <code>errors</code> containing <code>MASTER_MISSING</code> or <code>ALIASES_MISSING</code>.<br>2. Load master rows into in-memory dictionaries: <code>dictByCleanName</code>, <code>dictByEmployeeId</code>, <code>dictTokenIndex</code>, <code>dictTrigramIndex</code>. Each entry stores minimal metadata: <code>candidateId</code>, <code>employeeId</code>, <code>fullName</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>activeFlag</code>, <code>hireDate</code>, <code>priorConfirmCount</code>.<br>3. Precompute canonical fingerprints for master rows matching the <code>CleanName</code> algorithm (tokenKey + trigrams). Save <code>masterLoadTimeMs</code> and <code>dictSizes</code> to return value and telemetry.<br>4. Initialize memo caches (<code>dictFuzzyMemo</code>, <code>dictPhoneticMemo</code>) keyed by <code>runId</code> so they are invalidated at run end.<br>5. Load <code>modConfig</code> weights and policy thresholds into local <code>matchConfig</code> object for use by ranking functions.<br>Failure modes & remediation:<br>- If master load exceeds memory or VBA collection limits, return <code>ok=False</code> with error <code>MASTER_TOO_LARGE</code>. Recommend partitioning or using external scorer. <br>Telemetry: write <code>InitializeMatching</code> latency to <code>__Match_Metrics</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>CleanName(rawName As String, options As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: deterministic canonicalisation of raw text fields into stable tokens and fingerprints consumed by later stages.<br>Inputs: <code>rawName</code> string; <code>options</code> may include <code>stripAccents</code> (Bool), <code>collapseSpaces</code> (Bool), <code>preserveNumbers</code> (Bool), <code>stopwordList</code> (Collection).<br>Outputs: dictionary with keys: <code>raw</code>, <code>clean</code>, <code>tokens</code>(array), <code>tokenKey</code>(string), <code>trigrams</code>(array), <code>numericSuffixes</code>(array), <code>hasNumericToken</code>(Bool), <code>fingerprint</code>(short string).<br>Processing rules (applied in order):<br>1. Replace NBSP and all unicode non-breaking spaces with regular space; optionally normalize other whitespace to single space.<br>2. Trim leading/trailing spaces; collapse sequential spaces if configured.<br>3. Convert to lowercase (culture-invariant).<br>4. Optional accent/diacritic stripping using a deterministic mapping table (store mapping as module-level resource to guarantee reproducibility).<br>5. Remove outer punctuation and parentheses but preserve internal apostrophes and hyphens where semantically important (configurable).<br>6. Tokenize on whitespace and punctuation; produce <code>tokens</code> array; numeric tokens are flagged; optionally removed into <code>numericSuffixes</code> if <code>preserveNumbers=False</code>.<br>7. Generate <code>tokenKey</code>: deterministic fingerprint for exact lookups — preserve first N tokens in order (configurable, default 3) and append sorted remainder to reduce sensitivity to title/suffix order changes.<br>8. Generate <code>trigrams</code>: sliding 3-char grams of the <code>clean</code> string without spaces for trigram Jaccard prefiltering.<br>Explainability: return both <code>raw</code> and <code>clean</code> to allow audit to show mapping. <br>Example (conceptual):<br>- raw: <code>&quot;Dr. María-José López  III&quot;</code> → clean: <code>&quot;maria-jose lopez iii&quot;</code>, tokens: <code>[&quot;maria-jose&quot;,&quot;lopez&quot;,&quot;iii&quot;]</code>, tokenKey: <code>&quot;maria-jose|lopez|iii&quot;</code>, trigrams: <code>[&quot;mar&quot;,&quot;ari&quot;,&quot;ria&quot;,...]</code>. <br>Edge-cases & tests: multi-byte characters, long names (>255 chars), names with embedded employee codes. Provide unit tests covering these. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>StageA_ExactLookup(cleanRec As Scripting.Dictionary, topK As Long) As Collection</code></strong><br>Purpose: immediate exact-match retrieval using canonical fingerprint and alias/prior-mapping crosswalks; extremely fast, low-cost stage.<br>Inputs: <code>cleanRec</code> (result of <code>CleanName</code>), <code>topK</code> (requested maximum candidates).<br>Outputs: collection of candidate objects, each containing: <code>candidateId</code>, <code>employeeId</code>, <code>fullName</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>source</code> (<code>master|alias|prior</code>), <code>matchedKey</code> (tokenKey or fingerprint), <code>matchedRule</code> = <code>&quot;A_EXACT&quot;</code>, <code>tieCandidate</code> flag if multiple identical matches found.<br>Behaviour:<br>1. Lookup <code>cleanRec.tokenKey</code> in <code>dictByCleanName</code>; if found, retrieve candidate list. <br>2. If not found and <code>cleanRec.numericSuffixes</code> present, try numeric-augmented fingerprint lookup. <br>3. Check alias store for explicit alias matches and include those candidates with source <code>&quot;alias&quot;</code>. <br>4. If more candidates than <code>topK</code>, apply deterministic tie-break ordering: prefer <code>activeFlag</code> true, then <code>sameOrg</code> if input has org hint, then earliest <code>hireDate</code>, then <code>candidateId</code> lexicographic. <br>5. If multiple exact matches remain equal after tie-break rules, set <code>AmbiguousExact</code> flag and return list for reviewer resolution.<br>Audit: include <code>matchedRule</code> and <code>matchedKey</code> in candidate metadata for auditability. <br>Performance: O(1) dictionary lookups; ensure <code>dictByCleanName</code> pre-warming in <code>InitializeMatching</code> to avoid runtime sheet accesses. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>StageB_TokenPhoneticLookup(cleanRec As Scripting.Dictionary, options As Scripting.Dictionary, topK As Long) As Collection</code></strong><br>Purpose: retrieve partial matches using token overlap and phonetic similarity; produces ranked candidates with token overlap and phonetic counts used downstream.<br>Inputs: <code>cleanRec</code>, <code>options</code> with <code>phoneticAlgorithm</code> (e.g., <code>&quot;doublemetaphone&quot;</code>), <code>minTokenOverlap</code> (0..1), <code>maxCandidatesPrefilter</code> (Int), <code>ignoreTokensList</code>.<br>Outputs: candidate collection where each candidate contains: <code>candidateId</code>, <code>tokenOverlapCount</code>, <code>tokenOverlapRatio</code>, <code>phoneticMatchCount</code>, <code>phoneticScore</code>, <code>matchedTokens[]</code>, <code>matchedRule</code> = <code>&quot;B_TOKEN_PHONETIC&quot;</code>, <code>prefilterScore</code>.<br>Process & optimizations:<br>1. For each token in <code>cleanRec.tokens</code>, query <code>dictTokenIndex[token]</code> to build a frequency map of candidateIds. Exclude tokens in <code>ignoreTokensList</code> or tokens with very high global frequency (> configured stoplist threshold).<br>2. Compute <code>tokenOverlapCount</code> and <code>tokenOverlapRatio = tokenOverlapCount / inputTokenCount</code> for each candidate; drop candidates below <code>minTokenOverlap</code> to limit subsequent work.<br>3. Compute phonetic tokens for input tokens (cache phonetic transforms in <code>dictPhoneticMemo</code>) and intersect with candidate phonetic tokens to compute <code>phoneticMatchCount</code> and <code>phoneticScore = phoneticMatchCount / inputTokenCount</code>.<br>4. Rank by <code>prefilterScore = w_overlap*tokenOverlapRatio + w_phonetic*phoneticScore</code> (weights configurable), output top <code>maxCandidatesPrefilter</code> items. <br>5. Provide <code>matchedTokens[]</code> and <code>evidenceRef</code> (example master fields or matched alias ids) for explainability. <br>Deterministic tie-breaker: if identical prefilterScore, fall back to <code>priorConfirmCount</code>, <code>sameOrg</code>, earliest <code>hireDate</code>, <code>candidateId</code>. <br>Performance considerations:<br>- Keep <code>dictTokenIndex</code> as candidateId arrays stored in memory; use frequency thresholds to avoid exploding candidate buckets on common tokens. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>StageC_FuzzyLookup(cleanRec As Scripting.Dictionary, candidatePrefilter As Collection, options As Scripting.Dictionary, topK As Long) As Collection</code></strong><br>Purpose: compute high-fidelity fuzzy similarity using normalized Levenshtein (banded DP), n-gram Jaccard, and optionally other metrics; produce <code>fuzzyComposite</code> and component breakdown.<br>Inputs: <code>cleanRec</code>, <code>candidatePrefilter</code> (from StageB or StageA fallback), <code>options</code> includes <code>MaxFuzzyComparisonsPerRow</code>, <code>NGramSize</code> (default 3), <code>FuzzyWeights</code> map, <code>EarlyExitMargin</code>.<br>Outputs: collection of top candidates annotated with: <code>levDistance</code> (int), <code>levScore</code> (0..1), <code>jaccardN</code> (0..1), <code>sigmoidScaledScore</code> (0..1), <code>fuzzyComposite</code>, <code>componentBreakdown</code> map, <code>matchedRule</code> = <code>&quot;C_FUZZY&quot;</code>.<br>Implementation & performance controls:<br>1. Prefilter candidatePrefilter by trigram overlap (quick set intersection on precomputed trigram sets) and sort by trigram potential; only proceed to Levenshtein for top <code>MaxFuzzyComparisonsPerRow</code> candidates. <br>2. Normalized Levenshtein: implement a banded algorithm that restricts computation to <code>|i-j|</code> <= bandWidth derived from expected distance to accelerate typical near-matches. Turn raw distance into <code>levScore = 1 - (distance / maxLen)</code> with clamp 0..1. <br>3. N-gram Jaccard computed on precomputed trigram sets for input and candidate: <code>jaccard = intersectionSize / unionSize</code>. <br>4. Combine: <code>fuzzyComposite = FuzzyWeights.lev*levScore + FuzzyWeights.jaccard*jaccardN + FuzzyWeights.token*tokenOverlapRatio</code>. Normalize result to 0..1. <br>5. Early-exit: maintain running top-K composite threshold; if a candidate's maximum possible composite (upper bound computed from partial metrics) cannot beat the current min top-K score, skip computing Levenshtein. <br>6. Memoization: <code>dictFuzzyMemo</code> caches normalized fuzzy results keyed by <code>(inputFingerprint, candidateFingerprint)</code>. Ensure cache invalidation per <code>runId</code>. <br>Telemetry: record <code>comparisonsDone</code> and <code>avgLevMs</code> for tuning. <br>Edge cases: very long strings (>300 chars) — fall back to n-gram only or truncate to safe length with documented rationale in audit. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>StageD_MLRanker(featureVectors As Collection, config As Scripting.Dictionary, topK As Long) As Collection</code></strong><br>Purpose: optional ML-based ranker (external service or local ensemble) to produce final ML scores and ranked candidates with explanation. This stage unifies numeric features into a learned score when available, otherwise falls back to deterministic ensemble.<br>Inputs: <code>featureVectors</code> where each item contains: <code>candidateId</code>, <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>levScore</code>, <code>phoneticScore</code>, <code>priorConfirmCount</code>, <code>sameOrgFlag</code>, <code>materialFlag</code>, <code>amountDiffNormalized</code>, etc. <code>config</code> includes <code>UseExternalScorer</code> (Bool), <code>ExternalScorerUrl</code>, <code>AuthToken</code>, <code>TimeoutSec</code>.<br>Outputs: ordered collection with <code>candidateId</code>, <code>mlScore</code> (0..1), <code>mlRank</code>, <code>mlExplain</code> (compact feature importances or textual reason), <code>serviceVersion</code> (if external), <code>fallbackUsed</code> flag.<br>Behaviour:<br>1. If <code>UseExternalScorer=True</code> and service reachable: assemble JSON payload (runId, rowId, featureVectors up to batchSize), POST with auth and timeout, parse response into <code>topK</code>. Implement retry/backoff and a circuit-breaker: after N consecutive failures mark service <code>UNAVAILABLE</code> for <code>circuitTimeoutSecs</code> and fallback to local ensemble.<br>2. Local ensemble: compute <code>mlScore = normalizedWeightedSum(features)</code> using weights from <code>modConfig</code> or admin UI; optionally apply monotonic calibrator (sigmoid) to map raw score into 0..1 with improved splitting behavior.<br>3. <code>mlExplain</code>: for local ensemble include top 3 contributing features with their contribution values; for external scorer copy returned feature importances into <code>mlExplain</code>. <br>Governance & privacy:<br>- If sending payload to external service, respect <code>modConfig.ExternalScorerPIIAllowed</code>: if false, send hashed/salted names and keep salt id in payload for traceability. Log call id and response id to <code>Audit_Log</code>. <br>Telemetry: track external scorer <code>latencyMs</code>, <code>httpStatus</code>, <code>responseSize</code> and <code>fallbackCount</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>RankCandidates(candidateSet As Collection, policy As Scripting.Dictionary, topK As Long) As Collection</code></strong><br>Purpose: final deterministic merge and band assignment; combine component and ML scores into <code>finalScore</code>, decide <code>confidenceBand</code> (AUTO/REVIEW/MANUAL), and detect ambiguous ties requiring human review.<br>Inputs: <code>candidateSet</code> where each item includes <code>componentBreakdown</code> and optional <code>mlScore</code>; <code>policy</code> contains <code>autoApplyThreshold</code>, <code>reviewThreshold</code>, <code>tieWindow</code>, <code>materialityOverrideRules</code> and <code>topK</code> fallback settings.<br>Outputs: ordered collection of <code>topK</code> candidates with fields: <code>candidateId</code>, <code>finalScore</code> (0..1), <code>confidenceBand</code> (<code>AUTO</code>/<code>REVIEW</code>/<code>MANUAL</code>), <code>componentBreakdown</code>, <code>rationale</code> (text), <code>ambiguousTie</code> (Bool), <code>tieReason</code> (if set).<br>Ranking algorithm & rules:<br>1. Compute <code>finalScore</code>: if <code>mlScore</code> present and <code>policy.useMlWhenAvailable</code> true then <code>finalScore = alpha*mlScore + (1-alpha)*componentEnsembleScore</code> (alpha configurable). Otherwise compute deterministic ensemble: weighted sum of tokenOverlap, trigramJaccard, fuzzyComposite, priorWeight, sameOrgBonus, signatureBonus.<br>2. Apply banding:<br>&nbsp;&nbsp;&nbsp;&nbsp;- <code>AUTO</code> if <code>finalScore &gt;= autoApplyThreshold</code> and <code>materialFlag=False</code> and not <code>ambiguousTie</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;- <code>REVIEW</code> if <code>finalScore &gt;= reviewThreshold and finalScore &lt; autoApplyThreshold</code> OR <code>ambiguousTie=True</code> OR <code>materialFlag=True</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;- <code>MANUAL</code> otherwise.<br>3. Ambiguous tie detection: if <code>finalScore(top1) - finalScore(top2) &lt;= tieWindow</code> OR if top candidates' componentBreakdowns show conflicting dominant rules (e.g., exact vs fuzzy) set <code>ambiguousTie=True</code> and include <code>tieReason</code> enumerating factors.<br>4. Deterministic ordering: after score sort, apply stable tie-breakers: sameEmployeeId first, <code>priorConfirmCount</code>, <code>activeFlag</code>, earliest hireDate, <code>candidateId</code> lexical. <br>5. Build <code>rationale</code> string: concise human-readable summary of top contributing components and any tie-break rule used. Also include structured <code>componentBreakdown</code> for audit. <br>Audit point: output full <code>candidateRank</code> list persisted to <code>Audit_Log</code> for that row. <br>UI output: include <code>evidenceRef</code> (posting examples, prior mapping id) for reviewer display. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>CallExternalScorer(payload As Scripting.Dictionary, endpoint As String, options As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: wrapper for reliable calls to external scoring/matching microservice with retries, circuit-breaker and PII-sanitisation options.<br>Inputs: <code>payload</code> (runId, rowId, featureVectors), <code>endpoint</code> URL, <code>options</code> includes <code>timeoutSec</code>, <code>maxRetries</code>, <code>authToken</code>, <code>hashPII</code> (Bool), <code>saltId</code> (string).<br>Outputs: dictionary <code>{ status, topK:Collection, serviceVersion, latencyMs, errorCode }</code>.<br>Behaviour:<br>1. If <code>options.hashPII=True</code> perform deterministic salted hashing of PII fields (name, employeeId) using salt from <code>modConfig</code> or provided <code>saltId</code>. Include <code>hashSaltId</code> in payload metadata for traceability.<br>2. HTTP POST with <code>authToken</code> header and <code>timeoutSec</code>. Implement <code>maxRetries</code> with exponential backoff. On HTTP 5xx or network error, retry; on 4xx treat as permanent and return error.<br>3. Circuit-breaker: maintain <code>externalScorerState</code> module-level status; on <code>N</code> consecutive failures set state to <code>OPEN</code> for <code>circuitTimeoutSecs</code>, immediately return fallback result instead of blocking. Track <code>failureCount</code> and <code>lastFailureTs</code>.<br>4. On success parse <code>topK</code> candidates and map back to local candidateIds; validate returned candidateIds are present in local <code>dictByEmployeeId</code> or log unmapped candidates as warnings. <br>Security & privacy: always prefer TLS connections and require <code>authToken</code>. Log minimal request/response meta to <code>__Telemetry</code> and full response only to secure central audit if configured. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Public function: <code>PersistMatchDecision(runId As String, rowId As Long, chosen As Scripting.Dictionary, decisionMeta As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: record an applied decision (auto or reviewer) persistently to <code>Audit_Log</code> and optionally to <code>ConfirmedMatches</code> for ML feedback.<br>Inputs: <code>runId</code>, <code>rowId</code>, <code>chosen</code> (candidate metadata), <code>decisionMeta</code> with keys: <code>decisionType</code> (AUTO/REVIEW_APPROVE/REJECT/SPLIT), <code>userId</code>, <code>rationale</code>, <code>signatureToken</code>, <code>materialFlag</code>.<br>Outputs: <code>{ ok:Boolean, auditRowId:Long, persistedToConfirmedMatches:Boolean }</code>.<br>Sequence and invariants:<br>1. Validate idempotency: compute or check <code>decisionToken = SHA1(runId &amp; &quot;|&quot; &amp; rowId &amp; &quot;|&quot; &amp; chosen.candidateId &amp; &quot;|&quot; &amp; decisionMeta.userId)</code> and check <code>Audit_Log</code> for existing row with same <code>decisionToken</code>. If found return <code>ok=True</code> with existing <code>auditRowId</code> (no double-write).<br>2. Compose <code>auditRec</code> with full fields: <code>runId</code>, <code>rowId</code>, <code>inputRowHash</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>componentBreakdown</code>, <code>finalScore</code>, <code>decisionType</code>, <code>userId</code>, <code>timestamp</code>, <code>decisionToken</code>, <code>evidenceRef</code>, <code>signatureToken</code> (if present).<br>3. Append via <code>modAudit.AppendAuditRow</code> and write to <code>ConfirmedMatches</code> only when <code>decisionType</code> is approval and <code>decisionMeta.persistForTraining=True</code>. For training entries, include <code>featureVector</code> and <code>label=1</code> (approved) or <code>label=0</code> (rejected).<br>4. Enforce materiality block: if <code>materialFlag=True</code> and <code>decisionType=AUTO</code> throw <code>MATERIALITY_BLOCK</code> error and require reviewer sign-off. <br>5. Return success and auditRowId. <br>Governance: ensure <code>ConfirmedMatches</code> exports anonymise PII if <code>modConfig.ExternalScorerPIIAllowed</code> false. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Internal helper: <code>ComputeFeatureVector(cleanRec As Scripting.Dictionary, candidate As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: build normalized numeric features used by the ML ranker and local ensemble; central place for normalization logic and missing-value defaults.<br>Standard feature schema (normalized 0..1 unless stated otherwise):<br>- <code>tokenOverlap</code> = intersection(tokens) / inputTokenCount.<br>- <code>trigramJaccard</code> = trigramIntersection / trigramUnion.<br>- <code>levScore</code> = 1 - (levDistance / maxLen).<br>- <code>phoneticScore</code> = phoneticMatches / inputTokenCount.<br>- <code>priorConfirmCountNormalized</code> = min(priorConfirmCount, X)/X with X configurable.<br>- <code>sameOrgFlag</code> = 1 if org matches else 0.<br>- <code>hireDateAgeMonthsNormalized</code> = (now - hireDate)/maxMonths capped at 1.<br>- <code>amountDiffNormalized</code> = abs(inputAmount - candidateAvgAmount)/maxAmountCap capped at 1.<br>Behaviour:<br>1. Always return full feature set with deterministic ordering of keys.<br>2. Use safe defaults for missing source values (0) and record missing indicators in feature vector to aid model training. <br>Explainability: include short text description per feature in returned map for use by UI or <code>mlExplain</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Internal helper: <code>DeterministicTieBreak(candidates As Collection) As String</code></strong><br>Purpose: when two or more candidates are equal or within <code>tieWindow</code>, return deterministic single winner key and a textual <code>tieReason</code> enumerating the tie-break steps applied.<br>Tie-break order (apply sequentially until one candidate selected):<br>1. Exact-match priority (if any candidate matched exact rule).<br>2. Same employeeId as input (if input had employee id hint).<br>3. activeFlag true over false.<br>4. higher <code>priorConfirmCount</code>.<br>5. sameOrg match favored.<br>6. earliest <code>hireDate</code> favored.<br>7. <code>candidateId</code> lexical ascending as final deterministic fallback.<br>Return: string <code>candidateId|tieReason</code> where <code>tieReason</code> lists applied rules joined by <code>;</code>. Persist the <code>tieReason</code> to audit. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Internal helper: <code>PrefilterCandidatesByTrigram(inputTrigrams As Collection, trigramIndex As Scripting.Dictionary, threshold As Double) As Collection</code></strong><br>Purpose: quick reduction of candidate universe using trigram hit counts and approximate Jaccard lower-bound to avoid full fuzzy calculations on all candidates.<br>Algorithm:<br>1. For each trigram in inputTrigrams, lookup <code>trigramIndex[trigram]</code> producing candidateId lists and accumulate hitCounts per candidate.<br>2. For each candidate, compute approximate potentialJaccard = hits / (<code>|inputTrigrams| + |candidateTrigrams| - hits</code>). If potentialJaccard < threshold skip candidate.<br>3. Return sorted collection by descending <code>hits</code> or potentialJaccard limited to <code>maxPrefilterCandidates</code>. <br>Performance: use integer counters in a VB <code>Scripting.Dictionary</code> to avoid repeated array operations. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Internal helper: <code>NormalizeWeightsAndPolicy(config As Scripting.Dictionary) As Scripting.Dictionary</code></strong><br>Purpose: ensure all weight sets and policies used for combining component scores sum to sensible totals and fill missing keys with defaults. Validate ranges and return normalized map: <code>{ tokenWeight:0.5, trigramWeight:0.25, fuzzyWeight:0.2, priorWeight:0.05 }</code> and band thresholds validated. Log config snapshot to <code>__Run_Config</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Data shapes & canonical examples (single-row trace)</strong><br><strong>Input</strong>: <code>staff_row</code> example fields: <code>{ rowId: 123, rawName: &quot;John A. O&#x27;Neil  &quot;, amount: 2500.00, costCenter: &quot;CC100&quot;, orgUnit: &quot;Sales&quot;, samplePostings: [P123,P124] }</code>.<br><strong>After CleanName</strong>: <code>{ clean: &quot;john a o&#x27;neil&quot;, tokens:[&quot;john&quot;,&quot;a&quot;,&quot;o&#x27;neil&quot;], tokenKey:&quot;john|a|o&#x27;neil&quot;, trigrams:[...], inputRowHash:&quot;sha1...&quot; }</code>.<br><strong>Candidate (example)</strong>: <code>{ candidateId:&quot;E789&quot;, employeeId:&quot;E789&quot;, fullName:&quot;John O&#x27;Neil&quot;, orgUnit:&quot;Sales&quot;, costCenter:&quot;CC100&quot;, priorConfirmCount:5, hireDate:&quot;2017-04-12&quot;, activeFlag:True }</code>.<br><strong>ComponentBreakdown</strong>: <code>{ tokenOverlap:0.75, trigramJaccard:0.62, levScore:0.95, priorWeight:0.12, sameOrgBonus:0.05 }</code>.<br><strong>Final</strong>: <code>{ finalScore:0.913, confidenceBand:&quot;AUTO&quot;, matchedRule:&quot;C_FUZZY&quot;, rationale:&quot;lev 0.95 (0.57), token 0.75 (0.25), prior 0.12 (0.05) =&gt; 0.913&quot; }</code> persisted to audit. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Power Query (PQ) alignment & recommended transforms (practical)</strong><br>1. Implement <code>fnNorm</code> in PQ that exactly mirrors <code>CleanName</code> logic: NBSP ⇒ space, lower-case, optional accent remove, consistent tokenization rules. Place <code>fnNorm</code> in a shared PQ library so analysts and VBA share canonicalization semantics. <br>2. PQ step <code>AddTokenKey</code> should produce <code>TokenKey</code> using the same deterministic ordering rules (first N tokens preserved then sorted remainder). Export <code>PQ_Staff_Normalized</code> named range and <code>PQ_CandidateMap</code> to named ranges for VBA to consume at run start.<br>3. PQ precompute <code>TrigramSet</code> and export as comma-delimited strings for rapid parsing by VBA into arrays. This reduces repeated string processing in VBA runtime and ensures the BI and VBA outputs align exactly. <br>4. For ML training exports, PQ flow should ingest <code>ConfirmedMatches</code> (ndjson) and expand <code>componentBreakdown</code> into flat columns so the external model receives stable feature columns: <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>levScore</code>, <code>phoneticScore</code>, <code>priorConfirmCount</code>, <code>sameOrgFlag</code>, <code>amountDiffNormalized</code>, <code>label</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Conceptual DAX measures for monitoring matching quality (operators & managers)</strong><br>1. <code>AutoApplyRate = DIVIDE([AutoAppliedRows],[TotalProcessedRows])</code> — monitors automation level.<br>2. <code>ReviewLoad = COUNTROWS(FILTER(&#x27;RunDetail&#x27;,&#x27;RunDetail&#x27;[confidenceBand]=&quot;REVIEW&quot;))</code> — reviewer workload indicator.<br>3. <code>AmbiguousTieRate = DIVIDE([AmbiguousTieCount],[TotalProcessedRows])</code> — if rising, indicates threshold tuning needed.<br>4. <code>FuzzyComparisonsAvg = AVERAGE(&#x27;MatchMetrics&#x27;[comparisonsC])</code> — expensive fuzzy work per row; correlate with run latency.<br>5. <code>MLFallbackRate = DIVIDE([ExternalScorerFallbacks],[ExternalScorerCalls])</code> — health of external scorer. <br>Use these measures in a small operations dashboard with alerts for thresholds breached. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Telemetry schema & metrics emitted</strong><br>Emit per-row metrics into <code>__Match_Metrics</code> and aggregate to <code>__Telemetry</code>:<br>- <code>runId</code>, <code>rowId</code>, <code>stageA_timeMs</code>, <code>stageB_timeMs</code>, <code>stageC_timeMs</code>, <code>stageD_timeMs</code>, <code>comparisonsC</code> (int), <code>candidatesPrefiltered</code>, <code>finalScoreTop1</code>, <code>finalScoreTop2</code>, <code>confidenceBand</code>, <code>ambiguousTie</code>(Bool), <code>errorCode</code> (if any).<br>Emit run-level metrics: <code>avgTimePerRowMs</code>, <code>P95TimePerRowMs</code>, <code>AutoApplyRate</code>, <code>AmbiguousTieRate</code>, <code>ExternalScorerLatencyMsAvg</code>, <code>ExternalScorerErrorRate</code>. Provide sample alerts: <code>AmbiguousTieRate &gt; 0.05</code> or <code>AvgTimePerRowMs exceeds SLA</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Error codes & deterministic handling (list)</strong><br>1. <code>MM_INIT_ERR_MASTER_MISSING</code> — master sheet missing; abort run.<br>2. <code>MM_PREFILTER_EMPTY</code> — no candidates after prefilter; escalate to reviewer queue and write <code>NO_CANDIDATE</code> audit.<br>3. <code>MM_FUZZY_COMP_LIMIT</code> — fuzzy cap reached; continue with partial results and emit telemetry.<br>4. <code>MM_EXTERNAL_SCORER_TIMEOUT</code> — external scorer timed out; fallback to local ensemble and increment <code>FallbackCount</code>.<br>5. <code>MM_MATERIALITY_BLOCK</code> — attempted auto-apply while materialFlag True; block and require reviewer sign-off. <br>All error codes are logged to <code>Audit_Log</code> with diagnostic context and stack traces for developer triage. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Performance & scaling recommendations (operational tuning)</strong><br>1. For medium master (≤10k rows): run pure-VBA pipeline with <code>MaxFuzzyComparisonsPerRow</code> 50 and <code>BatchSize</code> 500–1,000.<br>2. For large master (10k–100k): rely heavily on trigram prefiltering, reduce <code>MaxFuzzyComparisonsPerRow</code> to 10–20, and offload StageC/StageD to external scorer if available.<br>3. For very large master (100k+): implement an external microservice for heavy fuzzy and ML scoring; keep StageA and StageB local for quick hits.<br>4. Memoization: use in-run caches for pairs computed frequently; ensure cache keys include <code>runId</code> and <code>configSnapshot</code> to avoid stale reuse across runs. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Testing matrix (detailed)</strong><br>Unit tests (modTestingHarness):<br>1. <code>CleanName</code> cases: accent stripping, NBSP handling, punctuation, numeric tokens, stopword removal, very long names.<br>2. <code>StageA</code> exact matches: single exact, multiple exact (ambiguous), alias mapping present.<br>3. <code>StageB</code> token/phonetic: tokens with high-frequency stopwords, phonetic matches for common name variants (e.g., "Smith" / "Smyth").<br>4. <code>StageC</code> fuzzy: verification against known string pairs with expected normalized scores; test early-exit when <code>MaxFuzzyComparisonsPerRow</code> small.<br>Integration tests:<br>5. Pipeline on golden dataset: <code>InitializeMatching</code> → A→B→C→D → <code>RankCandidates</code> expected candidate ordering identical to baseline; use <code>ReplayRun</code> to assert deterministic parity.<br>Performance tests:<br>6. Synthetic master sizes 10k/50k/100k to measure <code>AvgTimePerRow</code>, memory footprint, and <code>FuzzyComparisons</code> counts. <br>Acceptance gating:<br>7. Precision & recall evaluation on holdout: auto-apply precision >= configured target (e.g., 98%). </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Configuration keys (must be persisted to <code>__Run_Config</code> before run)</strong><br>1. <code>TopK</code> (int) — number of candidates to return.<br>2. <code>AutoApplyThreshold</code> (double) — threshold >= which <code>AUTO</code> band applies.<br>3. <code>ReviewThreshold</code> (double) — threshold for <code>REVIEW</code> band lower bound.<br>4. <code>MaxFuzzyComparisonsPerRow</code> (int).<br>5. <code>NGramSize</code> (int).<br>6. <code>PrefilterTrigramThreshold</code> (double).<br>7. <code>TieWindow</code> (double).<br>8. <code>UseExternalScorer</code> & <code>ExternalScorerUrl</code> & <code>ExternalScorerPIIAllowed</code>. <br>Persisting ensures runs are reproducible and audits include config snapshot. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>ML feedback & training pipeline guidance</strong><br>1. Only export <code>ConfirmedMatches</code> rows where reviewer decisions include <code>decisionToken</code> and non-empty <code>rationale</code> to ensure label quality.<br>2. Export feature vectors using PQ or NDJSON with schema versioning and manifest: fields <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>levScore</code>, <code>phoneticScore</code>, <code>priorConfirmCount</code>, <code>sameOrgFlag</code>, <code>amountDiffNormalized</code>, <code>label</code>.<br>3. Maintain separate production and dev model versions; store <code>serviceVersion</code> returned by external scorer in audit. <br>4. For privacy, hash PII or remove names before sharing with external model training pipelines unless legal and policy approvals are present. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Governance & audit obligations (operational)</strong><br>1. Every run must persist <code>configSnapshot</code>, <code>codeVersion</code> (git commit or signature), and <code>runId</code> in <code>__Run_Config</code> and <code>Audit_Log</code> to ensure reproducibility.<br>2. For any row where <code>confidenceBand</code> is <code>AUTO</code> and <code>amount</code> or <code>delta</code> exceeds <code>modConfig.ReviewerHighDollarThreshold</code>, require a signed reviewer override recorded in <code>Audit_Log</code> before final commit. <br>3. Keep <code>ConfirmedMatches</code> writeable only by reviewer role or signed service account. <br>4. Ensure <code>Audit_Log</code> exports to central immutable DB per retention policy; local workbook audit is for operational troubleshooting only. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Operational troubleshooting (quick steps)</strong><br>1. If <code>AutoApplyRate</code> falls abruptly: check <code>modConfig</code> thresholds, review <code>AmbiguousTieRate</code> and recent changes to <code>modConfig</code> or <code>codeVersion</code> in <code>__Run_Config</code>.<br>2. If runs are slow: inspect <code>__Match_Metrics</code> for high <code>comparisonsC</code>, adjust <code>MaxFuzzyComparisonsPerRow</code> or tighten trigram threshold; consider offloading StageC to helper service.<br>3. External scorer failures: check circuit-breaker state, <code>ExternalScorerUrl</code> connectivity, and <code>__Telemetry</code> for <code>externalScorerLatencyMs</code>. <br>4. Unexpected candidate mismatches: re-run <code>ReplayRun</code> and examine <code>componentBreakdown</code> and tie reasons in <code>Audit_Log</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Developer notes & integration checklist</strong><br>1. Keep <code>CleanName</code> logic identical across PQ and VBA: maintain a single canonical document and update <code>fnNorm</code> in PQ and <code>CleanName</code> code in VBA simultaneously; version both in <code>Macro_ChangeLog</code>.<br>2. When adding features to candidate objects, add schema version and write a migration in <code>modMigration</code> to update historical audit rows if necessary.<br>3. When enabling external scorer, add circuit-breaker defaults and ensure training exports are anonymized if required by policy. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Acceptance criteria for modMatchingEngine release</strong><br>1. Unit/regression tests pass for canonical dataset; <code>RunRegressionSuite</code> produces zero unexpected diffs.<br>2. Performance: average matching time per row within SLA on representative hardware and master size.<br>3. Auto-apply precision meets configured target on holdout sample; <code>AmbiguousTieRate</code> within operational tolerance.<br>4. Audit records include complete <code>componentBreakdown</code> and <code>rationale</code> for every matched row. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Appendix — conceptual PQ steps summary (developer guide)</strong><br>1. <code>fnNorm(text)</code> — PQ function: replicate <code>CleanName</code> rules. <br>2. <code>AddTokenKey</code> — compute tokenKey deterministic rule aligned with VBA.<br>3. <code>ComputeTrigrams</code> — create trigram set and export as delimited string for rapid VBA parse.<br>4. <code>CandidateMap</code> — PQ join of <code>Master</code> + <code>PriorMappings</code> + <code>AliasStore</code> producing seed candidates used by StageA/B to reduce run-time lookups. <br>PQ ensures the analytics and the runtime pipeline use identical canonical inputs. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Appendix — conceptual DAX measures (operational examples)</strong><br>1. <code>AutoApplyRate = DIVIDE(SUM(&#x27;RunSummary&#x27;[AutoAppliedCount]), SUM(&#x27;RunSummary&#x27;[ProcessedCount]))</code>.<br>2. <code>PrecisionAuto = DIVIDE(SUM(&#x27;ConfirmedMatches&#x27;[TruePositivesAuto]), SUM(&#x27;ConfirmedMatches&#x27;[TruePositivesAuto]) + SUM(&#x27;ConfirmedMatches&#x27;[FalsePositivesAuto]))</code>.<br>3. <code>AvgFuzzyComparisons = AVERAGE(&#x27;MatchMetrics&#x27;[comparisonsC])</code>.<br>4. <code>AmbiguousTieRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;RunDetail&#x27;),&#x27;RunDetail&#x27;[AmbiguousTie]=TRUE), COUNTROWS(&#x27;RunDetail&#x27;))</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modMatchingEngine (VBA)"> <strong>Closing operational note</strong><br>Implement this module with strict attention to deterministic ordering, exhaustive audit fields, and careful telemetry. Start with conservative fuzzy caps and wide review bands for phase-1 rollout; tighten auto-apply thresholds only after measured precision on held-out production samples and reviewer sign-off. </td></tr></tbody></table></div><div class="row-count">Rows: 30</div></div><div class="table-caption" id="Table4" data-table="Docu_0202_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modFuzzyScores** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modFuzzyScores</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Module purpose (short)</strong><br><code>modFuzzyScores</code> centralises all fuzzy-matching, approximate-string, n-gram, and similarity utilities used by the UpdateHR+ orchestration. Its goals are: provide deterministic, high-performance fuzzy primitives in VBA; offer a stable tuning surface for thresholds and weights; supply profiling / diagnostic exports for threshold selection; and produce explainable feature outputs consumed by the ranking/ML pipeline. The module is written to be fully deterministic, memoizable per run, and to emit trace records for auditing and PQ training ingestion. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Design principles & constraints</strong><br>1. Single-responsibility: <code>modFuzzyScores</code> only computes string similarity, fingerprints, and diagnostics; it never writes to business sheets. <br>2. Determinism: functions return identical outputs for identical inputs; any randomness must be seeded and the seed stored in <code>__Run_Config</code>. <br>3. Idempotent caching: memoization keyed by <code>runId</code> and input fingerprint; caches cleared at run end. <br>4. Early-exit & caps: to protect Excel, heavy comparisons are bounded by <code>modConfig.MaxFuzzyComparisonsPerRow</code> and <code>modConfig.MaxFuzzyChars</code>. <br>5. Explainability: every scoring function returns a numeric score and a short rationale string suitable for audit rows (component contributions). <br>6. Interoperability: outputs use primitive types (Double, Long, String) and small dictionaries (Scripting.Dictionary) for feature vectors so other modules can consume without marshaling complexity. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Public surface (summary)</strong><br>Primary functions exposed to other modules (each described in detail later):<br>1. <code>LevenshteinDistance(sA As String, sB As String, Optional maxDistance As Long) As Long</code> — banded Levenshtein with early abort. <br>2. <code>NormalizedFuzzyScore(sA As String, sB As String, Optional options As Scripting.Dictionary) As Double</code> — normalized 0..1 fuzzy confidence combining Lev + n-gram. <br>3. <code>NGramFingerprint(s As String, n As Long) As String</code> — deterministic n-gram fingerprint string for prefilter indexing. <br>4. <code>ComputeFuzzyBatchScores(target As String, candidates As Collection, Optional maxComparisons As Long, Optional topK As Long) As Collection</code> — top-K batch scoring with memoization and incremental heap. <br>5. <code>ProfileFuzzyComparisons(historyRange As Range, Optional config As Scripting.Dictionary) As Scripting.Dictionary</code> — offline profiler producing precision/recall buckets and threshold recommendations. <br>6. <code>JaccardNGram(a As Collection, b As Collection) As Double</code> — n-gram Jaccard similarity helper. <br>7. <code>TokenOverlapScore(tokensA As Collection, tokensB As Collection) As Double</code> — token overlap ratio for tokenized fields. <br>8. <code>PhoneticEncode(s As String, Optional method As String) As String</code> — Metaphone/DoubleMetaphone soundex-like phonetic encoding. <br>9. <code>ExplainCompositeScore(featureVector As Scripting.Dictionary, weights As Scripting.Dictionary) As Scripting.Dictionary</code> — compose weighted final score and produce component breakdown. <br>10. <code>RecommendThresholds(historicalConfirmedRange As Range, targetPrecision As Double) As Scripting.Dictionary</code> — run simulation to recommend <code>autoApplyThreshold</code> and <code>reviewThreshold</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: LevenshteinDistance</strong><br>Purpose: compute edit distance between two strings with performance optimisations.<br>Signature: <code>LevenshteinDistance(sA As String, sB As String, Optional maxDistance As Long) As Long</code>.<br>Inputs: <code>sA</code>, <code>sB</code> — raw strings (caller should pass canonicalised CleanName when appropriate). <code>maxDistance</code> — optional early-abort guard; if provided, the algorithm returns a value > <code>maxDistance</code> as soon as it can prove the distance exceeds it.<br>Behavior & implementation notes:<br>1. Use banded dynamic programming matrix restricted to <code>abs(lenA - lenB) + margin</code> to reduce memory for near-equal lengths. <br>2. Represent rows as Variant arrays; update in-place to minimize allocations. <br>3. If <code>maxDistance</code> provided, maintain only the active diagonal band; if current minimal value in a row > <code>maxDistance</code>, abort early and return <code>maxDistance + 1</code>. <br>4. For long strings (both lengths > <code>modConfig.FuzzyLongStringThreshold</code>), pre-split into word tokens and apply a two-stage approach: prefix common-token trimming (remove identical leading/trailing tokens) before computing char-based distance. <br>5. The function returns integer distance (0..N).<br>Output & audit: Each call is expected to clear any internal temporary arrays on exit; callers should log distances when used in scoring. Provide short rationale text <code>&#x27;lev=&lt;distance&gt;&#x27;</code> if the caller requests explainability. <br>Complexity: O(n<em>m) worst-case; with banding O(n</em>bandwidth). <br>Edge cases & mitigations:<br>• If inputs are identical return 0 quickly.<br>• If one string empty return len(other).<br>• If either string length > <code>modConfig.MaxFuzzyChars</code> truncate to <code>MaxFuzzyChars</code> with warning; caller may opt to pre-hash instead for huge fields. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: NormalizedFuzzyScore</strong><br>Purpose: robust normalized similarity combining Levenshtein and n-gram similarity into a single 0..1 confidence used as a component in candidate ranking.<br>Signature: <code>NormalizedFuzzyScore(sA As String, sB As String, Optional options As Scripting.Dictionary) As Double</code>.<br>Inputs & options:<br>1. <code>options(&quot;levWeight&quot;)</code> — weight for Levenshtein contribution (default 0.6). <br>2. <code>options(&quot;jaccardWeight&quot;)</code> — weight for n-gram Jaccard component (default 0.4). <br>3. <code>options(&quot;n&quot;)</code> — n for n-gram fingerprinting (default 3). <br>4. <code>options(&quot;maxLevDistance&quot;)</code> — short-circuit threshold used for performance. <br>Computation steps (deterministic pipeline):<br>1. Preprocess: if not already canonicalised, caller may have passed CleanName; otherwise <code>fnNorm</code> applied externally. Remove diacritics only if <code>options(&quot;stripAccents&quot;)=True</code>. <br>2. Compute <code>lev = LevenshteinDistance(sA, sB, options(&quot;maxLevDistance&quot;))</code>. Normalize to <code>levNorm = 1 - (lev / maxLen)</code> where <code>maxLen = Max(Len(sA), Len(sB))</code>. If <code>maxLen=0</code> return 1.0. <br>3. Build 3-gram sets for both strings, compute <code>jaccard = JaccardNGram(gramsA, gramsB)</code>. <br>4. Compute <code>score = levWeight * levNorm + jaccardWeight * jaccard</code>. Optionally apply small bias for exact signature matches (<code>signatureBonus</code>) if <code>SignatureMatch(sA,sB)=True</code> (adds 0.02 to score). <br>5. Clamp to [0,1]. <br>Return: score as Double between 0 and 1. <br>Explainability: returns numeric score; if <code>options(&quot;returnExplain&quot;)=True</code> the calling convention is to request <code>ExplainCompositeScore(featureVector, weights)</code> to obtain per-component breakdown. Audit: callers should write both <code>lev</code> and <code>jaccard</code> and final <code>score</code> to <code>componentBreakdown</code> in <code>Audit_Log</code>. <br>Performance notes: if input length exceeds <code>modConfig.MaxFuzzyChars</code>, first apply <code>NGramFingerprint</code> on truncated canonical form or pre-hash tokens to avoid expensive DP. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: NGramFingerprint</strong><br>Purpose: deterministic n-gram fingerprint used to prefilter and index candidate sets.<br>Signature: <code>NGramFingerprint(s As String, n As Long) As String</code>.<br>Behavior & output:<br>1. Clean the input: collapse whitespace, strip punctuation (configurable), convert to lowercase, and optionally remove stopwords if <code>modConfig.FingerprintStopwords=True</code>. <br>2. Generate sliding n-grams across the cleaned string. If tokenised mode enabled, generate n-grams across tokens instead of characters for long names (helps with long multi-word names). <br>3. Deduplicate grams and sort them lexicographically to ensure deterministic order. <br>4. Return a delimited canonical fingerprint string in the form <code>|gram1|gram2|gram3|...</code> which is intentionally compact and stable for dictionary keys. <br>Usage patterns: store as <code>dictFingerprint(&quot;fingerprint&quot;) = candidateIdList</code> to implement O(1)-ish prefilters. <br>Edge constraints: For very short strings where n > length, return single token as fingerprint. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: JaccardNGram</strong><br>Purpose: compute Jaccard similarity on gram sets which is used as a second-order similarity measure that tolerates transpositions and token reorderings.<br>Signature: <code>JaccardNGram(a As Collection, b As Collection) As Double</code>.<br>Behavior:<br>1. Accepts two collections of strings (gram tokens). <br>2. Compute <code>intersection = count(a∩b)</code> and <code>union = count(a∪b)</code>; <code>jaccard = intersection / union</code>. Return 0 when both sets empty. <br>Optimisations: implement hash table lookup for one set to avoid O(n*m) comparisons for large gram lists. <br>Explainability: callers store <code>intersect</code> and <code>union</code> as part of component breakdown. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: TokenOverlapScore</strong><br>Purpose: fast token-set overlap score for tokenised canonical fields (useful for multi-word names).<br>Signature: <code>TokenOverlapScore(tokensA As Collection, tokensB As Collection, Optional options As Scripting.Dictionary) As Double</code>.<br>Algorithm & weighting:<br>1. Lowercase token lists, optionally remove stopwords. <br>2. <code>overlap = count(commonTokens)</code>; compute <code>score = overlap / max(totalTokensA, totalTokensB)</code>. <br>3. Optionally apply positional weighting: exact token position matches get higher weight. <br>4. Optionally compute <code>tokenJaccard = overlapCount / (uniqueA + uniqueB - overlapCount)</code> if <code>options(&quot;useJaccard&quot;)=True</code>. <br>Return: token overlap ratio in 0..1. <br>Use-case: fast prefilter to eliminate candidates with very low overlap prior to computing Levenshtein. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: PhoneticEncode</strong><br>Purpose: produce a phonetic encoding to detect similar-sounding names (supports Metaphone / DoubleMetaphone and Soundex as fallback).<br>Signature: <code>PhoneticEncode(s As String, Optional method As String = &quot;DoubleMetaphone&quot;) As String</code>.<br>Implementation notes:<br>1. Provide two modes: precompiled VBA implementation of Metaphone family, and a faster approximate "reduced orthography" heuristic for languages with Latin scripts. <br>2. Deterministic output: always return same code for same input; maintain a mapping of ambiguous characters and handle diacritics deterministically. <br>3. Return single string token (or two tokens for Double Metaphone primary/alternate separated by <code>|</code> if desired). <br>Uses: phonetic matches used as a tie-breaker or feature with small weight (e.g., 0.05) in <code>ExplainCompositeScore</code>. <br>Limitations: phonetics work best on Western names; mark as lower-confidence for non-Latin scripts and include <code>phoneticQuality</code> flag in explain output. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: ComputeFuzzyBatchScores</strong><br>Purpose: take one target string and a candidate collection and produce a top-K scored list using memoization and prefilter heuristics to minimize expensive comparisons.<br>Signature: <code>ComputeFuzzyBatchScores(target As String, candidates As Collection, Optional maxComparisons As Long = -1, Optional topK As Long = 5, Optional options As Scripting.Dictionary) As Collection</code>.<br>Algorithm overview:<br>1. Prefilter: compute <code>targetFingerprint = NGramFingerprint(target, options(&quot;n&quot;))</code> and <code>targetTokens = Tokenize(target)</code>. Use candidate indexes <code>dictTokenIndex</code> and <code>dictFingerprintIndex</code> to produce an initial candidate subset. If prefilter returns empty, optionally fallback to scanning a small head of master list. <br>2. Maintain <code>maxComparisons</code> counter to stop and return current top-K if exceeded; default <code>maxComparisons = modConfig.MaxFuzzyComparisonsPerRow</code>. <br>3. For each candidate in reduced set:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Compute <code>tokenScore = TokenOverlapScore</code> (cheap).<br>&nbsp;&nbsp;&nbsp;&nbsp;b) If <code>tokenScore &lt; options(&quot;tokenMin&quot;)</code> skip further scoring unless explicitly allowed.<br>&nbsp;&nbsp;&nbsp;&nbsp;c) Compute <code>jaccard = JaccardNGram</code> (cheaper than full Lev). <br>&nbsp;&nbsp;&nbsp;&nbsp;d) If <code>jaccard</code> promising compute <code>lev = LevenshteinDistance</code> with <code>maxDistance</code> set to current top-K worst threshold to early exit. <br>&nbsp;&nbsp;&nbsp;&nbsp;e) Compose <code>normalizedScore = NormalizedFuzzyScore</code> or <code>ExplainCompositeScore</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;f) Insert candidate into a maintained top-K structure (binary heap or sorted collection). <br>4. After scanning or reaching maxComparisons, return sorted top-K candidate collection with full componentBreakdown for each. <br>Performance considerations:<br>- Use memoization: if <code>target</code> compared with same candidate previously during run, reuse cached score. <br>- Record timing per comparison and emit slow-comparison traces to <code>__Fuzzy_Profile</code>. <br>Explain & audit: return <code>Collection</code> where each item contains <code>candidateId</code>, <code>score</code>, <code>componentBreakdown</code>, <code>timingMs</code>, and <code>comparisonPath</code> (A/B/C stage used). </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: ProfileFuzzyComparisons</strong><br>Purpose: offline analytics on historical confirmed matches to recommend thresholds and show expected precision/recall tradeoffs.<br>Signature: <code>ProfileFuzzyComparisons(historyRange As Range, Optional config As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Input shape & assumptions:<br>- <code>historyRange</code> contains rows with <code>inputValue</code>, <code>confirmedCandidateId</code>, <code>candidateFeatureVector</code> or raw <code>beforeJSON</code>/<code>afterJSON</code> so that <code>modFuzzyScores</code> can re-compute features. <br>Process steps:<br>1. For each historical confirmed row, re-run <code>ComputeFuzzyBatchScores</code> for that <code>inputValue</code> and find where the confirmed candidate scored (rank, combinedScore). <br>2. Accumulate confusion matrix counts for threshold cutpoints (grid from 0.50 to 0.995). <br>3. Compute per-threshold precision, recall, F1, and expected <code>AutoApplyPrecision</code> and <code>AutoApplyRecall</code>. <br>4. Return a dictionary containing:<br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>thresholdGrid</code> — array of thresholds tested. <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>precisionAtThreshold[]</code>, <code>recallAtThreshold[]</code>, <code>f1AtThreshold[]</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>recommendedAutoApplyThreshold</code> (closest threshold with precision >= config("targetPrecision")). <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>recommendedReviewThreshold</code> (value that balances recall and reviewer load). <br>Outputs consumed by admin UI: build <code>__Fuzzy_Tuning</code> sheet showing AUPRC curve, table of expected reviewer counts per threshold, and recommended thresholds for configuration. <br>Test & verification: run on held-out sample and seed <code>modTestingHarness</code> test to validate threshold recommendation stability. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: ExplainCompositeScore</strong><br>Purpose: compute final weighted composite score and provide an explainable breakdown for audit and reviewer UI.<br>Signature: <code>ExplainCompositeScore(featureVector As Scripting.Dictionary, weights As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Inputs: featureVector keys typically: <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>fuzzyScore</code>, <code>phoneticFlag</code>, <code>priorConfirmCount</code>, <code>sameOrgFlag</code>, <code>signatureMatchFlag</code>. <br>Weights example: <code>{ token:0.50, trigram:0.25, fuzzy:0.20, prior:0.05 }</code>.<br>Output dictionary keys:<br>1. <code>finalScore</code> (Double 0..1). <br>2. <code>components</code> — a nested dictionary mapping feature-> contribution numeric value. <br>3. <code>rationaleString</code> — short human-readable summary like <code>&quot;0.50*token(0.84)+0.25*trigram(0.62)+0.20*fuzzy(0.77)+prior(0.10)=0.78&quot;</code>. <br>4. <code>tieBreakDetails</code> — includes <code>sameEmployeeId</code>, <code>hireDateRank</code>, <code>signatureOverlap</code> used when scores tie. <br>5. <code>explainVersion</code> — version string for provenance. <br>Design notes: ensure <code>rationaleString</code> fits within Excel cell limits and is concise; store full JSON in <code>Audit_Log</code> <code>componentBreakdown</code> cell for detailed BI/PQ ingestion. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Function: RecommendThresholds</strong><br>Purpose: automate threshold recommendations based on historical confirmed matches and target precision.<br>Signature: <code>RecommendThresholds(historicalConfirmedRange As Range, targetPrecision As Double, Optional config As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Steps:<br>1. Run <code>ProfileFuzzyComparisons</code> to generate precision/recall curves. <br>2. Find smallest threshold t where <code>precision(t) &gt;= targetPrecision</code> and <code>expectedReviewerLoad(t) &lt;= config(&quot;maxReviewerLoadPerRun&quot;)</code>. <br>3. If none found, propose operational mitigations: increase <code>maxComparisonsPerRow</code>, add alias entries, or require more reviewer capacity. <br>4. Return dictionary: <code>{autoApplyThreshold, reviewThreshold, expectedPrecisionAtAuto, expectedReviewerRowsAtAuto, notes}</code>. <br>Use in admin UI: bind to <code>AutoApplyThreshold</code> and present tradeoffs in <code>__Fuzzy_Tuning</code> UI. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Telemetry & profiling features</strong><br>1. Every heavy comparison writes a compact trace to <code>__Fuzzy_Profile</code> when <code>modConfig.FuzzyProfileEnabled=True</code>. Stored fields: <code>runId</code>, <code>rowId</code>, <code>candidateId</code>, <code>lev</code>, <code>jaccard</code>, <code>tokenOverlap</code>, <code>timeMs</code>, <code>stage</code> (A,B,C), <code>memoHit</code>. <br>2. Aggregate telemetry dimension keys: <code>AvgCompareTimeMs</code>, <code>ComparisonsPerRow</code>, <code>MemoHitRate</code>, <code>SlowComparePercentile95</code>. <br>3. Expose <code>DumpFuzzyProfile(runId, destPath)</code> to export ndjson or CSV for Power Query ingestion and ML training set creation. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Power Query (PQ) conceptual integration guidance</strong><br>Provide recommended PQ steps to consume <code>modFuzzyScores</code> outputs and expose them to BI and model training:<br>1. <strong>Ingest <code>Audit_Log</code> Export:</strong> source = exported ndjson/CSV from <code>modAudit.ExportAudit</code>. Use <code>Json.Document</code> to parse the <code>componentBreakdown</code> JSON column if stored as JSON. <br>2. <strong>Expand <code>componentBreakdown</code>:</strong> <code>Record.FieldValues</code> to convert to relational columns: <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>fuzzyScore</code>, <code>priorConfirmCount</code>, <code>combinedScore</code>, <code>confidenceBand</code>. <br>3. <strong>Add Labels:</strong> join with <code>ConfirmedMatches</code> to build <code>label</code> column (1=confirmed correct, 0=not confirmed or rejected). <br>4. <strong>Aggregate for thresholds:</strong> group by <code>combinedScoreBucket</code> and compute counts, TP, FP; compute precision and recall. <br>5. <strong>Feature export:</strong> produce training table selecting features and label; export to CSV or Azure Blob for ML pipeline. <br>6. <strong>Visualization:</strong> produce PQ table for Power BI with calculated column <code>Delta = after.amount - before.amount</code> to measure materiality linked to fuzzy decisions. <br>Implementation notes: ensure PQ step is deterministic and sorts records by <code>runId,rowId</code> before grouping to keep reproducibility. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Conceptual DAX measures for BI monitoring</strong><br>Recommended DAX measures for monitoring and acceptance metrics derived from fuzzy outputs after PQ ingestion into a model table called <code>FuzzyAudit</code>:<br>1. <code>AutoApplyRate = DIVIDE([AutoAppliedRows],[TotalRows])</code>.<br>2. <code>FuzzyAvgScore = AVERAGE(FuzzyAudit[combinedScore])</code>.<br>3. <code>PrecisionAtThreshold = CALCULATE(DIVIDE([TruePositives],[TruePositives]+[FalsePositives]), FILTER(FuzzyAudit, FuzzyAudit[combinedScore] &gt;= selectedThreshold))</code>.<br>4. <code>ReviewerLoadEstimate = COUNTROWS(FILTER(FuzzyAudit, FuzzyAudit[combinedScore] &lt; AutoThreshold &amp;&amp; FuzzyAudit[combinedScore] &gt;= ReviewThreshold))</code>.<br>5. <code>FuzzyCompareLatencyMs = AVERAGE(FuzzyAudit[comparisonMs])</code>.<br>Use these measures in operational dashboards to monitor performance and tune thresholds. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Configuration keys (modConfig) relevant to modFuzzyScores</strong><br>1. <code>MaxFuzzyComparisonsPerRow</code> — integer, default e.g., 300. <br>2. <code>FuzzyLongStringThreshold</code> — number of characters above which special tokenization used. <br>3. <code>FuzzyProfileEnabled</code> — boolean flag. <br>4. <code>FuzzyWeights</code> — JSON or cell-based weights for composite scoring. <br>5. <code>FuzzyNGramSize</code> — default 3. <br>6. <code>FuzzyMemoTTLSeconds</code> — in-run TTL for memoized entries. <br>7. <code>MaxFuzzyChars</code> — guard limit to protect Excel memory. <br>8. <code>FuzzyTargetPrecision</code> — default target precision used by <code>RecommendThresholds</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Explainability & audit integration</strong><br>1. For every top-K produced, <code>ComputeFuzzyBatchScores</code> returns full <code>componentBreakdown</code> including <code>lev</code>, <code>levNorm</code>, <code>jaccard</code>, <code>tokenOverlap</code>, <code>phoneticFlag</code>, <code>priorConfirmCount</code>, <code>combinedScore</code>, and <code>rationaleString</code>. Append this dictionary JSON to <code>Audit_Log</code> for retracing decisions. <br>2. When a candidate is auto-applied, include <code>componentBreakdown</code> in <code>ApplyDescriptor</code> so replays and forensic packs can re-evaluate the same features. <br>3. For reviewer decisions, store <code>ExplainCompositeScore</code> output plus reviewer rationale and the <code>featureVector</code> used so ML retraining has full provenance. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Performance optimisation strategy (engineer checklist)</strong><br>1. Pre-index master data: at run start call <code>modMappingStore.LoadMasterStore</code> and build <code>dictTokenIndex</code> and <code>dictFingerprintIndex</code>. <br>2. Memoize string->fingerprint and string->phoneticEncode results per run. <br>3. Use prefilter thresholds: tokenOverlapMin and jaccardMin to avoid heavy lev computations. <br>4. Use banded Levenshtein and pass <code>maxDistance</code> dynamically computed from current worst top-K score. <br>5. Limit heap size for top-K operations and use in-place arrays to implement binary heap to minimise VBA Collection overhead. <br>6. Flush profile telemetry every N rows rather than every row. <br>7. If external service available, offload heavy computations and fall back to local scoring if unavailable. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Edge cases and mitigations</strong><br>1. <strong>Long strings</strong>: truncate with warning and use n-gram tokenization; for legal names with long suffixes, consider hashing suffix and compare hash equality as cheap filter. <br>2. <strong>Non-Latin scripts</strong>: fallback to Unicode normalization and token-based Jaccard; flag <code>scriptQuality</code> in <code>componentBreakdown</code> and reduce auto-apply likelihood. <br>3. <strong>Common short names</strong>: tokenOverlap and jaccard low-discriminative; rely more on priorConfirmCount and sameOrgFlag; push to <code>REVIEW</code> band even if fuzzyScore high. <br>4. <strong>High volume of candidates</strong>: enforce <code>MaxFuzzyComparisonsPerRow</code> and fallback to token/phonetic heuristics. <br>5. <strong>Stable ties</strong>: apply deterministic tie-breakers: sameEmployeeId, sameOrg, earlierHireDate, lexicographic candidateId. Record which tie-break rule applied. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Testing checklist (unit & integration)</strong><br>Unit tests to include (implement via <code>modTestingHarness</code>):<br>1. <code>LevenshteinDistance</code> correctness tests: empty vs empty, single char differences, transpositions; test banding and early-exit. <br>2. <code>NormalizedFuzzyScore</code> correlation tests: identical strings → 1.0; small typo variations → >0.8; large differences → <0.4. <br>3. <code>NGramFingerprint</code> stability: same input returns same fingerprint; different punctuation variations map to same fingerprint after normalization. <br>4. <code>ComputeFuzzyBatchScores</code> top-K stability: deterministic order across runs with same seed/config. <br>5. <code>ProfileFuzzyComparisons</code> produces consistent recommended threshold for a synthetic dataset with known precision/recall curve. <br>Integration tests:<br>1. End-to-end: given a small master store and known staff rows, check that <code>modMatchingEngine</code> using <code>modFuzzyScores</code> returns expected top candidate and that <code>Audit_Log</code> contains component breakdown. <br>2. Stress: feed 10k synthetic rows and verify <code>MaxFuzzyComparisonsPerRow</code> prevents runaway CPU and that performance telemetry saved. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Operational runbook snippets (how operators use tuning outputs)</strong><br>1. Run <code>RecommendThresholds</code> nightly on confirmed matches to update <code>modConfig.AutoApplyThreshold</code> if sample volume and precision metrics are stable for 7 days. <br>2. If <code>FuzzyProfileEnabled</code>, review <code>__Fuzzy_Profile</code> for slow comparisons and inspect candidate strings to decide whether to add aliases or tune prefilter thresholds. <br>3. If <code>AutoApplyPrecision</code> drops below target, reduce Auto threshold or escalate to temporary review-only mode until retraining or alias cleanup completed. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Examples & narratives (non-code) for typical flows</strong><br>Example A — Short typo correction:<br>- Input: <code>Jonathon Smyth</code> <br>- CleanName: <code>jonathon smyth</code> tokens <code>[&quot;jonathon&quot;,&quot;smyth&quot;]</code> <br>- Candidate A: <code>jonathan smith</code> tokenOverlap 1/2 = 0.5, trigramJaccard 0.78, lev=3 → levNorm ~0.85 <br>- NormalizedFuzzyScore combined yields 0.86 → falls into <code>REVIEW</code> or near <code>AUTO</code> depending on weights. <br>- <code>ExplainCompositeScore</code> produces breakdown: <code>0.50*token(0.50)+0.25*jaccard(0.78)+0.20*lev(0.85)+0.05*prior(0.00) = 0.86</code> and rationale saved to <code>Audit_Log</code>. <br>Example B — Long corporate name with abbreviations:<br>- Input: <code>Acme International Pty Ltd.</code> <br>- NGramFingerprint removes stopwords and suffixes, produces grams focusing on <code>acme international</code>.<br>- Candidate matched via fingerprint and tokenOverlap high; fuzzy lev cheap and Jaccard high → immediate auto-apply. <br>Example C — Non-Latin script fallback:<br>- Input: <code>王 小明</code> <br>- Phonetic encoding not used; tokenization on whitespace yields tokens; use n-gram token Jaccard and prior-confirm priors; combinedScore moderate → flagged for review due to scriptQuality flag. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Data exports for ML training (recommended schema)</strong><br>Produce a training file with columns: <code>runId, rowId, inputClean, candidateId, tokenOverlap, trigramJaccard, fuzzyScore, phoneticFlag, priorConfirmCount, sameOrgFlag, signatureMatchFlag, combinedScore, labelConfirmed (1/0), timestamp, codeVersion</code>.<br>Use PQ steps to convert nested <code>componentBreakdown</code> JSON to these columns and append <code>labelConfirmed</code> from <code>ConfirmedMatches</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Security & privacy considerations</strong><br>1. PII handling: when sending feature vectors to external ML service, hash PII fields (e.g., employee names) with salt stored in <code>__Run_Config</code> and never send plaintext names unless contractually permitted. <br>2. Telemetry: avoid storing raw names in <code>__Fuzzy_Profile</code> unless allowed; prefer to store hashed or tokenized forms and component numbers only. <br>3. Audit exports: secure storage recommended; use encrypted archives when sending to central ingestion. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Migration & backwards compatibility</strong><br>1. Keep <code>explainVersion</code> field in explain output; new algorithm changes must increment version and provide a migration script to recompute componentBreakdown for previous runs if historical parity is required. <br>2. When changing default weights, persist previous default in <code>__Run_Config</code> and require migration acceptance before enabling new defaults for production runs. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Operational FAQ (short answers)</strong><br>Q: Why does identical pair sometimes produce slightly different numeric score across runs?<br>A: It should not. If observed, check <code>codeVersion</code> and <code>configSnapshot</code> in <code>Audit_Log</code> for determinism; floating precision effects are negligible but ensure <code>explainVersion</code> stable. <br>Q: How to reduce reviewer load quickly?<br>A: Increase <code>AutoApplyThreshold</code> after verifying precision curve, enrich mapping store with aliases, and raise <code>MaxFuzzyComparisonsPerRow</code> to allow more precise scoring if CPU allows. <br>Q: When should we use external scorer?<br>A: If candidate populations are large and <code>ComputeFuzzyBatchScores</code> is saturating CPU or the ML model requires heavy feature engineering not efficient in VBA. Use external scorer with hashed PII and ensure circuit-breaker fallback to local scoring. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Acceptance tests to include for delivery</strong><br>1. Unit test suite 100% pass on canonical examples including edge-cases (empty strings, extremely long strings, non-latin). <br>2. Regression: run <code>ComputeFuzzyBatchScores</code> on the canonical sample set and assert top-1 candidate and componentBreakdown match saved golden file (allowing only deterministic rounding differences). <br>3. Performance: for target volume X rows, average fuzzy compute time per row must be below SLA Yms on reference hardware; test with <code>modTestingHarness</code> synthetic dataset. <br>4. Integration: <code>modMatchingEngine</code> end-to-end results unchanged on golden dataset after replacing old fuzzy module. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Implementation pitfalls to avoid</strong><br>1. Recreating large temporary 2D arrays in inner loops — prefer re-using pre-allocated arrays and clearing as needed. <br>2. Frequent COM cross-calls (Range.Value) inside fuzzy loops — ensure all fuzzy work done in memory, and only write final outcomes to staging sheets. <br>3. Unbounded memo caches — tie memo cache lifecycle to <code>runId</code> and enforce TTL or memory caps to prevent Excel memory exhaustion. <br>4. Blindly increasing <code>MaxFuzzyComparisonsPerRow</code> — has linear CPU cost; prefer smarter prefilters. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Developer notes: useful heuristics & constants</strong><br>1. Default n-gram size: 3 for names; 4 for long phrases. <br>2. Default weights for <code>NormalizedFuzzyScore</code> when used alone: lev 0.6, jaccard 0.4. <br>3. SignatureBonus: 0.02 for exact signature matches; small but useful tie-breaker. <br>4. PhoneticWeight: include only as small signal (0.05) to avoid false positives. <br>5. Typical <code>MaxFuzzyComparisonsPerRow</code>: 300 for medium datasets; tune downward for older hardware. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Change log & versioning recommendations</strong><br>1. Keep <code>modFuzzyScores</code> version in <code>explainVersion</code> and in <code>__Run_Config</code>. <br>2. On any algorithm change, add migration note and re-run profiling baseline to show delta in precision/recall. <br>3. Store golden vectors for core functions (<code>LevenshteinDistance</code>, <code>NGramFingerprint</code>, <code>NormalizedFuzzyScore</code>) used in unit tests. </td></tr><tr><td data-label="Per-function technical breakdown — modFuzzyScores (VBA)"> <strong>Summary — operational value</strong><br><code>modFuzzyScores</code> is the deterministic, auditable, and explainable fuzzy core for UpdateHR+. It balances precision with performance, provides a tuning surface for safe auto-apply thresholds, emits explainable component breakdowns for audit and ML, and includes profiling features to continuously improve thresholds and identify dataset drift. Implementers should prioritise memoization, prefilters, and explainability integration with <code>Audit_Log</code> and PQ so analysts can iterate on thresholds and ML models with full provenance. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><div class="table-caption" id="Table5" data-table="Docu_0202_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modGoalSeekController** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modGoalSeekController</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Module purpose (short)</strong><br><code>modGoalSeekController</code> provides a production-ready, defensive, observable, and auditable orchestration layer for numerical root-finding in the UpdateHR+ solution. It wraps Excel’s native GoalSeek, validates function shapes, enforces deterministic fallbacks, captures rich trace-curves for forensic analysis, records structured telemetry and audit entries, and exposes configurable policies (timeouts, tolerances, attempts). The module intentionally isolates all GoalSeek behaviour so callers (<code>modCoreEngine</code>, <code>modMatchingEngine</code>, <code>modImpactSimulation</code>) can rely on repeatable, safe numeric solves without inline Excel blocking or inconsistent side-effects. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>High-level responsibilities</strong><br>1. Provide a single entry-point (<code>RunGoalSeek</code>) that attempts a native GoalSeek, respects per-row timeouts and attempt caps, captures diagnostics, and falls back to a deterministic search when native GoalSeek fails. <br>2. Pre-validate function shape (<code>PreValidateFunctionShape</code>) to avoid blind solves on oscillatory or discontinuous functions. <br>3. Provide deterministic fallback algorithm(s) (<code>IncrementalFallbackSearch</code>) that are idempotent and replayable. <br>4. Capture and persist sample curves / traces for audit and reviewer UI (<code>CaptureFunctionSample</code> and <code>__GS_Traces_&lt;runId&gt;</code>). <br>5. Record structured per-attempt telemetry (<code>RecordGSMetric</code>) to <code>__GS_Metrics</code> and <code>__Telemetry</code> for operational monitoring and BI. <br>6. Provide small helpers for safe cell evaluation (<code>EvaluateFunctionAt</code>) and audit mapping (<code>GSStatusToAudit</code>). <br>7. Keep all side-effects controlled: preserve/restore <code>Application</code> state, avoid event/macro triggers where possible, and detect workbook state changes caused by evaluations. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Design principles & constraints</strong><br>1. Fail-safe first: any single non-convergent GS must not block batch processing. <br>2. Deterministic algorithms: fallback search must produce identical results given identical workbook state, <code>configSnapshot</code>, and <code>runId</code>. <br>3. Observability: every attempt emits metrics and a <code>TraceRef</code> for forensic replay. <br>4. Minimal surface to caller: callers need only pass targetRange and changingRange with a small <code>runContext</code> dictionary. <br>5. Non-invasive: avoid user-interactive prompts; surface escalate events to reviewer UI via <code>Audit_Log</code>. <br>6. Security & privacy: avoid storing PII in telemetry/traces; numeric x/y only. <br>7. Protect Excel: cap sample points and comparisons to avoid long blocking loops; perform short <code>DoEvents</code> and Timer checks to honor timeouts. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Public function list (summary)</strong><br>1. <code>RunGoalSeek(targetCell As Range, changingCell As Range, targetValue As Double, runContext As Scripting.Dictionary) As Scripting.Dictionary</code> — main orchestrator. <br>2. <code>PreValidateFunctionShape(targetCell As Range, changingCell As Range, samplePoints As Long, runContext As Scripting.Dictionary) As Scripting.Dictionary</code> — pre-check monotonicity/unimodality. <br>3. <code>CaptureFunctionSample(targetCell As Range, changingCell As Range, samplePoints As Long, Optional domainLow As Variant, Optional domainHigh As Variant, Optional useLogSpacing As Boolean) As Collection</code> — sample curve capture. <br>4. <code>EvaluateFunctionAt(changingValue As Double, changingCell As Range, targetCell As Range, Optional restoreOnExit As Boolean = True) As Scripting.Dictionary</code> — safe atomic evaluation and timing. <br>5. <code>IncrementalFallbackSearch(low As Double, high As Double, evaluateCallback As Variant, targetValue As Double, maxSteps As Long, tolerance As Double, options As Scripting.Dictionary) As Scripting.Dictionary</code> — deterministic fallback search. <br>6. <code>RecordGSMetric(runId As String, rowId As Long, metric As Scripting.Dictionary)</code> — telemetry sink. <br>7. <code>GSStatusToAudit(runId As String, rowId As Long, gsResult As Scripting.Dictionary) As Scripting.Dictionary</code> — produce audit payload. <br>8. <code>LoadGSConfig() As Scripting.Dictionary</code> — read GS-related config keys from <code>modConfig</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — RunGoalSeek</strong><br><strong>Signature:</strong> <code>RunGoalSeek(targetCell As Range, changingCell As Range, targetValue As Double, runContext As Scripting.Dictionary) As Scripting.Dictionary</code>.<br><strong>Purpose:</strong> Attempts a native GoalSeek then fallback if necessary; records telemetry and returns structured diagnostics.<br><strong>Expected runContext keys:</strong> <code>runId</code> (String) <br><code>rowId</code> (Long) <br><code>TimeoutSec</code> (Double) <br><code>MaxAttempts</code> (Long) <br><code>Tolerance</code> (Double) <br><code>InitialGuess</code> (Double, Optional) <br><code>LowBound</code>/<code>HighBound</code> (Double, Optional) <br><code>AllowFallback</code> (Boolean, default True) <br><code>SamplePoints</code> (Long, optional override) <br><strong>Processing pipeline (step-by-step):</strong><br>1. Validate inputs: ensure <code>targetCell</code> and <code>changingCell</code> are present and not multi-cell ranges. If invalid, return <code>Status=&quot;ERROR_INPUT&quot;</code> with descriptive <code>Diagnostics</code>. <br>2. Load GS config defaults by calling <code>LoadGSConfig()</code> and override with any runContext values. <br>3. Call <code>PreValidateFunctionShape</code> with sampled points to produce <code>precheck</code> output. If <code>precheck.action = &quot;FAIL&quot;</code> and <code>AllowFallback=False</code>, return <code>Status=&quot;PRECHECK_FAIL&quot;</code> with trace and recommendation. <br>4. Save and disable application state: store <code>oldCalc</code>, <code>oldScreenUpdating</code>, <code>oldEnableEvents</code> and set conservative safe values (<code>Calculation = Manual</code>, <code>ScreenUpdating=False</code>, <code>EnableEvents=False</code>). <br>5. Attempt native GoalSeek:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) If <code>InitialGuess</code> provided, set <code>changingCell = InitialGuess</code> before calling GoalSeek to seed solver. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Wrap <code>Range.GoalSeek Goal:=targetValue, ChangingCell:=changingCell</code> in <code>On Error</code> block and use <code>Timer</code> checks to enforce <code>TimeoutSec</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;c) If <code>GoalSeek</code> returns success and <code>Abs(targetCell.Value - targetValue) &lt;= Tolerance</code>, mark <code>Status=&quot;CONVERGED_NATIVE&quot;</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) If native fails or times out, capture exception, call <code>CaptureFunctionSample</code> for diagnostics and proceed to fallback if allowed. <br>6. If fallback allowed, call <code>IncrementalFallbackSearch</code> with domain from <code>[LowBound, HighBound]</code> (or derived from <code>InitialGuess</code> ± padding) and pass <code>EvaluateFunctionAt</code> (or a wrapped callback) and <code>targetValue</code>. <br>7. Record GS metric by calling <code>RecordGSMetric</code> with outcome including <code>methodUsed</code>, <code>attempts</code>, <code>runtimeMs</code>, <code>finalResidual</code>, and <code>traceRef</code>. <br>8. Restore application state. <br>9. Build and return result dictionary with keys: <code>Status</code>, <code>MethodUsed</code>, <code>SolutionValue</code> (if any), <code>Attempts</code>, <code>FinalResidual</code>, <code>TraceRef</code>, <code>Diagnostics</code> (precheck, exception messages), and <code>runtimeMs</code>. <br><strong>Notes and safety:</strong> Always restore app state in <code>Finally</code>-like block; ensure <code>EnableEvents</code> restored even when <code>On Error</code> fires. In case workbook state mutated unexpectedly during evaluation, the module records <code>cellCalcStateHash</code> to help forensic analysis and avoid silent failures. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — PreValidateFunctionShape</strong><br><strong>Signature:</strong> <code>PreValidateFunctionShape(targetCell As Range, changingCell As Range, samplePoints As Long, runContext As Scripting.Dictionary) As Scripting.Dictionary</code>.<br><strong>Purpose:</strong> Sample f(x) across domain to estimate monotonicity, derivative variability, and detect discontinuities or noise that make native GoalSeek risky. <br><strong>Algorithm (deterministic):</strong><br>1. Derive sampling domain:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) If <code>runContext.LowBound</code>/<code>HighBound</code> provided, use them. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Else use <code>InitialGuess</code> ± <code>GS_SafeDomainPadding * max(|InitialGuess|, baselineSpan)</code> where <code>baselineSpan</code> is a configurable default. <br>2. Generate <code>samplePoints</code> uniformly (or log-spaced if <code>useLogSpacing=True</code>) across domain — typical <code>samplePoints</code> 7..15. <br>3. For each x call <code>EvaluateFunctionAt</code> and collect <code>(x,y,evalMs,status)</code>; if <code>status</code> is error, note it but continue. <br>4. Compute finite differences <code>d[i] = (y[i+1]-y[i])/(x[i+1]-x[i])</code> for i=1..N-1. <br>5. Compute metrics:<br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>monotonicityScore = count(sign(d[i]) == sign(d[1])) / (N-1)</code> (gives fraction of derivative signs consistent). <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>avgDerivative = mean(d[i])</code>, <code>derivativeStdDev = stdev(d[i])</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>jumpCount</code> = count of relative jumps where <code>|d[i+1]-d[i]|/max(|d[i]|,epsilon) &gt; threshold</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• <code>errSamplePct</code> = fraction of samples that produced errors. <br>6. Decide recommendation:<br>&nbsp;&nbsp;&nbsp;&nbsp;• If <code>monotonicityScore &gt;= GS_MonotonicityThreshold</code> and <code>jumpCount==0</code> => <code>action = &quot;OK&quot;</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• If <code>monotonicityScore &gt;= warnThreshold</code> or <code>jumpCount small</code> => <code>action = &quot;WARN&quot;</code> plus recommended domain adjustments. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Else => <code>action = &quot;FAIL&quot;</code> and recommend <code>REVIEW</code>. <br>7. Return dictionary with <code>[action, monotonicityScore, avgDerivative, derivativeStdDev, jumpCount, samplePointsCollection, recommendationString, traceRef]</code>. <br><strong>Audit:</strong> Store returned <code>samplePoints</code> to <code>__GS_Traces_&lt;runId&gt;</code> and include <code>traceRef</code> in output. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — CaptureFunctionSample</strong><br><strong>Signature:</strong> <code>CaptureFunctionSample(targetCell As Range, changingCell As Range, samplePoints As Long, Optional domainLow As Variant, Optional domainHigh As Variant, Optional useLogSpacing As Boolean = False) As Collection</code>.<br><strong>Purpose:</strong> deterministic sampling that produces (x,f(x)) trace for diagnostics, plotting in reviewer UI, and reproducible audit. <br><strong>Behaviour & details:</strong><br>1. Create <code>xPoints</code> list across domain; support log-spacing for magnitudinal ranges. <br>2. For each x: call <code>EvaluateFunctionAt(x, changingCell, targetCell, restoreOnExit:=True)</code> which returns <code>{value, evalMs, status, errorMsg, stateHash}</code>. Store tuple <code>(x, y, evalMs, status, errorMsg)</code> into returned collection. <br>3. After sample complete, write a compact row per sample into <code>__GS_Traces_&lt;runId&gt;</code> sheet including <code>rowId</code> for cross-reference and capture the range address or a traceRef string like <code>&quot;__GS_Traces_&lt;runId&gt;!A123:A129&quot;</code>. <br>4. Return the <code>Collection</code> and <code>traceRef</code>. Limit <code>samplePoints</code> to <code>GS_MaxSamplePoints</code> to protect runtime. If <code>GS_ProfileEnabled=True</code> store extended sample debugging in <code>__GS_Profile</code> sheet. <br><strong>Best practice:</strong> always call <code>CaptureFunctionSample</code> before calling fallback and when native fails so reviewers can see full function behaviour. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — EvaluateFunctionAt</strong><br><strong>Signature:</strong> <code>EvaluateFunctionAt(changingValue As Double, changingCell As Range, targetCell As Range, Optional restoreOnExit As Boolean = True) As Scripting.Dictionary</code>.<br><strong>Purpose:</strong> safely set a numeric value into <code>changingCell</code>, recalc the minimal scope, capture target value and evaluation time, and optionally restore the original <code>changingCell</code> value. <br><strong>Atomic steps & safety checklist:</strong><br>1. Save <code>oldVal = changingCell.Value</code>, and optionally <code>oldCalcMode</code> if switching calc modes. <br>2. Write <code>changingCell.Value = changingValue</code> with <code>Application.EnableEvents=False</code> to avoid macro triggers (note: callers must ensure <code>EnableEvents</code> toggled at higher level if needed). <br>3. Recalculate minimal area: prefer <code>targetCell.Worksheet.Calculate</code> or <code>Application.Calculate</code> if cross-sheet dependencies exist; stores <code>calcStart = Timer</code> and <code>calcEnd = Timer</code> to get <code>evalMs</code>. <br>4. Read <code>y = targetCell.Value</code> and <code>vType = VarType(y)</code>. If <code>IsError(y)</code> capture Excel error code and set <code>status=&quot;ERR&quot;</code> with <code>errorMsg</code>. <br>5. Optionally restore <code>changingCell</code> to <code>oldVal</code> if <code>restoreOnExit=True</code> (useful for sampling) or leave it as solution candidate for native GoalSeek. <br>6. Compute small state fingerprint <code>stateHash</code> by hashing critical named cells (configurable) to detect side-effect changes; store as diagnostic. <br>7. Return dictionary: <code>{value=y, evalMs=(calcEnd-calcStart)*1000, status, errorMsg, stateHash}</code>. <br><strong>Caveats:</strong> For volatile or event-driven workbooks, <code>EnableEvents</code> must be managed by caller; repeated EvaluateFunctionAt calls may cause side-effects in poorly designed workbooks — always capture stateHash to detect such mutation. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — IncrementalFallbackSearch</strong><br><strong>Signature:</strong> <code>IncrementalFallbackSearch(low As Double, high As Double, evaluateCallback As Variant, targetValue As Double, maxSteps As Long, tolerance As Double, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br><strong>Purpose:</strong> deterministic fallback search combining bisection (safe when sign change bracketed) with derivative-aware step/scan when bracket absent. Always deterministic and bounded. <br><strong>Inputs & options:</strong><br>- <code>evaluateCallback(x)</code> must return numeric <code>y</code> and optionally <code>evalMs</code> and <code>status</code>. <br>- <code>options(&quot;flatDerivativeThreshold&quot;)</code> — when derivative magnitude small, use scanning fallback. <br>- <code>options(&quot;initialStep&quot;)</code> and <code>options(&quot;stepShrink&quot;)</code> — for scanning. <br><strong>Algorithm (detailed flow):</strong><br>1. Evaluate <code>yLow = evaluateCallback(low)</code> and <code>yHigh = evaluateCallback(high)</code>. If either returns error, try to expand domain slightly or mark <code>ERR_DOMAIN</code>. <br>2. If <code>Sign(yLow-targetValue)</code> ≠ <code>Sign(yHigh-targetValue)</code> then standard bisection applies:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) For i = 1 to maxSteps: mid = (low+high)/2; yMid = evaluateCallback(mid); residual = Abs(yMid - targetValue); track bestSolution if residual smaller. If residual <= tolerance, return <code>CONVERGED</code> with <code>SolutionValue=mid</code>. Else if sign(yMid-targetValue) == sign(yLow-targetValue) then low=mid else high=mid. Continue. <br>3. If not bracketed but <code>PreValidateFunctionShape</code> indicated monotonicity and targetValue lies between yLow and yHigh (numerically), still apply bisection by treating as virtual bracket. <br>4. If flat derivative (<code>|delta y/delta x|</code> < threshold) or oscillatory/noisy, switch to scanning:<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Use <code>step = options(&quot;initialStep&quot;)</code>; for k from 0 to maxScanSteps: evaluate at <code>x = initialGuess + k*step</code> and <code>x = initialGuess - k*step</code> symmetrically; shrink step by <code>stepShrink</code> periodically; track minimal residual and return best when find residual <= tolerance or maxSteps exhausted. <br>5. Always record sample points and intermittently write partial trace to <code>__GS_Traces</code> for long searches. <br>6. Deterministic tie resolution: if two x have same residual choose lower x or earliest-sampled point depending on <code>options(&quot;tieBreak&quot;)</code> setting. <br>7. Return structure: <code>{Status, SolutionValue (or bestSolution), Attempts, FinalResidual, TraceRef, DiagnosticNotes}</code>. <br><strong>Edge behaviors:</strong> If function returns frequent errors (N/A), treat as <code>NO_CONVERGE</code> and include <code>errorCount</code> in diagnostics. If domain expansion needed, follow bounded expansion up to <code>GS_MaxDomainExpansion</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — RecordGSMetric</strong><br><strong>Signature:</strong> <code>RecordGSMetric(runId As String, rowId As Long, metric As Scripting.Dictionary)</code>.<br><strong>Purpose:</strong> single place to write GS telemetry. Ensures consistent columns and minimal sheet I/O. <br><strong>Minimum metric keys:</strong> <code>timestamp</code>, <code>methodUsed</code>, <code>status</code>, <code>attempts</code>, <code>runtimeMs</code>, <code>finalResidual</code>, <code>solutionValue</code>, <code>traceRef</code>, <code>errorCode</code>, <code>avgEvalMs</code>, <code>evalCount</code>. <br><strong>Behavior:</strong> append metric row to hidden <code>__GS_Metrics</code> table; if configured, also append JSON line to <code>__Telemetry</code> NDJSON export. Use single <code>Range.Value</code> assignment per append to minimize COM overhead. <br><strong>Downstream:</strong> <code>__GS_Metrics</code> is the canonical source for PQ ingestion and BI (see DAX measures below). Metrics must never include raw PII. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Function deep-dive — GSStatusToAudit</strong><br><strong>Signature:</strong> <code>GSStatusToAudit(runId As String, rowId As Long, gsResult As Scripting.Dictionary) As Scripting.Dictionary</code>.<br><strong>Purpose:</strong> build audit payload that other modules append to <code>Audit_Log</code> as part of staged changes; keeps audit schema consistent.<br><strong>Typical audit payload fields:</strong> <code>runId</code>, <code>rowId</code>, <code>actionType=&quot;GOALSEEK&quot;</code>, <code>status</code>, <code>methodUsed</code>, <code>attempts</code>, <code>solutionValue</code>, <code>finalResidual</code>, <code>traceRef</code>, <code>precheckSummary</code>, <code>notes</code>, <code>userId</code>, <code>timestamp</code>. <br><strong>Return:</strong> dictionary the caller can pass directly to <code>modAudit.AppendAuditRow</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Configuration keys (modConfig) used by module</strong><br>1. <code>GS_TimeoutSec</code> — per-row default timeout (e.g., 30). <br>2. <code>GS_MaxAttempts</code> — default max tries (e.g., 6). <br>3. <code>GS_Tolerance</code> — acceptable residual (business units; e.g., 0.01 for cents). <br>4. <code>GS_SamplePoints</code> — default sample points for pre-check (7–11). <br>5. <code>GS_MonotonicityThreshold</code> — e.g., 0.9. <br>6. <code>GS_FlatDerivativeThreshold</code> — threshold below which function considered flat. <br>7. <code>GS_MaxSamplePoints</code> — absolute cap for traces (e.g., 25). <br>8. <code>GS_MaxEvalMs</code> — if an evaluation takes longer than this, warn and optionally abort. <br>9. <code>GS_MaxDomainExpansion</code> — fraction or fixed amount for domain expansion. <br>10. <code>GS_ProfileEnabled</code> — boolean for heavy trace capture. <br>11. <code>GS_PersistentTraceRetentionDays</code> — retention policy for traces saved in workbook prior to export. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Explainability & audit integration</strong><br>1. Every GS run yields a <code>TraceRef</code> which is a stable pointer to a range on <code>__GS_Traces_&lt;runId&gt;</code> or an exported artifact path; this <code>TraceRef</code> is included in all GS-related <code>Audit_Log</code> entries. <br>2. For material rows, <code>Audit_Log</code> includes full <code>samplePoints</code> array JSON in <code>componentBreakdown</code> so reviewers can reconstruct the curve offline if needed. <br>3. <code>GSStatusToAudit</code> standardises the payload so BI, compliance, and forensics all read the same fields. <br>4. Provide <code>__GS_Viewer</code> UI macro to extract a <code>TraceRef</code> and render a chart for quick reviewer inspection (chart generation belongs to UI module, not this module). </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Telemetry & monitoring: PQ & DAX guidance</strong><br><strong>Power Query ingestion (conceptual steps):</strong><br>1. Source: export <code>__GS_Metrics</code> as CSV or NDJSON. <br>2. Use <code>Json.Document</code> for NDJSON; expand nested metric fields to columns. <br>3. Normalize timestamps to UTC and build relation with <code>Audit_Log</code> via <code>runId,rowId</code>. <br>4. Flatten <code>__GS_Traces</code> to create <code>GSTraceFlatten</code> table with <code>runId,rowId,x,y,evalMs,seq</code>. <br><strong>DAX measures (operational):</strong><br>1. <code>PctGSConverged = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[status]=&quot;CONVERGED&quot;), COUNTROWS(&#x27;GSMetrics&#x27;))</code>.<br>2. <code>AvgGSAttempts = AVERAGE(&#x27;GSMetrics&#x27;[attempts])</code>.<br>3. <code>GSAvgEvalMs = AVERAGE(&#x27;GSTraces&#x27;[evalMs])</code>.<br>4. <code>PctGSTimeout = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[status]=&quot;TIMEOUT&quot;), COUNTROWS(&#x27;GSMetrics&#x27;))</code>.<br>5. <code>MaterialGSRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[isMaterial]=TRUE), COUNTROWS(&#x27;GSMetrics&#x27;))</code> (requires tagging material rows). </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Examples & narratives (illustrative)</strong><br>Example A — Simple monotonic function (GoalSeek succeeds natively):<br>- Context: targetCell is a linear function of changingCell, monotonic across domain. <br>- Flow: <code>PreValidateFunctionShape</code> returns <code>OK</code> (monotonicityScore 1.0). <code>RunGoalSeek</code> calls native GoalSeek, converges in 1 attempt, <code>RecordGSMetric</code> logs <code>CONVERGED_NATIVE</code>, <code>Audit_Log</code> contains <code>TraceRef</code> with 7 sample points. <br>Example B — Oscillatory function with local minima (GoalSeek fails):<br>- Precheck returns <code>WARN</code> or <code>FAIL</code> with derivative sign flips. Native <code>GoalSeek</code> times out or returns wrong root. <code>RunGoalSeek</code> captures full sample curve and <code>IncrementalFallbackSearch</code> runs scanning with step shrink to find minimal residual; final residual above <code>Tolerance</code> → row flagged for reviewer with <code>NO_CONVERGE_FALLBACK</code> and trace exported. <br>Example C — Tiered/discontinuous function (tax bracket):<br>- Precheck <code>FAIL</code> due to discontinuities. <code>RunGoalSeek</code> immediately returns <code>PRECHECK_FAIL</code> and creates review ticket including the sampled curve showing step jumps; automatic fallback disabled for that row per policy. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Edge cases & mitigations (detailed)</strong><br>1. Volatile side effects: evaluation triggers macros/events — module disables <code>EnableEvents</code> and uses targeted sheet calc to reduce side effects. Always compute <code>stateHash</code> to detect changes. <br>2. Protected changing cell: detect <code>Locked</code> and <code>Worksheet.Protect</code> and return <code>LOCKED_CELL</code> without attempt. <br>3. Non-finite outputs: treat <code>#N/A</code>/<code>#DIV/0!</code> as error samples; if a large fraction of samples error, abort and escalate. <br>4. Flat functions: fallback scanning uses shrinking step and returns best-so-far; flag for reviewer if residual above tolerance. <br>5. Performance blowup (very expensive recalc): cap samplePoints and evalMs and return <code>TIMEOUT</code> if <code>evalMs</code> for single evaluation exceeds <code>GS_MaxEvalMs</code>. <br>6. Numeric instability: use business-tolerances (e.g., cents) not machine eps; provide <code>GS_Tolerance</code> in terms meaningful to finance. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Testing checklist (unit & integration)</strong><br>Unit tests to include (via <code>modTestingHarness</code>):<br>1. <code>EvaluateFunctionAt</code> correctness: set and restore <code>changingCell</code>, measured evaluation times, and <code>stateHash</code> detection. <br>2. <code>PreValidateFunctionShape</code>: synthetic functions (monotonic linear, noisy monotonic, oscillatory sin-like, discontinuous step) produce expected <code>OK/WARN/FAIL</code>. <br>3. <code>RunGoalSeek</code> native success: synthetic workbook function where <code>Range.GoalSeek</code> is expected to converge; verify <code>CONVERGED_NATIVE</code> returned. <br>4. <code>RunGoalSeek</code> native failure + fallback success: function that causes native to fail but fallback bisection converges. <br>5. Timeout handling: ensure module returns <code>TIMEOUT</code> if wall-clock exceeds configured <code>TimeoutSec</code>. <br>Integration tests:<br>1. Full pipeline: <code>modCoreEngine.ProcessStaffRow</code> that requires GS; verify <code>Audit_Log</code> includes GS payload and <code>__GS_Metrics</code> updated; <code>ReplayRun</code> reproduces identical solution. <br>2. Stress: batch of thousands where GS required ~5% rows; confirm chunking and timeouts prevent Excel freeze. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Performance & operational tuning guidance</strong><br>1. Minimize recalculation surface: prefer <code>Sheet.Calculate</code> before <code>Application.Calculate</code>. <br>2. Keep <code>GS_SamplePoints</code> conservative in production (7). Increase only for diagnostic runs. <br>3. Use <code>GS_MaxEvalMs</code> to detect expensive formula chains and optimize those calculators outside of GS runs. <br>4. Increase <code>TimeoutSec</code> only if <code>AvgEvalMs</code> is low; otherwise optimize workbook formulas. <br>5. Use telemetry to find high <code>evalMs</code> outliers and reduce <code>samplePoints</code> on rows with expensive evaluations. <br>6. If many complex GS runs are required, consider offloading numeric solving to an external service that receives function snapshots and returns solutions — ensure reproducible inputs and hashed PII. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Operational runbook snippets</strong><br>1. If a run shows many <code>PRECHECK_FAIL</code> entries: open <code>__GS_Traces_&lt;runId&gt;</code> and inspect sampled curves; identify patterns (tiered logic / discontinuities) and consider adjusting calculator formulas or introducing explicit split rules. <br>2. If <code>PctGSConverged</code> drops below threshold: increase <code>GS_SamplePoints</code> temporarily to collect more diagnostic traces and review <code>__GS_Profile</code> to find slow formulas. <br>3. For individual forensic investigation: use <code>TraceRef</code> from <code>Audit_Log</code>, load into <code>__GS_Viewer</code> and replay samples in the same <code>configSnapshot</code>. <br>4. For deploy changes affecting <code>GS_Tolerance</code> or <code>GS_TimeoutSec</code>, prepare <code>Macro_ChangeLog</code> entry and run acceptance tests on golden dataset. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Conceptual Power Query (PQ) transform for GS traces</strong><br>1. Source: export <code>__GS_Metrics</code> as NDJSON. <br>2. In PQ: <code>Json.Document</code> parse metrics rows and expand nested fields (traceRef, diagnostics). <br>3. Import <code>__GS_Traces</code> CSV/ndjson and expand arrays into rows <code>runId,rowId,seq,x,y,evalMs,status</code>. <br>4. Join metrics and traces on <code>runId,rowId</code> for trace-level dashboards. <br>5. Create a <code>GSRuns</code> summary table grouped by <code>runId</code> with measures: <code>PctConverged</code>, <code>AvgAttempts</code>, <code>AvgEvalMs</code> to feed BI. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Conceptual DAX measures for GS reporting</strong><br>1. <code>PctGSConverged = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[status]=&quot;CONVERGED&quot;), COUNTROWS(&#x27;GSMetrics&#x27;))</code>. <br>2. <code>AvgGSAttempts = AVERAGE(&#x27;GSMetrics&#x27;[attempts])</code>. <br>3. <code>GSAvgEvalMs = AVERAGE(&#x27;GSTraces&#x27;[evalMs])</code>. <br>4. <code>GSFailureRate = DIVIDE(CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;),&#x27;GSMetrics&#x27;[status] &lt;&gt; &quot;CONVERGED&quot;), COUNTROWS(&#x27;GSMetrics&#x27;))</code>. <br>5. <code>MaterialGSExceptions = CALCULATE(COUNTROWS(&#x27;GSMetrics&#x27;), FILTER(&#x27;GSMetrics&#x27;, &#x27;GSMetrics&#x27;[isMaterial] = TRUE &amp;&amp; &#x27;GSMetrics&#x27;[status] &lt;&gt; &quot;CONVERGED&quot;))</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Governance & safety controls</strong><br>1. Runs with <code>methodUsed &lt;&gt; &quot;CONVERGED_NATIVE&quot;</code> and <code>finalResidual &gt; modConfig.MaterialityThreshold</code> must require reviewer sign-off before commit. <br>2. Any change to <code>GS_Tolerance</code>, <code>GS_TimeoutSec</code>, or fallback algorithm parameters must be logged in <code>Macro_ChangeLog</code> and pass regression suite. <br>3. <code>__GS_Traces</code> retention policy: export sensitive traces to central audit DB and prune workbook traces per <code>modConfig.GS_PersistentTraceRetentionDays</code>. <br>4. Telemetry export must hash or omit PII; <code>TraceRef</code> should not contain raw employee identifiers. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Developer notes, recommended helper patterns</strong><br>1. Keep <code>EvaluateFunctionAt</code> small and testable — stub it in unit tests so fallback logic can be validated purely algorithmically. <br>2. Use <code>Scripting.Dictionary</code> for in-memory caches and <code>Collection</code> for ordered sample lists. <br>3. Maintain idiomatic <code>Try/Finally</code>-like pattern in VBA using <code>On Error</code> handlers to restore <code>Application</code> state. <br>4. Document deterministic tie-break rules in code comments and <code>__ModuleMeta</code> for reproducibility. <br>5. Emit <code>explainVersion</code> for the module so <code>ReplayRun</code> can confirm matching algorithm version. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Testing & acceptance criteria (delivery)</strong><br>1. Unit tests for every public function; <code>modTestingHarness</code> run must pass. <br>2. <code>ReplayRun</code> reproduces identical <code>SolutionValue</code> and <code>TraceRef</code> for at least 100 representative cases across native and fallback paths. <br>3. Telemetry coverage: each GoalSeek call produces <code>GSMetrics</code> row and <code>TraceRef</code> persisted to <code>Audit_Log</code> or <code>__GS_Traces</code>. <br>4. Performance: median <code>avgEvalMs</code> and total runtime per GS attempt meet SLA on representative hardware. <br>5. Governance: fallback usage and tolerance changes are recorded in <code>Macro_ChangeLog</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Implementation pitfalls to avoid</strong><br>1. Leaving <code>EnableEvents</code> disabled after an error — always restore in finalizer. <br>2. Using global <code>Application.Calculate</code> frequently — prefer sheet-scoped <code>Calculate</code>. <br>3. Not bounding samplePoints or scans — always enforce <code>GS_MaxSamplePoints</code> and <code>GS_MaxAttempts</code>. <br>4. Storing PII in <code>__GS_Traces</code> or <code>__GS_Metrics</code> — only numeric x/y and non-identifying bounds. <br>5. Non-deterministic floating tie-breaks — implement explicit tie rules (lower x, earlier sample). </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Operational example walkthrough (end-to-end narrative)</strong><br>1. Operator triggers UpdateHR+ run for a staff row requiring budget balancing that involves a numeric parameter found by solving a function on the Calculator sheet. <br>2. <code>modCoreEngine.ProcessStaffRow</code> calls <code>modGoalSeekController.RunGoalSeek</code> with <code>InitialGuess</code> and <code>runContext</code> including <code>rowId</code> and <code>runId</code>. <br>3. <code>RunGoalSeek</code> runs <code>PreValidateFunctionShape</code> which samples 7 points and returns <code>OK</code>. <br>4. Native <code>Range.GoalSeek</code> is invoked and converges in 2 attempts; <code>RecordGSMetric</code> logs <code>CONVERGED_NATIVE</code> with <code>attempts=2</code>, <code>runtimeMs=120</code>, <code>finalResidual=0.0001</code>, and <code>traceRef</code> pointing to 7 sample points saved. <br>5. <code>modCoreEngine</code> stages <code>ApplyDescriptor</code> with solution value and includes <code>GS</code> audit payload built by <code>GSStatusToAudit</code>. <br>6. On commit, <code>Audit_Log</code> contains GOALSEEK audit entry referencing <code>traceRef</code>; telemetry aggregates show healthy <code>PctGSConverged</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modGoalSeekController (VBA)"> <strong>Short summary</strong><br><code>modGoalSeekController</code> makes numerical solving robust and auditable for enterprise-grade reconciliations by validating function shapes, limiting runaway solves, providing deterministic fallbacks, capturing trace-curves for forensic and reviewer inspection, and emitting structured telemetry and audits so operations and BI can measure reliability and tune thresholds. The module’s responsibilities are: protect Excel execution, return deterministic results, trace everything needed for replay, and integrate with reviewer governance for material exceptions. </td></tr></tbody></table></div><div class="row-count">Rows: 27</div></div><div class="table-caption" id="Table6" data-table="Docu_0202_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modSuggestionUI** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modSuggestionUI</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Module purpose (summary)</strong><br><code>modSuggestionUI</code> is the non-visual controller for the reviewer suggestion lifecycle in UpdateHR+. It manages session state, paging, policy enforcement, bulk operations, reviewer decision capture, staging for commit, audit integration, ML export preparation, and replayability. The module contains deterministic business logic and orchestration; UI rendering and event hookups are performed by <code>frmReviewerUI</code>. <code>modSuggestionUI</code> never performs heavy UI drawing — it prepares payloads and staging artifacts and exposes event handlers consumed by the form. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Design principles & guarantees</strong><br>1. Separation of concerns: UI rendering ↔ <code>frmReviewerUI</code>; business logic and persistence ↔ <code>modSuggestionUI</code>. <br>2. Determinism: identical inputs + configSnapshot + codeVersion → identical suggestion ordering and audit outputs. <br>3. Idempotency: decisions keyed by <code>runId</code> + <code>inputRowHash</code>; duplicates detected and deduped. <br>4. Audit-first: every user action produces an <code>Audit_Log</code> row with provenance and a stable <code>actionHash</code>. <br>5. Least-privilege & dual-sign: role checks and dual-sign enforcement for material operations are enforced in-line. <br>6. Performance: paging, prefetching, and memoization used to avoid long UI blocking. <br>7. Safety: pre-commit policy gates (materiality, daily caps, dual-sign) block accidental mass writes. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Primary public functions (summary)</strong><br>1. <code>StartSuggestionSession(runId As String, suggestions As Collection, options As Scripting.Dictionary) As Scripting.Dictionary</code> — bootstrap session. <br>2. <code>LoadSuggestions(runId As String, suggestions As Collection, Optional pageSize As Long)</code> — persist suggestion index and page-ready rows. <br>3. <code>OpenReviewerForm(runId As String, rowId As Long, displayOptions As Scripting.Dictionary)</code> — prepare and show form payload for a single row. <br>4. <code>ShowBulkReviewDialog(runId As String, options As Scripting.Dictionary)</code> — aggregated bulk preview and action UI driver. <br>5. <code>ApplyAutoConfirmThreshold(runId As String) As Scripting.Dictionary</code> — auto-stage high-confidence non-material suggestions respecting caps. <br>6. <code>ProcessReviewerDecision(decision As Scripting.Dictionary) As Scripting.Dictionary</code> — validate and persist reviewer decisions (approve, edit, split, reject, escalate). <br>7. <code>CommitApprovedSuggestions(runId As String, commitOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — gate and hand-off staged approvals for commit. <br>8. <code>AbortSuggestionSession(runId As String, reason As String, requestedBy As String)</code> — cancel session and optionally unstage. <br>9. <code>ExportSuggestionReport(runId As String, format As String, destPath As String, options As Scripting.Dictionary)</code> — produce ML/audit/export artifacts. <br>10. <code>ReplayRunSuggestions(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — replay decisions for QA and parity checks. <br>11. <code>ValidateUserRole(userId As String, requiredRole As String) As Boolean</code> — role enforcement helper. <br>12. <code>SimulateBulkPreview(runId As String, candidateList As Collection) As Scripting.Dictionary</code> — non-destructive impact simulation used in bulk UI. <br>13. <code>CreateAliasRequestIfAppropriate(rowId As Long, proposedAlias As String, suggestedTargetId As String, requestedBy As String)</code> — convenience to raise alias requests. <br>14. <code>ExportForMLTraining(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code> — privacy-safe MX export for retraining. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Data models & key sheet artifacts</strong><br>1. <code>SuggestionRecord</code> (Scripting.Dictionary): <code>runId</code>, <code>rowId</code>, <code>inputRowHash</code>, <code>rawInput</code>, <code>cleanInput</code>, <code>topCandidates</code>(Collection), <code>samplePostings</code>(Collection), <code>combinedScore</code>, <code>confidenceBand</code>, <code>isMaterial</code>, <code>deltaAmount</code>, <code>evidenceRefs</code>. <br>2. <code>Candidate</code> (Scripting.Dictionary): <code>candidateId</code>, <code>employeeId</code>, <code>fullName</code>, <code>orgUnit</code>, <code>costCenter</code>, <code>componentBreakdown</code> (json string for audit), <code>combinedScore</code>, <code>confidenceBand</code>, <code>rationaleString</code>, <code>signatureOverlap</code>, <code>priorConfirmCount</code>, <code>gsStatus</code> (GoalSeek metadata optional). <br>3. Hidden sheet: <code>__Suggestions_&lt;runId&gt;</code> — flattened index rows for form rendering: <code>rowId</code>, <code>displayName</code>, <code>topCandidateId</code>, <code>combinedScore</code>, <code>confidenceBand</code>, <code>isMaterial</code>, <code>deltaAmount</code>, <code>samplePostingRefs</code>, <code>jsonPayload</code>. <br>4. Staging sheet: <code>__Stage_Run_&lt;runId&gt;</code> — ApplyDescriptor rows ready for commit: <code>rowId</code>, <code>targetSheet</code>, <code>targetAddress</code>, <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>status</code>, <code>inputRowHash</code>. <br>5. Session sheet: <code>__Suggestion_Session_&lt;runId&gt;</code> — sessionToken, options snapshot, page cursor state. <br>6. <code>__Suggestion_Profile</code> optionally collects slow UI actions and trace metrics for tuning. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — StartSuggestionSession</strong><br>Signature: <code>StartSuggestionSession(runId As String, suggestions As Collection, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Responsibilities:<br>1. Acquire a session lock token via <code>LockingAndConcurrency</code> to prevent concurrent reviewer sessions for same run. <br>2. Persist <code>options</code> snapshot to <code>__Suggestion_Session_&lt;runId&gt;</code> and include <code>codeVersion</code> and <code>configSnapshot</code> fields for reproducibility. <br>3. Call <code>LoadSuggestions</code> to materialise the initial page of suggestions. <br>4. Compute <code>BulkSummary</code>: counts per <code>confidenceBand</code>, total <code>deltaAmount</code> per band, <code>materialCount</code>, and <code>topMaterialRows</code>. <br>5. Return <code>sessionDescriptor</code> containing <code>sessionToken</code>, <code>rowsLoaded</code>, <code>bulkSummary</code>, and <code>warnings</code> array if preconditions fail. <br>Audit: append <code>SESSION_START</code> row to <code>Audit_Log</code> including <code>runId</code>, <code>sessionToken</code>, <code>userId</code>, <code>options</code> snapshot and <code>startTime</code>. <br>Failure handling: on lock failure, return <code>status=LOCKED</code> with <code>lockedBy</code> metadata. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — LoadSuggestions</strong><br>Signature: <code>LoadSuggestions(runId As String, suggestions As Collection, Optional pageSize As Long = 100) As Long</code>.<br>Operation:<br>1. Accepts <code>suggestions</code> collection where each element corresponds to one input <code>row</code> and contains the top-K candidates generated by <code>modMatchingEngine</code>. <br>2. Normalize each item to <code>SuggestionRecord</code> shape and validate required keys <code>rowId</code>, <code>inputRowHash</code>, and <code>topCandidates</code>. <br>3. Flatten into rows for <code>__Suggestions_&lt;runId&gt;</code>: for each suggestion create a single row with compact fields and store full JSON payload in <code>jsonPayload</code> (for PQ and audit). <br>4. Index in-memory: build <code>dictSuggestionsByRowId</code> and <code>dictSuggestionsByInputHash</code> for fast lookup. <br>5. Page: write only first <code>pageSize</code> rows to visible portion; flag <code>hasMore=True</code> if more exist. <br>6. Return the number of rows written for the initial page. <br>Performance notes: batch write range values where possible and avoid per-row sheet calls; employ a 2D variant array for writes to reduce COM overhead. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — OpenReviewerForm</strong><br>Signature: <code>OpenReviewerForm(runId As String, rowId As Long, displayOptions As Scripting.Dictionary)</code>.<br>Flow & validations:<br>1. Validate session token and that <code>rowId</code> exists in <code>dictSuggestionsByRowId</code>. <br>2. Validate user role via <code>ValidateUserRole(userId, &quot;Reviewer&quot;)</code>. If user lacks privilege, write <code>AUTH_DENIED</code> to <code>Audit_Log</code> and return error. <br>3. Build <code>uiPayload</code> comprised of: top-N candidates with <code>componentBreakdown</code> parsed, sample posting rows extracted from <code>samplePostings</code>, <code>impactPreview</code> (deltaAmount per candidate if computed), <code>gsTrace</code> if GoalSeek invoked, <code>evidenceLinks</code> pointing to <code>SimManifest</code>. <br>4. Call <code>frmReviewerUI.LoadPayload(uiPayload)</code> and show modal. <br>5. When displayed, append <code>REVIEW_OPEN</code> audit row with <code>runId</code>, <code>rowId</code>, <code>userId</code>, <code>sessionToken</code>, <code>uiPayloadSummary</code>. <br>6. Ensure UI event bindings so <code>frmReviewerUI.OnApprove</code> calls back to <code>modSuggestionUI.ProcessReviewerDecision</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ShowBulkReviewDialog</strong><br>Signature: <code>ShowBulkReviewDialog(runId As String, options As Scripting.Dictionary)</code>.<br>Purpose: provide a single place to preview and act on multiple rows at once using configured business rules.<br>Key steps:<br>1. Build aggregated metrics: counts by <code>confidenceBand</code>, <code>estimatedReviewerRows</code>, <code>totalDelta</code> aggregated by orgUnit & costCenter, and <code>topNMaterialRows</code>. <br>2. Provide safe filters: exclude high-dollar orgUnits, or apply only to specific <code>costCenter</code> sets. <br>3. Display options: <code>ApplyAboveThreshold(t)</code>, <code>HoldBelowThreshold</code>, <code>PreviewImpact</code>, <code>ExportEvidence</code>, <code>RequireSecondarySign</code> toggle. <br>4. When <code>ApplyAboveThreshold</code> confirmed, simulate via <code>SimulateBulkPreview</code> and display impact; then create staged <code>ApplyDescriptor</code> entries in <code>__Stage_Run_&lt;runId&gt;</code> respecting <code>DailyCaps</code> and <code>Materiality</code> rules. <br>5. Create <code>BULK_APPLY_PLANNED</code> audit row including <code>options</code>, <code>stagedCount</code>, <code>expectedDelta</code> and <code>previewManifest</code>. <br>Safety: require multi-approval or a reviewer password if <code>expectedDelta</code> exceeds <code>modConfig.ReviewerHighDollarThreshold</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ApplyAutoConfirmThreshold</strong><br>Signature: <code>ApplyAutoConfirmThreshold(runId As String) As Scripting.Dictionary</code>.<br>Behaviour:<br>1. Load <code>autoApplyThreshold</code> from <code>modConfig</code> or session options. <br>2. Iterate suggestions sorted by <code>combinedScore</code> descending and evaluate: if <code>combinedScore &gt;= autoApplyThreshold</code> and <code>isMaterial=False</code> and daily caps permit, stage <code>ApplyDescriptor</code> to <code>__Stage_Run_&lt;runId&gt;</code>. <br>3. For material rows (per <code>modMateriality.EvaluateMateriality</code>) send to review queue instead. <br>4. Respect <code>MaxAutoPerRun</code> and <code>DailyAutoApplyCapRows</code>/<code>DailyAutoApplyCapAmount</code>. Stop auto-applying once caps reached and record <code>skippedDueToCap</code>. <br>5. Produce summary dictionary: <code>autoStagedCount</code>, <code>skippedMaterialCount</code>, <code>skippedCapCount</code>, <code>stagedRowIds</code> and append <code>AUTO_APPLY_SUMMARY</code> audit row. <br>Idempotency: check <code>__Stage_Run_&lt;runId&gt;</code> for existing <code>inputRowHash</code> to avoid double staging. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ProcessReviewerDecision</strong><br>Signature: <code>ProcessReviewerDecision(decision As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Input <code>decision</code> shape: <code>runId</code>, <code>rowId</code>, <code>decisionType</code> (<code>APPROVE</code>/<code>EDIT</code>/<code>SPLIT</code>/<code>REJECT</code>/<code>ESCALATE</code>), <code>chosenCandidateId</code>, <code>edits</code> (optional dict), <code>splitAllocations</code> (optional collection), <code>reviewerId</code>, <code>rationale</code>.<br>Validation & rules:<br>1. Confirm session existence and <code>rowId</code> validity. <br>2. Confirm <code>reviewerId</code> role via <code>ValidateUserRole</code>; if <code>decisionType=APPROVE</code> and <code>deltaAmount</code> > <code>modConfig.ReviewerHighDollarThreshold</code> require <code>SeniorReviewer</code> role or <code>secondarySign</code> presence. <br>3. For <code>APPROVE</code>: if <code>edits</code> exist (override cost center / employee id / date), validate fields against allowed schema and run <code>modImpactSimulation.RunWhatIfAdjustments</code> in preview-only mode to compute impact; if <code>impact</code> material above threshold block commit until second signer approves. <br>4. For <code>SPLIT</code>: validate <code>splitAllocations</code> sum to 100; create multiple <code>ApplyDescriptor</code> entries matching split percentages with proportional <code>afterValues</code>. <br>5. For <code>REJECT</code>: record the decision and optionally create an alias request if pattern detection shows likely alias relation. <br>6. For <code>ESCALATE</code>: move the <code>rowId</code> to <code>SeniorReviewQueue</code> and notify via UI markers; store <code>escalationReason</code>. <br>Persistence & audit:<br>- Persist <code>ReviewerDecision</code> JSON to <code>Audit_Log</code> with <code>actionHash</code> (deterministic SHA1-like composite), <code>reviewerId</code>, <code>timestamp</code>, and <code>rationale</code>. <br>- Stage resulting <code>ApplyDescriptor</code> records (or movement to escalation staging) into <code>__Stage_Run_&lt;runId&gt;</code> with <code>status=STAGED</code>. <br>Return: <code>confirmationToken</code>, <code>status=&quot;OK&quot;</code> or <code>status=&quot;AWAITING_SECONDARY&quot;</code>. <br>Idempotency: if identical <code>actionHash</code> already present return existing <code>confirmationToken</code> and no duplicate records. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — CommitApprovedSuggestions</strong><br>Signature: <code>CommitApprovedSuggestions(runId As String, commitOptions As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Pre-commit validations and flow:<br>1. Read staged records from <code>__Stage_Run_&lt;runId&gt;</code> and ensure no overlapping addresses or duplicated <code>inputRowHash</code>. <br>2. Run <code>MaterialityPolicyEnforcer</code> across staged set; if any <code>Escalate</code> flagged rows require additional approval, abort commit and return <code>status=&quot;AWAITING_ESCALATION_RESOLUTION&quot;</code>. <br>3. Validate final integrity: sample cell-level checksum check for targets included in <code>__Stage_Backup_&lt;runId&gt;</code>. <br>4. If OK, call <code>modCoreEngine.CommitRun(runId)</code> or return staged descriptors to the core commit driver. <br>5. Record <code>COMMIT_INIT</code> and later <code>COMMIT_COMPLETE</code> audit rows with chunk-level details and a run-level checksum. <br>Failure handling: partial commit triggers <code>RollbackRun</code>; <code>modSuggestionUI</code> writes <code>COMMIT_FAIL</code> with forensic pointers and notifies operators. <br>Return: <code>commitSummary</code> containing <code>committedCount</code>, <code>failedCount</code>, <code>commitChunks</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — AbortSuggestionSession</strong><br>Signature: <code>AbortSuggestionSession(runId As String, reason As String, requestedBy As String)</code>.<br>Abort behavior:<br>1. Validate <code>requestedBy</code> has <code>Admin</code> or <code>Operator</code> override privilege. <br>2. Optionally move staged entries from <code>__Stage_Run_&lt;runId&gt;</code> to <code>__Stage_Aborted_&lt;runId&gt;</code> and mark <code>status=ABORTED</code>. <br>3. Clear in-memory suggestion dictionaries and release session lock token. <br>4. Append <code>SESSION_ABORT</code> audit row with <code>reason</code>, <code>requestedBy</code>, <code>unstagedCount</code>, and a forensic manifest reference for <code>ForensicPack</code>. <br>5. If abort triggered by an error during commit, call <code>modCoreEngine.RollbackRun</code> first, then run forensic packaging. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ExportSuggestionReport</strong><br>Signature: <code>ExportSuggestionReport(runId As String, format As String, destPath As String, options As Scripting.Dictionary)</code>.<br>Export characteristics:<br>1. Supported formats: <code>CSV</code>, <code>NDJSON</code> (newline-delimited JSON), <code>JSON</code>, optional ZIP packaging. <br>2. Include row-level fields: <code>runId</code>, <code>rowId</code>, <code>inputRowHash</code>, <code>rawInput</code>, <code>cleanInput</code>, <code>candidateList</code> (componentBreakdown), <code>decision</code>, <code>reviewerId</code>, <code>timestamp</code>, <code>applyDescriptor</code>. <br>3. Evidence pack: include <code>samplePostingCSV</code> for top material rows and <code>ImpactReport</code> CSV created from <code>modImpactSimulation</code>. <br>4. Manifest: <code>codeVersion</code>, <code>configSnapshot</code>, <code>fileChecksums</code> (if available), <code>exportedBy</code>. <br>5. Streaming: write in chunks to avoid memory exhaustion and include <code>part</code> markers when necessary. <br>6. Security: if <code>options(&quot;hashPII&quot;)=True</code> then replace name/employeeId with salted hash using salt in <code>__Run_Config</code>. <br>Audit: append <code>EXPORT</code> row to <code>Audit_Log</code> containing <code>destPath</code>, <code>manifest</code>, <code>rowCount</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ReplayRunSuggestions</strong><br>Signature: <code>ReplayRunSuggestions(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Replay steps and diagnostics:<br>1. Load <code>configSnapshot</code> and <code>codeVersion</code> from <code>__Run_Config</code> for <code>runId</code> to ensure identical configuration. <br>2. For each original <code>rowId</code> (ordered by <code>rowOrdinal</code>) re-run matching pipeline or load precomputed <code>CandidateMap</code> where available and recompute <code>componentBreakdown</code> using <code>modFuzzyScores</code> with the same weightings. <br>3. Compare recomputed <code>topCandidateId</code> and <code>combinedScore</code> to stored <code>Audit_Log</code> entries; collect <code>mismatchRows</code>. <br>4. Classify mismatches: <code>CONFIG_CHANGE</code>, <code>EXTERNAL_SCORER_DIFFERENCE</code>, <code>FLOATING_PRECISION_DIFF</code>, <code>ALIAS_UPDATED</code>. <br>5. Produce <code>replayReport</code> summarizing <code>parityRate</code>, <code>mismatchCount</code>, <code>topReasons</code>, and per-row diffs. <br>6. Append <code>REPLAY</code> audit row with <code>parityRate</code> and <code>replayManifest</code> for QA. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ValidateUserRole</strong><br>Signature: <code>ValidateUserRole(userId As String, requiredRole As String) As Boolean</code>.<br>Implementation:<br>1. Read <code>modConfig.UserRoles</code> mapping or <code>__UserRoles</code> table. <br>2. Support hierarchical roles mapping: <code>Admin &gt; SeniorReviewer &gt; Reviewer &gt; Operator</code>. <br>3. Validate by level comparison; return Boolean. <br>4. On failure, append <code>AUTH_DENIED</code> non-blocking log row with <code>userId</code>, <code>requiredRole</code>, <code>context</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — SimulateBulkPreview</strong><br>Signature: <code>SimulateBulkPreview(runId As String, candidateList As Collection) As Scripting.Dictionary</code>.<br>Purpose & flow:<br>1. Create ephemeral <code>__Sim_&lt;runId&gt;</code> sheet and apply <code>candidateList</code> ApplyDescriptors in-memory to sample postings or to a sample partition of historical postings. <br>2. Recalculate <code>Calculator</code> locally in manual-calc mode and capture deltas aggregated by <code>DisclosureBucket</code> x <code>Period</code>. <br>3. Compute <code>totalDelta</code>, <code>DeltaPct</code>, <code>TopMaterialRows</code> and <code>evidenceRefs</code>. <br>4. Return <code>ImpactReport</code> and save CSV snapshot to <code>__Exports</code> folder for reviewer download. <br>5. Ensure full restoration of workbook calculation and UI state on exit. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — CreateAliasRequestIfAppropriate</strong><br>Signature: <code>CreateAliasRequestIfAppropriate(rowId As Long, proposedAlias As String, suggestedTargetId As String, requestedBy As String)</code>.<br>Flow:<br>1. Validate alias not colliding with <code>modMappingStore</code> canonical names unless admin override. <br>2. Write request to <code>Alias_Requests</code> sheet: <code>requestId</code>, <code>rowId</code>, <code>proposedAlias</code>, <code>suggestedTargetId</code>, <code>evidenceRefs</code>, <code>requestedBy</code>, <code>status=PENDING</code>. <br>3. Notify reviewer UI via increment of pending alias counter visible to admins. <br>4. Append <code>ALIAS_REQUEST</code> audit row referencing <code>requestId</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Function detail — ExportForMLTraining</strong><br>Signature: <code>ExportForMLTraining(runId As String, options As Scripting.Dictionary) As Scripting.Dictionary</code>.<br>Behavior & privacy:<br>1. Collect training rows from <code>Audit_Log</code> where actionType in (<code>APPROVE</code>,<code>REJECT</code>) and where <code>componentBreakdown</code> present. <br>2. For each confirmed row, produce positive example for chosen candidate and sample negative candidates (N negatives per positive) with same feature vector shape. <br>3. If <code>options(&quot;hashPII&quot;)=True</code> replace <code>rawInput</code> and <code>employeeId</code> with salted hash using <code>__Run_Config.salt</code>. <br>4. Stream NDJSON lines to <code>destPath</code> and produce <code>trainingManifest</code> listing <code>featureColumns</code>, <code>labelDefinition</code>, <code>rowCount</code>. <br>5. Append <code>ML_EXPORT</code> audit row including <code>trainingManifest</code> and <code>hashing</code> flag. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>UI wiring & callbacks (non-visual orchestration)</strong><br>1. Expose event handlers for the form: <code>OnFormOpen</code>, <code>OnApprove</code>, <code>OnReject</code>, <code>OnEdit</code>, <code>OnSplit</code>, <code>OnEscalate</code>, <code>OnBulkAction</code>, <code>OnExportEvidence</code>. <br>2. Each handler validates user role, constructs a <code>ReviewerDecision</code> dictionary and calls <code>ProcessReviewerDecision</code>. <br>3. Form-level telemetry: capture <code>ReviewDurationSeconds</code> per row and write aggregated telemetry to <code>__Telemetry</code> instead of per-action audit to reduce noise. <br>4. Ensure form <code>OnClose</code> updates <code>__Suggestion_Session_&lt;runId&gt;</code> with <code>lastViewedRow</code> and <code>sessionHeartbeat</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Explainability & audit integration</strong><br>1. Every staged or final decision must include <code>componentBreakdown</code> JSON: <code>{&quot;tokenOverlap&quot;:0.56,&quot;trigramJaccard&quot;:0.41,&quot;fuzzyScore&quot;:0.85,&quot;priorConfirmCount&quot;:3,&quot;combinedScore&quot;:0.81}</code>. <br>2. <code>rationaleString</code> is a concise human summary kept under 256 characters for quick review and included in <code>ApplyDescriptor</code>. <br>3. Store full verbose JSON in <code>Audit_Log.componentBreakdown</code> cell to allow PQ to extract features for model training. <br>4. Keep <code>actionHash = SHA1(runId &amp; rowId &amp; decisionType &amp; reviewerId &amp; timestamp)</code> to ensure tamper-evident traceability; recommend external signing for legal-grade audit. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Power Query (PQ) conceptual transforms for suggestion outputs</strong><br>1. Import <code>Audit_Log</code> export (ndjson/CSV). Use <code>Json.Document</code> to parse <code>componentBreakdown</code> and <code>applyDescriptor</code> JSON columns. <br>2. Expand nested fields to flat columns: <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>fuzzyScore</code>, <code>priorConfirmCount</code>, <code>combinedScore</code>, <code>confidenceBand</code>. <br>3. Join <code>Audit_Log</code> rows marked <code>APPROVE</code> to <code>ConfirmedMatches</code> to build <code>label</code> column for ML. <br>4. Group by <code>runId</code> and <code>confidenceBucket</code> to compute reviewer workload estimates and <code>totalDelta</code> per bucket for operational dashboards. <br>5. Export PQ output table to Power BI, ensuring <code>runId</code> and <code>rowId</code> are preserved for drillthrough to <code>Audit_Log</code> evidence. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Conceptual DAX measures for reviewer/ops dashboards</strong><br>1. <code>ReviewerLoadEstimate = COUNTROWS(FILTER(&#x27;Suggestions&#x27;,&#x27;Suggestions&#x27;[confidenceBand]=&quot;Review&quot;))</code>.<br>2. <code>AutoApplyRate = DIVIDE([AutoAppliedRows],[TotalRows])</code>.<br>3. <code>AvgReviewTime = AVERAGE(&#x27;ReviewLog&#x27;[ReviewDurationSeconds])</code>.<br>4. <code>MaterialEscalationRate = DIVIDE([MaterialEscalations],[ReviewedRows])</code>.<br>5. <code>PrecisionAtThreshold = DIVIDE([ConfirmedByReviewer],[ReviewedRows])</code> filtered by <code>combinedScore &gt;= threshold</code>. Use these in daily ops dashboards and tie them to <code>modConfig</code> thresholds for trend monitoring. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Policies enforced by modSuggestionUI (extracted)</strong><br>1. Role-based action gating: only <code>Reviewer</code> can <code>Approve</code>; <code>SeniorReviewer</code> required for amounts > <code>ReviewerHighDollarThreshold</code>. <br>2. Daily auto-apply caps: per-user and per-run enforced by <code>ApplyAutoConfirmThreshold</code>. <br>3. Materiality-first escalation: material rows are never auto-applied. <br>4. Dual-sign rule: if staged set <code>totalDelta</code> exceeds <code>DualSignAmount</code> require second reviewer signature before <code>Commit</code>. <br>5. Immutable audit: suggestions and decisions appended to <code>Audit_Log</code>; changes require migration-level operations. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Error handling & resilience</strong><br>1. All functions trap fatal errors and write <code>SUGGESTION_MODULE_ERROR</code> with <code>errorCode</code>, <code>stackTrace</code>, and minimal context to <code>__Error_Trace</code>. <br>2. For transient sheet write failures use <code>SafeRangeWrite</code> to retry with exponential backoff up to <code>maxRetries</code>. On persistent failure, mark session <code>ERROR</code> and advise manual remediation in <code>Audit_Log</code>. <br>3. For stale session locks, allow admin <code>forceUnlock</code> with recorded reason and audit entry. <br>4. For external scorer or helper service failures, fallback to local scoring algorithm and record <code>EXTERNAL_SCORER_FALLBACK</code> in audit and telemetry. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Performance & scaling guidance</strong><br>1. Page size default: 100 rows per UI page. Tune by user desktop memory. <br>2. Prefetch only light-weight fields for list rendering; defer componentBreakdown parsing to detail load to avoid heavy JSON parsing for lists. <br>3. Use memoization for repeated <code>componentBreakdown</code> requests and shared candidate feature lookups across pages. <br>4. For very large runs, recommend partitioning suggestions by <code>orgUnit</code> and operating in parallel reviewer sessions with non-overlapping partitions to reduce contention. <br>5. Export and compression: avoid building giant JSON strings in memory — stream to disk in parts. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Security & privacy considerations</strong><br>1. Default: PII should be hashed in exports unless explicit admin opt-in exists. <br>2. <code>reviewerNotes</code> may contain sensitive remarks; treat as confidential and limit retention when required by policy. <br>3. Access logs: <code>__Access_Log</code> records form opens and exports by <code>userId</code> and <code>timestamp</code>. <br>4. External ML transfers: always use salted hashes and TLS; record consent in <code>Audit_Log</code> when PII leaves workbook. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Testing matrix (recommended test cases)</strong><br>Unit tests and integration tests to implement via <code>modTestingHarness</code>:<br>1. <code>StartSuggestionSession</code> — session created, lock acquired, bulk summary accurate for synthetic suggestions. <br>2. <code>LoadSuggestions</code> — pagination works, indexing correct, jsonPayload parseable. <br>3. <code>OpenReviewerForm</code> — payload includes topCandidates and samplePostings for given <code>rowId</code> and writes <code>REVIEW_OPEN</code> audit row. <br>4. <code>ProcessReviewerDecision</code> — test <code>APPROVE</code>, <code>EDIT</code>, <code>SPLIT</code>, <code>REJECT</code>, <code>ESCALATE</code>, including validation of splits summing to 100 and edit field schema validation. <br>5. <code>ApplyAutoConfirmThreshold</code> — respects caps and material flags, idempotent behavior on repeated runs. <br>6. <code>CommitApprovedSuggestions</code> — gates materiality and dual-sign; test rollback behavior on simulated commit failure. <br>7. <code>ExportSuggestionReport</code> — produce stable NDJSON with manifest and checksums. <br>8. <code>ReplayRunSuggestions</code> — parity=100% with golden dataset under same configSnapshot. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Operational runbook excerpts (how-to)</strong><br>1. Daily operator flow: run PQ refresh → run matching → <code>StartSuggestionSession</code> → review <code>BulkSummary</code> → run <code>ApplyAutoConfirmThreshold</code> → review material rows → commit staged applies via <code>CommitApprovedSuggestions</code>. <br>2. Escalation: if <code>MaterialFlag</code> set, do not commit; route to <code>SeniorReviewer</code> and require <code>secondarySign</code> before <code>Commit</code>. <br>3. Incident: on <code>COMMIT_FAIL</code>, call <code>AbortSuggestionSession</code>, generate <code>ForensicPack</code> and restore <code>__Stage_Backup_&lt;runId&gt;</code> via <code>RollbackRun</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Examples & narratives (concise)</strong><br>Example 1: Auto-apply run — 1000 suggestions, <code>AutoApplyThreshold=0.90</code>, 200 rows above threshold, 8 flagged material → <code>ApplyAutoConfirmThreshold</code> stages 192 rows (skipped 8), writes <code>AUTO_APPLY_SUMMARY</code>, operator reviews preview then calls <code>CommitApprovedSuggestions</code>, commit completes and <code>COMMIT_COMPLETE</code> audit row produced. <br>Example 2: Split approval — a payroll adjustment needs 60/40 split across two cost centers; reviewer uses <code>Split</code> action, <code>ProcessReviewerDecision</code> creates two <code>ApplyDescriptor</code> rows with proportional <code>afterValues</code>, both staged and audited with <code>SPLIT</code> metadata. <br>Example 3: Tie resolution — top two candidates 0.82 vs 0.81 flagged <code>AMBIGUOUS_TIE</code>; <code>OpenReviewerForm</code> shows <code>ShowCandidateDiffs</code>, reviewer selects candidate, enters rationale, action persisted and used for later <code>RecommendThresholds</code> training. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>PQ & DAX conceptual examples for reviewer analytics</strong><br>Power Query steps:<br>1. Ingest <code>Audit_Log</code> NDJSON.<br>2. Parse <code>componentBreakdown</code> JSON and expand to columns. <br>3. Create <code>confidenceBucket</code> column: <code>Auto(&gt;=0.88)</code>, <code>Review(0.70–0.88)</code>, <code>Manual(&lt;0.70)</code>. <br>4. Aggregate counts and sum <code>deltaAmount</code> by <code>confidenceBucket</code> and <code>orgUnit</code>. <br>5. Output BI-ready table for Power BI Dashboard. <br>DAX measures (conceptual):<br>1. <code>AutoApplyRate = DIVIDE([AutoAppliedRows],[TotalRows])</code>.<br>2. <code>AvgCombinedScore = AVERAGE(Suggestions[combinedScore])</code>.<br>3. <code>ReviewerThroughput = DIVIDE([ReviewedRows], [ActiveReviewerHours])</code>.<br>4. <code>MaterialEscalationPct = DIVIDE([MaterialEscalations],[ReviewedRows])</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Acceptance criteria for module delivery</strong><br>1. Deterministic replay: <code>ReplayRunSuggestions</code> reproduces initial decisions for golden dataset when <code>configSnapshot</code> and <code>codeVersion</code> unchanged. <br>2. Idempotency: repeated <code>ProcessReviewerDecision</code> calls for identical <code>actionHash</code> do not duplicate staging or audit rows. <br>3. Audit completeness: every state transition (session start/open/review/decision/stage/commit/abort/export) writes a corresponding <code>Audit_Log</code> row with required provenance fields. <br>4. Performance: UI page open latency < 1s on typical hardware for pageSize 100 with prefetch enabled (measure on reference machine). <br>5. Security: exports default to hashed PII; role checks block unauthorized actions. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Developer notes & implementation guidance</strong><br>1. Use <code>Scripting.Dictionary</code> extensively for in-memory indexes and clear them at session end. <br>2. Minimise COM calls: bulk-read <code>__Suggestions</code> into 2D arrays and bulk-write staged rows to <code>__Stage_Run</code> with a single Range.Value assignment. <br>3. Use deterministic <code>actionHash</code> composition to avoid double-writes; store <code>actionHash</code> as a unique key in <code>__DecisionIndex</code>. <br>4. For large exports, stream to file rather than building entire string in memory; use ADODB.Stream or file system streaming patterns. <br>5. Document <code>sessionToken</code> semantics and TTL; add an admin unlock path for orphaned sessions. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Common pitfalls & mitigations</strong><br>1. Pitfall: heavy JSON parsing per UI row → sluggish UI. Mitigation: parse only lightweight fields for listing and defer full json parsing to detail view. <br>2. Pitfall: unbounded memo caches causing memory leaks. Mitigation: bound caches by <code>memoSizeLimit</code> and clear on <code>AbortSuggestionSession</code>. <br>3. Pitfall: failing to enforce dual-sign rules pre-commit. Mitigation: centralize policy enforcement in <code>CommitApprovedSuggestions</code>. <br>4. Pitfall: unlabeled or inconsistent <code>componentBreakdown</code> versions. Mitigation: include <code>explainVersion</code> field and reject mismatched versions unless migration path provided. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Delivery checklist</strong><br>1. <code>modSuggestionUI.bas</code> with full unit tests and integration tests. <br>2. <code>frmReviewerUI.frm</code> userform with event hookups to <code>modSuggestionUI</code>. <br>3. Hidden-sheet templates: <code>__Suggestions_&lt;runId&gt;</code>, <code>__Stage_Run_&lt;runId&gt;</code>, <code>__Suggestion_Session_&lt;runId&gt;</code>, <code>__Sim_&lt;runId&gt;</code>. <br>4. Export tool: NDJSON/ZIP generator with manifest and checksum. <br>5. Runbook section covering daily ops, escalation, and forensic steps. </td></tr><tr><td data-label="Per-function technical breakdown — modSuggestionUI (VBA)"> <strong>Closing summary (concise)</strong><br><code>modSuggestionUI</code> orchestrates the human-in-the-loop suggestion lifecycle: session management, safe auto-applying, curated reviewer experiences, audit-grade decision capture, staged commit hand-off, ML export readiness, and deterministic replay. Implement with strong idempotency, role enforcement, staged artifacts for atomic commits, and PQ/DAX hooks for operations dashboards and ML training. </td></tr></tbody></table></div><div class="row-count">Rows: 35</div></div><div class="table-caption" id="Table7" data-table="Docu_0202_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **frmReviewerUI (VBA UserForm)**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>frmReviewerUI (VBA UserForm)</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Module purpose (concise)</strong><br><code>frmReviewerUI</code> is the interactive reviewer interface for UpdateHR+. It is a thin, auditable UI layer that presents top-N match suggestions, supporting evidence, and explainability to human reviewers and captures deterministic reviewer decisions (approve/reject/edit/split/escalate). The form delegates business rules to controller modules (<code>modSuggestionUI</code>, <code>modMateriality</code>, <code>modAudit</code>, <code>modCoreEngine</code>) and only manages presentation, validation of reviewer actions, and creation of structured decision payloads for staging and audit. This spec details every public event, helper, data contract, validation, UX pattern, telemetry, PQ and DAX integration notes, testing cases, and governance gates. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Design principles & constraints</strong><br>1. Separation of concerns: UI only — no domain writes except through controllers.<br>2. Determinism: identical inputs + config + code version produce identical UI-presented candidate ordering and rationale; tie-breakers deterministic (employeeId, hireDate, candidateId).<br>3. Audit-first: every reviewer action writes an <code>AuditRow</code> with full provenance before any staging. <br>4. Accessibility: keyboard-first & screen-reader friendly; localized strings via <code>__Localization</code>. <br>5. Role-aware: capabilities (approve, bulk apply, high-dollar override) depend on <code>modConfig.UserRoles</code> and per-run gating. <br>6. Performance: lazy-load heavy evidence (postings, GS trace) and cache per session; render candidate list from in-memory collections to avoid COM churn. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>High-level responsibilities</strong><br>1. Render Top-N candidate list and allow navigation and filtering.<br>2. Show candidate explainability (componentBreakdown) and evidence (sample postings, prior confirms, GS traces).<br>3. Enforce policy gates: materiality, daily caps, reviewer threshold, dual approval for large amounts.<br>4. Capture structured decisions (<code>ApplyDescriptor</code>, <code>decisionMeta</code>) and pass to <code>modSuggestionUI</code>/<code>modCoreEngine</code> for staging & commit.<br>5. Record telemetry for reviewer metrics and UX diagnostics.<br>6. Export evidence and support replay comparisons for QA. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Primary UI controls (logical list)</strong><br>1. Header area: <code>LabelRunId</code>, <code>LabelCodeVersion</code>, <code>LabelUser</code>, <code>LabelQueuePosition</code>.<br>2. Search/filter bar: <code>TextSearch</code>, <code>DropDownOrg</code>, <code>DropDownCostCenter</code>, <code>ConfidenceBandFilter</code>.<br>3. Candidate grid: <code>GridCandidates</code> with columns <code>Rank</code>, <code>CandidateName</code>, <code>EmployeeId</code>, <code>OrgUnit</code>, <code>CostCenter</code>, <code>Confidence%</code>, <code>CombinedScore</code>, <code>MatchedRule</code>, <code>DeltaAmt</code>, <code>PriorConfirmCount</code>, <code>GSStatusIcon</code>.<br>4. Detail pane: <code>PanelCandidateDetails</code>: <code>LabelFullName</code>, <code>LabelMeta</code>, <code>TableComponentBreakdown</code>, <code>ExamplePostingsList</code>, <code>TraceChartThumbnail</code>, <code>EvidenceLinks</code>.<br>5. Action toolbar: <code>BtnApprove</code>, <code>BtnReject</code>, <code>BtnSplit</code>, <code>BtnEdit</code>, <code>BtnEscalate</code>, <code>BtnBulkApply</code>, <code>BtnExportEvidence</code>, <code>BtnReplayCompare</code>, <code>BtnNext</code>, <code>BtnPrev</code>.<br>6. Controls for gating: <code>PasswordPromptModal</code>, <code>DualApprovalModal</code>, <code>RationaleTextbox</code> mandatory for edits and overrides.<br>7. Footer: <code>StatusBar</code> (progress, hints), <code>PendingCount</code>, <code>ReviewerSessionSave</code> toggle. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Public event handlers (per-function breakdown)</strong><br>1. <code>InitializeForm(runContext As Scripting.Dictionary, sessionOptions As Scripting.Dictionary)</code> — initialiser called by <code>modSuggestionUI</code> before Showing the form.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>runContext</code> contains <code>runId</code>, <code>userId</code>, <code>codeVersion</code>, <code>configSnapshot</code>; <code>sessionOptions</code> contains <code>singleRow</code> Boolean, <code>rowIds</code> array if bulk, <code>startRowIndex</code>, <code>topN</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Actions: validate <code>userId</code> privileges via <code>modSuggestionUI.ValidateReviewerPermission</code>, load <code>__Localization</code>, set UI control states, prefetch candidate pages for <code>startRowIndex</code> by calling <code>modSuggestionUI.LoadSuggestions</code>, populate <code>GridCandidates</code> first page. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Audit/Telemetry: record <code>FormInitialized</code> telemetry event with <code>runId</code>, <code>userId</code>, <code>startRowId</code>, <code>sessionOptions</code>. <br>2. <code>Form_Activate()</code> — form-level event run after show.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: focus <code>GridCandidates</code>, ensure Modal state, set keyboard accelerators binding (Ctrl+Enter approve, Ctrl+S bulk apply, etc.), start inactivity timer for session auto-save. <br>3. <code>LoadSuggestionsForRow(rowId As Long)</code> — core loader invoked when reviewer navigates to a different input row.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Inputs: <code>rowId</code> (source staff list row identifier). <br>&nbsp;&nbsp;&nbsp;&nbsp;• Actions: call <code>modSuggestionUI.GetCandidates(runId, rowId, topN)</code> which returns collection of candidate objects; map to UI rows; store full candidate objects in <code>frm</code>-level dictionary <code>dictCandidates(rowId)-&gt;Collection</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• UI: clear detail pane, present highlight for top candidate, compute <code>confidenceBand</code> color, and set <code>BtnApprove</code> enabled if policy allows. <br>4. <code>GridCandidates_OnSelectionChanged(index As Long)</code> — candidate selection event.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Actions: retrieve candidate object from form cache; call <code>RenderCandidateDetail(candidate)</code>; lazy-load example postings and GS trace via <code>modSuggestionUI.FetchEvidence(runId, rowId, candidateId)</code> or <code>modGoalSeekController</code> if needed; update <code>StatusBar</code> with evidence load status. <br>5. <code>RenderCandidateDetail(candidate As Scripting.Dictionary)</code> — populate detail pane.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Detail shown: <code>componentBreakdown</code> table, <code>rationaleString</code>, <code>evidenceSamples</code> (limited to N), <code>priorConfirmHistory</code>, <code>signatureHistory</code>, <code>lastConfirmedDate</code>, <code>materialityIndicator</code>, <code>GSSummary</code> if present. <br>&nbsp;&nbsp;&nbsp;&nbsp;• UX: show compact rationale and "More detail" to expand full JSON. Provide accessible labels. <br>6. <code>BtnApprove_Click()</code> — primary reviewer approval flow.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Validations: ensure <code>modSuggestionUI.ValidateReviewerPermission(userId, &#x27;approve&#x27;)</code> true; check <code>modMateriality.EvaluateMateriality(rowData)</code> — if escalate flag returned then redirect to escalate flow; check <code>modBatchProcessing.EnforceDailyLimits(runId, userId)</code> and prompt for override only if permitted. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Decision payload: build <code>decisionMeta</code> containing <code>reviewerId</code>, <code>timestamp</code>, <code>rationale</code>, <code>uiContext</code> (selectedCandidateId, combinedScore, componentBreakdown), <code>sessionId</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Commit path: call <code>modSuggestionUI.CaptureReviewerDecision(runId, rowId, chosenCandidateId, decisionMeta)</code> which persists in <code>Audit_Log</code> and stages <code>ApplyDescriptor</code> to <code>__Stage_Run_&lt;runId&gt;</code>. When <code>CaptureReviewerDecision</code> returns success, mark UI row status <code>&#x27;APPROVED_PENDING_COMMIT&#x27;</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Telemetry/Audit: send <code>ReviewerAction</code> telemetry event and ensure <code>AuditRow</code> contains <code>beforeJSON</code>, <code>afterJSON</code> and <code>componentBreakdown</code>. <br>7. <code>BtnReject_Click()</code> — marking as no-match or alias request.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Actions: prompt reviewer for a rejection reason (dropdown + optional notes); allow suggestion of alias via <code>RequestAlias</code> link if reviewer indicates a likely correct mapping exists; call <code>modSuggestionUI.RecordReject</code> which appends <code>NO_MATCH</code> audit row. If <code>AliasRequested</code>, call <code>modAliasManagement.RequestAlias</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;• UI: move row to <code>REJECTED</code> queue and optionally show <code>SuggestAliasPopup</code>. <br>8. <code>BtnSplit_Click()</code> — split allocation flow.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Subform: open <code>frmSplitAllocation</code> with editable rows representing target candidates and allocation percentages or amounts. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Validation: allocations sum equals original amount; each allocation above <code>materialityThreshold</code> triggers review gating; disallow negative or zero allocations. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Output: multiple <code>ApplyDescriptor</code> entries (one per split part) with <code>decisionMeta</code> linking them; append audit rows for each split part; optionally call <code>modImpactSimulation.SimulateRunPreview</code> to show pre-commit impact on sample postings. <br>9. <code>BtnEdit_Click()</code> — inline edit flow for candidate mapping fields.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Editable fields: <code>costCenter</code>, <code>employeeId</code> (with lookup), <code>GLAccount</code> (if applicable). Edits are non-destructive: stored in <code>ApplyDescriptor</code> only; do not change <code>HRMaster</code> unless alias approved. <br>&nbsp;&nbsp;&nbsp;&nbsp;• Validation: on edit, call <code>modMappingStore.DetectPotentialDuplicateMaster</code> to detect collisions; if detected, show warning and require reviewer confirmation (and rationale) before allowing staging. Append an <code>EDIT</code> audit row. <br>10. <code>BtnEscalate_Click()</code> — escalation flow.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Actions: capture <code>escalationReason</code>, evidence snapshot, include <code>TraceCurve</code> or full postings if needed, mark row status <code>ESCALATED</code>, append <code>ESCALATE</code> audit row. Optionally call external notification (email/webhook) via helper service. <br>11. <code>BtnBulkApply_Click()</code> — bulk apply action.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: compute candidate eligibility by evaluating combinedScore against <code>sessionOptions(&quot;bulkThreshold&quot;)</code> or admin threshold; compute aggregate monetary impact; check <code>DailyAutoApplyCapRows</code> and <code>DailyAutoApplyCapAmount</code>; if safe, present confirmation dialog with a summary of counts and totals and an "I approve" checkbox. Bulk apply is chunked and staged per chunk; audit each chunk commit and collect per-chunk errors. Bulk apply requires explicit reviewer permission and may require password or dual approval if totals exceed configured caps. <br>12. <code>BtnExportEvidence_Click()</code> — export evidence for selected row(s).<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: marshal candidate details, componentBreakdown, sample postings, GS traces, and <code>ApplyDescriptor</code> into CSV/ndjson using <code>modAuditExportHelpers.WriteJSONFile</code> and <code>PackageExport</code>. Include <code>manifest.json</code> with <code>runId</code>, <code>codeVersion</code>, and <code>configSnapshot</code>. Exports saved to secure path and path shown to user. <br>13. <code>BtnReplayCompare_Click()</code> — replay comparison for QA.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: call <code>modBatchUtilities.ReplayRun(originalRunId, replayOptions)</code> with <code>replayOptions</code> including <code>compareTolerance</code>. Present side-by-side <code>componentBreakdown</code> diffs and highlight changed decision outcomes. Append a <code>REPLAY</code> audit row with <code>replayResultStatus</code>. <br>14. <code>BtnNext_Click()</code> / <code>BtnPrev_Click()</code> — navigation handlers.<br>&nbsp;&nbsp;&nbsp;&nbsp;• Behaviour: move to next/previous row in review queue and call <code>LoadSuggestionsForRow</code> accordingly; persist <code>ReviewerSession</code> state after each navigation to <code>__Reviewer_Sessions</code>. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Internal helper functions (detailed)</strong><br>1. <code>RequireReviewerPassword(action As String, amount As Double) As Boolean</code> — UI modal that prompts for reviewer password or second reviewer credentials if <code>amount</code> > <code>ReviewerHighDollarThreshold</code> or action requires escalation. Returns <code>True</code> on successful authentication. <br>2. <code>ValidateActionPolicy(userId As String, actionType As String, rowData As Scripting.Dictionary) As Scripting.Dictionary</code> — wrapper that queries <code>modConfig</code>, <code>modMateriality</code>, and <code>modBatchProcessing</code> and returns <code>validationResult</code> with keys <code>allowed</code> Boolean, <code>reason</code> String, <code>gating</code> String (e.g., <code>DUAL_APPROVAL_REQUIRED</code>). <br>3. <code>BuildDecisionMeta(userId As String, rowId As Long, candidateId As String, actionType As String, uiContext As Scripting.Dictionary) As Scripting.Dictionary</code> — construct canonical decision meta used for audit and staging: includes <code>reviewerId</code>, <code>timestamp</code>, <code>rationale</code>, <code>uiState</code> (filters/sort), <code>componentBreakdownSnapshot</code>, <code>evidenceSnapshotRef</code>, <code>sessionId</code>. <br>4. <code>StageApplyDescriptor(applyDesc As Scripting.Dictionary) As Boolean</code> — wrapper that calls <code>modSuggestionUI.StageApplyDescriptor</code> which writes to <code>__Stage_Run_&lt;runId&gt;</code>; the helper handles retries and returns boolean; on error, append an <code>APPLY_STAGE_FAILED</code> audit row with diagnostics. <br>5. <code>AppendAuditLocal(auditRec As Scripting.Dictionary)</code> — ensure <code>auditRec</code> includes <code>codeVersion</code>, <code>explainVersion</code>, <code>configSnapshot</code> then call <code>modAudit.AppendAuditRow</code>; retry on transient errors and present a friendly message to reviewer if persistent. <br>6. <code>FetchEvidenceCached(runId As String, rowId As Long, candidateId As String) As Scripting.Dictionary</code> — in-form cache lookup for evidence; if missing, call <code>modSuggestionUI.FetchEvidence</code> and cache on <code>__UI_Cache_&lt;sessionId&gt;</code> hidden sheet and in-memory dictionary. Cache TTL tied to session. <br>7. <code>RenderTraceChart(tracePoints As Collection)</code> — lightweight rendering of GS trace thumbnail using small canvas control or embedded chart; do not perform heavy charting in VBA UI thread — snapshot only and link to full trace export for deep diagnostics. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Data contracts & schema (explicit)</strong><br>1. <code>ApplyDescriptor</code> — fields required: <code>runId</code>, <code>rowId</code>, <code>inputRowHash</code>, <code>candidateId</code> (or <code>splitParts[]</code>), <code>beforeJSON</code>, <code>afterJSON</code>, <code>decisionMeta</code> (see below), <code>stagedBy</code> = <code>&quot;frmReviewerUI&quot;</code>, <code>stagedAt</code> timestamp, <code>applyId</code> GUID. <br>2. <code>decisionMeta</code> — fields: <code>reviewerId</code>, <code>timestamp</code>, <code>rationale</code>, <code>uiContext</code> (filter/sort), <code>sessionId</code>, <code>approvalMethod</code> (manual/password/dual), <code>evidenceRef</code>. <br>3. <code>AuditRow</code> — standard Audit schema extended with <code>uiAction</code>, <code>componentBreakdownJSON</code>, <code>confidenceBand</code>, <code>materialFlag</code>, <code>traceRef</code>, <code>applyId</code> (if staged), <code>rowChecksum</code>. <br>4. <code>ReviewerSession</code> — <code>sessionId</code>, <code>userId</code>, <code>startTime</code>, <code>lastRowViewed</code>, <code>filters</code>, <code>pageSize</code>, <code>persisted</code> Boolean. <br>5. <code>FeatureVector</code> (for ML): <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>levScore</code>, <code>phoneticFlag</code>, <code>priorConfirmCount</code>, <code>sameOrgFlag</code>, <code>signatureOverlap</code>, <code>combinedScore</code>, <code>materialFlag</code>, <code>label</code> (if confirmed). The form must produce and persist this when capturing decisions. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Explainability UX & content (how to present)</strong><br>1. Short rationale: single-line <code>rationaleString</code> for immediate reading, max ~140 characters, e.g., <code>&quot;token 0.62+trigram 0.18+lev 0.14+prior 0.06 =&gt; 0.78 (REVIEW)&quot;</code>. <br>2. Expandable JSON: full <code>componentBreakdown</code> stored as JSON in hidden field with "View raw JSON" link for analysts. <br>3. Evidence list: show top 3 example postings with date, amount, description and link "Show more (N)". <br>4. GS trace: show small curve thumbnail; clicking opens full trace page with sample points and pre-commit behaviour. <br>5. Visual cues: confidence color bands (green >= auto, amber = review, red = manual), materiality icons (⚠), and prior-confirm count badges. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Policy gating & approval flows</strong><br>1. Single approval path: typical for items below monetary threshold and within daily caps where <code>combinedScore &gt;= AutoThreshold</code> but reviewer chooses to confirm UI. <br>2. Dual approval path: enforced when <code>materiality</code> or <code>totalBulkAmount</code> exceed <code>modConfig.DualApprovalThreshold</code>; second reviewer executes <code>DualApprove</code> UI which attaches <code>secondaryReviewerId</code> and <code>secondarySignatureHash</code> to <code>ApplyDescriptor</code>. <br>3. Password gating: for immediate single-reviewer high-dollar approvals require inline password entered via ephemeral modal validated against secure store or external auth if available (do not store password). <br>4. Escalation: <code>BtnEscalate</code> moves row to <code>ESCALATED</code> queue and alerts senior reviewers; no staging permitted until clear. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Telemetry & diagnostics (what to collect)</strong><br>1. Form open/close events with durations and <code>runId</code>.<br>2. Per-row time spent (focus on <code>LoadSuggestionsForRow</code> to <code>BtnApprove</code> latency).<br>3. Action events: <code>Approve</code>, <code>Reject</code>, <code>Split</code>, <code>Edit</code>, <code>Escalate</code>, <code>BulkApply</code> with timestamps and success/failure codes. <br>4. Evidence fetch timing & cache hit rate; slow evidence fetchs appended to <code>__UI_Diagnostics</code>.<br>5. Bulk apply chunk timings and per-chunk failures. <br>6. Telemetry privacy: do not include raw PII; store only <code>inputRowHash</code> when possible; if needing PII for debug, hash values with <code>__Run_Config.salt</code>. Telemetry writer uses <code>modTelemetry.RecordTelemetryPoint</code>. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Power Query (PQ) & BI integration (how reviewer outputs are consumed)</strong><br>1. Periodic export: <code>modAudit.ExportAudit(runId, &#x27;ndjson&#x27;, destPath)</code> called after run finalization. PQ steps to ingest: <code>Json.Document</code> -> expand <code>componentBreakdown</code> -> normalize <code>ApplyDescriptor</code> arrays -> create <code>FuzzyAudit</code> table. <br>2. PQ transforms to produce <code>ReviewerActivity</code> table: group by <code>reviewerId</code> and compute <code>AvgTimePerRow</code>, <code>ApprovalRate</code>, <code>OverrideRate</code>. <br>3. Build <code>ConfirmedMatches</code> training dataset: join <code>FuzzyAudit</code> with reviewer decisions using <code>applyId</code> and <code>decisionMeta</code> label. <br>4. Provide <code>ImpactReport</code> PQ flow from <code>__Sim_&lt;runId&gt;</code> to compute aggregated Delta by <code>DisclosureBucket</code> and period for final reviewer sign-off. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Conceptual DAX measures for reviewer dashboards</strong><br>1. <code>ReviewerApprovalRate = DIVIDE([Approvals],[Reviews])</code>.<br>2. <code>AvgTimePerReview = AVERAGE(ReviewerActivity[TimeSec])</code>.<br>3. <code>OverrideRate = DIVIDE([ManualOverrides],[AutoCandidatesPresented])</code>.<br>4. <code>MaterialEscalationCount = COUNTROWS(FILTER(Audit, Audit[materialFlag]=&quot;Escalate&quot;))</code>.<br>5. <code>ReviewerPrecision = DIVIDE([TruePositives],[TruePositives]+[FalsePositives])</code> where TP/FP derived from <code>ConfirmedMatches</code> ground truth sample. <br>These measures should be consumed by operations dashboards for tuning thresholds and reviewer staffing. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Security & compliance specifics for frmReviewerUI</strong><br>1. Role enforcement: call <code>modConfig.UserRoles</code> on form open and re-check before any sensitive action. <br>2. Passwords & approvals: do not store plain passwords; if external auth used, store ephemeral token only for session. <br>3. PII minimisation: telemetry and exports default to hashed identifiers; opt-in real PII export only for accredited reviewers via admin controls. <br>4. Evidence export: require <code>ExportEvidence</code> permission and write assets only to pre-approved secure network paths; recommend out-of-band encryption via deployment scripts. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Testing & QA checklist (explicit)</strong><br>1. Unit tests for UI logic: simulate <code>GridCandidates_OnSelectionChanged</code> with mock candidates and assert <code>RenderCandidateDetail</code> populates correct fields. <br>2. Integration tests: simulate <code>BtnApprove_Click</code> path to ensure <code>modSuggestionUI.CaptureReviewerDecision</code> called and <code>__Stage_Run_&lt;runId&gt;</code> updated with <code>ApplyDescriptor</code>. <br>3. Policy tests: attempt high-dollar approval and assert password prompt + dual-approval gating triggers. <br>4. Accessibility tests: keyboard-only navigation, screen reader labels present, high-contrast mode. <br>5. Performance tests: simulate paged loads of 1,000 rows and ensure first-page render < target ms (configurable). <br>6. Telemetry tests: events emitted for form open/close, actions and evidence fetch latencies. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Edge cases and mitigations</strong><br>1. Offline reviewer: if external scorer or telemetry unavailable, UI shows unobtrusive warning and allows local cached decisions to be staged; ensure <code>modSuggestionUI</code> records fallback path in <code>componentBreakdown</code>. <br>2. Long evidence payloads: truncate display after N items and provide ExportEvidence link. <br>3. Candidate tie: show tie-break rationale and enforce deterministic tie-breaker order; allow reviewer to pick but record the tie-break rule used. <br>4. Staging write failures: if <code>StageApplyDescriptor</code> fails, retry and show clear message; persist <code>decisionMeta</code> in local session storage and allow reviewer to retry or export forensic pack. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Examples & walkthroughs (narrative)</strong><br>Example single-row approve (narrative):<br>&nbsp;&nbsp;&nbsp;&nbsp;1. Reviewer opens form for rowId 324; <code>InitializeForm</code> loads top-3 candidates. <br>&nbsp;&nbsp;&nbsp;&nbsp;2. Candidate 1 shows <code>combinedScore=0.91</code> (green auto band), <code>materialFlag=false</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;3. Reviewer clicks <code>Approve</code>, enters brief rationale, <code>RequireReviewerPassword</code> not triggered, <code>CaptureReviewerDecision</code> stages <code>ApplyDescriptor</code>, <code>Audit_Log</code> appended, UI marks <code>APPROVED_PENDING_COMMIT</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;4. After chunk commit the core engine writes final <code>COMMITTED</code> audit row. <br>Example split and simulate (narrative):<br>&nbsp;&nbsp;&nbsp;&nbsp;1. Reviewer selects <code>Split</code>, allocates 60% to candidate A and 40% to candidate B. <br>&nbsp;&nbsp;&nbsp;&nbsp;2. Form calls <code>modImpactSimulation.SimulateRunPreview</code> for the split and presents <code>ImpactReport</code> preview. <br>&nbsp;&nbsp;&nbsp;&nbsp;3. Reviewer accepts, form stages two <code>ApplyDescriptor</code> rows and writes two <code>APPLY</code> audit rows. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Operational runbook snippets (how reviewers should operate)</strong><br>1. Pre-review: ensure <code>__Localization</code> and <code>__Run_Config</code> loaded; confirm <code>modConfig.UserRoles</code> assignment. <br>2. During review: use search/filter to narrow candidates; open detail before approving; enter concise rationale. <br>3. Bulk apply: always run <code>ExportImpactReport</code> before bulk applying and verify daily caps. <br>4. Incident: if suspect data tampering or unexpected behavior, use <code>BtnReplayCompare</code> and create <code>ForensicPack</code>; notify governance per runbook. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Developer notes & pitfalls to avoid</strong><br>1. Avoid heavy string concatenations or JSON serialisations in UI thread for large payloads — offload to helper modules. <br>2. Keep in-memory caches bounded per session; clear on close. <br>3. Do not perform direct writes to primary sheets from UI; always stage via controller. <br>4. Ensure <code>AppendAuditRow</code> is resilient: wrap in retry loop and persist unsent audit rows locally for later flush. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Acceptance criteria for frmReviewerUI delivery</strong><br>1. All event flows implemented and tested: open, load candidates, select, approve, reject, split, edit, escalate, bulk apply, export. <br>2. Every reviewer action writes a valid <code>AuditRow</code> with <code>componentBreakdown</code> and <code>decisionMeta</code>. <br>3. Policy gates enforced and dual-approval flows operational. <br>4. Accessibility and localization validated. <br>5. Integration tests with <code>modSuggestionUI</code>, <code>modAudit</code>, <code>modCoreEngine</code>, <code>modMateriality</code>, and <code>modImpactSimulation</code> pass. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>PQ and DAX conceptual examples for reviewer outputs (short)</strong><br>1. PQ transform to flatten <code>componentBreakdown</code> JSON from <code>Audit_Log</code>: use <code>Json.Document</code> -> expand fields <code>tokenOverlap</code>, <code>trigramJaccard</code>, <code>levScore</code>, <code>priorConfirmCount</code>, <code>combinedScore</code>, <code>rationale</code>. <br>2. PQ to prepare <code>ReviewerActivity</code> table: group <code>Audit_Log</code> by <code>reviewerId</code> and compute <code>AvgTimePerRow</code>, <code>ApprovalRate</code>, <code>OverrideRate</code>. <br>3. DAX measure example: <code>ReviewerPrecision = DIVIDE([TruePositives],[TruePositives]+[FalsePositives])</code> where TP/FP derived by joining <code>ConfirmedMatches</code>. Use <code>ReviewerPrecision</code> to tune <code>AutoApplyThreshold</code>. </td></tr><tr><td data-label="Per-function technical breakdown — frmReviewerUI (VBA UserForm)"> <strong>Final notes & deliverables</strong><br>1. Provide localizable string keys for all UI texts in <code>__Localization</code>. <br>2. Ensure form reads <code>codeVersion</code> and <code>configSnapshot</code> and prints them in footer for audit. <br>3. Keep <code>frmReviewerUI</code> thin — delegate business rules to <code>modSuggestionUI</code>, <code>modMateriality</code>, <code>modAudit</code> and ensure testability by injecting <code>mock</code> data for unit tests. <br>4. Document the <code>ApplyDescriptor</code> JSON schema in the repository and include migration scripts if schema evolves. </td></tr></tbody></table></div><div class="row-count">Rows: 21</div></div><div class="table-caption" id="Table8" data-table="Docu_0202_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modAudit** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modAudit</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Module purpose (summary)</strong><br><code>modAudit</code> is the authoritative append-only audit subsystem for UpdateHR+. It is responsible for deterministic event capture, durable storage of run-level and per-row provenance, exportable immutable artifacts, integrity/seal computations, forensic bundle generation, and safe replay. The module exposes small, well-tested APIs for single-row appends, batch writes, seal/verify operations, streaming exports, export signing, import, archival, and forensic pack assembly. It is intentionally conservative: lightweight JSON payloads stored in single cells for nested objects, canonical column ordering for reproducible checksums, strict idempotency patterns, and explicit retention/legal-hold handling. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Design principles & non-functional requirements</strong><br>1. Append-only & provenance-first: never update previous audit rows in-place; record state transitions with new audit rows. <br>2. Deterministic canonicalization: JSON fields and checksum inputs are canonicalized (stable ordering, normalized whitespace) before hashing so identical structured content always yields the same checksum. <br>3. Atomic append semantics: single-row append must succeed fully or fail cleanly with diagnostic written to <code>__Diagnostics</code>. <br>4. Scale-safe streaming: support exports of very large runs by streaming rows in blocks instead of loading entire <code>Audit_Log</code> into memory. <br>5. Idempotency and replay: every logical action includes <code>inputRowHash</code> and <code>actionId</code> to allow idempotent replays and dedup detection. <br>6. Separation of concerns: <code>modAudit</code> itself does not perform domain matching or scoring — callers supply component breakouts and before/after objects. <br>7. Compliance controls: retention policies, legal hold flags, and export signing features built-in to meet audit/regulatory needs. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Canonical schema (Audit_Log table)</strong><br>Columns (canonical order used for checksums):<br>1. <code>RowOrdinal</code> (Long) — physical row number assigned on append.<br>2. <code>RunId</code> (String) — GUID for run.<br>3. <code>ActionId</code> (String) — deterministic action id (e.g., runId + ":" + inputRowHash + ":" + actionType).<br>4. <code>ActionType</code> (String) — e.g., <code>SCORE</code>, <code>SUGGEST</code>, <code>REVIEW_DECISION</code>, <code>APPLY</code>, <code>COMMIT</code>, <code>ROLLBACK</code>, <code>RUN_START</code>, <code>RUN_SEAL</code>, <code>EXPORT</code>.<br>5. <code>InputRowHash</code> (String) — SHA1/CRC of input canonical fields for idempotency.<br>6. <code>BeforeJSON</code> (String) — compact canonical JSON of before-state.<br>7. <code>AfterJSON</code> (String) — compact canonical JSON of after-state (or null for non-apply actions).<br>8. <code>CandidateId</code> (String) — optional; candidate chosen for apply or null.<br>9. <code>Confidence</code> (Double) — 0..1 numeric score when applicable.<br>10. <code>ComponentBreakdown</code> (String) — compact JSON of feature contributions used by ranker/fuzzy.<br>11. <code>GSRef</code> (String) — optional id referencing GoalSeek trace(s).<br>12. <code>MaterialFlag</code> (Boolean) — true if row exceeded materiality thresholds.<br>13. <code>UserId</code> (String) — actor initiating action (operator/reviewer/system).<br>14. <code>TimestampUTC</code> (String ISO8601).<br>15. <code>RowChecksum</code> (String) — hex checksum of canonical subset per row.<br>16. <code>Notes</code> (String) — optional free-text rationale or reviewer notes. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: InitAudit(runId, userId, metadata)</strong><br>Purpose: prepare audit structures and record run start metadata.<br>Expected call pattern: invoked at Run start by <code>modCoreEngine.RunUpdateHR</code>.<br>Inputs: <code>runId</code> (GUID), <code>userId</code> (operator id), <code>metadata</code> (dictionary: codeVersion, configSnapshot, environment, sourceWorkbook, runOptions).<br>Behaviour (per-function flow):<br>1. Ensure <code>Audit_Log</code> ListObject/table exists; create if missing with canonical columns. <br>2. Append <code>RUN_START</code> audit row containing <code>metadata</code> in <code>Notes</code> or <code>ComponentBreakdown</code> as compact JSON. <br>3. Insert control entry into hidden <code>__Audit_Control</code> sheet containing <code>runId</code>, <code>state=OPEN</code>, <code>acquireLockToken</code> and <code>startTime</code>. <br>4. Reserve export folder/path in <code>__Run_Config</code> if provided; initialize in-memory <code>auditBuffer</code> and counters for the run. <br>5. Return boolean success and diagnostic dictionary on failure. <br>Audit point: <code>RUN_START</code> row is the first authoritative record for any run and contains <code>codeVersion</code>/<code>configSnapshot</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: AppendAuditRow(auditRec) -> Long</strong><br>Purpose: reliable append of a single audit event; primary API used across modules.<br>Caller contract (required keys on auditRec): <code>runId</code>, <code>inputRowHash</code>, <code>actionType</code>, <code>userId</code>, <code>timestampUTC</code>. Recommended keys: <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>confidence</code>, <code>componentBreakdown</code>, <code>gsRef</code>, <code>materialFlag</code>, <code>notes</code>.<br>Atomic append algorithm:<br>1. Validate required fields and canonicalize any JSON fields (property ordering, no unnecessary whitespace, stable number formatting). <br>2. Compute <code>componentBreakdownHash</code>, <code>beforeJSONHash</code>, <code>afterJSONHash</code>. <br>3. Compute <code>rowChecksum = ComputeRowChecksum</code> using canonical ordering (see function details). <br>4. Convert the record to a 1-row variant array matching the <code>Audit_Log</code> column order. <br>5. Call <code>WriteAtomicRow</code> helper to append the row; <code>WriteAtomicRow</code> implements a small retry loop (configurable 3 retries) and uses <code>ListObject.ListRows.Add</code> or direct Range assignment for performance. <br>6. On success, update <code>__Audit_Control[runId].lastRowOrdinal</code>, increment counters, and return new <code>RowOrdinal</code> (Long). <br>7. On failure, write a diagnostic <code>AUDIT_APPEND_FAIL</code> row to <code>__Diagnostics</code> with serialized input and error info; return negative error code. <br>Performance note: callers that will write many rows should instead call <code>AppendAuditRowsBatch</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: AppendAuditRowsBatch(auditRecs) -> Dictionary</strong><br>Purpose: highly performant batch append for thousands of rows; used by chunk commits and telemetry flush.<br>Algorithm & behaviour:<br>1. Accept <code>auditRecs</code> as Collection of audit dictionaries. <br>2. Precompute checksums for each record; build a 2D variant array in canonical column ordering. <br>3. Acquire a temporary worksheet target range and write the array in a single <code>Range.Value</code> assignment (or use DataBodyRange Resize on the <code>ListObject</code>). <br>4. Validate write by checking number of rows written and compute part-file checksum(s) for export manifest. <br>5. Update <code>__Audit_Control</code> lastRowOrdinal and in-memory run counters. <br>6. Return summary dict: <code>rowsAppended</code>, <code>firstRowOrdinal</code>, <code>lastRowOrdinal</code>, <code>errors[]</code>. <br>Batch sizing: controlled by <code>modConfig.AuditBatchWriteSize</code> (typical default 1000) to avoid memory/clipboard issues. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Internal helper: ComputeRowChecksum(auditRow) -> String</strong><br>Purpose: deterministic checksum computed from canonical ordered fields to enable tamper-detection and run seals.<br>Canonical inputs used: <code>RunId|ActionId|ActionType|InputRowHash|TimestampUTC|UserId|CandidateId|Confidence|ComponentBreakdownHash|BeforeJSONHash|AfterJSONHash</code> (componentHash/JSON hashes internalized to keep checksum size manageable).<br>Procedure:<br>1. Ensure each field converted to stable string (numbers formatted with fixed decimal places where required, booleans as <code>true</code>/<code>false</code>, null as empty string). <br>2. Concatenate with a single non-printable delimiter (e.g., <code>|</code>) that is not allowed in input fields; if delimiter may appear, escape it first. <br>3. Pass canonical concatenated string to VBA checksum routine: preferred <code>SHA1</code> if available, fallback to <code>CRC32</code> for speed; return hex string uppercase. <br>Notes: All consumers must use the same canonicalization rules to avoid checksum mismatches. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: VerifyRowChecksum(rowOrdinal) -> Boolean</strong><br>Purpose: recompute and compare the checksum for a single row; used during integrity checks and import validation.<br>Behaviour:<br>1. Read the row into dictionary using canonical column map. <br>2. Compute checksum and compare to stored <code>RowChecksum</code>. <br>3. If mismatch, write <code>AUDIT_CHECKSUM_MISMATCH</code> to <code>__Diagnostics</code> with both values and sample <code>beforeJSON</code>/<code>afterJSON</code> snippets. <br>Return: True when checksums match; False otherwise. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: SealAuditRun(runId) -> Boolean</strong><br>Purpose: finalise a run by computing the run-level seal and marking run sealed/immutable within the workbook.<br>Seal algorithm (deterministic):<br>1. Query all <code>RowChecksum</code> values for <code>runId</code> in ascending <code>RowOrdinal</code>. <br>2. Concatenate checksums in canonical order and compute <code>sealChecksum = SHA1(concatenatedChecksums)</code> (or CRC composite). <br>3. Append a <code>RUN_SEAL</code> audit row with <code>notes</code> containing the <code>sealChecksum</code>, <code>sealedBy</code>, <code>sealedAt</code>. <br>4. Update <code>__Audit_Control</code> entry for run: <code>state = SEALED</code>, <code>sealChecksum</code> and <code>sealedAt</code>. <br>5. Optionally call <code>ExportAudit</code> automatically or stage for scheduled export. <br>Integrity: <code>ValidateAuditIntegrity</code> will use <code>sealChecksum</code> to detect tampering. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: ValidateAuditIntegrity(Optional runId) -> Dictionary</strong><br>Purpose: full integrity scan that recomputes row checksums and validates seals for one or all sealed runs.<br>Process:<br>1. If <code>runId</code> provided, restrict to that run; otherwise iterate sealed runs listed in <code>__Audit_Control</code>. <br>2. For each run: read <code>RowChecksum</code> array, recompute each row’s checksum in batches, and collect mismatches. <br>3. Recompute <code>sealChecksum</code> and compare to stored <code>sealChecksum</code>. <br>4. Build integrity report dictionary containing: <code>runId</code>, <code>checkedRows</code>, <code>mismatches[]</code> (with <code>rowOrdinal</code>, <code>storedChecksum</code>, <code>computedChecksum</code>, <code>reason</code>), <code>sealMatch</code> boolean, <code>status</code> (<code>OK</code>/<code>WARN</code>/<code>SUSPECT</code>). <br>5. Append an <code>AUDIT_INTEGRITY_CHECK</code> row summarizing results. <br>Action on mismatch: if mismatches found, automatically generate a <code>ForensicPack</code> suggestion and lock run edits (<code>__Audit_Control</code> flag <code>lockedForInvestigation=True</code>). </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Public function: ExportAudit(runId, exportFormat, destPath, options) -> Dictionary</strong><br>Purpose: export run audit into canonical artifact formats consumable by BI and central audit DBs.<br>Supported formats: <code>NDJSON</code> (newline-delimited JSON), <code>CSV</code> (with JSON columns), <code>SQL_INSERTS</code> (parameterised), and <code>PARQUET</code> via helper tool.<br>Guaranteed export characteristics:<br>1. Deterministic ordering: rows exported in <code>RowOrdinal</code> order. <br>2. Each exported row includes <code>RowChecksum</code> and repeated <code>runId</code> and manifest metadata. <br>3. A <code>manifest.json</code> is produced containing: <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, <code>exportFormat</code>, <code>exportedAt</code>, <code>rowCount</code>, <code>sealChecksum</code>, <code>fileChecksums[]</code> (per-part). <br>Export algorithm (streaming):<br>1. Mark run as <code>exporting=True</code> in <code>__Audit_Control</code> to block configuration changes during export. <br>2. Stream rows in blocks (<code>modConfig.ExportBatchSize</code>) to file(s) using <code>StreamAuditExport</code> helper to avoid memory spikes. <br>3. Compute part checksums while streaming for inclusion in the manifest. <br>4. After full export, optionally compress and sign artifacts (see <code>SignAuditExport</code>). <br>Return: dictionary with <code>exportPath</code>, <code>manifest</code>, <code>files[]</code>, <code>durationMs</code>. <br>Idempotency: if <code>exportFormat</code>/<code>destPath</code> exist and <code>options(&quot;force&quot;)=False</code>, export will not re-run and returns existing manifest. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Internal helper: StreamAuditExport(runId, writer, options)</strong><br>Purpose: internal streaming routine used by <code>ExportAudit</code> to write rows safely and efficiently.<br>Behaviour & implementation notes:<br>1. Open writer stream (file or network). <br>2. Iterate <code>Audit_Log</code> ListObject by blocks (e.g., 1000 rows). For each row block transform to JSON/CSV line and write to stream. <br>3. After each block, flush and update progress to <code>__Export_Status</code> (hidden sheet). <br>4. Compute incremental checksum for each block for manifest. <br>5. Support resume: if abbreviated export file exists, support resuming at last written <code>RowOrdinal</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: ExportAuditToDB(runId, connectionInfo, options) -> Dictionary</strong><br>Purpose: load audit into a centralized database using either bulk-file ingestion or direct batched inserts.<br>Modes:<br>1. <code>bulkFile</code>: generate NDJSON/CSV artifact and call remote bulk loading API or prepare files for DB team. <br>2. <code>directInsert</code>: use ADO/ODBC connection to perform parameterised inserts in transactions of <code>options(&quot;batchSize&quot;)</code>. <br>Behavior & safety rules:<br>1. Use idempotency check on DB side by providing <code>runId</code> and <code>rowChecksum</code>—DB loader should skip rows with same checksum. <br>2. Use transactions and retries (<code>options(&quot;maxRetries&quot;)</code>) for resilience. <br>3. On failure write <code>EXPORT_FAIL</code> audit row and generate <code>ForensicPack</code> for debugging. <br>Return: <code>rowsInserted</code>, <code>errors[]</code>, <code>durationMs</code>, <code>dbStatus</code>. <br>Security: use secure connections and do not embed credentials in workbook. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: CreateForensicPack(runId, destFolder, includeSnapshots)</strong><br>Purpose: assemble a bundle containing all artifacts required for incident investigation or compliance requests.<br>Contents created (recommended):<br>1. <code>audit.ndjson</code> — full run export (sealed). <br>2. <code>manifest.json</code> — run metadata and file checksums. <br>3. <code>staging_snapshot.json</code> — <code>__Stage_Backup_&lt;runId&gt;</code> snapshot containing before-images. <br>4. <code>gs_traces.json</code> — GoalSeek attempt traces from <code>__GS_Metrics</code>. <br>5. <code>sim_&lt;runId&gt;.csv</code> — Impact simulation snapshot if present. <br>6. <code>replay_report.json</code> — results from a <code>AuditReplay</code> dry-run if executed. <br>7. <code>forensic_report.txt</code> — automated summary: <code>ValidateAuditIntegrity</code> results, recommended actions, and chain-of-custody fields. <br>8. <code>chainOfCustody.csv</code> — record of who generated the pack and when. <br>Process:<br>1. Generate all items using existing export functions. <br>2. Optionally compress/encrypt with a passphrase supplied by operator (recommendation: use external secure helper or PowerShell for AES-256). <br>3. Return <code>packPath</code>, <code>packChecksum</code>, and <code>packSizeBytes</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: AuditReplay(runId, replayOptions) -> Dictionary</strong><br>Purpose: deterministic dry-run replay of a run’s apply decisions to validate idempotency and environment reproduction.<br>Replay steps:<br>1. Load <code>ApplyDescriptor</code> records from <code>Audit_Log</code> for <code>runId</code>, ordered by original <code>RowOrdinal</code>. <br>2. For each <code>ApplyDescriptor</code>: simulate writes into a temporary <code>__Replay</code> area or in-memory structure; if calculators are needed, set <code>Application.Calculation</code> to manual when preparing and re-enable after safe recalculation in a sandbox sheet. <br>3. Compute simulated <code>after</code> state and compare to original <code>afterJSON</code>; record any <code>differences</code> into <code>replayDiffs[]</code>. <br>4. Provide a <code>replayReport</code> summarizing <code>rowsReplayed</code>, <code>rowsMatched</code>, <code>rowsMismatched</code> with sample diffs and suggested root-cause (e.g., <code>calculator formula mismatch</code>, <code>named range changed</code>, <code>external lookup missing</code>). <br>5. Optionally allow <code>ReplayAndCommitToNewRun</code> when <code>replayOptions(&quot;commit&quot;)==True</code> and idempotency checks pass. <br>Return: <code>replayReport</code> and <code>diffReportPath</code> (if requested). </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: AuditDiff(runIdA, runIdB, options) -> Dictionary</strong><br>Purpose: row-level comparison of two runs for regression testing or QA.<br>Algorithm:<br>1. Build join keys (prefer <code>InputRowHash</code>). If absent, use <code>rowId</code> or best-effort matching heuristics (name+amount+costCenter). <br>2. For each matched pair compute field-level diffs for <code>beforeJSON</code>, <code>afterJSON</code>, <code>candidateId</code>, <code>confidence</code>, and compute <code>deltaAmount</code> for numeric fields. <br>3. Classify diffs as <code>NonMaterial</code>, <code>Material</code>, <code>Structural</code> (schema changes), or <code>Missing</code>. <br>4. Build <code>diffReport</code> with <code>rowsEqual</code>, <code>rowsDifferent</code>, <code>materialDiffs</code>, and <code>sampleDiffs</code>. <br>5. Persist <code>diffReport</code> to <code>__Diff_Reports</code> sheet and optionally export as JSON/CSV. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: ImportAuditCSV(filePath, options) -> Dictionary</strong><br>Purpose: idempotent import of externally created audit exports into workbook <code>Audit_Log</code> (useful for consolidation or rehydration).<br>Process and safeguards:<br>1. Validate provided <code>manifest.json</code> when available and compare <code>sealChecksum</code> if required. <br>2. Stream parse CSV/NDJSON and for each row compute <code>rowChecksum</code>; skip if <code>rowChecksum</code> present already (idempotent). <br>3. Append new rows using <code>AppendAuditRowsBatch</code>; update <code>__Audit_Control</code> indexes. <br>4. On parse error write <code>IMPORT_ERROR</code> row to <code>__Diagnostics</code> and abort if <code>options(&quot;stopOnError&quot;)=True</code>. <br>Return: <code>rowsImported</code>, <code>skippedDuplicates</code>, <code>errors[]</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: ReindexAudit(indexList) -> Dictionary</strong><br>Purpose: build quick-access index sheets to accelerate lookups by <code>InputRowHash</code>, <code>CandidateId</code>, <code>ActionType</code>, etc.<br>Behaviour:<br>1. For each key in <code>indexList</code> build a hidden sheet <code>__Index_&lt;Key&gt;</code> mapping key value -> concatenated RowOrdinals or a small structured table. <br>2. Use incremental updates after appends to keep indexes fresh; support full rebuild on demand. <br>3. Return index statistics for use by <code>modCoreEngine</code> and <code>modMatchingEngine</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: CompactAudit() -> Dictionary</strong><br>Purpose: housekeeping to reclaim workbook space while respecting retention and legal hold.<br>Process & policy:<br>1. Consult <code>modConfig.RetentionDays</code> and <code>__Audit_Control.legalHold</code> to find eligible runs. <br>2. For each eligible run, export via <code>ExportAudit</code> and move artifact to archive folder or external store; record <code>ArchivePointer</code> in <code>__ArchiveIndex</code>. <br>3. If <code>modConfig.AutoPurge=True</code>, delete local rows for archived runs (retain a small pointer index). <br>4. Rebuild <code>Audit_Log</code> as contiguous table and refresh indexes. <br>Return <code>compactReport</code> enumerating archived runs and space reclaimed. <br>Governance: require admin approval for purge when <code>legalHold</code> or compliance flags are present. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: AuditRetentionPolicyEnforcer(asOfDate)</strong><br>Purpose: scheduled enforcement job that archives/purges audit data according to retention policy and legal hold.<br>Behaviour:<br>1. Scan <code>__Audit_Control</code> for runs older than <code>asOfDate - RetentionDays</code>. <br>2. For eligible runs, call <code>ExportAudit</code> and then either mark as <code>Archived</code> or purge rows per policy. <br>3. Append <code>ARCHIVE</code> and <code>PURGE</code> action rows to <code>Audit_Log</code> describing the file pointer, archive checksum, and archive path. <br>4. When a run is under <code>legalHold</code>, skip and log <code>HOLD</code> entry. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: SignAuditExport(exportPath, signerId, usePKI)</strong><br>Purpose: attach a signature to exported artifacts for chain-of-custody; supports light-weight internal signatures and external PKI integration.<br>Modes and recommendations:<br>1. <code>internal</code> (default): compute <code>RunSignature = modSignatures.ComputeRunSignature(runId)</code> and store in <code>manifest.json</code> signedBy <code>signerId</code>; append signature row in <code>Audit_Log</code>. <br>2. <code>PKI</code> (recommended for legal-grade signing): call external signing helper/service (out-of-band) to get cryptographic signature and embed signature file adjacent to exports. <br>Implementation note: do not implement strong PKI in pure VBA; call secure external helper or signed PowerShell. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Function: VerifySignature(exportPath, signature, publicKey)</strong><br>Purpose: verify cryptographic or internal signatures on exported artifact.<br>Behaviour:<br>1. If <code>publicKey</code> provided, call external verifier helper or local wrapper; return boolean. <br>2. For internal signature, recompute run signature and compare. <br>3. Record <code>SIGNATURE_VERIFY</code> audit row with result, verifierId and timestamp. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Power Query (PQ) conceptual recipe for audit ingestion</strong><br>1. Ingest <code>manifest.json</code> first to read <code>rowSchema</code> and <code>jsonColumns</code> for stable typing. <br>2. Load NDJSON by reading file lines and using <code>Json.Document</code> to parse each line deterministically. <br>3. Expand <code>ComponentBreakdown</code>, <code>BeforeJSON</code>, and <code>AfterJSON</code> using <code>Record.FieldValues</code> and promote typed columns with <code>Table.TransformColumnTypes</code> using the manifest types. <br>4. Compute <code>Delta</code> columns: numeric diffs and <code>DeltaPct = try (after.amount - before.amount) / before.amount otherwise null</code>. <br>5. Create <code>RunSummary</code> pivot by grouping on <code>runId</code> and <code>actionType</code> to compute counts and average confidence; publish to Power BI. <br>6. For integrity monitoring, parse <code>rowChecksum</code> and compute <code>ConcatRowChecksums</code> for spot checks and compare to <code>sealChecksum</code> from manifest. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Conceptual DAX measures for audit & operational monitoring</strong><br>1. <code>TotalAuditRows = COUNTROWS(Audit)</code>.<br>2. <code>AutoApplyRate = DIVIDE(CALCULATE(COUNTROWS(Audit), Audit[actionType] = &quot;AUTO_APPLY&quot;), [TotalAuditRows])</code>.<br>3. <code>AvgConfidence = AVERAGE(Audit[confidence])</code>.<br>4. <code>AuditTamperRate = DIVIDE(CALCULATE(COUNTROWS(AuditIntegrity), AuditIntegrity[status] = &quot;SUSPECT&quot;), COUNTROWS(AuditIntegrity))</code>.<br>5. <code>MaterialImpact = SUMX(FILTER(Audit, Audit[materialFlag] = TRUE), Audit[after_amount] - Audit[before_amount])</code>.<br>6. <code>ReviewerLoad = COUNTROWS(FILTER(Audit, Audit[actionType] = &quot;REVIEW_DECISION&quot;))</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Examples & practical narratives</strong><br>Example scenario: chunk commit failure and recovery<br>1. <code>modCoreEngine</code> processes chunk 5 and prepares <code>ApplyDescriptor</code>s; calls <code>AppendAuditRowsBatch</code> to append <code>APPLY_ATTEMPT</code> records for the chunk.<br>2. During <code>CommitRun</code> while writing the chunk to primary target sheets a COM exception occurs halfway through causing partial writes. The commit catches the exception and calls <code>AppendAuditRow</code> to record <code>COMMIT_ATTEMPT_FAILED</code> with <code>beforeJSON</code> snapshot for the affected rows and <code>errorCode</code> in <code>Notes</code>.<br>3. <code>modCoreEngine</code> calls <code>RollbackRun</code> which reads <code>__Stage_Backup_&lt;runId&gt;</code> and appends <code>ROLLBACK</code> rows for each reverted cell. <br>4. <code>modAudit.SealAuditRun</code> is not called because run is left <code>OPEN</code> and <code>__Audit_Control</code> contains <code>lastSuccessfulChunk</code> allowing resume. <br>5. Forensics: operator runs <code>CreateForensicPack</code> which includes the chunk-level <code>COMMIT_ATTEMPT_FAILED</code> entries and GS traces for the rows. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Operational recommendations & runbook steps</strong><br>1. Pre-run: verify <code>Audit_Log</code> writable, <code>__Audit_Control</code> contains no stale <code>OPEN</code> runs. <br>2. During run: monitor <code>__Export_Status</code>, <code>__Telemetry</code> and <code>__Audit_Control.lastRowOrdinal</code>. <br>3. Post-run: call <code>SealAuditRun</code>, then <code>ExportAudit</code> with <code>compress=True</code> and <code>SignAuditExport</code> (PKI recommended). <br>4. Weekly: run <code>ValidateAuditIntegrity</code> for sealed runs and <code>CompactAudit</code> as needed. <br>5. Incident: if <code>ValidateAuditIntegrity</code> returns <code>SUSPECT</code>, immediately create <code>ForensicPack</code> and escalate to Security/Compliance. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Security, privacy and compliance features</strong><br>1. PII handling: <code>modConfig.AuditExportPIIPolicy</code> controls whether raw names are exported or replaced with salted hashes in <code>componentBreakdown</code> and telemetry exports. <br>2. Access control: restrict editing of <code>Audit_Log</code> sheet via workbook protection and role mapping in <code>modConfig.UserRoles</code>. <br>3. Encryption: recommend encrypting forensic packs and offloading signatures to a PKI service. <br>4. Legal hold: <code>__Audit_Control</code> supports <code>legalHold</code> flag to prevent archival/purge of specified runs. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Integration points with other modules</strong><br>1. <code>modCoreEngine</code> calls <code>InitAudit</code>, <code>AppendAuditRow</code> for per-row events and <code>SealAuditRun</code> at completion. <br>2. <code>modMatchingEngine</code> and <code>modFuzzyScores</code> provide <code>componentBreakdown</code> payloads that <code>modAudit</code> persists for training and PQ ingestion. <br>3. <code>modGoalSeekController</code> writes GS attempt traces referenced by <code>GSRef</code> used in <code>modAudit</code> entries. <br>4. <code>modTelemetry</code> consumes <code>__Audit_Control</code> and <code>__Audit_Seals</code> to report integrity trends. <br>5. <code>modAuditExportHelpers</code> is a companion module to convert <code>Audit_Log</code> exports into SQL or packaged artifacts; integrate tightly for <code>ExportAuditToDB</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Testing matrix (unit & integration tests)</strong><br>Unit tests:<br>1. <code>ComputeRowChecksum</code> fixed vectors: known inputs produce expected hex string. <br>2. <code>AppendAuditRow</code> atomicity under simulated Range write exceptions — ensure no half-rows. <br>3. <code>AppendAuditRowsBatch</code> write/resize behavior for small and large batches. <br>Integration tests:<br>1. Export/import round-trip: create run, append rows, <code>ExportAudit</code>, remove local run, <code>ImportAuditCSV</code> into clean workbook — confirm identical checksums and <code>ValidateAuditIntegrity</code> OK. <br>2. Replay: run <code>AuditReplay</code> and compare simulated after-state with original <code>afterJSON</code>. <br>3. Performance: export 100k synthetic rows to NDJSON and measure streaming memory usage and time. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Edge cases & mitigations</strong><br>1. Excel limits: extremely large audit volumes should be offloaded to central DB via <code>ExportAuditToDB</code>; use archival strategy to keep workbook size manageable. <br>2. Partial write / power loss: <code>AppendAuditRow</code> writes with pre-append checkpoints and <code>__Diagnostics</code> entries so a failed append is discoverable. <br>3. JSON canonicalization mismatches: use shared <code>JSONCanonicalize</code> helper and include <code>explainVersion</code> to detect algorithm changes. <br>4. Locale & number formatting: all canonical stringification uses invariant culture (ISO-8601, dot decimal) to avoid PQ parsing errors in different locales. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Operational observability (telemetry points)</strong><br>Telemetry counters to capture per-run and aggregate:<br>1. <code>AuditAppendLatencyMs</code> (avg, p95) — time per append. <br>2. <code>AuditBatchWriteTimeMs</code> — time for batch writes. <br>3. <code>ExportDurationMs</code> — per-run export time. <br>4. <code>ExportSizeBytes</code> and <code>ExportParts</code> — file sizes for storage planning. <br>5. <code>IntegrityMismatches</code> count over time. <br>Instrumented exports: <code>modAudit</code> writes minimal telemetry to <code>__Telemetry</code> and <code>modTelemetry</code> aggregates. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Implementation pitfalls (warnings to developers)</strong><br>1. Avoid cell-by-cell writes in append path; always buffer and write block assignments where possible. <br>2. Do not rely on Excel-based crypto for strong signatures — use external PKI helper. <br>3. Keep canonical column mapping in a single module constant to prevent checksum mismatches. <br>4. Avoid storing long JSON strings across many cells — prefer NDJSON exports for large nested data. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Schema examples (compact JSON examples for audit fields)</strong><br>1. <code>BeforeJSON</code> / <code>AfterJSON</code> example:<br><code>{ &quot;employeeId&quot;:&quot;E123&quot;, &quot;costCenter&quot;:&quot;CC01&quot;, &quot;amount&quot;: 12345.67, &quot;effectiveDate&quot;:&quot;2026-02-01&quot;, &quot;postingIds&quot;:[&quot;P123&quot;,&quot;P124&quot;] }</code><br>2. <code>ComponentBreakdown</code> example:<br><code>{ &quot;tokenOverlap&quot;:0.62, &quot;trigramJaccard&quot;:0.72, &quot;fuzzyScore&quot;:0.87, &quot;priorConfirmCount&quot;:3, &quot;combinedScore&quot;:0.81, &quot;rationale&quot;:&quot;0.5*token + 0.25*jacc + 0.25*fuzzy&quot; }</code><br>3. <code>Manifest.json</code> example fields:<br><code>{ &quot;runId&quot;:&quot;uuid&quot;, &quot;codeVersion&quot;:&quot;v1.2.0&quot;, &quot;configSnapshot&quot;:{...}, &quot;exportedAt&quot;:&quot;2026-02-19T10:20:00Z&quot;, &quot;rowCount&quot;:12345, &quot;sealChecksum&quot;:&quot;ABC123...&quot;, &quot;files&quot;:[ {&quot;name&quot;:&quot;audit.part1.ndjson&quot;,&quot;checksum&quot;:&quot;...&quot;} ] }</code> </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Conceptual PQ & DAX examples (operational)</strong><br>PQ flow to compute AutoApplyPrecision:<br>1. Ingest <code>audit.ndjson</code> using manifest-driven schema. <br>2. Expand <code>ComponentBreakdown</code> into flat columns. <br>3. Join with <code>ConfirmedMatches</code> to produce <code>label</code> column. <br>4. Bucket by <code>combinedScore</code> and compute <code>precision = TP / (TP+FP)</code> per bucket. <br>5. Output <code>__Fuzzy_Tuning</code> table used by admin to set thresholds. <br>DAX measure example for AutoApplyPrecision in Power BI:<br><code>AutoApplyPrecision = DIVIDE( CALCULATE(COUNTROWS(FuzzyAudit), FuzzyAudit[label]=1, FuzzyAudit[combinedScore] &gt;= SELECTEDVALUE(Config[AutoApplyThreshold]) ), CALCULATE(COUNTROWS(FuzzyAudit), FuzzyAudit[combinedScore] &gt;= SELECTEDVALUE(Config[AutoApplyThreshold])) )</code> </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Release & change control notes</strong><br>1. Any change to canonical schema or checksum algorithm must increment <code>auditSpecVersion</code> and require migration steps recorded in <code>__Migration_History</code>. <br>2. Migration scripts to transform old <code>beforeJSON</code> / <code>afterJSON</code> shapes to new normalized schema must produce backups <code>__Migration_Backup_&lt;ts&gt;</code>. <br>3. All code changes that touch <code>modAudit</code> require regression run producing identical <code>sealChecksum</code> for golden sample runs or explicit acceptance reasons documented in <code>Macro_ChangeLog</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Acceptance & delivery checklist</strong><br>1. Unit tests cover all checksum vectors and append edge-cases. <br>2. Integration tests demonstrate export-import round-trip and <code>SealAuditRun</code> correctness. <br>3. Performance test for expected run volumes. <br>4. Signed export workflow validated end-to-end. <br>5. Admin UI documention for <code>ExportAudit</code>, <code>SealAuditRun</code>, <code>CreateForensicPack</code>, and <code>ValidateAuditIntegrity</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modAudit (VBA)"> <strong>Final operational summary</strong><br><code>modAudit</code> is the backbone of traceability for UpdateHR+. Implement it with rigorous canonicalization, safe append/batch semantics, streaming exports, seal verification, and defensive retention/forensic features. Provide PQ recipes and DAX measures to hand the data to analysts, and ensure external PKI for production signing. Prioritise deterministic behaviour and test coverage so audit artifacts are reliable for compliance, reproduceable for replay, and actionable for forensic teams. </td></tr></tbody></table></div><div class="row-count">Rows: 37</div></div><div class="table-caption" id="Table9" data-table="Docu_0202_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Per-function technical breakdown — **modBatchProcessing** (VBA)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Per-function technical breakdown — <strong>modBatchProcessing</strong> (VBA)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Module purpose (concise)</strong><br><code>modBatchProcessing</code> provides deterministic, resumable, and auditable orchestration for processing large staff/budget update runs. Responsibilities include deterministic run planning, chunking, staging, checkpointing, atomic commit semantics per-chunk, resumability, parallel partition guidance, enforcement of daily/cap policies, telemetry emission, and tight integration with <code>modAudit</code>, <code>modCoreEngine</code>, <code>modConfig</code>, and UI modules. The module is designed to operate entirely in-process on Desktop Excel, minimizing sheet I/O inside loops, using in-memory arrays/dictionaries, and persisting minimal checkpoints to hidden sheets to ensure recovery after crashes. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Design goals & constraints</strong><br>1. <strong>Determinism:</strong> identical inputs + config → identical runPlan and chunkIds.<br>2. <strong>Idempotency:</strong> any chunk/process is safe to re-run; <code>inputRowHash</code> prevents double-applies.<br>3. <strong>Atomic chunk commit:</strong> commit entire chunk or revert completely; chunk-level checkpoint precedes writes.<br>4. <strong>Resource-aware:</strong> <code>BatchSize</code> and <code>MaxChunkBytes</code> guard memory and avoid Excel instability.<br>5. <strong>Minimal sheet-chatter:</strong> heavy work in- memory; flush staged rows in bulk to hidden staging sheets.<br>6. <strong>Governance built-in:</strong> pre-commit daily caps, reviewer gating, and auditor-friendly artifacts. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Public API & summary (functions)</strong><br>1. <code>StartBatch(runOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — initialize run and plan chunks. <br>2. <code>BuildRunPlan(runId As String, staffRange As Range, Optional partitionKey As String) As Scripting.Dictionary</code> — deterministic chunk map builder. <br>3. <code>ProcessChunk(runId As String, chunkId As String) As Scripting.Dictionary</code> — process rows and stage outcomes. <br>4. <code>CommitChunk(runId As String, chunkId As String, Optional commitOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — atomically write staged chunk to target sheets. <br>5. <code>ResumeBatch(runId As String) As Scripting.Dictionary</code> — safe resume logic that detects prior state. <br>6. <code>AbortRun(runId As String, reason As String) As Scripting.Dictionary</code> — safe run abort and archive. <br>7. <code>EnforceDailyLimits(runId As String) As Scripting.Dictionary</code> — pre-commit caps gate. <br>8. <code>ReplayChunk(runId As String, chunkId As String, Optional replayOptions As Scripting.Dictionary) As Scripting.Dictionary</code> — deterministic dry-run replay for QA. <br>9. <code>ExportRunPlan(runId As String, destPath As String, Optional format As String) As Scripting.Dictionary</code> — canonical export for approvals or external orchestration. <br>10. <code>PartitionDataset(staffRange As Range, strategy As String, maxPartitions As Long) As Collection</code> — partition helper for parallelization. <br>11. <code>MergeChunkResults(runId As String, workerArtifacts As Collection) As Scripting.Dictionary</code> — merge artifacts from parallel workers and detect conflicts. <br>12. Checkpoint primitives: <code>WriteChunkCheckpoint</code>, <code>ReadLastCheckpoint</code>, <code>MarkChunkCompleted</code>, <code>PurgeOldCheckpoints</code>. <br>13. Failure & retry helpers: <code>IsTransientError</code>, <code>RetryWithBackoff</code>, <code>EscalateFatal</code>. <br>14. Forensic pack: <code>GenerateForensicPack(runId As String, destPath As String)</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: StartBatch — full breakdown</strong><br>Purpose: create run header, validate preconditions, snapshot config, compute deterministic plan, and persist run metadata. <br>Inputs & expected runOptions keys:<br> - <code>staffRangeName</code> (String) — named range of staff rows.<br> - <code>userId</code> (String) — operator identity for audit.<br> - <code>dryRun</code> (Boolean) — whether to skip staging/writes.<br> - <code>batchSize</code> (Long, optional) — overrides default for run.<br> - <code>partitionKey</code> (String, optional) — field name to partition by.<br> - <code>runId</code> (String, optional) — allow deterministic restarts/replays. <br>Return: dictionary <code>{ runId, status, planSummary, validationErrors }</code>.<br>Key internal steps & validation:<br>1. Validate named ranges present and <code>Calculator</code> cell integrity via <code>modCoreEngine.ValidatePreRun</code>. <br>2. Validate operator role against <code>modConfig.UserRoles</code>; return <code>NO_PRIVILEGE</code> if insufficient. <br>3. Acquire run-level lock via <code>modCoreEngine.LockingAndConcurrency.AcquireLock</code> to prevent concurrent runs. <br>4. Compute <code>runId</code>: if provided use it; otherwise generate seeded GUID (time + user id) and persist. <br>5. Persist <code>configSnapshot</code> and <code>codeVersion</code> to <code>__Run_Config</code> for replay determinism. <br>6. Call <code>BuildRunPlan</code> to derive deterministic <code>chunkId</code> list using <code>modConfig.BatchSize</code> or provided override. <br>7. Insert run header row into <code>__Run_Header</code> and write <code>RUN_START</code> to <code>Audit_Log</code>. <br>8. If <code>dryRun=True</code> return plan and estimates only; set <code>status=PLANNED</code>. <br>Failure handling:<br> - Any validation failure returns structured <code>validationErrors</code> and <code>status=FAILED</code> and writes <code>RUN_PLAN_ERROR</code> to diagnostics. <br>Telemetry & audit:<br> - Emit telemetry point (<code>RunPlanned</code>) and write <code>RUN_START</code> audit row containing <code>planChecksum</code> and <code>estimatedCommitBytes</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: BuildRunPlan — full breakdown</strong><br>Purpose: deterministically partition the input rows into safe chunk units, optionally partition by key for parallelism. <br>Inputs: <code>runId</code>, <code>staffRange</code>, optional <code>partitionKey</code> and <code>batchSize</code>. <br>Algorithm & determinism rules:<br>1. Load <code>staffRange</code> into a variant array. Deterministic plan must rely only on input ordering; if <code>partitionKey</code> is supplied, sort by partitionKey (stable sort) then compute partitions - sorting must be stable and deterministic across Excel versions (use a VBA stable sort implementation). <br>2. Determine <code>batchSize</code>: use <code>runOptions.batchSize</code> if provided and within <code>modConfig.BatchSizeBounds</code>, otherwise <code>modConfig.BatchSize</code>. <br>3. Compute <code>chunkCount = Ceiling(totalRows / batchSize)</code> and for each chunk compute: <code>startRow</code>, <code>endRow</code>, <code>estimatedRows</code>, <code>estimatedBytes</code>. <br>4. Compute <code>chunkId</code> deterministically as <code>SHA1(runId &amp; &quot;:&quot; &amp; startRow &amp; &quot;-&quot; &amp; endRow &amp; &quot;:&quot; &amp; partitionKey)</code>. <br>5. For multi-partition mode: build per-partition chunk lists to enable safe parallel workers that do not write the same target cells. <br>Outputs & side effects:<br> - Persist <code>__Run_Plan</code> as a canonical list with columns: <code>chunkId</code>, <code>startRow</code>, <code>endRow</code>, <code>rowCount</code>, <code>status(PENDING)</code>, <code>estimatedBytes</code>, <code>requiresApproval</code> flag. <br>Governance rule:<br> - If <code>totalRows &gt;= modConfig.ApprovalThresholdRows</code> mark <code>runHeader.requiresApproval=True</code> and block commits until reviewer signature captured. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: ProcessChunk — full breakdown</strong><br>Purpose: process each row in chunk through matching and staging but do not perform production writes; stage to hidden staging sheet <code>__Stage_Run_&lt;runId&gt;</code>.<br>Inputs: <code>runId</code>, <code>chunkId</code>. <br>Return: <code>{ chunkId, processedRows, stagedRows, errors, timingMs }</code>.<br>Processing pipeline (per-row deterministic sequence):<br>1. Mark chunk <code>status=IN_PROGRESS</code> in <code>__Run_Plan</code>. <br>2. Load chunk rows into in-memory variant array to avoid repeated Range reads. <br>3. For each row (ordered by row ordinal):<br>&nbsp;&nbsp;&nbsp;&nbsp;a) Compute <code>inputRowHash</code> over canonical input columns (stable ordering); write to local lookup to detect duplicates. <br>&nbsp;&nbsp;&nbsp;&nbsp;b) Query <code>modAudit</code> for existing <code>inputRowHash</code> to skip already committed inputs (idempotency). <br>&nbsp;&nbsp;&nbsp;&nbsp;c) Invoke <code>modCoreEngine.ProcessStaffRow</code> or inline lightweight path to produce <code>ApplyDescriptor</code> or <code>suggestion</code> object. <br>&nbsp;&nbsp;&nbsp;&nbsp;d) If <code>ApplyDescriptor</code> is produced, append a staged row to a local staging buffer; include <code>beforeJSON</code>, <code>afterJSON</code>, <code>componentBreakdown</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;e) If <code>suggestion</code> for review, write to <code>__Review_Queue</code> (with minimal payload) for reviewer UI. <br>4. Flush staging buffer to <code>__Stage_Run_&lt;runId&gt;</code> every N rows or when memory threshold approaches; flush is a bulk <code>Range.Value = array</code> write. Each flush writes <code>status=STAGED</code> for those rows. <br>5. After chunk processed, compute <code>stagedChecksum</code> and set chunk <code>status=STAGED</code> with <code>stagedCount</code>. <br>Failure handling:<br> - On transient COM errors use <code>RetryWithBackoff</code> for flush operations; on repeated failures mark chunk <code>status=ERROR</code> and write diagnostics. <br>Telemetry & audit:<br> - Emit <code>ChunkProcessed</code> telemetry with <code>processedRows</code>, <code>avgMsPerRow</code>. <br>Optimization notes:<br> - Avoid calling heavy recalculation functions during processing; use <code>Application.Calculation = manual</code> only when necessary and restore on exit; minimize cross-thread UI updates. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: CommitChunk — full breakdown</strong><br>Purpose: atomically apply staged changes for a chunk to target worksheets; support dry-run, preview, and require reviewer sign-off if policy requires.<br>Inputs: <code>runId</code>, <code>chunkId</code>, <code>commitOptions</code> (keys: <code>dryRun</code>, <code>requireReviewerSign</code>, <code>simulateOnly</code>).<br>Return: <code>{ chunkId, commitStatus, committedRows, commitChecksum, errors }</code>.<br>Atomic commit algorithm (checkpoint-first):<br>1. Validate chunk status <code>STAGED</code>. <br>2. Call <code>EnforceDailyLimits</code> to ensure commit will not exceed daily caps; if caps would be exceeded, move remaining staged rows into review queue and return <code>status=AWAIT_REVIEW</code>. <br>3. Create commit lock token in <code>__Run_Status</code> (write with timestamp); this prevents multiple process attempts to commit same chunk. <br>4. Create <code>__Stage_Backup_&lt;runId&gt;</code> snapshot for the chunk: before-images of the target cells that will be modified; persist backupRef in checkpoint record. <br>5. Write pre-commit checkpoint to <code>__Run_Status</code> containing <code>chunkId</code>, <code>stagedChecksum</code>, <code>backupRef</code>, and <code>commitToken</code>. This must be durable in the workbook before any production writes. <br>6. Execution window: disable <code>ScreenUpdating</code>, <code>EnableEvents=False</code>, set <code>Calculation=Manual</code> and record prior states. <br>7. Apply grouped writes per target sheet: collect contiguous ranges and write in bulk using <code>Range.Value</code> assignments. For complicated cell mapping, compute 2D arrays of contiguous blocks to minimize COM calls. <br>8. After writes, compute <code>commitChecksum</code> by sampling a deterministic set of cells and comparing to <code>afterJSON</code> in staging. If mismatch above threshold, call <code>RollbackChunk</code> and write <code>COMMIT_MISMATCH</code> to <code>Audit_Log</code>. <br>9. On success: mark <code>chunk.status = COMMITTED</code>, write <code>CHUNK_COMMIT</code> audit event (batched) and per-row <code>APPLY</code> audit rows if <code>modConfig.AuditGranularity = FULL</code>. Remove commit lock. <br>10. Restore <code>ScreenUpdating</code>, <code>EnableEvents</code>, <code>Calculation</code> to prior state. <br>Failure & rollback details:<br> - <code>RollbackChunk</code> uses <code>__Stage_Backup_&lt;runId&gt;</code> to restore prior values and writes <code>ROLLBACK</code> audit rows with <code>rollbackReason</code> and <code>rollbackTime</code>. <br>Idempotency notes:<br> - If commit partially succeeded and resume runs <code>CommitChunk</code> again, the function checks <code>Audit_Log</code> for <code>inputRowHash</code> to avoid double-writes; any already applied rows are skipped and counted as <code>alreadyCommitted</code>. <br>Security & governance:<br> - If commit requires reviewer sign-off, reject commit until <code>modSuggestionUI</code> records reviewer confirmation and <code>modSignatures.RecordReviewerSignature</code> captures signature token. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: ResumeBatch — full breakdown</strong><br>Purpose: resume interrupted runs and process remaining chunks safely. <br>Algorithm and idempotent behavior:<br>1. Read <code>__Run_Plan</code> and <code>__Run_Status</code> to determine chunk states. <br>2. For each chunk:<br>&nbsp;&nbsp;&nbsp;&nbsp;- If <code>PENDING</code> → call <code>ProcessChunk</code>.<br>&nbsp;&nbsp;&nbsp;&nbsp;- If <code>IN_PROGRESS</code> → consult <code>__Run_Status</code> checkpoint to decide whether to re-run <code>ProcessChunk</code> or proceed to <code>CommitChunk</code> (if checkpoint shows commit was in-flight). <br>&nbsp;&nbsp;&nbsp;&nbsp;- If <code>STAGED</code> → call <code>CommitChunk</code> if caps/approval permits. <br>3. If a chunk shows <code>status=COMMITTED</code> but <code>Audit_Log</code> lacks expected per-row entries (partial commit detection), call <code>CommitVerification</code> to reconcile actual vs expected and either complete missing audit writes or trigger rollback/resolution policy. <br>4. After all chunks processed, set run <code>status=COMPLETED</code> and generate final <code>RunSummary</code> artifact. <br>Resume safety features:<br> - All decisions driven by persisted checkpoint info (<code>__Run_Status</code> and <code>__Stage_Run_&lt;runId&gt;</code>). <br> - Resume writes <code>RESUME</code> audit row referencing last checkpoint and operator. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: EnforceDailyLimits — full breakdown</strong><br>Purpose: pre-commit gate preventing over-application per-day or per-user monetary/row caps. <br>Inputs: <code>runId</code> and optionally <code>userId</code>.<br>Checks performed:<br>1. Aggregate <code>todayRowsApplied</code> and <code>todayAmountApplied</code> from <code>__DailyApplyTotals</code> (persisted table) and from prior committed chunks for the same day. <br>2. Compute <code>pendingRows</code> and <code>pendingAmount</code> from <code>__Run_Plan</code> staged chunks to be committed. <br>3. Compare against <code>modConfig.DailyAutoApplyCapRows</code> and <code>modConfig.DailyAutoApplyCapAmount</code>. <br>4. If would exceed caps return <code>allowed=False</code> with <code>reason=CAP_EXCEEDED</code> and automatically flag remaining staged rows with <code>NEEDS_REVIEW</code> and write <code>CAP_TRIGGER</code> audit event. <br>Atomic increment of daily totals:<br> - Use <code>SafeRangeWrite</code> to increment <code>__DailyApplyTotals</code> counters in a guarded update (read-modify-write loop with <code>RetryWithBackoff</code>) to avoid race conditions when multiple runs attempt to commit contemporaneously. <br>Per-user caps:<br> - If <code>modConfig.DailyAutoApplyCapsByUser</code> enabled, compute per-user totals and block commits accordingly. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: ReplayChunk — full breakdown</strong><br>Purpose: deterministic re-execution of a chunk in dry-run mode for QA, diffing, or compliance checks. <br>Inputs: <code>runId</code>, <code>chunkId</code>, <code>replayOptions</code> (keys: <code>compareToRunId</code>, <code>onlyDiffs</code>).<br>Algorithm:<br>1. Load <code>configSnapshot</code> & <code>codeVersion</code> from <code>__Run_Header</code> for the <code>runId</code> to guarantee deterministic behavior. <br>2. Recompute <code>ApplyDescriptor</code> for each row using the same matching and fuzzy functions and produce <code>afterJSON_replay</code>. <br>3. Compare <code>afterJSON_replay</code> with staged <code>afterJSON</code> or committed <code>afterJSON</code> for the original chunk. Collate differences into <code>diffReport</code> showing fields changed, numeric deltas, and likely cause (e.g., changed <code>modConfig</code> weights, codeVersion mismatch, external scorer differences). <br>4. If <code>compareToRunId</code> provided, perform symmetric diff across runs and produce aggregated statistics: <code>rowsMatched</code>, <code>rowsDiffering</code>, <code>sumDeltaAmount</code>, and <code>topN discrepancies</code>. <br>Outputs & artifacts:<br> - <code>diffReport</code> persisted to <code>__Replays</code> and an optional CSV export. <br>Governance:<br> - Replay operations must be authorized for <code>Reviewer</code> or <code>Admin</code> roles for sensitive runs. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: AbortRun — full breakdown</strong><br>Purpose: safe operator-requested abort with preserved staging and forensic artifacts; leaves data in a recoverable state. <br>Inputs: <code>runId</code>, <code>reason</code>, <code>requestedBy</code>.<br>Sequence of steps:<br>1. Acquire run lock and set <code>run.status = ABORT_REQUESTED</code>. <br>2. If any chunk commit in progress, wait for safe checkpoint (or if cannot wait, attempt graceful rollback of in-flight chunk using <code>__Stage_Backup_&lt;runId&gt;</code>). <br>3. Set all <code>PENDING</code>/<code>IN_PROGRESS</code>/<code>STAGED</code> chunks to <code>ABORTED</code> and persist. <br>4. Preserve <code>__Stage_Run_&lt;runId&gt;</code> and <code>__Stage_Backup_&lt;runId&gt;</code> and produce an <code>Abort</code> manifest containing operator details and reason. <br>5. Optionally call <code>GenerateForensicPack</code> to create a zipped archive and record <code>archiveRef</code> to <code>__Run_Header</code>. <br>6. Write <code>ABORT</code> audit row and release run lock. <br>Return: <code>{ runId, aborted=True, archiveRef }</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: ExportRunPlan — full breakdown</strong><br>Purpose: create portable artifact that describes chunk boundaries, sizes, and manifests for external approvals or orchestration. <br>Inputs: <code>runId</code>, <code>destPath</code>, <code>format</code> (<code>csv</code> or <code>ndjson</code>).<br>Content & metadata:<br>1. <code>RunPlan</code> rows: <code>runId</code>, <code>chunkId</code>, <code>startRow</code>, <code>endRow</code>, <code>rowCount</code>, <code>estimatedBytes</code>, <code>requiresApproval</code>. <br>2. <code>manifest.json</code> containing <code>runId</code>, <code>codeVersion</code>, <code>configSnapshot</code>, <code>planChecksum</code>, <code>exportedBy</code>, <code>exportTimestamp</code>. <br>3. Compute file-level checksum and persist to <code>__Run_Artifacts</code>. <br>Governance: require admin or operator sign-off to publish plan to shared network path; signed artifact assists external deployment and audit ingest. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: PartitionDataset — guidance & deterministic algorithm</strong><br>Purpose: produce partition slices to enable safe parallel processing by multiple worker clients or machines while avoiding cross-partition conflicts. <br>Supported strategies:<br>1. <code>byOrgUnit</code> — group rows by org unit, compute partitions by equalizing row counts per partition. <br>2. <code>byCostCenter</code> — often maps more directly to budget write targets and reduces cross-writes. <br>3. <code>byEmployeeIdHash</code> — stable hash of employeeId modulo <code>maxPartitions</code> to evenly distribute work while isolating by person. <br>Algorithm notes & safety:<br> - Ensure partition key produces disjoint targets: if two different rows in different partitions would write to same target cell (e.g., same cost center bucket), merging steps must be prepared. <br> - Export partition manifest containing partitionId, rowStart, rowEnd, rowCount, partitionChecksum. <br>Parallel run orchestration notes:<br> - For reliable parallel commit, assign workers distinct runIds or central coordinator to commit sequentially to avoid write conflicts; recommended pattern: parallel scoring & staging per partition, central merge + commit sequentially per chunk to maintain atomicity. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Function: MergeChunkResults — behavior & conflict detection</strong><br>Purpose: combine worker-generated staging artifacts (from partitioned parallel processing) into central staging and detect conflicts for manual resolution. <br>Inputs: <code>runId</code>, <code>workerArtifacts</code> (list of artifact paths or workbook refs).<br>Merge steps:<br>1. Validate each worker artifact manifest <code>runId</code> and <code>configSnapshot</code> to ensure compatibility. <br>2. For each staged row bring into central <code>__Stage_Run_&lt;runId&gt;</code> and detect collisions by <code>inputRowHash</code>. <br>3. If collisions exist with differing <code>afterJSON</code>, create <code>__Merge_Conflicts</code> entries capturing both candidates, combinedScore, monetary delta, and suggested resolution (highest combinedScore, priorConfirm, or manual). <br>4. Return summary with <code>mergedRows</code>, <code>conflictsDetected</code>, <code>conflictReportRef</code>. <br>Resolution workflow:<br> - Conflicts must be resolved via <code>frmReviewerUI</code> or admin tool; either accept one candidate or create split instructions. Once resolved, conflict rows change to <code>STAGED</code> and proceed to commit. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Checkpoint primitives — low-level functions</strong><br>Purpose: small durable operations used across module to guarantee recoverability.<br>Key primitives and their behavior:<br>1. <code>WriteChunkCheckpoint(runId, chunkId, state, metadata)</code> — synchronous write to <code>__Run_Status</code> or <code>__Run_Plan</code> with durable flush; ensures checkpoint persisted before commit actions. <br>2. <code>ReadLastCheckpoint(runId)</code> — returns last persisted checkpoint and commit token if any; used by <code>ResumeBatch</code>. <br>3. <code>MarkChunkCompleted(runId, chunkId, commitChecksum)</code> — mark durable completion, update <code>__Run_Plan</code> to <code>COMMITTED</code>, and write <code>CHUNK_COMMIT</code> summary event to <code>Audit_Log</code>. <br>4. <code>PurgeOldCheckpoints(beforeDate)</code> — housekeeping to remove artifacts older than retention policy in <code>modConfig.RetentionDays</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Failure classification & Retry policy</strong><br>1. <code>IsTransientError(errNumber As Long) As Boolean</code> — classify COM errors, file-share timeouts, and external scorer transient failures; map known error numbers to transient list. <br>2. <code>RetryWithBackoff(actionFunc As Variant, retries As Long, baseDelayMs As Long, maxDelayMs As Long)</code> — central wrapper used for IO ops (SafeRangeWrite, flush export) implementing exponential backoff and logging each retry to <code>__Diagnostics_&lt;runId&gt;</code>. <br>3. <code>EscalateFatal(runId As String, chunkId As String, errorRec As Scripting.Dictionary)</code> — on fatal errors produce <code>ForensicPack</code>, lock run from further changes, and notify configured escalation group (manifest logged but actual notification via external integration optional). <br>Error handling best practices:<br> - Treat workbook-level COM errors as transient if they match known patterns and retry a small number of times; otherwise mark <code>chunk.status=ERROR</code> and pause run for operator review. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>ForensicPack generation — full breakdown</strong><br>Purpose: create reproducible forensic artifact for incident investigation with full provenance. <br>Contents:<br>1. <code>__Run_Plan</code> and <code>__Run_Header</code> for the run. <br>2. <code>__Stage_Run_&lt;runId&gt;</code> and <code>__Stage_Backup_&lt;runId&gt;</code> exported as NDJSON or CSV. <br>3. <code>Audit_Log</code> rows filtered for <code>runId</code>. <br>4. <code>__Telemetry</code> slice (relevant time window) and <code>__Diagnostics_&lt;runId&gt;</code> stack traces. <br>5. <code>__GS_Metrics</code>, <code>__Fuzzy_Profile</code> entries related to rows in run. <br>6. <code>modConfig.configSnapshot</code> and <code>codeVersion</code> value. <br>7. <code>manifest.json</code> containing file checksums and operator notes. <br>Generation steps:<br> - Compose files into <code>forensic_&lt;runId&gt;_&lt;ts&gt;.zip</code>, compute file checksum (prefer external helper for SHA256), store path in <code>__Run_Artifacts</code>, and write <code>FORENSIC_PACK</code> audit row. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Telemetry emitted by modBatchProcessing</strong><br>Essential metrics recorded to <code>__Telemetry</code> and optionally pushed to external telemetry endpoint:<br>1. <code>ChunksPlanned</code> — number of chunks planned at start. <br>2. <code>ChunksProcessed</code> — number and per-chunk timing. <br>3. <code>AvgProcessingMsPerRow</code> — processing latency per row. <br>4. <code>CheckpointLatencyMs</code> — time to persist checkpoint to sheet after flush. <br>5. <code>ChunksCommitted</code> / <code>ChunksFailed</code> — success/failure counters. <br>6. <code>ResumeCount</code> — times run resumed. <br>7. <code>CapTriggers</code> — count of times daily caps prevented commit. <br>8. <code>MergeConflicts</code> — count of parallel merge conflicts. <br>Usage:<br> - Telemetry aids operations dashboards; PQ transforms ingest telemetry CSV exports into BI and alerts on thresholds. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Audit integration points (detailed)</strong><br>Audit policies and where events are written:<br>1. <code>RUN_START</code> — written by <code>StartBatch</code> with <code>runId</code>, <code>userId</code>, <code>planChecksum</code>, <code>estimatedRows</code>. <br>2. <code>CHUNK_STAGED</code> — written at chunk staging completion with <code>stagedCount</code> and <code>stagedChecksum</code>. <br>3. <code>CHUNK_COMMIT</code> — written when chunk commit completes with <code>committedRows</code>, <code>commitChecksum</code>, <code>commitTime</code>. <br>4. <code>APPLY_BATCH</code> or per-row <code>APPLY</code> — based on <code>modConfig.AuditGranularity</code>; includes <code>inputRowHash</code> and <code>componentBreakdown</code> pointer. <br>5. <code>ROLLBACK</code> / <code>ABORT</code> / <code>FORENSIC_PACK</code> — on error or abort. <br>Design trade-offs:<br> - High audit granularity yields better forensic fidelity but increases <code>Audit_Log</code> size and workbook bloat; recommend export to central audit DB for long-term retention. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Sheet model & naming conventions</strong><br>Persistent artifacts (hidden/protected):<br>1. <code>__Run_Header</code> — run-level metadata and status. <br>2. <code>__Run_Plan</code> — chunk list, deterministic chunkIds, per-chunk state. <br>3. <code>__Stage_Run_&lt;runId&gt;</code> — staged rows for a run. <br>4. <code>__Stage_Backup_&lt;runId&gt;</code> — before-images for rollback. <br>5. <code>__Run_Status</code> — commit lock token and last checkpoint. <br>6. <code>__Merge_Conflicts</code> — conflicts found during merges. <br>7. <code>__Run_Artifacts</code> — references to external exports. <br>8. <code>__Telemetry</code>, <code>__Diagnostics_&lt;runId&gt;</code>, <code>__GS_Metrics</code>. <br>Retention & housekeeping:<br> - Purge older run artifacts per <code>modConfig.RetentionDays</code>; provide <code>PurgeOldCheckpoints</code> callable by admin scripts or scheduled jobs. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Example end-to-end narrative (detailed)</strong><br>1. Operator clicks <code>Run</code> — <code>frmOperatorUI.BtnRun_Click</code> calls <code>StartBatch</code> with <code>staffRangeName</code> and <code>dryRun=False</code>. <br>2. <code>StartBatch</code> validates, snapshots config, builds deterministic <code>10,000-row</code> plan with <code>BatchSize=1000</code> producing 10 chunkIds, writes <code>RUN_START</code> audit row. <br>3. <code>ProcessChunk(chunk-001)</code>: loads rows 1..1000 into memory, computes <code>inputRowHash</code> for each, calls <code>modCoreEngine.ProcessStaffRow</code> to get <code>ApplyDescriptor</code> or <code>suggestion</code>, flushes staging every 200 rows to <code>__Stage_Run_&lt;runId&gt;</code>, marks chunk <code>STAGED</code>. <br>4. <code>CommitChunk(chunk-001)</code>: <code>EnforceDailyLimits</code> OK, write checkpoint to <code>__Run_Status</code> with <code>backupRef</code>, disable UI events, write blocks to <code>HR_Calculation</code> and <code>Detail_Budget</code> with <code>Range.Value</code> multi-cell arrays, compute <code>commitChecksum</code> and verify, write <code>CHUNK_COMMIT</code> audit row, restore UI state. <br>5. After chunk-006 commit, <code>EnforceDailyLimits</code> sees <code>DailyCapRows</code> would be exceeded by committing chunk-007; it moves chunk-007 staged rows to reviewer queue, writes <code>CAP_TRIGGER</code> audit event, and sets run <code>status=AWAIT_REVIEW</code>. <br>6. Reviewer inspects <code>ImpactReport</code> and signs off; operator resumes <code>CommitChunk(chunk-007)</code> and run completes. <br>7. Finalization writes <code>RUN_COMPLETE</code> audit row and exports <code>RunSummary.csv</code> via <code>ExportRunPlan</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Performance tuning, heuristics & sizing</strong><br>1. Determine <code>BatchSize</code> empirically: measure <code>avgRowBytes</code> and available memory. Example heuristic: <code>BatchSize = floor((AvailableMemoryMB * 0.6) / (avgRowBytes / 1024))</code>. <br>2. For desktop Excel on 8GB RAM, typical <code>BatchSize</code>: 500–2000 rows depending on row payload. <br>3. Use <code>modConfig.MaxFuzzyComparisonsPerRow</code> in tandem with <code>BatchSize</code> to keep CPU bounded. <br>4. Chunk boundary length trade-offs: smaller chunks → safer resume & smaller rollback scope; larger chunks → fewer commits and lower overhead. <br>5. For external scorer/high-latency calls, batch calls per chunk to reduce round-trips and leverage bulk-score endpoints. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Power Query (PQ) conceptual integration</strong><br>1. Ingest <code>__Run_Plan</code> and <code>Audit_Log</code> exports as PQ sources. Use <code>Json.Document</code> to parse <code>componentBreakdown</code> JSON cells. <br>2. Transform steps: expand nested <code>beforeJSON</code>/<code>afterJSON</code>, compute deltas, group by <code>chunkId</code> for chunk summaries, and create <code>ImpactByCostCenter</code> pivot tables. <br>3. For forensic analysis, PQ can load <code>__Stage_Backup_&lt;runId&gt;</code> and join with <code>__Stage_Run_&lt;runId&gt;</code> to produce <code>before/after</code> evidence tables for auditors. <br>4. Provide <code>FuzzyThresholdTune</code> PQ sheet that consumes outputs from <code>modFuzzyScores.ProfileFuzzyComparisons</code> (exported CSV) to build precision/recall charts and recommended thresholds. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Conceptual DAX measures for operational dashboards</strong><br>Recommended DAX measures derived from PQ-loaded tables (<code>Runs</code>, <code>RunChunks</code>, <code>RunAudit</code>, <code>Telemetry</code>):<br>1. <code>RunsCompleted = COUNTROWS(FILTER(Runs, Runs[status]=&quot;COMPLETED&quot;))</code>.<br>2. <code>ChunksCommitted = COUNTROWS(FILTER(RunChunks, RunChunks[status]=&quot;COMMITTED&quot;))</code>.<br>3. <code>AvgProcessingMsPerRow = AVERAGE(RunChunks[processingMs] / RunChunks[processedRows])</code>.<br>4. <code>ResumeRate = DIVIDE([RunsResumed], [TotalRuns])</code> where <code>[RunsResumed] = COUNTROWS(FILTER(Runs, Runs[resumeCount] &gt; 0))</code>.<br>5. <code>CapTriggerRate = DIVIDE([RunsWithCapTrigger], [TotalRuns])</code>. <br>6. <code>ConflictCount = SUM(MergeConflicts[conflictCount])</code>. <br>Use these measures to build alerting rules and SLA dashboards. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Testing & acceptance criteria (exhaustive checklist)</strong><br>Unit tests (via <code>modTestingHarness</code>):<br>1. <code>BuildRunPlan</code> determinism: identical inputs produce identical plans and chunkIds. <br>2. <code>Checkpoint</code> primitives survive simulated workbook crash and resume logic replays correctly. <br>3. <code>EnforceDailyLimits</code> blocks expected commits when caps exceeded. <br>Integration tests:<br>1. Full end-to-end: process 10k synthetic rows and verify <code>Audit_Log</code> contains expected <code>APPLY</code>/<code>REVIEW</code> counts and <code>commitChecksum</code> matches staging checksum. <br>2. Recovery scenarios: simulate power loss mid-commit — resume and verify no double-applies. <br>Performance tests:<br>1. Measure <code>avgMsPerRow</code> and memory usage at target scale; validate against SLA. <br>Security tests:<br>1. Role enforcement: only <code>Operator</code> can start runs; only <code>Reviewer/Admin</code> override caps. <br>Acceptance gates:<br> - All unit tests pass; regression parity to golden run confirmed; performance within SLA; audit integration tested. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Edge cases & mitigations (detailed)</strong><br>1. <strong>Stale locks</strong>: detect via <code>lockedAt</code> older than <code>modConfig.LockStaleTimeout</code>; operator action <code>RecoverLock</code> requires justification and writes <code>LOCK_RECOVER</code> audit row. <br>2. <strong>Partial commit due to power loss</strong>: <code>CommitChunk</code> must detect partial state using <code>commitChecksum</code> and either complete missing audit writes or roll back using <code>__Stage_Backup_&lt;runId&gt;</code>. <br>3. <strong>Conflicting parallel commits</strong>: merge step detects <code>inputRowHash</code> collisions and writes <code>__Merge_Conflicts</code>; resolution required before commit. <br>4. <strong>Huge single row</strong>: if a single row <code>estimatedBytes &gt; MaxRowBytes</code>, fail chunk with <code>ROW_TOO_LARGE</code> and direct operator to manual handling. <br>5. <strong>External scorer outages</strong>: circuit-breaker trips after N failures; local fallback scoring used; telemetry records <code>ExternalScorerDowntime</code>. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Developer implementation tips (VBA-focused)</strong><br>1. Use <code>Scripting.Dictionary</code> for in-memory maps and variant arrays for rows to minimize Range calls. <br>2. Batch flush staging with <code>Range.Value = array</code> rather than cell-by-cell. <br>3. Keep <code>On Error</code> handlers robust: always restore <code>Application</code> states (<code>ScreenUpdating</code>, <code>Calculation</code>, <code>EnableEvents</code>). <br>4. Persist checkpoints promptly before risky operations. <br>5. Use deterministic hashing routine (e.g., stable SHA1 implemented in VBA or CRC32) with fixed encoding (UTF-8 equivalent deterministic mapping). <br>6. Keep memoization caches per <code>runId</code> and clear after run to avoid memory leaks. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Security, governance & deployment notes</strong><br>1. Use signed macro workbook for production. <br>2. Store exported artifacts and forensic packs in secure network locations with access controls and audit trails. <br>3. Integrate optional central audit DB ingestion for immutability. <br>4. Require <code>Reviewer</code> sign-off for runs exceeding <code>ApprovalThresholdRows</code> or <code>ApprovalThresholdAmount</code>. <br>5. Use <code>modSignatures</code> to record reviewer signature tokens; for legal-grade signing integrate external PKI. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Operational runbook snippets (practical)</strong><br>1. Pre-run: refresh PQ transforms, run <code>AutoSmokeTests</code>, ensure <code>__Run_Locks</code> is clear. <br>2. During run: monitor <code>__Telemetry</code> and <code>RunChunks</code> sheet for <code>ERROR</code>/<code>CAP_TRIGGER</code>/<code>RESUME</code> events; do not interrupt running commit windows. <br>3. On transient failure: <code>ResumeBatch</code> after fixing external condition. <br>4. On suspected tampering: immediately generate <code>ForensicPack</code> and escalate per policy. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>CI/CD & change control</strong><br>1. Include <code>modBatchProcessing</code> unit tests in pre-commit and run regression suite in CI. <br>2. Maintain <code>Macro_ChangeLog</code> entries and require code reviews for changes to commit/checkpoint logic. <br>3. Backward compatibility: changes to <code>__Run_Plan</code> schema require migration scripts in <code>modMigration</code> and idempotent migration history entries. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Acceptance checklist before production rollout</strong><br>1. Deterministic plan behavior validated across sample runs. <br>2. Resume and rollback verified under simulated failures. <br>3. Telemetry integrated with operational dashboards. <br>4. Reviewer gating and daily caps operational and exercised. <br>5. Training and runbook delivered to operators and reviewers. </td></tr><tr><td data-label="Per-function technical breakdown — modBatchProcessing (VBA)"> <strong>Short summary (one line)</strong><br><code>modBatchProcessing</code> makes large-scale UpdateHR+ runs predictable, resumable, and auditable by deterministic chunking, robust staging/checkpointing, atomic chunk commit semantics, reviewer gating, and integrated telemetry/audit artifacts that support operational control and forensic analysis. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>