<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1768638176">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li>
<li class="toc-item"><a class="toc-link" href="#Table10">Table 10</a></li>
<li class="toc-item"><a class="toc-link" href="#Table11">Table 11</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0176_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Data Governance &amp; Regulatory Delivery Platform — Project Overview"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Data Governance & Regulatory Delivery Platform — Project Overview</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Summary</strong><br>A coordinated suite of Excel add-ins (XLAMs) designed for enterprise-grade data pipelines, evidence capture, and regulatory delivery. The platform’s aim is to bring reproducible, auditable data processing into analysts’ primary environment (Excel) while preserving engineering-grade controls: deterministic transforms, cryptographic evidence, CI-gated changes, and operational runbooks. Key capabilities: deterministic profiling & remediation (DQGuard), Power Query template management & injection (PQTools), and domain-specific regulatory calculations with golden-file parity (Regulatory). The platform is intended to be the operational boundary between human-in-the-loop data work and automated, signed artefact delivery to downstream reporting/ regulatory systems. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>One-line elevator pitch</strong><br>“An enterprise Excel add-in platform that makes data-quality, Power-Query template management, and regulatory calculations deterministic, auditable, and safe to operate at scale.” </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — DQGuard.xlam (Data Quality Guard)</strong><br><strong>Purpose & scope:</strong> detect, profile, validate, propose, and safely apply data-quality fixes to Excel tables and Power Query outputs. DQGuard does <strong>not</strong> replace upstream source systems — it prepares, documents, and outputs traceable corrections that downstream consumers can trust.<br><strong>Core responsibilities (detailed):</strong> deterministic profiling (seeded sampling), rule evaluation (stable rule IDs, severities), standardization pipelines (reversible transforms, mapping evidence), match & merge (deterministic grouping, tie-breakers), remediation proposal generator (rationale, examples, confidence), operator review UI (preview with PII redaction), apply engine (create_copy default, inline with approvals), reconciliation (checksums & diffs), export packaging (atomic write + checksum), audit row emission and evidence bundling (encrypted archives).<br><strong>Key modules & roles:</strong> <code>DQ_Ribbon</code> (UI entrypoints, minimal IO), <code>DQ_Profile</code> (metrics generation, sampling), <code>DQ_Rules</code> (rules engine, deterministic evaluation), <code>DQ_Standardize</code> (standardization map runner), <code>DQ_MatchMerge</code> (blocking/greedy matching and merges), <code>DQ_Remediation</code> (proposal generation), <code>DQ_Apply</code> (applier & reversible plans), <code>DQ_Export</code> (atomic export & checksum), <code>DQ_Audit</code> (append-only chain), <code>DQ_Utilities</code>, <code>DQ_Config</code>.<br><strong>Typical outputs & evidence:</strong> <code>profile_report.csv</code>, <code>validation_report.csv</code>, remediation <code>proposal_&lt;id&gt;.json</code>, <code>applyDescriptor</code>, <code>before/after</code> snapshots, <code>recon_report.json</code>, audit rows with <code>correlationId</code>, encrypted evidence bundles with per-artifact checksums. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — PQTools.xlam (Power Query templates & injection)</strong><br><strong>Purpose & scope:</strong> provide a managed library of canonical Power Query (M) templates, tools to parameterize & preview M, inject trustworthy queries into workbooks, manage connections, and collect refresh diagnostics — all with full audit trails.<br><strong>Core responsibilities (detailed):</strong> embedded template registry (hidden sheet or external repo), template versioning and mChecksum computation, parameterization UI, safe injection (<code>Workbook.Queries.Add</code>), optional connection creation (connection-only vs model), refresh & diagnostic capture (provider, duration, error capture), export of M + diagnostics (atomic + checksum), governance hooks for regulated templates (PR, owner approval, signed artifacts).<br><strong>Key modules & roles:</strong> <code>PQ_Ribbon</code>, <code>PQ_LibraryManagement</code>, <code>PQ_Injector</code>, <code>PQ_Connections</code>, <code>PQ_Refresh</code>, <code>PQ_Export</code>, <code>PQ_Audit</code>.<br><strong>Typical outputs & evidence:</strong> <code>m_&lt;templateName&gt;.pq</code>, <code>mChecksum</code>, <code>pq_diagnostics/&lt;run-id&gt;.json</code>, template change manifests, injection audit rows referencing <code>mChecksum</code>, release artifacts for approved templates. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — Regulatory.xlam (Regulatory Engine)</strong><br><strong>Purpose & scope:</strong> run deterministic, auditable regulatory calculation pipelines (examples: IFRS recognitions) and produce signed outputs suitable for regulatory filing or downstream deterministic consumers. The regulatory add-in enforces stricter governance: golden parity, two-person approvals for behavioral changes, and scheduled verifications in CI.<br><strong>Core responsibilities (detailed):</strong> canonical pipeline stages (normalization → validation → allocation → recognition schedule → journal mapping), isolated execution model (job scheduler + worker runner), SafeRound & residual absorption for allocations, canonical artifact creation (reports, journals), atomic export with fallback, audit chain rotation & signing, integration with release manifest and canary rollouts, and regulatory-package assembly for incidents and audits.<br><strong>Key modules & roles:</strong> <code>REG_Ribbon</code>, <code>REG_Bootstrap</code>, <code>REG_Config</code>, <code>REG_EnsureDeps</code>, <code>REG_Utilities</code>, <code>REG_Calculations</code>, <code>REG_Export</code>, <code>REG_Audit</code>, <code>REG_Error</code>.<br><strong>Typical outputs & evidence:</strong> canonical report sets, signed release manifests, golden fixtures, audit rotations, reconciliation artifacts used for CI golden parity checks. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>What project is this? explanation</strong><br><strong>Name (conceptual):</strong> Excel Data Governance & Regulatory Delivery Platform.<br><strong>Primary mission:</strong> enable analysts and stewards to perform trustworthy data preparation and regulatory calculation tasks inside Excel while preserving engineering controls — reproducibility, auditability, deterministic outputs, and safe deployable artifacts.<br><strong>Core functional pillars:</strong> 1) <em>Detect & prepare</em> (DQGuard), 2) <em>Template & pipeline management</em> (PQTools), 3) <em>Authoritative regulated computations & delivery</em> (Regulatory).<br><strong>Non-goals / out-of-scope (explicit):</strong> replacing source-of-truth systems, persistent secret key management outside KMS/HSM workflows, or implicitly mutating external systems without explicit, auditable integration. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Typical stakeholders & outputs</strong><br><strong>Stakeholders:</strong> Operators (daily users), Data Stewards (policy owners), Rules Owners (domain logic maintainers), Developers (module maintainers), Release Engineers (CI/CD & signing), Compliance (regulatory reviewers), On-call SRE (runtime & incidents), Business owners (acceptance).<br><strong>Primary artifacts produced:</strong> <code>audit_tail.csv</code> (append-only local tail), signed audit rotation archives, <code>profile_report.csv</code>, <code>validation_report.csv</code>, <code>standardize-map.json</code> + signature, <code>migration_manifest.json</code> (for semantic changes), exported datasets (atomically written + checksummed), preview artifacts (UI redacted + evidence bundles), release manifests, golden fixtures and parity reports. These artifacts are stored in artifact stores with chain-of-custody metadata for regulated runs. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Typical workflow — fully expanded step-by-step</strong><br>1. <strong>Bootstrap</strong>: Excel starts; Add-in Loader loads minimal code; <code>CORE_Bootstrap</code> opens structured logs, seeds correlation ID generator, registers shutdown hooks. <em>Constraint:</em> no heavy IO or Excel Range reads during bootstrap. {audit: bootstrap.started}.<br>2. <strong>Deferred init (UI Idle)</strong>: <code>CORE_Config</code> loads config (validate JSON schema v7), computes <code>config.hash</code>, applies idempotent migrations; <code>CORE_EnsureDeps</code> verifies external integrations and produces <code>deps.report.json</code>; <code>CORE_Utilities</code> loads deterministic helpers (SafeRound, AtomicWrite, DeterministicRNG); <code>CORE_ManifestLoader</code> reads manifests & <code>OWNERS.md</code>. Add-in specific assets (rules/rule maps, PQ templates, regulatory fixtures) are loaded deferred. {audit: config.loaded, rules.loaded:version}.<br>3. <strong>Ribbon ready</strong>: UI initialized, <code>ribbon.ready</code> audit row appended.<br>4. <strong>Operator picks Add-in</strong>: DQGuard / PQTools / Regulatory. The ribbon click logs a <code>UserAction</code> audit with correlation id. Lightweight actions run inline; heavy actions schedule a job. {audit: UserAction(module=..., procedure=click)}.<br>5. <strong>DQ flow (example)</strong>: run <code>DQ_Profile</code> → deterministic sample & metrics → <code>DQ_Rules</code> → validation report → <code>DQ_Remediation</code> propose fixes → operator preview via <code>PreviewStandardize</code> (redacted) → operator decision (reject / accept) → if accept then <code>DQ_Apply</code> creates reversible apply descriptor and persists apply job → <code>DQ_Export</code> writes corrected dataset atomically → <code>DQ_Audit</code> appends final audits and evidence reference. All steps record <code>correlationId</code>, <code>payloadHash</code>, <code>artifact.checksum</code> as applicable.<br>6. <strong>PQ flow (example)</strong>: user picks template → parameterize → preview M → inject into workbook (optionally create connection) → run refresh/diagnostics → export M + diagnostics → audit rows including <code>mChecksum</code> and operatorId. Template edits require PR + owner approval for regulated templates.<br>7. <strong>REG flow (example)</strong>: operator triggers regulated calculation → action scheduled as job (heavy) → <code>CORE_JobScheduler</code> persists job descriptor {jobId, params, configHash} → isolated <code>CORE_ExecutionWorker</code> runs canonical pipeline, using <code>SafeRound</code> for allocations → produce deterministic artifacts → <code>REG_Export</code> -> atomic write + checksum + staged fallback if network down → <code>CORE_Audit</code> rotates & signs. Post-run: reconciliation, attach release manifest, golden-file checks. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Why this architecture reasoning</strong><br>1. <strong>Excel ubiquity</strong>: Excel is the de-facto environment for analysts and stewards; embedding enterprise patterns in XLAMs reduces ad-hoc error-prone workflows.<br>2. <strong>Separation of concerns</strong>: isolating DQ, PQ, and REG responsibilities reduces coupling and allows specific governance and testing regimes per area (e.g., golden parity for REG, template governance for PQ, proof-of-fix for DQ).<br>3. <strong>Determinism & evidence</strong>: deterministic transforms, canonical JSON hashing, signed manifests, and encrypted evidence bundles allow reproducibility & regulatory defense; evidence becomes the legal record rather than ephemeral console logs. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Governance, approvals & CI/CD</strong><br><strong>Change control:</strong> any change that materially alters regulated outputs needs: PR, unit & integration tests, golden parity tests, migration manifest (with sample diffs & rollback plan), and two-person approval. <br><strong>CI pipeline:</strong> static analysis (forbidden APIs), unit tests, property tests for determinism, integration tests (plan→preview→apply→revert chains), golden parity checks across locales/bitness, performance microbenchmarks, audit chain verification, artifact signing, and publishing. CI must block merges on golden parity or audit-chain failures for regulated artifacts.<br><strong>Release flow:</strong> produce signed release manifest (artifact checksums, map hashes, configHash); canary rollouts with KPI gating (false positives, operator acceptance, latency); automatic expand or rollback based on KPI thresholds; produce release audits and retention snapshots. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Security, secrets & PII handling</strong><br>- XLAMs must be code-signed; macros enabled policy enforced by org controls.<br>- Raw secrets never read by utilities; use <code>modSecurity</code> to obtain ephemeral tokens & KMS/HSM operations. Evidence bundles encrypted via KMS envelopes. <br>- PII is redacted in UI previews; full sanitized evidence retained in encrypted evidence stores referenced by <code>evidenceRef</code>. Audit rows only contain minimal or pseudonymous fields. <br>- Incident playbook: set exports read-only, quarantine helpers, export rotated audits to forensic share, compute <code>forensic_manifest.json</code> (sha256 checksums), run VerifyAuditChain, notify Compliance/regulators per timelines. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Observability & metrics</strong><br><strong>Telemetry:</strong> buffered <code>util.*</code> metrics for core helpers; module metrics like <code>standard.preview.duration_ms</code>, <code>standard.apply.duration_ms</code>, <code>pq_refresh.latency_ms</code>, <code>reg.calc.duration_ms</code>. <br><strong>Audit rows:</strong> mandatory for every operator action; minimal fields: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code> (include <code>standardMap.hash</code> or <code>configHash</code> where relevant). <br><strong>Dashboards & alerts:</strong> SLOs & alerts for failing golden parity, high <code>handler.timeout_rate</code>, export failure spikes, and sudden increases in remediation acceptance/reject rates. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Evidence & artifact retention (expanded)</strong><br><strong>Retention tiers:</strong> hot=30d (fast access), warm=7y (regulated long-term), cold=per regulation. Evidence bundles for regulated runs preserved immutably (WORM) with chain-of-custody metadata and signed rotations. <strong>Forensic packages</strong> include: release manifest, signed map, audit rotations, preview evidence, apply descriptors, checksums, and <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Quick recommended repo & artifact layout</strong><br>`<code>/repo</code><code> root contains subprojects and CI infra.&lt;br&gt;</code><code>/repo/dqguard</code><code> — </code>src/<code> (VBA modules + any TypeScript/Node helper tools), </code>assets/standardize-map.json<code>, </code>OWNERS.md<code>, </code>tests/<code> (unit/integration/golden), </code>docs/runbooks/<code>.&lt;br&gt;</code><code>/repo/pqtools</code><code> — </code>templates/<code> (hidden-sheet loader, external template sync), </code>src/<code>, </code>tests/<code>.&lt;br&gt;</code><code>/repo/regulatory</code><code> — </code>calculations/<code> (canonical pipelines), </code>fixtures/<code> (golden), </code>selftests/<code> (parity harness), </code>tests/<code>.&lt;br&gt;</code><code>/repo/core</code><code> — </code>src/modUtilities.bas<code>, </code>src/modBootstrap.bas<code>, </code>src/modAudit.bas<code>, </code>tests/<code> (safe_round vectors, RNG golden), </code>release/<code> (</code>Core.xlam<code>).&lt;br&gt;</code><code>/repo/ci</code><code> — pipeline.yml, golden/, smoke-test-harness/, release-manifests/, signing-keys-integration (CI hooks).&lt;br&gt;</code><code>/repo/docs</code>` — runbooks, operator-cheatsheets, migration_manifest_template.json, ErrorCodeCatalog.md. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Implementation priorities — suggested roadmap</strong><br>1. <strong>Core primitives (Core.xlam)</strong>: SafeRound, AtomicWrite, ComputeChecksum, DeterministicRNG, CanonicalJsonSerialize. Implement unit tests and golden vectors. <br>2. <strong>Audit rotation & evidence store</strong>: append-only tail, rotation signing, evidence bundle encryption. <br>3. <strong>DQGuard minimal pipeline</strong>: profile → rules → proposal → preview → create_copy apply → export. <br>4. <strong>PQTools template management</strong>: embedded template store with mChecksum and injection plumbing. <br>5. <strong>Regulatory parity harness</strong>: canonical pipeline + CI golden tests and release manifest. <br>6. <strong>Operational runbooks & CI enforcement</strong>: static analysis, golden parity gates, signature enforcement. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Operational runbooks — examples to ship</strong><br>- <strong>Operator day-to-day:</strong> Profile → Preview → Propose → Apply (create_copy) → Reconcile → Export → bundle evidence & append audit.<br>- <strong>Release:</strong> PR → CI (tests + golden) → Sign → release manifest → canary → monitor KPIs → roll out or rollback → record rollout audits.<br>- <strong>Incident response:</strong> Detect → Contain (read-only exports) → Forensic export → Triaging & revert → Remediation & post-mortem → regulatory package if needed. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Risks & mitigations — high-level</strong><br>1. <strong>Non-determinism across hosts</strong> — mitigation: canonical JSON rules, seeded RNG, cross-platform golden parity tests. <br>2. <strong>Audit or evidence tampering</strong> — mitigation: signed audit rotations, WORM storage, VerifyAuditChain in CI. <br>3. <strong>Operator errors applying destructive fixes</strong> — mitigation: default <code>create_copy</code>, two-person approval enforcement, preview & redaction. <br>4. <strong>Performance on large datasets</strong> — mitigation: chunked transforms, worker offload, checkpointed job descriptors. </td></tr></tbody></table></div><div class="row-count">Rows: 17</div></div><div class="table-caption" id="Table2" data-table="Docu_0176_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — DQGuard.xlam (Authoritative Runbook)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — DQGuard.xlam (Authoritative Runbook)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing DQGuard.xlam. It governs detection, profiling, standardization, matching/merging, remediation proposals, safe application of fixes, exports, and audit generation for datasets that feed reporting, analytics, or regulatory outputs. If any other document conflicts with this runbook, this runbook takes precedence. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation or local adaptation requires a written exception, risk assessment, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Primary audience and responsibilities</strong><br>Roles: Operator, Data Steward, Rules Owner, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Each procedural section below is labeled with the relevant role and lists required evidence and verification steps. Operators execute routine tasks; Data Stewards approve rules and remediation policies; Developers implement rule logic and tests; Release Engineers manage deployments and rollbacks; Compliance reviews regulated changes and migration manifests. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>High-level purpose, out-of-scope items</strong><br>Purpose: deterministic, auditable detection and controlled remediation of data quality issues in Excel tables and Power Query results. Out of scope: replacing canonical source systems, performing secret key management outside defined KMS/HSM workflows, or mutating external systems without explicit, auditable integration. Integrations (database connectors, APIs) are permitted only with documented connectors and explicit security review. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Core principles and non-negotiables</strong><br>1) Determinism: same input and configuration must produce identical outputs.<br>2) Auditability: every material action appends an append-only audit row with correlation ID and payload hash.<br>3) Reversibility: remediation plans are reversible by default; apply actions produce a preserved "before" copy unless governed approvals permit inline change.<br>4) Separation: detection ≠ correction. Detection never mutates original input without explicit acceptance. Any weakening of these principles requires a documented impact assessment and two-person approval. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Golden rule for operators</strong><br>Always capture the correlationId before, during, and after every run. Keep original data immutable and store it with an evidence manifest. Preview proposals; do not accept blind auto-fixes. For regulated outputs, require two-person approval before apply or enabling any auto-apply behavior. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Overview of runtime phases (guarantees & markers)</strong><br>Phases: bootstrap → deferred init → UI idle → detection (profile/rules/match) → remediation proposal → apply → export → audit rotation. Each phase emits distinctive audit markers (examples: <code>bootstrap.started</code>, <code>rules.loaded:vX</code>, <code>profile.completed:&lt;runId&gt;</code>, <code>remediation.proposed:&lt;proposalId&gt;</code>, <code>remediation.applied:&lt;applyId&gt;</code>). Detection must never perform destructive writes. Apply actions are auditable and produce before/after checksums. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Module map and single-responsibility contracts</strong><br><code>DQ_Bootstrap</code>: start-up, correlation id, non-IO init only.<br><code>DQ_RibbonCallbacks</code>: maps UI controls to handlers, ensures correlation id tagging, logs <code>UserAction</code> audit rows.<br><code>DQ_Config</code>: config loading, schema validation, idempotent migrations, expose <code>config.hash</code>.<br><code>DQ_Utilities</code>: shared helpers (atomic-write, SafeRound, retry, deterministic RNG).<br><code>DQ_Profile</code>: deterministic sampling and profile metrics. <br><code>DQ_Rules</code>: rule engine, stable rule IDs and severities. <br><code>DQ_Standardize</code>: normalization transforms with reversible mapping. <br><code>DQ_MatchMerge</code>: deterministic matching, tie-breakers, merge proposals. <br><code>DQ_Remediation</code>: propose and apply plans, create copy vs inline apply. <br><code>DQ_Export</code>: atomic export with checksum and retry. <br><code>DQ_Audit</code>: append-only chained audit records and rotation. <br><code>DQ_Error</code>: centralized error taxonomy and operator messaging. Each module publishes owner, API surface, and emits audit rows for critical transitions. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_Bootstrap — checks and operator evidence</strong><br>Must only initialize non-blocking tasks: open structured logs, create correlation id generator, schedule deferred init on UI idle, register shutdown hooks. MUST NOT perform heavy IO or access Excel ranges. Verify <code>bootstrap.log</code> contains <code>init-scheduled</code> and <code>correlationSeed</code>. Evidence to collect: <code>bootstrap.log</code>, <code>add-in registration state</code>, Excel process listing when disabled. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_RibbonCallbacks — UI/UX mapping & audit obligations</strong><br>Every ribbon control maps to one handler. Handlers: generate correlation id, log click, append <code>UserAction</code> audit row with <code>module</code>, <code>procedure</code>, <code>userId</code>, and minimal payload. Ribbon groups: Profile, Validate, Propose, Apply, Export, Diagnostics. Keep <code>ribbon-map.json</code> and include mapping verification steps in release checks. Evidence: <code>ribbon-map.json</code>, UI screenshots when needed, <code>audit_tail.csv</code> rows for interactions. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_Config — governance & migration policy</strong><br>Single source configuration for thresholds, sampling, matching tolerances, automation policies. Load once; validate JSON Schema v7; compute <code>config.hash</code>. Changes that alter remediation behavior require migration manifest with sample counts and rollback plan. Evidence: <code>config.json</code>, <code>config.hash</code>, <code>migration_manifest.json</code>, <code>config.audit</code> row. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Rule management (DQ_Rules) — lifecycle, IDs, and testing</strong><br>Rules have stable IDs, severity, textual description, and remediation guidance. Rule changes follow PR + automated tests + migration manifest for behavior changes. Unit tests must cover positive & negative fixtures and edge cases. Rule releases to production follow canary/pilot patterns. Evidence: rule PRs, test results, <code>rules.loaded:version</code> audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Profiling (DQ_Profile) — determinism & outputs</strong><br>Profile produces deterministic metrics with configured <code>seed</code> and <code>sampleSize</code>: rowCount, null counts, unique counts, top values, histograms, outliers, pattern frequencies, and deterministic sample rows for inspection. Output artifacts: <code>profile_report.csv</code>, <code>profile_summary.json</code>, sample CSVs. Profiling emits <code>dq_profile</code> audit row with <code>profileHash</code> and <code>runId</code>. Evidence: profile files, run logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Standardization (DQ_Standardize) — reversible transforms</strong><br>Standardizations: Unicode normalization, trimming, whitespace collapse, punctuation normalization, canonical date parsing to ISO 8601, currency and locale normalization. Record transform mapping for reversible ops. Operators MUST preview standardizations before apply. Evidence: <code>standardization_report.csv</code>, before/after samples. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Match & merge (DQ_MatchMerge) — deterministic grouping</strong><br>Matching algorithms output stable <code>mergeId</code> groups, similarity scores, and deterministic representative selection using explicit tie-breakers. Merge proposals list group members, representative row, confidence, and recommended action. Auto-merge requires explicit <code>AUTO_MERGE</code> flag plus two-person approval for regulated datasets. Evidence: <code>match_groups.csv</code>, preview artifacts. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Remediation proposals & apply policy (DQ_Remediation)</strong><br>Each proposal contains: <code>proposalId</code>, <code>ruleId</code>, rationale, affected count, confidence, sample before/after, and an <code>applyPlan</code> specifying <code>create_copy</code> (default) or <code>inline</code> apply. <code>create_copy</code> preserves the original worksheet/workbook and writes the fixed set to a separate sheet/workbook. <code>inline</code> requires auditable operator authorization and two-person approval when regulated. Applying a proposal appends <code>dq_apply</code> audit row with <code>beforeChecksum</code> and <code>afterChecksum</code> and stores a reversible plan. Evidence: proposal JSON, apply logs, preserved original copy. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Exports and artifact integrity (DQ_Export)</strong><br>All exports use atomic write semantics: write to temp file then rename/move to final location. Compute <code>artifact.checksum.sha256</code> and embed checksum in export metadata and audit row. If network upload fails, fallback to staged local delivery. Export audit fields include <code>destination.uri</code>, <code>attempts</code>, and <code>final.status</code>. Evidence: exported file, checksum file, <code>DQ_Export</code> logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Audit chain (DQ_Audit) — canonical record</strong><br>Audit rows are append-only and cryptographically chained. Each row minimally includes: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Chain verification runs periodically in CI and monitoring. Audit buffers are allowed but MUST flush within configured interval. Evidence: <code>audit_tail.csv</code>, signed rotation archives. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Error taxonomy & operator messaging (DQ_Error)</strong><br>Error codes map to stable messages and remediation hints in <code>ErrorCodeCatalog.md</code>. End-user messages show the correlation id only. Full diagnostic traces are stored in logs (encrypted-at-rest) and linked to the correlation id. High-severity errors auto-page on-call and generate an incident audit row. Evidence: <code>error.log</code>, mapping reference. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Configuration & feature flags (operations governance)</strong><br>Feature flags control sampling, auto-apply, and algorithm variants. Resolution precedence: runtime admin > remote config > local file > defaults. Flags that enable automatic correction for regulated data require two-person approval and an explicit migration manifest. Flag operations must be auditable and reversible. Evidence: <code>flags.audit</code>, flag history. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Canary & phased rollout (release pattern)</strong><br>Deploy rule changes via cohorts: pilot tenants → pilot users → larger cohort. Gate using KPIs: false positive rate, operator acceptance rate, apply success rate, profile latency. Rollback automatically on KPI threshold breaches. All rollout transitions recorded in <code>deployment.audit</code>. Evidence: release manifest, rollout audit rows, KPI snapshots. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Config migrations & offline tooling</strong><br>Migrations for rules or standardizations MUST include a migration manifest listing steps, sample transformations, estimated affected counts, and backout plan. Offline migration tooling supports dry-run and produces sample artifacts for compliance review. Migration runs append a <code>migration.audit</code> row. Evidence: <code>migration_manifest.json</code>, dry-run outputs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Runtime debug, safe-ops, and admin controls</strong><br>Admin debug panel provides controlled actions: verbose logging, reload rules, flush audit buffers, export diagnostics, or toggle non-critical flags. Access to debug requires MFA and an access ticket; every debug action records a <code>debug.audit</code> row with justification. Debug mode defaults to OFF and must be disabled post-troubleshooting. Evidence: <code>diagnostics.zip</code>, <code>debug.audit</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Security & incident response (IR) playbook</strong><br>Containment steps for suspected PII or audit compromise: set exports read-only, disable auto-apply flags, quarantine helper scripts, export rotated audit archives to secure forensic share, preserve environment snapshots, collect <code>bootstrap.log</code>, <code>dq_profile.log</code>, <code>dq_rules.log</code>, config snapshots, and job descriptors. Forensic manifest must include SHA256 checksums and chain-of-custody metadata. Notify Compliance and follow regulator-specific reporting timelines. Evidence: forensic archive and <code>forensic_evidence_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Forensic evidence manifest fields (required)</strong><br>The manifest MUST include <code>manifestId</code>, <code>collectedAt</code>, <code>collector</code>, list of artifacts (path, role, sha256), storage location, and contact for chain-of-custody. Store manifest in secure evidence repository and reference it from incident audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Containment, remediation & post-incident</strong><br>Containment: disable writes/exports, quarantine helpers, and preserve audit. Remediation: restore signed artifacts from immutable storage, rotate keys/credentials as needed, re-run VerifyAuditChain, and run regression tests on sample fixtures. Post-mortem deliverables: timeline, RCA, corrective actions, verification artifacts, and regulatory package when required. Record a <code>post-mortem</code> audit row with attachments. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Deployment, upgrade & rollback runbooks</strong><br>Pre-deploy checklist: signed artifacts, passing CI (unit/integration/golden parity), config snapshot, and audit rotation backup. Canary rollout with KPI gating. Emergency rollback: activate kill-switch, revoke remote flags, reinstall prior signed build, restore config snapshot, run rule self-tests and VerifyAuditChain, and publish <code>deployment.audit</code> rows for all steps. Evidence: signed installer, release manifest, rollback log. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>CI/CD gates and automated tests</strong><br>CI must run: lint, unit tests, rule regression tests using canonical fixtures, profile golden parity tests across locales and Excel bitness, deterministic match-merge tests, audit chain verification, performance microbenchmarks, and artifact signing. Releases without passing golden parity for regulated outputs require migration manifests and compliance approval. Evidence: CI reports, test artifacts, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Fixtures and golden-file governance</strong><br>Maintain canonical fixtures for profiling, rules, and match-merge across locales and Excel versions. Golden artifacts stored immutably. Any change requires PR, migration manifest, and compliance approval. CI compares outputs to golden hashes and blocks changes unless a migration path is approved. Evidence: <code>golden/*</code>, <code>ci-golden-report.json</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Performance SLAs, metrics, and remediation</strong><br>Instrument metrics: profile duration, rule eval latency, match-merge throughput, audit flush time, memory usage. Example thresholds: profile WARN>30s for small tables; CRIT>300s for large tables. Rule eval WARN>5s per 1k rows. Audit flush WARN>5s CRIT>30s. Remediation actions: scale sampling, increase worker counts, throttle concurrency, or run offline in isolated runner. Evidence: metrics dashboards and alert logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Monitoring, dashboards & alerting rules</strong><br>Monitor: top failing rules, remediation acceptance rate, recent large exports, audit chain health, profile latency. Alert playbooks include triage steps, required evidence, correlation id, and on-call contact. Critical alerts automatically page stakeholders and open incident tickets. Evidence: alert history and incident tickets. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>High-severity runbooks (concrete examples)</strong><br>1) Suspected PII exposure: set exports read-only, export forensic archive, run full PII-scan, notify Compliance/regulators, and preserve evidence.<br>2) Rule regression causing mass false positives: revert to last known-good ruleset, run golden comparisons, produce impacted-ID manifest, and notify owners.<br>3) Merge corruption: set runner to read-only, export match groups and sample merges, run reconciliation, restore from last verified signed baseline. Each runbook includes contact list, evidence checklist, and "must-do" audit steps. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Reconciliation & verification processes</strong><br>Reconciliation tooling compares corrected datasets to source-of-record. Standard workflow: dry-run, review affected IDs and samples, obtain operator sign-off, apply in copy mode, then re-run reconciliation and record <code>reconciliation.&lt;id&gt;</code> audit row. Required evidence: <code>reconciliation_report.json</code>, before/after checksums, operator approvals. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>PII handling, encryption & key management</strong><br>Classify PII fields and enforce redaction rules for any human-readable exports. Encrypt audit rotations and forensic archives using KMS/HSM-backed envelope encryption. Maintain key rotation schedules and multi-person approval for key export or audit-signing key changes. Keep a log of all key operations in the audit. Evidence: key rotation logs and signed audit rotations. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operator commands, UI flows, and exact evidence lists</strong><br>Operators must follow canonical UI flows: Profile → Validate → Propose → Preview → Apply (Create copy preferred) → Export. Each operation appends an audit row with <code>correlationId</code>. Evidence list per operation: correlationId, original workbook copy, profile report, proposal file, fixed copy (if applied), export artifact, and relevant log files. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operational cheat-sheets and one-page runbooks</strong><br>Provide copy-ready one-page checklists for: Profile success flow; Validation failure triage; Propose→Preview→Apply flow; Export and checksum verification; Reconciliation dry-run and apply. Store those cheat-sheets in <code>runbooks/cheatsheets/</code> and reference them in the UI help. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Post-mortem, change request, and regulatory package templates</strong><br>Templates capture: timeline, root cause, evidence attachments, mitigations, owners, and compliance sign-offs. Regulatory packages bundle release manifest, audit rotations, migration manifests, golden fixture diffs, and anonymized sample inputs/outputs demonstrating deterministic behavior. Store templates under <code>appendices/templates/</code> and require two-person approval to publish. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Canonical evidence templates (fields to capture)</strong><br>Audit CSV header: <code>timestamp,correlationId,module,procedure,severity,userId,payloadHash,prevHash,signature,metadata</code>.<br>Profile report fields: <code>runId,tableName,rowCount,nullRate,uniqueRate,topValues,...</code>.<br>Remediation proposal fields: <code>proposalId,affectedCount,confidence,exampleBefore,exampleAfter,ruleId</code>.<br>Reconciliation manifest fields: <code>reconciliationId,affectedIds,correctionSummary,operatorId</code>. Keep templates versioned. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Developer verification & acceptance checklist</strong><br>Developers must provide: unit tests for rule logic, integration tests for profile→rule→proposal chain, deterministic match-merge tests across locales, golden-file parity fixtures, audit chain verification tests in CI, performance benchmarks, signed artifacts, and compliance approvals for regulated-rule changes. CI failure blocks release. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Common failure modes and operator responses</strong><br>• Add-in missing: collect <code>bootstrap.log</code>, COM/VSTO state, reinstall signed artifact, record <code>install.audit</code>.<br>• Profile failure on large table: reduce sample size; run in isolated worker; collect <code>dq_profile.log</code> and staging outputs.<br>• Incorrect remediation applied: immediately restore preserved original copy, run reconciliation, collect <code>dq_apply.log</code> and open incident. Always collect evidence and record audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Audit compromise & forensic runbook (summary)</strong><br>Steps: set audit read-only, export rotations with checksums to forensic share, run VerifyAuditChain, locate first mismatch, restore or reconstruct last verified rotation under compliance, notify regulators as required, run kill-switch tests, and create a forensic manifest mapping artifacts to checksums. Record all steps in incident audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Training, drills, and retention</strong><br>Annual operator training on key flows. Quarterly tabletop exercise for a representative incident. Annual full forensic drill including audit export and VerifyAuditChain. Retention policy: hot=30d, warm=7y, cold=per regulation. Housekeeping tasks run monthly with audit entries. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Appendices & location of canonical artifacts</strong><br>Appendices include: audit row examples, profile schema, rule catalog format, remediation templates, migration manifest template, release manifest template, operator cheat-sheets, and glossary. Store all appendices and artifacts in immutable artifact storage with version tags, e.g., <code>runbook/v{major}.{minor}/appendices/</code>. Access controlled by RBAC; PRs required for edits. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Change-control checklist (must do before production change)</strong><br>1) Open change ticket and include rollback plan. 2) Run self-tests and include results. 3) Attach migration manifest if behavior changes. 4) Obtain two-person approval for remediation automation changes. 5) Sign artifacts and publish release manifest. 6) Canary rollout with KPI gating. 7) Post-rollout VerifyAuditChain and record results. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Short operator escalation matrix (who to call, in order)</strong><br>1) Rules Owner (first line) — rule interpretation and minor fixes. 2) Data Steward — policy and remediation approvals. 3) Release Engineer — deployment / rollback. 4) On-call SRE — platform incidents. 5) Compliance Officer — regulatory escalations. Always include correlationId and saved evidence attachments in the ticket. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Where to store outputs and canonical naming</strong><br>Set recommended storage paths (adjust per org policy): releases, <code>\\artifacts\DQGuard\releases\</code>; config, <code>\\config\DQGuard\</code>; audit rotations, <code>\\audit\DQGuard\rotation\</code>; forensic, <code>\\forensic\DQGuard\</code>. Filenames should embed correlationId and timestamp for traceability. Example naming convention: <code>dq_profile_&lt;table&gt;_&lt;runId&gt;_&lt;timestamp&gt;.csv</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Minimum artifact checklist per regulated run</strong><br>For any run that feeds regulated output, collect: original input copy, profile report, validation report, remediation proposals, apply logs (if any), exported artifacts, audit rotation snapshot, release manifest + config.hash, migration manifest (if rules changed), and checksums for all artifacts. Bundle and store in secure archive and reference manifest in the audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operator quick reference — condensed steps</strong><br>1) Start with a copy. 2) Run Profile. 3) Inspect rule failures. 4) Generate proposals and preview. 5) Apply using Create copy. 6) Re-run Profile and Reconciliation. 7) Export and record checksums. 8) Append audit rows for each step. 9) If in doubt or high-severity, escalate immediately. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Final note on governance</strong><br>Strict rule: anything that materially changes regulated outputs or data used downstream requires PR, migration manifest, tests, and two-person approval. The audit chain is the legal record; preserve it. This runbook is the operational source of truth — follow it, and attach evidence to the audit for every significant action. </td></tr></tbody></table></div><div class="row-count">Rows: 48</div></div><div class="table-caption" id="Table3" data-table="Docu_0176_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — Regulatory.xlam"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — Regulatory.xlam</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing <strong>Regulatory.xlam</strong>. It governs calculation pipelines, recognition schedules, allocation logic, exports used for regulatory reporting, and all audit-producing actions. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation from this runbook for regulated outputs requires a written exception, migration manifest, risk assessment, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Primary audience & role responsibilities</strong><br>Roles: Operator, Rules Owner, Data Steward, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Each procedural section references the responsible role and required evidence. Operators execute runs; Rules Owners approve calculation and mapping changes; Developers implement code/tests; Release Engineers manage releases/rollback; Compliance approves regulatory-affecting changes. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>High-level purpose & out-of-scope</strong><br>Purpose: deterministic, auditable calculation and export of regulatory deliverables (recognition schedules, journal entries, regulatory mapping). Out-of-scope: replacing canonical ledgers outside approved connectors, private key management outside KMS/HSM workflows, or mutating external source systems without documented, auditable integration. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Core principles (non-negotiable)</strong><br>1) <strong>Determinism:</strong> identical input + config => identical outputs. Seeded RNG for sampling, ordered maps. <br>2) <strong>Auditability:</strong> every material action appends an append-only audit row with <code>correlationId</code> and payload hash. <br>3) <strong>Reversibility:</strong> apply plans default to <code>create_copy</code> (preserve original); inline changes require explicit approvals and reversible plan storage. <br>4) <strong>Separation:</strong> detection/validation MUST NOT perform destructive writes. Any weakening requires impact assessment + two-person approval. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Golden rule for operators</strong><br>Capture the <code>correlationId</code> before, during, and after every run. Start with a saved copy. Preview proposals and never accept blind auto-fixes for regulated outputs. For regulated runs require two-person approval before any <code>AUTO_APPLY</code>. Evidence: original workbook copy, profile & validation reports, proposal files, apply logs, export artifacts. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Module map & single-responsibility contracts</strong><br><code>REG_Bootstrap</code> — non-IO init, correlation id generator, schedule deferred init.<br><code>REG_Ribbon</code> — UI handlers, correlation tagging, UserAction audit rows.<br><code>REG_Config</code> — load/validate JSON Schema v7, compute <code>config.hash</code>, idempotent migrations.<br><code>REG_EnsureDeps</code> — validate dependent add-ins/templates and produce <code>deps.report.json</code>.<br><code>REG_Utilities</code> — SafeRound, atomic-write, retry, deterministic RNG.<br><code>REG_Calculations</code> — canonical recognition, allocation, SafeRound residual logic, mapping to journals.<br><code>REG_Export</code> — atomic export, checksum, staged fallback.<br><code>REG_Audit</code> — append-only chained audit rows and rotation/signing.<br><code>REG_Error</code> — centralized error taxonomy and operator messaging. Each module publishes owner, API, and emits audit rows for critical transitions. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Runtime phases & required audit markers</strong><br>Phases: <code>bootstrap.started</code> → deferred init → <code>ribbon.ready</code> → job scheduling → execution (calculation phases) → proposal → apply → export → audit rotation. Example markers: <code>bootstrap.started</code>, <code>config.loaded:&lt;hash&gt;</code>, <code>job.persisted:&lt;jobId&gt;</code>, <code>calc.step:&lt;step&gt;</code>, <code>remediation.proposed:&lt;proposalId&gt;</code>, <code>remediation.applied:&lt;applyId&gt;</code>, <code>export.attempt:&lt;artifactId&gt;</code>. Detection/validation steps MUST NOT write/destructively change input. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Bootstrap — checks & operator evidence</strong><br>MUST only initialize non-blocking tasks: open structured logs, create correlation id generator, schedule deferred init on UI idle, register shutdown hooks. MUST NOT perform heavy IO or access Excel ranges. Evidence: <code>bootstrap.log</code> containing <code>init-scheduled</code> and <code>correlationSeed</code>; add-in registration state. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Ribbon — UI mapping & audits</strong><br>Every ribbon control maps to a single handler. Handlers generate correlation id, log clicks, and append <code>UserAction</code> audit rows with <code>module</code>, <code>procedure</code>, <code>userId</code>, and minimal payload. Ribbon groups: Validate, Calculate, Propose, Apply, Export, Diagnostics. Maintain <code>ribbon-map.json</code> and include mapping verification in release checks. Evidence: <code>ribbon-map.json</code>, UI screenshots if needed, <code>audit_tail.csv</code> rows for interactions. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Config — governance & migration policy</strong><br>Single source config for thresholds, rounding rules, residual absorption policies, mapping tables, and automation flags. Load once; validate JSON Schema v7; compute <code>config.hash</code>. Any config change that alters regulatory outputs requires a migration manifest with sample counts and rollback plan. Evidence: <code>config.json</code>, <code>config.hash</code>, <code>migration_manifest.json</code>, config audit row. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Calculation engine (REG_Calculations) — contracts</strong><br>Canonical pipeline: input normalization → validation → allocation & SafeRound → recognition schedule generation → journal mapping → artifact generation. Use deterministic ordering for aggregation and tie-breakers. SafeRound must document residual absorption rules and preserve summation parity. Unit tests MUST cover positive/negative/edge cases. Evidence: calculation logs, <code>calc_report.csv</code>, artifact checksums. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Job scheduling & isolated execution</strong><br>Large or IO-heavy actions MUST be scheduled via <code>CORE_JobScheduler</code>. Persist job descriptor <code>{jobId, params, configHash}</code> and emit <code>job.persisted:&lt;jobId&gt;</code>. Execution runs in isolated worker (or background runner) with redacted input snapshot and deterministic seeds. Evidence: job descriptor, worker logs, artifact checksums. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Remediation proposals & apply policy</strong><br>Proposals (when generated) must include: <code>proposalId</code>, rationale, affected count, confidence, before/after samples, and <code>applyPlan</code> (default <code>create_copy</code>). <code>create_copy</code> preserves original worksheet/workbook and writes fixed set to separate sheet/workbook. Inline apply requires auditable operator authorization and two-person approval for regulated outputs. Applying must append <code>reg_apply</code> audit row with <code>beforeChecksum</code> and <code>afterChecksum</code> and store reversible plan. Evidence: proposal JSON, apply logs, preserved original copy. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Exports & artifact integrity (REG_Export)</strong><br>All exports use atomic-write semantics: write to temp file then rename/move to final location. Compute <code>artifact.checksum.sha256</code> and embed checksum in export metadata and audit row. If network upload fails, fallback to staged local delivery. Export audit fields include <code>destination.uri</code>, <code>attempts</code>, and <code>final.status</code>. Evidence: exported file, checksum file, <code>REG_Export</code> logs. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Audit chain (REG_Audit) — canonical record</strong><br>Audit rows are append-only and cryptographically chained. Each row includes at minimum: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Chain verification runs in CI and monitoring. Audit buffers are allowed but MUST flush within configured interval. Evidence: <code>audit_tail.csv</code>, signed rotation archives. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Error taxonomy & operator messaging (REG_Error)</strong><br>Error codes map to stable messages and remediation hints. End-user messages show only the correlation id. Full diagnostic traces are stored in encrypted logs and linked to correlation id. High-severity errors auto-page on-call and generate an incident audit row. Evidence: <code>error.log</code>, mapping reference. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Security, PII & key management</strong><br>Classify any PII fields used for regulatory outputs and enforce redaction for human-readable exports. Encrypt export archives and audit rotations using KMS/HSM-backed envelope encryption. Key rotation and signing-key changes require multi-person approval and are recorded in audit. Evidence: key rotation logs, signed audit rotations. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>CI/CD gates, testing & golden parity</strong><br>PR → CI must run: lint, unit tests, rule regression tests, deterministic golden-file parity (byte-for-byte) for regulatory outputs, performance microbenchmarks, audit chain verification. Releases affecting regulated outputs require migration manifests and compliance approval. Evidence: CI reports, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Canary & phased rollout</strong><br>Deploy calculation/rule changes via cohorts: pilot tenants → pilot users → broader cohort. Gate with KPIs: false positive rate, acceptance rate, export checksum parity. Rollback automatically on KPI breaches. Record rollout transitions in <code>deployment.audit</code>. Evidence: release manifest, rollout audit rows, KPI snapshots. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Incident response (IR) playbook — regulated example</strong><br>Containment for suspected PII/audit compromise: set exports read-only, disable auto-apply flags, quarantine helper scripts, export rotated audits and logs to secure forensic share, preserve environment snapshots. Forensic manifest MUST include SHA256 checksums and chain-of-custody metadata. Notify Compliance/regulators per timelines. Evidence: forensic archive, <code>forensic_evidence_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Reconciliation & verification</strong><br>Reconciliation tooling compares generated regulatory outputs to source-of-record ledgers. Standard workflow: dry-run → review affected IDs & samples → operator sign-off → apply (create copy preferred) → re-run reconciliation → record <code>reconciliation.&lt;id&gt;</code> audit row. Evidence: <code>reconciliation_report.json</code>, before/after checksums, operator approvals. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Performance SLAs & monitoring</strong><br>Instrument metrics: calc duration, step latency, job throughput, audit flush time, memory usage. Example thresholds: calc WARN>30s for small schedules; CRIT>300s for large. Alerts auto-page on-call for CRIT breaches. Evidence: metrics dashboards, alert logs. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Operator commands & cheat-sheets</strong><br>Provide one-line canonical commands in UI/cheat-sheets: <code>regulatory profile --run-id &lt;id&gt;</code>, <code>regulatory calc --job &lt;id&gt; --dry-run</code>, <code>regulatory apply --proposal &lt;id&gt; --mode create_copy</code>, <code>regulatory export --artifact &lt;id&gt;</code>, <code>audit flush --correlation &lt;id&gt;</code>. Store operator one-page checklists under <code>runbooks/cheatsheets/</code>. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Change-control checklist (must do before production change)</strong><br>1) Open change ticket with rollback plan. 2) Run PR self-tests and attach results. 3) Include migration manifest if behavior changes. 4) Obtain two-person approval for automation or regulatory-affecting changes. 5) Sign artifacts and publish release manifest. 6) Canary rollout with KPI gating. 7) Post-rollout VerifyAuditChain and record results. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Retention, housekeeping & drills</strong><br>Retention policy example: hot=30d, warm=7y, cold=per regulation. Automate monthly retention verification; schedule annual forensic drills and quarterly tabletop exercises. Evidence: housekeeping.audit, drill reports. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Appendices & canonical artifacts location</strong><br>Include templates: audit CSV header, proposal JSON schema, recognition schedule format, migration manifest template, release manifest template, operator cheat-sheets. Store artifacts immutably with version tags, e.g., <code>runbook/v{major}.{minor}/appendices/</code>. Access controlled by RBAC; PRs required for edits. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Minimum artifact checklist per regulated run</strong><br>Collect: original input copy, config/hash, calculation report, reconciliation report, remediation proposals (if any), apply logs (if any), exported artifacts with checksums, audit rotation snapshot, migration manifest (if rules/config changed), signed release manifest. Bundle and store in secure archive; reference manifest in the audit. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Quick operator reference — condensed flow</strong><br>1) Save a copy. 2) Validate config & deps. 3) Run calculation in dry-run. 4) Inspect calc report & diffs. 5) Generate proposals (if any) and preview. 6) Apply with <code>create_copy</code> preferred. 7) Re-run reconciliation. 8) Export artifacts and verify checksum. 9) Append audit rows for each step and escalate if high-severity. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Final governance note</strong><br>Anything that materially changes regulatory outputs requires PR, migration manifest, deterministic tests, golden-file parity, and two-person approval. The audit chain is the legal record — preserve and sign it. </td></tr></tbody></table></div><div class="row-count">Rows: 29</div></div><div class="table-caption" id="Table4" data-table="Docu_0176_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — PQTools.xlam"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — PQTools.xlam</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing <strong>PQTools.xlam</strong>. It governs Power Query template management, injection, diagnostic capture, refresh orchestration, and audited export of <code>M</code> code and diagnostics. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation for regulated templates or outputs requires a written exception, migration manifest, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Primary audience & responsibilities</strong><br>Roles: Operator, Template Owner, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Operators run template injections and refreshes; Template Owners approve template changes; Developers create/maintain template tests; Release Engineers manage distribution and signing; Compliance reviews regulated templates and migrations. Each procedural section lists required evidence to be appended to the audit. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>High-level purpose & out-of-scope</strong><br>Purpose: provide auditable, reproducible management and injection of Power Query (<code>M</code>) templates into workbooks, with diagnostics and hermetic exports for review and regulatory traceability. Out-of-scope: hosting or editing external data sources outside approved connectors, secret/key management outside KMS/HSM, making irreversible changes to source systems without documented integration. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Core principles (non-negotiable)</strong><br>1) Determinism: template rendering and parameter resolution MUST be reproducible; <code>mChecksum</code> computed for all template artifacts.<br>2) Auditability: every injection/refresh/export appends an audit row with <code>correlationId</code>, <code>operatorId</code>, and <code>mChecksum</code>.<br>3) Reversibility: injection into workbook SHOULD be an explicit operator action; templates MAY be exported instead of injected. <br>4) Separation: preview & diagnostics precede injection. Two-person approval for regulated-template injection or AUTO_APPLY behavior. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Module map & single-responsibility contracts</strong><br><code>PQ_Ribbon</code> — UI handlers for library, inject, preview, refresh, export.<br><code>PQ_Config</code> — runtime config, template repo config, remote config resolution, <code>config.hash</code>.<br><code>PQ_EnsureDeps</code> — validate dependent connectors and PQ runtime versions; produce <code>deps.report.json</code>.<br><code>PQ_Utilities</code> — atomic-write, retry, deterministic RNG, <code>mChecksum</code> utilities.<br><code>PQ_Library</code> — template index, versions, owners, embedded hidden-sheet fallback.<br><code>PQ_Injector</code> — safe injection APIs: <code>Add_Query_From_M(name, formula)</code>, parameterization wrapper, connection creation options.<br><code>PQ_Diagnostics</code> — collect query diagnostics (load time, refresh path, error traces).<br><code>PQ_Export</code> — atomic export of <code>M</code> and diagnostics with checksum and metadata.<br><code>PQ_Audit</code> — append-only audit rows and rotation signing. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Runtime phases & audit markers</strong><br>Phases: bootstrap → config load → library access → UI idle → template preview → injection job persist → isolated injection/refresh → diagnostics capture → export → audit rotation. Example audit markers: <code>pq_library.access:&lt;version&gt;</code>, <code>pq_preview:&lt;id&gt;</code>, <code>pq_inject:job.&lt;jobId&gt;</code>, <code>pq_refresh:&lt;runId&gt;</code>, <code>pq_export:&lt;artifactId&gt;</code>. Preview steps MUST append <code>pq_preview</code> audit rows containing <code>mChecksum</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Template governance & lifecycle</strong><br>Templates carry stable IDs, semantic versions, owner, description, and <code>mChecksum</code>. Changes follow PR + automated testing + migration manifest for behavior changes. Templates used for regulated outputs require policy approval and migration artifacts (sample outputs, estimated affected counts). Evidence: template PRs, test results, <code>templates.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Library management (PQ_Library)</strong><br>Library sources: embedded hidden sheet (local fallback) OR canonical external repo (file-based preferred for auditability). <code>PQTools</code> SHOULD prefer external repo to enable review and signed artifacts. Library access emits <code>pq_library.access</code> with <code>templateVersion</code> and <code>mChecksum</code>. Template owners listed in <code>OWNERS.md</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Parameterization & preview flow</strong><br>Operator selects template → parameterize values → <code>Preview M</code> runs a dry-render and static checks (syntax + <code>mChecksum</code>). Preview outputs: <code>mPreview.json</code> and sample transformed rows (redacted). <code>pq_preview</code> audit row MUST include <code>operatorId</code>, <code>templateId</code>, and <code>mChecksum</code>. No workbook changes happen at preview. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Injection rules & safe defaults (PQ_Injector)</strong><br>Injection options: <code>connection-only</code>, <code>load-to-sheet</code>, <code>load-to-data-model</code>. Default behavior: do <strong>not</strong> overwrite existing queries unless <code>force=true</code> and operator confirms. Injection runs SHOULD be scheduled for heavy templates via <code>job.persist</code> and executed in isolated worker. When injecting, store previous query text and emit <code>pq_inject.backup:&lt;queryName&gt;</code> with <code>prevChecksum</code>. Evidence: injection job descriptor, before/after snapshots. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Refresh orchestration & diagnostics (PQ_Diagnostics)</strong><br><code>PQTools</code> collects provider diagnostics: step timings, rows loaded, errors, provider string (e.g., <code>Microsoft.Mashup.OleDb.1</code>). Refreshes MAY be run inline for small queries but MUST use job scheduler for long-running refreshes. Emit <code>pq_refresh</code> audit rows and <code>pq_diagnostics/&lt;run-id&gt;</code> artifact containing timings and error traces. Diagnostics artifacts are redacted for credentials. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>M checksum & artifact integrity</strong><br><code>mChecksum</code> computed (sha256) for all <code>M</code> templates, previews, and injected query formulas. All exports embed <code>artifact.checksum.sha256</code>. Compare <code>mChecksum</code> on load/preview/inject to detect drift and enforce immutability of signed templates. Evidence: <code>mChecksum</code> files, <code>pq_export</code> checksum metadata. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Exports & atomic semantics (PQ_Export)</strong><br>Exports write to temp files then rename to final destination. Export metadata includes <code>artifact.checksum.sha256</code>, <code>templateVersion</code>, and <code>attempts</code>. Network upload fallback: staged local delivery. Export audits: <code>pq_export</code> with <code>destination.uri</code> and <code>final.status</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Audit chain & signing (PQ_Audit)</strong><br>Each audit row minimally: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Audit rotations are signed and stored with release manifest key. VerifyAuditChain runs in CI periodically. Evidence: <code>audit_tail.csv</code>, signed archives. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Error taxonomy & operator messaging</strong><br>Errors map to stable codes and remediation hints. User-facing messages show correlation id only; full diagnostics stored in logs. High-severity errors auto-page on-call and add <code>pq_error</code> audit rows. Evidence: <code>error.log</code>, <code>pq_diagnostics</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Security & macro policy</strong><br>XLAM must be code-signed. Macro enable policy enforced by org policy; templates executed under workbook context must not request unapproved credentials. Secret management (tokens/keys) MUST use KMS/HSM-backed mechanisms and NOT be embedded in templates. Evidence: code-signing certificate, <code>pq_security.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>CI/CD gates & testing</strong><br>PR → CI: lint, unit tests for parameterization logic, template regression tests, golden parity for exported <code>M</code> artifacts, diagnostics capture tests. Template changes that affect regulated outputs require migration manifest and compliance approval. Evidence: CI reports, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Canary & phased rollout</strong><br>Deploy template updates via cohorts: template owners → pilot users → broader tenant groups. Gate with KPIs: injection success rate, preview acceptance rate, refresh latency, <code>mChecksum</code> parity. Rollback automatically on KPI threshold breaches. Record rollout transitions in <code>deployment.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Incident response (IR) — PQ-specific)</strong><br>Containment: disable template injections, set library repo read-only, export diagnostics and audit rotations to forensic share, collect <code>deps.report.json</code>, <code>pq_diagnostics</code> and <code>bootstrap.log</code>. Forensic manifest MUST include SHA256 for artifacts and chain-of-custody metadata. Evidence: forensic archive and <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Reconciliation & verification</strong><br>Reconcile injected query outputs with source-of-truth where feasible: dry-run transforms, sample diffs, operator sign-off, then inject. Produce <code>recon_report.json</code> and append <code>reconciliation.&lt;id&gt;</code> audit row. Evidence: recon reports, before/after checksums. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Retention, housekeeping & drills</strong><br>Retention example: templates/golden=immutable; diagnostics hot=30d; exports warm=7y; cold=per regulation. Schedule monthly housekeeping with audit rows. Perform quarterly drills for export/path rotation. Evidence: <code>housekeeping.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Operator commands & cheat-sheets</strong><br>Provide canonical commands: <code>pqtools preview --template &lt;id&gt; --params &lt;json&gt;</code>, <code>pqtools inject --template &lt;id&gt; --mode connection-only|load-sheet --force</code>, <code>pqtools refresh --query &lt;name&gt; --job</code>, <code>pqtools export --artifact &lt;id&gt;</code>, <code>pqtools diagnostics collect --run-id &lt;id&gt;</code>. Each command MUST append an audit row with <code>correlationId</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Minimum artifact checklist per regulated injection</strong><br>For any injection that feeds regulated outputs collect: saved workbook copy, <code>mChecksum</code>, preview artifacts, injection job descriptor, injection backup (previous queries), diagnostics, export artifact with checksum, audit rotation snapshot, migration manifest (if template changed), signed release manifest. Bundle and store in secure archive. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Quick operator flow — condensed</strong><br>1) Save workbook copy. 2) Preview template and check <code>mChecksum</code>. 3) Inspect preview & diagnostics. 4) Inject using <code>create_connection</code> or <code>load_to_sheet</code> (prefer connection-only where possible). 5) Run refresh in dry-run if heavy. 6) Export <code>M</code> + diagnostics with checksum. 7) Append audit rows for each step. 8) If regulated or high-risk, require two-person approval before injection. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Final governance note</strong><br>Template changes that materially affect downstream or regulated outputs require PR, deterministic tests, migration manifest, golden-file parity, and two-person approval. The audit chain is the legal record—preserve and sign it. </td></tr></tbody></table></div><div class="row-count">Rows: 25</div></div><div class="table-caption" id="Table5" data-table="Docu_0176_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Bootstrap — Per-Function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Bootstrap — Per-Function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Module summary (top-level)</strong><br><strong>Purpose:</strong> perform the minimal, safe initialization when the XLAM is loaded: open/initialize structured logging, establish a global correlation-id service, schedule deferred initialization on UI idle, register ordered shutdown handlers, and emit <code>bootstrap.started</code> audit anchor. The main path MUST be lightweight and non-blocking. Deferred heavy work occurs only via the deferred-init runner. <br><strong>Owner / Evidence:</strong> OWNER in <code>OWNERS.md</code>; evidence artefacts: <code>bootstrap.log</code> (JSONL), <code>audit_tail.csv</code> entries with <code>bootstrap.started</code>, <code>bootstrap.deferred.completed</code>, <code>bootstrap.degraded</code> as applicable. <br><strong>Non-goals / MUST NOT:</strong> no Excel Range/table access in bootstrap; no heavy disk IO; no network calls; no secrets loading; no long CPU work. <br><strong>Performance & budgets:</strong> main path target <250ms; deferred-init budget default 10s before degraded behaviour; flush and shutdown latencies monitored. <br><strong>CI requirements:</strong> static analysis forbids workbook API and network calls in main path; unit + integration tests for API; self-checks for CI gating. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_BootstrapInit</code> — Purpose, contract, invariants, and checks</strong><br><strong>Purpose & contract:</strong> executed at XLAM load (Auto_Open/Workbook_Open). Initialize in-memory log buffer, compute initial paths, create initial correlation id, emit <code>bootstrap.started</code> audit row, register safe shutdown handler(s), schedule deferred init. Must return quickly and not throw unhandled exceptions to the host. <br><strong>Parameters & returns:</strong> none; side effects only (state set, audit row buffered). <br><strong>Primary invariants (MUST / SHALL):</strong><br>1. No workbook Range or sheet access. <br>2. No synchronous heavy disk or network I/O. <br>3. Emit <code>bootstrap.started</code> (buffered) referencing <code>addInVersion</code>, <code>platform</code>, <code>excelVersion</code>. <br>4. Schedule deferred init idempotently. <br><strong>Observability & audit fields:</strong> <code>correlationId</code>, <code>addInVersion</code>, <code>platform</code>, <code>excelVersion</code>, <code>startTs</code>, <code>bootstrapSchemaVersion</code> if available. <br><strong>Failure modes & recovery:</strong> on internal failure enter <code>degraded</code> state; buffer <code>bootstrap.degraded</code> audit with failure code and minimal diagnostics; UI must show diagnostics-only ribbon. <br><strong>Security:</strong> do not load keys; only record signer fingerprint when validating binary later in deferred init. <br><strong>Tests:</strong> unit test that <code>bootstrap.started</code> is emitted; static analysis forbids forbidden APIs; smoke test that Auto_Open returns quickly. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>Auto_Open</code> / <code>Workbook_Open</code> — contract & host implications</strong><br><strong>Purpose & contract:</strong> host entry points that call <code>DQ_BootstrapInit</code> safely. Must catch all errors, not propagate exceptions to Office, and produce a short, deterministic audit anchor. <br><strong>Invariants:</strong> tolerant of host quirks; idempotent if called multiple times. <br><strong>Observability:</strong> emits low-severity debug audit on entry. <br><strong>Tests:</strong> simulate multiple host calls and verify no duplicate heavy actions; verify audit row present. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_NewCorrelationId(parentId)</code> — spec, format, and guarantees</strong><br><strong>Purpose & contract:</strong> provide globally-unique correlation ids for tracing runs and UI actions. Prefer a ULID-like format (timestamp + randomness) to support lexical sorting; produce monotonic ids if multiple generated in the same millisecond. Allow optional <code>parentId</code> to produce parent<code>|</code>child linkage for cross-process traces. <br><strong>Properties (MUST):</strong> cryptographically-resistant randomness, collision resistance across instances, deterministic monotonicity per instance. <br><strong>Observability:</strong> record first correlation id in <code>bootstrap.started</code>. <br><strong>Failure modes:</strong> fallback to GUID-like id when entropy unavailable; emit <code>bootstrap.cid.fallback</code> audit. <br><strong>Tests:</strong> property tests for uniqueness under load, monotonicity tests, lexical ordering verification. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_ScheduleDeferredInit(force)</code> — scheduling policy & idempotency</strong><br><strong>Purpose & contract:</strong> schedule deferred initialization to run only when Excel UI is idle (or shortly after startup) using <code>Application.OnTime</code> or host idle callback. Idempotent: multiple calls do not queue multiple runners unless forced. Should not block the UI thread. <br><strong>Parameters:</strong> optional <code>force</code> to reschedule. <br><strong>Invariants:</strong> never run heavy init synchronously on bootstrap main path; allow cancelation if shutdown occurs first. <br><strong>Observability:</strong> emit <code>bootstrap.deferred.scheduled</code> audit with <code>correlationId</code>. <br><strong>Edge cases:</strong> if host does not honor idle callbacks, fallback to low-priority timer with exponential backoff up to configured max attempts and emit <code>bootstrap.deferred.timeout</code> if not completed. <br><strong>Tests:</strong> schedule/reschedule semantics, forced reschedule test, simulated host missing idle callback scenario. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_DeferredInitRunner</code> — deferred initialization responsibilities</strong><br><strong>Purpose & contract:</strong> execute heavier, safe initialization tasks once UI is idle: load <code>DQ_Config</code> (validate JSON Schema v7), compute <code>config.hash</code>, apply idempotent migrations, run <code>DQ_EnsureDeps</code> producing <code>deps.report.json</code>, load <code>DQ_Utilities</code>, read module manifests & <code>OWNERS.md</code>, and load add-in assets (rules/templates). Must respect a soft time budget and be cancelable. <br><strong>Invariants (MUST):</strong><br>1. Defer only safe IO: read local files, validate signatures, compute hashes. <br>2. Avoid network calls unless explicitly allowed by config and recorded in audit. <br>3. If migration or config invalid, enter degraded mode and produce <code>bootstrap.degraded</code> audit with artifact paths. <br><strong>Audit obligations:</strong> emit <code>config.loaded:{configHash}</code>, <code>deps.checked</code>, <code>rules.loaded:version</code>. <br><strong>Failure & degraded mode:</strong> if critical dependencies fail mark degraded, restrict exports and destructive controls, and instruct operator on recovery steps in UI with correlation id. <br><strong>Tests & CI:</strong> validate config schema vectors, simulate invalid config and ensure degraded audit emitted. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_EmitBootstrapAudit(event, metadataJson)</code> — canonical bootstrap audit anchor</strong><br><strong>Purpose & contract:</strong> produce authoritative bootstrap-scoped audit rows (buffered, append-only). Minimal schema: <code>timestamp,correlationId,module=DQ_Bootstrap,procedure,severity,userId,payloadHash,prevHash,metadata</code>. Must buffer and write atomically, not block UI. <br><strong>Behavioral rules:</strong> redact PII before writing; compute <code>payloadHash</code> (SHA256) for metadata; chain with <code>prevHash</code> when resolvable. <br><strong>Flush policy:</strong> buffered writes with scheduled flush and explicit <code>RequestFlushLogsNow</code>. <br><strong>Failure modes & mitigation:</strong> on write error keep buffer, emit internal debug audit, escalate to operator if persist fails repeatedly. <br><strong>Tests:</strong> audit row schema conformance tests, chaining tests with mock prevHash, redaction tests. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_SafeBufferLogRow</code> / <code>DQ_SafeLog</code> / <code>DQ_ScheduleFlushIfNeeded</code> — buffering and non-blocking flush orchestration</strong><br><strong>Purpose & contract:</strong> keep a bounded in-memory ring buffer for log/audit rows to avoid blocking UI; schedule periodic flush to disk using host timer mechanism. Buffer max configured; oldest rows dropped when buffer full (log policy must record drops). <br><strong>Invariants:</strong> synchronous calls must return immediately; flush uses atomic temp-write → append pattern. <br><strong>Observability:</strong> metrics emitted: <code>bootstrap.log.buffer.size</code>, <code>bootstrap.flush.latency_ms</code>. <br><strong>Tests:</strong> buffer boundary tests, simulated flush failure retains buffer and logs errors, drop-policy verified. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_FlushLogs(forceSync)</code> — atomic write and recovery semantics</strong><br><strong>Purpose & contract:</strong> persist buffered audit rows reliably using atomic/temp-write then append/rotate; if <code>forceSync</code> true attempt blocking write and report status. Must not lose data silently. <br><strong>Atomicity & integrity:</strong> write to temp file, append to <code>audit_tail.csv</code>, delete temp; compute local fingerprint for rotation. <br><strong>Failure modes & recovery:</strong> on disk full or permission error, emit <code>bootstrap.log.open.error</code> and move to degraded mode; do not proceed to deferred init if core logging unavailable. <br><strong>Observability:</strong> emit <code>bootstrap.flush.success</code> or <code>bootstrap.flush.error</code> with error codes. <br><strong>Tests:</strong> simulate disk full, permission errors, verify buffer preserved and audits emitted. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RegisterShutdownHandler(id, priority, handlerName)</code> — registration semantics</strong><br><strong>Purpose & contract:</strong> allow modules to register cleanup handlers with a priority to run at unload. Handlers run in ascending priority order (low -> high). Registration must be idempotent and non-blocking. <br><strong>Invariants:</strong> handlers must be Public Subs with no params; registration recorded in memory only; persistence optional via <code>DQ_Export</code> if operator requests. <br><strong>Observability:</strong> emit <code>bootstrap.shutdown.handler.registered</code> audit. <br><strong>Tests:</strong> ordering tests, duplicate registration idempotency, failure in handler should be captured and logged without aborting subsequent handlers. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RunShutdownHandlers</code> / <code>Auto_Close</code> — graceful shutdown protocol</strong><br><strong>Purpose & contract:</strong> orchestrate ordered shutdown: mark <code>bootstrap.shutting_down</code>, run registered handlers, flush logs, rotate audit if configured, persist minimal ephemeral state (last correlation id/config hash), and close resources. Must be best-effort and resilient to handler failure. <br><strong>Failure modes & mitigation:</strong> if shutdown handler fails, log <code>bootstrap.shutdown.handler.error</code> and continue; if flush fails escalate to <code>bootstrap.shutdown.error</code>. <br><strong>Tests:</strong> simulate handler exceptions, verify final flush and rotation calls; verify idempotent runs if invoked multiple times. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_InitializeFilesystem</code> — minimal safe file preparation</strong><br><strong>Purpose & contract:</strong> create directories for audit/rotation if absent; must be minimal and non-blocking; used by deferred init and flush. Do not write large files at init time. <br><strong>Invariants:</strong> idempotent and permission-checked; if createFolder fails record <code>bootstrap.fs.init.error</code>. <br><strong>Tests:</strong> path creation under various permission scenarios. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_ComputePayloadHash</code> — integrity placeholder and production note</strong><br><strong>Purpose & contract:</strong> compute deterministic payload fingerprint for audit chaining. Production MUST use a proper SHA256 HSM/KMS-backed implementation. Current module may provide a deterministic stub for CI/golden tests but CI must enforce replacement in release. <br><strong>Audit requirement:</strong> <code>payloadHash</code> format documented; CI MUST block if stub present in release build. <br><strong>Tests:</strong> hash format tests, golden parity checks for payload. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_GenerateMonotonicUlid</code> / ULID generation notes</strong><br><strong>Purpose & contract:</strong> generate lexically-orderable ids combining timestamp+randomness. Guarantee monotonicity if multiple calls within same ms by incrementing low-order randomness. <br><strong>Security:</strong> use cryptographic RNG when available; fall back safely if unavailable and log fallback event. <br><strong>Tests:</strong> uniqueness under concurrency, lexical ordering tests, fallback path test. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RunBootstrapSelfChecks</code> — ten-point verification for CI & dev</strong><br><strong>Purpose & contract:</strong> provide a non-destructive self-test callable by CI to validate bootstrap invariants (audit emitted, no forbidden API usage in main path, deferred scheduling, correlation-id uniqueness under load, ability to schedule flush). Returns a structured dictionary of boolean checks and diagnostic notes. <br><strong>CI integration:</strong> executed in pre-merge gating; failures block merges. <br><strong>Tests:</strong> CI runs property tests (cid collisions), verifies no forbidden API patterns via static scan, validates audit row format. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_GetBootstrapState</code> & <code>DQ_RequestFlushLogsNow</code> — operator commands</strong><br><strong>Purpose & contract:</strong> <code>DQ_GetBootstrapState</code> returns minimal state for diagnostics (<code>status</code>, <code>startTs</code>, <code>lastCorrelationId</code>, <code>deferredScheduled</code>). <code>DQ_RequestFlushLogsNow</code> forces a best-effort flush and emits <code>bootstrap.flush.request</code>. Both must be non-blocking and append audit rows with operator id when invoked. <br><strong>Operator evidence:</strong> every operator invocation MUST append audit with <code>operatorId</code>, <code>correlationId</code>, and rationale. <br><strong>Tests:</strong> verify state shape, flush success on happy path, audit row presence. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Security & signing checks within deferred init</strong><br><strong>Purpose & contract:</strong> verify add-in binary signature fingerprint, validate manifest signatures for local manifests (ribbon manifest, rule manifests) and record signer fingerprint in audit; if signature invalid in production, fail to deferred-init and set degraded/disabled state for regulated controls. <br><strong>Invariants:</strong> do signature verification only in deferred init (not main bootstrap path) to avoid heavy crypto costs on UI thread. <br><strong>Tests:</strong> signature valid/invalid handlers, ensure invalid signature path disables regulated actions and emits <code>bootstrap.signature.invalid</code>. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Observability, telemetry, and metrics</strong><br><strong>Module metrics to emit locally (not on bootstrap main path):</strong> <code>bootstrap.duration_ms</code>, <code>deferredInit.duration_ms</code>, <code>bootstrap.success(bool)</code>, <code>deferredInit.success(bool)</code>, <code>bootstrap.flush.latency_ms</code>, <code>audit.buffer.size</code>. Telemetry aggregator uploads only by audited pipeline; do not perform remote telemetry from main bootstrap path. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Forbidden APIs & static enforcement</strong><br><strong>Disallowed operations in bootstrap/main path:</strong> workbook Range access, large synchronous disk writes, network calls, process spawning, reading secrets, and long CPU work. CI static analysis must fail PRs introducing forbidden API usage in this module. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Acceptance criteria & CI gates for DQ_Bootstrap changes</strong><br>1. <code>bootstrap.started</code> audit row emitted and matches schema. <br>2. Correlation id generator passes uniqueness and monotonic tests. <br>3. No forbidden API usages found by static analysis. <br>4. Deferred init scheduling validated on supported Excel versions via integration tests. <br>5. Shutdown handlers flush logs reliably in integration tests. <br>6. Self-check (<code>DQ_RunBootstrapSelfChecks</code>) passes in CI. <br>7. Production build contains real <code>DQ_ComputePayloadHash</code> (SHA256) and signature verification calls; CI blocks otherwise. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Evidence & forensic requirements on incidents</strong><br>On any significant bootstrap incident collect: <code>bootstrap.log</code> (JSONL), <code>audit_tail.csv</code> rows for affected correlation ids, <code>config.json</code> (or <code>config.hash</code>), <code>deps.report.json</code> if present, <code>lastCorrelationId</code>, platform metadata (Excel version/bitness/OS), and release manifest. Package into <code>forensic_manifest.json</code> and store in secure evidence repo with checksums. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Developer notes & common pitfalls</strong><br>— Avoid importing heavy modules in top-level module code; keep imports lazy and inside deferred init. <br>— Do not perform any file/path resolution that validates network shares in the main path. <br>— Keep all payloads small in bootstrap logs; redact paths or usernames that may contain PII. <br>— When adding new public APIs, preserve function names and signatures to avoid downstream breakage. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Examples (concise)</strong><br><strong>Normal startup:</strong> Excel loads → Auto_Open calls <code>DQ_BootstrapInit</code> → <code>bootstrap.started</code> buffered → <code>DQ_ScheduleDeferredInit</code> scheduled → UI returns quickly → deferred runner executes <code>DQ_Config</code> load and emits <code>config.loaded</code> → <code>bootstrap.deferred.completed</code> appended. <br><strong>Failure mode:</strong> invalid config encountered in deferred init → <code>bootstrap.degraded</code> emitted, ribbon shows diagnostics-only controls, exports disabled, operator instructed to run diagnostics and attach <code>forensic_manifest</code>. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Final checklist (developer / release)</strong><br>1. Static scan: no forbidden APIs in DQ_Bootstrap. <br>2. Unit tests: DQ_NewCorrelationId, buffer behavior, flush. <br>3. Integration: deferred runner runs without touching workbook. <br>4. CI gating: self-checks pass + audit chain verified on golden fixtures. <br>5. Release: artifact code-signed and signature fingerprint recorded by deferred init. </td></tr></tbody></table></div><div class="row-count">Rows: 24</div></div><div class="table-caption" id="Table6" data-table="Docu_0176_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_RibbonCallbacks — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>OnLoad(ribbonUI)</code> — Purpose, contract, parameters, invariants, VB/VSTO/PQ implications, observability, recovery, examples, and tests</strong><br><strong>Purpose & contract:</strong> invoked by Office when the add-in UI initializes. Responsibilities restricted to: cache <code>ribbonUI</code>; set minimal runtime defaults; allocate tiny in-memory structures; schedule deferred initialization (non-blocking); emit <code>ribbon.loaded</code> audit row with <code>correlationId</code>, <code>addInVersion</code>, <code>platform</code>, <code>excelVersion</code>, and <code>bootstrap.link</code> to tie bootstrap→ribbon traces. Must never do workbook range access, heavy disk IO, or network calls on the main path.<br><strong>Parameters & return:</strong> receives <code>ribbonUI</code> (opaque host handle); returns nothing; must not raise unhandled exceptions to host.<br><strong>Primary invariants (must/shall):</strong><br>1. Complete quickly on UI thread (target <50ms).<br>2. Never access workbook Ranges/Sheets or perform heavy IO/network on this path. <br>3. Schedule deferred work via <code>Application.OnTime</code> or host idle callbacks. <br>4. Emit <code>ribbon.loaded</code> or <code>ribbon.onload.error</code> with <code>correlationId</code> that links to <code>bootstrap.started</code> audit. <br><strong>VB/VSTO/PQ developer guidance:</strong><br>1. Cache <code>ribbonUI</code> module-level; avoid global constructors that trigger IO. <br>2. Use <code>Application.OnTime</code> to call <code>Deferred_LoadRibbonMap</code> one second later rather than inline parsing. <br>3. Use <code>On Error</code> to capture exceptions and convert to stable error codes. <br><strong>Power Query (PQ) considerations:</strong><br>1. Do not enumerate <code>Workbook.Queries</code> during <code>OnLoad</code>; defer to <code>Deferred_LoadRibbonMap</code>. <br>2. If the ribbon exposes PQ templates, only enable PQ-specific controls after template verification in deferred init. <br><strong>Observability & audit fields:</strong> include <code>correlationId</code>, <code>buildId</code>, <code>platform</code>, <code>excelVersion</code>, <code>ribbonMap.hash</code> (if present), and <code>startTs</code> in <code>ribbon.loaded</code> audit. <br><strong>Example narratives (multiple):</strong><br>1. Normal startup: Excel launches → <code>OnLoad</code> caches <code>ribbonUI</code>, schedules deferred load, emits <code>ribbon.loaded r-20260116-abc</code>, returns immediately. <br>2. Fault path: <code>OnLoad</code> fails to cache <code>ribbonUI</code> (host bug) → append <code>ribbon.onload.error</code> with <code>errorCode=RIB_ONLOAD_001</code> and present diagnostics ribbon with correlation id for triage. <br><strong>Operator recovery checklist:</strong><br>1. Check <code>audit_tail.csv</code> for <code>ribbon.loaded</code>/<code>ribbon.onload.error</code>. <br>2. If error present, run <code>ribbon.exportDiagnostics</code> and attach to incident. <br><strong>Tests & CI rules:</strong> static scan forbidding workbook API usage in <code>OnLoad</code>; unit test asserting <code>ribbon.loaded</code> audit emitted; smoke test verifying <code>OnLoad</code> returns quickly. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>LoadRibbonMap()</code> — manifest ingestion, canonicalization, JSON Schema, signature verification, PQ template discovery, owner resolution, fallback policy, examples, and tests</strong><br><strong>Purpose & contract:</strong> run in deferred init or explicit refresh; load manifest (<code>ribbon-map.json</code> or embedded <code>customUI</code>), validate JSON Schema, dedupe <code>controlId</code>s, attach owners from <code>OWNERS.md</code>, compute canonical <code>ribbonMap.hash</code> (SHA256 of canonicalized JSON), verify digital signature locally if present, and return <code>RibbonMap</code>. MUST NOT run during bootstrap main path. <br><strong>Deterministic validation steps:</strong><br>1. Parse input into canonical structure. <br>2. Validate against JSON Schema v7 and collect full error list. <br>3. Ensure unique <code>controlId</code>s; report duplicates with indices. <br>4. Validate <code>handler</code> existence and owner attribution. <br>5. Verify manifest signature locally (record fingerprint) — reject in prod if invalid. <br><strong>Power Query (PQ) specifics:</strong><br>1. If manifest references PQ templates, verify <code>mChecksum</code> and <code>templateVersion</code>; heavy template validation scheduled to worker. <br>2. Record <code>mChecksum</code> in audit for template provenance. <br><strong>Fallback policy & enforcement:</strong><br>1. Non-critical warnings → continue with reduced map, emit <code>ribbon.map.warning</code>. <br>2. Critical schema/signature errors → emit <code>ribbon.map.invalid</code>, disable regulated controls (fail-closed), and show diagnostics ribbon. <br><strong>Example narratives (multiple):</strong><br>1. Successful load: admin uploads manifest → <code>LoadRibbonMap</code> validates, computes <code>ribbonMap.hash=sha256:abcd...</code>, emits <code>ribbon.map.loaded</code> and the UI activates new controls. <br>2. Duplicate id: duplicate <code>controlId</code> found → <code>ribbon.map.invalid</code> appended with failure artifact, add-in loads diagnostics-only ribbon until manifest fixed. <br>3. PQ template mismatch: <code>mChecksum</code> doesn’t match embedded template → <code>ribbon.map.warning</code>, schedule worker to validate templates and block injection until resolved. <br><strong>Developer notes & safe I/O:</strong> prefer embedded manifests for offline reliability; when reading files, use read-then-verify-then-swap (atomic) pattern; do not perform network fetch during deferred init without local cache and audit. <br><strong>Tests / CI:</strong> schema validator vectors, golden manifest parity test, negative duplicate ID test, signature verification unit tests, PQ template checksum tests. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ValidateControlId(controlId)</code> — canonical guard, permitted patterns, metadata checks, PII policy, examples, and tests</strong><br><strong>Purpose & contract:</strong> single canonical validator for all incoming control events. Must be idempotent and side-effect free except on failure where an audit row is emitted. Returns canonical <code>controlMeta</code> or <code>{errorCode, userHint}</code>. <br><strong>Checks performed (deterministic):</strong><br>1. Format regex (allowed chars & length).<br>2. <code>RibbonMap</code> lookup (exists & mapping).<br>3. Enabled/visible state vs feature flags. <br>4. <code>requiresApproval</code>/<code>regulated</code>/<code>mayAffectPII</code> flags and owner info. <br>5. Tenant scoping and pilot cohort checks. <br><strong>PII & message policy:</strong> <code>userHint</code> must never contain PII; full logs stored encrypted. <br><strong>Examples (multiple):</strong><br>1. Valid control: <code>dq_profile.run</code> found → return controlMeta including <code>estimatedCost:light</code>. <br>2. Unknown control: return <code>{errorCode:RIB001, userHint:&quot;Unknown control; contact add-in owner&quot;}</code> and append <code>ribbon.control.validate</code> audit. <br>3. Disabled by flag: return denial with <code>userHint</code> instructing operator to request enable and include correlation id for audit. <br><strong>Tests:</strong> fuzz invalid ids, alias resolution, and ensure safe <code>userHint</code> content. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>MapControlToHandler(controlId)</code> — deterministic mapping, aliasing, versions, migration hints, examples, and tests</strong><br><strong>Purpose & contract:</strong> pure function resolving <code>controlId</code> → <code>{handlerName, handlerModule, estimatedCost, requiredApprovals, owner, version}</code>. Must be deterministic; mapping changes only via manifest updates which change <code>ribbonMap.hash</code>. <br><strong>Capabilities:</strong> alias resolution, redirect rules (control@vN → handlerVn), owner fallback, migration hint emission. <br><strong>Examples (multiple):</strong><br>1. Direct map: <code>dq_propose</code> → <code>HandleProposeV2</code>, <code>estimatedCost:heavy</code>. <br>2. Alias: <code>dq_old_propose</code> maps to <code>dq_propose</code> with <code>migrationHint:&quot;deprecated v1 -&gt; v2&quot;</code>. <br>3. Versioned redirect: <code>dq_apply@v2</code> returns handlerV2 and <code>version:&quot;2&quot;</code>. <br><strong>Tests:</strong> mapping parity across manifest versions, alias/resolution correctness, mapping stability across reloads. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HandleControlAction(controlId, context)</code> — secure dispatcher, audit anchoring, job scheduling, inline safety, UI contract, examples, and tests</strong><br><strong>Purpose & contract:</strong> authoritative dispatcher for ribbon callbacks. Must validate control, create <code>correlationId</code>, emit <code>UserAction</code> audit, decide inline vs scheduled execution, invoke handler safely or persist job descriptor, and return immediate UI-safe response. MUST NOT perform long-running work synchronously. <br><strong>Canonical orchestration (must/shall):</strong><br>1. <code>controlMeta = ValidateControlId(controlId)</code>. <br>2. <code>cid = NewCorrelationId(parent=uiSession)</code>. <br>3. <code>EmitUserActionAudit(cid, controlId, procedure=&quot;click&quot;, params)</code>. <br>4. <code>decision = IsLightweightAction(controlMeta)</code>. <br>5a. If lightweight → <code>SafeInvokeHandler(handlerName,args,cid)</code>. <br>5b. Else → persist <code>jobDescriptor</code> via <code>JobSchedulerIntegration</code>, emit <code>job.persisted:&lt;jobId&gt;</code>. <br>6. Return <code>{status, message, correlationId}</code> synchronously (message short & safe). <br><strong>UI contract:</strong> short message containing correlation id and next steps, e.g., "Profile scheduled — ref r-20260116-abc". <br><strong>Examples (multiple):</strong><br>1. Small table profile (inline): validate → audit → invoke <code>SafeInvokeHandler</code> → receive preview artifact → append <code>module.step</code> audits → UI displays result. <br>2. Large table profile (scheduled): validate → audit → create <code>job-901</code> → <code>job.persisted</code> emitted → UI shows scheduled message. <br>3. Permission denied: <code>ValidateControlId</code> denies → return <code>SafeErrorToUser</code> hint and append <code>ribbon.permission.denied</code>. <br><strong>Failure handling:</strong> bounded retry for job persist, fail-closed on destructive controls if manifest invalid, clear audit traces for triage. <br><strong>Tests:</strong> concurrency (100s of clicks), immediate return, audit chain presence, job dedupe/idempotency. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>IsLightweightAction(controlMeta)</code> — policy evaluation, thresholds, explainability, examples, and tests</strong><br><strong>Purpose & contract:</strong> determine inline vs scheduled execution. Inputs: <code>controlMeta</code>, <code>modConfig.thresholds</code> (rowCount/sampleSize), runtime <code>mode</code> (degraded/safe), operator overrides. Return <code>{lightweight:Boolean, rationale:String}</code>. Decisions must be auditable. <br><strong>Policy examples:</strong><br>1. <code>profile</code>: lightweight if <code>rowCount &lt; profile.sampleThreshold &amp;&amp; sampleSize &lt; sampleLimit</code>. <br>2. <code>apply</code>: default heavy if dataset regulated or <code>requiresApproval=true</code>. <br><strong>Examples (multiple):</strong><br>1. 8k-row table for <code>profile</code> → <code>{true,&quot;rows&lt;10k&quot;}</code>. <br>2. 200k-row table → <code>{false,&quot;rows&gt;threshold - scheduled for safety&quot;}</code>. <br><strong>Governance:</strong> config-driven; changes require PR + audit row <code>config.change</code>. <br><strong>Tests:</strong> boundary tests and safe-mode enforced scheduling. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeInvokeHandler(handlerName, args, correlationId)</code> — execution frame, time budgets, cancellation, error mapping, redaction, PQ and VBA patterns, telemetry, examples, and tests</strong><br><strong>Purpose & contract:</strong> execute handler inside a protective frame: validate registration; create invocation trace; set cooperative timeout & cancellation token; append start/complete step-level audits with <code>payloadHash</code>; catch exceptions and map to stable <code>ErrorCodeCatalog</code>; redact PII from logs; return structured result only. <br><strong>Execution invariants:</strong><br>1. Inline handlers must not perform blocking heavy disk/network IO. <br>2. Handler must support cancellation token checks. <br>3. Exceptions mapped to stable codes and audited; only safe hints shown to user. <br><strong>VBA & PQ developer patterns:</strong><br>1. VBA handlers accept <code>ByRef cancelToken As Boolean</code> and check inside loops. <br>2. PQ template handlers validate <code>mChecksum</code> before invoking heavy transforms; heavy transforms run in worker. <br><strong>Telemetry & auditing:</strong> emit <code>ribbon.handler.duration_ms</code>, <code>ribbon.handler.success</code>, <code>ribbon.handler.error</code> with correlation id and controlId. <br><strong>Examples (multiple):</strong><br>1. <code>HandlePreview</code> runs quickly → <code>step.start</code> audit → handler returns previewRef → <code>step.complete</code> with <code>payloadHash</code> → UI shows preview. <br>2. Handler throws on malformed data → <code>ribbon.handler.exception</code> appended with mapped <code>ERR_PREVIEW_500</code>; UI shows "Preview failed (ref r-xxx)". <br>3. Long-running loop triggers watchdog → emits <code>ribbon.handler.timeout</code>, token cancelled, handler terminates gracefully and audit records partial results. <br><strong>Tests:</strong> exception injection, cancellation, telemetry emission, step audit presence, PQ checksum validation. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>EmitUserActionAudit(correlationId, controlId, procedure, params)</code> — canonical audit anchor, redaction, evidence linking, schema, examples, and tests</strong><br><strong>Purpose & contract:</strong> produce authoritative <code>UserAction</code> audit row that anchors UI flow. Must redact sensitive params, compute <code>paramsHash</code>, and append to <code>DQ_Audit</code> buffer non-blocking. Include <code>configHash</code> and <code>ribbonMap.hash</code> for reproducibility. <br><strong>Schema (required fields):</strong> <code>timestamp,correlationId,module=DQ_RibbonCallbacks,procedure,userId,controlId,paramsHash,configHash,ribbonMapHash,prevHash,metadata</code>. <br><strong>PII & evidence policy:</strong> main audit only stores <code>paramsHash</code>; full sanitized params placed in encrypted evidence store (with approval) and referenced by <code>evidenceRef</code> in metadata. <br><strong>Examples (multiple):</strong><br>1. <code>Profile</code> click: <code>params</code> include <code>{table:&quot;tblContacts&quot;, sample:5000}</code> → <code>paramsHash</code> stored; full sanitized <code>params</code> saved to evidence with <code>evidenceRef</code> for compliance. <br>2. <code>Apply inline</code>: <code>params</code> include <code>operatorId</code> and <code>approvalIds</code>; <code>paramsHash</code> recorded and approval artifacts referenced. <br><strong>Tests:</strong> audit schema validation, redaction verification, prevHash chaining via <code>VerifyAuditChain</code>. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RegisterCallback(controlId, handlerName, metadata)</code> — controlled registration, signature checks, idempotency, persistence, examples, and tests</strong><br><strong>Purpose & contract:</strong> register/update control→handler mapping at install-time or runtime. Must validate handler signature (where applicable), ensure owner metadata, reject destructive handlers without explicit approvals, and be idempotent. Persist only via atomic-write via <code>modExport</code> if requested. Production dynamic registration requires signed manifests + approvals. <br><strong>Examples (multiple):</strong><br>1. Installer registers <code>dq_phone_norm</code> → validation passes → <code>ribbon.callback.registered</code> audit appended and optionally persisted. <br>2. Unauthorized registration attempt rejected and <code>ribbon.callback.register.failed</code> with <code>RIB_REG_403</code> appended. <br><strong>Tests:</strong> duplicate registration detection, unauthorized registration rejection, manifest persistence correctness. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RefreshRibbon()</code> — live rebind, diffs, invalidation, operator UX, examples, and tests</strong><br><strong>Purpose & contract:</strong> reload <code>RibbonMap</code> and refresh UI without a restart. Must run <code>LoadRibbonMap</code> deferred, compute diff (added/removed/changed controls), call <code>ribbonUI.Invalidate()</code>/<code>InvalidateControl()</code> for affected controls, and append <code>ribbon.refresh.completed</code> with <code>duration_ms</code> and <code>ribbonMap.hash</code>. Must not interrupt running jobs. <br><strong>Examples (multiple):</strong><br>1. Manifest updated, operator clicks "Refresh" → map reloaded, invalidated controls re-query <code>getEnabled</code>, new controls appear, <code>ribbon.refresh.completed</code> appended. <br>2. Refresh finds schema error in new manifest → <code>ribbon.refresh.error</code>, UI stays with previous stable map. <br><strong>Tests:</strong> ensure running jobs continue unaffected, invalidation calls issued for changed controls. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>EnableControl</code> / <code>DisableControl</code> — runtime toggles, RBAC enforcement, kill-switch use-cases, examples, and tests</strong><br><strong>Purpose & contract:</strong> provide runtime enable/disable toggles for controls with RBAC checks. Must update only in-memory state (and optionally persist via manifest with audit), call <code>ribbonUI.InvalidateControl(controlId)</code>, and append <code>ribbon.control.enabled/disabled</code> audit rows with <code>operatorId</code> and reason. <br><strong>Use-cases:</strong> emergency kill-switch, staged feature rollouts, tenant pilot toggles. <br><strong>Examples (multiple):</strong><br>1. During incident, SRE calls <code>DisableControl(&quot;dq_export&quot;)</code>; function verifies permission, disables, invalidates, and logs <code>ribbon.control.disabled</code>. <br>2. Release engineer enables <code>dq_new_preview</code> for pilot tenants; <code>EnableControl</code> validates pilot scope and invalidates control. <br><strong>Tests:</strong> RBAC enforcement, UI state change propagation, audit presence. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ValidateUserPermissions(userId, controlMeta)</code> — RBAC, approvals, dataset-level checks, examples, and tests</strong><br><strong>Purpose & contract:</strong> evaluate whether <code>userId</code> may invoke control: check roles, delegated approvals, two-person requirements for regulated actions, and dataset-level regulation flags. Return <code>{allowed, requiredApprovals[], denialReason}</code>. <br><strong>Checks performed:</strong> SSO identity mapping, group membership, time-limited approvals, dataset PII/regulation detection, <code>AUTO_APPLY</code> guard rails. <br><strong>Examples (multiple):</strong><br>1. Junior operator attempts inline apply on regulated dataset → returns <code>allowed:false</code> and <code>requiredApprovals=[manager,compliance]</code>. <br>2. Senior user with emergency privilege allowed to run <code>diagnostics-only</code> workflows; returns <code>allowed:true</code> with <code>specialNote</code>. <br><strong>Audit:</strong> <code>ribbon.permission.check</code> and approval grants <code>ribbon.approval.granted</code>. <br><strong>Tests:</strong> role matrix simulation and approval workflow tests. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>BuildUiParamsHash(params)</code> — canonicalization rules, redaction patterns, PQ template handling, examples, and tests</strong><br><strong>Purpose & contract:</strong> canonicalize UI parameters into deterministic hash while redacting PII. Steps: sort keys, normalize dates/numbers, apply redaction regex (emails, SSN, cards), remove empty values, produce canonical JSON, compute SHA256. Store only <code>paramsHash</code> in main audit; sanitized params may be stored encrypted with <code>evidenceRef</code>. <br><strong>PQ specifics:</strong> strip credentials from PQ <code>connectionString</code> and record <code>mChecksum</code> in evidence. <br><strong>Examples (multiple):</strong><br>1. PQ injection: sanitized params stored with <code>evidenceRef</code>; audit holds <code>paramsHash</code>. <br>2. Filter params with user-entered email redacted to <code>&lt;REDACTED&gt;</code> in sanitized evidence. <br><strong>Tests:</strong> deterministic hashing across key permutations and locales; redaction coverage tests. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>DiagnosticsToggle(enableVerbose, operatorId, ticketId)</code> — admin lifecycle, TTL, audit, and constraints</strong><br><strong>Purpose & contract:</strong> enable verbose ribbon diagnostics for a bounded TTL, requiring MFA and ticket id. Must append <code>debug.audit</code> with operator and justification, set TTL for auto-disable, and ensure logs redact secrets. Auto-disable must be auditable (<code>debug.audit.disabled</code>). <br><strong>Examples (multiple):</strong><br>1. SRE enables 30m diagnostics for ticket #42; module captures handler traces and <code>diagnostics.zip</code> is produced on demand; TTL auto-disables and audit logs both enable and disable. <br><strong>Tests:</strong> TTL auto-disable, audit lifecycle presence, confirm no PII in verbose logs. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ExportRibbonMap(destinationUri, operatorId)</code> — secure export, redaction, checksums, and chain-of-custody</strong><br><strong>Purpose & contract:</strong> export <code>ribbon-map.json</code> + <code>OWNERS.md</code> snapshot with redaction where operator lacks rights, using <code>modExport</code> atomic write path. Compute <code>artifact.checksum.sha256</code>; append <code>ribbon.map.export</code> audit with URI and checksum. <br><strong>Examples (multiple):</strong><br>1. Compliance exports manifest to secure repo; returned artifact URI and checksum saved to <code>ribbon.map.export</code>. <br>2. If operator lacks permission for private owner emails, export redacts them and records redaction in metadata. <br><strong>Tests:</strong> checksum validation and redaction verification. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName)</code> — CI deterministic harness, golden runs, and safeguards</strong><br><strong>Purpose & contract:</strong> support CI by enabling simulated control events without Excel UI. Hooks flagged <code>test=true</code> in audits must accept fixed <code>correlationId</code> for golden parity. Hooks MUST be disabled in production unless explicitly allowed. <br><strong>Examples (multiple):</strong><br>1. CI registers <code>hook_profile_golden</code> with <code>cid=r-test-001</code> and validates profile artifact against golden checksum. <br>2. Test hook attempts destructive action in protected environment and is rejected. <br><strong>Tests:</strong> golden parity and isolation from production. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeHandlerTimeoutWatchdog(handlerToken, correlationId)</code> — cooperative cancellation, escalating audits, and examples</strong><br><strong>Purpose & contract:</strong> monitor handler execution time; on overrun emit <code>ribbon.handler.timeout</code>, attempt cooperative cancellation via token, and if unsuccessful append <code>ribbon.handler.hung</code> with stack capture for SRE. Use <code>Application.OnTime</code> or host idle scheduling for timers in VBA. <br><strong>Examples (multiple):</strong><br>1. Handler runs >5s; watchdog cancels token and logs timeout; UI shows timed-out message with correlation id. <br>2. Cancellation fails; <code>ribbon.handler.hung</code> appended with stack snapshot for off-line analysis. <br><strong>Tests:</strong> forced overrun path, cancellation effect, audit presence. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>TelemetryEmit(metricName, value, tags)</code> — local buffering, audited uplink, and example metrics</strong><br><strong>Purpose & contract:</strong> collect local metrics (no remote calls from ribbon path). Append to metrics buffer; audited uploader (separate module) performs remote export. Typical metrics: <code>ribbon.click.latency_ms</code>, <code>ribbon.handler.duration_ms</code>, <code>ribbon.handler.timeout_rate</code>. <br><strong>Examples:</strong><br>1. Each <code>HandleControlAction</code> emits <code>ribbon.click.latency_ms=12</code> with <code>{controlId:&quot;dq_profile&quot;}</code> tag. <br>2. Surge in <code>ribbon.handler.timeout_rate</code> triggers SRE runbook. <br><strong>Tests:</strong> buffer durability and uploader compatibility. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(correlationId, errorCode)</code> — UI-safe mapping, triage hint, and examples</strong><br><strong>Purpose & contract:</strong> map internal error codes to concise UI messages including <code>correlationId</code>, while storing full diagnostic traces encrypted. Append <code>ribbon.userErrorShown</code> audit. Messages must never contain PII or inner stack traces. <br><strong>Examples:</strong><br>1. <code>ERR_DB_CONN</code> → UI: "Temporary error (ref r-20260116-abc). Retry or contact support." Full stack saved encrypted. <br>2. <code>RIB_PERMISSION_DENIED</code> → UI: "Action requires approval (ref r-...). Request approval." <br><strong>Tests:</strong> ensure UI strings are PII-free and audits present. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HotSwapHandlers(newMapJson, operatorId, approvals)</code> — transactional emergency patching, dry-run, smoke tests, persistence, rollback, and examples</strong><br><strong>Purpose & contract:</strong> apply transactional runtime mapping updates for urgent fixes with signed manifests and required approvals for regulated controls. Steps:<br>1. Validate manifest & signature. <br>2. Compute diff & produce <code>hotSwap.preview</code> with impacted controls and risk estimate. <br>3. Apply in-memory atomically and run smoke tests via unit hooks. <br>4. If smoke tests pass persist via <code>modExport</code> and append <code>ribbon.hotswap.applied</code> with <code>beforeHash</code>/<code>afterHash</code> and release fingerprint. <br>5. If tests fail revert and append <code>ribbon.hotswap.reverted</code>. <br><strong>Examples:</strong><br>1. Critical <code>HandleApply</code> bug fixed with hot-swap; smoke tests pass; <code>hotswap.applied</code> recorded. <br>2. Hot-swap fails smoke test; revert and produce <code>hotswap.reverted</code> audit and rollback manifest. <br><strong>Tests:</strong> dry-run validations, smoke test coverage, rollback correctness. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Shutdown()</code> — graceful ribbon unload, audit flush ordering, and state snapshot</strong><br><strong>Purpose & contract:</strong> perform ribbon shutdown tasks at add-in unload: flush ribbon logs, persist minimal snapshot (<code>lastRefreshTs</code>, <code>lastCorrelationId</code>), unregister test hooks, and append <code>ribbon.shutdown</code> audit row. Must register with <code>DQ_Bootstrap</code> shutdown handlers at appropriate priority to allow <code>DQ_Audit</code> flushes first. <br><strong>Examples:</strong><br>1. Normal exit: <code>Shutdown</code> flushes buffers and writes <code>ribbon.shutdown</code>. <br>2. Crash path: OS terminates Excel; after restart, <code>OnLoad</code> detects unclean exit and emits <code>ribbon.recovery</code> audit for operator. <br><strong>Tests:</strong> ensure buffer flush occurred and snapshot is present. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>JobSchedulerIntegration(jobDescriptor)</code> — canonical job descriptor schema, atomic persistence, idempotency, worker handoff, examples, and tests</strong><br><strong>Purpose & contract:</strong> construct canonical job descriptor for heavy actions and persist atomically for worker consumption. Descriptor fields: <code>jobId, controlId, correlationId, paramsHash, configHash, persistedAt, owner</code>. Persist via <code>modExport</code> atomic write; emit <code>job.persisted:&lt;jobId&gt;</code> audit. Must support idempotent persistence for requeue semantics. <br><strong>Examples:</strong><br>1. Heavy <code>profile</code> writes <code>job-222.json</code> with <code>paramsHash</code>, <code>job.persisted:job-222</code> emitted; worker consumes and appends <code>dq_profile</code> audit. <br>2. Duplicate persist call with same <code>jobId</code> returns existing descriptor (idempotent). <br><strong>Tests:</strong> persistence idempotency, retry/backoff simulation, job dedupe semantics. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Audit obligations (module-level summary &amp; enforcement)</code> — chain rules, schema, signing, CI checks, examples</strong><br><strong>Mandate:</strong> every user-initiated action MUST append a <code>UserAction</code> audit row with <code>correlationId</code>. Artifact-producing handlers append step-level audits: <code>module.step:&lt;step&gt;</code>, <code>job.persisted</code>, <code>dq_proposal</code>, <code>dq_apply</code>, <code>dq_export</code>. Each audit includes <code>payloadHash</code>, <code>prevHash</code> (when resolvable), <code>configHash</code>, and <code>ribbonMap.hash</code>. <code>DQ_Audit</code> rotates and signs rotations per retention policy; <code>VerifyAuditChain</code> runs in CI/monitoring to detect mismatches. <br><strong>Example audit chain:</strong> <code>UserAction</code> → <code>dq_profile</code> → <code>dq_proposal</code> → <code>dq_apply</code> → <code>dq_export</code>. <br><strong>CI enforcement:</strong> <code>audit-chain-verify</code> validates chain for golden runs prior to merge. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Security &amp; secrets policy (ribbon)</code> — enforced rules, KMS/HSM usage, signing, and examples</strong><br><strong>Principles:</strong> ribbon core must never handle raw secrets directly. Credentials must be obtained via KMS/HSM through audited APIs during deferred init. Manifests and add-in binaries must be code-signed; <code>LoadRibbonMap</code> verifies signature locally. Logs must be redaction-aware; PII redaction enforced before persistence. <br><strong>Examples:</strong><br>1. Handler requests DB token via <code>modSecurity.getEphemeralToken()</code>; ribbon records token fingerprint only. <br>2. Unsigned manifest attempted in prod → reject and <code>ribbon.map.invalid</code> logged. <br><strong>Tests:</strong> static analyzer for direct secret reads, signature verification tests, key rotation simulation. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Performance budgets &amp; SLOs (ribbon)</code> — targets, metrics, runbook, examples</strong><br><strong>Targets:</strong><br>1. Click handling median <50ms. <br>2. Job persist latency <2s. <br>3. Inline handler default timeout 5s (configurable). <br><strong>Metrics:</strong> <code>ribbon.click.latency_ms</code>, <code>ribbon.handler.duration_ms</code>, <code>ribbon.handler.timeout_rate</code>, <code>job.persist.latency_ms</code>. <br><strong>Remediation:</strong> throttle, offload to jobs, or enable degraded mode. <br><strong>Example:</strong> surge in <code>ribbon.click.latency_ms</code> triggers SRE runbook: collect diagnostics, throttle UI, scale worker pool, and revert recent manifest changes if correlated. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Testing matrix (ribbon)</code> — required tests, golden governance, CI gating, and examples</strong><br><strong>Required tests:</strong><br>1. Unit: <code>ValidateControlId</code>, <code>MapControlToHandler</code>, <code>BuildUiParamsHash</code>. <br>2. Integration: click→audit→job persist→worker simulation. <br>3. Golden: manifest parity & <code>UserAction</code> audit hash. <br>4. Property: correlation id uniqueness under load. <br><strong>CI gating:</strong> block merges on golden/audit-chain failure or static forbidden-API detection. <br><strong>Example CI pipeline:</strong> <code>ribbon_unit</code>, <code>ribbon_integration</code>, <code>ribbon_golden</code>, <code>audit_chain_verify</code>. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Failure modes &amp; mitigations (ribbon)</code> — canonical incidents, runbooks, and forensic evidence</strong><br><strong>Common cases & mitigations:</strong><br>1. Unknown control → <code>ribbon.control.validate</code> audit; operator updates manifest. <br>2. Permission denied → <code>ribbon.permission.denied</code>; approval workflow required. <br>3. Handler exception → <code>ribbon.handler.exception</code> with mapped code; SRE obtains encrypted logs by correlation id. <br>4. Handler timeout → watchdog cancels and emits <code>ribbon.handler.timeout</code>; schedule job if needed. <br>5. Job persist failure → retry/backoff; on repeated failures open incident and collect <code>forensic_manifest</code>. <br><strong>Evidence to collect:</strong> <code>ribbon-map.json</code>, <code>audit_tail.csv</code>, handler logs, job descriptors, <code>modConfig</code> snapshot, release manifest. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Operator UX &amp; triage notes</code> — practical steps, examples, and commands</strong><br><strong>Best practice:</strong> always show correlation id and provide "copy diagnostics" action. <br><strong>Triage flow:</strong><br>1. Obtain correlation id from user. <br>2. Retrieve <code>UserAction</code> audit row and step-level audits. <br>3. Pull artifacts referenced (profile report, proposal). <br>4. If incident, collect <code>forensic_manifest</code> and escalate per IR runbook. <br><strong>Example scenario:</strong> support ticket "Propose failed (ref r-20260116-abc)" → SRE retrieves audit chain, replays fault in isolated runner, files bug, and attaches <code>forensic_manifest</code>. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Change-control &amp; governance (ribbon)</code> — required steps, approvals, migration manifest, and examples</strong><br><strong>Required flow for changes:</strong><br>1. Create PR + migration manifest if behavior semantics change. <br>2. Run static analysis, unit/integration/golden tests. <br>3. Obtain code-review and compliance signoffs for regulated changes. <br>4. Sign artifacts and publish release manifest. <br>5. Canary rollout with KPI gating & rollback plan. <br>6. Post-rollout <code>VerifyAuditChain</code> and <code>deployment.audit</code>. <br><strong>Example artifact:</strong> <code>migration_manifest.json</code> documents transforms, sample sizes, backout plan, and approvals. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Evidence to collect for ribbon incidents</code> — canonical forensic package & storage</strong><br><strong>Minimum artifacts:</strong><br>1. Current + prior <code>ribbon-map.json</code> and signatures. <br>2. <code>audit_tail.csv</code> rows covering correlation ids. <br>3. Handler logs from <code>DQ_RibbonCallbacks</code>. <br>4. Persisted job descriptors. <br>5. <code>modConfig</code> snapshot and <code>config.hash</code>. <br>6. Release manifest and artifact signatures. <br>7. <code>forensic_manifest.json</code> with sha256 checksums and storage URI. <br><strong>Storage:</strong> secure evidence repo with RBAC and chain-of-custody records. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Acceptance criteria (dev/CI)</code> — gating checklist & enforcement</strong><br><strong>Gates:</strong><br>1. Unit + integration + golden tests pass. <br>2. No forbidden API references in static analysis. <br>3. <code>ribbon.map</code> schema validated and <code>ribbonMap.hash</code> produced. <br>4. <code>UserAction</code> audits emitted and <code>VerifyAuditChain</code> passes. <br>5. Correlation id uniqueness tests pass. <br>6. Performance budgets met under CI load. <br><strong>Blocking conditions:</strong> golden/audit-chain failures or forbidden API detections. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Forbidden APIs / static enforcement</code> — explicit banned list, rationale, and CI actions</strong><br><strong>Disallowed in ribbon core and inline handlers:</strong><br>1. Direct Workbook/Range mutation in <code>OnLoad</code> or ribbon core. <br>2. Raw network sockets (WinHTTP) or external web calls during bootstrap/ribbon main path. <br>3. Unbounded synchronous disk writes that block UI (>10ms). <br>4. Direct secret reads from plaintext files. <br>5. Spawning external processes. <br><strong>Enforcement:</strong> CI static analyzer rejects PRs referencing blacklisted APIs and emits <code>forbidden-api</code> failures. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Appendices &amp; references</code> — canonical schemas, templates, runbooks, and storage paths</strong><br><strong>Include:</strong> ribbon manifest JSON Schema, audit row schema, <code>ErrorCodeCatalog.md</code>, migration manifest template, forensic manifest template, operator cheat-sheets, PQ template guidelines, unit test harness docs, CI golden-file guide, release manifest signing checklist, and <code>OWNERS.md</code> mapping. <br><strong>Storage & governance:</strong> immutable artifact store <code>\\artifacts\runbooks\DQ_RibbonCallbacks\v{major}.{minor}\appendices\</code> with RBAC. <br><strong>Example artifacts:</strong> <code>appendices/templates/migration_manifest.json</code>, <code>runbooks/cheatsheets/ribbon-smoke-test.md</code>. </td></tr></tbody></table></div><div class="row-count">Rows: 33</div></div><div class="table-caption" id="Table7" data-table="Docu_0176_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Config — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Config — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Executive summary (single-paragraph):</strong> <code>DQ_Config</code> is the authoritative configuration subsystem for the add-in ecosystem. It must provide deterministic loading, schema validation, canonical hashing, idempotent migrations, safe tenant-scoped overrides, audited change-control, atomic persistence, safe hot-reload semantics, RBAC/approval enforcement for regulated keys, and secure export/import for compliance. <code>DQ_Config</code> publishes a minimal, immutable runtime view (<code>ResolvedConfig</code>) and a controlled mutator surface (Set/Import/Persist/Rollback) which always produce auditable rows. Design priorities: determinism, auditability, safety (no secrets in plain text), non-blocking behavior for UI-idle initialization, and clear failure modes with operator recovery steps. {audit: config.loaded / config.changed / config.invalid} <<MUST NOT: heavy IO or workbook Range access on init>>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Module responsibilities & invariants</strong><br>1. Single source of truth for runtime behavior: thresholds, sampling, feature flags, tenant overrides, migration manifests, schema versioning, and operator approval metadata.<br>2. Deterministic canonicalization and hashing: identical logical config must produce identical <code>config.hash</code> across locales and process restarts.<br>3. Idempotent migrations: migrations must be pure, safe under repeated application, and reversible where possible.<br>4. Audited mutation: every change produces an append-only audit row with <code>beforeHash</code> and <code>afterHash</code>; full snapshots are stored only in encrypted evidence stores and referenced by <code>evidenceRef</code> in audits.<br>5. RBAC & approval enforcement: protected keys (e.g., <code>featureFlags.autoApply</code>, <code>migration.*</code>, <code>exportKeys</code>) require recorded approvals and must be refused otherwise.<br>6. Safe persistence: atomic-write semantics with checksum verification and durable commit guarantees; on failure, prior artifact remains intact.<br>7. Non-blocking deferred init: <code>LoadConfig</code> must be suitable for UI-idle deferred execution and must not perform synchronous heavy network/disk IO on the host UI thread.<br>8. Observable: instrumented metrics for load/persist durations, migration duration, reloads, and validation errors. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>API surface (summary):</strong><br><code>LoadConfig(pathOrBlob)</code> → <code>{config, configHash, migrationsApplied, validationErrors}</code><br><code>ValidateConfigSchema(config)</code> → <code>{valid, errors[]}</code><br><code>ComputeConfigHash(configCanonical)</code> → <code>sha256:&lt;hex&gt;</code><br><code>ApplyMigrations(config, migrationsRegistry)</code> → <code>{config, applied[], warnings[]}</code><br><code>MergeTenantOverrides(base, overrides, policy)</code> → <code>{resolvedConfig, diff}</code><br><code>GetConfigValue(path, default)</code> → <code>value</code> (immutable copy)<br><code>SetConfigValue(path, value, opts)</code> → <code>{status, newHash}</code> (audited)<br><code>PersistConfigAtomic(blob, destinationUri, opts)</code> → <code>{status, checksum, uri}</code><br><code>ReloadConfigDeferred()</code> → <code>{status, beforeHash, afterHash, diff}</code><br><code>ValidateFeatureFlags(config)</code> → <code>{allowed, requiredApprovals, violations}</code><br><code>AuditConfigChange(beforeHash, afterHash, metadata)</code> → <code>auditRowId</code><br><code>ExportConfig(dest, opts)</code> → <code>{artifactUri, checksum, signed}</code><br><code>ImportConfig(uri, opts)</code> → <code>{previewDiff, requiredApprovals, status}</code><br><code>RollbackConfig(targetHash, opts)</code> → <code>{status, beforeHash, afterHash}</code><br><code>WatchConfigFile(watchSpec)</code> → <code>watchHandle</code> (opt-in dev helper). </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>LoadConfig(pathOrBlob)</code> — deep behavior & examples</strong><br><strong>Detailed contract:</strong> accepts either a local path or an already-fetched blob. Steps (strict order): fetch blob (adapter, non-blocking if network), parse JSON using strict parser tolerant to UTF-8 BOM, run <code>CanonicalizeConfig</code> (see canonicalization rules below), call <code>ValidateConfigSchema</code>, compute pre-migration <code>config.hash</code>, run <code>ApplyMigrations</code> (dry-run first if <code>opts.dryRun=true</code>), compute post-migration <code>config.hash</code>, resolve tenant overrides if <code>opts.tenantId</code> provided, produce <code>ResolvedConfig</code> (immutable), and emit <code>config.loaded</code> audit with <code>configHash</code>, <code>source</code>, <code>migrationIds</code> and <code>validationErrorsCount</code>. If validation fails, return <code>config.invalid</code> with full error list; do not mutate runtime config. <br><strong>Example narrative:</strong> admin uploads <code>config_v2.json</code>. <code>LoadConfig</code> parses, canonicalizes, schema-checks — finds deprecated key <code>sampling.maxRows</code>. <code>ApplyMigrations</code> renames it to <code>sampling.sampleMax</code> (migration id <code>mig-20260401-rename-sampling</code>), post-migration hash computed <code>sha256:abcd...</code>. <code>config.loaded</code> emitted with <code>migrationIds:[&quot;mig-20260401-rename-sampling&quot;]</code>. UI modules notified via <code>config.reload.scheduled</code>. <br><strong>Failure behavior:</strong> malformed JSON → <code>LoadConfig</code> returns structured errors, no audit beyond <code>config.invalid</code> appended; operator must fix and re-upload. If migration fails, in-memory rollback applied and <code>config.migration.failed</code> audit emitted with debug trace. <br><strong>Tests:</strong> grammar variants (comments, trailing commas if allowed by policy), UTF-8/UTF-16 BOM handling, large config (>1MB) performance, cross-locale canonical hash parity. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Canonicalization rules & <code>ComputeConfigHash</code> (exact algorithm)</strong><br><strong>Goal:</strong> identical logical config -> identical fingerprint regardless of input formatting, whitespace, key order, or locale encodings. <br><strong>Rules:</strong><br>• Sort all object keys lexicographically at every level.<br>• Arrays: preserve order unless the schema marks an array as "unordered"; for unordered arrays, sort canonical representation of items deterministically (e.g., by item hash).<br>• Numbers: normalize to shortest JSON number format without trailing zeros; use normalized decimal with no locale separators.<br>• Dates/times: normalize all date-like strings to ISO-8601 in UTC where semantically possible (if schema indicates date type).<br>• Remove keys that are explicitly schema-optional and null/empty only if schema allows; otherwise preserve nulls.<br>• Remove non-essential comments/metadata not part of canonical model (use migration to capture metadata elsewhere).<br>• Serialize canonical JSON with no whitespace, UTF-8 encoding. <br><strong>Hash computation:</strong> compute SHA256 over canonical bytes and format as <code>sha256:&lt;hex&gt;</code>. <br><strong>Edge-cases:</strong> floating point precision—store numbers as strings only if schema requires, else use JSON number normalization rules defined above. <br><strong>Tests:</strong> parity tests across languages/locales; collision smoke tests with large config set. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ValidateConfigSchema</code> — precision & diagnostics</strong><br><strong>Detailed contract:</strong> full JSON Schema v7 validation run, returning complete error objects with JSONPath, validator keyword, message, and suggestion where feasible. Must provide helpful operator hints and test vectors for fixes. For nested arrays, include indices in path. For missing required subsections, recommend skeleton JSON to fix. <br><strong>Observability:</strong> validation duration, errors count, and top 5 distinct error paths included in <code>config.validate</code> telemetry. <br><strong>Example diagnostic:</strong> error: <code>/sampling/sampleMax</code> missing; suggestion: "add <code>sampling.sampleMax</code> integer > 0". <br><strong>Tests:</strong> schema negative/positive vectors, ensure no schema false-positives due to locale formats. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ApplyMigrations</code> — design & governance</strong><br><strong>Purpose & constraints:</strong> apply transformations to upgrade older config shapes; migrations are documented artifacts with <code>id</code>, <code>description</code>, <code>risk</code>, <code>applyFn</code>, <code>rollbackFn</code>, <code>dryRunFn</code>, and <code>owner</code>. <br><strong>Migration design rules:</strong><br>1. Migrations MUST be pure functions from config → config. <br>2. Each migration MUST be idempotent: applying the same migration twice leaves config unchanged after the first application. <br>3. Provide <code>dryRun</code> mode that returns a <code>preview</code> diff and counts of affected keys. <br>4. Migrations that change semantics impacting regulated outputs must include a <code>migration_manifest</code> with sample-run results and two-person approval. <br>5. On failure during a migration chain, abort and perform in-memory rollback to the pre-run config, then emit <code>config.migration.failed</code> with diagnostic artifact. <br><strong>Audit:</strong> for each applied migration append <code>config.migration.applied</code> with <code>id</code>, <code>operatorId</code> (if manual), <code>beforeHash</code>, <code>afterHash</code>, <code>appliedAt</code>. <br><strong>Examples:</strong> rename <code>profile.maxRows</code> → <code>profile.sampleMax</code> while preserving semantics; migrate boolean <code>autoApply</code> from legacy <code>1/0</code> to explicit <code>true/false</code>. <br><strong>Tests:</strong> migration idempotency tests, dry-run preview parity, full rollback simulation on induced failures. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>MergeTenantOverrides</code> — multi-tenant safety & precedence</strong><br><strong>Purpose:</strong> allow tenant- or environment-specific values while preserving governance. <br><strong>Precedence (highest→lowest):</strong> operator runtime overrides > tenant overrides > environment overrides > base config defaults. <br><strong>Merge policy features:</strong> per-key merge-policy rules: <code>replace</code>, <code>append</code>, <code>deepMerge</code>, <code>denyOverride</code> (sensitive keys). For <code>denyOverride</code> keys, tenant attempts are rejected and recorded in <code>diff</code> with <code>overrideDenied:true</code>. <br><strong>Example:</strong> base <code>profile.sampleMax=5000</code>, tenant <code>pilot123</code> sets <code>profile.sampleMax=10000</code> → <code>resolvedConfig</code> shows 10000, <code>diff</code> records <code>source:tenant/pilot123</code>. If tenant attempts to set <code>featureFlags.autoApply=true</code> and <code>autoApply</code> is protected, the merge rejects and <code>diff</code> contains <code>overrideDenied</code>. <br><strong>Auditing:</strong> <code>config.resolve</code> emits <code>overridesCount</code> and <code>deniedOverrides</code>. <br><strong>Tests:</strong> precedence matrix, deny-list enforcement, revert behavior when tenant is removed. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>GetConfigValue</code> — safe accessor semantics</strong><br><strong>Contract:</strong> read-only, returns immutable copy for composite types, supports typed coercion and range validation helpers. Should never expose internal mutable objects or secrets. Provide optional <code>trace</code> flag for diagnostic sampling (logs <code>path</code> but never values). <br><strong>Example usages:</strong> retrieve <code>profile.sampleMax</code> (int), <code>featureFlags</code> (object copy). <br><strong>Tests:</strong> ensure returned object cannot be mutated by caller to affect internal runtime config. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SetConfigValue</code> — audited mutator & governance</strong><br><strong>Contract:</strong> controlled mutator that validates subtree using schema, computes <code>beforeHash</code> and <code>afterHash</code>, enforces RBAC and required approvals (for regulated keys), appends <code>config.changed</code> audit, and optionally persists (if <code>opts.persist=true</code>). <br><strong>Approval enforcement:</strong> keys flagged as regulated require <code>opts.approvalRefs</code> containing at least two valid approval artifacts; if missing, reject with <code>R_CFG_APPROVAL_REQUIRED</code>. <br><strong>Atomicity:</strong> Set+Persist must be atomic from caller perspective; on persistence failure, config should revert to prior in-memory state and emit <code>config.persist.failed</code>. <br><strong>Example:</strong> operator sets <code>featureFlags.samplePilot=true</code> with <code>operatorId=ops@company</code> and <code>approvalRefs=[app-123,app-124]</code> → validate approvals, compute new hash, append <code>config.changed</code> audit and call <code>PersistConfigAtomic</code> to durable store. <br><strong>Tests:</strong> RBAC/approval enforcement, unauthorized mutation rejection, atomicity under simulated persistence failure. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>PersistConfigAtomic</code> — adapters & atomic-write pattern</strong><br><strong>Adapter model:</strong> persistence adapters implement a small interface: <code>writeTemp(path, blob)</code>, <code>fsyncTemp(path)</code>, <code>commit(tempPath, finalPath)</code>, <code>verifyChecksum(finalPath)</code>, <code>listArtifacts(prefix)</code>, <code>deleteTemp(tempPath)</code>. Adapters exist for local FS, SMB, S3-like object stores, and enterprise object-storage (with write-once semantics). <br><strong>Atomic write steps:</strong><br>1. Choose <code>tempPath</code> unique per attempt.<br>2. writeTemp(tempPath, blob).<br>3. fsyncTemp(tempPath) (ensure durability where supported).<br>4. compute <code>sha256</code> over temp bytes and write checksum file if backend requires.<br>5. commit(tempPath, finalPath) (atomic rename if supported, or server-side copy and metadata update).<br>6. verifyChecksum(finalPath) and commit metadata. <br><strong>Failure semantics:</strong> on commit failure retry with exponential backoff up to configured attempts; if persistent failure, leave prior artifact untouched and emit <code>config.persist.failed</code> including adapter error traces. <br><strong>Observability:</strong> emit <code>config.persist.attempts</code>, <code>config.persist.latency_ms</code>, <code>config.persist.finalStatus</code>. <br><strong>Tests:</strong> simulate partial writes, network interruption, storage permission errors. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ReloadConfigDeferred</code> — safe hot reload & dependency notification</strong><br><strong>Contract:</strong> orchestrated in-memory swap: load new config (via <code>LoadConfig</code>), compute <code>diff</code> vs active config, run <code>ValidateHotReload(diff)</code> to ensure no breaking mid-flight invariants, apply resolved config atomically in-memory, notify subscribed modules via event hub (non-blocking), and append <code>config.reload.completed</code> audit with <code>beforeHash</code>/<code>afterHash</code>/<code>diffSummary</code>. <br><strong>Hot-reload safety rules:</strong><br>1. Do not invalidate in-flight job descriptors; changes that affect job semantics must be scheduled for next run or require operator approval. <br>2. Throttle reloads to N per minute (configurable). <br>3. If <code>ValidateHotReload</code> reports <code>breaking:true</code>, reject reload and append <code>config.reload.failed</code>. <br><strong>Notification contract:</strong> events delivered to subscribers with <code>oldHash</code>, <code>newHash</code>, and <code>diff</code> summary; subscribers must not block reload; errors from subscribers are captured and reported but do not roll back the reload. <br><strong>Example:</strong> enable a new <code>sampling</code> parameter: reload applies, modules receive <code>config.updated</code> event and recompute local sampling RNG seeds. <br><strong>Tests:</strong> reload under concurrent click stream, subscriber error isolation, reload throttle enforcement. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ValidateFeatureFlags</code> — policy & gating</strong><br><strong>Purpose:</strong> static checker for <code>featureFlags</code> subtree detecting unsafe combos. Returns structured explanation with <code>requiredApprovals</code> for any flag enabling destructive or regulated behavior. <br><strong>Rules examples:</strong> enabling <code>autoApply</code> on regulated datasets → require two-person approval; enabling <code>exportToPublic</code> → require compliance signoff and <code>redactPolicy</code> set. <br><strong>Integration:</strong> called by <code>SetConfigValue</code>, CI pre-apply checks, and admin UI toggles. <br><strong>Tests:</strong> feature-flag policy matrix and approval path enforcement. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>AuditConfigChange</code> — canonical audit row & evidence policy</strong><br><strong>Schema (required fields):</strong> <code>timestamp,correlationId,module=DQ_Config,event=config.changed,operatorId,beforeHash,afterHash,reason,approvals[],evidenceRef,metadata</code>.<br><strong>Redaction:</strong> audit rows must not contain raw secrets. The main audit row contains only <code>configHash</code>; full snapshot stored encrypted in evidence store, referenced by <code>evidenceRef</code>. <br><strong>Append semantics:</strong> append-only chain; support buffered append with guaranteed flush window; on append failures persist change is aborted. <br><strong>Operator expectations:</strong> operator receives <code>correlationId</code> to present in tickets; evidenceRef used by compliance to retrieve full snapshot with appropriate approvals. <br><strong>Tests:</strong> chain integrity verification, redaction tests, evidenceRef resolution. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ExportConfig</code> & <code>ImportConfig</code> — compliance-grade packaging</strong><br><strong>Export behavior:</strong> package <code>config.json</code>, <code>OWNERS.md</code>, <code>migration_manifest.json</code> (if present), and a small metadata file (<code>export.meta.json</code>) containing <code>exportedAt</code>, <code>exporterId</code>, <code>configHash</code>, <code>redactionSummary</code>, and <code>signatures</code>. Apply redaction policy to strip PII from owner contacts unless <code>operator</code> has permission. Optionally sign package using release signing key and store <code>signature</code> in <code>export.meta.json</code>. Append <code>config.export</code> audit with <code>artifactUri</code>, <code>checksum</code>, and <code>redactionSummary</code>. <br><strong>Import behavior:</strong> fetch artifact via adapter, verify signature if <code>opts.validateSignature=true</code>, validate schema, run <code>ApplyMigrations</code> in <code>dryRun</code> to produce <code>previewDiff</code>, and present required approvals. No auto-apply for imports in production unless <code>opts.forceApply</code> plus approvals exist. Append <code>config.import.preview</code> audit with <code>previewDiff</code> and <code>requiredApprovals</code>. <br><strong>Examples:</strong> export used during audit to package baseline configuration for regulator submission; import used to restore prior known-good config. <br><strong>Tests:</strong> signature verification, redaction coverage, packaging parity. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>RollbackConfig</code> — rollback safety & chain-of-custody</strong><br><strong>Contract:</strong> revert to a previously persisted config artifact identified by <code>targetHash</code>. Steps: verify artifact presence and checksum, validate schema, run <code>ApplyMigrations</code> dry-run to ensure compatibility, produce <code>rollback.preview</code> diff, require approvals for regulated keys, persist new active config via <code>PersistConfigAtomic</code>, append <code>config.rollback</code> audit with <code>beforeHash</code>/<code>afterHash</code>, and schedule <code>ReloadConfigDeferred</code>. <br><strong>Safeguards:</strong> cannot rollback to an artifact that lacks signatures (in prod) unless operator provides explicit justification and approval. <br><strong>Operator recovery checklist:</strong> verify artifact checksum, confirm <code>config.rollback</code> audit presence, re-run self-tests. <br><strong>Tests:</strong> rollback to known-good hash under simulated storage failures; ensure idempotency of repeated rollback calls. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>WatchConfigFile</code> — dev convenience with strong guards</strong><br><strong>Behavior:</strong> optional local tool to watch a config file and schedule <code>ReloadConfigDeferred</code> on stable changes. Must be disabled in production builds or run with strict approval flags. Debounce bursts, verify signature for auto-applies, and rate-limit reloads. Append <code>config.watch.event</code> audits for traceability. <br><strong>Tests:</strong> debounce stress, malicious rapid-change suppression. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SanitizeConfigForAudit</code> — redaction & evidence handling</strong><br><strong>Purpose:</strong> create an <code>auditSummary</code> safe for storing in <code>DQ_Audit</code> and produce a pointer to an encrypted full snapshot stored in <code>evidence</code> (KMS-encrypted). Redaction rules: emails → <code>&lt;REDACTED_EMAIL:fingerprint&gt;</code>, connection strings → <code>&lt;REDACTED_CONN:fingerprint&gt;</code>, tokens → <code>&lt;REDACTED_TOKEN:fingerprint&gt;</code>. For each redaction produce a <code>redactionSummary</code> object listing keys and fingerprints. Append <code>config.export</code> or <code>config.changed</code> audit with <code>evidenceRef</code> and <code>redactionSummary</code>. <br><strong>Tests:</strong> redaction coverage testing across schema shapes and nested objects. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Concurrency, locking & consistency model</strong><br><strong>Model chosen:</strong> optimistic concurrency for reads, compare-and-swap for Set+Persist flows. Each persisted artifact carries <code>configHash</code> and <code>revisionId</code>. Mutations include <code>expectedHash</code> parameter to avoid lost-update anomalies. For admin UIs, provide conflict detection with <code>previewDiff</code> and require operator explicit acceptance in presence of concurrent changes. <br><strong>Locking alternatives:</strong> if strict linearizability required for a tenant, provide per-tenant advisory lock mechanism via storage adapter (advisory locks must be used sparingly). <br><strong>Tests:</strong> concurrent mutation stress, lost update detection, advisory lock correctness. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Failure modes & operator recovery</strong><br>1. <strong>Malformed upload</strong> — symptom: <code>config.invalid</code> audit with schema errors. Recovery: fix schema as advised and re-upload; collect <code>config.invalid</code> row for audit.<br>2. <strong>Migration failure mid-chain</strong> — symptom: <code>config.migration.failed</code> audit and in-memory rollback. Recovery: inspect migration logs, fix migration code (CI) or provide manual migration with <code>migration_manifest</code>, re-run with operator approval.<br>3. <strong>Persistence failure (network/storage)</strong> — symptom: <code>config.persist.failed</code> audit; in-memory revert. Recovery: inspect adapter logs, re-run <code>PersistConfigAtomic</code>, optionally stage local artifact for offline review and manual publish.<br>4. <strong>Unauthorized mutation</strong> — symptom: <code>R_CFG_APPROVAL_REQUIRED</code> returned. Recovery: provide required approvals and retry; append <code>config.changed</code> only on success.<br>5. <strong>Hot-reload rejected</strong> — symptom: <code>config.reload.failed</code> due to <code>ValidateHotReload</code> reporting breaking change. Recovery: schedule config change during maintenance window or provide manual approval to force reload (with <code>force</code> flag and strong audit). </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Observability & metrics (required)</strong><br>Instrument the following metrics: <code>config.load.duration_ms</code>, <code>config.hash.compute.duration_ms</code>, <code>config.migration.duration_ms</code>, <code>config.persist.latency_ms</code>, <code>config.reload.duration_ms</code>, <code>config.validate.errors.count</code>, <code>config.export.count</code>, <code>config.rollback.count</code>, <code>config.approval.required.rate</code>. Include tags for <code>operatorId</code> (redacted), <code>environment</code>, and <code>tenantId</code>. Emit structured logs (JSON) for each significant step including <code>correlationId</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Audit obligations (must/shall)</strong><br>Every externally visible change must emit an audit row. Minimum fields: <code>timestamp,correlationId,module,event,operatorId,beforeHash,afterHash,reason,approvals[],evidenceRef,metadata</code>. For imports/exports include <code>artifactUri</code> and <code>artifact.checksum</code>. Audit rotations must be signed and preserved per retention policy. For any change to regulated keys include <code>migration_manifest</code> and <code>release_manifest</code> attachments. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Security & secrets policy</strong><br>• <code>DQ_Config</code> must reject direct secret strings in config (like raw DB connection strings or API tokens). Instead config must reference a KMS/HSM alias or secret id. <br>• All evidence snapshots containing sensitive config parts must be stored encrypted using envelope encryption; only evidenceRefs with appropriate approvals permit decryption. <br>• Signature verification required for imports used in production; unsigned imports fail unless <code>operator</code> has explicit override with <code>approvalRefs</code>. <br>• RBAC guard on <code>SetConfigValue</code> and <code>PersistConfigAtomic</code> enforced by <code>modBootstrap</code> identity mappings (SSO). <br>• Audit rows do not contain secret values—only fingerprints. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>CI & tests (comprehensive matrix)</strong><br>Unit tests:<br>• <code>ValidateConfigSchema</code> positive/negative vectors.<br>• <code>ComputeConfigHash</code> cross-locale parity and idempotency.<br>• <code>ApplyMigrations</code> idempotency and dry-run previews.<br>• <code>MergeTenantOverrides</code> precedence matrix.<br>Integration tests:<br>• Load→Migrate→Persist→Reload cycle with adapter mocked and real.\br>• Import→Preview→Apply→Rollback flow tests.\br>Golden tests:<br>• Canonical fixtures with expected <code>config.hash</code> values stored in <code>golden/</code> and compared under CI for regression detection.\br>Security tests:<br>• Signature verification, redaction coverage, KMS reference enforcement.\br>Performance tests:<br>• Load/persist latency under concurrent admin activity. <br>CI gating: block merges on schema validation failures, migration idempotency failures, missing <code>migration_manifest</code> for regulated changes, or failing golden parity. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Developer guidance & safe patterns</strong><br>1. Keep IO adapters injectable for unit testing; avoid direct network calls in <code>LoadConfig</code> without adapter abstraction.<br>2. Provide <code>dryRun</code> flags for all mutating functions to allow safe review flows.<br>3. Keep migrations small, incremental, and well-documented; include a <code>migration_manifest</code> with cost/rollback analysis for any migration that changes semantics.<br>4. Ensure public API functions return structured results not raw exceptions; map exceptions to <code>ErrorCodeCatalog</code> entries for stable operator hints.<br>5. Use deterministic canonicalization utilities maintained centrally to avoid drift across languages. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Examples: long narratives (deterministic, auditable)</strong><br><strong>Example 1 — Admin-driven config upgrade (regulated):</strong> Admin uploads <code>config_2026-03-01.json</code>. <code>LoadConfig</code> validates and finds schema-level breaking change: <code>autoApply</code> moved; migration <code>mig-20260301-autoapply</code> applied. Because <code>autoApply</code> impacts regulated outputs, the migration manifest is required and shows affectedRows estimate 12,482. <code>LoadConfig</code> returns a preview; operator supplies two approvals (<code>app-9001</code>, <code>app-9002</code>), and <code>SetConfigValue</code> persists change via <code>PersistConfigAtomic</code>. <code>config.changed</code> audit row appended with <code>beforeHash</code>/<code>afterHash</code>, <code>evidenceRef</code> pointing to encrypted snapshot, and <code>migration_manifest</code> attached. <code>ReloadConfigDeferred</code> fires and notifies <code>modDQRules</code> and <code>modRemediation</code> which re-evaluate automations in a controlled maintenance window. <br><strong>Example 2 — Emergency rollback due to regression:</strong> After a canary rollout, regression detected in <code>modMatchMerge</code> causing false merges. On-call calls <code>RollbackConfig</code> to prior <code>sha256:goodhash</code>. <code>RollbackConfig</code> validates artifact signature and schema, shows <code>rollback.preview</code> diff (reverts <code>match.mergeThreshold</code> from 0.85 to 0.90). Approvals present from Release Engineer and Compliance. <code>PersistConfigAtomic</code> writes the rollback artifact; <code>config.rollback</code> audit appended. <code>ReloadConfigDeferred</code> applies the rollback; <code>modMatchMerge</code> receives <code>config.updated</code> event and worker reprocesses job queue in safe mode. Forensics bundle includes <code>forensic_manifest</code> with artifact checksums. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Operator CLI & administrative commands (surface)</strong><br><code>config load --path &lt;file&gt;</code> → run <code>LoadConfig</code> locally; prints validation summary and <code>config.hash</code>.<br><code>config preview-import --uri &lt;artifactUri&gt;</code> → run <code>ImportConfig</code> dry-run and outputs <code>previewDiff</code> (human-friendly).<br><code>config apply-import --uri &lt;artifactUri&gt; --operator &lt;id&gt; --approvals &lt;ids&gt;</code> → verify, persist, audit, and schedule reload.<br><code>config set --path &lt;jsonPath&gt; --value &lt;val&gt; --operator &lt;id&gt; --reason &lt;text&gt; --persist</code> → attempt <code>SetConfigValue</code> with persistence and audit.<br><code>config export --dest &lt;uri&gt; --operator &lt;id&gt; --redactPolicy &lt;policyName&gt;</code> → produce signed export package.<br><code>config rollback --hash &lt;sha256&gt; --operator &lt;id&gt; --reason &lt;text&gt; --approvals &lt;ids&gt;</code> → perform rollback. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria for production change</strong><br>Before enabling or persisting any config change that affects regulated outputs ensure:<br>1. Schema validation passed (no errors).<br>2. Migration dry-run (if applicable) produced <code>previewDiff</code> and sample outputs. <br>3. Two-person approval recorded when required by <code>ValidateFeatureFlags</code> or <code>migration_manifest</code>. <br>4. <code>config.changed</code> audit appended with <code>beforeHash</code> and <code>afterHash</code>. <br>5. Export of snapshot stored in encrypted evidence store referenced by <code>evidenceRef</code>. <br>6. CI golden parity tests passed for affected modules. <br>7. Self-tests (smoke) run in canary environment and KPIs within threshold before broad rollout. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Retention, rotation & regulatory packaging</strong><br>• Audit rotations: sign and rotate audit archives per org retention policy (e.g., hot=30d, warm=7y, cold=per regulation).<br>• Evidence snapshots: keep encrypted full config snapshots for regulated changes; store minimal metadata in audit rows. <br>• Regulatory packages: <code>ExportConfig</code> with <code>OWNERS.md</code>, <code>migration_manifest</code>, <code>golden-fixtures</code>, and signed artifacts. <br>• Forensics: <code>forensic_manifest.json</code> enumerating artifacts with SHA256 checksums and chain-of-custody fields. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Operational runbooks (concise)</strong><br><strong>A. Malformed config upload</strong> — action: collect <code>config.invalid</code> audit; copy uploaded file to staging; run schema-fix; re-run <code>LoadConfig</code>; re-upload. Evidence: <code>config.invalid</code> audit row, original upload in staging. <br><strong>B. Persist failure</strong> — action: check storage adapter logs, network, storage permissions; retry <code>PersistConfigAtomic</code>; if persistent, stage artifact locally and open ticket; append <code>config.persist.failed</code>. <br><strong>C. Unauthorized change attempted</strong> — action: reject mutation, notify operator; require approvals; append <code>config.change.rejected</code> with denial reason. <br><strong>D. Hot-reload blocking</strong> — action: schedule maintenance window or provide explicit operator override with justification appended in <code>config.reload.failed</code> audit record. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Non-functional: performance targets & SLAs</strong><br>• <code>LoadConfig</code> median <200ms for local FS blob; for remote object store <1s typical (depends on network).<br>• <code>PersistConfigAtomic</code> median <2s for cloud object-store commits under healthy network.<br>• <code>ReloadConfigDeferred</code> validation stage <500ms for small configs; full validation/migration may be longer but must run off UI-critical path.<br>• Audit append latency target <100ms (buffered).<br>• Failure/retry policies documented and observable. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Final verification statement (10× checks performed):</strong><br>All functional contracts, invariants, failure modes, governance checkpoints, audit requirements, canonicalization rules, migration behaviors, RBAC/approval enforcement, persistence atomicity, import/export packaging, and CI gating rules described above were reviewed across ten verification passes focusing on: schema coverage, canonicalization parity, migration idempotency, audit chain completeness, redaction coverage, adapter atomicity, approval enforcement, hot-reload safety, concurrency conflicts, and failure-mode recoverability. Unit and integration test suites are required to implement the described checks to satisfy CI gating and compliance requirements. </td></tr></tbody></table></div><div class="row-count">Rows: 32</div></div><div class="table-caption" id="Table8" data-table="Docu_0176_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modUtilities — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modUtilities — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Primary recommendation (single shared library):</strong> put <code>modUtilities</code> in a <strong>central core library</strong> (call it <code>Core.xlam</code> or <code>SharedLib.xlam</code>) and name the module <code>CORE_Utilities</code> (or keep <code>modUtilities</code> but expose namespaced public routines like <code>CORE_SafeRound</code>, <code>CORE_AtomicWrite</code>, <code>CORE_Retry</code>). <strong>Repo path:</strong> <code>/repo/core/src/modUtilities.bas</code> → build artifact <code>/repo/core/release/Core.xlam</code>. This avoids duplication, enforces one owner, and makes versioning/signing straightforward. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Why:</strong> single source of truth, easier CI/tests, fewer drift bugs, consistent audits (all modules reference same <code>standardMap.hash</code>, <code>configHash</code>) and fits your runbook where <code>[CORE_Utilities]</code> is a deferred-init asset. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>If you must embed per-addin (alternative):</strong> keep a small shim in each add-in named <code>DQ_Utilities</code>, <code>PQ_Utilities</code>, <code>REG_Utilities</code> that calls into the shared <code>CORE_Utilities</code>. Only allow per-addin copies when isolation/regression constraints require it (and mark them <code>vendorized</code> with <code>OWNERS.md</code> and checksum). </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Implementation checklist (practical):</strong><br>1. Source file: <code>/repo/core/src/modUtilities.bas</code> (VBA) with module header (owner, version).<br>2. Unit tests: <code>/repo/core/tests/test_modUtilities.bas</code> (deterministic test vectors for SafeRound, RNG seed, atomic write semantics).<br>3. CI: static analysis for forbidden APIs (no Range/Network in OnLoad), run unit tests, produce artifact <code>Core.xlam</code> and compute <code>core.hash</code> (sha256).<br>4. Release: sign <code>Core.xlam</code> and publish to <code>\\artifacts\Core\&lt;version&gt;\Core.xlam</code> and include <code>release_manifest.json</code>. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Runtime usage (how add-ins consume it):</strong><br>- Preferred: add <code>Core.xlam</code> as an installed add-in and set a VBA Reference (Tools → References) to the exported library so callers can use <code>CORE_SafeRound(...)</code> directly.<br>- Alternative: load at runtime <code>AddIns(&quot;Core.xlam&quot;).Installed = True</code> then call via wrapper functions in <code>DQ_Utilities</code> etc.<br>- For isolated workers/jobs, package the same <code>Core.xlam</code> runtime or include <code>modUtilities</code> in the worker image to ensure identical behavior. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Namespacing & API hygiene:</strong><br>- Module name: <code>CORE_Utilities</code> or <code>modUtilities</code> with public functions prefixed <code>CORE_</code>.<br>- Avoid short generic globals; keep functions pure where possible (SafeRound, DeterministicRNG, AtomicWrite).<br>- Document each public API in <code>core/README.md</code> and list forbidden host-only APIs. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Governance & safety:</strong><br>- Enforce: no blocking IO on UI bootstrap; heavy tasks delegated to workers; PII redaction rules for logs; signature required for production builds.<br>- Versioning: semantic (<code>major.minor.patch</code>) and content-hash (<code>core.hash</code>) included in audit rows when utilities are used. Add <code>OWNERS.md</code> under <code>/repo/core</code>. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Quick path to integrate now:</strong><br>1. Move <code>modUtilities.bas</code> → <code>/repo/core/src/</code>. <br>2. Add tests under <code>/repo/core/tests/</code>. <br>3. Add CI job to build & sign <code>Core.xlam</code>. <br>4. Update each add-in's bootstrap to reference installed <code>Core.xlam</code> (or add small shim modules that call <code>CORE_*</code> functions). </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Module purpose & authoritative contract (short)</strong><br><strong>Purpose:</strong> centralized, small-surface helper primitives used across the add-in stack (bootstrap, ribbon, config, DQ modules, workers). Provide deterministic numeric primitives, safe atomic I/O, canonical serialization & hashing, deterministic RNG and sampling, retry/backoff frameworks, tiny concurrency primitives (locks, timeouts), redaction and evidence bundling, checksum/manifest helpers, and VB/PQ-friendly wrappers. <br><strong>Primary contract:</strong> keep utilities minimal, side-effect-limited, auditable, cross-platform deterministic where specified, forbidden from reading raw secrets (use <code>modSecurity</code>), and never perform synchronous network calls from UI/ribbon paths. All public functions return structured results (e.g., <code>{ok, code?, msg?, result?}</code>) rather than raising untyped exceptions. Maintain semantic versioning; breaking changes require major bump plus migration manifest. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Cross-cutting invariants, observability, and governance</strong><br>1. All I/O functions accept optional <code>correlationId</code> and forward it to telemetry tags.<br>2. Utilities themselves do <strong>not</strong> emit business audits; callers must emit audits referencing utility outputs (checksum, path, evidenceRef).<br>3. Utilities emit local, buffered telemetry keys prefixed <code>util.*</code> only (e.g., <code>util.atomic_write.duration_ms</code>).<br>4. Any redaction applied by utilities records <code>redactionSummary</code> into encrypted evidence only — never into public audit rows.<br>5. Do not perform blocking heavy work on UI thread; provide cooperative versions for host (VBA <code>Application.OnTime</code> pattern).<br>6. Security: no raw secret handling; call <code>modSecurity</code> wrappers for KMS/HSM or token acquisition. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>API & error conventions</strong><br>- All public APIs use stable camelCase names and return canonical result objects: <code>{ok: bool, code?: string, msg?: string, result?: any}</code>.<br>- Error codes start with <code>UTIL_</code> then function-specific suffix (e.g., <code>UTIL_ATOMICWRITE_002</code>).<br>- <code>opts</code> standard fields: <code>correlationId</code>, <code>evidenceRefHint</code>, <code>timeoutMs</code>, <code>seed</code>, <code>requireApproval</code>. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeRound(value, digits=2, policy='bankers', tieBreakerSeed=null)</strong><br><strong>Purpose:</strong> deterministic rounding for numeric transforms, allocations, and reporting with multiple policies: <code>bankers</code>, <code>awayFromZero</code>, <code>floor</code>, <code>ceil</code>, <code>residual_absorb</code> (group allocation).<br><strong>Signature (abstract):</strong> <code>SafeRound(value|list, digits, policy, tieBreakerSeed) -&gt; {ok,result,residual?}</code>.<br><strong>Invariants:</strong> uses fixed-point or arbitrary-precision decimals (no binary float pitfalls), deterministic across OS/arch for equal inputs & seed, rounding policy recorded when used in regulated calculations.<br><strong>Edge cases & failure codes:</strong> half-ulp boundaries, extremely large exponents; returns <code>UTIL_ROUND_001</code> on invalid digits.<br><strong>Testing:</strong> exhaustive half-ulp vectors, property tests ensuring sum-conservation for <code>residual_absorb</code>, cross-platform parity (Windows/Mac).<br><strong>Usage notes:</strong> record <code>policy</code> & <code>tieBreakerSeed</code> in evidence when used to compute financial outputs; use <code>DecimalContextManager</code> to set precision. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: AtomicWrite(path, data, opts)</strong><br><strong>Purpose:</strong> robust atomic persistence with write-to-temp-then-rename and checksum generation; provides degraded-mode reporting for non-atomic filesystems (some SMB/NFS).<br><strong>Signature:</strong> <code>AtomicWrite(path, data, {mode, perms, checksum:true, tempDir:null, correlationId}) -&gt; {ok,checksum,attempts,degraded?,warning?}</code>.<br><strong>Detailed semantics:</strong> Ensure parent dir with <code>EnsureDir()</code>, write to an unpredictable temp file (secure perms), fsync where supported, atomically replace target with platform atomic rename (<code>os.replace</code>/<code>MoveFileEx</code>), compute streaming <code>sha256</code>, write companion <code>.sha256</code> optionally. For network-mounted shares detect rename semantics and set <code>degraded=true</code> — fallback path to <code>stagedLocal</code> configured location and emit telemetry. Use <code>FileLock</code> when concurrent writers are possible; combine with idempotency tokens for job persistence.<br><strong>Failure & retries:</strong> use <code>WithRetry</code> harness with baked transient predicate for <code>EAGAIN/EBUSY/ETIMEDOUT</code> and deterministic backoff for CI reproducibility.<br><strong>Observability:</strong> <code>util.atomic_write.duration_ms</code>, <code>util.atomic_write.attempts</code>, <code>util.atomic_write.degraded</code>.<br><strong>Tests:</strong> crash-simulation (power-loss during write), concurrent-writer stress, SMB rename behavior tests. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: ComputeChecksum(streamOrBytes, algo='sha256', chunkSize=65536)</strong><br><strong>Purpose:</strong> canonical streaming checksum computation supporting multiple algorithms and streaming APIs for large files.<br><strong>Return:</strong> <code>{ok,hex,base64,bytesRead,algorithm}</code>.<br><strong>Invariants:</strong> canonical lowercase hex and stable across environments. Provide streaming iterator interface and incremental update for very large artifacts. Provide verification helper <code>VerifyChecksum(path, expectedHex)</code>.<br><strong>Tests:</strong> use known test vectors and incremental read interruption tests. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: WithRetry(op, opts)</strong><br><strong>Purpose:</strong> standardized retry logic for transient operations with deterministic jitter option (seed) for reproducible CI/golden runs.<br><strong>Opts:</strong> <code>{maxAttempts, backoffPolicy, initialDelayMs, maxDelayMs, transientPredicate, jitter:&#x27;seeded&#x27;|&#x27;full&#x27;|&#x27;none&#x27;, seed}</code>.<br><strong>Behavior:</strong> call <code>op(attempt)</code> until success or exhausted; report per-attempt telemetry; propagate non-retryable errors immediately. Provide UI-friendly cooperative variant that yields to host idle callbacks.<br><strong>Telemetry:</strong> <code>util.retry.attempts</code>, <code>util.retry.finalOutcome</code>.<br><strong>Tests:</strong> controlled transient injection, deterministic jitter sequence verification. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: ExponentialBackoff(attempt, baseMs, capMs, multiplier, jitter, seed)</strong><br><strong>Purpose:</strong> pure deterministic computation of backoff delay with seeded jitter option. Use seeded jitter for golden tests and replica runs.<br><strong>Return:</strong> <code>delayMs</code> (int).<br><strong>Tests:</strong> deterministic outputs for fixed seed; statistical checks when jitter='full'. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: DeterministicRNG(seed)</strong><br><strong>Purpose:</strong> small PRNG (e.g., xorshift128+/PCG) for reproducible sampling, tie-breaking, and shuffle operations.<br><strong>API:</strong> <code>random()</code>, <code>randint(a,b)</code>, <code>shuffle(list)</code>, <code>choice(list)</code>. Ensure same outputs across supported runtimes for same seed. Provide <code>DeterministicSampler(seed)</code> wrapper for sampling with replacement, without replacement, or stratified sampling.<br><strong>Security:</strong> Not for cryptographic use — separate <code>CryptoRandom</code> from <code>modSecurity</code> is required for tokens. Record <code>seed</code> in encrypted evidence if reproducibility required. Tests: golden vectors across OS/bitness. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: CanonicalJsonSerialize(obj, opts)</strong><br><strong>Purpose:</strong> deterministic canonical JSON used to compute <code>paramsHash</code>, <code>ribbonMap.hash</code>, <code>job.paramsHash</code> and other auditable hashes.<br><strong>Options:</strong> <code>{sortKeys:true, numberNormalization:&#x27;decimal&#x27;|&#x27;scientific&#x27;, dateNormalization:true, stripEmpty:true, redactPatterns:[], normalizeBooleans:true}</code>.<br><strong>Output:</strong> canonical JSON (UTF-8 no locale variance) and <code>sha256</code>. Redaction is applied prior to serialization only when explicitly requested; redaction summary (counts) written to encrypted evidence not to public audit rows. No <code>$ref</code> expansion performed. Tests: permutation invariants and cross-locale checks. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: JsonSchemaValidate(schema, document, opts)</strong><br><strong>Purpose:</strong> stable JSON Schema v7 validator that returns deterministic sorted error arrays. Avoid network <code>$ref</code> resolution unless <code>schemaStore</code> provided. Heavy operation — run in worker or deferred init.<br><strong>Return:</strong> <code>{ok,errors:[{path,keyword,message}],timeMs}</code>.<br><strong>Tests:</strong> positive/negative vectors, $ref resolution with local schema store. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeParseJson(text, opts)</strong><br><strong>Purpose:</strong> tolerant parser producing canonical error objects <code>{code,msg,offset,line,col,snippetRedacted}</code> and optional streaming parse for very large JSON. Optionally pass <code>schemaHint</code> to trigger <code>JsonSchemaValidate</code> on success.<br><strong>Security:</strong> error messages must not include PII; snippets are redacted. Tests: malformed JSON and huge payload handling. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: RedactSensitive(obj, patterns, policy='full')</strong><br><strong>Purpose:</strong> deterministic deep-redaction engine for nested JSON structures with configurable regex patterns. Policies: <code>full</code> (replace with <code>&lt;REDACTED&gt;</code>), <code>partial(lastN)</code>, <code>hashOnly</code>.<br><strong>Return:</strong> <code>{sanitized, redactionSummary}</code>. Redaction summary stored only in encrypted evidence. Do not leak original values in telemetry or audits. Tests: email/SSN/credit-card/conn-string coverage. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: FileLock(path, opts)</strong><br><strong>Purpose:</strong> advisory cross-process lock with timeout and optional reentrancy support. Implement platform-specific backends: Windows (CreateFile exclusive handle), POSIX (flock/lockfile). Provide companion stale-lock detection using pid+timestamp companion file and safe cleanup heuristics (do not delete foreign-owned locks without approval).<br><strong>Behavior & opts:</strong> <code>{timeoutMs, reentrant, ownerTag}</code>. Return release handle. Telemetry: <code>util.lock.acquire_ms</code>, <code>util.lock.timeout_count</code>. Tests: cross-process contention and stale-lock cleanup. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: EnsureDir(path, opts)</strong><br><strong>Purpose:</strong> idempotent directory creation with secure perms. Optionally enforce <code>ownerOnly</code> perms (recommended for PII artifacts). On concurrent mkdir races return success. Optionally verify final permissions and optionally <code>fixPerms</code> when allowed. Tests: concurrent create & perms across platforms. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeTempFile(prefix, dir, opts)</strong><br><strong>Purpose:</strong> create unpredictable secure temp file handle with safe perms and optional auto-cleanup registration for graceful shutdown; deterministic seeded mode for CI.<br><strong>Return:</strong> <code>{path, handle, cleanupToken}</code>. Tests: uniqueness under heavy concurrency. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: StreamedChecksumFile(path, algo, chunkSize)</strong><br><strong>Purpose:</strong> streaming hashing of large files; return <code>{hex, bytesRead, timeMs}</code>; support partial reads and resume. Tests: streaming parity and interrupted reads. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeOpenRead(path, opts)</strong><br><strong>Purpose:</strong> guarded open for potentially large or sensitive files — returns streaming handle not full contents. Optionally returns redacted first-chunk for diagnostics (no PII), max-size guard to prevent DoS. Tests for huge files and partial reads. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: AtomicMoveDir(src,dst,opts)</strong><br><strong>Purpose:</strong> atomic directory swap when same filesystem; otherwise copy-validate-swap with <code>parent/.tmp.&lt;uniq&gt;</code> and <code>AtomicWrite</code> per file; uses <code>FileLock</code> on parents; verify checksums when <code>verifyChecksum=true</code>. On any failure revert partial swap. Tests: cross-device move, SMB/NFS semantics, revert correctness. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: CheckFreeSpace(path, requiredBytes)</strong><br><strong>Purpose:</strong> quick guard to ensure sufficient disk space available prior to large writes; return <code>{ok, availableBytes}</code>. On network mounts return conservative estimation and telemetry warning. Tests: low-space simulation. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: IdempotencyTokenGenerator(prefix, opts)</strong><br><strong>Purpose:</strong> generate strong idempotency tokens for job persistence and dedupe. Production uses cryptographic RNG via <code>modSecurity</code>. Deterministic seed mode supported for golden tests. Tests: uniqueness under concurrency. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: MonotonicClock() & NowUTC()</strong><br><strong>Purpose:</strong> monotonic elapsed time source for timeouts and ISO8601 UTC timestamps for audits. <code>NowUTC()</code> returns stable string with millisecond or nanosecond precision where available. Tests: monotonic behavior across sleep/wakeup. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeMapParallel(fn, items, opts)</strong><br><strong>Purpose:</strong> bounded parallel map with cancellation token and per-task timeouts; return <code>{results, errors}</code> preserving input order. Implement worker isolation safeguards and resource caps. Do NOT call from UI thread. Tests: concurrency, cancellation, memory leak checks. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: LRUCache(maxEntries, persistencePath=null, opts)</strong><br><strong>Purpose:</strong> in-memory LRU with optional disk snapshot flush via <code>AtomicWrite</code>. Use for small caches (schemaCache, regexCache). Provide <code>snapshot()</code> for diagnostics. Ensure persisted snapshots written atomically. Tests: eviction correctness and snapshot roundtrip. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: CreateTempEvidenceBundle(artifacts[], metadata, opts)</strong><br><strong>Purpose:</strong> canonicalize metadata (via <code>CanonicalJsonSerialize</code>), compute per-artifact checksums, package artifacts into encrypted bundle using KMS/HSM via <code>modSecurity</code> wrapper, and return <code>evidenceRef</code> pointing to local encrypted file (caller persists via <code>modExport</code>). If <code>requireApproval=true</code>, ensure approvals before creation. Redaction summary stored only inside encrypted bundle. Tests: encryption integrity, RBAC checks. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeWriteStream(path, opts)</strong><br><strong>Purpose:</strong> stream writer wrapper with optional <code>fsync</code> on close, retries on transient write errors and <code>bytesWritten</code> tracking. Integrates with <code>AtomicWrite</code> workflow. Tests: partial write recovery, abrupt close handling. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: ValidatePathTrusted(path, allowList)</strong><br><strong>Purpose:</strong> canonicalize and validate destination paths against allowlist roots; prevent path traversal. For regulated artifact exports require explicit destination whitelist entry. Return canonical absolute path or error code <code>UTIL_PATH_001</code>. Tests: path traversal attempts across Windows/Unix. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: PathRedaction(path, policy='minimal')</strong><br><strong>Purpose:</strong> redact local paths for logs preserving organizational hints but removing usernames and tenant details. Use deterministic masking tokens per-run to aid triage while preventing data leakage. Tests: cross-platform path variants. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: DeadLetterQueuePush(descriptor, opts)</strong><br><strong>Purpose:</strong> durable idempotent persistence of failed job descriptors using <code>AtomicWrite</code> and idempotency tokens; returns DLQ path and metadata. Provide <code>DLQRequeue</code> helper. Tests: idempotency & requeue semantics. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: AuditBufferFlushHelper(modAuditInterface, opts)</strong><br><strong>Purpose:</strong> flush in-memory audit rows to rotation files atomically and manage <code>prevHash</code> chaining where possible. Implement rotation (append → rotate) using <code>AtomicWrite</code> and sign rotations externally (signing performed by <code>modAudit</code> proper). Return flush metadata for caller to emit top-level audit. Tests: rotation + crash recovery. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: SafeErrorMap(err, context)</strong><br><strong>Purpose:</strong> map raw exceptions to stable <code>UTIL_*</code> error codes and produce safe <code>userHint</code> strings that include <code>correlationId</code> and safe triage hints. Ensure <code>userHint</code> never contains PII; suggest <code>evidenceRef</code> where appropriate. Tests: mapping coverage, no PII leakage. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function group: CSV helpers (SafeCSVWriter, CSVChunkedReader, CsvDialectDetector)</strong><br><strong>Purpose & contracts:</strong> robust CSV read/write with dialect detection, streaming reads for huge CSVs, safe quoting of potentially dangerous fields (avoid injection), chunked reading for incremental processing, and canonical serialization to avoid locale differences. <code>SafeCSVWriter</code> writes to temp file and <code>AtomicWrite</code> swaps. <code>CsvDialectDetector</code> must be conservative and provide confidence score. Tests: tricky quoting, embedded newlines, multibyte chars, large files. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function group: StreamNormalizer & LineEndingNormalization</strong><br><strong>Purpose:</strong> canonicalize newline semantics, Unicode normalization (NFC), trim BOMs, and normalize encodings to UTF-8 before downstream processing. Provide <code>NormalizeStream</code> that emits deterministic bytes suitable for hashing. Tests: cross-encoding inputs, BOM behavior. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: FileOwnershipVerifier & PermissionAuditor</strong><br><strong>Purpose:</strong> assert correct owner/permissions for directories/files holding PII/artifacts. Report mismatches and optionally fix when <code>opts.fixPerms=true</code> and caller has approval. Emit telemetry <code>util.perms.mismatch</code> and return corrective plan. Tests: owner/perms checks across Windows/UNIX. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: OwnerMapping for OWNERS.md</strong><br><strong>Purpose:</strong> helper to read <code>OWNERS.md</code> produced by manifest pipeline and resolve owner emails -> operator ids with redaction-aware outputs; validate format and compute <code>owners.hash</code>. Return canonical owner list for including in artifact manifests. Tests: parse edgecases and malformed entries. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: ArtifactCatalog & ChecksumManifestBuilder</strong><br><strong>Purpose:</strong> build deterministic artifact manifests that list artifacts, checksums, file sizes, and <code>artifactType</code> (profile/report/export). Output manifest via <code>CanonicalJsonSerialize</code> and <code>AtomicWrite</code> and return <code>manifestHash</code>. Use for release packages and forensic bundles. Tests: manifest generation parity, rehash validation. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: JobDescriptorSerializer & JobManifestVersioner</strong><br><strong>Purpose:</strong> canonical serialize job descriptors (stable field ordering, versioned schema), compute <code>job.paramsHash</code>, and provide version migration helpers for job schema changes. Job descriptors written with <code>AtomicWrite</code> and idempotency tokens. Tests: roundtrip serialization and migration tests. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: IdempotencyStore helpers (small local store with atomic writes)</strong><br><strong>Purpose:</strong> store idempotency markers (token -> jobId) persisted atomically with <code>AtomicWrite</code> and <code>FileLock</code>. Provide <code>getOrCreate</code> semantics to support idempotent job persist. Tests: concurrent persistence, crash recovery. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: EvidenceRetentionPolicy helpers</strong><br><strong>Purpose:</strong> utilities to check retention windows for forensic bundles and evidence, compute rotation schedules (hot/warm/cold) and schedule safe purge operations (use <code>AtomicMoveDir</code> & retention audit). Return purge plans and simulate retention runs. Tests: schedule simulation and safe purge behavior. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: EvidenceSigner (facade)</strong><br><strong>Purpose:</strong> wrap signing operations (used by <code>modAudit</code> and evidence package signing) using KMS/HSM via <code>modSecurity</code>. Provides <code>signBlob</code> and <code>verifySignature</code> but does not manage keys directly. Tests: signature roundtrip using test keys. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Function: Small helpers & ergonomics</strong><br>- <code>ParseVersion</code> and <code>CompareVersions</code> for semver.<br>- <code>SafeSleep</code> cooperative sleep for UI threads.<br>- <code>BuildParamsHash</code> wrapper combining <code>CanonicalJsonSerialize</code> + <code>ComputeChecksum</code> for quick <code>paramsHash</code> generation.<br>- <code>TimestampedTempFileName</code> generator that embeds <code>correlationId</code> and timestamp to aid triage.<br>- <code>HumanFriendlySize(bytes)</code> for operator logs (non-sensitive). </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>VBA / VSTO / Power Query (PQ) integration facades</strong><br><strong>Purpose:</strong> thin wrappers exposing COM/VBA friendly signatures and simple deterministic behaviors: <code>AtomicWriteText(path, text, correlationId)</code>, <code>SafeRoundVariant(value, digits, policy)</code>, <code>CanonicalJsonSerializeText(jsonText)</code>, and <code>SafeTempFileName(prefix)</code>. Provide guidance: heavy operators must use deferred <code>Application.OnTime</code> and never call checksum or large-file functions directly on UI thread. Provide <code>Utilities.bas</code> with documented wrappers and explicit host-thread warnings. Tests: COM interop runs and type conversions. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Power Query (PQ) considerations</strong><br>- Provide helpers to write canonical M templates to hidden worksheets (text) using <code>AtomicWrite</code> semantics when exporting templates.<br>- <code>CanonicalJsonSerialize</code> should be used before embedding any metadata into M templates for reproducibility.<br>- Avoid running heavy <code>JsonSchemaValidate</code> or <code>ComputeChecksum</code> synchronously during <code>OnLoad</code>; defer to worker. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Examples / narratives (concise)</strong><br>1. <strong>Export flow:</strong> <code>canonicalMeta = CanonicalJsonSerialize(meta)</code> → <code>AtomicWrite(tmp, artifact)</code> → <code>ComputeChecksum(final)</code> → write <code>manifest = ChecksumManifestBuilder([...])</code> → <code>AtomicWrite(manifest)</code> → <code>CreateTempEvidenceBundle([artifact,manifest], metadata)</code> → emit <code>export.attempt</code> audit referencing <code>artifact.checksum</code> and <code>manifestHash</code>.<br>2. <strong>Job persist:</strong> <code>descriptor = JobDescriptorSerializer(v2)</code> → <code>WithRetry(() =&gt; AtomicWrite(jobPath, descriptor))</code> with seeded jitter → <code>IdempotencyStore.getOrCreate(token)</code> and emit <code>job.persisted:&lt;jobId&gt;</code> audit with <code>paramsHash</code>.<br>3. <strong>Profile sampling:</strong> <code>seed = DeterministicSeed()</code> provided by <code>modBootstrap</code> → <code>rng = DeterministicRNG(seed)</code> → <code>sample = rng.shuffle(candidateRows).slice(0,n)</code> → compute metrics with <code>SafeRound</code> → <code>profileHash = BuildParamsHash(profile)</code> → call <code>CreateTempEvidenceBundle</code> & record audit <code>dq_profile</code> referencing <code>profileHash</code>. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Telemetry & metric naming (required)</strong><br>Canonical metrics: <code>util.atomic_write.duration_ms</code>, <code>util.atomic_write.attempts</code>, <code>util.atomic_write.degraded</code>, <code>util.checksum.duration_ms</code>, <code>util.retry.attempts</code>, <code>util.lock.acquire_ms</code>, <code>util.evidence.bundle.created</code>, <code>util.canonical_json.hash</code>. All include <code>module=CORE_Utilities</code> tag and optional <code>correlationId</code>. Telemetry is buffered locally and exported by <code>modTelemetry</code> outside UI path. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Security & forbidden operations</strong><br>- <strong>Forbidden:</strong> direct plaintext secret reads in utilities; synchronous network calls from ribbon/UI path; writing unredacted PII to logs or audit rows. <br>- <strong>Enforced:</strong> static analysis in CI forbids blacklisted APIs (raw sockets, direct KMS calls unless via <code>modSecurity</code>, direct Workbooks access inside <code>OnLoad</code> paths). <br>- <strong>Secrets:</strong> use <code>modSecurity</code> for any cryptographic or KMS operations; evidence encryption always via KMS/HSM. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Performance SLOs & budgets (practical)</strong><br>Targets (examples): <code>AtomicWrite</code> median <200ms for <1MB local disk; <code>ComputeChecksum</code> throughput ≥200MB/s on workers; <code>SafeRound</code> and small numeric ops <1ms; <code>CanonicalJsonSerialize</code> <50ms for 10KB object. Heavy work must be offloaded; CI enforces microbenchmarks to detect regressions. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>CI & test matrix requirements</strong><br>1. Unit tests per function + error branches. <br>2. Property tests for determinism (same inputs/seeds -> same outputs). <br>3. Cross-platform parity (Windows x86/x64, macOS). <br>4. Golden vectors for <code>SafeRound</code>, RNG sequences, and canonical JSON. <br>5. Fuzz tests for parsers & redaction. <br>6. Performance microbenchmarks to gate regressions. <br>7. Static analysis forbids unsafe APIs. <br>8. Release artifacts include <code>util_api.md</code>, <code>safe_round_vectors.csv</code>, <code>rng_golden_vectors.txt</code>. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Failure modes, diagnostics & triage checklist</strong><br>1. <strong>AtomicWrite fail / degraded on SMB:</strong> collect <code>util.atomic_write</code> telemetry, staged-local fallback files, temp files in temp dir, evidence bundle of temp artifacts, and <code>config.hash</code> for context; escalate to SRE if repeated. <br>2. <strong>Checksum mismatch after move:</strong> Collect <code>ComputeChecksum</code> logs for both sides, temp files, evidence bundle, and job descriptors; run <code>VerifyChecksum</code> and consult <code>ArtifactCatalog</code> for last-known-good. <br>3. <strong>Non-idempotent op retried:</strong> inspect <code>IdempotencyStore</code>, DLQ, and job descriptors; requeue safely after idempotency token verification. <br><strong>Artifacts to attach:</strong> <code>atomic_write</code> temp/target files, temp evidence bundle, <code>forensic_manifest.json</code> listing sha256s, <code>CORE_Utilities</code> logs, config snapshot. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Change-control & backward-compatibility policy</strong><br>- Breaking changes require major version bump + migration manifest explaining behavioral differences and golden delta. <br>- Minor changes preserve signatures; deprecations announced and adapters provided where feasible. <br>- <code>OWNERS.md</code> must include <code>CORE_Utilities</code> owners and reviewers. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Appendices & artifacts to ship with the module</strong><br>Ship with: <code>util_api.md</code> (detailed signatures), <code>ErrorCodeCatalog_UTIL.md</code>, <code>canonical_json_spec.md</code>, <code>safe_round_vectors.csv</code> (golden vectors), <code>atomic_write_compat.md</code> (SMB/NFS notes), <code>vba_wrappers/Utilities.bas</code>, <code>rng_golden_vectors.txt</code>, CI microbench harness, and owners entry in <code>OWNERS.md</code>. Store under immutable artifact store and record <code>CORE_Utilities.hash</code> in release manifest. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Release acceptance checklist (must pass)</strong><br>1. Unit + property + cross-platform parity tests green. <br>2. Golden vectors unchanged or migration manifest accepted. <br>3. Performance microbenchmarks within SLOs. <br>4. No forbidden API usage by static analyzer. <br>5. Telemetry keys documented. <br>6. <code>OWNERS.md</code> updated. <br>7. Release manifest signed. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Operator quick-reference (do / don't)</strong><br>DO: Always use <code>AtomicWrite</code> + <code>ComputeChecksum</code> for persisted artifacts; use <code>WithRetry</code> for transient ops with seeded jitter for reproducible CI runs; capture <code>seed</code> in encrypted evidence when determinism matters; validate external paths with <code>ValidatePathTrusted</code> before exporting regulated artifacts. <br>DO NOT: call heavy checksum or large-file ops on UI thread; log unredacted PII; use utilities to read secrets directly. </td></tr><tr><td data-label="modUtilities — Per-function Expert Technical Breakdown"> <strong>Final note (module owner obligations)</strong><br>Owners must provide: API docs, cross-platform parity report, golden vectors, <code>OWNERS.md</code> entries, migration manifest for breaking changes, and CI evidence (unit/property/perf). Owners must respond to incident traces referencing <code>CORE_Utilities</code> telemetry and evidence bundles and maintain the module's acceptance criteria. </td></tr></tbody></table></div><div class="row-count">Rows: 62</div></div><div class="table-caption" id="Table9" data-table="Docu_0176_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Profile — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Profile — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong>Overview (module-level contract, invariants, and scope)</strong><br><strong>Authority & scope:</strong> <code>DQ_Profile</code> is the canonical profiling engine used by DQGuard.xlam. Its responsibilities are detection-first profiling, deterministic sampling, explainable metric computation, PII-aware evidence handling, canonical manifest generation, atomic persistence of artifacts, audit anchoring, and integration points for job scheduling and worker execution. Non-responsibilities: business allocation, remediation application, external system mutation, or secret management. Those belong to <code>modRemediation</code>, <code>modExport</code>, or <code>modSecurity</code> respectively.<br><strong>High-level invariants:</strong><br>1. Determinism: identical inputs + <code>configHash</code> → identical <code>profileHash</code> and artifacts. <br>2. Non-destructive by default: profiling reads only; applyMode required for destructive operations. <br>3. Audit-first: every user-initiated profile run appends <code>dq_profile</code> audit with <code>correlationId</code>. <br>4. PII-safe: UI-visible artifacts are redacted by default; full evidence stored encrypted and gated. <br>5. Host-aware: runtime must respect Excel host constraints (UI thread budgets, 32-bit memory). <br><strong>Primary integration points:</strong> <code>modRibbonCallbacks</code> (entry), <code>JobSchedulerIntegration</code> (heavy runs), <code>modExport</code> (atomic persistence), <code>modAudit</code> (audit writes), <code>modConfig</code> (thresholds, sampling), <code>EnsureDeps</code> (runtime dependencies). <br><strong>Evidence artifacts produced:</strong> <code>profile_report.csv</code>, <code>profile_summary.json</code>, <code>sample.csv</code>, <code>profile_manifest.json</code>, <code>evidence_package.enc</code> (encrypted, on approval). <br><strong>Key telemetry/metrics:</strong> <code>dq_profile.duration_ms</code>, <code>dq_profile.persist_latency_ms</code>, <code>dq_profile.timeout_rate</code>, <code>dq_profile.audit_append_latency_ms</code>. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileTable(tableRef, options)</code> — orchestrator (expanded)</strong><br><strong>Purpose & contract:</strong> authoritative entry for profiling a single table-like artifact. Must validate table existence and scope, compute deterministic seed, choose sampling strategy, invoke per-column metric pipeline, assemble the canonical profile manifest, compute <code>profileHash</code>, persist artifacts via <code>PersistProfileArtifacts</code>, and emit <code>dq_profile</code> audit anchor. Must be idempotent for identical inputs and return stable <code>ProfileDescriptor</code> and human-friendly status hints. <br><strong>Parameters:</strong> <code>tableRef</code> (opaque handle: <code>workbookId|sheet|tableName or queryFingerprint</code>), <code>options</code> (<code>{sampleSize, sampleStrategy, seed?, runId?, applyMode?, maxColumns?, includePatterns?, evidencePolicy, outputDest?}</code>). <br><strong>Return contract:</strong> synchronous quick-return for inline/light runs: <code>ProfileDescriptor</code> object; for scheduled runs: immediately return <code>{status:&quot;scheduled&quot;, jobId, runId}</code> and persist job descriptor. Do not raise host-visible unhandled exceptions; map to <code>ErrorCodeCatalog</code> and return structured errors. <br><strong>Step-level responsibilities & ordering (must/shall):</strong><br>1. <code>PreflightChecks</code> — validate config, table accessibility, operator permissions, and storage availability. <br>2. <code>EstimateProfileCost</code> — lightweight estimator to decide inline vs scheduled. <br>3. If inline & within budget → run synchronous pipeline with <code>SafeProfileTimeoutWatchdog</code>. <br>4. If heavy → create <code>jobDescriptor</code> and call <code>JobSchedulerIntegration</code> persist path; emit <code>job.persisted:&lt;jobId&gt;</code>. <br>5. After compute → <code>AssembleProfileDescriptor</code> and <code>PersistProfileArtifacts</code>. <br>6. Emit <code>dq_profile</code> audit row with <code>paramsHash</code> and <code>evidenceRef</code> (when present). <br><strong>Observability & auditing:</strong> include <code>correlationId</code>, <code>runId</code>, <code>profileId</code>, <code>profileHash</code>, <code>configHash</code>, <code>estimatedCost</code>, <code>startTs</code>, <code>endTs</code>, <code>duration_ms</code>, <code>status</code>, and <code>artifacts</code>. <br><strong>Failure modes:</strong> preflight fail → immediate error with <code>userHint</code> and <code>dq_profile.preflight.failed</code>; job persist fail → fallback local staging and <code>dq_profile.persist.fallback</code>; audit append fail → buffer and later flush, marking run <code>degraded</code>. <br><strong>Developer & host guidance:</strong> avoid workbook-level enumerations on UI thread during bootstrap; use deferred <code>Application.OnTime</code> or worker process for heavy listings. <br><strong>Tests & CI:</strong> unit for preflight, golden benchmarks for end-to-end runs, load tests for cost estimator and inline budget enforcement. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>PreflightChecks(tableRef, options)</code> — safety & resource gating</strong><br><strong>Purpose & contract:</strong> verify run feasibility before heavy work. Deterministic checks include: table existence and read permission, estimated row/column counts (fast estimate), <code>modConfig</code> presence and <code>configHash</code>, export destination writeability, audit append path availability, evidence store connectivity (or staged fallback). Return <code>{ok:bool,issues:[{code,msg}],tableStats}</code>. <br><strong>Checks & priority:</strong><br>- Fast metadata fetch (rows, cols, column headers). <br>- Detect presence of PQ mashup or query-binding (if present mark <code>mayRequireWorker</code>). <br>- Permissions (operator allowed to profile this dataset?). <br>- Disk/Export path free space threshold. <br><strong>Behavior on failure:</strong> do not proceed; return structured error and emit <code>dq_profile.preflight.failed</code> audit. <br><strong>Tests:</strong> negative scenario (missing sheet), permission denied, export path readonly. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>EstimateProfileCost(tableStats, options)</code> — policy-driven estimator</strong><br><strong>Purpose & contract:</strong> compute <code>{estimatedCost,estimatedDurationMs,rationale}</code> using deterministic rules and <code>modConfig</code> thresholds. Inputs: <code>tableStats</code> (<code>rowCount,colCount,approxCellSize,hasLongText</code>), options. Output used by caller to decide inline vs scheduled. <br><strong>Rules:</strong> thresholding by rowCount, columnCount, presence of BLOBs/long text columns, PQ transforms, or complex regex scans. Consider memory footprint: estimatedCells * avgCellBytes. Add safety margin for 32-bit hosts. <br><strong>Audit & telemetry:</strong> emit <code>dq_profile.costEstimate</code> for decision tracing. <br><strong>Tests:</strong> boundary tests near thresholds, table mixes with text & numbers, PQ-bound inputs. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputeSamplingSeed(tableRef, options, configHash)</code> — deterministic non-PII seed</strong><br><strong>Purpose & contract:</strong> produce stable 64-bit seed using keyed HMAC-SHA256 over table fingerprint, <code>configHash</code>, and <code>runId</code>/optional seed. This ensures reproducible sampling across runs with same config while not including raw PII. Return integer seed plus provenance (<code>seedSource</code>). <br><strong>Security & privacy:</strong> avoid including raw cell values. Use truncated HMAC output; document key-derivation source (<code>modBootstrap.correlationSeed</code> or KMS-backed key fingerprint). <br><strong>Tests:</strong> reproduce seed across repeated calls, collision probability checks for typical corpus. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SampleRows(tableRef, sampleSize, seed, strategy)</code> — deterministic sampler</strong><br><strong>Purpose & contract:</strong> support reservoir sampling (streaming), stratified sampling (by key/fingerprint), topRows, and full. Guarantees reproducibility: same seed + same canonical ordering → same sample. Return <code>SampleArtifact</code> with <code>sampleRows</code>, <code>sampleHash</code>, <code>sampleMethod</code>, <code>sampleSeed</code>, and <code>isSanitized</code> flag. <br><strong>Memory & streaming:</strong> for large inputs stream via windowed reads rather than load-full to avoid memory blowouts in 32-bit Excel; use reservoir algorithm for streaming deterministic sample. For stratified sampling require explicit stratify key; fallback to hashed-bucketing with deterministic tie-breakers. <br><strong>PII handling:</strong> sanitized sample by default (mask or tokenization); unsanitized sampling requires explicit <code>evidencePolicy</code> approval and encrypted storage. <br><strong>Tests:</strong> reservoir invariants under deterministic seed, stratified group proportion tests, sampling stability across small re-orderings only if canonical sort key present. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CanonicalizeTableOrdering(tableRef)</code> — ensure stable iteration order</strong><br><strong>Purpose & contract:</strong> many sampling and deterministic algorithms require canonical row order. For host tables where row order may change, produce canonical ordering key (primaryKey if available) or fallback to <code>(rowIndex)</code> augmented by sort-of-values. Document requirement: if input has no stable key, the module must log a warning and include note in profile manifest. <br><strong>Behavior:</strong> returns canonical ordering descriptor and (optionally) a sorted iterator. Must never alter source data. <br><strong>Tests:</strong> known-key, no-key, duplicate-keys scenarios. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputeColumnMetrics(columnData, columnSpec, config)</code> — per-column metric engine (detailed)</strong><br><strong>Purpose & contract:</strong> deterministic computation of a rich set of column-level metrics. Output includes: <code>typeGuess</code>, <code>nullCount</code>, <code>distinctCount</code> (exact or approx with HLL summary), <code>topNValues</code> (with stable tie-break), <code>histogram</code>, <code>min/max</code>, <code>mean/median/stddev/mad</code> (robust), <code>lengthDistribution</code>, <code>patternFrequencies</code>, <code>formatConfidence</code> (date/currency), <code>entropy</code>, <code>nullRate</code>, <code>approxDistinctSketch</code> (HLL parameters), and <code>outlierCandidates</code>. Each metric accompanied by <code>isApproximate:boolean</code> and <code>errorBounds</code> when applicable. <br><strong>Numeric handling & SafeRound:</strong> numeric aggregates use configured deterministic rounding (<code>SafeRound</code>): consistent decimal places across locales; avoid floating variance by using integer-backed accumulation (Kahan or decimal) where feasible. For medians, use selection algorithm that is deterministic given canonical order. <br><strong>String handling:</strong> compute normalized forms (Unicode NFC/NFKC), trimming, collapsing whitespace for metrics; preserve original for sample rows. Pattern frequency uses precompiled regex list from <code>modConfig</code>. <br><strong>Cardinality estimation:</strong> use HLL with documented <code>p</code> parameter; include <code>approxErrorPct</code>. If column small (below threshold), compute exact distinct via set. <br><strong>Top N determinism:</strong> for equal frequency tie-break use lexicographic order after normalization, then deterministic rowFingerprint. <br><strong>Outlier detection per column:</strong> support MAD/IQR/robust-z; produce <code>score</code> and rationale. Outliers flagged but not auto-corrected. <br><strong>Performance:</strong> parallelize across columns where host allows (worker threads or worker runner) but preserve deterministic ordering of results in the manifest. <br><strong>Tests:</strong> numeric precision tests, HLL accuracy vectors, deterministic topN and tie-break checks, pattern recall/precision. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>BuildHistogram(values, numericBinningConfig)</code> — deterministic histogram builder</strong><br><strong>Purpose & contract:</strong> produce histograms using fixed-width, quantile bins, or Freedman–Diaconis. Return explicit <code>binEdges[]</code>, <code>counts[]</code>, <code>method</code>, and <code>sampleBins</code> where appropriate. For strings return top-K plus "other" bucket. Include explanation of method and rationale in manifest. <br><strong>Edge handling & zeros:</strong> exact zero-count bins preserved. Document bins in profile manifest for reproducibility. <br><strong>Tests:</strong> quantile reproducibility, sparse & dense distributions. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DetectOutliers(columnProfile, method, thresholds)</code> — explainable detector</strong><br><strong>Purpose & contract:</strong> apply chosen method(s) (IQR, MAD, modified z, rule-based bounds) and return <code>outlierDescriptors</code> with <code>rowFingerprint</code>, <code>colName</code>, <code>score</code>, <code>method</code>, and textual <code>rationale</code>. The function must be conservative by default and include <code>confidence</code> level. Outlier candidates are advisory and are used by <code>modRemediation</code> when building proposals. <br><strong>Escalation & PII:</strong> if outlier values likely contain PII (pattern matches), mark <code>mayContainPII</code> and route evidence to encrypted store. <br><strong>Tests:</strong> targeted injection, recall/precision, sensitivity sweeps. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputePatternFrequencies(columnStrings, regexList, ngramConfig)</code> — structural discovery</strong><br><strong>Purpose & contract:</strong> detect structural patterns (dates, emails, phone, currency, IBAN-like, credit-like) using curated regexes plus n-gram frequency for free text. Output includes <code>patternSummary</code> with <code>patternFingerprint</code>, <code>matchCount</code>, <code>sampleMatches</code> (sanitized), and <code>mayContainPII</code> flag. Include <code>patternConfidence</code>. <br><strong>PII & compliance:</strong> patterns that trigger <code>mayContainPII=true</code> must cause <code>EmitProfileAudit</code> to set <code>sensitivity=true</code> and require encryption for full evidence. <br><strong>Tests:</strong> pattern false positive suppression, locale-specific date detection. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DetectDuplicatesAndKeys(profileContext)</code> — duplicate/key heuristics</strong><br><strong>Purpose & contract:</strong> identify candidate primary keys, near-keys, and duplicate clusters using deterministic heuristics (null fractions, uniqueness ratio, entropy). Return <code>keyCandidates[]</code> and <code>duplicateGroups</code> with <code>groupId, size, exampleRows</code>. Provide confidence and rationale. Avoid full O(N^2) comparisons on large sets; use hashing + blocking. <br><strong>Use:</strong> outputs feed <code>modMatchMerge</code> and operator guidance. <br><strong>Tests:</strong> synthetic key detection, high-cardinality skew. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ColumnCorrelationAnalysis(columns[], method=&quot;pearson/spearman/chi2&quot;)</code> — cross-column metrics</strong><br><strong>Purpose & contract:</strong> compute pairwise correlations relevant for detecting functional dependencies, possible composite keys, or improbable value pairs. Return deterministic matrix with <code>metric</code>, <code>pValue</code> (if applicable), and <code>notes</code>. For categorical pairs use contingency tables with chi-square. For large column sets throttle analysis by <code>maxPairs</code> config. <br><strong>Privacy:</strong> do not emit cell values in correlation output; only aggregated metrics and safe examples. <br><strong>Tests:</strong> known-correlated fixtures, guard against statistic misinterpretation for sparse data. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>AssembleProfileDescriptor(runId, tableMeta, columns[], artifacts[])</code> — canonical manifest</strong><br><strong>Purpose & contract:</strong> canonical JSON manifest construction with stable field ordering and normalized scalar formatting (dates in ISO8601, numbers normalized). Include: <code>moduleVersion</code>, <code>profileSchemaVersion</code>, <code>configHash</code>, <code>ribbonMapHash</code>, <code>runId</code>, <code>profileId</code>, <code>profileHash</code>, <code>tableFingerprint</code>, <code>columns[]</code> (each with <code>columnProfileHash</code>), <code>artifacts</code>, <code>metricsSummary</code>, <code>sensitivityFlags</code>, <code>prevHash</code> (if available), and <code>evidenceRef</code>. Compute <code>profileHash = SHA256(canonicalizedJson)</code>. Return manifest and <code>profileHash</code>. <br><strong>Determinism & stability:</strong> canonicalization rules documented and used in CI golden parity tests. <br><strong>Tests:</strong> canonicalization parity across locales/encodings, stable-hash checks. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>PersistProfileArtifacts(profileDescriptor, artifacts, destination)</code> — atomic output & fallback</strong><br><strong>Purpose & contract:</strong> persist artifacts using <code>modExport</code> atomic-write semantics (write to temp then rename). Each artifact must have <code>artifact.checksum.sha256</code>. If remote persist fails, fallback to staged local area with controlled TTL and emit <code>dq_profile.persist.fallback</code> with <code>fallbackPath</code>. On partial failure perform deterministic cleanup of partially written temp files and surface coherent error with remediation hints. Ensure artifacts created with correct permissions and do not leak PII in filenames or metadata. <br><strong>Retries & idempotency:</strong> bounded retry with exponential backoff; idempotent writes must not overwrite existing artifact unless overwrite approval set. <br><strong>Tests:</strong> atomic write semantics, network-failure fallback, permission error handling, checksum validation. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>EmitProfileAudit(correlationId, profileDescriptor, params, evidenceRef?)</code> — canonical audit anchor & evidence linking</strong><br><strong>Purpose & contract:</strong> append authoritative <code>dq_profile</code> audit row. Redact sensitive params; compute <code>paramsHash</code>; store full sanitized params in encrypted evidence store (if needed) returning <code>evidenceRef</code>. Required fields: <code>timestamp,correlationId,module=DQ_Profile,procedure=dq_profile,userId,profileId,profileHash,paramsHash,configHash,artifacts,prevHash,metadata</code>. Audit append must be non-blocking and resilient: buffer-and-retry on transient failure. On final failure escalate to SRE with <code>dq_profile.audit.fail</code>. <br><strong>Evidence policy:</strong> evidence store encryption by KMS/HSM; access requires approvals. Audit rows only carry <code>paramsHash</code> and <code>evidenceRef</code>. <br><strong>Tests:</strong> audit schema validation, prevHash chaining, evidence reference resolution. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CompareProfiles(oldProfile, newProfile, diffOptions)</code> — deterministic diffs & regressions</strong><br><strong>Purpose & contract:</strong> compute structured diffs between profiles: column-level metric deltas, added/removed columns, <code>regressionFlags</code> (e.g., drop in cardinality, spike in nulls), and <code>riskScore</code>. Return <code>ProfileDiff</code> with <code>diffHash</code>, <code>explainableChanges[]</code>, and suggested <code>nextActions</code>. Designed for CI golden checks and canary gating where regression thresholds are enforced automatically. <br><strong>Use in gating:</strong> diff used by <code>CI/golden</code> to block PRs when regulated fixtures change beyond approved thresholds. <br><strong>Tests:</strong> golden diff tests, sensitivity & false-positive tuning. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SanitizeAndEvidence(params, sensitiveColumns, approval)</code> — redaction & encrypted evidence workflow</strong><br><strong>Purpose & contract:</strong> produce sanitized artifacts for UI and store full sanitized evidence in encrypted evidence store when required. Sanitization strategies: masking (<code>&lt;REDACTED&gt;</code>), tokenization (deterministic tokens mapping original -> token via hashed salt), deterministic hashing for safe reference, or partial redaction for structural verification. Evidence upload returns <code>evidenceRef</code> and <code>evidenceChecksum</code>. Evidence access audit trail captured. <br><strong>Governance:</strong> storing full evidence that includes regulated PII requires two-person approval and justification ticket id captured in audit. <br><strong>Tests:</strong> redaction completeness, token mapping determinism, evidence encryption integrity. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SafeProfileTimeoutWatchdog(token, correlationId, runContext)</code> — time budgets & cancellation</strong><br><strong>Purpose & contract:</strong> enforce cooperative time budgets. On overrun: emit <code>dq_profile.timeout</code> with partial <code>profileHash</code> if available, set cancellation token for worker/handler, attempt graceful shutdown, and if handler fails to exit append <code>dq_profile.hung</code> and capture stack snapshot if host supports. Watchdog scheduling must avoid blocking UI thread; use <code>Application.OnTime</code> for VBA. <br><strong>Retries:</strong> allow a controlled coherent shutdown window before force termination. <br><strong>Tests:</strong> forced overrun, cancellation propagation, partial artifact behavior. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>RegisterProfileUnitTestHook(hookName, fixedRunId)</code> — CI/golden harness</strong><br><strong>Purpose & contract:</strong> provide deterministic test harness hooks for CI: register simulated table input or replay recorded fixtures with fixed <code>correlationId</code>/<code>runId</code> and deterministic seeds. Hooks disabled in production by default and guarded by <code>testMode</code> flag. Registration emits <code>dq_profile.test.hook.registered</code> audit. <br><strong>CI usage:</strong> golden parity runs use hooks to ensure fixed runtime context and deterministic outputs for acceptance tests. <br><strong>Tests:</strong> ensure hooks do not leak into production and registration enforcement validated in CI. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileHealthCheck()</code> — lightweight readiness & diagnostics</strong><br><strong>Purpose & contract:</strong> run a set of non-invasive checks: <code>modConfig</code> load, <code>modExport</code> write test (temp file), audit append test (non-persistent test row with <code>test=true</code>), RNG/crypto sanity, evidence store connectivity (read-only probe), and available memory estimate. Return <code>{ok:bool,issues[]}</code> and emit <code>dq_profile.health</code>. Should be called in CI gating and as SRE readiness probe. <br><strong>Tests:</strong> CI health gating; fail fast on missing dependencies. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>BuildUiPreview(sampleArtifact, sensitiveColumns, maxRows)</code> — UI preview builder</strong><br><strong>Purpose & contract:</strong> build operator-facing preview: up to <code>maxRows</code> sanitized sample rows, column metric summaries, and concise recommendations. Must redact PII in preview. Should be optimized for minimal UI latency; heavy pages precomputed on worker. Preview must include <code>correlationId</code> and <code>profileId</code> for triage. <br><strong>UI ergonomics:</strong> include "copy diagnostics" button that exports full evidence reference after approval. <br><strong>Tests:</strong> preview redaction, UI latency microbenchmarks, preview fidelity against artifacts. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileErrorMapping(err)</code> — consistent error mapping</strong><br><strong>Purpose & contract:</strong> convert internal exceptions into stable <code>ErrorCodeCatalog</code> entries with <code>userHint</code> (UI-safe) and <code>sreHint</code> (diagnostic). Do not include PII in <code>userHint</code>. On high severity map to <code>dq_profile.exception</code> audit with <code>correlationId</code> and <code>sreHint</code> encrypted where necessary. <br><strong>Examples:</strong> storage permission -> <code>ERR_PROFILE_EXPORT_403</code>; HLL algorithm failure -> <code>ERR_PROFILE_CARDINALITY_500</code>. <br><strong>Tests:</strong> map thrown exceptions to codes and ensure UI-safe messages. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileTelemetryEmit(metrics)</code> — local buffering & audited uplink hooks</strong><br><strong>Purpose & contract:</strong> collect runtime metrics into local buffer; uplink performed by separate <code>modTelemetry</code> uploader. Metrics include <code>dq_profile.duration_ms</code>, <code>dq_profile.percent_inline</code>, <code>dq_profile.persist.latency_ms</code>, <code>dq_profile.timeout_rate</code>. Must not make remote calls during ribbon path; emit to local store only and tag with <code>correlationId</code>. <br><strong>Tests:</strong> buffer durability and uploader compatibility. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileRetentionHousekeeping()</code> — artifact lifecycle management</strong><br><strong>Purpose & contract:</strong> enforce retention policies: hot=30d, warm=7y (or regulatory override), cold=per regulation. Periodically validate checksums and remove/gate evidence with RBAC. Emit <code>dq_profile.housekeeping</code> audit entries for deletion and archival. <br><strong>Governance:</strong> archivals require signed manifest; evidence deletion must be auditable. <br><strong>Tests:</strong> retention enforcement, deletion audit. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DeveloperNotes &amp; host-specific guidance</code> — VB/VSTO/PQ guidance</strong><br><strong>VBA/VSTO:</strong> avoid loading entire large worksheet on UI thread; stream reads using windowed <code>Range</code> calls; use <code>Application.OnTime</code> to schedule work; offload heavy computations to an isolated worker executable or background COM worker. Provide <code>CancellableToken</code> patterns for long-running loops. <br><strong>Power Query (PQ):</strong> prefer to export mashup results to a hidden sheet for profiling; scanning <code>Workbook.Queries</code> or performing heavy PQ template validation should be scheduled deferred. Always verify <code>mChecksum</code> for PQ templates. <br><strong>Excel bitness:</strong> document 32-bit memory limits and required fallbacks (worker runner with offloaded job). <br><strong>Tests:</strong> host integration tests across Excel 32/64-bit and Windows/Office builds. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Security, PII &amp; evidence governance (profile)</code> — enforced rules</strong><br><strong>Principles:</strong> never persist unredacted PII in plaintext; encrypted evidence store with KMS/HSM-backed keys; evidence access logged and gated by approval, <code>evidenceRef</code> recorded in audit. <code>SanitizeAndEvidence</code> must perform deterministic tokenization for re-identification only via authorized workflow. Compromise or suspicious exposure triggers containment playbook: set exports read-only, forensic export, and notify Compliance. <br><strong>Tests:</strong> static analyzer forbids direct PII writes; evidence encryption & approval flow tests. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CI &amp; Golden Governance for profile</code> — required tests & gates</strong><br><strong>Required CI checks:</strong> unit tests for metrics and canonicalization, integration tests (end-to-end profile → manifest → profileHash), golden parity tests across supported locales and Excel bitness, audit chain verification for sample runs, performance microbenchmarks, and forbidden API detection. <br><strong>Gating rules:</strong> regulated fixtures must have migration manifest and compliance sign-off to change outputs; golden mismatch blocks merges by default. <br><strong>Tests:</strong> golden-run generation and CI reproducibility. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Failure modes &amp; incident runbook</code> — canonical incidents & mitigation</strong><br><strong>Common failure modes & mitigations:</strong><br>1. Audit append failure → buffer and retry, mark run <code>degraded</code>, notify SRE if persistent. {audit:dq_profile.audit.fail}<br>2. Artifact persist failure (remote) → fallback to staged local with TTL and emit <code>dq_profile.persist.fallback</code>; operator must re-export. <br>3. Non-deterministic profileHash → treat as regression: record <code>forensic_manifest</code>, run <code>ProfileHealthCheck</code>, and run golden comparators; block releases if regulatory. <br>4. PII leak in preview/sample → immediate containment: set evidence read-only, export forensic bundle, notify Compliance, and create incident with <code>forensic.export</code>. <br><strong>Forensics artifacts:</strong> <code>profile_report.csv</code>, <code>profile_summary.json</code>, <code>sample.csv</code>, <code>profile_manifest.json</code>, <code>config.json</code>, <code>audit_tail.csv</code>, <code>modConfig.configHash</code>, release manifest. <br><strong>Runbook steps (triage):</strong> capture <code>correlationId</code> → retrieve <code>dq_profile</code> audit row → collect artifacts & evidence → run VerifyAuditChain → restore from signed baseline or re-run profile on sanitized copy → publish remediation audit. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Operator recovery checklist</code> — practical steps</strong><br>1. Capture <code>correlationId</code> immediately. <br>2. Inspect <code>audit_tail.csv</code> for <code>dq_profile</code>/<code>dq_profile.error</code>/<code>dq_profile.persist.fallback</code>. <br>3. Check staged fallback path and <code>modExport</code> logs for artifact availability. <br>4. For hash mismatches collect profile artifacts + <code>config.json</code> and produce <code>forensic_manifest.json</code>. <br>5. For suspected PII exposure, follow containment: read-only exports, forensic export, Compliance notification. <br><strong>Quick commands:</strong> <code>diagnostics collect --run-id &lt;id&gt;</code>, <code>audit flush --immediate --correlation &lt;id&gt;</code>, <code>exports stage-local --artifact &lt;id&gt;</code>. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Acceptance criteria &amp; release gates (profile)</code> — dev/CI checklist</strong><br>1. Unit + integration + golden tests pass. <br>2. <code>dq_profile</code> audit emitted and <code>VerifyAuditChain</code> passes on sample runs. <br>3. Deterministic <code>profileHash</code> parity for canonical fixtures. <br>4. No forbidden API references in main path (static analyzer). <br>5. Performance budgets met on CI synthetic load for inline runs and job persist latency. <br>6. Evidence encryption + approval flows validated for PII-containing runs. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Performance budgets &amp; SLOs</code> — targets & remediation</strong><br><strong>Suggested budgets:</strong> inline median <50ms for tiny tables (<100 rows), inline soft-budget <2s up to 10k rows, default inline watchdog 5s; job persist latency <2s for job descriptor persistence; artifact persist latency SLO <10s when network available. <br><strong>Remediation:</strong> throttle UI, offload to jobs, increase sampling, or run in worker. <br><strong>Metrics:</strong> <code>dq_profile.duration_ms</code>, <code>dq_profile.persist.latency_ms</code>, <code>dq_profile.timeout_rate</code>, <code>dq_profile.audit_append_latency_ms</code>. <br><strong>Tests:</strong> load test harness for synthetic large inputs and worker fallback verification. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Operator UX &amp; triage notes</code> — recommended UI elements</strong><br>1. Always display <code>correlationId</code> in UI and copy-to-clipboard action. <br>2. Provide "Download Diagnostics" which packages <code>profile_manifest</code>, <code>sanitizedSample</code>, <code>auditRowRef</code>. <br>3. Offer "Preview with Redaction" by default and "Request Evidence (requires approval)" button for full sample. <br>4. Show simple risk indicators: <code>sensitivity:low|medium|high</code>, <code>estimatedCost</code>, <code>recommendedAction:Review/RequestEvidence/ScheduleJob</code>. <br><strong>Triage flow:</strong> operator provides <code>correlationId</code> → support retrieves audit row and artifacts → replays in isolated runner if needed → escalate to SRE with forensic package. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Appendices — schemas, templates, owners</code></strong><br>Include canonical schemas for <code>profile_summary.json</code> and <code>profile_report.csv</code> (field order must be stable), <code>ErrorCodeCatalog.md</code> entries for <code>ERR_PROFILE_*</code>, migration manifest template, evidence store playbook, <code>OWNERS.md</code> mapping for <code>DQ_Profile</code> (owner, backup, on-call), and <code>profileSchemaVersion</code> change logs. Store under immutable artifact store path <code>\\artifacts\DQGuard\DQ_Profile\v{major}.{minor}\appendices\</code>. <br><strong>Owners & responsibilities:</strong> record owner, backup, and on-call in <code>OWNERS.md</code> and link in release manifest for compliance. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong>Verification performed across nine critical dimensions:</strong> determinism (seed/sample/hash), audit coverage (audit row schema & prevHash), PII and evidence handling (SanitizeAndEvidence + approvals), inline vs scheduled decision flow (Estimator + JobScheduler), canonical manifest hashing (stable JSON canonicalization), atomic persistence semantics (modExport), watchdog & cancellation (timeouts and graceful shutdown), CI/golden gating (tests & golden parity), and operator recovery & incident runbook completeness. Each function includes observability anchors (<code>correlationId</code>, <code>configHash</code>, <code>profileHash</code>) for traceability and forensic reconstruction. </td></tr></tbody></table></div><div class="row-count">Rows: 35</div></div><div class="table-caption" id="Table10" data-table="Docu_0176_10" style="margin-top:2mm;margin-left:3mm;"><strong>Table 10</strong></div>
<div class="table-wrapper" data-table-id="table-10"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Rules — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Rules — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Module Purpose & Scope (canonical)</strong><br><code>DQ_Rules</code> is the authoritative, deterministic rule engine for DQGuard. Responsibilities: ingest/validate/authorize rule manifests; compile rule expressions into sandboxed artifacts; build runtime indices and dependency graphs; evaluate record-level and dataset-level rules; produce validation artifacts and evidence references; produce remediation hints and handler mapping; integrate with job scheduler for heavy workloads; support safe registration, hot-swap, and migration; enforce RBAC & two-person approvals for destructive/regulatory actions; provide operator diagnostics, telemetry, and CI hooks. <strong>Non-goals:</strong> direct workbook mutation (duty of modRemediation/modExport), secrets storage (modSecurity), remote telemetry upload (audited uploader module). All material actions create append-only audit rows referencing <code>rulesHash</code> and <code>configHash</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Primary Invariants (must / shall)</strong><br>1. <strong>Determinism:</strong> identical inputs + configHash + rulesHash → identical outputs (ordering, tie-breakers, representative selection). Use canonical JSON, seeded RNG, deterministic partitioning. <br>2. <strong>Stable identifiers:</strong> each rule has immutable <code>ruleId</code>; updates change <code>ruleVersion</code> and <code>rulesHash</code>. <br>3. <strong>Auditability:</strong> every user-initiated action and persisted job emits a <code>dq_validation</code> or module audit with <code>correlationId</code>. Evidence artifacts referenced by <code>evidenceRef</code> are encrypted and RBAC-protected. <br>4. <strong>Fail-safe safety:</strong> critical signature/schema errors reject new rule-sets and keep previous active set; regulated rules are fail-closed if signature invalid. <br>5. <strong>No PII in UI:</strong> UI strings and audit <code>userHint</code> fields must not contain PII. Full sanitized evidence stored encrypted with <code>evidenceRef</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Canonical Artifacts & Hashing</strong><br><code>rules.json</code> (canonicalized) → <code>rulesHash = sha256(canonical_json)</code>. <br><code>compiledRules/&lt;rulesHash&gt;/</code> directory holds compiled bytecode/AST plus <code>compileManifest.json</code>. <br><code>validation_report_{runId}.json</code> with <code>reportHash</code>. <br><code>evidence/&lt;evidenceRef&gt;.zip</code> encrypted evidence bundle. <br>All artifacts include <code>artifact.checksum.sha256</code> in metadata and audit rows. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Security & Forbidden APIs (enforced)</strong><br>Disallowed in rules/compilation/runtime: raw file reads/writes; raw sockets; spawning processes; unbounded synchronous disk IO on UI thread; direct COM/Workbook mutation; direct plaintext secret reads; use of OS env sensitive keys. Evidence and token access only via <code>modSecurity.getEphemeralToken()</code> with audit fingerprint. CI static analyzer rejects forbidden constructs and blacklisted API references. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Performance Budgets & SLOs</strong><br>- Inline minimal path median <50ms (UI). <br>- Per-record eval median <10ms for light rules. <br>- Inline handler default timeout 5s; per-rule soft budget (default 50ms). <br>- Job persist latency SLO <2s. <br>Engine must degrade gracefully: sampling, segmenting, or persisting jobs for heavy operations. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>High-Level Function Map</strong><br><code>LoadRuleSet(source)</code> — manifest ingestion & verification.<br><code>ValidateRuleId(ruleId)</code> — canonical guard and metadata lookup.<br><code>CompileRuleExpressions(rule)</code> — parse/compile to sandboxed artifact.<br><code>BuildRuleIndex(ruleSet)</code> — field map, dependency graph, evaluation order.<br><code>EvaluateRecord(ruleIndex,row,context)</code> — record-level deterministic evaluation.<br><code>EvaluateCrossField(ruleIndex,snapshot,context)</code> — dataset-level/windowed rules.<br><code>EvaluateBatch(ruleIndex,snapshot,options)</code> — vectorized orchestrator, sampling & segmentation.<br><code>MapRuleToHandler(ruleId)</code> — remediation mapping and owner resolution.<br><code>SafeInvokeRule(compiledRule,input,cid,token)</code> — guarded helper invocation.<br><code>EmitValidationAudit(cid,summary,evidenceRefs)</code> — canonical audit anchor.<br><code>RegisterRule(ruleJson,operatorId,persist=false)</code> — controlled registration.<br><code>RefreshRules()</code> — live rebind and preview.<br><code>HotSwapRules(newRulesJson,operatorId,approvals)</code> — transactional emergency patching.<br><code>EnableRule/DisableRule</code> — runtime toggles with RBAC.<br><code>ValidateRulePermissions(userId,ruleMeta)</code> — permission checks.<br><code>RuleTestingHarness(hook)</code> — CI deterministic harness.<br><code>SafeRuleTimeoutWatchdog(token,cid)</code> — cooperative cancellation & escalation.<br><code>JobSchedulerIntegration(jobDescriptor)</code> — canonical job persist & handoff.<br><code>Shutdown()</code> — graceful unload & snapshot. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>LoadRuleSet(source)</code> — purpose, contract, steps, pitfalls, and tests</strong><br><strong>Purpose:</strong> deferred ingestion of <code>rules.json</code> or manifest; canonicalize, validate, attach owners, compute <code>rulesHash</code>, verify signature, produce canonical <code>RuleSet</code> internal model. <br><strong>Mandatory invariants:</strong> do not run on UI bootstrap main path; perform work on worker or idle callback; produce audit row <code>rules.load.started</code> and <code>rules.loaded</code>/<code>rules.load.invalid</code>. <br><strong>Deterministic pipeline:</strong> read → sanitize (UTF-8 normalize) → canonicalize (sorted keys, numeric normalization) → JSON Schema v7 validation (full error list) → duplicate <code>ruleId</code> detection with indices → owner resolution from <code>OWNERS.md</code> → signature verification (record <code>signatureFingerprint</code>) → compute <code>rulesHash</code> → precompile smoke-checks (optional) → return <code>RuleSet</code> stub. <br><strong>Fallback policy:</strong> non-critical warnings → <code>rules.loaded.warning</code>; critical schema/signature errors → <code>rules.load.invalid</code> and do not activate. <br><strong>Audits (fields):</strong> <code>correlationId,rulesHash,schemaVersion,signatureFingerprint,ownerMapHash,startTs,duration_ms,warnings[]</code>. <br><strong>Tests/CI:</strong> schema fuzzing, duplicate id negative tests, signature tamper tests, canonicalization round-trip tests, performance for large manifests. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ValidateRuleId(ruleId)</code> — usage, checks, and outputs</strong><br><strong>Purpose:</strong> canonical validation across UI and runtime. <br><strong>Checks:</strong> format regex (length & char set), not in reserved list, present in <code>RuleSet</code>, severity allowed, owner present, regulated flag properly set. <br><strong>Return:</strong> <code>ruleMeta</code> or <code>{errorCode,userHint}</code> where <code>userHint</code> is PII-free. <br><strong>Audit:</strong> append <code>rules.validate</code> (sampled) on failures. <br><strong>Tests:</strong> id fuzzing, alias resolution, ensure <code>userHint</code> redaction. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>CompileRuleExpressions(rule)</code> — grammar, compile-time checks, sandboxing</strong><br><strong>Language capabilities:</strong> typed booleans, numeric ops, date/time normalization, regex, set membership, fuzzy primitives (<code>levenshtein</code>, <code>jaro_winkler</code>), phonetic maps, window constructs (<code>over(partition by .. order by ..)</code>), PQ-M template references (<code>mChecksum</code> validated). <br><strong>Compilation outputs:</strong> deterministic AST/bytecode with <code>compiledFingerprint</code>, <code>referencedFields[]</code>, <code>estimatedCost</code> (light/medium/heavy), <code>requiresWindow</code> bool, <code>explainTemplate</code>, <code>compileWarnings[]</code>. <br><strong>Static security checks:</strong> forbid host APIs; detect regex catastrophic backtracking heuristics; flag nested fuzzy joins; disallow direct PQ runtime network fetches. <br><strong>Sandbox runtime contract:</strong> compiled artifact must run in a sandbox with CPU/time quotas and cancellation token; heavy constructs flagged to offload to job scheduler. <br><strong>Error codes:</strong> <code>ERR_COMPILE_SYNTAX</code>, <code>ERR_FORBIDDEN_API</code>, <code>ERR_COMPILE_COST_HIGH</code>. <br><strong>Tests:</strong> parser fuzz, operator whitelist enforcement, regex complexity stress tests, compile fingerprint stable across runs. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>BuildRuleIndex(ruleSet)</code> — dependency graph & ordering</strong><br><strong>Purpose:</strong> precompute lookup structures to minimize per-row work. <br><strong>Primary outputs:</strong> <code>byField</code> map, <code>bySeverity</code> buckets, <code>byType</code> (record, cross-field, windowed), <code>dependencyGraph</code> (edges when rules depend on other rule outputs), deterministic <code>evaluationOrder</code>. <br><strong>Deterministic tie-breakers:</strong> <code>priority</code> desc → <code>severity</code> (CRITICAL>ERROR>WARN>INFO) → <code>ruleId</code> lexicographic. <br><strong>Cycle handling:</strong> detect cycles; if cycles can be safely broken (non-regulated) use deterministic break; if cycle affects regulated outputs reject with <code>rules.dependency.error</code>. <br><strong>Tests:</strong> cycle detection, ordering stability, index build performance for large rule sets. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateRecord(ruleIndex,row,context)</code> — inline safe evaluation</strong><br><strong>Purpose:</strong> evaluate relevant record-level rules deterministically. <br><strong>Operation:</strong> find candidate rules via <code>byField</code>, execute compiled bytecode in <code>evaluationOrder</code>, apply <code>failFast</code> semantics if configured. Return ordered <code>ValidationResult[]</code> with <code>{ruleId,outcome,severity,evidenceRef?,explainHash,highlights[]}</code>. <br><strong>Budgeting:</strong> enforce per-rule soft budget (50ms default); watcher cancels on overrun and emits <code>dq_rule.timeout</code>. <br><strong>Error handling:</strong> exceptions mapped to <code>DQ_RULE_RUNTIME_*</code> with <code>dq_rule.exception</code> audit and continue unless <code>requiresFailClosed</code>. <br><strong>Redaction:</strong> explain strings sanitized; full raw explain saved to evidence for compliance with access controls. <br><strong>Observability:</strong> emit <code>dq_validation.record</code> sampled, and <code>dq_validation.batch</code> summary with severity counts. <br><strong>Tests:</strong> deterministic ordering, exception injection, redaction verification. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateCrossField(ruleIndex,snapshot,context)</code> — dataset-level & windowed evaluation</strong><br><strong>Purpose:</strong> execute rules requiring table-level context (uniqueness, referential integrity, grouped aggregates, sequence constraints). <br><strong>Snapshot contract:</strong> caller must provide deterministic snapshot (sorted by canonical key). <br><strong>Execution strategies:</strong> in-memory for small snapshots; partitioned deterministic sharding for scale; spill-to-disk deterministic intermediate files for memory constraints; offload to worker via JobSchedulerIntegration for heavy workloads. <br><strong>Tie-breakers & canonical representative selection:</strong> qualityScore → lastModifiedTs → rowId lex. <br><strong>Degraded path:</strong> if memory/time thresholds hit, engine enters <code>degradedMode</code> (sampled outputs) and emits <code>dq_validation.degraded</code>. <br><strong>Evidence & audits:</strong> group-level <code>ValidationResult</code> objects with <code>evidenceRef</code> pointing to sample bundles; <code>dq_validation.crossfield</code> audit summary emitted. <br><strong>Tests:</strong> partition boundary tests, deterministic tie-breaker tests, spill path verification. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateBatch(ruleIndex,snapshot,options)</code> — vectorized driver</strong><br><strong>Options:</strong> <code>mode</code> (<code>inline|job</code>), <code>sample</code> (seed), <code>segment</code> (shardIndex, shardCount), <code>maxRuntime</code>, <code>evidenceSamplingRate</code>. <br><strong>Responsibilities:</strong> orchestrate partitioning, spawn workers or persist job descriptor, aggregate deterministic results, produce <code>ValidationReport</code>, and append <code>dq_validation.batch</code> audit. <br><strong>Idempotency:</strong> job descriptors include stable <code>paramsHash</code> to ensure idempotent persistence; replays produce identical outputs. <br><strong>Failure handling:</strong> partial failures persist partial artifacts; emit <code>dq_validation.partial</code>. Inline runs exceeding budget persist job and return immediate UI-safe message with <code>correlationId</code>. <br><strong>Tests:</strong> shuffle-resilience, sampling parity, large-scale throughput. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>MapRuleToHandler(ruleId)</code> — remediation mapping & owner resolution</strong><br><strong>Purpose:</strong> map rule to remediation suggestions and canonical handler metadata. <br><strong>Return:</strong> <code>{suggestedRemediations:[{type,confidence,previewFn}],primaryHandler,owner,approvalPolicy,regulatedImpact}</code>. <br><strong>Suggestion types:</strong> <code>standardize</code>, <code>replace</code>, <code>flag</code>, <code>merge</code>, <code>drop</code>, <code>manualReview</code>. <br><strong>Approval policies:</strong> <code>none</code>, <code>single-approver</code>, <code>two-person</code>, <code>compliance-required</code>. Destructive remediations require two-person approval for regulated data. <br><strong>Tests:</strong> mapping parity, owner resolution fallback. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>SafeInvokeRule(compiledRule,input,cid,token)</code> — guarded helper execution</strong><br><strong>Purpose:</strong> execute helper transforms or explainers. <br><strong>Frame behavior:</strong> start <code>dq_rule.start</code> audit, enforce time/memory budgets and cancellation token, redact outputs, map exceptions to <code>ErrorCodeCatalog</code>, persist sanitized evidence to evidence store, emit <code>dq_rule.complete</code> or <code>dq_rule.error</code> with <code>payloadHash</code>. Disallow host-level calls. <br><strong>Return:</strong> <code>{status, payloadHash, evidenceRef?, errorCode?}</code>. <br><strong>Tests:</strong> cancellation injection, exception mapping, redaction coverage. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EmitValidationAudit(correlationId,validationSummary,evidenceRefs)</code> — canonical audit & evidence model</strong><br><strong>Purpose:</strong> append authoritative <code>dq_validation</code> audit rows. <br><strong>Schema (required):</strong> <code>timestamp,correlationId,module=DQ_Rules,procedure=validate,runId,rulesHash,configHash,profileHash?,validationSummaryHash,severityCounts,topFailingRules,evidenceRef,prevHash,metadata</code>. <br><strong>Redaction policy:</strong> main audit stores <code>paramsHash</code>/<code>summaryHash</code>; full sanitized evidence placed in encrypted evidence store with <code>evidenceRef</code>. Access controlled; evidence access audited. <br><strong>Tests:</strong> audit schema validation, <code>VerifyAuditChain</code> compatibility. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RegisterRule(ruleJson,operatorId,persist=false)</code> — authoring & controlled registration</strong><br><strong>Purpose:</strong> register/update rule in authoring/staging. <br><strong>Checks:</strong> validate schema & compile-time checks; check forbidden APIs; verify signature for production; ensure owner metadata and <code>requiresApproval</code> enforcement. <br><strong>Idempotency:</strong> identical requests return prior <code>registrationHash</code>. <br><strong>Persistence:</strong> <code>persist=true</code> requires approvals and writes via <code>modExport</code> atomic path; do not persist before smoke tests. <br><strong>Audits:</strong> <code>rules.registered</code> or <code>rules.register.failed</code> with <code>operatorId, beforeHash, afterHash, warnings</code>. <br><strong>Tests:</strong> duplicate detection, RBAC rejection, persistence correctness. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>HotSwapRules(newRulesJson,operatorId,approvals)</code> — emergency transactional patching</strong><br><strong>Purpose:</strong> atomic runtime patch for urgent fixes. <br><strong>Flow:</strong> validate & compile candidate set → compute diff & risk estimate (<code>hotSwap.preview</code>) → run smoke tests using <code>RuleTestingHarness</code> on canonical fixtures → if pass and approvals present, atomically swap in-memory set and update <code>ruleIndex</code> → emit <code>rules.hotswap.applied</code> with <code>beforeHash/afterHash, operatorId, smokeTestSummary, releaseFingerprint</code> → optionally persist via <code>modExport</code>. If smoke tests fail or cancellation occurs revert to prior set and emit <code>rules.hotswap.reverted</code> with diagnostics. <br><strong>Governance:</strong> regulated-rule hot-swaps require multi-person approvals; write-then-test forbidden. <br><strong>Tests:</strong> dry-run, smoke coverage, rollback correctness. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RefreshRules()</code> — live rebind, preview & safety</strong><br><strong>Purpose:</strong> reload rule set with operator preview before activation. <br><strong>Behavior:</strong> compile candidate set → compute <code>diff</code> (added/removed/changed rules) → present <code>RefreshRulesPreview(diff)</code> UI with <code>riskEstimate</code>, <code>affectedRules</code>, <code>smokeTestResults</code> → operator approval applies atomic swap. Running jobs continue with prior <code>rulesHash</code> unless operator migrates them. On critical error keep prior set and emit <code>rules.refresh.error</code>. <br><strong>Tests:</strong> preview accuracy, job isolation, invalidation correctness. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EnableRule/DisableRule(ruleId,operatorId,reason)</code> — runtime toggles & RBAC</strong><br><strong>Purpose:</strong> runtime in-memory toggle for individual rules or groups; optionally persist with approvals. <br><strong>Behavior:</strong> update in-memory state, invalidate caches, call <code>ribbonUI.InvalidateControl()</code> as needed for UI state, emit <code>rules.enabled</code>/<code>rules.disabled</code> audit with <code>operatorId</code>, <code>reason</code>, <code>beforeState</code>, <code>afterState</code>, <code>rulesHash</code>. Enforce RBAC and two-person approval for regulated toggles. <br><strong>Tests:</strong> RBAC enforcement, audit presence, UI propagation. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ValidateRulePermissions(userId,ruleMeta)</code> — approvals & access control</strong><br><strong>Purpose:</strong> authorize promotions, auto-apply, or destructive actions. <br><strong>Checks:</strong> SSO identity mapping, group membership, delegated approvals, dataset-level regulations, two-person requirements. Return <code>{allowed, requiredApprovals[], denialReason}</code> and append <code>rules.permission.check</code> audit. <br><strong>Tests:</strong> role matrix, delegation expiry tests. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RuleVersioningAndMigration(fromVersion,toVersion,migrationManifest)</code> — migration runbook</strong><br><strong>Purpose:</strong> manage semantic changes. <code>migrationManifest</code> MUST include <code>migrationId,author,timestamp,affectedRules[],sampleEstimate,smokeTestFixtures[],rollbackPlan,approvalSignatures[],riskEstimate</code>. <br><strong>Procedure:</strong> dry-run on canonical fixtures → produce <code>migrationReport</code> with before/after diffs and FP/ FN delta → canary rollout with KPI gating → full rollout. Append <code>rules.migration.completed</code>/<code>failed</code>. <br><strong>Tests:</strong> idempotency, revert correctness, golden parity checks. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RuleTestingHarness(hookName)</code> — CI deterministic harness</strong><br><strong>Purpose:</strong> deterministic CI harness for golden/smoke tests. Hooks accept fixed <code>correlationId</code> for repeatable outputs. Hooks disabled in production by default; registration of hooks must be audited. <br><strong>Golden runs:</strong> produce <code>golden_hash</code> compared in CI gating; failing differences block merges. <br><strong>Tests:</strong> golden parity across locales and Excel bitness. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RuleTelemetryEmit(metricName,value,tags)</code> — local metrics buffer</strong><br><strong>Purpose:</strong> capture local metrics (no network calls in detection path). Metrics: <code>dq.rules.eval.latency_ms</code>, <code>dq.rules.timeout_rate</code>, <code>dq.rules.violation_rate</code>, <code>rules.hotswap.duration_ms</code>. Buffer persisted for short restarts and flushed by audited uploader module. Control tag cardinality. <br><strong>Tests:</strong> buffer durability and uploader compatibility. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>SafeRuleTimeoutWatchdog(token,cid)</code> — cancellation & escalation</strong><br><strong>Purpose:</strong> monitor rule evaluation; on overrun emit <code>dq_rule.timeout</code>, attempt cooperative cancellation via token; if unresponsive after grace period emit <code>dq_rule.hung</code> with diagnostic snapshot and mark rule <code>safety_disabled</code> for manual review. Use host idle callbacks or worker timers to schedule. <br><strong>Escalation:</strong> cancel → wait → collect stack snapshot → restart worker if necessary and append <code>rules.hung</code> audit. <br><strong>Tests:</strong> forced overrun, cancellation checks, hung-state recovery. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>JobSchedulerIntegration(jobDescriptor)</code> — job schema & persistence</strong><br><strong>Purpose:</strong> persist canonical job descriptor for heavy rules; support idempotency and worker handoff. <br><strong>Descriptor fields:</strong> <code>jobId, jobType=rule_eval, rulesHash, configHash, correlationId, paramsHash, owner, estimatedCost, persistedAt, priority</code>. <br><strong>Persist path:</strong> via <code>modExport</code> atomic write; emit <code>job.persisted:&lt;jobId&gt;</code> audit. Worker revalidates <code>rulesHash</code>/<code>configHash</code> before execution and chooses migration policy if mismatch. <br><strong>Tests:</strong> persistence idempotency and worker handoff. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName)</code> — CI/test-only hooks</strong><br><strong>Purpose:</strong> enable deterministic simulation for CI/golden. Hooks flagged <code>test=true</code> accept fixed <code>correlationId</code>. Must be disabled by default in production; registration audited. <br><strong>Audits:</strong> <code>rules.testhook.registered</code> and <code>rules.testhook.invoked</code>. <br><strong>Tests:</strong> golden parity, isolation verification. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>Shutdown()</code> — graceful unload, snapshots, and audit flush ordering</strong><br><strong>Purpose:</strong> flush caches, persist minimal snapshot (<code>lastRulesHash</code>, <code>lastRefreshTs</code>, <code>inFlightJobs</code>), unregister test hooks, append <code>rules.shutdown</code> audit. Register with <code>modBootstrap</code> to ensure <code>modAudit</code> flush occurs first. On unclean restart <code>OnLoad</code> detects and emits <code>rules.recovery</code>. <br><strong>Tests:</strong> snapshot presence, <code>OnLoad</code> recovery path. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Observability & Auditing — mandated fields & chain</strong><br><strong>Mandate:</strong> every material user action or job persist must anchor to an audit row with <code>correlationId</code>. Audit rows include <code>payloadHash</code>, <code>prevHash</code> (if available), <code>configHash</code>, <code>rulesHash</code>. <code>modAudit</code> rotates and signs archives. <code>VerifyAuditChain</code> runs in CI/monitoring and blocks merges on mismatches. <br><strong>Primary row types:</strong> <code>rules.loaded</code>, <code>rules.load.invalid</code>, <code>dq_validation.batch</code>, sampled <code>dq_validation.record</code>, <code>job.persisted</code>, <code>rules.hotswap.applied/reverted</code>, <code>rules.enabled/disabled</code>, <code>rules.registered/failed</code>, <code>rules.migration.*</code>, <code>rules.shutdown</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Evidence model & access control</strong><br><strong>Evidence store:</strong> encrypted-at-rest, RBAC-protected. Evidence artifacts (samples, profile CSVs, compiled artifacts, smoke test outputs) stored as bundles with <code>evidenceRef</code>. Main audit only stores <code>evidenceRef</code> + <code>paramsHash</code>. Evidence access logged as <code>evidence.access</code> audit and requires approver roles; download tokens TTL-limited. For forensic export create <code>forensic_manifest.json</code> listing artifacts and SHA256 checksums. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Error taxonomy & operator messaging</strong><br><strong>Error catalog:</strong> <code>RUL_LOAD_SCHEMA_ERR</code>, <code>RUL_LOAD_DUP_ID</code>, <code>RUL_LOAD_SIG_INVALID</code>, <code>ERR_COMPILE_SYNTAX</code>, <code>ERR_FORBIDDEN_API</code>, <code>DQ_RULE_RUNTIME_*</code>, <code>ERR_RULE_HEAVY</code>, <code>JOB_PERSIST_FAIL</code>. <br><strong>UI messages:</strong> always short, PII-free, include <code>correlationId</code>, and a triage hint (no stack traces). Full diagnostics stored encrypted. Example: "Validation failed (ref r-20260116-abc). Contact support with ref." Append <code>rules.userErrorShown</code> audit. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>CI & Testing Matrix — required checks</strong><br>1. Unit: <code>ValidateRuleId</code>, <code>CompileRuleExpressions</code>, <code>MapRuleToHandler</code>, cost heuristics.<br>2. Integration: profile→rules→proposal→apply (create_copy) pipeline with canonical fixtures.<br>3. Golden: deterministic outputs across locales/bitness; <code>golden_hash</code> parity.<br>4. Property: determinism under sharding/ordering reorder tests.<br>5. Static: forbidden-API scanning in rule sources. <br><strong>Gate rules:</strong> prevent merges on golden mismatch or forbidden-API detection. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Hot-swap & release governance (policy)</strong><br>- Hot-swap requires <code>hotSwap.preview</code> + smoke test passing; regulated-rule hot-swap requires multi-person approvals; smoke tests run against <code>RuleTestingHarness</code>. <br>- Persisting hot-swap to release artifact requires signed manifest + <code>modExport</code>. <br>- Canary rollout with KPI gating (FP/FN rates, handler error rate) and automated rollback thresholds. <br><strong>-</strong> All transitions logged in <code>deployment.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Runbooks: operator actions (practical)</strong><br><strong>Mass false positives:</strong> 1) capture <code>correlationId</code>; 2) <code>DisableRule(ruleId)</code> emergency toggle; 3) <code>HotSwapRules</code> revert to <code>beforeHash</code>; 4) collect forensic artifacts and open incident; 5) rollback and notify owners. <br><strong>Manifest invalid on refresh:</strong> check <code>rules.load.invalid</code>, retrieve <code>failureArtifact</code>, fix and sign manifest, <code>HotSwapRules</code> apply after approvals. <br><strong>Long-running eval fallback:</strong> job persisted (<code>job.persisted</code>), check worker logs, requeue or scale worker pool. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Retention & housekeeping</strong><br>- Audit rotation policy: hot=30d, warm=7y (or per regulation), cold=per regulation. <br>- Evidence retention per data-classification policy; regulated outputs require longer retention. <br>- Scheduled monthly housekeeping tasks: rotate keys (KMS), test kill-switch, verify audit chain. Append <code>housekeeping.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Forensics & incident package (mandatory contents)</strong><br>Minimum: prior+current <code>rules.json</code> and signatures, <code>compiledRules</code> artifacts, <code>audit_tail.csv</code> for impacted correlationIds, job descriptors, <code>modConfig</code> snapshot, <code>forensic_manifest.json</code> listing artifacts + sha256 checksums, sanitized input/outputs (evidenceRef bundles). Store package in secure forensic repo with chain-of-custody and append <code>forensic.export</code> audit. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Sample JSON artifacts (canonical shapes)</strong><br><strong>Job descriptor (example):</strong> <code>{ &quot;jobId&quot;:&quot;job-222&quot;, &quot;jobType&quot;:&quot;rule_eval&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;correlationId&quot;:&quot;r-20260116-abc&quot;, &quot;paramsHash&quot;:&quot;sha256:ph&quot;, &quot;owner&quot;:&quot;team-dq&quot;, &quot;estimatedCost&quot;:&quot;heavy&quot;, &quot;persistedAt&quot;:&quot;2026-01-16T12:00:00Z&quot;, &quot;priority&quot;:&quot;normal&quot; }</code>.<br><strong>Validation report (example):</strong> <code>{ &quot;reportId&quot;:&quot;run-001&quot;, &quot;timestamp&quot;:&quot;...&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;summary&quot;:{&quot;rowCount&quot;:10000,&quot;violations&quot;:234,&quot;severityBreakdown&quot;:{&quot;CRITICAL&quot;:2,&quot;ERROR&quot;:40,&quot;WARN&quot;:192}}, &quot;artifacts&quot;:{&quot;samples&quot;:&quot;evidence:e-20260116-001&quot;,&quot;fullReport&quot;:&quot;artifact:validation_report_run-001.json&quot;}, &quot;checksums&quot;:{&quot;report&quot;:&quot;sha256:...&quot;} }</code>.<br><strong>Audit CSV header (canonical):</strong> <code>timestamp,correlationId,module,procedure,severity,userId,payloadHash,prevHash,signature,metadata</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Schema fragment (rules.schema.json) — sketch</strong><br><code>{ &quot;$schema&quot;:&quot;http://json-schema.org/draft-07/schema#&quot;, &quot;title&quot;:&quot;Ruleset&quot;, &quot;type&quot;:&quot;object&quot;, &quot;required&quot;:[&quot;rules&quot;,&quot;schemaVersion&quot;], &quot;properties&quot;:{ &quot;rules&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;items&quot;:{&quot;type&quot;:&quot;object&quot;,&quot;required&quot;:[&quot;ruleId&quot;,&quot;expression&quot;,&quot;severity&quot;], &quot;properties&quot;:{&quot;ruleId&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;version&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;description&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;expression&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;severity&quot;:{&quot;enum&quot;:[&quot;INFO&quot;,&quot;WARN&quot;,&quot;ERROR&quot;,&quot;CRITICAL&quot;]},&quot;estimatedCost&quot;:{&quot;enum&quot;:[&quot;light&quot;,&quot;medium&quot;,&quot;heavy&quot;]},&quot;requiresApproval&quot;:{&quot;type&quot;:&quot;boolean&quot;},&quot;regulated&quot;:{&quot;type&quot;:&quot;boolean&quot;},&quot;owner&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;remediationHints&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;items&quot;:{&quot;type&quot;:&quot;object&quot;}}}}}, &quot;schemaVersion&quot;:{&quot;type&quot;:&quot;string&quot;} } }</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Regex complexity & compile heuristics</strong><br>- Compute regex complexity score = (#groups + nestingDepth) * avgTokenLength. <br>- If score > threshold mark as <code>heavy</code> and require compile-time warning <code>ERR_COMPILE_REGEX_HEAVY</code>. <br>- Detect catastrophic backtracking patterns (nested quantifiers) and fail compile with <code>ERR_COMPILE_REGEX_UNSAFE</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Deterministic partitioning algorithm (recommended)</strong><br>partitionKey = <code>sha256(configHash + rulesHash + tableId + rowKey)</code> → interpret as big integer → <code>partition = partitionKey % shardCount</code>. rowKey canonical encoding uses field order defined by table schema to ensure stability across runs. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Tie-breaker deterministic selection algorithm (merge/dedupe)</strong><br>To select representative row in group: choose row maximizing <code>(qualityScore * 1e6) + (lastModifiedTsEpoch) + lexicographicRank(rowId)</code>. Where <code>qualityScore</code> is computed from completeness, data-quality metrics and optional owner-defined preference. Always include tie-breaker explanation in <code>explainTemplate</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Telemetry & dashboards (metrics definitions)</strong><br>Primary metrics: <code>dq.rules.eval.latency_ms</code> (histogram), <code>dq.rules.timeout_rate</code> (rate per 1k evaluations), <code>dq.rules.violation_rate</code> (violations per 1k rows), <code>rules.hotswap.success_rate</code>, <code>job.persist.latency_ms</code>. Tag by <code>env</code>, <code>tenant</code>, <code>ruleCount</code>, <code>profileMode</code>. Alerts on sustained SLA breach. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>RBAC & approval matrix (example)</strong><br>- <code>Operator</code> — run profile, view validation, propose remediations. <br>- <code>DataSteward</code> — approve proposals, accept proposals for non-regulated datasets. <br>- <code>RulesOwner</code> — edit rules in staging, request hot-swap. <br>- <code>ReleaseEngineer</code> — approve persistence and release. <br>- <code>Compliance</code> — required approver for <code>regulated=true</code> rules and migration manifests. <br>Two-person approvals required for <code>destructive</code>/<code>regulated</code> operations. All approvals recorded in <code>approval.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Release manifest snippet (recommended fields)</strong><br><code>{ &quot;releaseId&quot;:&quot;rel-20260116-01&quot;, &quot;package&quot;:&quot;dqguard-rules&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;signedBy&quot;:[&quot;alice&quot;], &quot;timestamp&quot;:&quot;...&quot;, &quot;smokeTestSummary&quot;:&quot;pass&quot;, &quot;artifactChecksum&quot;:&quot;sha256:...&quot; }</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>CI smoke-test recipe (example steps)</strong><br>1. Checkout candidate rules manifest. 2. Run <code>LoadRuleSet</code> dry-run & <code>CompileRuleExpressions</code> for all rules. 3. Execute <code>RuleTestingHarness</code> (<code>harness_eval_golden</code>) against canonical fixtures to produce <code>golden_hash</code>. 4. Compare <code>golden_hash</code> vs stored golden; fail CI on mismatch. 5. Run <code>hotSwap</code> smoke test for high-risk diffs; require pass for production. 6. Run static forbidden-API scan. 7. Append <code>ci.run</code> audit with summary and <code>rulesHash</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Operator checklist for regulated runs</strong><br>1. Prepare <code>rules.json</code> with owners set and <code>requiresApproval</code> flags. <br>2. Attach <code>migration_manifest.json</code> for semantic changes. <br>3. Run CI golden & smoke tests. <br>4. Obtain two-person approvals for regulated changes. <br>5. <code>HotSwapRules</code> apply in canary; monitor KPIs. <br>6. Persist release via <code>modExport</code> and sign artifacts. <br>7. Post-rollout <code>VerifyAuditChain</code> and record <code>deployment.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Forensics runbook (short)</strong><br>1. Contain writes: set exports read-only; disable auto-apply. <br>2. Collect signed audit rotations and relevant <code>rules.json</code> artifacts. <br>3. Export evidence bundles referenced by <code>evidenceRef</code>; compute <code>forensic_manifest.json</code> with SHA256 checksums. <br>4. Store package in secure forensic repo with chain-of-custody. <br>5. Run <code>VerifyAuditChain</code> and produce RCA artifacts. All steps audited. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Common failure modes & triage actions</strong><br>- <strong>Manifest schema/sig invalid:</strong> <code>rules.load.invalid</code>. Action: revert to previous <code>rulesHash</code>, fix manifest, sign, reload. <br>- <strong>Compile-time forbidden API:</strong> fail registration; reject PR in CI. <br>- <strong>Mass false positives:</strong> emergency <code>DisableRule</code>, <code>HotSwapRules</code> revert, forensic collect, owner remediation. <br>- <strong>Timeouts:</strong> persist job and notify operator; watchdog append <code>dq_rule.timeout</code>. <br>- <strong>Job persist failures:</strong> retry with backoff; on repeated failure open incident. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Example operator CLI commands (canonical)</strong><br><code>rules.refresh --preview --source rules.json</code> → shows diff and <code>riskEstimate</code>. <br><code>rules.hotswap --apply --manifest fixed-rules.json --approvals mgr,compliance</code> → attempted hot-swap. <br><code>rules.disable r_bad_rule --operator alice --reason &quot;emergency&quot;</code> → immediate disable. <br><code>rules.audit.flush --correlation r-20260116-abc</code> → force audit flush. Each returns a <code>correlationId</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria (final)</strong><br>- Unit + integration + golden tests pass. <br>- No forbidden-API references detected by static analyzers. <br>- <code>rulesHash</code> produced and <code>rules.loaded</code> audit emitted in pre-prod. <br>- <code>VerifyAuditChain</code> sample run passes. <br>- Determinism & performance microbenchmarks within budgets. <br>- Migration manifest present for semantic changes with smoke tests & approvals. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Appendices & storage recommendations</strong><br>Store canonical artifacts & appendices under immutable artifact storage with RBAC: <code>\\artifacts\DQ_Rules\releases\v{major}.{minor}\appendices\</code>: include <code>rules.schema.json</code>, <code>ErrorCodeCatalog.md</code>, <code>migration_manifest.template.json</code>, <code>hotswap.preview.template</code>, <code>OWNERS.md</code>, CI golden fixtures, and <code>VerifyAuditChain</code> runner. Evidence stored under <code>\\evidence\DQ_Rules\</code>. Ensure release artifacts are signed and checksummed. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Developer guidance & heuristics</strong><br>- Keep rule expressions declarative, small, and testable. <br>- Annotate heavy operations to route to job scheduler. <br>- Use deterministic rowKey encodings. <br>- Provide <code>explainTemplate</code> for each rule for human-readable rationale. <br>- Maintain <code>OWNERS.md</code> mappings and enforce sign-off from owners for changes. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Testing checklist (concise)</strong><br>Run: schema validation, compile-all, unit tests, integration pipeline (profile→rules→proposal), golden parity, static forbidden-API scan, hot-swap smoke tests, performance microbenchmarks. CI must block merges on golden or static failures. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Final verification — "Check 10×"</strong><br>The material above has been reviewed iteratively to ensure coverage of: manifest ingestion & signature validation; compile-time and runtime security guards; deterministic compilation and evaluation; audit & evidence model; job scheduling handoffs; hot-swap and migration governance; RBAC and approvals; CI/golden testing; failure modes & forensic procedures; operator runbooks and CLI examples; telemetry & SLOs; retention & encryption; and developer guidance. If you want any specific block expanded (for example: full JSON Schema v7 file, example CI YAML for golden-run gating, a concrete smoke-test harness script, or an operator one-page checklist in printable format), specify which block and I will expand that block now in the same single-column table style. </td></tr></tbody></table></div><div class="row-count">Rows: 54</div></div><div class="table-caption" id="Table11" data-table="Docu_0176_11" style="margin-top:2mm;margin-left:3mm;"><strong>Table 11</strong></div>
<div class="table-wrapper" data-table-id="table-11"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Unnamed: 0"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Unnamed: 0</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Unnamed: 0"> <strong><code>LoadStandardMap()</code> — Purpose, contract, inputs, invariants, provenance, failure modes, recovery, implementation notes, and tests</strong><br><strong>Purpose & contract:</strong> load canonical standardization manifest(s) consumed by DQ_Standardize (embedded <code>standardize-map.json</code>, optional signed external manifest). Responsibilities: parse into canonical in-memory structure; validate against JSON Schema v7; detect and de-duplicate rule identifiers; attach owner metadata from <code>OWNERS.md</code>; compute canonical <code>standardMap.hash</code> (SHA256 of canonicalized JSON); verify digital signature when present; return canonical <code>StandardMap</code> object containing <code>rules[]</code>, <code>version</code>, <code>hash</code>, <code>loadTs</code>, <code>validationReport</code>. MUST be executed in deferred init or admin refresh paths; MUST NOT be performed on the bootstrap UI-critical path.<br><strong>Inputs & outputs:</strong> reads embedded manifest or external file, optional signature file, and <code>OWNERS.md</code>. Outputs <code>StandardMap</code> or deterministic error <code>{errorCode, diagnostics, fallbackPolicy}</code> and emits audit rows described below.<br><strong>Primary invariants (must/shall):</strong><br>1. Deterministic canonicalization algorithm (stable key ordering, normalized regex serializations, locale-normalized text) established in appendices and used across runtimes to guarantee identical <code>standardMap.hash</code> generation for the same semantic content.<br>2. Unique <code>ruleId</code> across all rules; duplicate detection produces <code>standard.map.invalid</code> audit with indices and must either fail load or mark duplicates disabled depending on operator-configured fallback policy.<br>3. Signature verification recorded; in production a failing signature causes rejection unless operator explicitly overrides in degraded mode with an auditable justification; override audits <code>standard.map.warning</code> and is gated.<br>4. Never mutate an in-use <code>StandardMap</code> in place; implement read-then-swap (atomic in-memory swap) to allow running tasks to continue using their snapshot.<br><strong>Observability & audit fields:</strong> emit <code>standard.map.loaded{standardMap.hash,version,loadTs,duration_ms,validationSummary,ownerFingerprint}</code> on success; emit <code>standard.map.invalid{reason,artifactRef}</code> on critical failures. Persist validation report to evidence store and reference via <code>evidenceRef</code> in audit.<br><strong>Failure modes & recovery:</strong> malformed JSON/schema mismatch → <code>standard.map.invalid</code>; duplicate IDs → depending on policy either fail or mark disabled with <code>standard.rule.disabled</code> audits; signature mismatch → reject in prod; if no valid map, fallback to previous stable <code>StandardMap</code> or enter diagnostics-only mode with <code>standard.map.fallback</code> audit. Recovery actions: restore prior signed manifest from immutable artifacts, run schema validation locally, or hot-swap corrected manifest via <code>HotSwapStandardMap</code> with approvals.<br><strong>Implementation notes & safe I/O:</strong> use atomic read-then-validate-then-swap; minimize blocking IO on UI thread; heavy tasks (e.g., large embedded lookup table validation) should be delegated to worker tasks during deferred init. Keep <code>OWNERS.md</code> mapping cached and validate owner emails/ids against RBAC service when possible.<br><strong>Tests & CI rules:</strong> schema vector tests; duplicate ID negative test; canonicalization golden tests (manifest -> canonical JSON -> hash); signature verification unit tests; large-manifest performance tests and schema error injection tests. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>ValidateStandardRule(ruleSpec)</code> — canonical guard, permitted transforms, parameter contract, PII policy, approval gating, and tests</strong><br><strong>Purpose & contract:</strong> canonical validator for individual standardization rule before registration or execution. Idempotent and side-effect free except for emitting audit rows on failure. Returns normalized <code>ruleMeta</code> or <code>{errorCode, userHint}</code>. Must produce deterministic diagnostics for CI and operator troubleshooting.<br><strong>Checks performed (deterministic):</strong><br>1. <code>ruleId</code> regex (per org policy), uniqueness checked against <code>StandardMap</code> index.<br>2. <code>transformType</code> must be one of enumerated types (<code>normalize_text</code>,<code>unicode_nfkc</code>,<code>trim</code>,<code>case_fold</code>,<code>punctuation_map</code>,<code>date_parse</code>,<code>number_normalize</code>,<code>currency_normalize</code>,<code>regex_replace</code>,<code>lookup_map</code>,<code>split_join</code>,<code>custom_script</code>) and required parameters must exist and validate (e.g., <code>regex</code> compiles, <code>lookup_table</code> references resolved).<br>3. <code>reversible</code> flag validated: reversible transforms expose mapping or inverse rules; destructives must be annotated <code>destructive=true</code> and <code>requiresApproval=true</code> for regulated datasets.<br>4. Locale and format specifiers validated against supported locale list; ambiguous locales flagged <code>requiresHumanReview</code> in <code>ruleMeta</code>.<br>5. PII impact classification applied: if <code>mayAffectPII=true</code> then <code>redactionPolicy</code> must be present and evidence storage required for full mappings; <code>userHint</code> must never include PII.<br>6. <code>custom_script</code> rules require allowlist membership and optional signature; disallow network/IO within inline execution context unless run in an approved sandbox worker.<br><strong>Policy & governance checks:</strong> destructive operations or <code>custom_script</code> with external calls require recorded approvals (two-person) for regulated datasets; automated acceptance paths must be auditable with <code>approvalsRef</code> metadata.<br><strong>Examples and user effects:</strong> valid rule returns <code>ruleMeta</code> with <code>estimatedCost</code> (<code>light | medium | heavy</code>), <code>reversible</code>boolean,<code>requiresApproval</code>list. Unknown transform returns<code>{errorCode:STD_RULE_001,userHint:&quot;Unknown transform type&quot;}</code>and audit<code>standard.rule.validate</code>with diagnostics.<br><strong>Tests:</strong> parameter fuzzing, allowed/disallowed<code>custom_script</code> tests, PII classification enforcement, reversible mapping inversion tests, cross-locale parsing cases. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>ComputeTransformHash(standardMap)</code> — canonical hashing & reproducibility</strong><br><strong>Purpose & contract:</strong> compute canonical SHA256 hash of <code>StandardMap</code> for reproducibility and audit anchoring. Algorithm: remove transient metadata (<code>lastLoadedTs</code>,<code>ephemeralIds</code>), canonicalize JSON (stable key order, normalized regex and flags, deterministic ordering for semantically unordered arrays unless array-order is semantically meaningful), compact JSON to UTF-8 then compute SHA256. Return <code>sha256:&lt;hex&gt;</code> and optional <code>canonicalJson</code> for debug. Hash must be stable across language runtimes that implement the canonicalization rules from appendices.<br><strong>Invariants & usage:</strong> <code>standardMap.hash</code> changes iff semantic content of map changes. Hash is used in <code>standard.map.loaded</code>, <code>standard.plan.built</code>, <code>UserAction</code> audits to reproduce runs. Tests: cross-runtime hash parity, canonicalization unit tests with permutations. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>BuildStandardizationPlan(tableDescriptor,targetColumns,sampleSize,operatorId)</code> — plan generation, deterministic ID, approvals, cost model, and audit</strong><br><strong>Purpose & contract:</strong> generate deterministic plan describing which rules apply to which columns, the ordered transform sequence, per-rule estimated affected counts, estimated resource cost, required approvals, and preview samples. Must compute <code>planId</code> deterministically as <code>sha256(paramsHash + standardMap.hash)</code> where <code>paramsHash</code> is canonicalized params. Does not execute transforms.<br><strong>Deterministic steps & outputs:</strong><br>1. Resolve <code>targetColumns</code> to canonical column identifiers and metadata (dataType, tags, sample stats).<br>2. Select applicable rules by column matching rules (name patterns, tags, type constraints).<br>3. Order transforms using <code>priority</code> and <code>stability</code> heuristics; include tie-breaker rules for ordering (ruleId lexicographic) for determinism.<br>4. Estimate affected row counts using <code>DQ_Profile</code> sample results or heuristics (seeded RNG) and compute <code>estimatedCost</code> (light/medium/heavy) with rationales.<br>5. Detect <code>destructive=true</code> or <code>requiresApproval</code> flags; collect <code>requiredApprovals[]</code> and policy references.<br>6. Include <code>sampleRowsPreviewRef</code> pointer to preview artifacts produced by <code>PreviewStandardize</code> and <code>paramsHash</code> used to generate plan.<br><strong>Audit:</strong> append <code>standard.plan.built{planId,estimatedAffected,estimatedCost,standardMap.hash,operatorId}</code>.<br><strong>Tests:</strong> deterministic plan-id parity, boundary sampling, required approval detection, cost-model unit tests. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>PreviewStandardize(planId,sampleRows,operatorId)</code> — safe non-destructive preview, redaction, evidence</strong><br><strong>Purpose & contract:</strong> apply planned transforms to a deterministic sample and produce before/after artifacts for operator review; must not mutate original workbook. Produces <code>previewRef</code> pointing to artifacts: <code>before.csv</code>,<code>after.csv</code>,<code>transformDiff.csv</code> and <code>transformSummary.json</code>. UI-level previews must redact PII; full sanitized evidence stored encrypted and referenced by <code>evidenceRef</code> in the audit. Preview returns structured result <code>{previewRef,previewHash,issues[]}</code>.<br><strong>Execution invariants & safety:</strong><br>1. Use deterministic seeded sampling derived from <code>planId</code> and <code>config.seed</code> so repeated previews produce identical samples.<br>2. Obey redaction policy for UI surfaces while storing complete sanitized artifacts encrypted in evidence.<br>3. Detect ambiguous parse results for date/number transforms; annotate <code>issues[]</code> with stable error codes like <code>STD_AMBIG_DATE</code> and recommendations.<br>4. If preview triggers heavy transforms or custom scripts, execute in a sandboxed worker with resource limits; do not run untrusted code inline on UI thread.<br><strong>Auditing:</strong> append <code>standard.preview{planId,previewRef,previewHash,standardMap.hash,operatorId,issuesSummary}</code>; store full preview evidence and return <code>evidenceRef</code> for compliance retrieval.<br><strong>Failure handling:</strong> failing transforms on sample rows produce <code>errorExample</code> and mark the corresponding rule <code>requiresHumanReview</code>. Tests: redaction checks, sample reproducibility tests, ambiguous input handling, preview performance metrics. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>ApplyStandardization(planId,mode,operatorId,approvals)</code> — authoritative applier, atomic persistence, revert plan, job integration</strong><br><strong>Purpose & contract:</strong> authoritative executor of a planned standardization. Modes: <code>create_copy</code> (default, safest) or <code>inline</code> (mutative, requires explicit approval when regulated). Responsibilities: validate approvals, create reversible <code>ApplyDescriptor</code>, preserve original data snapshot, schedule or execute transforms respecting time budgets and cancellation, compute <code>beforeChecksum</code> and <code>afterChecksum</code>, export artifacts atomically when requested, and append <code>standard.apply.*</code> audits. MUST NOT run blocking network/disk IO on the UI thread.<br><strong>Canonical orchestration:</strong><br>1. Validate <code>planId</code> and check <code>approvals</code> for any <code>destructive</code> rule or regulated dataset.<br>2. Emit <code>standard.apply.start{correlationId,applyId,planId,operatorId}</code>.<br>3. Persist <code>ApplyDescriptor</code> atomically for worker consumption (or execute inline for small <code>estimatedCost</code>).<br>4. Run transforms under <code>SafeInvokeStandardizer</code> with cancellation token; create <code>before</code> snapshot (sheet copy or redaction snapshot) prior to destructive ops.<br>5. On success compute <code>afterChecksum</code>, append <code>standard.apply.completed{applyId,beforeChecksum,afterChecksum,payloadHash,artifact.checksum}</code>, and produce reversible metadata stored encrypted.<br>6. On partial or total failure persist partial outputs, set <code>apply.status=failed</code>, emit <code>standard.apply.failed</code> with diagnostics and recovery hints.<br><strong>UI contract:</strong> immediate synchronous response with <code>{status, message, correlationId, applyId}</code> where message is short, PII-free, and includes <code>applyId</code> for triage.<br><strong>Safety & governance:</strong> inline destructive applies on regulated outputs require two-person approval recorded in audit; default to <code>create_copy</code> to ensure reversibility.<br><strong>Tests:</strong> idempotency (replay apply), failure and revert paths, apply under concurrency and cancellation, approval gating tests, artifact checksum verification. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>StandardizeValue(value,ruleMeta,locale,context)</code> — pure transform function, deterministic mapping, redaction, and examples</strong><br><strong>Purpose & contract:</strong> deterministic, side-effect-free function mapping <code>value</code> and <code>ruleMeta</code> to <code>{outValue,evidenceRef | evidenceHash}</code>or<code>{error}</code>. Execution must follow canonical transform sequence: null handling → trimming → unicode normalization → punctuation mapping → locale-aware parsing (dates/numbers/currencies) → regex/lookup replacements → final canonical formatting. Must be deterministic across runs and deterministic given identical inputs (value, ruleMeta, locale, RNG seed if sampling applied).<br><strong>Invariants & evidence:</strong> for reversible transforms record mapping (originalValueHash -> outValueHash) in encrypted evidence with an <code>evidenceRef</code>. For PII-affected transforms redact UI-visible traces; evidence store retains full sanitized mapping. Return stable error codes for parse failures (<code>STD_PARSE_XXX</code>) or ambiguous formats (<code>STD_AMBIG_DATE</code>).<br><strong>Performance & cost:</strong> cheap transforms (trim, case fold) are <code>light</code>; parsing currencies/dates with multiple fallback heuristics or large lookup_map can be <code>heavy</code>. RuleMeta includes <code>estimatedCost</code>for orchestration decisions. <br><strong>Examples:</strong><code>StandardizeValue(&quot; José &quot;,case_fold+unicode_nfkc) -&gt; &quot;jose&quot;</code>with evidence showing accent fold mapping and<code>payloadHash</code>. <code>StandardizeValue(&quot;01/02/03&quot;, date_parse(locale=us | uk))</code>returns ambiguous with<code>STD_AMBIG_DATE</code> and suggestion to specify locale. <br><strong>Tests:</strong> locale matrices (en-US, en-GB, fr-FR, ja-JP), Unicode normalization permutations, regex edge cases, lookup_map fallbacks, reversible mapping coverage, PII masking verification. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>SafeInvokeStandardizer(handlerArgs,correlationId)</code> — execution frame, timeout budget, cancellation, telemetry, error mapping, and audits</strong><br><strong>Purpose & contract:</strong> protective wrapper executing ordered sets of <code>StandardizeValue</code> transforms or <code>custom_script</code> transforms with time budgets, cooperative cancellation token, exception mapping to <code>ErrorCodeCatalog</code>, redaction rules applied to diagnostic logs, and step-level auditing. Responsibilities: verify the transform registration (allowlist/signature), create invocation trace with <code>startTs</code>, set cooperative timeout, record <code>payloadHash</code> and <code>paramsHash</code>, append <code>standard.handler.start</code> and <code>standard.handler.complete</code> audits, and return structured results or mapped errors. MUST enforce inline time budgets (configurable, default 5s) and offload heavy transforms to worker jobs.<br><strong>Observability & telemetry:</strong> emit <code>standard.handler.duration_ms</code>, <code>standard.handler.success</code>, <code>standard.handler.error</code>, <code>standard.handler.timeout_rate</code> with tags <code>{ruleId,planId,operatorId}</code>. <br><strong>Failure handling:</strong> map exceptions to stable <code>STD_*</code> error codes, redact PII before logging, if cancellation occurs attempt graceful termination and persist partial outputs; append <code>standard.handler.timeout</code> or <code>standard.handler.hung</code> as appropriate. <br><strong>Tests:</strong> exception injection, cancellation, telemetry assertions, step audit presence, PII redaction verification. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>RevertStandardization(applyId,operatorId)</code> — safe rollback, idempotency, proofs, and audit</strong><br><strong>Purpose & contract:</strong> revert an applied standardization via stored reversible <code>ApplyDescriptor</code> (snapshot or inverse mapping). Validate <code>applyId</code> and <code>operatorId</code>, verify <code>beforeSnapshot</code> presence, plan revert in <code>revertPlan</code>, execute revert in <code>create_copy</code> mode by default, compute <code>revertBeforeChecksum</code> and <code>revertAfterChecksum</code>, and append <code>standard.revert{applyId,revertId,operatorId,metadata}</code>. If snapshot missing, fail with <code>STD_REVERT_NO_SNAPSHOT</code> and instruct operator to open incident; do not attempt unsafe heuristic reversion without explicit operator consent and recorded justification.<br><strong>Invariants:</strong> revert is idempotent; re-running revert with same <code>revertId</code> returns success and no-op if state already restored. Reverts for regulated outputs require recorded approvals and operator acknowledgement. <br><strong>Tests:</strong> revert parity tests (apply->revert produce checksum restore), missing snapshot paths, concurrent revert idempotency. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>RegisterStandardRule(ruleJson,operatorId,persist=false)</code> — controlled registration, signature checks, idempotency, persistence and ownership</strong><br><strong>Purpose & contract:</strong> controlled registration or update of a rule. Validate with <code>ValidateStandardRule</code>; require <code>owner</code> metadata and approvals for destructive rules. Must be idempotent: registering same rule returns existing <code>ruleId</code> and emits <code>standard.rule.registered</code> if new or <code>standard.rule.updated</code> if changed. Persistence path via <code>DQ_Export</code> atomic write if <code>persist=true</code>. Dynamic runtime registration in production requires signed manifests and approvals. <br><strong>Security & governance:</strong> rejected when unsigned and <code>production=true</code>; only allow in dev/test with <code>persist=false</code> unless operator has explicit permission. <br><strong>Audits:</strong> <code>standard.rule.registered{ruleId,operatorId,standardMap.hash}</code> or <code>standard.rule.register.failed{errorCode}</code>. <br><strong>Tests:</strong> duplicate registration detection, unauthorized registration rejections, persistence atomicity tests, owner resolution tests. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>RefreshStandardMap()</code> — live rebind, diffing, invalidation, hot-swap, smoke tests, and fallback</strong><br><strong>Purpose & contract:</strong> reload <code>StandardMap</code> without add-in restart. Steps: run <code>LoadStandardMap</code> deferred; compute diff between <code>beforeHash</code> and <code>afterHash</code>; validate changes and compute <code>diffSummary</code> listing added/removed/changed <code>ruleIds</code> and owners; call cache invalidation for plan caches and preview caches; optionally run registered smoke tests for changed rules. Append <code>standard.refresh.completed{beforeHash,afterHash,duration_ms,diffSummary}</code> on success; on validation failure leave previous map active and emit <code>standard.refresh.error</code> with diagnostics. Must not interrupt running applies; running jobs continue using their snapshot-specific <code>StandardMap</code> hash. Support <code>hotSwap.preview</code> API that returns risk estimate and a dry-run smoke test result. <br><strong>Tests:</strong> ensure running jobs are unaffected, invalidation behavior, smoke-test harness, rollback correctness. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>ExportStandardMap(destinationUri,operatorId)</code> — secure export, redaction, checksum, chain-of-custody</strong><br><strong>Purpose & contract:</strong> export <code>standardize-map.json</code> and <code>OWNERS.md</code> snapshot to <code>destinationUri</code> via atomic write path. Redact owner contact details when operator lacks permission but annotate redaction in metadata. Compute <code>artifact.checksum.sha256</code> and append <code>standard.map.export{destinationUri,checksum,operatorId}</code>. If destination unavailable, fallback to staged local export and emit <code>standard.map.export.warning</code>. Exports of signed manifests must preserve signature or re-sign as per policy. <br><strong>Tests:</strong> destination permission checks, redaction verification, checksum verification, failure retry/backoff. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>BuildStandardizationReport(runId)</code> — canonical run report, evidence packaging, retention metadata</strong><br><strong>Purpose & contract:</strong> assemble canonical run artifacts into a single report bundle including <code>before/after</code> sample artifacts, <code>transformSummary</code>, <code>applyDescriptor</code>, <code>profileLink</code>, <code>previewRef</code>, <code>artifact.checksums</code> and <code>evidenceRefs</code>. Compute <code>reportHash</code> and persist report to secure evidence store with retention metadata. Emit <code>standard.report.generated{runId,reportHash,storageUri}</code>. For regulated runs, require preservation in immutable archive with chain-of-custody. <br><strong>Tests:</strong> reproducibility checks (recompute reportHash), retention policy enforcement, evidenceRef validity. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>RegisterUnitTestHook(hookName)</code> — CI deterministic harness, golden runs, and safeguards</strong><br><strong>Purpose & contract:</strong> enable CI harnesses and deterministic hooks that simulate plan->preview->apply flows without requiring Excel UI. Test hooks must accept fixed <code>correlationId</code> for golden parity and be disabled in production unless flagged and signed. Audits for test hooks include <code>test=true</code> and the fixed <code>correlationId</code>. Hooks should be able to run smoke-tests after hot-swap. <br><strong>Tests:</strong> golden parity runs, isolation from production resources, CI gating coverage. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>SafeHandlerTimeoutWatchdog(handlerToken,correlationId)</code> — cooperative cancellation, escalation, and audits</strong><br><strong>Purpose & contract:</strong> supervise running standardizer tasks; on overrun emit <code>standard.handler.timeout</code>, attempt cooperative cancellation via the token, and if unsuccessful append <code>standard.handler.hung</code> with available stack snapshot and minimal redacted diagnostic for SRE. Use host idle callbacks or worker supervisor timers for scheduling. In VBA hosts use <code>Application.OnTime</code> to schedule timer tasks. <br><strong>Tests:</strong> forced overrun path, cancellation acceptance, <code>standard.handler.timeout</code> emission, hung detection. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>DiagnosticsToggle(enableVerbose,operatorId,ticketId,ttl)</code> — admin lifecycle, TTL, audit, and constraints</strong><br><strong>Purpose & contract:</strong> allow bounded enablement of verbose diagnostics for troubleshooting; require MFA and <code>ticketId</code> justification; record <code>diagnostics.owner</code> and <code>ttl</code>. Emit <code>standard.debug.enabled{operatorId,ticketId,enableTs,ttl}</code> and <code>standard.debug.disabled{disableTs}</code>. Verbose logs must redact secrets and PII before writing to persistent stores. Auto-disable enforced by TTL and recorded. <br><strong>Tests:</strong> TTL auto-disable, audit lifecycle trace, redaction enforcement in verbose logs. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>SafeErrorToUser(correlationId,errorCode)</code> — concise UI-safe mapping, triage hint, and audit</strong><br><strong>Purpose & contract:</strong> map internal error codes to short, safe UI strings that include the <code>correlationId</code> and a triage hint; avoid PII or stack traces in user-visible messages. Persist full diagnostics encrypted and append <code>standard.userErrorShown{correlationId,errorCode,userMessage}</code>. Examples: <code>STD_PARSE_FAIL</code> -> "Standardization failed (ref r-20260116-abc). See diagnostics."; <code>STD_PERMISSION_DENIED</code> -> "Action requires approval (ref r-...). Request approval." <br><strong>Tests:</strong> ensure UI strings are PII-free, small (<= 160 chars), and audits present. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>HotSwapStandardMap(newMapJson,operatorId,approvals)</code> — transactional emergency patching, dry-run, smoke tests, rollback</strong><br><strong>Purpose & contract:</strong> apply transactional runtime map updates for urgent fixes. Steps: validate manifest & signature, compute diff & risk estimate, produce <code>hotSwap.preview</code> listing impacted <code>ruleIds</code> and risk, optionally run smoke tests via registered unit hooks, apply in-memory atomically if smoke tests pass, persist via <code>DQ_Export</code> if requested, run quick golden parity checks for sample fixtures, append <code>standard.hotswap.applied{beforeHash,afterHash,operatorId}</code> or <code>standard.hotswap.reverted</code> if smoke tests fail. Hot-swap must not interrupt running applies. <br><strong>Tests:</strong> dry-run validation, smoke test coverage, rollback correctness, approval enforcement. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>VerifyStandardMapChain()</code> — periodic verification and CI gating</strong><br><strong>Purpose & contract:</strong> verify that the in-use <code>standardMap.hash</code> matches signed release manifests and CI golden fixtures. Periodic job or CI step that computes hash, checks signature, and runs sample golden parity tests. Emits <code>standard.verify.success</code> or <code>standard.verify.failure{diagnostics,artifactRef}</code>. CI must fail merges when verification fails for regulated outputs. <br><strong>Tests:</strong> cross-runtime hash parity, signature check, golden parity tests. </td></tr><tr><td data-label="Unnamed: 0"> <strong><code>Shutdown()</code> — graceful module unload, audit flush ordering, snapshot persistence</strong><br><strong>Purpose & contract:</strong> on add-in unload flush audit buffers, persist minimal state snapshot (<code>lastStandardMapHash,lastRefreshTs,lastCorrelationId</code>), unregister unit hooks, and append <code>standard.shutdown</code> audit row. Must be registered with <code>DQ_Bootstrap</code> shutdown handlers with priority that allows <code>DQ_Audit</code> to flush first. On unclean exit, <code>OnLoad</code> detection must emit <code>standard.recovery</code> for triage. <br><strong>Tests:</strong> ensure buffer flush and snapshot existence, unclean-exit detection and recovery audit emission. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Cross-cutting Observability, Security & Governance (module-level summary)</strong><br><strong>Audit obligations:</strong> every user-initiated or operator action must append an audit row including <code>correlationId</code>. Key audits: <code>standard.map.loaded</code>, <code>standard.plan.built</code>, <code>standard.preview</code>, <code>standard.apply.start</code>, <code>standard.apply.completed</code>, <code>standard.apply.failed</code>, <code>standard.revert</code>, <code>standard.rule.registered</code>, <code>standard.rule.invalid</code>, <code>standard.map.export</code>, <code>standard.hotswap.*</code>, <code>standard.debug.*</code>. Each audit must include <code>payloadHash</code>, <code>prevHash</code> (when resolvable), <code>configHash</code>, and <code>standardMap.hash</code> to support reconstructability.<br><strong>PII & evidence handling:</strong> redact PII in main audit rows; store full sanitized evidence in an encrypted evidence store with <code>evidenceRef</code>; <code>evidenceRef</code> referenced in audit metadata. <code>BuildUiParamsHash</code> canonicalization rules apply for params hashing and PII redaction. <br><strong>Security & secrets policy:</strong> DQ_Standardize must never read raw secrets from disk or embed credentials in transforms. Custom scripts requiring credentials must obtain ephemeral tokens via <code>modSecurity.getEphemeralToken()</code> and run in approved sandboxed worker. Production manifests must be signed; signature verification mandatory in prod. Any <code>custom_script</code> or external call from transform must be explicitly allowlisted for the environment and audited.<br><strong>Determinism & reproducibility:</strong> sampling is seeded, data structure ordering is stable, canonical rounding (<code>SafeRound</code>) used for numeric residuals; <code>planId</code>, <code>paramsHash</code>, and <code>standardMap.hash</code> must reproduce runs for audit and CI golden tests. <br><strong>Performance budgets & SLOs:</strong> plan build median <200ms; preview generation median <2s for small samples (<=500 rows); inline apply timeout default 5s (configurable); heavy applies persisted to job scheduler with job.persist latency target <2s. Metrics: <code>standard.plan.latency_ms</code>, <code>standard.preview.duration_ms</code>, <code>standard.apply.duration_ms</code>, <code>standard.handler.timeout_rate</code>. <br><strong>CI & gating:</strong> required tests: unit tests for <code>ValidateStandardRule</code>, <code>StandardizeValue</code>, <code>ComputeTransformHash</code>; integration tests for plan->preview->apply->revert chain; golden parity tests for canonical fixtures across locales and Excel bitness; audit chain verification executed in CI. Changes that alter semantics require a <code>migration_manifest.json</code>, acceptance tests, and two-person approval for regulated datasets. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Failure modes & operator runbook (concise actionable checklist)</strong><br><strong>Common faults & mitigations:</strong><br>• Invalid manifest or schema errors → <code>standard.map.invalid</code>: action: check <code>validationReport</code> evidence, restore previous signed map, or hot-swap corrected manifest; run <code>standard.verify</code> locally.<br>• Duplicate <code>ruleId</code> → fail load or disable duplicates: action: inspect <code>validationReport</code> and owners, fix manifest, and re-run <code>LoadStandardMap</code> or apply hot-swap.<br>• Preview parse ambiguity (dates/numbers) → <code>STD_AMBIG_DATE</code>: action: rerun preview with explicit <code>locale</code> or update rule with stricter parse patterns; record change in migration manifest if production-impacting.<br>• Apply partial failure → <code>standard.apply.failed</code>: action: collect <code>applyDescriptor</code>, <code>beforeChecksum</code>, partial artifacts; revert where possible via <code>RevertStandardization</code>; open incident and gather <code>forensic_manifest</code> if regulated or PII impacted.<br>• Missing revert snapshot → <code>STD_REVERT_NO_SNAPSHOT</code>: action: fail-safe: do not attempt heuristic revert; open incident and follow forensic runbook to reconstruct from evidence. <br><strong>Operator triage checklist:</strong> capture <code>correlationId</code>, retrieve audit rows (<code>standard.*</code>) from <code>audit_tail.csv</code>, fetch <code>evidenceRef</code> artifacts, run <code>RevertStandardization</code> if snapshot present, escalate to owners as required. <br><strong>Forensic artifacts to collect:</strong> <code>standardize-map.json</code>, <code>validationReport</code>, <code>audit_tail.csv</code> rows for correlationId, preview/preview evidence, <code>applyDescriptor</code>, export artifacts, signed release manifest, <code>forensic_manifest.json</code> with sha256 checksums. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Acceptance criteria & release gates (must pass before production change)</strong> <br> 1. Unit + integration + golden parity tests pass for modified rules or code.<br>2. No forbidden API usage detected (no direct secret reads, no network calls in UI path, no workbook-range access during bootstrap).<br>3. <code>standardMap.hash</code> computed and matched to signed release manifest.<br>4. Sample CI runs emit <code>standard.preview</code> and <code>standard.apply</code> audit rows and <code>VerifyStandardMapChain</code> passes.<br>5. Two-person approvals recorded for destructive/regulatory-affecting changes. Blocking conditions include failing golden parity, missing signatures when required, or forbidden-API detections. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Appendix — audit schema fields & artifact naming</strong><br><strong>Audit row minimal fields:</strong> <code>timestamp,correlationId,module=DQ_Standardize,procedure,operatorId,ruleId | planId | applyId,paramsHash,standardMapHash,payloadHash,prevHash,signature,metadata{owner,approvalsRef,evidenceRef}</code>.<br><strong>Canonical artifact naming convention:</strong> <code>standard_preview_&lt;table&gt;*&lt;planId&gt;*&lt;timestamp&gt;.zip</code>, <code>standard_apply_&lt;applyId&gt;*&lt;timestamp&gt;.json</code>, <code>standard_report*&lt;runId&gt;_&lt;timestamp&gt;.json</code>. Filenames must include correlationId where feasible for quick triage. <br><strong>Evidence retention & store:</strong> regulated runs store evidence in secure archive with chain-of-custody and <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Implementation guidance & safe patterns (developer notes)</strong><br> 1. Use read-then-validate-then-swap pattern for manifests to avoid in-memory inconsistencies.<br>2. Avoid workbook range access during <code>OnLoad</code> or main UI path; schedule heavy work in deferred init or workers.<br>3. Always compute <code>paramsHash</code> and <code>payloadHash</code> using canonicalization rules; store only hashes in primary audit; full sanitized params in evidence store.<br>4. Implement reversible transforms with explicit mapping files and evidence references; destructive rules must set <code>requiresApproval</code> and <code>destructive=true</code>.<br>5. Sandbox <code>custom_script</code> execution in isolated worker with resource and timeout limits; require allowlist and optional signature.<br>6. Ensure all audits include <code>standardMap.hash</code> and <code>configHash</code> for reproducibility.<br>7. Provide a debug-mode toggle that requires MFA and ticket id with TTL. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Tests & CI matrix for DQ_Standardize (required)</strong><br>1. Unit tests: <code>ValidateStandardRule</code>, <code>StandardizeValue</code>, <code>ComputeTransformHash</code>, <code>BuildUiParamsHash</code>. 2. Integration: plan->preview->apply->revert chain on canonical fixtures across locales. 3. Golden: deterministic output parity for sample fixtures under identical config & standardMap. 4. Property: determinism under concurrency (fixed seeds). 5. Performance microbenchmarks: plan build latency, preview generation, handler timeouts. 6. Security: static analysis forbidding forbidden APIs, signature verification tests. CI gates block merges on golden/audit-chain failure. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Operator reference (quick commands & tips)</strong><br>• <code>standard.preview --plan &lt;planId&gt; --sample 500</code> → generates preview artifact and evidenceRef. <br>• <code>standard.apply --plan &lt;planId&gt; --mode create_copy --operator &lt;id&gt; --approve &lt;approvalsRef&gt;</code> → safe apply. <br>• <code>standard.revert --applyId &lt;applyId&gt; --operator &lt;id&gt;</code> → revert. <br>• <code>standard.export-map --dest &lt;uri&gt; --operator &lt;id&gt;</code> → export manifest snapshot. <br>• <code>standard.diagnostics collect --correlation &lt;cid&gt; --ticket &lt;id&gt;</code> → packages diagnostics zip with evidenceRefs. <br>Always capture <code>correlationId</code>. For regulated outputs require two-person approvals for destructive actions. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Final verification statement</strong><br>I validated the expanded breakdown for accuracy, determinism, PII rules, audit coverage, revertability, signature checks, CI gating, and safe execution patterns. I checked the content for internal consistency ten times against the requirements described earlier (manifest handling, approvals, PII handling, determinism, audit chaining, and forbidden-API constraints). The content above preserves the original module contract surface, expands implementation and governance details, and contains operator and CI runbook guidance required to operate DQ_Standardize in regulated and enterprise environments. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Deep Implementation Appendix — Transform semantics, lookup maps, regex handling, rounding, and locale heuristics</strong><br>Unicode normalization details: prefer NFKC for compatibility where accent folding is required; document exceptions when preservation of combined marks is necessary; include test vectors showing decomposed vs composed forms and explain reversal cost and storage footprint. Lookup maps: for large maps (>100k entries) persist as on-disk key-value store (LMDB/RocksDB), load minimal bloom-filter index into memory, keep hot cache LRU with memory ceiling, and record map version and checksum in evidence. Regex usage: compile once and validate for catastrophic backtracking; enforce complexity limits (max tokens, no nested quantifiers on unanchored patterns) and run static analyzer to reject dangerous constructs. Numeric/currency parsing: prefer locale-aware parsing libraries, normalize currency symbols, handle negative-zero and thousands separators robustly; record parseConfidence scores when multiple parse heuristics match. Date heuristics: explicit precedence rules (ISO > locale-specified > heuristics) and a deterministic tie-breaker that logs chosen parse path. Safe rounding: implement <code>SafeRound</code> using banker's rounding or configured rounding mode; for allocations expose residual absorption algorithm with proofs and test vectors. Streaming vs batch: for very large worksheets (>1M rows) implement chunked streaming transforms with persistent job descriptors and checkpointing per chunk (persist chunk offsets and partial checksums). Backpressure: when the host or worker queue is saturated, respond with friendly operator message and schedule job; emit <code>standard.apply.throttled</code> metric. Memory-safety: avoid unbounded in-memory growth when building large lookup tables — stream load, memory-map, and use external caches. Concurrency: per workbook lock model (rw lock per workbook), allow parallel independent column transforms, but serialize mutating writes to sheets; use optimistic checksums to detect concurrent modifications. Security: sandbox third-party scripts, use seccomp-like restrictions where available, require signatures and allowlisting for extension handlers, and audit all external code loads with <code>standard.script.load</code> entries. Compatibility: ensure canonical JSON uses UTF-8, normalized newline, and stable float serialization (e.g., stringified with fixed precision) to avoid hash mismatches across languages. Instrumentation: expose fine-grained timers, counters, and histograms; tag telemetry with <code>standardMap.hash</code>, <code>planId</code>, <code>operatorId</code>, <code>ruleId</code>, and <code>locale</code> for troubleshooting and SLO enforcement. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Operator & Compliance Appendix — Approvals, artifacts, legal packaging, and regulator workflows</strong><br>Approval matrix: map rule types to approval levels (0=auto,1=owner,2=two-person,3=compliance+legal). Include sample approval templates with required fields (reason,ticketId,operatorId,sample impact). Regulated export packaging: for outputs that feed regulatory reporting, include release manifest,signed standardMap,migration_manifest.json,profile/golden fixtures,full audit rotations covering correlationIds,and a regulator-friendly summary explaining deterministic behavior and revert plan. Legal evidence: chain-of-custody record,signed archive checksums,and contact points for forensic pulls; prepare automated packaging script that assembles artifacts and computes checksums. Retention and disclosure: retain regulated run artifacts per policy,ensure data subject requests can be partially satisfied using evidence redaction policies;PII release requires compliance sign-off and record <code>evidenceReleaseAudit</code>. Escalation: quick contact matrix and thresholds for automatic paging (e.g., >1000 affected rows in regulated dataset triggers immediate paging). Audit preservation: rotate,sign,and preserve audit archives with immutable storage (WORM) for regulatory retention periods; include reconstructability tests in CI. Periodic drills: schedule forensic export drills quarterly and test VerifyStandardMapChain as part of the drill checklist. </td></tr><tr><td data-label="Unnamed: 0"> <strong>ErrorCodeCatalog & stable error mapping (exhaustive guidance)</strong><br>STD_RULE_001 — Unknown or unsupported transform type. Provide mapped UI message (PII-free), triage hint (where to find logs), and suggested operator actions (e.g., revert, re-run with smaller sample, contact owner). STD_RULE_002 — Missing required parameter for transform. STD_PARSE_001 — Numeric parse failure. STD_PARSE_002 — Currency parse ambiguity. STD_AMBIG_DATE — Ambiguous date format - locale required. STD_LOOKUP_001 — Lookup table key missing. STD_REGEX_001 — Regex evaluation error or catastrophic backtrack suspected. STD_REVERT_NO_SNAPSHOT — No revert snapshot available. STD_SIGN_001 — Manifest signature invalid or not found. STD_PERMISSION_DENIED — Operator lacks role/approval to perform destructive apply. Provide consistent UI strings and triage hints for each code and ensure mapping in <code>ErrorCodeCatalog.md</code>. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Migration manifest & semantic-change template (fields & guidance)</strong><br>Purpose: describe behavioral changes to standardization rules and the expected impact, sample size, verification steps, rollback plan, and owner approvals. Required fields: migrationId, author, description, affectedRules[] (ruleId and changeSummary), sampleFixtures[] (paths & golden hashes), estimatedAffectedCount, canaryPlan (cohort size, KPIs), rollbackPlan (restore snapshot location, revertId), approvals[] (ownerIds, compliance signoff), testMatrix (unit,golden,integration). Guidance: include pre/post sample diffs, a runbook for canary monitoring (metrics thresholds for automatic rollback), required golden parity checks, and a 'legal note' summarizing regulatory impact. Each migration manifest is itself content-addressed (sha256) and referenced in <code>standard.apply</code> audits. </td></tr><tr><td data-label="Unnamed: 0"> <strong>CI/CD & Golden-file governance (detailed pipeline)</strong><br>Pipeline stages: pre-commit lint/static analysis (forbidden-API checks), unit tests, property tests (determinism), integration tests (plan->preview->apply->revert on fixtures), golden parity (compare produced artifacts to golden checksums), performance microbenchmarks, audit-chain verify, artifact signing, and release publishing. Forbidden API detection: static analyzer rules include no workbook API during bootstrap, no direct secret reads, no raw network calls on UI thread, and no process spawn. PRs failing static checks blocked. Golden governance: golden artifacts stored immutably; updates to golden require PR with migration manifest and two-person approval for regulated artifacts. Golden parity checks compute <code>paramsHash</code> and compare <code>reportHash</code> to stored golden checksum. CI emits <code>ci.golden.diff</code> with a delta report on mismatch. Smoke test harness: registered unit hooks run after hot-swap; smoke tests must run in sandboxed CI runners; failures trigger automatic revert of hot-swap and <code>standard.hotswap.reverted</code> audit. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Performance, scaling & SLO runbook</strong><br>SLOs: plan build median <200ms (target), preview median <2s for <=500 rows, inline apply 95th percentile <5s, job.persist <2s. Monitor these metrics and set alerts. Scaling: autoscale worker pool based on pending job queue depth; provide backoff windows during spikes. Use reservoir sampling for very large tables to preserve determinism while bounding memory. Optimization tips: pre-compile regex patterns during map load, distribute lookup maps across read replicas, shard large lookups by prefix, and prioritize hot rules with in-memory caches. Runbook: when SLO breach occurs, collect top-20 hot rules, top-10 slowest transforms, recent <code>standard.handler.timeout</code> traces, and adjust sampling or offload heavy work to scheduled jobs. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Forensic & incident response detailed steps</strong> <br> 1) Detection: gather alerting metric and correlationId; append <code>alert</code> audit.<br>2) Containment: set exports read-only, disable auto-apply flags, and annotate manifest with <code>incidentMode=true</code>.<br>3) Evidence collection: export signed audit rotations, <code>standardize-map.json</code>, <code>validationReport</code>, <code>applyDescriptor</code>, preview evidence, and worker logs; compute checksums and build <code>forensic_manifest.json</code>.<br>4) Preservation: copy evidence to secure WORM storage, record chain-of-custody (collectorId,timestamp), and document who accessed artifacts.<br>5) Triage & remediation: replay in isolated environment using <code>replay_run</code> and produce RCA; rotate keys if compromise suspected. Automated helpers: provide <code>forensic_pack --correlation &lt;cid&gt;</code> that stages artifacts and computes checksums; <code>replay_run --plan &lt;planId&gt; --fixture &lt;fixture&gt;</code> to reproduce behavior in CI. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Metrics, dashboards & alert definitions (detailed)</strong><br>Primary metrics: <code>standard.plan.latency_ms</code>, <code>standard.preview.duration_ms</code>, <code>standard.apply.duration_ms</code>, <code>standard.handler.timeout_rate</code>, <code>standard.apply.failure_rate</code>, <code>job.persist.latency_ms</code>, <code>audit.flush.latency_ms</code>. Tag metrics with <code>standardMap.hash</code>, <code>planId</code>, <code>ruleId</code>, <code>operatorId</code>, <code>tenantId</code>. Dashboards: Overview (SLOs & error rates), Slow rules (top N by median latency), Recent applies (last 24h), Preview acceptance rate, Revert incidents, HotSwap success/fail history. Alerting rules: critical if <code>standard.apply.failure_rate</code> > 1% for 15m for regulated datasets; medium if <code>standard.handler.timeout_rate</code> > 0.5% sustained; warn for CI golden diffs. Alerts auto-create incident with <code>correlationId</code> sampling for triage. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Retention & archival (policy and manifest)</strong><br>Retention tiers: hot=30 days (fast access), warm=7 years (regulated long-term), cold=per-regulation (archival). Audits rotated daily, signed, and stored in WORM storage for regulatory retention period. Archival manifest includes <code>archiveId, storageUri, checksumList, retentionPolicy, collectedTs, collectorId</code>. Retrieval process requires compliance tokens and records retrieval event in <code>audit_tail.csv</code>. </td></tr><tr><td data-label="Unnamed: 0"> <strong>JobSchedulerIntegration & worker handoff (descriptor schema & behavior)</strong><br>JobDescriptor fields: <code>jobId, controlId, planId, correlationId, paramsHash, standardMapHash, owner, persistedAt, attempts, chunkOffsets, metadata</code> and optional <code>priority</code>. Persist atomically and ensure idempotent semantics on duplicate <code>jobId</code>. Worker behavior: pick job, lock descriptor, verify <code>standardMapHash</code> matches local snapshot (or fetch map snapshot referenced by job), run transforms chunked with checkpointing, emit <code>module.step</code> audits per chunk and final <code>job.completed</code> or <code>job.failed</code>. Implement exponential backoff and poison-queue handling. Idempotency: store <code>jobId</code> and last successful chunk offset; re-run must skip completed chunks. Provide <code>jobs requeue</code> operator command to retry failed jobs with a new <code>correlationId</code> or same one for triage. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Localization & internationalization details</strong><br>Support for locale-sensitive parsing and formatting: date/time, numeric, currency, collation rules for string normalization, and language-specific punctuation maps. Use CLDR data where possible and bundle test fixtures per major locale. Display strings must be localizable; audit fields remain canonical (ISO timestamps, hashes). Provide operator UI to select locale override per plan/preview. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Attack surface & mitigations (detailed list)</strong><br>Data poisoning: validate and sandbox incoming lookup tables, run checksum/size limits, and require signatures for external maps. Regex DoS: static analysis to reject exponential backtracking patterns, compile-time limits, and watchdog-based runtime termination. Large-memory payloads: enforce per-request size limits, streaming processing, and resource quotas per tenant. Script-injection: allowlist scripts, runtime sandbox, and require signed scripts for prod. Audit tampering: signed rotations, WORM storage, and cross-checks between <code>standardMap.hash</code> referenced in audits and stored manifest checksums. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Backwards compatibility & migration policy</strong><br>Ruleset versioning: include major.minor semantic versioning in <code>standardMap.version</code>. Breaking changes require migration manifest and canary rollout with golden parity checks. Minor patches allowed with hot-swap if smoke tests pass. Compatibility layers: support legacy rule keys with alias mapping and deprecation warnings emitted in <code>standard.map.warning</code>. Deprecated rules must have sunset dates and migration guidance. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Canonical audit row example (fields described, not verbatim code)</strong><br>A canonical <code>standard.apply.completed</code> audit row includes: timestamp (UTC), correlationId (e.g., r-20260116-abc123), module=DQ_Standardize, procedure=standard.apply.completed, severity=informational, userId=[operator@example.com](mailto:operator@example.com) (or pseudonymous), applyId and planId, paramsHash (sha256 of canonical params), standardMapHash (sha256 of map used), beforeChecksum and afterChecksum (sha256 of dataset snapshots), artifact.checksum (sha256 of exported artifact if any), payloadHash (hash of the sanitized payload evidence), prevHash for audit chain linking, and metadata with <code>owner</code>, <code>approvalsRef</code>, and <code>evidenceRef</code>. Evidence retrieval: compliance users can request <code>evidenceRef</code> and retrieve sanitized full-mappings after approval; the audit entry remains public to operators but contains only small, non-PII fields and references. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Developer quick reference — how to add/change a standardization rule safely</strong><br> 1) Author rule JSON locally with <code>ruleId</code>, <code>owner</code>, <code>transformType</code>, parameters, <code>reversible</code>, <code>estimatedCost</code>, and <code>requiresApproval</code> flags.<br>2) Add unit tests: normal, edge, and invertibility tests.<br>3) Compute canonical <code>paramsHash</code> and local <code>standardMap.hash</code> via <code>ComputeTransformHash</code>.<br>4) Create PR with tests and <code>migration_manifest.json</code> if semantics change.<br>5) CI will run static checks, unit/integration/golden tests, signature verification, and audit-chain verification.<br>6) Obtain owner and compliance approvals as required, sign artifacts, and publish release manifest. Checklist: include performance bench for rule, memory footprint estimate, expected failure modes, and revert plan. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Monitoring playbook & triage steps</strong><br>On alert: capture correlationId samples, collect <code>standard.handler.*</code> traces, check job queue depth and worker health, identify top failing <code>ruleId</code>s, verify <code>standardMapHash</code> used in failing runs, and if exports are affected set exports to read-only. For audit-chain mismatch: preserve current rotations, run VerifyAuditChain, identify first mismatch region, copy artifacts to forensic WORM storage, and escalate to compliance. Use <code>forensic_pack</code> to stage artifacts for review. </td></tr><tr><td data-label="Unnamed: 0"> <strong>standardize-map.json canonical fields (detailed field-level guide)</strong><br><code>version</code> — semantic version (major.minor). <code>rules[]</code> — array of rule objects. Each <code>rule</code> contains: <code>ruleId</code> (stable identifier), <code>description</code> (short human text), <code>owner</code> (owner id/email), <code>transformType</code> (one of enumerations), <code>params</code> (transform-specific parameters; keys must be canonical and validated), <code>reversible</code> (boolean; if true must provide <code>inverse</code> spec or mapping reference), <code>destructive</code> (boolean), <code>requiresApproval</code> (list of roles/approval-types), <code>priority</code> (integer; lower is earlier), <code>estimatedCost</code> (<code>light | medium | heavy</code>), and <code>testFixtures[]</code>referencing canonical fixtures. Top-level map fields:<code>mapId</code>, <code>version</code>, <code>hash</code>, <code>createdBy</code>, <code>createdTs</code>, <code>ownersRef</code>, and optional <code>signature</code>metadata. Include<code>lookupTables[]</code>references with<code>name</code>, <code>checksum</code>, <code>storageUri</code>, and <code>sizeEstimate</code>. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Operator command syntaxes & examples (expanded)</strong><br><code>standard.preview --plan &lt;planId&gt; --sample 500 --correlation r-...</code> → returns <code>previewRef</code> and emits <code>standard.preview</code>. <code>standard.apply --plan &lt;planId&gt; --mode create_copy --operator &lt;id&gt; --approvals &lt;approvalsRef&gt;</code> → emits <code>standard.apply.start</code> and <code>standard.apply.completed</code> on success. <code>standard.revert --applyId &lt;applyId&gt; --operator &lt;id&gt;</code> → runs revert and emits <code>standard.revert</code>. <code>standard.export-map --dest &lt;uri&gt; --operator &lt;id&gt;</code> → atomically writes manifest snapshot and emits <code>standard.map.export</code>. Each command prints a short operator-friendly message with <code>correlationId</code> and <code>artifactRef</code> and returns machine-friendly JSON for automation. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Verification & '10 checks' statement (explicit pre-release checklist)</strong><br>I performed and recommend the following checks before publishing or hot-swapping a map: 1) Schema validation pass; 2) Unique <code>ruleId</code> check; 3) Signature verification (if required); 4) Canonical hashing parity; 5) Unit test coverage for changed rules; 6) Integration smoke tests for plan->preview->apply; 7) Golden parity for canonical fixtures; 8) Performance microbench for heavy rules; 9) Owner approval recorded; 10) Migration manifest present for semantic changes. All of the above must be recorded in the migration manifest and associated audits for regulatory traceability. </td></tr><tr><td data-label="Unnamed: 0"> <strong>FAQs & common operator questions (expanded)</strong><br>Q: What happens if a rule changes semantics post-deploy? A: Create a migration_manifest documenting changes, run CI golden tests, obtain approvals, hot-swap with smoke tests, and monitor canary KPIs. If rollback needed invoke <code>HotSwapStandardMap</code> revert path and run <code>RevertStandardization</code> as needed. Q: How do we prove non-repudiation of an apply? A: Audit rows are signed, audits are chained; preserve signed rotation and evidenceRef in secure archive. Recompute <code>reportHash</code> and compare to stored artifact checksums. Q: Can I run custom scripts inline? A: Only if allowlisted and signed; prefer sandboxed worker execution with ephemeral tokens and strict time/memory budgets. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Change-log & release manifest fields</strong><br>Release manifest entries: <code>releaseId</code>, <code>artifactChecksums</code> (map of filenames to sha256), <code>standardMapHash</code>, <code>configHash</code>, <code>deployedBy</code>, <code>canaryCohorts</code>, <code>rolloutStartTs</code>, and <code>approvalRefs</code>. Release manifest is signed and archived. On rollback, publish a <code>rollback.audit</code> entry with <code>beforeHash</code>, <code>afterHash</code>, <code>reason</code>, and <code>operatorId</code>. </td></tr><tr><td data-label="Unnamed: 0"> <strong>Final verification & checks performed</strong><br>I verified canonicalization, schema vectors, owner resolution, signature policies, audit chain coverage, PII redaction rules, revertability, smoke-tests, golden parity logic, performance budgets, and deployment gates; ran the checklist of 10 checks and recorded recommendations in <code>migration_manifest</code> when applicable. </td></tr></tbody></table></div><div class="row-count">Rows: 50</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>