<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1768716778">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li>
<li class="toc-item"><a class="toc-link" href="#Table6">Table 6</a></li>
<li class="toc-item"><a class="toc-link" href="#Table7">Table 7</a></li>
<li class="toc-item"><a class="toc-link" href="#Table8">Table 8</a></li>
<li class="toc-item"><a class="toc-link" href="#Table9">Table 9</a></li>
<li class="toc-item"><a class="toc-link" href="#Table10">Table 10</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0176_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Data Governance &amp; Regulatory Delivery Platform — Project Overview"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Data Governance & Regulatory Delivery Platform — Project Overview</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Summary</strong><br>A coordinated suite of Excel add-ins (XLAMs) designed for enterprise-grade data pipelines, evidence capture, and regulatory delivery. The platform’s aim is to bring reproducible, auditable data processing into analysts’ primary environment (Excel) while preserving engineering-grade controls: deterministic transforms, cryptographic evidence, CI-gated changes, and operational runbooks. Key capabilities: deterministic profiling & remediation (DQGuard), Power Query template management & injection (PQTools), and domain-specific regulatory calculations with golden-file parity (Regulatory). The platform is intended to be the operational boundary between human-in-the-loop data work and automated, signed artefact delivery to downstream reporting/ regulatory systems. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>One-line elevator pitch</strong><br>“An enterprise Excel add-in platform that makes data-quality, Power-Query template management, and regulatory calculations deterministic, auditable, and safe to operate at scale.” </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — DQGuard.xlam (Data Quality Guard)</strong><br><strong>Purpose & scope:</strong> detect, profile, validate, propose, and safely apply data-quality fixes to Excel tables and Power Query outputs. DQGuard does <strong>not</strong> replace upstream source systems — it prepares, documents, and outputs traceable corrections that downstream consumers can trust.<br><strong>Core responsibilities (detailed):</strong> deterministic profiling (seeded sampling), rule evaluation (stable rule IDs, severities), standardization pipelines (reversible transforms, mapping evidence), match & merge (deterministic grouping, tie-breakers), remediation proposal generator (rationale, examples, confidence), operator review UI (preview with PII redaction), apply engine (create_copy default, inline with approvals), reconciliation (checksums & diffs), export packaging (atomic write + checksum), audit row emission and evidence bundling (encrypted archives).<br><strong>Key modules & roles:</strong> <code>DQ_Ribbon</code> (UI entrypoints, minimal IO), <code>DQ_Profile</code> (metrics generation, sampling), <code>DQ_Rules</code> (rules engine, deterministic evaluation), <code>DQ_Standardize</code> (standardization map runner), <code>DQ_MatchMerge</code> (blocking/greedy matching and merges), <code>DQ_Remediation</code> (proposal generation), <code>DQ_Apply</code> (applier & reversible plans), <code>DQ_Export</code> (atomic export & checksum), <code>DQ_Audit</code> (append-only chain), <code>DQ_Utilities</code>, <code>DQ_Config</code>.<br><strong>Typical outputs & evidence:</strong> <code>profile_report.csv</code>, <code>validation_report.csv</code>, remediation <code>proposal_&lt;id&gt;.json</code>, <code>applyDescriptor</code>, <code>before/after</code> snapshots, <code>recon_report.json</code>, audit rows with <code>correlationId</code>, encrypted evidence bundles with per-artifact checksums. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — PQTools.xlam (Power Query templates & injection)</strong><br><strong>Purpose & scope:</strong> provide a managed library of canonical Power Query (M) templates, tools to parameterize & preview M, inject trustworthy queries into workbooks, manage connections, and collect refresh diagnostics — all with full audit trails.<br><strong>Core responsibilities (detailed):</strong> embedded template registry (hidden sheet or external repo), template versioning and mChecksum computation, parameterization UI, safe injection (<code>Workbook.Queries.Add</code>), optional connection creation (connection-only vs model), refresh & diagnostic capture (provider, duration, error capture), export of M + diagnostics (atomic + checksum), governance hooks for regulated templates (PR, owner approval, signed artifacts).<br><strong>Key modules & roles:</strong> <code>PQ_Ribbon</code>, <code>PQ_LibraryManagement</code>, <code>PQ_Injector</code>, <code>PQ_Connections</code>, <code>PQ_Refresh</code>, <code>PQ_Export</code>, <code>PQ_Audit</code>.<br><strong>Typical outputs & evidence:</strong> <code>m_&lt;templateName&gt;.pq</code>, <code>mChecksum</code>, <code>pq_diagnostics/&lt;run-id&gt;.json</code>, template change manifests, injection audit rows referencing <code>mChecksum</code>, release artifacts for approved templates. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Per add-in — Regulatory.xlam (Regulatory Engine)</strong><br><strong>Purpose & scope:</strong> run deterministic, auditable regulatory calculation pipelines (examples: IFRS recognitions) and produce signed outputs suitable for regulatory filing or downstream deterministic consumers. The regulatory add-in enforces stricter governance: golden parity, two-person approvals for behavioral changes, and scheduled verifications in CI.<br><strong>Core responsibilities (detailed):</strong> canonical pipeline stages (normalization → validation → allocation → recognition schedule → journal mapping), isolated execution model (job scheduler + worker runner), SafeRound & residual absorption for allocations, canonical artifact creation (reports, journals), atomic export with fallback, audit chain rotation & signing, integration with release manifest and canary rollouts, and regulatory-package assembly for incidents and audits.<br><strong>Key modules & roles:</strong> <code>REG_Ribbon</code>, <code>REG_Bootstrap</code>, <code>REG_Config</code>, <code>REG_EnsureDeps</code>, <code>REG_Utilities</code>, <code>REG_Calculations</code>, <code>REG_Export</code>, <code>REG_Audit</code>, <code>REG_Error</code>.<br><strong>Typical outputs & evidence:</strong> canonical report sets, signed release manifests, golden fixtures, audit rotations, reconciliation artifacts used for CI golden parity checks. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>What project is this? explanation</strong><br><strong>Name (conceptual):</strong> Excel Data Governance & Regulatory Delivery Platform.<br><strong>Primary mission:</strong> enable analysts and stewards to perform trustworthy data preparation and regulatory calculation tasks inside Excel while preserving engineering controls — reproducibility, auditability, deterministic outputs, and safe deployable artifacts.<br><strong>Core functional pillars:</strong> 1) <em>Detect & prepare</em> (DQGuard), 2) <em>Template & pipeline management</em> (PQTools), 3) <em>Authoritative regulated computations & delivery</em> (Regulatory).<br><strong>Non-goals / out-of-scope (explicit):</strong> replacing source-of-truth systems, persistent secret key management outside KMS/HSM workflows, or implicitly mutating external systems without explicit, auditable integration. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Typical stakeholders & outputs</strong><br><strong>Stakeholders:</strong> Operators (daily users), Data Stewards (policy owners), Rules Owners (domain logic maintainers), Developers (module maintainers), Release Engineers (CI/CD & signing), Compliance (regulatory reviewers), On-call SRE (runtime & incidents), Business owners (acceptance).<br><strong>Primary artifacts produced:</strong> <code>audit_tail.csv</code> (append-only local tail), signed audit rotation archives, <code>profile_report.csv</code>, <code>validation_report.csv</code>, <code>standardize-map.json</code> + signature, <code>migration_manifest.json</code> (for semantic changes), exported datasets (atomically written + checksummed), preview artifacts (UI redacted + evidence bundles), release manifests, golden fixtures and parity reports. These artifacts are stored in artifact stores with chain-of-custody metadata for regulated runs. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Typical workflow — fully expanded step-by-step</strong><br>1. <strong>Bootstrap</strong>: Excel starts; Add-in Loader loads minimal code; <code>CORE_Bootstrap</code> opens structured logs, seeds correlation ID generator, registers shutdown hooks. <em>Constraint:</em> no heavy IO or Excel Range reads during bootstrap. {audit: bootstrap.started}.<br>2. <strong>Deferred init (UI Idle)</strong>: <code>CORE_Config</code> loads config (validate JSON schema v7), computes <code>config.hash</code>, applies idempotent migrations; <code>CORE_EnsureDeps</code> verifies external integrations and produces <code>deps.report.json</code>; <code>CORE_Utilities</code> loads deterministic helpers (SafeRound, AtomicWrite, DeterministicRNG); <code>CORE_ManifestLoader</code> reads manifests & <code>OWNERS.md</code>. Add-in specific assets (rules/rule maps, PQ templates, regulatory fixtures) are loaded deferred. {audit: config.loaded, rules.loaded:version}.<br>3. <strong>Ribbon ready</strong>: UI initialized, <code>ribbon.ready</code> audit row appended.<br>4. <strong>Operator picks Add-in</strong>: DQGuard / PQTools / Regulatory. The ribbon click logs a <code>UserAction</code> audit with correlation id. Lightweight actions run inline; heavy actions schedule a job. {audit: UserAction(module=..., procedure=click)}.<br>5. <strong>DQ flow (example)</strong>: run <code>DQ_Profile</code> → deterministic sample & metrics → <code>DQ_Rules</code> → validation report → <code>DQ_Remediation</code> propose fixes → operator preview via <code>PreviewStandardize</code> (redacted) → operator decision (reject / accept) → if accept then <code>DQ_Apply</code> creates reversible apply descriptor and persists apply job → <code>DQ_Export</code> writes corrected dataset atomically → <code>DQ_Audit</code> appends final audits and evidence reference. All steps record <code>correlationId</code>, <code>payloadHash</code>, <code>artifact.checksum</code> as applicable.<br>6. <strong>PQ flow (example)</strong>: user picks template → parameterize → preview M → inject into workbook (optionally create connection) → run refresh/diagnostics → export M + diagnostics → audit rows including <code>mChecksum</code> and operatorId. Template edits require PR + owner approval for regulated templates.<br>7. <strong>REG flow (example)</strong>: operator triggers regulated calculation → action scheduled as job (heavy) → <code>CORE_JobScheduler</code> persists job descriptor {jobId, params, configHash} → isolated <code>CORE_ExecutionWorker</code> runs canonical pipeline, using <code>SafeRound</code> for allocations → produce deterministic artifacts → <code>REG_Export</code> -> atomic write + checksum + staged fallback if network down → <code>CORE_Audit</code> rotates & signs. Post-run: reconciliation, attach release manifest, golden-file checks. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Why this architecture reasoning</strong><br>1. <strong>Excel ubiquity</strong>: Excel is the de-facto environment for analysts and stewards; embedding enterprise patterns in XLAMs reduces ad-hoc error-prone workflows.<br>2. <strong>Separation of concerns</strong>: isolating DQ, PQ, and REG responsibilities reduces coupling and allows specific governance and testing regimes per area (e.g., golden parity for REG, template governance for PQ, proof-of-fix for DQ).<br>3. <strong>Determinism & evidence</strong>: deterministic transforms, canonical JSON hashing, signed manifests, and encrypted evidence bundles allow reproducibility & regulatory defense; evidence becomes the legal record rather than ephemeral console logs. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Governance, approvals & CI/CD</strong><br><strong>Change control:</strong> any change that materially alters regulated outputs needs: PR, unit & integration tests, golden parity tests, migration manifest (with sample diffs & rollback plan), and two-person approval. <br><strong>CI pipeline:</strong> static analysis (forbidden APIs), unit tests, property tests for determinism, integration tests (plan→preview→apply→revert chains), golden parity checks across locales/bitness, performance microbenchmarks, audit chain verification, artifact signing, and publishing. CI must block merges on golden parity or audit-chain failures for regulated artifacts.<br><strong>Release flow:</strong> produce signed release manifest (artifact checksums, map hashes, configHash); canary rollouts with KPI gating (false positives, operator acceptance, latency); automatic expand or rollback based on KPI thresholds; produce release audits and retention snapshots. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Security, secrets & PII handling</strong><br>- XLAMs must be code-signed; macros enabled policy enforced by org controls.<br>- Raw secrets never read by utilities; use <code>modSecurity</code> to obtain ephemeral tokens & KMS/HSM operations. Evidence bundles encrypted via KMS envelopes. <br>- PII is redacted in UI previews; full sanitized evidence retained in encrypted evidence stores referenced by <code>evidenceRef</code>. Audit rows only contain minimal or pseudonymous fields. <br>- Incident playbook: set exports read-only, quarantine helpers, export rotated audits to forensic share, compute <code>forensic_manifest.json</code> (sha256 checksums), run VerifyAuditChain, notify Compliance/regulators per timelines. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Observability & metrics</strong><br><strong>Telemetry:</strong> buffered <code>util.*</code> metrics for core helpers; module metrics like <code>standard.preview.duration_ms</code>, <code>standard.apply.duration_ms</code>, <code>pq_refresh.latency_ms</code>, <code>reg.calc.duration_ms</code>. <br><strong>Audit rows:</strong> mandatory for every operator action; minimal fields: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code> (include <code>standardMap.hash</code> or <code>configHash</code> where relevant). <br><strong>Dashboards & alerts:</strong> SLOs & alerts for failing golden parity, high <code>handler.timeout_rate</code>, export failure spikes, and sudden increases in remediation acceptance/reject rates. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Evidence & artifact retention (expanded)</strong><br><strong>Retention tiers:</strong> hot=30d (fast access), warm=7y (regulated long-term), cold=per regulation. Evidence bundles for regulated runs preserved immutably (WORM) with chain-of-custody metadata and signed rotations. <strong>Forensic packages</strong> include: release manifest, signed map, audit rotations, preview evidence, apply descriptors, checksums, and <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Quick recommended repo & artifact layout</strong><br>`<code>/repo</code><code> root contains subprojects and CI infra.&lt;br&gt;</code><code>/repo/dqguard</code><code> — </code>src/<code> (VBA modules + any TypeScript/Node helper tools), </code>assets/standardize-map.json<code>, </code>OWNERS.md<code>, </code>tests/<code> (unit/integration/golden), </code>docs/runbooks/<code>.&lt;br&gt;</code><code>/repo/pqtools</code><code> — </code>templates/<code> (hidden-sheet loader, external template sync), </code>src/<code>, </code>tests/<code>.&lt;br&gt;</code><code>/repo/regulatory</code><code> — </code>calculations/<code> (canonical pipelines), </code>fixtures/<code> (golden), </code>selftests/<code> (parity harness), </code>tests/<code>.&lt;br&gt;</code><code>/repo/core</code><code> — </code>src/modUtilities.bas<code>, </code>src/modBootstrap.bas<code>, </code>src/modAudit.bas<code>, </code>tests/<code> (safe_round vectors, RNG golden), </code>release/<code> (</code>Core.xlam<code>).&lt;br&gt;</code><code>/repo/ci</code><code> — pipeline.yml, golden/, smoke-test-harness/, release-manifests/, signing-keys-integration (CI hooks).&lt;br&gt;</code><code>/repo/docs</code>` — runbooks, operator-cheatsheets, migration_manifest_template.json, ErrorCodeCatalog.md. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Implementation priorities — suggested roadmap</strong><br>1. <strong>Core primitives (Core.xlam)</strong>: SafeRound, AtomicWrite, ComputeChecksum, DeterministicRNG, CanonicalJsonSerialize. Implement unit tests and golden vectors. <br>2. <strong>Audit rotation & evidence store</strong>: append-only tail, rotation signing, evidence bundle encryption. <br>3. <strong>DQGuard minimal pipeline</strong>: profile → rules → proposal → preview → create_copy apply → export. <br>4. <strong>PQTools template management</strong>: embedded template store with mChecksum and injection plumbing. <br>5. <strong>Regulatory parity harness</strong>: canonical pipeline + CI golden tests and release manifest. <br>6. <strong>Operational runbooks & CI enforcement</strong>: static analysis, golden parity gates, signature enforcement. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Operational runbooks — examples to ship</strong><br>- <strong>Operator day-to-day:</strong> Profile → Preview → Propose → Apply (create_copy) → Reconcile → Export → bundle evidence & append audit.<br>- <strong>Release:</strong> PR → CI (tests + golden) → Sign → release manifest → canary → monitor KPIs → roll out or rollback → record rollout audits.<br>- <strong>Incident response:</strong> Detect → Contain (read-only exports) → Forensic export → Triaging & revert → Remediation & post-mortem → regulatory package if needed. </td></tr><tr><td data-label="Data Governance &amp; Regulatory Delivery Platform — Project Overview"> <strong>Risks & mitigations — high-level</strong><br>1. <strong>Non-determinism across hosts</strong> — mitigation: canonical JSON rules, seeded RNG, cross-platform golden parity tests. <br>2. <strong>Audit or evidence tampering</strong> — mitigation: signed audit rotations, WORM storage, VerifyAuditChain in CI. <br>3. <strong>Operator errors applying destructive fixes</strong> — mitigation: default <code>create_copy</code>, two-person approval enforcement, preview & redaction. <br>4. <strong>Performance on large datasets</strong> — mitigation: chunked transforms, worker offload, checkpointed job descriptors. </td></tr></tbody></table></div><div class="row-count">Rows: 17</div></div><div class="table-caption" id="Table2" data-table="Docu_0176_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — DQGuard.xlam (Authoritative Runbook)"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — DQGuard.xlam (Authoritative Runbook)</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing DQGuard.xlam. It governs detection, profiling, standardization, matching/merging, remediation proposals, safe application of fixes, exports, and audit generation for datasets that feed reporting, analytics, or regulatory outputs. If any other document conflicts with this runbook, this runbook takes precedence. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation or local adaptation requires a written exception, risk assessment, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Primary audience and responsibilities</strong><br>Roles: Operator, Data Steward, Rules Owner, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Each procedural section below is labeled with the relevant role and lists required evidence and verification steps. Operators execute routine tasks; Data Stewards approve rules and remediation policies; Developers implement rule logic and tests; Release Engineers manage deployments and rollbacks; Compliance reviews regulated changes and migration manifests. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>High-level purpose, out-of-scope items</strong><br>Purpose: deterministic, auditable detection and controlled remediation of data quality issues in Excel tables and Power Query results. Out of scope: replacing canonical source systems, performing secret key management outside defined KMS/HSM workflows, or mutating external systems without explicit, auditable integration. Integrations (database connectors, APIs) are permitted only with documented connectors and explicit security review. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Core principles and non-negotiables</strong><br>1) Determinism: same input and configuration must produce identical outputs.<br>2) Auditability: every material action appends an append-only audit row with correlation ID and payload hash.<br>3) Reversibility: remediation plans are reversible by default; apply actions produce a preserved "before" copy unless governed approvals permit inline change.<br>4) Separation: detection ≠ correction. Detection never mutates original input without explicit acceptance. Any weakening of these principles requires a documented impact assessment and two-person approval. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Golden rule for operators</strong><br>Always capture the correlationId before, during, and after every run. Keep original data immutable and store it with an evidence manifest. Preview proposals; do not accept blind auto-fixes. For regulated outputs, require two-person approval before apply or enabling any auto-apply behavior. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Overview of runtime phases (guarantees & markers)</strong><br>Phases: bootstrap → deferred init → UI idle → detection (profile/rules/match) → remediation proposal → apply → export → audit rotation. Each phase emits distinctive audit markers (examples: <code>bootstrap.started</code>, <code>rules.loaded:vX</code>, <code>profile.completed:&lt;runId&gt;</code>, <code>remediation.proposed:&lt;proposalId&gt;</code>, <code>remediation.applied:&lt;applyId&gt;</code>). Detection must never perform destructive writes. Apply actions are auditable and produce before/after checksums. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Module map and single-responsibility contracts</strong><br><code>DQ_Bootstrap</code>: start-up, correlation id, non-IO init only.<br><code>DQ_RibbonCallbacks</code>: maps UI controls to handlers, ensures correlation id tagging, logs <code>UserAction</code> audit rows.<br><code>DQ_Config</code>: config loading, schema validation, idempotent migrations, expose <code>config.hash</code>.<br><code>DQ_Utilities</code>: shared helpers (atomic-write, SafeRound, retry, deterministic RNG).<br><code>DQ_Profile</code>: deterministic sampling and profile metrics. <br><code>DQ_Rules</code>: rule engine, stable rule IDs and severities. <br><code>DQ_Standardize</code>: normalization transforms with reversible mapping. <br><code>DQ_MatchMerge</code>: deterministic matching, tie-breakers, merge proposals. <br><code>DQ_Remediation</code>: propose and apply plans, create copy vs inline apply. <br><code>DQ_Export</code>: atomic export with checksum and retry. <br><code>DQ_Audit</code>: append-only chained audit records and rotation. <br><code>DQ_Error</code>: centralized error taxonomy and operator messaging. Each module publishes owner, API surface, and emits audit rows for critical transitions. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_Bootstrap — checks and operator evidence</strong><br>Must only initialize non-blocking tasks: open structured logs, create correlation id generator, schedule deferred init on UI idle, register shutdown hooks. MUST NOT perform heavy IO or access Excel ranges. Verify <code>bootstrap.log</code> contains <code>init-scheduled</code> and <code>correlationSeed</code>. Evidence to collect: <code>bootstrap.log</code>, <code>add-in registration state</code>, Excel process listing when disabled. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_RibbonCallbacks — UI/UX mapping & audit obligations</strong><br>Every ribbon control maps to one handler. Handlers: generate correlation id, log click, append <code>UserAction</code> audit row with <code>module</code>, <code>procedure</code>, <code>userId</code>, and minimal payload. Ribbon groups: Profile, Validate, Propose, Apply, Export, Diagnostics. Keep <code>ribbon-map.json</code> and include mapping verification steps in release checks. Evidence: <code>ribbon-map.json</code>, UI screenshots when needed, <code>audit_tail.csv</code> rows for interactions. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>DQ_Config — governance & migration policy</strong><br>Single source configuration for thresholds, sampling, matching tolerances, automation policies. Load once; validate JSON Schema v7; compute <code>config.hash</code>. Changes that alter remediation behavior require migration manifest with sample counts and rollback plan. Evidence: <code>config.json</code>, <code>config.hash</code>, <code>migration_manifest.json</code>, <code>config.audit</code> row. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Rule management (DQ_Rules) — lifecycle, IDs, and testing</strong><br>Rules have stable IDs, severity, textual description, and remediation guidance. Rule changes follow PR + automated tests + migration manifest for behavior changes. Unit tests must cover positive & negative fixtures and edge cases. Rule releases to production follow canary/pilot patterns. Evidence: rule PRs, test results, <code>rules.loaded:version</code> audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Profiling (DQ_Profile) — determinism & outputs</strong><br>Profile produces deterministic metrics with configured <code>seed</code> and <code>sampleSize</code>: rowCount, null counts, unique counts, top values, histograms, outliers, pattern frequencies, and deterministic sample rows for inspection. Output artifacts: <code>profile_report.csv</code>, <code>profile_summary.json</code>, sample CSVs. Profiling emits <code>dq_profile</code> audit row with <code>profileHash</code> and <code>runId</code>. Evidence: profile files, run logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Standardization (DQ_Standardize) — reversible transforms</strong><br>Standardizations: Unicode normalization, trimming, whitespace collapse, punctuation normalization, canonical date parsing to ISO 8601, currency and locale normalization. Record transform mapping for reversible ops. Operators MUST preview standardizations before apply. Evidence: <code>standardization_report.csv</code>, before/after samples. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Match & merge (DQ_MatchMerge) — deterministic grouping</strong><br>Matching algorithms output stable <code>mergeId</code> groups, similarity scores, and deterministic representative selection using explicit tie-breakers. Merge proposals list group members, representative row, confidence, and recommended action. Auto-merge requires explicit <code>AUTO_MERGE</code> flag plus two-person approval for regulated datasets. Evidence: <code>match_groups.csv</code>, preview artifacts. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Remediation proposals & apply policy (DQ_Remediation)</strong><br>Each proposal contains: <code>proposalId</code>, <code>ruleId</code>, rationale, affected count, confidence, sample before/after, and an <code>applyPlan</code> specifying <code>create_copy</code> (default) or <code>inline</code> apply. <code>create_copy</code> preserves the original worksheet/workbook and writes the fixed set to a separate sheet/workbook. <code>inline</code> requires auditable operator authorization and two-person approval when regulated. Applying a proposal appends <code>dq_apply</code> audit row with <code>beforeChecksum</code> and <code>afterChecksum</code> and stores a reversible plan. Evidence: proposal JSON, apply logs, preserved original copy. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Exports and artifact integrity (DQ_Export)</strong><br>All exports use atomic write semantics: write to temp file then rename/move to final location. Compute <code>artifact.checksum.sha256</code> and embed checksum in export metadata and audit row. If network upload fails, fallback to staged local delivery. Export audit fields include <code>destination.uri</code>, <code>attempts</code>, and <code>final.status</code>. Evidence: exported file, checksum file, <code>DQ_Export</code> logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Audit chain (DQ_Audit) — canonical record</strong><br>Audit rows are append-only and cryptographically chained. Each row minimally includes: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Chain verification runs periodically in CI and monitoring. Audit buffers are allowed but MUST flush within configured interval. Evidence: <code>audit_tail.csv</code>, signed rotation archives. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Error taxonomy & operator messaging (DQ_Error)</strong><br>Error codes map to stable messages and remediation hints in <code>ErrorCodeCatalog.md</code>. End-user messages show the correlation id only. Full diagnostic traces are stored in logs (encrypted-at-rest) and linked to the correlation id. High-severity errors auto-page on-call and generate an incident audit row. Evidence: <code>error.log</code>, mapping reference. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Configuration & feature flags (operations governance)</strong><br>Feature flags control sampling, auto-apply, and algorithm variants. Resolution precedence: runtime admin > remote config > local file > defaults. Flags that enable automatic correction for regulated data require two-person approval and an explicit migration manifest. Flag operations must be auditable and reversible. Evidence: <code>flags.audit</code>, flag history. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Canary & phased rollout (release pattern)</strong><br>Deploy rule changes via cohorts: pilot tenants → pilot users → larger cohort. Gate using KPIs: false positive rate, operator acceptance rate, apply success rate, profile latency. Rollback automatically on KPI threshold breaches. All rollout transitions recorded in <code>deployment.audit</code>. Evidence: release manifest, rollout audit rows, KPI snapshots. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Config migrations & offline tooling</strong><br>Migrations for rules or standardizations MUST include a migration manifest listing steps, sample transformations, estimated affected counts, and backout plan. Offline migration tooling supports dry-run and produces sample artifacts for compliance review. Migration runs append a <code>migration.audit</code> row. Evidence: <code>migration_manifest.json</code>, dry-run outputs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Runtime debug, safe-ops, and admin controls</strong><br>Admin debug panel provides controlled actions: verbose logging, reload rules, flush audit buffers, export diagnostics, or toggle non-critical flags. Access to debug requires MFA and an access ticket; every debug action records a <code>debug.audit</code> row with justification. Debug mode defaults to OFF and must be disabled post-troubleshooting. Evidence: <code>diagnostics.zip</code>, <code>debug.audit</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Security & incident response (IR) playbook</strong><br>Containment steps for suspected PII or audit compromise: set exports read-only, disable auto-apply flags, quarantine helper scripts, export rotated audit archives to secure forensic share, preserve environment snapshots, collect <code>bootstrap.log</code>, <code>dq_profile.log</code>, <code>dq_rules.log</code>, config snapshots, and job descriptors. Forensic manifest must include SHA256 checksums and chain-of-custody metadata. Notify Compliance and follow regulator-specific reporting timelines. Evidence: forensic archive and <code>forensic_evidence_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Forensic evidence manifest fields (required)</strong><br>The manifest MUST include <code>manifestId</code>, <code>collectedAt</code>, <code>collector</code>, list of artifacts (path, role, sha256), storage location, and contact for chain-of-custody. Store manifest in secure evidence repository and reference it from incident audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Containment, remediation & post-incident</strong><br>Containment: disable writes/exports, quarantine helpers, and preserve audit. Remediation: restore signed artifacts from immutable storage, rotate keys/credentials as needed, re-run VerifyAuditChain, and run regression tests on sample fixtures. Post-mortem deliverables: timeline, RCA, corrective actions, verification artifacts, and regulatory package when required. Record a <code>post-mortem</code> audit row with attachments. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Deployment, upgrade & rollback runbooks</strong><br>Pre-deploy checklist: signed artifacts, passing CI (unit/integration/golden parity), config snapshot, and audit rotation backup. Canary rollout with KPI gating. Emergency rollback: activate kill-switch, revoke remote flags, reinstall prior signed build, restore config snapshot, run rule self-tests and VerifyAuditChain, and publish <code>deployment.audit</code> rows for all steps. Evidence: signed installer, release manifest, rollback log. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>CI/CD gates and automated tests</strong><br>CI must run: lint, unit tests, rule regression tests using canonical fixtures, profile golden parity tests across locales and Excel bitness, deterministic match-merge tests, audit chain verification, performance microbenchmarks, and artifact signing. Releases without passing golden parity for regulated outputs require migration manifests and compliance approval. Evidence: CI reports, test artifacts, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Fixtures and golden-file governance</strong><br>Maintain canonical fixtures for profiling, rules, and match-merge across locales and Excel versions. Golden artifacts stored immutably. Any change requires PR, migration manifest, and compliance approval. CI compares outputs to golden hashes and blocks changes unless a migration path is approved. Evidence: <code>golden/*</code>, <code>ci-golden-report.json</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Performance SLAs, metrics, and remediation</strong><br>Instrument metrics: profile duration, rule eval latency, match-merge throughput, audit flush time, memory usage. Example thresholds: profile WARN>30s for small tables; CRIT>300s for large tables. Rule eval WARN>5s per 1k rows. Audit flush WARN>5s CRIT>30s. Remediation actions: scale sampling, increase worker counts, throttle concurrency, or run offline in isolated runner. Evidence: metrics dashboards and alert logs. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Monitoring, dashboards & alerting rules</strong><br>Monitor: top failing rules, remediation acceptance rate, recent large exports, audit chain health, profile latency. Alert playbooks include triage steps, required evidence, correlation id, and on-call contact. Critical alerts automatically page stakeholders and open incident tickets. Evidence: alert history and incident tickets. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>High-severity runbooks (concrete examples)</strong><br>1) Suspected PII exposure: set exports read-only, export forensic archive, run full PII-scan, notify Compliance/regulators, and preserve evidence.<br>2) Rule regression causing mass false positives: revert to last known-good ruleset, run golden comparisons, produce impacted-ID manifest, and notify owners.<br>3) Merge corruption: set runner to read-only, export match groups and sample merges, run reconciliation, restore from last verified signed baseline. Each runbook includes contact list, evidence checklist, and "must-do" audit steps. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Reconciliation & verification processes</strong><br>Reconciliation tooling compares corrected datasets to source-of-record. Standard workflow: dry-run, review affected IDs and samples, obtain operator sign-off, apply in copy mode, then re-run reconciliation and record <code>reconciliation.&lt;id&gt;</code> audit row. Required evidence: <code>reconciliation_report.json</code>, before/after checksums, operator approvals. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>PII handling, encryption & key management</strong><br>Classify PII fields and enforce redaction rules for any human-readable exports. Encrypt audit rotations and forensic archives using KMS/HSM-backed envelope encryption. Maintain key rotation schedules and multi-person approval for key export or audit-signing key changes. Keep a log of all key operations in the audit. Evidence: key rotation logs and signed audit rotations. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operator commands, UI flows, and exact evidence lists</strong><br>Operators must follow canonical UI flows: Profile → Validate → Propose → Preview → Apply (Create copy preferred) → Export. Each operation appends an audit row with <code>correlationId</code>. Evidence list per operation: correlationId, original workbook copy, profile report, proposal file, fixed copy (if applied), export artifact, and relevant log files. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operational cheat-sheets and one-page runbooks</strong><br>Provide copy-ready one-page checklists for: Profile success flow; Validation failure triage; Propose→Preview→Apply flow; Export and checksum verification; Reconciliation dry-run and apply. Store those cheat-sheets in <code>runbooks/cheatsheets/</code> and reference them in the UI help. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Post-mortem, change request, and regulatory package templates</strong><br>Templates capture: timeline, root cause, evidence attachments, mitigations, owners, and compliance sign-offs. Regulatory packages bundle release manifest, audit rotations, migration manifests, golden fixture diffs, and anonymized sample inputs/outputs demonstrating deterministic behavior. Store templates under <code>appendices/templates/</code> and require two-person approval to publish. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Canonical evidence templates (fields to capture)</strong><br>Audit CSV header: <code>timestamp,correlationId,module,procedure,severity,userId,payloadHash,prevHash,signature,metadata</code>.<br>Profile report fields: <code>runId,tableName,rowCount,nullRate,uniqueRate,topValues,...</code>.<br>Remediation proposal fields: <code>proposalId,affectedCount,confidence,exampleBefore,exampleAfter,ruleId</code>.<br>Reconciliation manifest fields: <code>reconciliationId,affectedIds,correctionSummary,operatorId</code>. Keep templates versioned. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Developer verification & acceptance checklist</strong><br>Developers must provide: unit tests for rule logic, integration tests for profile→rule→proposal chain, deterministic match-merge tests across locales, golden-file parity fixtures, audit chain verification tests in CI, performance benchmarks, signed artifacts, and compliance approvals for regulated-rule changes. CI failure blocks release. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Common failure modes and operator responses</strong><br>• Add-in missing: collect <code>bootstrap.log</code>, COM/VSTO state, reinstall signed artifact, record <code>install.audit</code>.<br>• Profile failure on large table: reduce sample size; run in isolated worker; collect <code>dq_profile.log</code> and staging outputs.<br>• Incorrect remediation applied: immediately restore preserved original copy, run reconciliation, collect <code>dq_apply.log</code> and open incident. Always collect evidence and record audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Audit compromise & forensic runbook (summary)</strong><br>Steps: set audit read-only, export rotations with checksums to forensic share, run VerifyAuditChain, locate first mismatch, restore or reconstruct last verified rotation under compliance, notify regulators as required, run kill-switch tests, and create a forensic manifest mapping artifacts to checksums. Record all steps in incident audit rows. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Training, drills, and retention</strong><br>Annual operator training on key flows. Quarterly tabletop exercise for a representative incident. Annual full forensic drill including audit export and VerifyAuditChain. Retention policy: hot=30d, warm=7y, cold=per regulation. Housekeeping tasks run monthly with audit entries. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Appendices & location of canonical artifacts</strong><br>Appendices include: audit row examples, profile schema, rule catalog format, remediation templates, migration manifest template, release manifest template, operator cheat-sheets, and glossary. Store all appendices and artifacts in immutable artifact storage with version tags, e.g., <code>runbook/v{major}.{minor}/appendices/</code>. Access controlled by RBAC; PRs required for edits. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Change-control checklist (must do before production change)</strong><br>1) Open change ticket and include rollback plan. 2) Run self-tests and include results. 3) Attach migration manifest if behavior changes. 4) Obtain two-person approval for remediation automation changes. 5) Sign artifacts and publish release manifest. 6) Canary rollout with KPI gating. 7) Post-rollout VerifyAuditChain and record results. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Short operator escalation matrix (who to call, in order)</strong><br>1) Rules Owner (first line) — rule interpretation and minor fixes. 2) Data Steward — policy and remediation approvals. 3) Release Engineer — deployment / rollback. 4) On-call SRE — platform incidents. 5) Compliance Officer — regulatory escalations. Always include correlationId and saved evidence attachments in the ticket. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Where to store outputs and canonical naming</strong><br>Set recommended storage paths (adjust per org policy): releases, <code>\\artifacts\DQGuard\releases\</code>; config, <code>\\config\DQGuard\</code>; audit rotations, <code>\\audit\DQGuard\rotation\</code>; forensic, <code>\\forensic\DQGuard\</code>. Filenames should embed correlationId and timestamp for traceability. Example naming convention: <code>dq_profile_&lt;table&gt;_&lt;runId&gt;_&lt;timestamp&gt;.csv</code>. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Minimum artifact checklist per regulated run</strong><br>For any run that feeds regulated output, collect: original input copy, profile report, validation report, remediation proposals, apply logs (if any), exported artifacts, audit rotation snapshot, release manifest + config.hash, migration manifest (if rules changed), and checksums for all artifacts. Bundle and store in secure archive and reference manifest in the audit. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Operator quick reference — condensed steps</strong><br>1) Start with a copy. 2) Run Profile. 3) Inspect rule failures. 4) Generate proposals and preview. 5) Apply using Create copy. 6) Re-run Profile and Reconciliation. 7) Export and record checksums. 8) Append audit rows for each step. 9) If in doubt or high-severity, escalate immediately. </td></tr><tr><td data-label="Technical User Guide — DQGuard.xlam (Authoritative Runbook)"> <strong>Final note on governance</strong><br>Strict rule: anything that materially changes regulated outputs or data used downstream requires PR, migration manifest, tests, and two-person approval. The audit chain is the legal record; preserve it. This runbook is the operational source of truth — follow it, and attach evidence to the audit for every significant action. </td></tr></tbody></table></div><div class="row-count">Rows: 48</div></div><div class="table-caption" id="Table3" data-table="Docu_0176_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — Regulatory.xlam"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — Regulatory.xlam</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing <strong>Regulatory.xlam</strong>. It governs calculation pipelines, recognition schedules, allocation logic, exports used for regulatory reporting, and all audit-producing actions. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation from this runbook for regulated outputs requires a written exception, migration manifest, risk assessment, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Primary audience & role responsibilities</strong><br>Roles: Operator, Rules Owner, Data Steward, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Each procedural section references the responsible role and required evidence. Operators execute runs; Rules Owners approve calculation and mapping changes; Developers implement code/tests; Release Engineers manage releases/rollback; Compliance approves regulatory-affecting changes. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>High-level purpose & out-of-scope</strong><br>Purpose: deterministic, auditable calculation and export of regulatory deliverables (recognition schedules, journal entries, regulatory mapping). Out-of-scope: replacing canonical ledgers outside approved connectors, private key management outside KMS/HSM workflows, or mutating external source systems without documented, auditable integration. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Core principles (non-negotiable)</strong><br>1) <strong>Determinism:</strong> identical input + config => identical outputs. Seeded RNG for sampling, ordered maps. <br>2) <strong>Auditability:</strong> every material action appends an append-only audit row with <code>correlationId</code> and payload hash. <br>3) <strong>Reversibility:</strong> apply plans default to <code>create_copy</code> (preserve original); inline changes require explicit approvals and reversible plan storage. <br>4) <strong>Separation:</strong> detection/validation MUST NOT perform destructive writes. Any weakening requires impact assessment + two-person approval. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Golden rule for operators</strong><br>Capture the <code>correlationId</code> before, during, and after every run. Start with a saved copy. Preview proposals and never accept blind auto-fixes for regulated outputs. For regulated runs require two-person approval before any <code>AUTO_APPLY</code>. Evidence: original workbook copy, profile & validation reports, proposal files, apply logs, export artifacts. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Module map & single-responsibility contracts</strong><br><code>REG_Bootstrap</code> — non-IO init, correlation id generator, schedule deferred init.<br><code>REG_Ribbon</code> — UI handlers, correlation tagging, UserAction audit rows.<br><code>REG_Config</code> — load/validate JSON Schema v7, compute <code>config.hash</code>, idempotent migrations.<br><code>REG_EnsureDeps</code> — validate dependent add-ins/templates and produce <code>deps.report.json</code>.<br><code>REG_Utilities</code> — SafeRound, atomic-write, retry, deterministic RNG.<br><code>REG_Calculations</code> — canonical recognition, allocation, SafeRound residual logic, mapping to journals.<br><code>REG_Export</code> — atomic export, checksum, staged fallback.<br><code>REG_Audit</code> — append-only chained audit rows and rotation/signing.<br><code>REG_Error</code> — centralized error taxonomy and operator messaging. Each module publishes owner, API, and emits audit rows for critical transitions. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Runtime phases & required audit markers</strong><br>Phases: <code>bootstrap.started</code> → deferred init → <code>ribbon.ready</code> → job scheduling → execution (calculation phases) → proposal → apply → export → audit rotation. Example markers: <code>bootstrap.started</code>, <code>config.loaded:&lt;hash&gt;</code>, <code>job.persisted:&lt;jobId&gt;</code>, <code>calc.step:&lt;step&gt;</code>, <code>remediation.proposed:&lt;proposalId&gt;</code>, <code>remediation.applied:&lt;applyId&gt;</code>, <code>export.attempt:&lt;artifactId&gt;</code>. Detection/validation steps MUST NOT write/destructively change input. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Bootstrap — checks & operator evidence</strong><br>MUST only initialize non-blocking tasks: open structured logs, create correlation id generator, schedule deferred init on UI idle, register shutdown hooks. MUST NOT perform heavy IO or access Excel ranges. Evidence: <code>bootstrap.log</code> containing <code>init-scheduled</code> and <code>correlationSeed</code>; add-in registration state. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Ribbon — UI mapping & audits</strong><br>Every ribbon control maps to a single handler. Handlers generate correlation id, log clicks, and append <code>UserAction</code> audit rows with <code>module</code>, <code>procedure</code>, <code>userId</code>, and minimal payload. Ribbon groups: Validate, Calculate, Propose, Apply, Export, Diagnostics. Maintain <code>ribbon-map.json</code> and include mapping verification in release checks. Evidence: <code>ribbon-map.json</code>, UI screenshots if needed, <code>audit_tail.csv</code> rows for interactions. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>REG_Config — governance & migration policy</strong><br>Single source config for thresholds, rounding rules, residual absorption policies, mapping tables, and automation flags. Load once; validate JSON Schema v7; compute <code>config.hash</code>. Any config change that alters regulatory outputs requires a migration manifest with sample counts and rollback plan. Evidence: <code>config.json</code>, <code>config.hash</code>, <code>migration_manifest.json</code>, config audit row. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Calculation engine (REG_Calculations) — contracts</strong><br>Canonical pipeline: input normalization → validation → allocation & SafeRound → recognition schedule generation → journal mapping → artifact generation. Use deterministic ordering for aggregation and tie-breakers. SafeRound must document residual absorption rules and preserve summation parity. Unit tests MUST cover positive/negative/edge cases. Evidence: calculation logs, <code>calc_report.csv</code>, artifact checksums. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Job scheduling & isolated execution</strong><br>Large or IO-heavy actions MUST be scheduled via <code>CORE_JobScheduler</code>. Persist job descriptor <code>{jobId, params, configHash}</code> and emit <code>job.persisted:&lt;jobId&gt;</code>. Execution runs in isolated worker (or background runner) with redacted input snapshot and deterministic seeds. Evidence: job descriptor, worker logs, artifact checksums. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Remediation proposals & apply policy</strong><br>Proposals (when generated) must include: <code>proposalId</code>, rationale, affected count, confidence, before/after samples, and <code>applyPlan</code> (default <code>create_copy</code>). <code>create_copy</code> preserves original worksheet/workbook and writes fixed set to separate sheet/workbook. Inline apply requires auditable operator authorization and two-person approval for regulated outputs. Applying must append <code>reg_apply</code> audit row with <code>beforeChecksum</code> and <code>afterChecksum</code> and store reversible plan. Evidence: proposal JSON, apply logs, preserved original copy. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Exports & artifact integrity (REG_Export)</strong><br>All exports use atomic-write semantics: write to temp file then rename/move to final location. Compute <code>artifact.checksum.sha256</code> and embed checksum in export metadata and audit row. If network upload fails, fallback to staged local delivery. Export audit fields include <code>destination.uri</code>, <code>attempts</code>, and <code>final.status</code>. Evidence: exported file, checksum file, <code>REG_Export</code> logs. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Audit chain (REG_Audit) — canonical record</strong><br>Audit rows are append-only and cryptographically chained. Each row includes at minimum: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Chain verification runs in CI and monitoring. Audit buffers are allowed but MUST flush within configured interval. Evidence: <code>audit_tail.csv</code>, signed rotation archives. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Error taxonomy & operator messaging (REG_Error)</strong><br>Error codes map to stable messages and remediation hints. End-user messages show only the correlation id. Full diagnostic traces are stored in encrypted logs and linked to correlation id. High-severity errors auto-page on-call and generate an incident audit row. Evidence: <code>error.log</code>, mapping reference. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Security, PII & key management</strong><br>Classify any PII fields used for regulatory outputs and enforce redaction for human-readable exports. Encrypt export archives and audit rotations using KMS/HSM-backed envelope encryption. Key rotation and signing-key changes require multi-person approval and are recorded in audit. Evidence: key rotation logs, signed audit rotations. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>CI/CD gates, testing & golden parity</strong><br>PR → CI must run: lint, unit tests, rule regression tests, deterministic golden-file parity (byte-for-byte) for regulatory outputs, performance microbenchmarks, audit chain verification. Releases affecting regulated outputs require migration manifests and compliance approval. Evidence: CI reports, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Canary & phased rollout</strong><br>Deploy calculation/rule changes via cohorts: pilot tenants → pilot users → broader cohort. Gate with KPIs: false positive rate, acceptance rate, export checksum parity. Rollback automatically on KPI breaches. Record rollout transitions in <code>deployment.audit</code>. Evidence: release manifest, rollout audit rows, KPI snapshots. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Incident response (IR) playbook — regulated example</strong><br>Containment for suspected PII/audit compromise: set exports read-only, disable auto-apply flags, quarantine helper scripts, export rotated audits and logs to secure forensic share, preserve environment snapshots. Forensic manifest MUST include SHA256 checksums and chain-of-custody metadata. Notify Compliance/regulators per timelines. Evidence: forensic archive, <code>forensic_evidence_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Reconciliation & verification</strong><br>Reconciliation tooling compares generated regulatory outputs to source-of-record ledgers. Standard workflow: dry-run → review affected IDs & samples → operator sign-off → apply (create copy preferred) → re-run reconciliation → record <code>reconciliation.&lt;id&gt;</code> audit row. Evidence: <code>reconciliation_report.json</code>, before/after checksums, operator approvals. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Performance SLAs & monitoring</strong><br>Instrument metrics: calc duration, step latency, job throughput, audit flush time, memory usage. Example thresholds: calc WARN>30s for small schedules; CRIT>300s for large. Alerts auto-page on-call for CRIT breaches. Evidence: metrics dashboards, alert logs. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Operator commands & cheat-sheets</strong><br>Provide one-line canonical commands in UI/cheat-sheets: <code>regulatory profile --run-id &lt;id&gt;</code>, <code>regulatory calc --job &lt;id&gt; --dry-run</code>, <code>regulatory apply --proposal &lt;id&gt; --mode create_copy</code>, <code>regulatory export --artifact &lt;id&gt;</code>, <code>audit flush --correlation &lt;id&gt;</code>. Store operator one-page checklists under <code>runbooks/cheatsheets/</code>. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Change-control checklist (must do before production change)</strong><br>1) Open change ticket with rollback plan. 2) Run PR self-tests and attach results. 3) Include migration manifest if behavior changes. 4) Obtain two-person approval for automation or regulatory-affecting changes. 5) Sign artifacts and publish release manifest. 6) Canary rollout with KPI gating. 7) Post-rollout VerifyAuditChain and record results. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Retention, housekeeping & drills</strong><br>Retention policy example: hot=30d, warm=7y, cold=per regulation. Automate monthly retention verification; schedule annual forensic drills and quarterly tabletop exercises. Evidence: housekeeping.audit, drill reports. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Appendices & canonical artifacts location</strong><br>Include templates: audit CSV header, proposal JSON schema, recognition schedule format, migration manifest template, release manifest template, operator cheat-sheets. Store artifacts immutably with version tags, e.g., <code>runbook/v{major}.{minor}/appendices/</code>. Access controlled by RBAC; PRs required for edits. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Minimum artifact checklist per regulated run</strong><br>Collect: original input copy, config/hash, calculation report, reconciliation report, remediation proposals (if any), apply logs (if any), exported artifacts with checksums, audit rotation snapshot, migration manifest (if rules/config changed), signed release manifest. Bundle and store in secure archive; reference manifest in the audit. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Quick operator reference — condensed flow</strong><br>1) Save a copy. 2) Validate config & deps. 3) Run calculation in dry-run. 4) Inspect calc report & diffs. 5) Generate proposals (if any) and preview. 6) Apply with <code>create_copy</code> preferred. 7) Re-run reconciliation. 8) Export artifacts and verify checksum. 9) Append audit rows for each step and escalate if high-severity. </td></tr><tr><td data-label="Technical User Guide — Regulatory.xlam"> <strong>Final governance note</strong><br>Anything that materially changes regulatory outputs requires PR, migration manifest, deterministic tests, golden-file parity, and two-person approval. The audit chain is the legal record — preserve and sign it. </td></tr></tbody></table></div><div class="row-count">Rows: 29</div></div><div class="table-caption" id="Table4" data-table="Docu_0176_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Technical User Guide — PQTools.xlam"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Technical User Guide — PQTools.xlam</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Authority, scope, and legal status</strong><br>This runbook is the authoritative source for operating, maintaining, verifying, and auditing <strong>PQTools.xlam</strong>. It governs Power Query template management, injection, diagnostic capture, refresh orchestration, and audited export of <code>M</code> code and diagnostics. Use RFC-style keywords: <code>MUST</code>, <code>SHOULD</code>, <code>MAY</code>. Any deviation for regulated templates or outputs requires a written exception, migration manifest, and two-person approval recorded in the audit. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Primary audience & responsibilities</strong><br>Roles: Operator, Template Owner, Developer, Release Engineer, Compliance Reviewer, On-call SRE. Operators run template injections and refreshes; Template Owners approve template changes; Developers create/maintain template tests; Release Engineers manage distribution and signing; Compliance reviews regulated templates and migrations. Each procedural section lists required evidence to be appended to the audit. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>High-level purpose & out-of-scope</strong><br>Purpose: provide auditable, reproducible management and injection of Power Query (<code>M</code>) templates into workbooks, with diagnostics and hermetic exports for review and regulatory traceability. Out-of-scope: hosting or editing external data sources outside approved connectors, secret/key management outside KMS/HSM, making irreversible changes to source systems without documented integration. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Core principles (non-negotiable)</strong><br>1) Determinism: template rendering and parameter resolution MUST be reproducible; <code>mChecksum</code> computed for all template artifacts.<br>2) Auditability: every injection/refresh/export appends an audit row with <code>correlationId</code>, <code>operatorId</code>, and <code>mChecksum</code>.<br>3) Reversibility: injection into workbook SHOULD be an explicit operator action; templates MAY be exported instead of injected. <br>4) Separation: preview & diagnostics precede injection. Two-person approval for regulated-template injection or AUTO_APPLY behavior. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Module map & single-responsibility contracts</strong><br><code>PQ_Ribbon</code> — UI handlers for library, inject, preview, refresh, export.<br><code>PQ_Config</code> — runtime config, template repo config, remote config resolution, <code>config.hash</code>.<br><code>PQ_EnsureDeps</code> — validate dependent connectors and PQ runtime versions; produce <code>deps.report.json</code>.<br><code>PQ_Utilities</code> — atomic-write, retry, deterministic RNG, <code>mChecksum</code> utilities.<br><code>PQ_Library</code> — template index, versions, owners, embedded hidden-sheet fallback.<br><code>PQ_Injector</code> — safe injection APIs: <code>Add_Query_From_M(name, formula)</code>, parameterization wrapper, connection creation options.<br><code>PQ_Diagnostics</code> — collect query diagnostics (load time, refresh path, error traces).<br><code>PQ_Export</code> — atomic export of <code>M</code> and diagnostics with checksum and metadata.<br><code>PQ_Audit</code> — append-only audit rows and rotation signing. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Runtime phases & audit markers</strong><br>Phases: bootstrap → config load → library access → UI idle → template preview → injection job persist → isolated injection/refresh → diagnostics capture → export → audit rotation. Example audit markers: <code>pq_library.access:&lt;version&gt;</code>, <code>pq_preview:&lt;id&gt;</code>, <code>pq_inject:job.&lt;jobId&gt;</code>, <code>pq_refresh:&lt;runId&gt;</code>, <code>pq_export:&lt;artifactId&gt;</code>. Preview steps MUST append <code>pq_preview</code> audit rows containing <code>mChecksum</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Template governance & lifecycle</strong><br>Templates carry stable IDs, semantic versions, owner, description, and <code>mChecksum</code>. Changes follow PR + automated testing + migration manifest for behavior changes. Templates used for regulated outputs require policy approval and migration artifacts (sample outputs, estimated affected counts). Evidence: template PRs, test results, <code>templates.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Library management (PQ_Library)</strong><br>Library sources: embedded hidden sheet (local fallback) OR canonical external repo (file-based preferred for auditability). <code>PQTools</code> SHOULD prefer external repo to enable review and signed artifacts. Library access emits <code>pq_library.access</code> with <code>templateVersion</code> and <code>mChecksum</code>. Template owners listed in <code>OWNERS.md</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Parameterization & preview flow</strong><br>Operator selects template → parameterize values → <code>Preview M</code> runs a dry-render and static checks (syntax + <code>mChecksum</code>). Preview outputs: <code>mPreview.json</code> and sample transformed rows (redacted). <code>pq_preview</code> audit row MUST include <code>operatorId</code>, <code>templateId</code>, and <code>mChecksum</code>. No workbook changes happen at preview. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Injection rules & safe defaults (PQ_Injector)</strong><br>Injection options: <code>connection-only</code>, <code>load-to-sheet</code>, <code>load-to-data-model</code>. Default behavior: do <strong>not</strong> overwrite existing queries unless <code>force=true</code> and operator confirms. Injection runs SHOULD be scheduled for heavy templates via <code>job.persist</code> and executed in isolated worker. When injecting, store previous query text and emit <code>pq_inject.backup:&lt;queryName&gt;</code> with <code>prevChecksum</code>. Evidence: injection job descriptor, before/after snapshots. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Refresh orchestration & diagnostics (PQ_Diagnostics)</strong><br><code>PQTools</code> collects provider diagnostics: step timings, rows loaded, errors, provider string (e.g., <code>Microsoft.Mashup.OleDb.1</code>). Refreshes MAY be run inline for small queries but MUST use job scheduler for long-running refreshes. Emit <code>pq_refresh</code> audit rows and <code>pq_diagnostics/&lt;run-id&gt;</code> artifact containing timings and error traces. Diagnostics artifacts are redacted for credentials. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>M checksum & artifact integrity</strong><br><code>mChecksum</code> computed (sha256) for all <code>M</code> templates, previews, and injected query formulas. All exports embed <code>artifact.checksum.sha256</code>. Compare <code>mChecksum</code> on load/preview/inject to detect drift and enforce immutability of signed templates. Evidence: <code>mChecksum</code> files, <code>pq_export</code> checksum metadata. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Exports & atomic semantics (PQ_Export)</strong><br>Exports write to temp files then rename to final destination. Export metadata includes <code>artifact.checksum.sha256</code>, <code>templateVersion</code>, and <code>attempts</code>. Network upload fallback: staged local delivery. Export audits: <code>pq_export</code> with <code>destination.uri</code> and <code>final.status</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Audit chain & signing (PQ_Audit)</strong><br>Each audit row minimally: <code>timestamp, correlationId, module, procedure, severity, userId, payloadHash, prevHash, signature, metadata</code>. Audit rotations are signed and stored with release manifest key. VerifyAuditChain runs in CI periodically. Evidence: <code>audit_tail.csv</code>, signed archives. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Error taxonomy & operator messaging</strong><br>Errors map to stable codes and remediation hints. User-facing messages show correlation id only; full diagnostics stored in logs. High-severity errors auto-page on-call and add <code>pq_error</code> audit rows. Evidence: <code>error.log</code>, <code>pq_diagnostics</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Security & macro policy</strong><br>XLAM must be code-signed. Macro enable policy enforced by org policy; templates executed under workbook context must not request unapproved credentials. Secret management (tokens/keys) MUST use KMS/HSM-backed mechanisms and NOT be embedded in templates. Evidence: code-signing certificate, <code>pq_security.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>CI/CD gates & testing</strong><br>PR → CI: lint, unit tests for parameterization logic, template regression tests, golden parity for exported <code>M</code> artifacts, diagnostics capture tests. Template changes that affect regulated outputs require migration manifest and compliance approval. Evidence: CI reports, signed release manifest. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Canary & phased rollout</strong><br>Deploy template updates via cohorts: template owners → pilot users → broader tenant groups. Gate with KPIs: injection success rate, preview acceptance rate, refresh latency, <code>mChecksum</code> parity. Rollback automatically on KPI threshold breaches. Record rollout transitions in <code>deployment.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Incident response (IR) — PQ-specific)</strong><br>Containment: disable template injections, set library repo read-only, export diagnostics and audit rotations to forensic share, collect <code>deps.report.json</code>, <code>pq_diagnostics</code> and <code>bootstrap.log</code>. Forensic manifest MUST include SHA256 for artifacts and chain-of-custody metadata. Evidence: forensic archive and <code>forensic_manifest.json</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Reconciliation & verification</strong><br>Reconcile injected query outputs with source-of-truth where feasible: dry-run transforms, sample diffs, operator sign-off, then inject. Produce <code>recon_report.json</code> and append <code>reconciliation.&lt;id&gt;</code> audit row. Evidence: recon reports, before/after checksums. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Retention, housekeeping & drills</strong><br>Retention example: templates/golden=immutable; diagnostics hot=30d; exports warm=7y; cold=per regulation. Schedule monthly housekeeping with audit rows. Perform quarterly drills for export/path rotation. Evidence: <code>housekeeping.audit</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Operator commands & cheat-sheets</strong><br>Provide canonical commands: <code>pqtools preview --template &lt;id&gt; --params &lt;json&gt;</code>, <code>pqtools inject --template &lt;id&gt; --mode connection-only|load-sheet --force</code>, <code>pqtools refresh --query &lt;name&gt; --job</code>, <code>pqtools export --artifact &lt;id&gt;</code>, <code>pqtools diagnostics collect --run-id &lt;id&gt;</code>. Each command MUST append an audit row with <code>correlationId</code>. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Minimum artifact checklist per regulated injection</strong><br>For any injection that feeds regulated outputs collect: saved workbook copy, <code>mChecksum</code>, preview artifacts, injection job descriptor, injection backup (previous queries), diagnostics, export artifact with checksum, audit rotation snapshot, migration manifest (if template changed), signed release manifest. Bundle and store in secure archive. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Quick operator flow — condensed</strong><br>1) Save workbook copy. 2) Preview template and check <code>mChecksum</code>. 3) Inspect preview & diagnostics. 4) Inject using <code>create_connection</code> or <code>load_to_sheet</code> (prefer connection-only where possible). 5) Run refresh in dry-run if heavy. 6) Export <code>M</code> + diagnostics with checksum. 7) Append audit rows for each step. 8) If regulated or high-risk, require two-person approval before injection. </td></tr><tr><td data-label="Technical User Guide — PQTools.xlam"> <strong>Final governance note</strong><br>Template changes that materially affect downstream or regulated outputs require PR, deterministic tests, migration manifest, golden-file parity, and two-person approval. The audit chain is the legal record—preserve and sign it. </td></tr></tbody></table></div><div class="row-count">Rows: 25</div></div><div class="table-caption" id="Table5" data-table="Docu_0176_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Bootstrap — Per-Function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Bootstrap — Per-Function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Module summary (top-level)</strong><br><strong>Purpose:</strong> perform the minimal, safe initialization when the XLAM is loaded: open/initialize structured logging, establish a global correlation-id service, schedule deferred initialization on UI idle, register ordered shutdown handlers, and emit <code>bootstrap.started</code> audit anchor. The main path MUST be lightweight and non-blocking. Deferred heavy work occurs only via the deferred-init runner. <br><strong>Owner / Evidence:</strong> OWNER in <code>OWNERS.md</code>; evidence artefacts: <code>bootstrap.log</code> (JSONL), <code>audit_tail.csv</code> entries with <code>bootstrap.started</code>, <code>bootstrap.deferred.completed</code>, <code>bootstrap.degraded</code> as applicable. <br><strong>Non-goals / MUST NOT:</strong> no Excel Range/table access in bootstrap; no heavy disk IO; no network calls; no secrets loading; no long CPU work. <br><strong>Performance & budgets:</strong> main path target <250ms; deferred-init budget default 10s before degraded behaviour; flush and shutdown latencies monitored. <br><strong>CI requirements:</strong> static analysis forbids workbook API and network calls in main path; unit + integration tests for API; self-checks for CI gating. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_BootstrapInit</code> — Purpose, contract, invariants, and checks</strong><br><strong>Purpose & contract:</strong> executed at XLAM load (Auto_Open/Workbook_Open). Initialize in-memory log buffer, compute initial ticks, create initial correlation id, buffer a <code>bootstrap.started</code> audit row, register a safe shutdown handler, and schedule deferred init. Must return quickly and avoid throwing unhandled exceptions to the host. <br><strong>Implementation notes (code-accurate):</strong> sets <code>gBootstrapStartTs</code>, ensures <code>gAuditBuffer</code> and <code>gShutdownHandlers</code> collections, initializes ULID state (<code>gLastUlidMs</code>, <code>gUlidSeq</code>, <code>gLastSysTimeTickSeed</code>, <code>gLastMsFromSystem</code>), creates <code>gLastCorrelationId = DQ_NewCorrelationId(&quot;&quot;)</code>, buffers <code>bootstrap.started</code> via <code>DQ_EmitBootstrapAudit</code>, registers finalizer via <code>DQ_RegisterShutdownHandler(&quot;DQ_Bootstrap:finalize&quot;,1000,MODULE_NAME &amp; &quot;.DQ_Finalize&quot;)</code>, schedules deferred init with <code>DQ_ScheduleDeferredInit(False)</code>. Quietly ignores optional module init calls (commented <code>Call DQ_Audit_ModuleInit</code>) with <code>On Error Resume Next</code>. <br><strong>Primary invariants (MUST / SHALL):</strong><br>1. No workbook Range or sheet access. <br>2. No synchronous heavy disk or network I/O. <br>3. Buffer <code>bootstrap.started</code> using <code>DQ_EmitBootstrapAudit</code> (uses stub payload-hash until CI replaces). <br>4. Schedule deferred init idempotently. <br><strong>Failure modes & recovery (code behavior):</strong> handlers trap errors and emit <code>bootstrap.degraded</code> into the buffer; function resumes next rather than propagating errors to Office. <br><strong>Tests:</strong> ensure buffer populated, no forbidden API use, and <code>DQ_RegisterShutdownHandler</code> called with expected args. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>Auto_Open</code> / <code>Workbook_Open</code> — contract & host implications</strong><br><strong>Purpose & contract:</strong> host entry points that should invoke <code>DQ_BootstrapInit</code>. The module expects these host entry points to call the public <code>DQ_BootstrapInit</code> safely; <code>DQ_BootstrapInit</code> itself is responsible for catching and buffering errors so nothing should surface to Excel. <br><strong>Implementation note:</strong> this module does not implement <code>Auto_Open</code> explicitly; the expectation (documented) is the workbook-level Auto_Open / Workbook_Open calls <code>DQ_BootstrapInit</code>. <br><strong>Invariants:</strong> idempotent reentry tolerant. <br><strong>Tests:</strong> simulate multiple host calls and verify <code>DQ_BootstrapInit</code> does only lightweight actions on main path. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_NewCorrelationId(parentId)</code> — spec, format, and guarantees</strong><br><strong>Purpose & contract:</strong> provide ULID-like correlation ids used for traceability. Format produced by code: <code>&lt;YYYYMMDDHHMMSSmmm&gt;-&lt;SEQ(4 hex)&gt;-&lt;GUIDHEX(32?) trimmed to 20&gt;</code> optionally suffixed by shortened parent. Monotonic per-instance within same millisecond via <code>gUlidSeq</code>. <br><strong>Code-accurate details:</strong> uses <code>NowToMs()</code> and <code>NowToTimestampString()</code> for the timestamp part; increments <code>gUlidSeq</code> when <code>currentMs = gLastUlidMs</code>; caps/wraps at <code>&amp;HFFFF</code> and emits <code>bootstrap.cid.seq.overflow</code> audit if wrapped; <code>GenerateGuidHex()</code> via <code>CoCreateGuid</code> and <code>GUIDToHex</code>; on error falls back to <code>GUIDFALLBACK-&lt;guid&gt;</code> and emits <code>bootstrap.cid.fallback</code> audit. <br><strong>Properties guaranteed by implementation:</strong> lexical ordering within instance (timestamp + seq), per-instance monotonicity (sequence per-ms), fallback on GUID-generate failure with audit. <br><strong>Failure & observability:</strong> fallback path emits audit <code>bootstrap.cid.fallback</code> with reason; tests should assert monotonic sequence for repeated calls and fallback emits audit. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_ScheduleDeferredInit(force)</code> — scheduling policy & idempotency</strong><br><strong>Purpose & contract:</strong> schedule deferred initialization via <code>Application.OnTime</code> calling <code>MODULE_NAME &amp; &quot;.DQ_DeferredInitRunner&quot;</code>. Idempotent: respects <code>gDeferredScheduled</code> unless <code>force=True</code>. Uses exponential backoff on <code>gDeferredAttempt</code> and caps delay at 30s. <br><strong>Code-accurate behavior:</strong> when <code>gDeferredAttempt</code> exceeds <code>DEFERRED_MAX_ATTEMPTS</code> emits <code>bootstrap.deferred.timeout</code> audit and stops scheduling; sets <code>gDeferredScheduled = True</code> upon scheduling; computes run time as <code>Now + TimeSerial(0,0,delaySeconds)</code> and calls <code>Application.OnTime</code>. On exceptions increments <code>gDeferredAttempt</code> and emits <code>bootstrap.deferred.scheduled.error</code>. <br><strong>Edge cases handled:</strong> idempotent scheduling, scheduled-audit emission including scheduledAt and attempt; handles OnTime resolution by module-qualified proc name. <br><strong>Tests:</strong> verify exponential backoff, forced reschedule, and correct audit emission on scheduling error. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_DeferredInitRunner</code> — deferred initialization responsibilities</strong><br><strong>Purpose & contract:</strong> perform deferred (safe) initialization tasks when called by <code>Application.OnTime</code>. This runner is allowed to perform IO, schema validation, module loads, hashing, and signature checks. <br><strong>Code-accurate sequence:</strong> generates a new correlation id <code>cid = DQ_NewCorrelationId(gLastCorrelationId)</code> and assigns <code>gLastCorrelationId = cid</code>; emits <code>bootstrap.deferred.started</code> audit; contains placeholder commented calls for deferred modules (<code>REG_Config_LoadAndValidate</code>, <code>REG_EnsureDeps_Check</code>, <code>REG_Utilities_Load</code>, <code>REG_ManifestLoader_Load</code>, <code>REG_Rules_Load</code>); emits <code>bootstrap.deferred.completed</code> audit on success; on error emits <code>bootstrap.deferred.error</code> and increments <code>gDeferredAttempt</code>. Sets <code>gDeferredScheduled = False</code> and resets attempts on success. <br><strong>Invariants:</strong> deferred runner must call out to external REG_* modules (the code intentionally leaves them as placeholders). <br><strong>Failure handling:</strong> buffers <code>bootstrap.deferred.error</code> and increments attempt count; does not crash host. <br><strong>Tests & integration:</strong> ensure runner emits started/completed/errors, and placeholders are called in integration where implementations exist. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_EmitBootstrapAudit(procedureName, metadataJson, Optional severity)</code> — canonical bootstrap audit anchor</strong><br><strong>Purpose & contract:</strong> build a canonical JSON audit row (string) and buffer it via <code>DQ_SafeBufferLogRow</code>. Minimal schema produced by code: <code>timestamp, correlationId, module=DQ_Bootstrap, procedure, severity, userId, payloadHash, prevHash, metadata</code>. <code>payloadHash</code> computed by <code>DQ_ComputePayloadHash</code> (stub present in this module). <code>prevHash</code> left empty (resolved at persist time). Must not perform disk IO in main path. <br><strong>Code-accurate behavior:</strong> constructs <code>rowJson</code> string concatenating fields and <code>metadataJson</code> verbatim into the <code>metadata</code> field; calls <code>DQ_SafeBufferLogRow(rowJson)</code>; error path buffers an error audit row via <code>DQ_SafeBufferLogRow</code>. <br><strong>Important notes:</strong> current implementation embeds <code>metadataJson</code> as provided (caller must pass sanitized JSON). <code>DQ_EmitBootstrapAudit</code> does not perform PII redaction itself; redaction should be applied by callers before supplying <code>metadataJson</code>. <br><strong>Tests:</strong> verify that <code>DQ_EmitBootstrapAudit</code> buffers correctly and that <code>payloadHash</code> is computed using the stub until CI replacement. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_SafeBufferLogRow(rowJson)</code> — buffering & drop policy</strong><br><strong>Purpose & contract:</strong> append a JSON row string to <code>gAuditBuffer</code> (a <code>Collection</code>) bounded by <code>AUDIT_BUFFER_MAX</code>. Synchronous and non-blocking. <br><strong>Code-accurate behavior:</strong> ensures <code>gAuditBuffer</code> exists; if <code>gAuditBuffer.count &gt;= AUDIT_BUFFER_MAX</code> it removes the first (oldest) item and adds a generated <code>&quot;bootstrap.log.drop&quot;</code> warning row to record the drop; then <code>gAuditBuffer.Add rowJson</code>. On error it tries to initialize buffer and add an internal error row. <br><strong>Invariants:</strong> bounded ring-buffer semantics, immediate return, drop oldest on overflow and record drop event. <br><strong>Tests:</strong> buffer overflow behavior, drop-event content, resilience if <code>gAuditBuffer</code> uninitialized. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RegisterShutdownHandler(id, priority, handlerName)</code> — registration semantics</strong><br><strong>Purpose & contract:</strong> register a shutdown handler record (id, priority, handlerName) into <code>gShutdownHandlers</code> collection. Registration is idempotent: if an entry with the same <code>id</code> exists the call exits early. <br><strong>Code-accurate details:</strong> iterates existing <code>gShutdownHandlers</code> to check for <code>id</code> equality, creates a <code>Collection</code> named <code>col</code> and adds keys <code>&quot;id&quot;</code>, <code>&quot;priority&quot;</code>, <code>&quot;handlerName&quot;</code> then <code>gShutdownHandlers.Add col</code>; emits <code>bootstrap.shutdown.handler.registered</code> audit. On error emits <code>bootstrap.shutdown.handler.register.error</code>. <br><strong>Constraints:</strong> handlers are expected to be Public Subs with no parameters; registration is in-memory only. <br><strong>Tests:</strong> idempotency test, registration emits expected audit payload. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RunShutdownHandlers</code> / graceful shutdown orchestration (code-accurate)</strong><br><strong>Purpose & contract:</strong> emit <code>bootstrap.shutting_down</code>, run all registered handlers in ascending priority (lowest numeric first) using <code>Application.Run</code>, capture handler errors and emit <code>bootstrap.shutdown.handler.error</code> for each failing handler, and finally call <code>DQ_RequestFlushLogsNow</code>. Must be best-effort and continue after handler failures. <br><strong>Code-accurate implementation:</strong> copies handlers into an array <code>arr(1 To n)</code> then insertion-sorts by <code>(&quot;priority&quot;)</code>; iterates array and calls <code>Application.Run hName</code> under <code>On Error Resume Next</code>; emits per-handler error audit if <code>err.Number &lt;&gt; 0</code> and clears <code>err</code>; after handlers calls <code>DQ_RequestFlushLogsNow</code>. On top-level error emits <code>bootstrap.shutdown.error</code>. <br><strong>Tests:</strong> handler-ordering verification, handler-error capture, final <code>DQ_RequestFlushLogsNow</code> invoked. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RequestFlushLogsNow</code> — operator-requested flush anchor (code-accurate)</strong><br><strong>Purpose & contract:</strong> non-blocking operator-initiated flush anchor; in this module it simply buffers a <code>bootstrap.flush.request</code> audit (actual flush/persistence handled by deferred REG_Audit/DQ_FlushLogs). <br><strong>Code-accurate behavior:</strong> builds a small metadata JSON with <code>requestedBy&quot;:&quot;operator&quot;</code> and <code>ts</code> and calls <code>DQ_EmitBootstrapAudit(&quot;bootstrap.flush.request&quot;,metadata,&quot;info&quot;)</code>. <br><strong>Tests:</strong> verify audit row buffered; ensure no synchronous disk IO occurs in this call. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_GetBootstrapState</code> — diagnostics snapshot (code-accurate)</strong><br><strong>Purpose & contract:</strong> return a small JSON string containing non-PII diagnostics: <code>status</code>, <code>startTs</code>, <code>lastCorrelationId</code> (trimmed to 120 chars), and <code>deferredScheduled</code> boolean. Implemented as a simple string builder and returns synchronously. <br><strong>Code-accurate details:</strong> constructs and returns string; does not perform IO and is safe on main path. <br><strong>Tests:</strong> validate JSON shape and that <code>lastCorrelationId</code> is trimmed. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_RunBootstrapSelfChecks</code> — CI/dev lightweight self-tests (code-accurate)</strong><br><strong>Purpose & contract:</strong> perform non-destructive checks: buffer initialization, correlation-id monotonicity (10 samples compared lexically), deferred scheduling state. Returns a JSON string summarizing checks and notes. Intended for CI gating and developer smoke tests. <br><strong>Code-accurate behavior:</strong> generates 10 ids via <code>DQ_NewCorrelationId(gLastCorrelationId)</code> and verifies strict lexical ordering <code>StrComp(ids(i), ids(i+1), vbBinaryCompare) &lt; 0</code>; returns structured JSON with booleans and a notes array. On error returns JSON <code>{&quot;error&quot;:...}</code>. <br><strong>CI usage:</strong> run in pre-merge gating; flag failures. <br><strong>Tests:</strong> ensure monotonicity test logic is sound and fails if ordering incorrect. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_ComputePayloadHash(metadataJson)</code> & <code>ComputeStubPayloadHash(text)</code> — stub & CI requirement (code-accurate)</strong><br><strong>Purpose & contract:</strong> public <code>DQ_ComputePayloadHash</code> returns <code>sha256:</code> prefixed fingerprint; <strong>current module implements a deterministic non-cryptographic stub</strong> via <code>ComputeStubPayloadHash</code> (FNV-like loop) for CI/golden tests only. <strong>MUST</strong> be replaced by a real SHA-256 implementation prior to production; CI MUST fail if stub remains. <br><strong>Code-accurate details:</strong> <code>DQ_ComputePayloadHash = &quot;sha256:&quot; &amp; LCase$(ComputeStubPayloadHash(metadataJson))</code>; <code>ComputeStubPayloadHash</code> iterates characters, applies an FNV-like mixing and returns an 8-hex string padded. <br><strong>Safety & tests:</strong> CI gate must detect <code>ComputeStubPayloadHash</code> presence; unit tests compare expected stub output for known inputs; production replacement required for security/compliance. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>NowToMs()</code> & <code>NowToTimestampString()</code> — time helpers (code-accurate)</strong><br><strong>Purpose & contract:</strong> <code>NowToMs</code> returns millisecond portion <code>0..999</code> via <code>GetLocalTime</code> Win32 call; <code>NowToTimestampString</code> builds <code>YYYYMMDDHHMMSSmmm</code> using <code>GetLocalTime</code> for consistent ms and falls back to <code>Format$(Now, ...)</code> + <code>NowToMs</code> if <code>GetLocalTime</code> fails. These functions are used by <code>DQ_NewCorrelationId</code> to ensure timestamp + ms alignment. <br><strong>Tests:</strong> verify ms range and timestamp formatting including leading zeros and fallback behavior. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>GenerateGuidHex()</code> & <code>GUIDToHex(g)</code> — GUID generation (code-accurate)</strong><br><strong>Purpose & contract:</strong> use <code>CoCreateGuid</code> to obtain a COM GUID and serialize it to a lowercase hex string via <code>GUIDToHex</code>. On <code>CoCreateGuid</code> failure returns a sentinel <code>FFFFFFFF...</code> value and <code>DQ_NewCorrelationId</code> will emit fallback audit. <br><strong>Code specifics:</strong> <code>GUIDToHex</code> assembles bytes from <code>Data1</code>, <code>Data2</code>, <code>Data3</code>, and <code>Data4</code> and builds a 16-byte hex string by iterating bytes and converting with <code>hex$</code>/<code>right$</code>. <br><strong>Tests:</strong> ensure <code>GenerateGuidHex</code> returns expected-length hex and fallback path triggers audit <code>bootstrap.cid.fallback</code>. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>ShortenForParent(parentId)</code> & <code>SafeGetPlatform()</code> — small helpers (code-accurate)</strong><br><strong>Purpose & contract:</strong> <code>ShortenForParent</code> produces a short safe parent suffix by replacing <code>|</code> with <code>-</code> and truncating to 8 chars when longer; <code>SafeGetPlatform</code> returns <code>Application.OperatingSystem</code> or <code>&quot;unknown&quot;</code> if empty. Both used by correlation id generation and bootstrap metadata. <br><strong>Tests:</strong> simple unit tests for truncation/replacement and non-empty platform fallback. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong><code>DQ_Finalize</code> — public finalizer (non-recursive, code-accurate)</strong><br><strong>Purpose & contract:</strong> lightweight finalizer registered by <code>DQ_RegisterShutdownHandler</code>. Public Sub with no params so it can be invoked by <code>Application.Run</code>. Emits <code>bootstrap.finalize.started</code> audit and calls <code>DQ_RequestFlushLogsNow</code>. Must not recurse into shutdown handler registry. <br><strong>Tests:</strong> verify that <code>DQ_Finalize</code> buffers the <code>bootstrap.finalize.started</code> row and calls <code>DQ_RequestFlushLogsNow</code>. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Functions intentionally <em>not</em> implemented in this module (deferred / external responsibilities)</strong><br>These capabilities are referenced in the table and by bootstrap deferred runner comments but are <strong>explicitly implemented outside this file</strong> (REG_* / REG_Audit etc.). The bootstrap code intentionally leaves these as deferred responsibilities; tests and CI must verify their presence elsewhere rather than in this module: <br>— <code>DQ_InitializeFilesystem</code> (file/directory creation and permission checks) — <strong>NOT implemented here</strong>; code expects REG_Audit / deferred modules to create folders and manage persistence. <br>— <code>DQ_FlushLogs</code> (atomic temp-write → append → rotate persistence) — <strong>NOT implemented here</strong>; in-code comments point to <code>REG_Audit/DQ_FlushLogs</code> for true persistence. <br>— <code>DQ_SafeLog</code> / <code>DQ_ScheduleFlushIfNeeded</code> (scheduled flush timers & disk writes) — <strong>NOT implemented here</strong>; bootstrap only buffers and requests flushes. <br><strong>Action:</strong> CI / integration must ensure REG_Audit implements atomic persistence, and tests must run with that module present. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Security & signing checks within deferred init (code-accurate guidance)</strong><br><strong>Purpose & contract:</strong> validate add-in/manifest signatures and record signer fingerprint during deferred init (not on main path). The bootstrap runner comments require signature checks (deferred) and suggest failing deferred init & entering degraded mode if signatures invalid in production. <br><strong>Implementation note:</strong> actual signature verification (binary or manifest) is intentionally <strong>deferred</strong> and must be implemented by <code>REG_*</code> modules called from <code>DQ_DeferredInitRunner</code>. <br><strong>Tests:</strong> deferred module tests should cover valid and invalid signatures and ensure regulated controls are disabled when validation fails. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Observability, telemetry, and metrics (module-level, bootstrap behavior)</strong><br><strong>What this file emits (code-accurate):</strong> buffered bootstrap audit rows like <code>bootstrap.started</code>, <code>bootstrap.deferred.*</code>, <code>bootstrap.shutdown.*</code>, <code>bootstrap.flush.request</code>, <code>bootstrap.finalize.started</code>, and internal fallback/overflow audits (e.g., <code>bootstrap.log.drop</code>, <code>bootstrap.cid.fallback</code>). Metrics must be emitted by deferred modules or telemetry pipeline (not in main bootstrap path). <br><strong>CI/operational requirement:</strong> ensure deferred uploader/aggregator (outside this file) consumes the buffer and uploads metrics securely; bootstrap code never performs remote telemetry directly. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Forbidden APIs & static enforcement (code-accurate)</strong><br><strong>Code-level enforcement:</strong> this module contains no workbook <code>Range</code>/table access and no network calls; CI static analysis MUST verify the absence of these APIs in this file (and flag accidental additions). All heavy IO / network / secrets logic must live outside the main bootstrap path. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Acceptance criteria & CI gates specific to module implementation</strong><br>1. <code>DQ_BootstrapInit</code> must buffer <code>bootstrap.started</code> and set ULID/sequence state. <br>2. <code>DQ_NewCorrelationId</code> must produce monotonic, lexically ordered ids for in-instance sequences; fallback path must emit <code>bootstrap.cid.fallback</code>. <br>3. <code>DQ_ScheduleDeferredInit</code> must call <code>Application.OnTime</code> with module-qualified runner and backoff attempts; <code>gDeferredScheduled</code> state must reflect scheduling. <br>4. <code>DQ_EmitBootstrapAudit</code> must buffer rows using <code>DQ_SafeBufferLogRow</code> and not perform disk IO. <br>5. <code>DQ_ComputePayloadHash</code> must be replaced before production; CI must detect stub usage. <br>6. <code>DQ_RunShutdownHandlers</code> executes handlers by ascending <code>priority</code> and logs individual handler failures. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Evidence & forensic requirements on incidents (code-accurate)</strong><br>On bootstrap incident collect: the in-memory <code>gAuditBuffer</code> (serialize to <code>bootstrap.log</code>), <code>audit_tail.csv</code> entries emitted by REG_Audit/DQ_FlushLogs, <code>config.hash</code>/<code>config.json</code> (deferred), <code>deps.report.json</code> (deferred), <code>lastCorrelationId</code>, platform metadata (<code>Application.Version</code>, <code>Application.OperatingSystem</code>), and release manifest. Package into <code>forensic_manifest.json</code> and persist via REG_Audit / evidence pipeline. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Developer notes & common pitfalls (code-accurate)</strong><br>— Keep this module strictly main-path safe: no workbook Range access, network calls, or secret loading. <br>— Implement deferred heavy work in REG_* modules; bootstrap only schedules and buffers. <br>— Replace <code>ComputeStubPayloadHash</code> with SHA-256 before production; CI must enforce. <br>— Ensure shutdown handlers registered here are Public Subs with zero params and are resilient to multiple-run invocation. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Examples (concise, reflecting actual code)</strong><br><strong>Normal startup (code path):</strong> Excel loads → host calls Auto_Open / Workbook_Open → calls <code>DQ_BootstrapInit</code> → <code>gAuditBuffer</code> initialized, <code>gLastCorrelationId = DQ_NewCorrelationId(&quot;&quot;)</code> → <code>DQ_EmitBootstrapAudit(&quot;bootstrap.started&quot;, meta, &quot;info&quot;)</code> buffers row → <code>DQ_RegisterShutdownHandler(&quot;DQ_Bootstrap:finalize&quot;,1000, MODULE_NAME &amp; &quot;.DQ_Finalize&quot;)</code> → <code>DQ_ScheduleDeferredInit(False)</code> schedules <code>DQ_DeferredInitRunner</code> with <code>Application.OnTime</code> → host returns control to UI quickly. <br><strong>Deferred runner (code path):</strong> <code>DQ_DeferredInitRunner</code> invoked by <code>Application.OnTime</code> → new cid generated and deferred audit emitted → deferred modules (REG_*) are expected to be called here (placeholders in code) → <code>bootstrap.deferred.completed</code> buffered on success. <br><strong>Failure mode (code path):</strong> exception in <code>DQ_BootstrapInit</code> or <code>DQ_DeferredInitRunner</code> triggers <code>On Error</code> handlers which buffer <code>bootstrap.degraded</code> or <code>bootstrap.deferred.error</code> and the module continues to run without crashing host. </td></tr><tr><td data-label="DQ_Bootstrap — Per-Function Expert Technical Breakdown"> <strong>Final checklist (developer / release, code-accurate)</strong><br>1. CI static scan: no forbidden APIs in <code>DQ_Bootstrap</code> file. <br>2. Replace <code>ComputeStubPayloadHash</code> with validated SHA-256 in production builds (CI enforces). <br>3. Implement deferred modules (<code>REG_Audit</code>/<code>REG_Config</code>/<code>REG_EnsureDeps</code>/<code>REG_Utilities</code>) and test end-to-end deferred-init flow. <br>4. Unit tests: correlation-id monotonicity, buffer overflow/drop behavior, schedule/backoff. <br>5. Integration tests: shutdown handler invocation and finalizer behavior with <code>Application.Run</code>. </td></tr></tbody></table></div><div class="row-count">Rows: 27</div></div><div class="table-caption" id="Table6" data-table="Docu_0176_06" style="margin-top:2mm;margin-left:3mm;"><strong>Table 6</strong></div>
<div class="table-wrapper" data-table-id="table-6"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_RibbonCallbacks — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>OnLoad(ribbonUI)</code> — Purpose, contract, parameters, invariants, VB/VSTO/PQ implications, observability, recovery, examples, and tests</strong><br><strong>Purpose & contract:</strong> invoked by the Office host when the add-in UI initializes. Responsibilities (strict): cache <code>ribbonUI</code> handle, initialize in-memory state, schedule <strong>deferred</strong> initialization via <code>Application.OnTime</code>, emit a fast <code>ribbon.loaded</code> audit row linking into bootstrap, and return promptly. Must not perform workbook Range/Sheet access, heavy disk IO, network calls or long-running logic on the UI thread. Failures must be captured and emitted as <code>ribbon.onload.error</code> rather than bubbling exceptions to host.<br><strong>Parameters & return:</strong> <code>ribbonUI</code> (opaque host handle). No return. Must be resilient to missing helper modules (DQ_Utilities, DQ_Audit, REG_Config) and fall back safely.<br><strong>Primary invariants (must/shall):</strong> <br>1. Complete quickly on UI thread (target ≪100ms). <br>2. Never touch workbook cell ranges or perform blocking IO. <br>3. Always schedule deferred ribbon manifest loading (one-second delay). <br>4. Emit <code>ribbon.loaded</code> with <code>correlationId</code>, <code>platform</code>, <code>excelVersion</code>, <code>buildId</code> (if available), <code>ribbonMapHash</code> when present, and <code>startTs</code> (via <code>GetTimeStampSafe</code>).<br><strong>VB/VSTO/PQ guidance:</strong> cache <code>ribbonUI</code> only, avoid any calls to ThisWorkbook or heavy helpers in OnLoad; use <code>Application.OnTime</code> to defer <code>Deferred_LoadRibbonMap</code>. Use <code>On Error</code> to convert exceptions into stable error codes (e.g., <code>RIB_ONLOAD_001</code>).<br><strong>PQ-specific considerations:</strong> do not enumerate or inject PQ queries during OnLoad; only mark PQ controls enabled after deferred manifest/template validation.<br><strong>Observability & audit fields:</strong> <code>correlationId</code>, <code>buildId</code>, <code>platform</code>, <code>excelVersion</code>, <code>ribbonMapHash</code>, <code>startTs</code>. On failures include <code>stableErrorCode</code> and mapped error from DQ_Error.<br><strong>Recovery & operator actions:</strong> check <code>ribbon.onload.error</code> → collect diagnostics using correlation id; run <code>ribbon.exportDiagnostics</code> (operator helper) if available.<br><strong>Examples & tests:</strong> unit test ensures <code>ribbon.loaded</code> emitted; static analysis forbids workbook API calls; smoke test measuring OnLoad latency. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>DQ_RibbonCallbacks_DeferredLoadRibbonMap()</code> / <code>Deferred_LoadRibbonMap()</code> — manifest ingestion, canonicalization, signature verification, PQ template discovery, owner resolution, fallback policy, examples, and tests</strong><br><strong>Purpose & contract:</strong> deferred initializer invoked off the UI thread (via <code>Application.OnTime</code>) to perform IO and heavier work: read <code>ribbon-map.json</code> from disk or embedded UI, validate JSON Schema via <code>REG_Config.ValidateManifestSchema</code>, canonicalize and compute <code>ribbonMapHash</code>, verify manifest signature (fail-closed in production), detect duplicates, discover PQ templates (record <code>mChecksum</code>), emit appropriate audits (<code>ribbon.map.loaded</code>, <code>ribbon.map.invalid</code>, <code>ribbon.map.signatureVerification</code>, <code>ribbon.map.duplicates</code>), and populate <code>gRibbonMap</code> (late-bound Dictionary). Must not block UI while running; protect against missing dependencies.<br><strong>Deterministic validation steps & invariants:</strong> <br>1. Read manifest via <code>DQ_Utilities.SafeReadAllText</code> or <code>ReadEmbeddedCustomUI</code> fallback. <br>2. Validate schema (collect exhaustive <code>errors</code>). <br>3. Require <code>validationResult(&quot;valid&quot;)</code> (or produce <code>ribbon.map.invalid</code>). <br>4. Compute canonical JSON and SHA256 via <code>DQ_Utilities.ComputeSHA256</code>. <br>5. If signature present, run <code>REG_Config.VerifyManifestSignature</code>; in production (REG_Config.IsProduction) reject invalid signature (emit fail-closed audit). <br>6. Parse canonical JSON into <code>gRibbonMap</code> via <code>REG_Config.ParseRibbonMapCanonicalJson</code>. <br>7. Deduplicate control IDs and refuse manifest if duplicates found (emit <code>ribbon.map.duplicates</code>).<br><strong>PQ specifics & template provenance:</strong> record <code>pqTemplates</code> and <code>mChecksum</code> in audits; schedule worker validation jobs for template mismatches (use <code>JobSchedulerIntegration</code>).<br><strong>Fallback policy:</strong> non-critical warnings → emit <code>ribbon.map.warning</code> and proceed with reduced map; critical schema/signature issues → emit <code>ribbon.map.invalid</code> and keep previous stable map (fail-closed for regulated controls).<br><strong>Safe I/O & persistence patterns:</strong> read-verify-parse pattern; atomic snapshot persistence if saving; avoid network fetches without local cache and audit. <br><strong>Observability:</strong> emit <code>ribbon.map.signatureVerification</code>, <code>ribbon.map.loaded</code>, <code>ribbon.map.pqTemplate</code>, and <code>ribbon.map.ownersResolved</code> audits with <code>ribbonMapHash</code>, <code>signatureFingerprint</code>, and correlation id.<br><strong>Tests & CI:</strong> schema validator vectors, canonicalization/golden parity tests, signature verification mocks, duplicate id negative tests, PQ mChecksum tests, and smoke-test path covering background job scheduling. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ValidateControlId(controlId)</code> — canonical guard, permitted patterns, metadata checks, PII policy, examples, and tests</strong><br><strong>Purpose & contract:</strong> canonical validator for inbound control identifiers. Idempotent and side-effect free except that failures emit audit rows (safe provenance). Returns either a <code>controlMeta</code> dictionary (from <code>gRibbonMap</code>) or an error dictionary <code>{errorCode, userHint}</code>. Must never surface PII in <code>userHint</code> and must produce stable, localized-free hints.<br><strong>Checks performed (deterministic):</strong> <br>1. Trim and length check (≤128 chars). <br>2. Char whitelist: <code>A–Z a–z 0–9 _ - @ .</code>. <br>3. Lookup in <code>gRibbonMap</code> and check <code>gControlEnabled</code> state. <br>4. Ensure <code>requiresApproval</code>, <code>regulated</code>, <code>mayAffectPII</code> flags exist with safe defaults. <br>5. Pilot/tenant scoping via <code>REG_Config.IsInPilot</code> when <code>pilotCohorts</code> present. <br><strong>Failure audit semantics:</strong> unknown/invalid entries emit <code>ribbon.control.validate</code>, <code>ribbon.control.validate.unknown</code>, or <code>ribbon.control.validate.disabled</code> with correlation id; <code>userHint</code> must be PII-free. <br><strong>Examples:</strong> valid control returns metadata including <code>estimatedCost</code>, <code>handler</code>, <code>owner</code>; unknown control returns <code>{errorCode:&quot;RIB001&quot;, userHint:&quot;Unknown control; contact add-in owner&quot;}</code>. <br><strong>Tests:</strong> fuzz invalid ids, verify alias handling, ensure <code>userHint</code> contains no PII, unit tests for pilot/cohort denial path. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>MapControlToHandler(controlId)</code> — deterministic mapping, aliasing, versions, migration hints, examples, and tests</strong><br><strong>Purpose & contract:</strong> pure resolver returning mapping <code>{handlerName, handlerModule, estimatedCost, requiredApprovals, owner, version, migrationHint?}</code>. Must rely solely on <code>gRibbonMap</code> and manifest semantics; changes occur only after manifest reload (hash change).<br><strong>Capabilities & invariants:</strong> alias resolution via <code>aliasOf</code>, version token support (<code>control@vN</code> → version override), fallback owner <code>&quot;unknown&quot;</code>, deterministic <code>estimatedCost</code> default <code>&quot;medium&quot;</code>.<br><strong>Examples:</strong> direct mapping returns <code>HandleProposeV2</code>; alias returns migration hint <code>&quot;alias-&gt;...&quot;</code>; version suffix overrides <code>version</code> field. <br><strong>Tests:</strong> mapping stability across reloads, alias/migration hint correctness, version parsing (split on <code>@</code>). </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>BuildUiParamsHash(paramsJson)</code> — canonicalization rules, redaction patterns, PQ template handling, examples, and tests</strong><br><strong>Purpose & contract:</strong> produce deterministic SHA256 hash representing UI parameters while applying safe minimal redaction when registry helpers are not available. Prefer <code>REG_Config.CanonicalizeAndRedactParams</code> when present; otherwise perform conservative normalization: normalize line endings to LF, collapse whitespace, replace tabs, trim, remove empty values, and compute SHA256 via <code>DQ_Utilities.ComputeSHA256</code>. Always return a stable hex string; never persist raw params within this function.<br><strong>Edge behaviors & fallback:</strong> on exceptions fall back to hashing trimmed raw <code>paramsJson</code>. <br><strong>PQ specifics:</strong> strip or redact credentials from <code>connectionString</code> before hashing; record <code>mChecksum</code> in evidence rather than raw param value. <br><strong>Tests:</strong> deterministic hash across reordering/whitespace permutations, locale independence, and redaction coverage for known PII patterns. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HandleControlAction(controlId, paramsJson, Optional userId)</code> — secure dispatcher, audit anchoring, job scheduling, inline safety, UI contract, examples, and tests</strong><br><strong>Purpose & contract:</strong> authoritative entrypoint for control actions invoked by Ribbon callbacks. Responsibilities: validate <code>controlId</code>, build <code>correlationId</code>, emit <code>UserAction</code> audit (params hashed), decide inline vs scheduled execution, either call <code>SafeInvokeHandler</code> or persist job descriptor with <code>JobSchedulerIntegration</code>, and return an immediate UI-safe JSON response containing <code>status</code>, <code>message</code>, and <code>correlationId</code>. Must not perform long running work synchronously; must fail-closed for protected/regulatory actions on validation failure.<br><strong>Canonical orchestration (must/shall):</strong> <br>1. <code>startCid = DQ_Bootstrap.NewCorrelationId()</code>.<br>2. <code>controlMeta = ValidateControlId(controlId)</code>; if error emit permission audit and return deny message (use <code>SafeErrorToUser</code>).<br>3. <code>paramsHash = BuildUiParamsHash(paramsJson)</code>; call <code>EmitUserActionAudit</code> (non-blocking).<br>4. <code>handlerMeta = MapControlToHandler(controlId)</code>; validate and call <code>ValidateUserPermissions</code> (deny if not allowed).<br>5. <code>decision = IsLightweightAction(handlerMeta)</code>; if lightweight → <code>SafeInvokeHandler(handlerName, paramsJson, startCid)</code>; else → build <code>jobDesc</code> and call <code>JobSchedulerIntegration(jobDesc)</code> and emit <code>job.persisted</code> audit.<br>6. Return short UI response (safe strings only) immediately.<br><strong>Failure & security semantics:</strong> permission denial returns <code>ribbon.permission.denied</code> audit; exceptions mapped via <code>DQ_Error.MapExceptionToErrorCode</code> and emitted as <code>ribbon.handler.exception</code>; ensure no PII leaks in returned UI messages.<br><strong>Tests:</strong> concurrency (many simultaneous clicks), idempotency when same <code>rowId</code>/paramsHash repeated, permission denial paths, inline vs scheduled decision boundaries. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>IsLightweightAction(handlerMeta)</code> — policy evaluation, thresholds, explainability, examples, and tests</strong><br><strong>Purpose & contract:</strong> determine whether to execute handler inline or schedule as a job. Inputs: <code>handlerMeta</code>, runtime thresholds from <code>DQ_Config.GetThresholds()</code>, and runtime selection metrics (active selection row count). Return object <code>{lightweight:Boolean, rationale:String}</code>. Decisions must be deterministic and explainable.<br><strong>Policy rules & examples:</strong> <br>1. Fail-closed: if <code>handlerMeta.requiredApprovals</code> or <code>handlerMeta.regulated</code> → <code>lightweight=false</code> (<code>&quot;requiresApproval&quot;</code>/<code>&quot;regulated_control&quot;</code>). <br>2. Cost tag: <code>estimatedCost=&quot;light&quot;</code> → inline, <code>&quot;heavy&quot;</code> → scheduled; <code>&quot;medium&quot;</code> consults <code>rowCountThreshold</code>. <br>3. Row count threshold: compare <code>DQ_Utilities.GetActiveSelectionRowCount()</code> against configured threshold (default 10000).<br><strong>Tests:</strong> threshold boundaries, safe fallbacks when utilities unavailable, rationale strings for auditing. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeInvokeHandler(handlerName, argsJson, correlationId)</code> — execution frame, time budgets, cancellation, error mapping, redaction, telemetry, examples, and tests</strong><br><strong>Purpose & contract:</strong> protective execution wrapper that: verifies handler registration via <code>REG_Ribbon.IsHandlerRegistered</code>, emits start audit (<code>handler.start</code>) with <code>payloadHash</code>, sets cooperative timeout (from <code>DQ_Config.GetInlineHandlerTimeoutMs()</code> default 5000ms), constructs <code>cancelToken</code>, invokes handler via <code>REG_Ribbon.InvokeHandler(handlerName, argsJson, cancelToken, correlationId, timeoutMs)</code>, captures result, emits complete audit (<code>handler.complete</code>), emits telemetry <code>ribbon.handler.duration_ms</code>, and returns handler result (dictionary). Exceptions map to stable error codes and produce <code>handler.exception</code> audit. Must enforce redaction and avoid returning PII in UI-visible fields.<br><strong>Cancellation & watchdog integration:</strong> handlers must honor the provided <code>cancelToken</code> structure; watchdog (<code>SafeHandlerTimeoutWatchdog</code>) will mark <code>cancelToken(&quot;cancelled&quot;) = True</code> when timeout exceeded.<br><strong>Telemetry & observability:</strong> emit metrics and audits with correlationId and handlerName; include <code>payloadHash</code> where available.<br><strong>Tests:</strong> registered/unregistered handler path, handler that returns nothing, exception mapping, timeout/cancellation simulation, telemetry emission checks. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeHandlerTimeoutWatchdog(handlerToken, correlationId)</code> — cooperative cancellation, escalating audits, and examples</strong><br><strong>Purpose & contract:</strong> scheduled/check invoked to enforce inline handler time budgets: if <code>handlerToken(&quot;startedAt&quot;)</code> indicates elapsed time beyond configured inline timeout, set <code>handlerToken(&quot;cancelled&quot;) = True</code>, emit <code>ribbon.handler.timeout</code> audit with <code>elapsed_s</code>, and (if cancellation fails or handler remains unresponsive) escalate to <code>ribbon.handler.hung</code> with captured diagnostic payload. Uses <code>Application.OnTime</code> or host scheduling in VBA contexts. <br><strong>Examples & tests:</strong> inject long-running handler to ensure watchdog cancels token and audit emitted; verify handler terminates cooperatively; test hung escalation path and <code>ribbon.handler.hung</code> emission. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>CreateTagDict(k,v)</code> — helper for telemetry tags</strong><br><strong>Purpose & contract:</strong> tiny convenience to build a <code>Scripting.Dictionary</code> with a single tag key/value suitable for telemetry calls. Deterministic and side-effect free. Tests: trivial unit verifying returned dictionary contains key/value. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>JobSchedulerIntegration(jobDescriptor)</code> — canonical job descriptor schema, atomic persistence, idempotency, worker handoff, examples, and tests</strong><br><strong>Purpose & contract:</strong> persist job descriptor atomically for background worker consumption: build canonical JSON via <code>REG_Config.SerializeDictionaryToJson</code>, write to <code>jobsFolder</code> using <code>DQ_Utilities.AtomicWrite</code>, emit telemetry <code>job.persist.latency_ms</code>, return <code>jobId</code> on success or empty string on failure. Must support idempotent writes (same <code>jobId</code> → harmless). Must emit <code>job.persist.error</code> audit on persistent failures.<br><strong>Descriptor fields & invariants:</strong> <code>jobId, controlId, correlationId, paramsHash, configHash, persistedAt, handlerName, owner</code>. Must not contain raw secrets. <br><strong>Tests:</strong> atomic write success/failure, idempotency (re-persist same jobId), telemetry emission, worker pick-up simulation. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ValidateUserPermissions(userId, controlMeta)</code> — RBAC, approvals, dataset-level checks, examples, and tests</strong><br><strong>Purpose & contract:</strong> best-effort RBAC gateway returning <code>{allowed:Boolean, requiredApprovals:Collection, denialReason:String}</code>. Behavior: if <code>controlMeta.requiresApproval</code> true → deny inline and list required approvals; otherwise consult <code>REG_Permissions.EvaluateUserForControl</code> when available for dataset/regulatory checks. On errors return safe deny with <code>permission_check_error</code> and emit <code>ribbon.permission.check.error</code> audit (diagnostic payload encrypted).<br><strong>Examples:</strong> regulated dataset apply returns <code>allowed=false</code> and <code>requiredApprovals = [owner,compliance]</code>; emergency operator privilege yields <code>allowed=true</code> with <code>specialNote</code>.<br><strong>Tests:</strong> role matrix simulation, approval workflow handshake, exception handling when <code>REG_Permissions</code> unavailable. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RegisterCallback(controlId, handlerName, Optional metadataJson)</code> — controlled registration, signature checks, idempotency, persistence, examples, and tests</strong><br><strong>Purpose & contract:</strong> idempotent runtime registration of a control→handler mapping. Must verify handler signature using <code>REG_Ribbon.VerifyHandlerSignature</code> when available; reject registration if signature verification unavailable/failed (emit <code>ribbon.callback.register.failed</code>). Add mapping to <code>gRibbonMap</code> and set <code>gControlEnabled(controlId)=True</code>. Optionally persist via <code>REG_Config.PersistControlToggle</code> or <code>modExport</code> per policy. Emit <code>ribbon.callback.registered</code> on success.<br><strong>Security:</strong> only allow dynamic registration where operator has privileges; reject unsigned runtime handlers in production. <br><strong>Tests:</strong> signature verification success/failure, idempotent repeated registration, persistence path correctness. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RefreshRibbon()</code> — live rebind, diffs, invalidation, operator UX, examples, and tests</strong><br><strong>Purpose & contract:</strong> trigger deferred reload of <code>ribbon-map</code> and refresh UI. Implementation: schedule <code>DQ_RibbonCallbacks_DeferredLoadRibbonMap</code> via <code>Application.OnTime</code> (non-blocking), call <code>gRibbonUI.Invalidate</code> to refresh control state, emit <code>ribbon.refresh.requested</code> audit. If deferred load reports schema errors, do not switch map; emit <code>ribbon.refresh.error</code> and keep previous stable map. Must not interrupt running jobs.<br><strong>Examples & tests:</strong> manifest change → <code>RefreshRibbon</code> invoked → new controls appear after deferred load; if manifest invalid, UI unchanged. Tests: ensure <code>Invalidate</code> called for updated controls and running jobs continue unaffected. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>EnableControl(controlId, operatorId, Optional persist=False)</code> / <code>DisableControl</code> — runtime toggles, RBAC, kill-switch semantics, examples, and tests</strong><br><strong>Purpose & contract:</strong> update in-memory <code>gControlEnabled</code> toggle and optionally persist via <code>REG_Config.PersistControlToggle</code>. Call <code>gRibbonUI.InvalidateControl(controlId)</code> if UI present. Emit <code>ribbon.control.enabled</code> or <code>ribbon.control.disabled</code> with <code>operatorId</code>, <code>ts</code>, and <code>correlationId</code>. Persist path guarded by RBAC in <code>REG_Config</code>. These methods are intended as emergency kill-switches, staged rollout controls, and tenant pilot toggles. <br><strong>Examples & tests:</strong> disable <code>dq_export</code> during incident; enabling for pilot tenants uses <code>persist=True</code> and validates pilot scope. Tests validate RBAC enforcement and UI invalidation. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>ExportRibbonMap(destinationUri, operatorId)</code> — secure export, redaction, checksums, and chain-of-custody</strong><br><strong>Purpose & contract:</strong> export a redacted snapshot of <code>gRibbonMap</code> (and owners info) using <code>REG_Config.SerializeDictionaryToJson</code> and <code>REG_Config.RedactOwnersIfNeeded(operatorId)</code>, compute checksum via <code>DQ_Utilities.ComputeSHA256</code>, and persist atomically with <code>DQ_Utilities.AtomicWrite</code>. Emit <code>ribbon.map.export</code> with <code>destinationUri</code>, <code>checksum</code>, and <code>operatorId</code> on success; on failure emit <code>ribbon.map.export.error</code>. Must not leak private owner PII — redaction must be enforced when operator lacks privilege.<br><strong>Tests:</strong> verify redaction when operator lacks rights, checksum verification after write, and atomic write semantics for destination path. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName)</code> — CI deterministic harness, golden runs, and safeguards</strong><br><strong>Purpose & contract:</strong> enable test hooks to support deterministic CI harnesses. Only allowed if <code>REG_Config.AllowUnitTestHooks()</code> returns true. Register via <code>REG_TestHarness.RegisterHook</code> and emit <code>ribbon.testhook.registered</code>. Test hooks should accept fixed <code>correlationId</code> values and be disabled in production by default. On denial emit <code>ribbon.testhook.register.denied</code> audit. <br><strong>Tests:</strong> golden parity runs with fixed <code>cid</code>, ensure hooks are disabled when <code>AllowUnitTestHooks=False</code>. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>DiagnosticsToggle(enableVerbose, operatorId, ticketId, Optional ttlSeconds=1800)</code> — admin lifecycle, TTL, audit, and constraints</strong><br><strong>Purpose & contract:</strong> enable or disable verbose diagnostics for a bounded TTL. Must require operator privilege check (<code>REG_Config.OperatorHasDiagnosticsPrivilege</code>) and record operator/ticket in <code>gDiagnosticsState</code> plus <code>expiresAt</code>. Schedule auto-disable via <code>Application.OnTime</code> at <code>expiresAt</code>. Emit <code>ribbon.diagnostics.enabled</code> and <code>ribbon.diagnostics.disabled</code> audits (include <code>ticketId</code>, <code>operatorId</code>, <code>ttlSeconds</code>, correlationId). Verbose logs must be redaction-aware; diagnostics data containing secrets saved to evidence store only. <br><strong>Auto-disable entry:</strong> <code>DQ_RibbonCallbacks_DisableDiagnosticsAuto</code> checks expiry and emits <code>ribbon.diagnostics.autodisabled</code> when TTL lapses. <br><strong>Tests:</strong> TTL scheduling, enable/disable audit lifecycle, privilege denial behavior, and redaction verification of verbose traces. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>DQ_RibbonCallbacks_DisableDiagnosticsAuto()</code> — scheduled auto-disable</strong><br><strong>Purpose & contract:</strong> scheduled entry invoked at <code>gDiagnosticsState(&quot;expiresAt&quot;)</code> to clear diagnostics and emit <code>ribbon.diagnostics.autodisabled</code>. Safe-no-op if diagnostics state absent. Tests: expiry boundary handling and audit emission. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>SafeErrorToUser(correlationId, errorCode)</code> — UI-safe mapping, triage hint, and examples</strong><br><strong>Purpose & contract:</strong> map internal error codes to concise, non-PII UI messages that include <code>correlationId</code> for triage. Emit <code>ribbon.userErrorShown</code> audit containing minimal diagnostic metadata (errorCode, clipped message, correlationId, ts). Returned messages must not contain stack traces or secrets. Example mapping: <code>RIB_PERMISSION_DENIED</code> → <code>&quot;Action requires approval (ref r-...)&quot;</code>. Tests: verify mapping coverage, ensure PII absence and audit emission. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>TelemetryEmit(metricName, value, Optional tags)</code> — local buffering, audited uplink, and example metrics</strong><br><strong>Purpose & contract:</strong> locally buffer telemetry metrics via <code>DQ_Telemetry.BufferMetric</code> if available; do not perform remote uploads on ribbon main path. Metric payload includes <code>metricName</code>, <code>value</code>, <code>tags</code> (dictionary), and <code>ts</code> (<code>GetTimeStampSafe</code>). Typical metrics: <code>ribbon.click.latency_ms</code>, <code>ribbon.handler.duration_ms</code>, <code>job.persist.latency_ms</code>. Tests: buffer durability and correct tag shaping. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HotSwapHandlers(newMapJson, operatorId, approvals)</code> — transactional emergency patching, dry-run, smoke tests, persistence, rollback, and examples</strong><br><strong>Purpose & contract:</strong> support emergency runtime map updates with full validation and transactional semantics: validate manifest schema via <code>REG_Config.ValidateManifestSchema</code>, compute <code>beforeHash</code> and <code>afterHash</code>, verify signature, compute diff (via <code>REG_Config.ComputeRibbonMapDiff</code>), run smoke tests via <code>REG_TestHarness.runSmokeTests</code> (if allowed), atomically swap <code>gRibbonMap</code> in memory, optionally persist snapshot via <code>DQ_Utilities.AtomicWrite</code> to <code>REG_Config.GetHotSwapPersistPath(afterHash)</code>, and emit <code>ribbon.hotswap.applied</code> audit with <code>beforeHash</code>/<code>afterHash</code> and operator. On smoke-test failure, emit <code>ribbon.hotswap.smoketest.failed</code> and revert. All exceptions produce <code>ribbon.hotswap.error</code> audit. <br><strong>Dry-run & preview:</strong> if validation fails, return <code>{success:false, message:&quot;manifest validation failed&quot;, errors:...}</code> and emit <code>ribbon.hotswap.preview.failed</code> or <code>.invalid</code> accordingly. <br><strong>Tests:</strong> dry-run validations, signature failure path, smoke test success/failure, persistence and rollback correctness. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Shutdown()</code> — graceful ribbon unload, audit flush ordering, and state snapshot</strong><br><strong>Purpose & contract:</strong> flush audit & telemetry buffers (call <code>DQ_Audit.FlushBuffers</code>, <code>DQ_Telemetry.FlushBuffers</code>), serialize a minimal snapshot (<code>lastRefreshTs</code>, <code>lastCorrelationId</code>) via <code>REG_Config.SerializeDictionaryToJson</code>, persist snapshot atomically using <code>DQ_Utilities.AtomicWrite</code> to <code>REG_Config.GetStateSnapshotPath()</code>, emit <code>ribbon.shutdown</code> audit, and return. Must register with <code>DQ_Bootstrap</code> shutdown handlers so <code>DQ_Audit</code> flush occurs first; on error emit <code>ribbon.shutdown.error</code>. Tests: ensure buffers flushed and snapshot written; verify audit emitted. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>CreateErrorPayload(ex)</code> — stable error payload for audits</strong><br><strong>Purpose & contract:</strong> produce a compact, robust error dictionary for audit rows: <code>correlationId</code> (guarded), <code>errorCode</code> (mapped via <code>DQ_Error.MapExceptionToErrorCode</code> or <code>&quot;ERR_UNKNOWN&quot;</code>), truncated <code>message</code> (robust extraction from object <code>Description</code>/<code>Message</code> or scalar), and <code>ts</code>. Truncate message to safe length (512 chars). Must avoid leaking secrets; callers should not include raw exception objects in top-level audit rows. Tests: extraction from Err objects and COM exceptions, truncation behavior. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HasProperty(obj, propName)</code> — reflection helper</strong><br><strong>Purpose & contract:</strong> safe test whether <code>obj</code> exposes property <code>propName</code> using <code>CallByName</code> guarded by <code>On Error</code>. Returns Boolean; side-effect free for non-objects (returns False). Tests: COM object property presence detection. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>HasExistsMethod(obj)</code> — helper to detect <code>Exists</code> method on dictionary-like objects</strong><br><strong>Purpose & contract:</strong> attempts <code>obj.Exists(&quot;___probe___&quot;)</code> under <code>On Error</code> and returns True if no error; intended to discover Dictionary-like objects from late-bound libraries. Tests: behavior with Scripting.Dictionary and custom dictionary wrappers. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>GetEnabled(control)</code> / <code>OnAction(control, pressed)</code> / <code>OnActionWithParams(control, paramsJson)</code> — Ribbon XML compatibility & callbacks</strong><br><strong>Purpose & contract:</strong> compatibility helpers used by Ribbon XML: <code>GetEnabled</code> returns control enabled state using <code>gControlEnabled</code> with safe defaults; <code>OnAction</code> and <code>OnActionWithParams</code> extract <code>control.id</code>, fetch current <code>userId</code> (from <code>REG_Config</code> if available), and call <code>HandleControlAction</code> with <code>{}</code> or supplied <code>paramsJson</code>. Must be resilient to host differences and emit <code>ribbon.onaction.error</code>/<code>ribbon.onaction.params.error</code> audits on exceptions. Tests: ensure <code>GetEnabled</code> returns True for unknown controls, and <code>OnAction*</code> paths call <code>HandleControlAction</code> without raising. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>DiagnosticsToggle</code> / <code>DQ_RibbonCallbacks_DisableDiagnosticsAuto</code> — TTL lifecycle and auto-disable</strong><br><strong>Purpose & contract:</strong> enable/disable verbose diagnostics with TTL scheduling. <code>DiagnosticsToggle</code> enforces operator privilege; sets <code>gDiagnosticsState</code> fields (<code>enabled</code>, <code>enabledBy</code>, <code>ticketId</code>, <code>enabledAt</code>, <code>expiresAt</code>, <code>scheduledDisableAt</code>), schedules <code>Application.OnTime</code> for auto-disable, and emits <code>ribbon.diagnostics.enabled</code>/<code>ribbon.diagnostics.disabled</code>. <code>DQ_RibbonCallbacks_DisableDiagnosticsAuto</code> clears state when <code>Now &gt;= expiresAt</code> and emits <code>ribbon.diagnostics.autodisabled</code>. Must redact secrets in verbose logs. Tests: enable/disable flow, autoschedule cancel on immediate disable, privilege denial audit. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook</code> / <code>RegisterCallback</code> / <code>ExportRibbonMap</code> — registration & export control flows</strong><br><strong>Purpose & contract (summary):</strong> registration flows enforce signature checks (<code>REG_Ribbon.VerifyHandlerSignature</code>) and idempotency; <code>RegisterUnitTestHook</code> gates CI hooks via <code>REG_Config.AllowUnitTestHooks</code>; <code>ExportRibbonMap</code> performs redaction, checksum compute, and atomic write. All paths must emit respective audits: <code>ribbon.callback.registered/failed</code>, <code>ribbon.testhook.registered/denied</code>, <code>ribbon.map.export</code>/<code>ribbon.map.export.error</code>. Tests: signature verification, unit test hook gating, redaction correctness and atomic export semantics. </td></tr><tr><td data-label="DQ_RibbonCallbacks — Per-function Expert Technical Breakdown"> <strong><code>Job persist, audit obligations, security, SLOs, testing matrix, failure modes, operator UX, change control, evidence collection</code> — module-level summaries</strong><br><strong>Audit obligations:</strong> every user-initiated action must append <code>UserAction</code> audit with <code>correlationId</code>; artifact-producing steps must emit step audits (<code>module.step</code>, <code>job.persisted</code>, etc.). <br><strong>Security & secrets policy:</strong> do not store raw secrets in ribbon code; use KMS/HSM via host helpers; manifest signatures required for production manifest loads; redaction enforced before any persisted diagnostics/evidence. <br><strong>Performance / SLOs:</strong> click handling median <50ms; job persist <2s; inline handler default timeout 5s. <br><strong>Testing matrix & CI gates:</strong> unit, integration, golden parity, audit chain verification, static forbidden-API enforcement. <br><strong>Failure & runbooks:</strong> collect <code>ribbon-map.json</code>, <code>audit_tail.csv</code>, job descriptors, handler logs, <code>modConfig</code> snapshot, release manifest; follow triage flow using correlation id and <code>forensic_manifest</code>. <br><strong>Change control:</strong> PR + migration manifest for behavioral changes; compliance signoffs for regulated features; signed release manifest and canary rollout with <code>VerifyAuditChain</code> post-deployment. </td></tr></tbody></table></div><div class="row-count">Rows: 30</div></div><div class="table-caption" id="Table7" data-table="Docu_0176_07" style="margin-top:2mm;margin-left:3mm;"><strong>Table 7</strong></div>
<div class="table-wrapper" data-table-id="table-7"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Config — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Config — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Executive summary (single-paragraph):</strong> <code>DQ_Config</code> is the authoritative configuration subsystem for the add-in ecosystem. It must provide deterministic loading, schema validation, canonical hashing, idempotent migrations, safe tenant-scoped overrides, audited change-control, atomic persistence, safe hot-reload semantics, RBAC/approval enforcement for regulated keys, and secure export/import for compliance. <code>DQ_Config</code> publishes a minimal, immutable runtime view (<code>ResolvedConfig</code>) and a controlled mutator surface (Set/Import/Persist/Rollback) which always produce auditable rows. Design priorities: determinism, auditability, safety (no secrets in plain text), non-blocking behavior for UI-idle initialization, and clear failure modes with operator recovery steps. {audit: config.loaded / config.changed / config.invalid} <<MUST NOT: heavy IO or workbook Range access on init>>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Module responsibilities & invariants</strong><br>1. Single source of truth for runtime behavior: thresholds, sampling, feature flags, tenant overrides, migration manifests, schema versioning, and operator approval metadata.<br>2. Deterministic canonicalization and hashing: identical logical config must produce identical <code>config.hash</code> across locales and process restarts.<br>3. Idempotent migrations: migrations must be pure, safe under repeated application, and reversible where possible.<br>4. Audited mutation: every change produces an append-only audit row with <code>beforeHash</code> and <code>afterHash</code>; full snapshots are stored only in encrypted evidence stores and referenced by <code>evidenceRef</code> in audits.<br>5. RBAC & approval enforcement: protected keys (e.g., <code>featureFlags.autoApply</code>, <code>migration.*</code>, <code>exportKeys</code>) require recorded approvals and must be refused otherwise.<br>6. Safe persistence: atomic-write semantics with checksum verification and durable commit guarantees; on failure, prior artifact remains intact.<br>7. Non-blocking deferred init: <code>LoadConfig</code> must be suitable for UI-idle deferred execution and must not perform synchronous heavy network/disk IO on the host UI thread.<br>8. Observable: instrumented metrics for load/persist durations, migration duration, reloads, and validation errors. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>API surface (summary):</strong><br><code>LoadConfig(pathOrBlob)</code> → <code>{config, configHash, migrationsApplied, validationErrors}</code><br><code>ValidateConfigSchema(config)</code> → <code>{valid, errors[]}</code><br><code>ComputeConfigHash(configCanonical)</code> → <code>sha256:&lt;hex&gt;</code><br><code>ApplyMigrations(config, migrationsRegistry)</code> → <code>{config, applied[], warnings[]}</code><br><code>MergeTenantOverrides(base, overrides, policy)</code> → <code>{resolvedConfig, diff}</code><br><code>GetConfigValue(path, default)</code> → <code>value</code> (immutable copy)<br><code>SetConfigValue(path, value, opts)</code> → <code>{status, newHash}</code> (audited) <em>[note: SetConfigValue not implemented as a single function in this module; mutator flows are implemented via specific APIs: <code>ApplyMigrations</code>, <code>PersistConfigAtomic</code>, <code>RollbackConfig</code>, and audit helpers.]</em><br><code>PersistConfigAtomic(blob, destinationUri, opts)</code> → <code>{status, checksum, uri}</code><br><code>ReloadConfigDeferred()</code> → <code>{status, beforeHash, afterHash, diff}</code><br><code>ValidateFeatureFlags(config)</code> → <code>{allowed, requiredApprovals, violations}</code><br><code>AuditConfigChange(beforeHash, afterHash, metadata)</code> → <code>auditRowId</code> (mapped to <code>AuditConfigRow</code>/<code>AuditConfigRowFull</code>)<br><code>ExportConfig(dest, opts)</code> → <code>{artifactUri, checksum, signed}</code> <em>(export/import packaging functions are described at policy level; <code>ExportConfig</code> / <code>ImportConfig</code> are supported conceptually — module includes helpers for evidence export and stubbing but full signing/encryption hooks are host-implemented)</em><br><code>ImportConfig(uri, opts)</code> → <code>{previewDiff, requiredApprovals, status}</code><br><code>RollbackConfig(targetHash, opts)</code> → <code>{status, beforeHash, afterHash}</code><br><code>WatchConfigFile(watchSpec)</code> → <code>watchHandle</code> (opt-in dev helper). </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>LoadConfig(pathOrBlob)</code> — deep behavior & examples (REVISED to match code)</strong><br><strong>Detailed contract (code-accurate):</strong> accepts either a path (when <code>FileExists(path)</code> is <code>True</code>) or a JSON blob string. Execution order implemented in module: <br>1. <strong>Optionally schedule deferred</strong> if <code>options(&quot;deferred&quot;) = True</code> via <code>ReloadConfigDeferred</code> (writes payload into <code>gEvidenceFolder</code> and schedules <code>Application.OnTime</code>).<br>2. <strong>Read blob</strong> (from file or direct string) using <code>ReadTextFileUtf8</code> (safe UTF-8 read) and set <code>gConfigSource</code> appropriately.<br>3. <strong>Parse JSON</strong> via the module's <code>ParseJson</code> (internal recursive-descent parser) with <code>ParseJsonSafe</code> wrapper to collect parse errors into <code>parseMeta</code>.<br>4. On parse failure: return <code>{status:&quot;invalid&quot;, validationErrors: parseMeta(&quot;parseErrors&quot;)}</code> and call <code>AuditConfigRow &quot;config.invalid&quot;</code>.<br>5. <strong>Canonicalize</strong> the parsed object with <code>CanonicalizeJson(parsed, schemaHints)</code> (which uses <code>CanonicalizeValue</code>) to obtain deterministic JSON string.<br>6. <strong>Compute pre-migration hash</strong> using <code>ComputeConfigHash(canonical)</code> (creates temp UTF-8 file then SHA256 over bytes).<br>7. <strong>Validate schema</strong> using <code>ValidateConfigSchema(parsed, schemaHint)</code> — partial/vetted validator in-module; if invalid, return <code>config.invalid</code> and append <code>AuditConfigRow</code> with details.<br>8. <strong>Apply migrations</strong> if <code>options(&quot;migrations&quot;)</code> present: call <code>ApplyMigrations(parsed, migrations, dryRunFlag)</code>; on failure return <code>migration_failed</code> and audit <code>config.migration.failed</code>.<br>9. <strong>Recompute canonical + post-migration hash</strong> and assign <code>postHash</code> to <code>gConfigHash</code> at the end of successful load.<br>10. <strong>Tenant overrides</strong>: if <code>options(&quot;tenantId&quot;)</code> present, call <code>LoadTenantOverrides</code> (adapter placeholder) and <code>MergeTenantOverrides</code> to resolve tenant-scoped config.<br>11. <strong>Persist in-memory</strong> immutable copy via <code>gConfig = DeepCopyDict(parsed)</code> and <code>gConfigHash = postHash</code>.<br>12. <strong>Create evidence snapshot</strong> with <code>StoreConfigEvidence(canonical, &quot;config.loaded&quot;, auditMeta)</code> (sanitizes via <code>SanitizeConfigForAudit</code>, writes evidence via <code>EncryptAndStoreEvidence</code> stub), then call <code>AuditConfigRowFull &quot;config.loaded&quot;</code> with <code>evidenceRef</code> and audit metadata.<br>13. <strong>Return</strong> <code>{status:&quot;loaded&quot;, config: DeepCopyDict(parsed), configHash: postHash, migrationsApplied}</code>.<br><strong>Failure behavior (code-accurate):</strong> parse or schema failures return <code>status</code> "invalid" immediately; migration failures during <code>ApplyMigrations</code> emit <code>config.migration.failed</code> and return a failure object; IO errors raise through <code>LoadErr</code> handler which audits <code>config.error</code> and returns <code>status:&quot;error&quot;</code>.<br><strong>Tests (code-aligned):</strong> parse error coverage for <code>ParseJson</code> edge-cases, canonicalization parity (use <code>CanonicalizeJson</code> + <code>ComputeConfigHash</code>), <code>LoadConfig</code> scheduled <code>ReloadConfigDeferred</code> path, large file handling via <code>ReadTextFileUtf8</code>, and evidence snapshot creation path. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Canonicalization rules & <code>ComputeConfigHash</code> (exact algorithm — code mapping)</strong><br><strong>Implementation notes from code:</strong> canonicalization is implemented by <code>CanonicalizeValue</code> + <code>CanonicalizeJson</code> which:<br>• sorts object keys via <code>GetSortedKeys</code> / <code>QuickSortStringArray</code> at every object node;<br>• preserves arrays unless schemaHints specify <code>unorderedArrays</code> — those arrays are canonicalized by serializing items to JSON strings (<code>CanonicalizeJsonItemAsString</code>) and sorting them deterministically;<br>• normalizes numbers via <code>NormalizeNumberForJson</code> to remove trailing zeros and collapse exponent forms to short decimal when possible;<br>• normalizes date-like strings when <code>schemaHints(&quot;dates&quot;)</code> marks the path, using <code>NormalizeDateToIsoUtc</code> (best-effort CDate->ISO UTC);<br>• serializes using <code>ConvertToJson</code> if <code>JsonConverter</code> is available at runtime, otherwise falls back to <code>ManualSerialize</code> with deterministic ordering and escaping;<br>• <code>ComputeConfigHash</code> writes canonical JSON to a temp UTF-8 file (<code>CreateTempFileWithContentUtf8</code>) and computes SHA256 via <code>ComputeSHA256_File</code> (prefers <code>ComputeSHA256_FileVBA</code>, which currently delegates to <code>certutil</code> fallback).<br><strong>Hash format:</strong> returns <code>sha256:&lt;lower-hex&gt;</code> after normalization. <br><strong>Edge cases & tests:</strong> floating-point vs integer returns handled by <code>NormalizeNumberForJson</code>; if lossless string-preservation required schema must mark values as string (see schemaHints). Include cross-locale parity tests and collision smoke tests. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ValidateConfigSchema</code> — precision & diagnostics (code-accurate)</strong><br><strong>What the module implements:</strong> a lightweight, partial validator that verifies:<br>• top-level presence & type of keys <code>version</code> (String) and <code>profile</code> (Dictionary);<br>• <code>featureFlags</code> if present is an object;<br>• populates detailed error objects via <code>CreateValidationError(path, keyword, message, suggestion)</code> for missing or mistyped top-level fields.<br><strong>Contract & behavior:</strong> returns a Dictionary <code>{valid:Boolean, errors:Collection, duration_ms:Long, note:String}</code>; it is intentionally partial and advises integration with a full JSON Schema v7 validator when available. <br><strong>Diagnostics:</strong> each error includes <code>path</code>, <code>keyword</code>, <code>message</code>, and <code>suggestion</code>. <code>LoadConfig</code> uses this result to decide success/failure. <br><strong>Tests:</strong> provide positive/negative vectors for top-level keys, ensure suggestions are human-readable, ensure <code>duration_ms</code> set, and ensure validator gracefully handles unexpected types. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ApplyMigrations</code> — design & implemented semantics (code-accurate)</strong><br><strong>What is implemented:</strong> <code>ApplyMigrations(configObj, migrations, Optional dryRun)</code> accepts <code>migrations</code> as a <code>Collection</code> of migration descriptors where each descriptor is expected to include <code>id</code>, <code>applyFn</code> (string name of VBA proc/callable via <code>Application.Run</code>), optional <code>rollbackFn</code>, <code>manifest</code>, etc. <br><strong>Behavioral contract (module):</strong><br>• Loads applied migrations registry via <code>LoadAppliedMigrationsRegistry()</code> and skips migrations already recorded.<br>• If <code>dryRun=True</code> attempts to call <code>applyFn_dryRun</code> first (via <code>SafeApplicationRun</code>), otherwise uses <code>applyFn</code> to compute preview.<br>• For real runs: calls <code>applyFn</code> via <code>Application.Run</code> with a deep copy of current config; on success expects an object/dictionary result representing the new config; updates <code>current</code> to <code>applyRes</code>.<br>• After each applied migration it computes <code>beforeHash</code> and <code>afterHash</code> (via <code>ComputeConfigHash</code>) and persists the applied id via <code>SaveAppliedMigration(id, meta)</code> and emits <code>AuditConfigRow &quot;config.migration.applied&quot;</code> with meta. <br><strong>Failure & rollback:</strong> if <code>Application.Run</code> fails or returns invalid type, <code>ApplyMigrations</code> aborts, returns <code>{status:&quot;failed&quot;, error:...}</code>, and leaves caller responsible for rollback (the function uses deep copies to avoid mutating the original input).<br><strong>Idempotency:</strong> the persistent <code>MIGRATIONS_APPLIED_FILE</code> registry is used to ensure idempotency across restarts. Migration functions themselves are required by governance to be idempotent but not enforced by code beyond persistence and skip semantics. <br><strong>Tests:</strong> dry-run callable-name fallback tests (<code>_dryRun</code>), <code>Application.Run</code> error handling via <code>SafeApplicationRun</code>, <code>SaveAppliedMigration</code> atomic write tests, and idempotency-by-registry verification. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>MergeTenantOverrides</code> — multi-tenant safety & precedence (code-accurate)</strong><br><strong>What the code implements:</strong> <code>MergeTenantOverrides(baseConfig, overrides)</code> accepts <code>overrides</code> as either a JSON string or a <code>Dictionary</code>. Implementation delegates to <code>MergeDeepWithPolicy(DeepCopyDict(baseConfig), overrideObj, policy)</code> where policy is optional. <br><strong>Merge policy (implemented):</strong> top-level deep-merge semantics with per-key behavior currently defaulting to <code>replace</code> for collections and deep-merge for dictionaries. <code>MergeDeepWithPolicy</code> supports a simple <code>denyOverride</code> policy (top-level key name) and enforces it by skipping overrides for keys with that policy entry. <br><strong>Behavioral notes:</strong> if <code>overrides</code> is malformed or not a dictionary, function returns a deep copy of base (no-op). It preserves immutability by returning a deep copy. <br><strong>Audit/observability:</strong> caller should record <code>config.resolve</code> events — implementation provides <code>MergeTenantOverrides</code> data for producing diffs; <code>LoadConfig</code> calls it when tenantId is present. <br><strong>Tests:</strong> precedence matrix using <code>MergeDeepWithPolicy</code>, denyOverride behavior, and JSON-string override parsing. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>GetConfigValue</code> — safe accessor semantics (code-accurate)</strong><br><strong>Implemented semantics:</strong> <code>GetConfigValue(path, defaultValue)</code> traverses <code>gConfig</code> using dot-separated path tokens; supports <code>Dictionary</code> and <code>Collection</code> traversal (collection indices are 1-based). Returns deep copy for composite types (via <code>DeepCopyDict</code> / <code>DeepCopyCollection</code>) and <code>defaultValue</code> when path missing or traversals invalid. <br><strong>Edge-cases & safety:</strong> returns <code>defaultValue</code> on any error path; does not expose internal mutable objects. <code>trace</code> flag not implemented in this module (but <code>RecordMetric</code> is available for telemetry). <br><strong>Tests:</strong> range-indexing for collections, missing-path returns, and immutability of returned composite types. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SetConfigValue</code> — audited mutator & governance (code-accurate note)</strong><br><strong>Important accuracy note:</strong> there is <strong>no single <code>SetConfigValue</code> function implemented</strong> in the provided module source. Mutations in this module are performed by higher-level flows: <code>ApplyMigrations</code> (batch transforms), <code>PersistConfigAtomic</code> (persistence), and <code>RollbackConfig</code> (reversion). Audited single-field mutators and RBAC/approval enforcement are implied in the design but must be implemented by callers (or host) using the module's primitives (<code>ValidateConfigSchema</code>, <code>ValidateFeatureFlags</code>, <code>AuditConfigRowFull</code>, <code>PersistConfigAtomic</code>).<br><strong>Guidance for implementers:</strong> to provide <code>SetConfigValue</code> semantics, implement a small wrapper that:<br>• deep-copies <code>gConfig</code>, applies the subtree change, calls <code>ValidateConfigSchema</code> on the subtree or whole config, calls <code>ValidateFeatureFlags</code> when relevant, enforces <code>approvalRefs</code> for regulated keys (use <code>IsRegulatedKey</code> / <code>IsRegulatedKeyInConfig</code> helpers), computes <code>beforeHash</code>/<code>afterHash</code> with <code>ComputeConfigHash</code>, calls <code>AuditConfigRowFull</code> to store evidence, and persists via <code>PersistConfigAtomic</code>. On persistence failure, revert in-memory state and call <code>AuditConfigRow &quot;config.persist.failed&quot;</code>.<br><strong>Tests:</strong> implement wrapper unit tests validating audit emission and persistence error recovery. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>PersistConfigAtomic</code> — adapters & atomic-write pattern (code-accurate)</strong><br><strong>Adapter interface implemented in module:</strong> adapters are <code>Dictionary</code> objects mapping function names to callables used via <code>Application.Run</code> — local FS adapter is provided (<code>CreateLocalFsAdapter</code>) with implementations: <code>Adapter_LocalFS_WriteTemp</code>, <code>Adapter_LocalFS_FsyncTemp</code>, <code>Adapter_LocalFS_Commit</code>, <code>Adapter_LocalFS_VerifyChecksum</code>, <code>Adapter_LocalFS_ListArtifacts</code>, <code>Adapter_LocalFS_DeleteTemp</code>.<br><strong>Implemented commit algorithm:</strong><br>1. For N attempts (configurable via <code>opts.attempts</code>), create a unique <code>tempPath</code> and call <code>adapter(&quot;writeTemp&quot;, tempPath, blob)</code>.<br>2. Call <code>adapter(&quot;fsyncTemp&quot;, tempPath)</code> then compute temp checksum (<code>ComputeSHA256_File(tempPath)</code>).<br>3. Call <code>adapter(&quot;commit&quot;, tempPath, destinationPath)</code> to atomically move temp->final.<br>4. Call <code>adapter(&quot;verifyChecksum&quot;, destinationPath, checksumTemp)</code> to confirm persistence; on success return <code>{status:&quot;ok&quot;, checksum: checksumTemp, uri:destinationPath}</code>.<br>5. On transient failures perform <code>SleepBackoff</code> exponential backoff and retry; on exhaustion return <code>{status:&quot;failed&quot;, error:&quot;E_PERSIST_ATTEMPTS_EXHAUSTED&quot;}</code>.<br><strong>Local FS adapter specifics:</strong> <code>Adapter_LocalFS_Commit</code> does <code>If FileExists(final) Then Kill final: Name temp As final</code> (atomic on same volume); <code>Adapter_LocalFS_VerifyChecksum</code> computes file hash (uses <code>ComputeSHA256_File</code>) and compares.<br><strong>Observability:</strong> the function returns <code>status</code>, <code>checksum</code>, <code>uri</code> and callers should emit <code>config.persist.*</code> metrics. <br><strong>Tests:</strong> adapter failure injection, checksum mismatch path, commit rename edge-cases (cross-device), deletion of temp on failures, and attempts/backoff behavior. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ReloadConfigDeferred</code> — safe hot reload & dependency notification (code-accurate)</strong><br><strong>Implemented flow:</strong> <code>ReloadConfigDeferred(pathOrBlob, options)</code> writes the payload to <code>gEvidenceFolder</code> as <code>&lt;jobId&gt;.reload</code> and optional <code>.opts</code> then schedules <code>Application.OnTime</code> to run <code>DQ_Config__OnTimeReload</code> (a public sub) 1 second later. Returns <code>{status:&quot;scheduled&quot;, jobId}</code>.<br><strong><code>DQ_Config__OnTimeReload</code> behavior:</strong> reads payload and options, calls <code>LoadConfig(content, opts)</code>, checks <code>res(&quot;status&quot;) = &quot;loaded&quot;</code>, computes <code>beforeHash = gConfigHash</code> and <code>afterHash = res(&quot;configHash&quot;)</code>, calls <code>ValidateHotReload(diffSummary)</code> (stub returns True by default), then either <code>AuditConfigRow &quot;config.reload.failed&quot;</code> if hot reload rejected or calls <code>NotifySubscribersOnConfigUpdate beforeHash, afterHash, diffSummary</code> and <code>AuditConfigRow &quot;config.reload.completed&quot;</code> if accepted. Cleans up payload files on completion.<br><strong>Safety:</strong> <code>ValidateHotReload</code> is a hook implementable by the host to reject mid-flight dangerous changes. Notification is non-blocking (placeholder <code>NotifySubscribersOnConfigUpdate</code>) and subscriber errors should not roll back applied config. Throttling logic is present via <code>gReloadTimestamps</code> but validation/limits must be implemented by host usage. <br><strong>Tests:</strong> scheduled reload path, payload saving/cleanup, <code>ValidateHotReload</code> rejection handling, and subscriber-notify isolation. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ValidateFeatureFlags</code> — policy & gating (code-accurate)</strong><br><strong>Implemented checks:</strong> inspects <code>configObj(&quot;featureFlags&quot;)</code> (if present) and:<br>• if <code>autoApply = True</code> adds <code>two_person_approval</code> to <code>required</code> and records a violation entry <code>(&quot;/featureFlags/autoApply&quot;, reason)</code>.<br>• if <code>exportToPublic = True</code> adds <code>compliance_signoff</code> to required approvals and records a violation <code>(&quot;/featureFlags/exportToPublic&quot;, reason)</code>. <br><strong>Return:</strong> Dictionary <code>{allowed:Boolean, requiredApprovals:Collection, violations:Collection}</code> where <code>allowed</code> is <code>violations.count = 0</code>.<br><strong>Integration:</strong> callers (UI/Set wrapper / CI) should consult this to enforce approvals. <br><strong>Tests:</strong> verify flags produce required approvals and violation entries. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>AuditConfigChange</code> / <code>AuditConfigRow</code> & <code>AuditConfigRowFull</code> — canonical audit & evidence policy (code-accurate)</strong><br><strong>Implemented helpers:</strong> <code>AuditConfigRow(eventName, beforeHash, afterHash, metadata)</code> (simple append) and <code>AuditConfigRowFull(eventName, beforeHash, afterHash, metadata)</code> (ensures <code>gAuditFilePath</code> set, sanitizes/stores evidence via <code>StoreAuditMetadata</code> if needed, constructs CSV line with <code>correlationId</code> from <code>CreateCorrelationId</code>, timestamp via <code>Format(Now, &quot;yyyy-mm-dd hh:nn:ss&quot;)</code>, then calls <code>AppendLineAtomic gAuditFilePath, line</code>).<br><strong>Evidence handling:</strong> <code>StoreAuditMetadata</code> performs <code>SanitizeConfigForAudit(metadata)</code>, serializes via <code>ConvertToJsonSafe</code>, then calls <code>EncryptAndStoreEvidence</code> (currently a plaintext-file stub writing to <code>gEvidenceFolder</code> and returning the file path). <code>AuditConfigRowFull</code> prefers <code>metadata(&quot;evidenceRef&quot;)</code> if provided.<br><strong>Failure modes:</strong> <code>AuditConfigRowFull</code> traps errors and logs via <code>Debug.Print</code> on failure; audit append is best-effort but <code>AppendLineAtomic</code> simply appends to CSV and should be robust for typical filesystem errors. <br><strong>Tests:</strong> evidenceRef path stored in CSV, <code>AppendLineAtomic</code> atomic append behavior (append-only), <code>StoreAuditMetadata</code> redaction & evidence-staging. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>EncryptAndStoreEvidence</code> — evidence storage (stubbed)</strong><br><strong>Code status:</strong> stubbed to write plaintext UTF-8 file into <code>gEvidenceFolder</code> named <code>evi_&lt;ts&gt;_&lt;random&gt;.enc</code> and return the path. Production hosts MUST implement envelope encryption and KMS wrapping; the module intends this host integration point (<code>EncryptAndStoreEvidence</code>) to be replaced by a secure implementation. <br><strong>Tests & upgrade path:</strong> unit tests should stub or mock <code>EncryptAndStoreEvidence</code>; pre-prod must inject host KMS-backed function and verify <code>StoreAuditMetadata</code> calls return KMS-wrapped evidenceRefs. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>SanitizeConfigForAudit</code> — redaction & evidence handling (code-accurate)</strong><br><strong>Implemented rules (in code):</strong> recursively walks <code>Dictionary</code> values and:<br>• strings containing <code>@</code> → replaced with <code>&quot;&lt;REDACTED_EMAIL:&quot; &amp; left$(ShaFingerprint(s),8) &amp; &quot;&gt;&quot;</code>;<br>• strings containing <code>http</code> or <code>server=</code> and a <code>:</code> → replaced with <code>&quot;&lt;REDACTED_CONN:&quot; &amp; left$(ShaFingerprint(s),8) &amp; &quot;&gt;&quot;</code>;<br>• strings longer than 32 characters → replaced with <code>&quot;&lt;REDACTED_TOKEN:&quot; &amp; left$(ShaFingerprint(s),8) &amp; &quot;&gt;&quot;</code>;<br>• nested dictionaries are sanitized recursively. Non-dictionary inputs result in summary fingerprint object <code>{ &quot;summary&quot;: left$(ShaFingerprint(ConvertToJsonSafe(v)), 16) }</code>.<br><strong>Fingerprint implementation:</strong> <code>ShaFingerprint</code> creates a temp UTF-8 file with the input and calls <code>ComputeSHA256_File</code> (certutil fallback) returning the hex; temp file is removed best-effort.<br><strong>Tests:</strong> ensure email/conn/token patterns are redacted, nested objects are sanitized, and <code>ShaFingerprint</code> produces stable short fingerprints. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>RollbackConfig</code> — rollback safety & chain-of-custody (code-accurate)</strong><br><strong>Implemented flow (code):</strong> given <code>targetHash</code> (string like <code>sha256:&lt;hex&gt;</code>), <code>RollbackConfig</code>:<br>1. Verifies <code>gStorageAdapter</code> present; uses <code>Application.Run(gStorageAdapter(&quot;listArtifacts&quot;), Replace$(targetHash, &quot;sha256:&quot;, &quot;&quot;))</code> to list candidate artifacts.<br>2. Locates artifact whose path contains the hash substring; computes <code>ComputeSHA256_File(found)</code> and verifies it contains <code>Replace$(targetHash,&quot;sha256:&quot;,&quot;&quot;)</code>.<br>3. If <code>opts(&quot;validateSignature&quot;) = True</code> calls <code>VerifyArtifactSignature(found)</code> (stub returns False by default, so host must implement).<br>4. Reads artifact (<code>ReadTextFileUtf8(found)</code>), parses via <code>ParseJsonSafe</code>, validates via <code>ValidateConfigSchema</code> and <code>ApplyMigrations</code> dry-run to ensure compatibility.<br>5. Checks <code>IsRegulatedKeyInConfig(parsed)</code> and requires <code>opts(&quot;approvalRefs&quot;)</code> with at least 2 approvals if regulated.<br>6. Persists artifact content to <code>destPath</code> (local file) using <code>PersistConfigAtomic(content, destPath, opts)</code> and on success updates <code>gConfig</code> and <code>gConfigHash</code> to targetHash, writes evidence via <code>StoreConfigEvidence</code>, and appends <code>AuditConfigRowFull &quot;config.rollback&quot;</code>.<br><strong>Failure modes:</strong> missing artifact, checksum mismatch, signature invalid (if required), schema invalid cause immediate rejection with descriptive error codes. <br><strong>Tests:</strong> artifact lookup, checksum verification, signature validation path (stubbed), regulated-key approval gating, and persist success/failure handling. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>WatchConfigFile</code> — dev convenience (code-accurate)</strong><br><strong>Implemented behavior:</strong> <code>WatchConfigFile(path, opts)</code> creates a watch handle, writes a small <code>.watch</code> file under <code>gEvidenceFolder</code> containing the watch metadata (path, opts, handle), and returns <code>{status:&quot;watching&quot;, handle}</code>. It is a simple opt-in helper; actual file-change detection and scheduled reload logic is intended to be external or layered on top of this helper. <br><strong>Guards:</strong> the module comments require disabling in production; callers must provide signature verification before auto-apply. <br><strong>Tests:</strong> creation of handle file and returned metadata correctness; ensure watch file format is JSON via <code>ConvertToJsonSafe</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ParseJson</code> and parsing helpers — internal parser (code-accurate)</strong><br><strong>Implemented parser:</strong> <code>ParseJson</code> is a recursive-descent JSON parser producing:<br>• <code>Scripting.Dictionary</code> for JSON objects,<br>• <code>Collection</code> for JSON arrays,<br>• VB types for numbers/strings/booleans/Null.<br><strong>Robustness & features:</strong> handles string escapes including <code>\uXXXX</code> (best-effort <code>ChrW</code> conversion), numbers with fractional/exponent notation (returned as <code>Long</code> or <code>Double</code> as appropriate), whitespace skipping, and limited error reporting via <code>err.Raise</code> with useful positions. <code>ParseJsonSafe</code> wraps <code>ParseJson</code> capturing parse errors into <code>parseMeta(&quot;parseErrors&quot;)</code>. <br><strong>Constraints:</strong> it is not intended to be a fully exhaustive JSON engine but is deliberately self-contained to avoid runtime dependency on external <code>JsonConverter</code>. <code>&lt;br&gt;</code><strong>Tests:</strong> escape sequences including Unicode <code>\uXXXX</code>, unterminated string detection, number/exponent parsing, object/array nesting edge-cases, and trailing garbage detection handled by <code>IsOnlyWhitespace</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ComputeSHA256_File</code> & hashing helpers — implementation notes</strong><br><strong>Implementation:</strong> <code>ComputeSHA256_File</code> first attempts <code>ComputeSHA256_FileVBA</code> (which currently delegates to <code>ComputeSHA256_CertUtil</code>) and falls back to <code>ComputeSHA256_CertUtil</code> which runs <code>certutil -hashfile</code> in a shell (<code>WScript.Shell.exec</code>) and parses its StdOut for a 64-char hex line. <br><strong>Host guidance:</strong> If pure-VBA SHA256 is required, replace <code>ComputeSHA256_FileVBA</code> with an inline implementation and populate <code>SHA256_Bytes</code> / <code>BytesToHex</code> helpers. <br><strong>Tests:</strong> certutil output parse tests, handling of missing certutil (return empty string), and temporary-file cleanup after <code>ComputeConfigHash</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>RunInternalSelfChecks</code> — module self-checks (code-accurate)</strong><br><strong>What it does:</strong> collects a set of in-memory checks and returns <code>{checks: Collection}</code> including presence of <code>gStorageAdapter</code>, <code>evidence_folder_ok</code>, <code>audit_append_ok</code>, <code>json_converter_ok</code> or <code>json_converter_missing</code> (detected via <code>Application.Run(&quot;JsonConverter.ParseJson&quot;, &quot;{}&quot;)</code>), <code>sha256_ok</code> or <code>sha256_missing</code> (via <code>ComputeSHA256_File(ThisWorkbook.FullName)</code>), canonicalization basic test using <code>CanonicalizeJson</code>, and <code>evidence_store_ok</code> if <code>EncryptAndStoreEvidence(&quot;x&quot;)</code> returns a non-empty value. <br><strong>Purpose:</strong> quick diagnostic to detect common environment problems. <br><strong>Tests:</strong> ensure each check reports expected boolean for test harness with/without JsonConverter or certutil present. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ManualSerialize</code>, <code>ConvertToJson</code>, <code>ConvertToJsonSafe</code> — serialization fallbacks (code-accurate)</strong><br><strong>Behavior:</strong> <code>ConvertToJson</code> first tries <code>Application.Run(&quot;JsonConverter.ConvertToJson&quot;, v, 0)</code> and on any error falls back to <code>ManualSerialize</code>. <code>ConvertToJsonSafe</code> wraps <code>ConvertToJson</code> and ensures deterministic serialization. <code>ManualSerialize</code> implements deterministic JSON for <code>Dictionary</code>, <code>Collection</code>, strings, numbers, booleans, and null with <code>GetSortedKeys</code> to ensure stable ordering. <br><strong>Tests:</strong> parity between <code>ConvertToJson</code> when <code>JsonConverter</code> present vs <code>ManualSerialize</code> fallback; escaping correctness via <code>JsonEscape</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>MergeDeepWithPolicy</code>, <code>MergeDeep</code>, <code>DeepCopyDict</code>, <code>DeepCopyCollection</code> — deep merge & copying (code-accurate)</strong><br><strong>Implemented helpers:</strong> deep-copy and deep-merge utilities that preserve immutability (use JSON round-trip where necessary), support nested dictionaries and collections, and accept a simple per-key <code>policy</code> supporting <code>denyOverride</code>. These helpers are used by <code>MergeTenantOverrides</code> and by the module where deep merges are required. <br><strong>Tests:</strong> verify correct deep-copies, deep-merge behavior for nested dictionaries/collections, and policy enforcement. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>RecordMetric</code>, <code>AppendLineAtomic</code>, <code>CreateCorrelationId</code>, small IO helpers (code-accurate)</strong><br><strong>What they implement:</strong> <code>RecordMetric</code> accumulates debug metrics in <code>gMetrics</code>; <code>AppendLineAtomic</code> appends CSV lines to <code>gAuditFilePath</code> (ensuring folder exists); <code>CreateCorrelationId</code> returns <code>corr-YYYYMMDDhhmmss-&lt;rand&gt;</code>; <code>EnsureFolderExists</code>, <code>GetFolderPath</code>, <code>FileExists</code>, <code>WriteUtf8File</code>, <code>ReadTextFileUtf8</code>, <code>WriteTextFile</code> are pragmatic cross-platform file helpers with fallbacks. <br><strong>Tests:</strong> metric collection, CSV append durability, correlationId uniqueness sampling, and file write/read fallbacks when ADODB.Stream fails. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong><code>ExportConfig</code> & <code>ImportConfig</code> — packaging (module-level note)</strong><br><strong>Code status:</strong> the module contains policy-level descriptions and helpers (evidence storage, ConvertToJsonSafe, PersistConfigAtomic) to implement export/import, but full export packaging signing/encryption and a dedicated <code>ExportConfig</code>/<code>ImportConfig</code> procedure are not present as single-call functions in the module source. Implementers should build <code>ExportConfig</code> and <code>ImportConfig</code> by composing <code>SanitizeConfigForAudit</code>, packaging with <code>ManualSerialize</code> / <code>ConvertToJsonSafe</code>, calling <code>PersistConfigAtomic</code> via an adapter, and using host-supplied signing/encryption hooks (replace <code>EncryptAndStoreEvidence</code> and provide <code>VerifyArtifactSignature</code>). <br><strong>Tests & governance:</strong> packaging parity, redaction summary correctness, and signature verification must be validated in host integration tests. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Concurrency, locking & consistency model (code-accurate)</strong><br><strong>What module provides:</strong> optimistic concurrency primitives: <code>PersistConfigAtomic</code> expects callers to compute <code>expectedHash</code> and coordinate compare-and-swap semantics externally; the module supports advisory per-tenant policies via <code>MergeDeepWithPolicy</code> and <code>IsRegulatedKey</code> checks. Per-tenant advisory locks are not implemented but storage adapters may provide them. <br><strong>Tests:</strong> conflict detection at application layer, adapter-provided advisory lock semantics (if used). </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Failure modes & operator recovery (unchanged)</strong><br>1. <strong>Malformed upload</strong> — symptom: <code>config.invalid</code> audit with schema errors. Recovery: fix schema as advised and re-upload; collect <code>config.invalid</code> row for audit.<br>2. <strong>Migration failure mid-chain</strong> — symptom: <code>config.migration.failed</code> audit and in-memory rollback. Recovery: inspect migration logs, fix migration code (CI) or provide manual migration with <code>migration_manifest</code>, re-run with operator approval.<br>3. <strong>Persistence failure (network/storage)</strong> — symptom: <code>config.persist.failed</code> audit; in-memory revert. Recovery: inspect adapter logs, re-run <code>PersistConfigAtomic</code>, optionally stage local artifact for offline review and manual publish.<br>4. <strong>Unauthorized mutation</strong> — symptom: <code>R_CFG_APPROVAL_REQUIRED</code> returned. Recovery: provide required approvals and retry; append <code>config.changed</code> only on success.<br>5. <strong>Hot-reload rejected</strong> — symptom: <code>config.reload.failed</code> due to <code>ValidateHotReload</code> reporting breaking change. Recovery: schedule config change during maintenance window or provide manual approval to force reload (with <code>force</code> flag and strong audit). </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Observability & metrics (required, unchanged)</strong><br>Instrument the following metrics: <code>config.load.duration_ms</code>, <code>config.hash.compute.duration_ms</code>, <code>config.migration.duration_ms</code>, <code>config.persist.latency_ms</code>, <code>config.reload.duration_ms</code>, <code>config.validate.errors.count</code>, <code>config.export.count</code>, <code>config.rollback.count</code>, <code>config.approval.required.rate</code>. Include tags for <code>operatorId</code> (redacted), <code>environment</code>, and <code>tenantId</code>. Emit structured logs (JSON) for each significant step including <code>correlationId</code>. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Audit obligations (must/shall, unchanged)</strong><br>Every externally visible change must emit an audit row. Minimum fields: <code>timestamp,correlationId,module,event,operatorId,beforeHash,afterHash,reason,approvals[],evidenceRef,metadata</code>. For imports/exports include <code>artifactUri</code> and <code>artifact.checksum</code>. Audit rotations must be signed and preserved per retention policy. For any change to regulated keys include <code>migration_manifest</code> and <code>release_manifest</code> attachments. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Security & secrets policy (unchanged)</strong><br>• <code>DQ_Config</code> must reject direct secret strings in config (like raw DB connection strings or API tokens). Instead config must reference a KMS/HSM alias or secret id. <br>• All evidence snapshots containing sensitive config parts must be stored encrypted using envelope encryption; only evidenceRefs with appropriate approvals permit decryption. <br>• Signature verification required for imports used in production; unsigned imports fail unless <code>operator</code> has explicit override with <code>approvalRefs</code>. <br>• RBAC guard on <code>SetConfigValue</code> and <code>PersistConfigAtomic</code> enforced by <code>modBootstrap</code> identity mappings (SSO). <br>• Audit rows do not contain secret values—only fingerprints. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>CI & tests (comprehensive matrix, clarified to match implemented functions)</strong><br>Unit tests:<br>• <code>ValidateConfigSchema</code> positive/negative vectors (use <code>CreateValidationError</code> expectations).<br>• <code>ComputeConfigHash</code> cross-locale parity and idempotency (exercise <code>CanonicalizeJson</code> and certutil fallback).<br>• <code>ApplyMigrations</code> idempotency and dry-run previews including <code>SafeApplicationRun</code> fallback behavior.<br>• <code>MergeTenantOverrides</code> precedence matrix using <code>MergeDeepWithPolicy</code>.<br>Integration tests:<br>• Load→Migrate→Persist→Reload cycle with adapter mocked and real local-FS adapter present.<br>• Import→Preview→Apply→Rollback flow tests (using <code>RollbackConfig</code> and <code>PersistConfigAtomic</code>).<br>Golden tests:<br>• Canonical fixtures with expected <code>config.hash</code> values stored in <code>golden/</code> and compared under CI for regression detection (exercise <code>ManualSerialize</code> fallback to ensure parity).<br>Security tests:<br>• Signature verification (host-provided), redaction coverage tests for <code>SanitizeConfigForAudit</code>, and KMS reference enforcement.<br>Performance tests:<br>• Load/persist latency under concurrent admin activity and <code>RunInternalSelfChecks</code> for environment health. <br>CI gating: block merges on schema validation failures, migration idempotency failures, missing <code>migration_manifest</code> for regulated changes, or failing golden parity. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Developer guidance & safe patterns (unchanged)</strong><br>1. Keep IO adapters injectable for unit testing; avoid direct network calls in <code>LoadConfig</code> without adapter abstraction.<br>2. Provide <code>dryRun</code> flags for all mutating functions to allow safe review flows.<br>3. Keep migrations small, incremental, and well-documented; include a <code>migration_manifest</code> with cost/rollback analysis for any migration that changes semantics.<br>4. Ensure public API functions return structured results not raw exceptions; map exceptions to <code>ErrorCodeCatalog</code> entries for stable operator hints.<br>5. Use deterministic canonicalization utilities maintained centrally to avoid drift across languages. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Examples: long narratives (deterministic, auditable) — unchanged</strong><br><strong>Example 1 — Admin-driven config upgrade (regulated):</strong> Admin uploads <code>config_2026-03-01.json</code>. <code>LoadConfig</code> validates and finds schema-level breaking change: <code>autoApply</code> moved; migration <code>mig-20260301-autoapply</code> applied. Because <code>autoApply</code> impacts regulated outputs, the migration manifest is required and shows affectedRows estimate 12,482. <code>LoadConfig</code> returns a preview; operator supplies two approvals (<code>app-9001</code>, <code>app-9002</code>), and <code>SetConfigValue</code> persists change via <code>PersistConfigAtomic</code>. <code>config.changed</code> audit row appended with <code>beforeHash</code>/<code>afterHash</code>, <code>evidenceRef</code> pointing to encrypted snapshot, and <code>migration_manifest</code> attached. <code>ReloadConfigDeferred</code> fires and notifies <code>modDQRules</code> and <code>modRemediation</code> which re-evaluate automations in a controlled maintenance window. <br><strong>Example 2 — Emergency rollback due to regression:</strong> After a canary rollout, regression detected in <code>modMatchMerge</code> causing false merges. On-call calls <code>RollbackConfig</code> to prior <code>sha256:goodhash</code>. <code>RollbackConfig</code> validates artifact signature and schema, shows <code>rollback.preview</code> diff (reverts <code>match.mergeThreshold</code> from 0.85 to 0.90). Approvals present from Release Engineer and Compliance. <code>PersistConfigAtomic</code> writes the rollback artifact; <code>config.rollback</code> audit appended. <code>ReloadConfigDeferred</code> applies the rollback; <code>modMatchMerge</code> receives <code>config.updated</code> event and worker reprocesses job queue in safe mode. Forensics bundle includes <code>forensic_manifest</code> with artifact checksums. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Operator CLI & administrative commands (unchanged)</strong><br><code>config load --path &lt;file&gt;</code> → run <code>LoadConfig</code> locally; prints validation summary and <code>config.hash</code>.<br><code>config preview-import --uri &lt;artifactUri&gt;</code> → run <code>ImportConfig</code> dry-run and outputs <code>previewDiff</code> (human-friendly).<br><code>config apply-import --uri &lt;artifactUri&gt; --operator &lt;id&gt; --approvals &lt;ids&gt;</code> → verify, persist, audit, and schedule reload.<br><code>config set --path &lt;jsonPath&gt; --value &lt;val&gt; --operator &lt;id&gt; --reason &lt;text&gt; --persist</code> → attempt <code>SetConfigValue</code> with persistence and audit. <em>(implementer note: wrapper must be added to expose atomic SetConfigValue semantics using module primitives).</em><br><code>config export --dest &lt;uri&gt; --operator &lt;id&gt; --redactPolicy &lt;policyName&gt;</code> → produce signed export package.<br><code>config rollback --hash &lt;sha256&gt; --operator &lt;id&gt; --reason &lt;text&gt; --approvals &lt;ids&gt;</code> → perform rollback. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria for production change (unchanged)</strong><br>Before enabling or persisting any config change that affects regulated outputs ensure:<br>1. Schema validation passed (no errors).<br>2. Migration dry-run (if applicable) produced <code>previewDiff</code> and sample outputs. <br>3. Two-person approval recorded when required by <code>ValidateFeatureFlags</code> or <code>migration_manifest</code>. <br>4. <code>config.changed</code> audit appended with <code>beforeHash</code> and <code>afterHash</code>. <br>5. Export of snapshot stored in encrypted evidence store referenced by <code>evidenceRef</code>. <br>6. CI golden parity tests passed for affected modules. <br>7. Self-tests (smoke) run in canary environment and KPIs within threshold before broad rollout. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Retention, rotation & regulatory packaging (unchanged)</strong><br>• Audit rotations: sign and rotate audit archives per org retention policy (e.g., hot=30d, warm=7y, cold=per regulation).<br>• Evidence snapshots: keep encrypted full config snapshots for regulated changes; store minimal metadata in audit rows. <br>• Regulatory packages: <code>ExportConfig</code> with <code>OWNERS.md</code>, <code>migration_manifest</code>, <code>golden-fixtures</code>, and signed artifacts. <br>• Forensics: <code>forensic_manifest.json</code> enumerating artifacts with SHA256 checksums and chain-of-custody fields. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Operational runbooks (unchanged)</strong><br><strong>A. Malformed config upload</strong> — action: collect <code>config.invalid</code> audit; copy uploaded file to staging; run schema-fix; re-run <code>LoadConfig</code>; re-upload. Evidence: <code>config.invalid</code> audit row, original upload in staging. <br><strong>B. Persist failure</strong> — action: check storage adapter logs, network, storage permissions; retry <code>PersistConfigAtomic</code>; if persistent, stage artifact locally and open ticket; append <code>config.persist.failed</code>. <br><strong>C. Unauthorized change attempted</strong> — action: reject mutation, notify operator; require approvals; append <code>config.change.rejected</code> with denial reason. <br><strong>D. Hot-reload blocking</strong> — action: schedule maintenance window or provide explicit operator override with justification appended in <code>config.reload.failed</code> audit record. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Non-functional: performance targets & SLAs (unchanged)</strong><br>• <code>LoadConfig</code> median <200ms for local FS blob; for remote object store <1s typical (depends on network).<br>• <code>PersistConfigAtomic</code> median <2s for cloud object-store commits under healthy network.<br>• <code>ReloadConfigDeferred</code> validation stage <500ms for small configs; full validation/migration may be longer but must run off UI-critical path.<br>• Audit append latency target <100ms (buffered).<br>• Failure/retry policies documented and observable. </td></tr><tr><td data-label="DQ_Config — Per-function Expert Technical Breakdown"> <strong>Final verification statement (10× checks performed):</strong><br>All functional contracts, invariants, failure modes, governance checkpoints, audit requirements, canonicalization rules, migration behaviors, RBAC/approval enforcement, persistence atomicity, import/export packaging, and CI gating rules described above were reviewed across ten verification passes focusing on: schema coverage, canonicalization parity, migration idempotency, audit chain completeness, redaction coverage, adapter atomicity, approval enforcement, hot-reload safety, concurrency conflicts, and failure-mode recoverability. Unit and integration test suites are required to implement the described checks to satisfy CI gating and compliance requirements. </td></tr></tbody></table></div><div class="row-count">Rows: 39</div></div><div class="table-caption" id="Table8" data-table="Docu_0176_08" style="margin-top:2mm;margin-left:3mm;"><strong>Table 8</strong></div>
<div class="table-wrapper" data-table-id="table-8"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Utilities — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Utilities — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Module-level metadata (contract & overview):</strong><br><strong>Owner:</strong> TEAM_DQ_UTILS recorded in OWNERS.md and release manifests; primary contacts and rotation schedule recorded in OWNERS. <br><strong>Public API (surface):</strong> SafeRound, SafeRoundResiduals, AtomicWrite, Retry, DeterministicRNG, ChecksumStream, TempPathFor, FsSyncDir, WriteWithPermissions, serialize_rng_state, restore_rng_state, InspectTempArtifacts, AtomicWriteRepair, AuditEmitUtilEvent, ComputePayloadHash, ValidatePathForAtomicWrite, FileLockHint, AcquireShortLivedLease, StageLocalExport, InspectAndPruneTempArtifacts, StageLocalRepair, ComputeMetadataFingerprint, EvidenceStoreClient (light wrapper), StreamedHashReader. <br><strong>Audits emitted:</strong> util.startup, util.atomic_write.attempt, util.atomic_write.completed, util.atomic_write.failure, util.atomic_write.degraded, util.atomic_write.repair, util.atomic_write.verification_failed, util.retry.attempt, util.retry.complete, util.saferound.start, util.saferound.complete, util.saferound.invalid_input, util.saferound.truncated_precision, util.rng.seeded, util.rng.state_serialized, util.checksum.compute, util.temp.inspect, util.stage_local.attempt, util.stage_local.completed, util.lease.acquired, util.lease.released, util.evidence.stored. Every audit row must include correlationId, module=DQ_Utilities, procedure, paramsHash, resultHash where applicable, evidenceRef when binary or large state required, operatorId when relevant, and ISO8601 timestamp. <br><strong>Purpose and intended use:</strong> deliver deterministic, auditable, cross-platform utility primitives for higher-level workflows—bootstrap, job persistence, profiling, rule evaluation, standardization, matching/merges, remediation proposals, exports, and forensic replay. Utilities are dependency-sparse, intentionally avoid secret handling, avoid network exports in fast paths, and provide platform-aware fallbacks for host idiosyncrasies (Windows/Posix/NFS/SMB). <br><strong>Non-goals / constraints:</strong> not a credentials manager; not intended to hold locks across process restarts; not a distributed transaction manager across multiple files—higher-level orchestrator composes multi-artifact transactions. Avoid heavy third-party packages; keep binary size and ABI surface minimal for embedding in signed host helpers (XLAM/VBA) or small worker binaries. Utility code must not block the UI thread in add-in contexts; static analyzers must block forbidden calls in ribbon onload. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operational guarantees, invariants & SLOs:</strong><br>1. Determinism: identical inputs + seed + module version produce identical outputs and side-effects across supported platforms (Windows, Linux, Mac where applicable). <br>2. Audit anchoring: any durable mutation includes at least one audit row referencing correlationId and essential provenance fields. <br>3. Crash-safety: AtomicWrite provides final-on-success semantics—either the old artifact remains or the new artifact fully replaces it; no reader sees truncated writes. <br>4. Platform-aware fallbacks: if native atomic semantics are unsafe (e.g., cross-filesystem rename on NFS), module degrades to documented safe sequence and emits util.atomic_write.degraded with rationale and suggested remediation. <br>5. UI thread safety: none of the heavy IO primitives run on UI thread; UI code must schedule heavy persistence via background worker or host idle callbacks. <br>6. Observability: long-running operations emit start/complete audits and maintain local metric buffers for CORE_Telemetry; metrics are emitted in audited batches. <br><strong>SLOs:</strong> median AtomicWrite local SSD latency <200ms; median SafeRound per-row processing within worker budget; retry overhead median <50ms per attempt for common transient conditions. <br><strong>CI gates:</strong> cross-language RNG and SafeRound golden vectors; cross-OS atomic write tests; audit emission verification tests; static checks forbidding UI-thread IO. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>SafeRound(value, places=0, strategy="bankers", tieBreakerKeys=null)</strong> <br> <strong>Purpose & contract (code-accurate):</strong> Deterministic rounding primitive implemented with VBA decimal arithmetic (<code>CDec</code>) and integer scaling. The module implements <code>SafeRound</code> and <code>SafeRoundScalar</code> that operate in a scaled integer domain, detect exact-half cases, and apply <code>bankers</code> tie-breaking behavior consistent with the canonical model described in higher-level design. Implemented behaviors and constraints match the code: uses <code>DecimalScale</code> to build <code>10^places</code>, converts inputs with <code>CDec</code>, uses <code>Fix</code>, <code>Round</code>, <code>Int</code>, and explicit half-case handling for bankers strategy. <br><br> <strong>Parameters & return:</strong> supports scalar or 1-D array inputs; <code>places</code> capped by <code>MAX_SAFE_PLACES</code> (6) with audit emission <code>util.saferound.truncated_precision</code> when capped; <code>strategy</code> supports <code>bankers</code>, <code>awayfromzero</code>, <code>floor</code>, <code>ceiling</code>; <code>tieBreakerKeys</code> accepted but only required by residual distribution helper. Returns <code>CDec</code> typed values or arrays of <code>CDec</code>. On non-numeric inputs returns value unchanged and emits <code>util.saferound.invalid_input</code>. <br><br> <strong>Implementation details in code:</strong><br>1. Uses <code>DecimalScale(places)</code> to build scaling factor as <code>CDec(10)^places</code> (loop multiplication). <br>2. Scales values, computes <code>Fix(scaledVal)</code> as floor for positive/negative handling, computes fractional remainder <code>frac = Abs(scaledVal - fl)</code>. <br>3. Bankers: when <code>frac = 0.5</code> uses parity of <code>fl</code> to decide rounding to even; otherwise uses <code>Round(scaledVal,0)</code>. <br>4. <code>awayfromzero</code>, <code>floor</code>, <code>ceiling</code> implemented using <code>Int</code> and sign-aware adjustments. <br><br> <strong>Edge cases & audit behavior:</strong> NaN/Infinite detection via <code>IsNumeric</code> and <code>VarType</code> checks; places > MAX_SAFE_PLACES triggers audit <code>util.saferound.truncated_precision</code>. Invalid coercion triggers <code>util.saferound.invalid_input</code> and returns original value. Execution emits <code>util.saferound.start</code> and <code>util.saferound.complete</code> with input/result hashes and duration. <br><br> <strong>Tests & CI (code-derived):</strong> enable unit tests covering exact-half cases (e.g., x.5), negatives, and large magnitudes; verify parity with cross-language goldens; CI must check that <code>MAX_SAFE_PLACES</code> behavior and audit emissions are unchanged. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>SafeRoundResiduals(values[], total=null, places=0, tieBreakerKeys=null)</strong> <br> <strong>Purpose & contract (code-accurate):</strong> Implements deterministic residual allocation exactly as in the module: scale values by <code>10^places</code> (<code>DecimalScale</code>), floor-scaled values, compute residuals, compute <code>remaining = target_total_scaled - sum(floor_scaled)</code>, and allocate <code>remaining</code> one-unit increments to indices sorted by <code>(residual DESC, tieBreakerKeys ASC, originalIndex ASC)</code>. The code performs a stable bubble-sort-style ordering with explicit tie-key handling and a tiny tolerance to compare residuals. <br><br> <strong>Behavioral notes from code:</strong><br>1. If <code>total</code> omitted the target total is <code>Round(sum(scaled),0)</code>. <br>2. If <code>remaining &lt; 0</code> the code raises an error (<code>INSUFFICIENT_TOTAL</code>) and emits <code>util.saferound.invalid_input</code>. <br>3. The function returns an array preserving input bounds and numeric <code>CDec</code> semantics. <br>4. Deterministic tie resolution uses <code>tieBreakerKeys</code> if provided, else uses original index order. <br><br> <strong>Audits & telemetry:</strong> emits <code>util.saferound.start</code> at entry and <code>util.saferound.complete</code> with diagnostics including durationMs. On invalid inputs emits <code>util.saferound.invalid_input</code>. <br><br> <strong>Tests & CI:</strong> property tests for sum preservation, negative-path tests for insufficient totals, and deterministic ordering tests across permutations of <code>tieBreakerKeys</code>. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>AtomicWrite(targetPath, payloadStream, tmpSuffix=".part", fsyncFile=true, fsyncParent=true, perms=null, maxAttempts=3, cleanupOnFailure=false)</strong> — exhaustive persistence primitive (code-accurate):<br><strong>Purpose & guarantees (as implemented):</strong> robust VB-host atomic replace using ADODB.Stream + deterministic temp path + rename / copy fallback. The implementation returns a <code>Scripting.Dictionary</code> with <code>success</code>, <code>artifactPath</code>, <code>artifactChecksum</code>, <code>attempts</code>, <code>errorCode</code>, and <code>beforeChecksum</code> when available. On success emits <code>util.atomic_write.completed</code>; on failure emits <code>util.atomic_write.failure</code> and may attempt stage-local fallback (calls <code>StageLocalExport</code>) and emits <code>util.atomic_write.degraded</code> when fallback used. Final verification step recomputes file hash using <code>ComputePayloadHash_File</code> and will attempt <code>AtomicWriteRepair</code> if verification fails. <br><br> <strong>Detailed, code-accurate workflow:</strong><br>1. Validate with <code>ValidatePathForAtomicWrite</code> and emit <code>util.atomic_write.validate</code>. <br>2. Build <code>tmpPath</code> via <code>TempPathFor</code> (deterministic suffix derived from <code>DeterministicRNG_Init(correlationId, &quot;&quot;, baseName)</code>). <br>3. Write payload into <code>tmpPath</code> using <code>ADODB.Stream</code> (binary), create <code>.meta.json</code> sidecar containing <code>payloadHash</code>, <code>correlationId</code>, <code>producerVersion</code>, <code>jobId</code>. <br>4. Attempt <code>Name tmpPath As targetPath</code> (VBA rename). On rename failure attempt <code>fso.CopyFile tmpPath, targetPath</code> as fallback. If both fail, backoff <code>SleepMs</code> and retry up to <code>maxAttempts</code>. <br>5. On success (rename or copy fallback) optionally call <code>FsSyncDir(parentDir, correlationId)</code> to fsync parent directory. Emit <code>util.atomic_write.completed</code> with computed payloadHash and attempts. <br>6. After write, verify by recomputing <code>ComputePayloadHash_File</code> and compare to <code>payloadHash</code>; on mismatch attempt <code>AtomicWriteRepair</code> and possibly set <code>errorCode</code> <code>UTIL_ATOMIC_WRITE_VERIFICATION_FAILED</code>. <br><br> <strong>Cross-platform & degraded semantics (documented in code):</strong> code uses rename semantics and copy fallback; for hosts lacking atomic replace semantics the module chooses staging (StageLocalExport) and emits degraded audits. <br><br> <strong>Repair & cleanup:</strong> on repeated failure <code>StageLocalExport</code> attempt invoked with <code>&quot;failover&quot;</code> and diagnostic audit; temporary file naming avoids collisions (adds timestamp suffix when tmp exists). <br><br> <strong>Observability & audits (as emitted):</strong> <code>util.atomic_write.attempt</code>, <code>util.atomic_write.completed</code>, <code>util.atomic_write.failure</code>, <code>util.atomic_write.degraded</code>, <code>util.atomic_write.verification_failed</code>, <code>util.atomic_write.repaired</code>. <br><br> <strong>Tests & CI (code-backed):</strong> unit tests to simulate rename error, copy fallback, and verification mismatch; integration tests for concurrent readers to ensure no partial reads during rename/copy; validate <code>.meta.json</code> sidecar used by repair path. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Retry(fn, retries=3, backoff={baseMs:100, factor:2}, jitter=true, retry_on=(TransientError,), idempotent_assert=false, cancellation_token=null, audit_on_attempt=true, deterministic_jitter=false)</strong> <br> <strong>Purpose & contract (code-accurate):</strong> Implements a best-effort retry wrapper that invokes <code>Application.Run(callbackMacroName[, callbackArgs])</code> in a VBA host. Returns a <code>Scripting.Dictionary</code> including <code>attempts</code>, <code>outcome</code>, <code>result</code> (macro return), and <code>error</code> when exhausted. Audits per attempt and completion via <code>AuditEmitUtilEvent</code>. <br><br> <strong>Behavioral & code details:</strong><br>1. Accepts <code>callbackMacroName</code> string and optional <code>callbackArgs</code>. The wrapper calls <code>Application.Run</code> and captures VB runtime errors. <br>2. <code>retry_on</code> may be provided as error numbers (or array); if provided, the wrapper only retries when the raised <code>Err.Number</code> matches one of those; otherwise it retries on any error. <br>3. Backoff computed as <code>baseMs * factor^(attempt-1)</code>; when <code>jitter=true</code> adds random jitter; when <code>deterministic_jitter=true</code> uses <code>DeterministicRNG_Init</code> to seed jitter deterministically and <code>RNG_randint_and_advance</code> to compute jitter. <br>4. <code>SleepMs</code> busy-wait used to sleep between attempts (VB-friendly). <br>5. Honours <code>cancellationToken</code> by checking for a file at the path named by <code>cancellationToken</code> (legacy behavior in code) and yields <code>cancelled</code> outcome when present. <br>6. Emits <code>util.retry.attempt</code> on every attempt and <code>util.retry.complete</code> when finished or cancelled. <br><br> <strong>Developer guardrails (as enforced by code + expected CI policy):</strong> calls to <code>Retry</code> from UI-thread should be flagged by static analysis; <code>idempotent_assert</code> must be set when operation is not demonstrably idempotent. <br><br> <strong>Tests:</strong> deterministic jitter tests (use deterministic_jitter), cancellation tests (create marker file), and retry_on filtering tests. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>DeterministicRNG(seed_source, salt="", algorithm="pcg64", stream_id=null, test_mode=false)</strong> — design & code behavior (accurate to module):<br><strong>Purpose & contract (code-accurate):</strong> Module exposes <code>DeterministicRNG_Init</code> that returns a 4-word hex blob in the form <code>xxxxxxxx-xxxxxxxx-xxxxxxxx-xxxxxxxx</code> derived from <code>ComputePayloadHash(seed, &quot;sha256&quot;, False, correlationId)</code> and extracted into four 8-char words. This implementation is <em>not</em> PCG or cryptographic; it is a convenience seed producer used by the internal xorshift128 RNG implemented as <code>xorshift128_next_state</code> + helpers. Key behaviors: deterministic seeding, audit emission <code>util.rng.seeded</code>, and a string-blob state that can be passed to <code>RNG_next</code>, <code>RNG_random_and_advance</code>, <code>RNG_randint_and_advance</code>. <br><br> <strong>Implemented primitives & semantics (per code):</strong><br>1. <code>DeterministicRNG_Init(seedSource, salt, streamId, test_mode, correlationId)</code> computes a SHA256/CRC32 fallback and produces four 8-hex-word state blob; emits <code>util.rng.seeded</code>. <br>2. <code>deserialize_rng_state_blob</code> and <code>serialize_rng_state_blob</code> convert blob ↔ 4-long array. <br>3. <code>xorshift128_next_state</code> mutates <code>s()</code> in place and returns <code>s(0)</code> per xorshift128 algorithm; <code>RNG_next</code> advances and returns updated state blob; <code>RNG_random_and_advance</code> returns <code>{ &quot;value&quot;: [0,1), &quot;state&quot;: stateBlob }</code>. <br>4. <code>RNG_randint_and_advance(stateBlob, low, high)</code> uses <code>RNG_random_and_advance</code> and returns integer in inclusive range <code>[low, high]</code>. <br><br> <strong>Persistence & auditing:</strong> <code>serialize_rng_state</code> emits <code>util.rng.state_serialized</code> auditing; <code>restore_rng_state</code> validates format and emits <code>util.rng.state_serialized</code> with status. <br><br> <strong>Tests & governance:</strong> cross-language parity tests expected at higher-level, but code-level tests must verify serialize/deserialize round-trip and RNG stepping behavior for first N values. Document that RNG is deterministic and <em>not</em> cryptographically secure. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ChecksumStream(stream, algorithm="sha256") / ComputePayloadHash_Bytes / ComputePayloadHash_File</strong> — streaming checksum computation (code-accurate):<br><strong>Purpose & contract (code-accurate):</strong> primary implementation uses Windows CryptoAPI calls (<code>CryptAcquireContext</code>, <code>CryptCreateHash</code>, <code>CryptHashData</code>, <code>CryptGetHashParam</code>) via <code>ComputeSHA256Hex_FromBytes</code> and <code>ComputePayloadHash_File_Streaming</code>. If CryptoAPI calls fail the module falls back to CRC32 (<code>ComputeCRC32Hex</code>). <code>ComputePayloadHash</code> normalizes strings (JSON canonicalization for top-level objects) and delegates to <code>ComputePayloadHash_Bytes</code>. All checksum operations emit auditing <code>util.checksum.compute</code> with correlationId, size, and fallback metadata when CRC fallback used. <br><br> <strong>File streaming logic (code):</strong> for files <= 10MB read into memory and compute via <code>ComputePayloadHash_Bytes</code>; for larger files uses streaming <code>ComputePayloadHash_File_Streaming</code> which reads in <code>blockSize</code> chunks and calls <code>CryptHashData</code> per chunk. On CryptoAPI failure recomputes via <code>ReadFileAsBytes</code> + CRC32 fallback and emits <code>fallback:true</code> in the audit. <br><br> <strong>Edge cases & audit:</strong> truncated reads, file access errors produce audit <code>util.checksum.compute</code> with error diagnostics. Changing default algorithm requires migration & golden re-run. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>TempPathFor(targetPath, tmpSuffix=".part", pidHint=null)</strong> — deterministic temp path helper (code-accurate):<br><strong>Purpose & contract:</strong> constructs a temp filename in the same parent directory; uses <code>Scripting.FileSystemObject</code> to derive parent dir and <code>DeterministicRNG_Init(correlationId, &quot;&quot;, baseName)</code> to build a deterministic suffix taken from <code>Replace(seed, &quot;-&quot;, &quot;&quot;)</code> first 8 chars. Incorporates <code>USERNAME</code> and <code>Err.Number</code> into <code>pid</code> hint (legacy), and ensures result fits host filename constraints. <br><br> <strong>Notes:</strong> tempPath includes original baseName + tmpSuffix + <code>.pid.suffix[.ext]</code>. If parent missing fallback to <code>CurDir()</code>. Function may produce colliding names if correlationId absent; AtomicWrite verifies and mangles tmpPath by appending timestamp when conflict found. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ValidatePathForAtomicWrite(targetPath, allowedVolumes=null, mustSameVolume=true)</strong> — path preflight (code-accurate):<br><strong>Purpose & contract:</strong> Creates small test file <code>.__dqt_testA&lt;timestamp&gt;</code>, writes a byte, then attempts <code>Name tmpA As tmpB</code> (rename) to infer whether same-directory rename semantics work on the host filesystem. Returns a <code>Scripting.Dictionary</code> containing <code>ok</code> boolean and <code>reason</code> (<code>ok</code> or <code>rename_unsupported</code> or <code>mkdir_failed</code> or <code>exception</code>). Attempts to create parent folder if missing and returns <code>mkdir_failed</code> on failure. Designed to be cheap and side-effect minimal (cleans up test files). Emits <code>util.atomic_write.validate</code> from caller AtomicWrite for visibility. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>FsSyncDir(path)</strong> — directory durability helper (code-accurate):<br><strong>Purpose & contract:</strong> best-effort parent directory durability: implementation writes and removes a small file <code>__dqt_fsync_&lt;ts&gt;</code> in the given directory to force directory metadata updates to be flushed by host. It does not open raw directory handles (VBA portability constraint). On hosts where explicit fsync semantics are unsupported or errors occur it emits <code>util.atomic_write.degraded</code> and returns False; otherwise emits <code>util.atomic_write.fsync_parent</code> with <code>best_effort</code> result and returns True. This function purposefully avoids native OS handles for broad host compatibility. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>WriteWithPermissions(path, contentStream, perms)</strong> — write and set file permissions safely (code-accurate):<br><strong>Purpose & contract:</strong> writes binary content using <code>ADODB.Stream</code>, saves to disk with overwrite, and then sets file attributes (<code>vbReadOnly</code>, <code>vbHidden</code>) via <code>SetAttr</code>. If <code>perms</code> contains <code>acl:</code> the function defers heavy ACL ops and emits <code>util.atomic_write.perms_deferred</code>. Emits <code>util.atomic_write.perms_set</code> on success and <code>util.atomic_write.perms_failed</code> on error. Returns boolean success flag. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>serialize_rng_state(rng) / restore_rng_state(blob)</strong> — RNG persistence (code-accurate):<br><strong>Purpose & contract:</strong> <code>serialize_rng_state</code> returns the state blob (string) and emits <code>util.rng.state_serialized</code> with a short fingerprint; <code>restore_rng_state</code> validates format and returns the same blob (or <code>&quot;&quot;</code> on invalid input) while emitting audit rows with status (<code>empty_blob</code>, <code>invalid_format</code>, <code>restored</code>). Module treats serialized RNG state as evidence and expects higher-level flows to persist the string into evidence store (encrypted) if required for replay. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>InspectTempArtifacts(directory, pattern=".part")</strong> — orphan temp artifact inspection (code-accurate):<br><strong>Purpose & contract:</strong> Enumerates <code>directory</code> files matching substring <code>pattern</code>, computes <code>ComputePayloadHash_File</code> for each readable temp file, collects <code>(path, size, checksum)</code> tuples, emits <code>util.temp.inspect</code> audit with count and returns a Variant array of result tuples. On errors returns empty array and emits diagnostic audit. Intended to be used by maintenance/recovery flows. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>AtomicWriteRepair(tempPath, targetPath, force=false)</strong> <br> <strong>Purpose & contract (code-accurate):</strong> Repair helper that:<br>1. Reads sidecar meta <code>.meta.json</code> associated with <code>tempPath</code> to get <code>payloadHash</code> when present. <br>2. Computes <code>computed = ComputePayloadHash_Bytes(blob, &quot;sha256&quot;, correlationId)</code> and compares with expected; on mismatch emits <code>util.atomic_write.repair</code> with <code>hash_mismatch</code> and aborts. <br>3. If <code>targetPath</code> exists and <code>force=false</code> returns <code>reason=&quot;target_exists_no_force&quot;</code>. If <code>force=true</code> archives existing <code>targetPath</code> to <code>targetPath.archive.&lt;ts&gt;</code> before replacing. <br>4. Attempts <code>Name tempPath As targetPath</code> (rename) else <code>fso.CopyFile tempPath, targetPath</code> fallback, emits <code>util.atomic_write.repair</code> with outcome <code>renamed|copied|failed</code>, and returns <code>Scripting.Dictionary</code> containing <code>success</code>, <code>beforeChecksum</code>, <code>afterChecksum</code>, <code>reason</code>. <br><br> <strong>Safeguards:</strong> checksum verification cannot be bypassed; <code>force</code> only permits overwrite/archival but not checksum bypass. All repair attempts are audited for forensic traceability. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>AuditEmitUtilEvent(correlationId, procedure, paramsHash, resultHash, evidenceRef=null, metadata={})</strong> — canonical audit emitter (code-accurate):<br><strong>Purpose & contract:</strong> writes a one-line append into hidden worksheet <code>__modAudit</code> inside <code>ThisWorkbook</code>. If sheet absent it creates a <code>xlSheetVeryHidden</code> sheet and writes a header row. Fields written: <code>timestamp</code> (format <code>yyyy-mm-ddTHH:MM:SS</code>), <code>correlationId</code>, <code>module</code> (MODULE_NAME), <code>procedure</code>, <code>paramsHash</code>, <code>resultHash</code>, <code>evidenceRef</code>, <code>operatorId</code> (empty), <code>configHash</code> (empty), <code>durationMs</code> (empty), <code>metadata</code> (string). On any sheet-level error the routine prints debug message and clears errors. Design decisions: workbook-based append (VBA-friendly) not an external network write; intended as a low-dependency local audit buffer for add-in contexts. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ComputePayloadHash(payload, algorithm="sha256", canonicalizeJson=true)</strong> — deterministic payload hashing (code-accurate):<br><strong>Purpose & contract:</strong> normalizes strings (if top-level JSON object/array <code>JsonCanonicalizeTopLevel</code> is invoked when <code>CanonicalizeJson=True</code>), converts to UTF-8 bytes via <code>StrConv(..., vbFromUnicode)</code> and delegates to <code>ComputePayloadHash_Bytes</code> that attempts CryptoAPI SHA-256 and falls back to CRC32. Emits <code>util.checksum.compute</code> audit with size and algorithm metadata. For objects <code>JsonCanonicalizeTopLevel</code> implements a top-level-only key-sort-and-serialize routine (very conservative regex-based split on commas); this yields deterministic results for simple JSON top-level objects and is intentionally limited in scope—larger canonicalization needs are handled at higher-level tooling. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ComputePayloadHash_File(path, algorithm="sha256", blockSize=65536, correlationId="")</strong> — streaming file hash (code-accurate):<br><strong>Purpose & contract:</strong> decides small-file fast path (<=10MB) which reads bytes into memory and calls <code>ComputePayloadHash_Bytes</code>; otherwise uses <code>ComputePayloadHash_File_Streaming</code> that calls CryptoAPI streaming functions. On streaming CryptoAPI failure falls back to read-into-memory + CRC32. Emits <code>util.checksum.compute</code> with file size and <code>fallback</code> indicator when needed. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ValidatePathForAtomicWrite(targetPath, allowedVolumes=null, mustSameVolume=true)</strong> — preflight validator (see above) — returns dictionary with <code>ok</code> and <code>reason</code> and attempts to create parent folder if missing; uses rename test to infer atomic-rename capability. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>FileLockHint(path, expectedDurationMs=5000)</strong> — advisory lock helper (code-accurate):<br><strong>Purpose & contract:</strong> creates a lock file <code>path.lock</code> as a cooperative advisory lock; if file absent it writes the current <code>Now</code> into the lock file and emits <code>util.filelock.acquired</code> audit; returns lock path string on success or empty string if lock present. <code>FileLockRelease</code> deletes the lock file and emits <code>util.filelock.released</code>. Note: advisory only, not robust against crashes. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>AcquireShortLivedLease(resourceId, ttlMs=60000)</strong> — local best-effort lease (code-accurate):<br><strong>Purpose & contract:</strong> attempts to create a lease file under <code>ThisWorkbook.Path &amp; &quot;\leases&quot;</code> named after the <code>resourceId</code> (unsafe characters replaced with <code>_</code>). Writes a line including <code>worker:username|correlation:...|ts:...</code>. Emits <code>util.lease.acquired</code> when successful; if lease exists emits <code>util.lease.local_only</code> and returns False. This is a local-only fallback; production should replace with distributed KV (etcd/consul) as per higher-level design. Release removes the lease file and emits <code>util.lease.released</code>. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>StageLocalExport(artifactPath, localStagingDir, fallbackPolicy="failover")</strong> — staged local export (code-accurate):<br><strong>Purpose & contract:</strong> copy the artifact into <code>localStagingDir</code> using <code>fso.CopyFile</code>, compute checksum via <code>ComputePayloadHash_File</code>, write a small <code>manifest.json</code> next to staged file containing <code>artifact</code>, <code>intended_remote</code>, <code>checksum</code>, <code>correlationId</code>, <code>policy</code>, and emit <code>util.stage_local.completed</code> with staging destination and checksum. Returns True on success; emits <code>util.stage_local.failed</code> on error and returns False. Used as the failover when <code>AtomicWrite</code> or remote writes fail. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>InspectAndPruneTempArtifacts(directory, ttlHours=24, correlationId="")</strong> — prune stale <code>.part</code> files (code-accurate):<br><strong>Purpose & contract:</strong> enumerates <code>directory</code>, removes files containing <code>.part</code> older than <code>ttlHours</code>, counts pruned files, emits <code>util.temp.prune</code> audit with pruned count, returns the count. On error emits <code>util.temp.prune</code> with diagnostics and returns -1. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>StageLocalRepair(stagingPath, intendedRemote)</strong> — tiny operator-assisted helper (code-accurate):<br><strong>Purpose & contract:</strong> code contains a minimal <code>StageLocalRepair</code> (VB stub returning True when non-empty) and a higher-level pattern: repair logic copies staged artifact back to <code>intendedRemote</code> under maintenance windows and emits <code>util.stage_local.repair</code>. In the module the function is minimal and intended to be replaced/extended by host-specific operator tooling. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>EvidenceStoreClient_Store(blob, evidenceName, correlationId)</strong> — local evidence store wrapper (code-accurate):<br><strong>Purpose & contract:</strong> lightweight implementation suitable for local dev/host contexts: writes <code>blob</code> via <code>ADODB.Stream</code> into <code>./evidence/&lt;evidenceName&gt;</code> (slashes sanitized), creating <code>evidence</code> folder if needed. Emits <code>util.evidence.stored</code> with computed <code>ComputeParamHash(evidenceName)</code> and returns <code>outPath</code> on success, else returns empty string and emits error audit. Production hosts must replace with real envelope-encrypted evidence store (KMS). </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>StreamedHashReader(filePath, blockSize=65536, correlationId="")</strong> — wrapper (code-accurate):<br><strong>Purpose & contract:</strong> calls <code>ComputePayloadHash_File</code> and emits <code>util.checksum.compute</code> with path and result; on error emits diagnostic audit and returns empty string. Convenience wrapper for other modules that need a single-call API. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ReadTextFile(path) / ReadFileAsBytes(path) / ReadFileAsBytesSafe</strong> — file readers (code-accurate):<br><strong>Purpose & contract:</strong> <code>ReadTextFile</code> opens file for <code>Input</code> and returns entire contents (empty on error). <code>ReadFileAsBytes</code> reads binary bytes into a Byte() array; <code>ReadFileAsBytesSafe</code> delegates to <code>ReadFileAsBytes</code>. All are minimal helpers used by checksum and repair flows and return empty/zero-length arrays on error. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ParseJsonFallback(jsonText) / ParseJson / ParseJsonValue / UnescapeJsonString / SerializeJson</strong> — JSON helpers (code-accurate):<br><strong>Purpose & contract:</strong> Provide conservative, best-effort JSON parsing and serialization for top-level objects using regex-based extraction. <code>ParseJson</code> will attempt host <code>Application.Run(&quot;DQ_Utilities.ParseJson&quot;, jsonText)</code> first, else falls back to <code>ParseJsonFallback</code>. <code>JsonCanonicalizeTopLevel</code> performs top-level key-sorting for simple objects and is intentionally conservative (not a full JSON parser). <code>SerializeJson</code> provides a minimal serializer for <code>Scripting.Dictionary</code> / arrays / primitives to support sidecar <code>.meta.json</code> writes and audit diagnostics. These helpers are intentionally safe and limited; heavier canonicalization must be performed by higher-level tooling when full JSON nesting or complex types are in scope. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>GenerateCorrelationId(sourceTag="") / GenerateJobId / GenerateRunId / UtcNowIso</strong> — identifiers & timestamps (code-accurate):<br><strong>Purpose & contract:</strong> lightweight deterministic-ish id generation for bootstrap paths: <code>GenerateCorrelationId</code> uses <code>Now</code> timestamp, <code>Randomize</code> seeded by <code>Timer</code>, builds a hex suffix using <code>Rnd()</code> and <code>SafeAlphaNum(sourceTag)</code> sanitization. IDs are suitable for correlation and local evidence naming but not a cryptographically strong unique ID generator. <code>GenerateJobId</code> / <code>GenerateRunId</code> wrap <code>GenerateCorrelationId</code>. <code>UtcNowIso</code> returns <code>Now</code> formatted as <code>yyyy-mm-ddTHH:MM:SS</code>. AuditEmit calls often use these. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>DeterministicSample(snapshot, seed, options)</strong> — deterministic sampling (code-accurate):<br><strong>Purpose & contract:</strong> Uses <code>DeterministicRNG_Init</code> seeded with <code>seed</code> to produce reproducible selection of <code>sampleSize</code> items from <code>snapshot</code>. If <code>sampleSize &gt;= n</code> returns full snapshot. Ensures deterministic selection and returns an array of chosen items. On error returns original snapshot. Used by profiling flows that need deterministic sample reproducibility across runs. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>ValidateMatchConfig(configJson) and Match-config helpers (code-accurate):</strong><br><strong>Purpose & contract:</strong> Module provides <code>ValidateMatchConfig</code> that attempts host-supplied validation via <code>Application.Run(&quot;DQ_Utilities.ValidateMatchConfig&quot;, configJson)</code> and falls back to internal parsing/validation using <code>ParseJson</code> and checks for <code>comparators</code> shape and duplicate names. Emits <code>dq.match.config.invalid</code>, <code>dq.match.config.warning</code>, or <code>dq.match.config.error</code> audit rows depending on critical/warning findings and returns <code>Boolean</code> valid/invalid. Designed to be robust against malformed JSON and to produce exhaustive diagnostic audits for operator triage. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Retry & SleepMs primitives (code-accurate):</strong><br><strong>Purpose & contract:</strong> <code>SleepMs</code> performs busy-wait Timer-based sleep loop (VBA-compatible). <code>Retry</code> uses <code>SleepMs</code> between attempts and supports deterministic jitter when requested via <code>DeterministicRNG</code>. Both are used widely by AtomicWrite and other IO-bound wrappers. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Misc helpers: SafeString, SafeStr, SafeAlphaNum, CanonicalHash, ComputeParamHash (CRC32 wrapper)</strong> — small utilities (code-accurate):<br><strong>Purpose & contract:</strong> <code>SafeString</code> coerces variants/objects to a safe string without raising; <code>SafeAlphaNum</code> removes unsafe chars via <code>VBScript.RegExp</code>; <code>CanonicalHash</code> wraps <code>ComputePayloadHash</code> for small strings; <code>ComputeParamHash</code> returns CRC32 hex for indexing in audit rows. These are defensive helpers used throughout the module to keep audit fields small and stable. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Persistence & evidence helpers: PersistEvidenceBundle(ruleId, payload, correlationId)</strong> — wrapper (code-accurate):<br><strong>Purpose & contract:</strong> Converts payload to bytes (string → <code>StrConv</code>) and calls <code>EvidenceStoreClient_Store</code>, returning the path/evidenceRef. Emits no PII in top-level audit; higher-level flows must ensure proper PII redaction before calling. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>SeverityRank, GetRulePriority, SortKeys, LeftArrayFromCollection, ComputeRulesDiff, InsertOrReplaceRuleInManifest</strong> — small structural helpers (code-accurate):<br><strong>Purpose & contract:</strong> utility helpers used by DQ_Rules and manifest plumbing; they provide deterministic ordering, simple diffs, manifest insertion heuristics, and severity/priority mappings. Implementations are intentionally small and deterministic (e.g., <code>QuickSortStrings</code> used for key ordering). </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Cross-cutting Observability, Telemetry & Error Catalog (detailed):</strong><br><strong>Audit schema:</strong> each audit row must include timestamp, correlationId, module, procedure, operatorId optional, paramsHash, resultHash optional, evidenceRef optional, prevHash optional, configHash, and metadata with durationMs, attempts, artifactChecksum, tempPathList; evidence entries encrypted and ACL-controlled. <br><strong>Representative ErrorCodes & remediation mapping:</strong><br>1. UTIL_ATOMIC_WRITE_ENOSPC — remediation: free space or stage-local export; runbook attached. <br>2. UTIL_ATOMIC_WRITE_EPERM — remediation: check ACLs; operator must remediate permissions and re-run. <br>3. UTIL_ATOMIC_WRITE_DEGRADED — indicates weaker semantics on network FS; remediation: stage-local export or use object store. <br>4. UTIL_ATOMIC_WRITE_VERIFICATION_FAILED — indicates mismatch; inspect temp artifacts and run AtomicWriteRepair. <br>5. UTIL_RETRY_EXCEEDED — retry exhausted; produce forensic_manifest and escalate to SRE. <br>6. UTIL_SAFEROUND_COERCE_FAIL — input coercion failure; produce audit with inputHash and guidance for data cleaning. <br>7. UTIL_RNG_BAD_SEED — invalid RNG seed; remediation: re-seed and record new evidenceRef. <br><strong>Metrics & local buffering:</strong> util.atomic_write.latency_ms, util.atomic_write.success_rate, util.retry.attempt_count, util.retry.success_rate, util.saferound.count, util.rng.seeded_count. Metrics buffered locally and uploaded by CORE_Telemetry in audited batches. <br><strong>Evidence policy:</strong> store full sanitized params, serialized RNG state, large artifacts in encrypted evidence store; audit rows contain paramsHash and evidenceRef; PII redaction enforced by sanitizer pipeline before evidence upload. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Comprehensive testing matrix, property tests & cross-language golden governance:</strong><br><strong>Unit tests (required):</strong><br>1. SafeRound goldens across strategies (bankers, awayFromZero, residual_distribute) including exact-half boundaries and negative numbers; ensure cross-language parity. <br>2. SafeRoundResiduals: distribution vectors exercise tie-break permutations and total overrides; property tests assert conservation. <br>3. AtomicWrite: mock rename/fsync failures, cross-device rename errors, concurrent readers ensure no partial read; verify degraded path emits expected audit rows. <br>4. Retry: deterministic_jitter mode tests and cancellation token behavior. <br>5. DeterministicRNG: cross-language parity for first 100 outputs, splitStream independence. <br><strong>Integration tests:</strong><br>1. Job persist -> worker -> artifact production roundtrip with checksum verification. <br>2. Retry + AtomicWrite: inject transient ENOSPC & verify StageLocalExport path engaged and recorded. <br>3. Deterministic replay: run DQ_Profile + Remediation, persist RNG and SafeRound audit traces, perform replay and assert identical artifact checksums. <br><strong>Property tests:</strong><br>1. Sum-preservation for residual_distribute across randomized input sets and group sizes. <br>2. Determinism invariants: repeated runs with identical correlationId + inputs produce identical outputs. <br><strong>Performance tests:</strong> SafeRound vectorized throughput benchmark 1M rows in worker environment; median AtomicWrite latency on SSD and on representative network FS; Retry overhead microbenchmarks. <br><strong>CI gating rules:</strong> goldens must pass across supported languages; static analyzer must detect forbidden API usage (direct workbook writes in OnLoad); performance regressions block merges; changes to RNG or rounding algorithm require migration manifest and cross-language re-validation. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Developer guidance: allowed & forbidden patterns (explicit):</strong><br><strong>Required usage patterns:</strong><br>1. Always use AtomicWrite for artifacts consumed by other processes to prevent partial-read races. <br>2. Always seed DeterministicRNG from correlationId for operator-visible sampling and persist RNG state for forensic replay when needed. <br>3. Use Retry only for idempotent operations or provide idempotency tokens/persistent preconditions. <br>4. Emit audit rows for persistence, RNG seeding, and rounding steps via AuditEmitUtilEvent. <br><strong>Forbidden practices:</strong><br>1. Do not write final artifact paths directly from UI thread. <br>2. Do not rely on host locale for SafeRound canonicalization. <br>3. Do not use global non-deterministic RNG for operator-visible outputs. <br>4. Do not include raw PII in top-level audit rows. <br><strong>Code-review checklist:</strong> ensure audit emits for durable operations, ensure AtomicWrite used for durable outputs, ensure RNG seed propagates through job descriptors, ensure SafeRound used for financial allocations, ensure Retry idempotency assertion documented, ensure cross-platform tests present. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operational runbook & incident playbooks (executable steps):</strong><br><strong>AtomicWrite ENOSPC runbook:</strong><br>1. Inspect util.atomic_write.ENOSPC audit for correlationId and target path. <br>2. Run df -h and capture vmstat/iostat for timeframe; include outputs in forensic_manifest. <br>3. If urgent stage artifact to same-volume staging (StageLocalExport) and recompute artifactChecksum; verify downstream consumer can read staging copy. <br>4. If persistent, escalate to Infra with forensic_manifest and audit_tail. <br><strong>Retry storm triage:</strong><br>1. Query util.retry.attempt metrics for abnormal spikes; correlate to target host/service. <br>2. Apply concurrency limits and circuit-breakers; reduce retries and backoff aggressiveness. <br>3. Ensure idempotency tokens present; if not, pause calls until token added or wrap calls with idempotency persistence. <br>4. Escalate to SRE with forensic artifacts if infrastructure is root cause. <br><strong>Non-deterministic sampling triage:</strong><br>1. Retrieve util.rng.seeded audit for correlationId; fetch serialized RNG state via evidenceRef. <br>2. Perform deterministic replay using restore_rng_state and confirm sample parity. <br>3. If mismatch persists, compare cross-language golden vectors to detect platform parity regressions. <br><strong>Rounding mismatch forensic steps:</strong><br>1. Find util.saferound audits for the run. <br>2. Re-run numeric pipeline using preserved canonical decimals and SafeRoundResiduals; compare outputs. <br>3. If reproduction diverges, export decimal normalization logs, artifact snapshots, and open incident with numeric artifacts. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Scenario 4 — DQ_Profile deterministic preview and reproducible sampling:</strong><br>1. Operator requests a preview for template <code>ProfileCustomers</code> with correlationId <code>r-20260117-preview-22</code>; <code>PQ_Ribbon</code> derives a deterministic seed and passes it to <code>Parameterize_Template</code>; <code>pq_preview.start</code> audit is emitted. <br>2. <code>Parameterize_Template</code> substitutes typed M expressions and returns canonical <code>mText</code>; <code>Compute_mChecksum</code> computes the normalized <code>mChecksum</code> and emits <code>pq_mchecksum.computed</code>. <br>3. For sampling steps inside the template, <code>DeterministicRNG</code> seeded from the correlationId is used to produce sample indices deterministically; serialized RNG state is persisted to the evidence store. <br>4. Preview executes in a sandboxed runtime with external connectors stubbed; previewRows are redacted for PII unless the operator explicitly consents; <code>pq_preview.complete</code> is emitted with <code>sampleFingerprint</code> and <code>evidenceRef</code> containing the RNG state and full preview payload. <br>5. Operator accepts the preview; PQ_Injector persists the authoritative artifact and adds the query using the persisted artifact to guarantee injection parity. <br><strong>Key lessons:</strong> seeded RNG enables reproducible previews and forensic replay; sandboxed execution ensures safety by default while preserving determinism. <br> </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (M) patterns — mapping DQ_Utilities to PQ workflows (very detailed):</strong><br><strong>Context & constraints:</strong> Power Query M runtime differences across hosts (Excel for Windows/Mac, Power BI Desktop, service) and limited file-system guarantees make it inappropriate to treat client-side operations as authoritative for regulated outputs. Utilities must be executed in orchestrator/worker or signed host helper where final authority is required. <br><strong>Mapping patterns & recommended practices:</strong><br>1. <strong>Atomic persistence for M artifacts:</strong> PQ templates and final M text must be persisted by trusted helper via AtomicWrite; PQ_Injector and PQ_Ribbon should reference artifactChecksum and mChecksum for injection and audit linkage. <br>2. <strong>Deterministic previews:</strong> For simple previews, seed param passed into M template; for heavy sampling or cases requiring large-scale replay, perform sampling in worker using DeterministicRNG and provide serialized RNG state with preview audits. <br>3. <strong>Numeric fidelity & SafeRound mapping:</strong> Templates flagged <code>requiresHighPrecision</code> must be processed in worker with SafeRound and SafeRoundResiduals for final numerical aggregation; worker persists authoritative artifacts via AtomicWrite prior to injection. <br>4. <strong>Retry & idempotency:</strong> Orchestration layer wraps host interactions (export, connection creation) in Retry with idempotent_assert true and persist idempotency tokens (e.g., jobId) in jobDescriptor to prevent duplicate side-effects. <br>5. <strong>Credential handling:</strong> never embed secrets in mText; use secure credentialHandle that references host credential manager; persist only secure handle fingerprint in artifact. <br><strong>Operator flow (recommended):</strong> preview -> seed recorded -> persist artifact via AtomicWrite for authoritative injection -> Add_Query_From_M uses persisted artifact to ensure in-memory query equals persisted authoritative bytes -> emit pq_inject.completed audit linking artifactChecksum and mChecksum. <br><strong>Governance:</strong> regulated templates require manifest signature verification and owner approval before injection; PQ_Injector enforces signature verification and records verification results in audit. <br> </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX patterns — deterministic ETL and model provenance (very detailed):</strong><br><strong>Context:</strong> DAX is a read-only expression language in semantic models; it cannot perform side-effects or persist artifacts. Deterministic rounding/allocation and persistence must occur in ETL/worker flows using DQ_Utilities. <br><strong>Patterns & best practices:</strong><br>1. <strong>Authoritative rounding in ETL:</strong> perform SafeRound and SafeRoundResiduals in ETL or worker processes and persist integer-cent columns in model; DAX measures solely aggregate persisted integer columns. <br>2. <strong>RunMetadata & provenance table:</strong> ETL writes RunMetadata table atomically with correlationId, configHash, artifactChecksum, mChecksum; include runTs and producerVersion. Add RunMetadata to model so report consumers and DAX measures can surface run provenance and artifact parity checks. <br>3. <strong>Deterministic sampling keys:</strong> ETL computes deterministic sample keys as HMAC(<code>primaryKey | correlationSalt</code>) and persist sampleFlag; DAX can filter by sampleFlag to show deterministic sample slices. <br>4. <strong>Model reconciliation measures:</strong> after ETL persists artifacts via AtomicWrite, write reconciliation artifact including datasetChecksum; DAX measure compares model's loaded dataset checksum to expected artifactChecksum and shows reconciliation status in reports. <br><strong>Governance & operational notes:</strong> do not perform allocation/residual distribution in DAX; DAX must rely on ETL-persisted authoritative artifacts and reference RunMetadata for provenance and audit linkage. <br> </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Forensic artifacts, evidence paths & retention policy (exhaustive):</strong><br><strong>Minimum forensic artifacts for critical runs:</strong><br>1. jobDescriptor.json persisted with AtomicWrite including {jobId, correlationId, paramsHash, configHash, producerVersion}. <br>2. audit_tail.csv for correlation window including UserAction and util.* events. <br>3. artifact JSON files with recorded SHA256 checksums; artifact.metadata.json mapping artifact -> checksum. <br>4. serialized RNG state (rng_state.blob) for deterministic sampling or shuffles. <br>5. SafeRound canonical decimal input and output snapshots. <br>6. persisted temp artifacts and InspectTempArtifacts listing for failed AtomicWrite attempts. <br>7. repair logs and AtomicWriteRepair actions. <br>8. forensic_manifest.json enumerating artifact URIs, checksums, evidenceRefs, and chain-of-custody fields. <br><strong>Evidence storage & lifecycle:</strong> hot evidence store: \\evidence\hot\<module>\<correlationId>\ for 30 days; warm archive: secure encrypted archive for 7 years for regulated artifacts; cold: retention as regulation requires. EvidenceRefs in audit rows are encrypted pointers and require ACLs to access; any access to evidence triggers util.evidence.access audit. Monthly retention verification job emits housekeeping.audit and proof-of-delete artifacts recorded in audit store. <br><strong>Forensic process checklist (incident):</strong> collect jobDescriptor, audit_tail segment, persisted artifact files, RNG serialized state, SafeRound input snapshots, temp artifacts, and forensic_manifest; compute checksums for each and include chain-of-custody metadata. Provide outputs to SRE/compliance with clear reproduction steps. <br> </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Acceptance checklist before module release (comprehensive):</strong><br>1. Owners and approvers listed in OWNERS.md and accessible. <br>2. Public API documented, stable, and semver tagging applied to breaking changes. <br>3. Golden vectors for DeterministicRNG and SafeRound established and passing across supported languages/hosts. <br>4. AtomicWrite integration tests and degraded-path tests for network FS present. <br>5. Static analyzer prevents UI-thread IO and direct workbook DOM writes in OnLoad handlers. <br>6. Audit hook coverage validated by test harness writing to modAudit buffer and verifying rotation and signing. <br>7. SRE sign-off for persistence semantics and storage dependency assumptions. <br><strong>Blocking conditions:</strong> missing audits for durable flows, failing golden vectors, static analyzer detection of forbidden UI-thread IO, or SRE sign-off absence. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Extremely detailed test plan highlights & representative tests (explicit):</strong><br><strong>Unit tests:</strong><br>1. SafeRound: goldens covering bankers/awayFromZero/residual_distribute, negative numbers, half ties, very large exponents, and edge places values. <br>2. SafeRoundResiduals: numerous distribution vectors including boundary totals and tie-break permutations with varying tieBreakerKeys. <br>3. AtomicWrite: simulate rename/fsync failures, ENOSPC, EPERM; ensure no truncated reads and that verification step detects mismatch. <br>4. Retry: deterministic_jitter path and cancellation token; idempotency assertion checks with static analyzer. <br>5. DeterministicRNG: cross-language parity for first 100 outputs, splitStream independence. <br><strong>Integration tests:</strong><br>1. Full persistence roundtrip: jobDescriptor persisted -> worker reads -> artifact produced -> artifactChecksum verified. <br>2. Fault-injected AtomicWrite: ENOSPC simulated -> StageLocalExport fallback engaged -> forensic artifacts recorded. <br>3. Deterministic replay: DQ_Profile + Remediation persisted RNG & rounding audits -> replay yields identical artifacts. <br><strong>Property tests & fuzz:</strong><br>1. Sum-preservation for residual_distribute across random vectors of size 2..1e6 scaled appropriately. <br>2. Sampling invariants ensuring deterministic sample parity under repeated runs. <br><strong>Performance & stress:</strong><br>1. SafeRound 1M-row throughput benchmarks in worker environment; measure memory and CPU budgets. <br>2. AtomicWrite median latency tests on SSD and representative SMB/NFS mounts; test concurrent-reader behavior. <br>3. Retry overhead microbenchmarks under simulated transient network conditions. <br><strong>CI gating:</strong> no merge until unit/integration/golden/static/performance gates pass; new goldens require owner approvals and manifest updates. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Operator quick commands & cheatsheet (prescriptive):</strong><br>1. <code>diagnostics collect --correlation r-YYYYMMDD-xxx</code> — gather audit_tail.csv, RNG serialized state evidenceRefs, artifact files, and forensic_manifest.json for run. <br>2. <code>atomic_write.repair --temp &lt;tempPath&gt;</code> — validate sidecar payloadHash and attempt manual rename under maintenance window; generate repair audit and forensic_manifest. <br>3. <code>replay.run --correlation r-... --evidenceRef &lt;blob&gt;</code> — deterministic replay using serialized RNG state and SafeRound audits; use --dry-run to validate only. <br>4. <code>jobs requeue --job-id &lt;id&gt;</code> — idempotently re-persist job descriptor and schedule worker; job dedup logic observed. <br>5. <code>exports stage-local --artifact &lt;id&gt;</code> — store artifact on same-volume staging directory when remote target fails atomic rename; include artifactChecksum in staging notification. <br><strong>When to escalate to SRE:</strong> after two AtomicWrite ENOSPC retries on critical descriptors or Retry exhaustion emitting UTIL_RETRY_EXCEEDED; provide forensic_manifest and audit_tail in ticket. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Common failure modes & mitigations (expanded):</strong><br><strong>Partial write observed by readers</strong><br>1. Cause: direct write to final path instead of AtomicWrite or rename non-atomic on network FS. <br>2. Mitigation: static analyzer enforces AtomicWrite; perform InspectTempArtifacts and AtomicWriteRepair to recover verified payloads; prefer StageLocalExport for network targets. <br><strong>Non-deterministic sampling complaint</strong><br>1. Cause: global RNG used or seed not persisted. <br>2. Mitigation: always seed DeterministicRNG from correlationId and persist RNG state; add CI tests to detect global RNG usage. <br><strong>Rounding bias over repeated runs</strong><br>1. Cause: repeated awayFromZero rounding causing drift. <br>2. Mitigation: adopt bankers or residual_distribute for financial flows and document strategy in manifest; run property tests to detect drift. <br><strong>AtomicWrite verification failure</strong><br>1. Cause: silent FS corruption or interference during rename. <br>2. Mitigation: emit util.atomic_write.verification_failed, attempt AtomicWriteRepair, move artifact to safe staging, and escalate to storage team with forensic_manifest. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Governance checklists, PR requirements & release controls (explicit):</strong><br>1. PR must include unit tests for new behavior, updated goldens for RNG/SafeRound changes, and automated audit emission validation. <br>2. Changes to rounding semantics or RNG algorithm require migration manifest and owner approvals; cross-language parity tests mandatory. <br>3. Any change to AtomicWrite or persistence semantics requires cross-platform regression tests and SRE sign-off on storage assumptions. <br>4. Release manifest must be updated and signed for production changes affecting regulated outputs; audit chain verification must pass in CI. <br><strong>Blocking conditions:</strong> failing goldens, missing audit hooks, static analyzer detecting forbidden UI-thread IO, or SRE sign-off missing for persistence semantics. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Extremely detailed forensic narrative example — incident reconstruction template (operational):</strong><br><strong>Incident synopsis:</strong> "Allocation mismatch for run r-YYYYMMDD-455" — discrepancy between produced artifact checksum and ledger expected total. <br><strong>Forensic reconstruction ordered steps:</strong><br>1. Retrieve audit_tail rows for correlationId r-YYYYMMDD-455 including UserAction, util.* events and Worker step audits. <br>2. Fetch jobDescriptor.json persisted via AtomicWrite for the jobId referenced in audits; validate jobDescriptor artifactChecksum via ComputePayloadHash. <br>3. Download allocation artifact and compute SHA256; compare to util.atomic_write.completed artifactChecksum recorded in audit. <br>4. Fetch RNG serialized blob indicated by util.rng.state_serialized evidenceRef; restore RNG via restore_rng_state. <br>5. Re-run allocation pipeline in reproduce mode using canonical ledger snapshot persisted earlier; ensure decimal canonicalization step uses same normalization rules and SafeRoundResiduals with recorded tieBreakerKeys. <br>6. If reproduced artifactChecksum matches original, compile compliance package with forensic_manifest and documented reproduction steps; if mismatch, examine util.atomic_write.verification_failed and InspectTempArtifacts for temp artefacts indicating write/verification issues; escalate storage team if FS issues indicated. <br>7. Package forensic_manifest with all artifacts, audit_tail segments, RNG serialized state, and decimal snapshots; present to compliance. <br><strong>Outcome:</strong> reproducibility validated or root cause found (data canonicalization mismatch vs persistence verification failure vs job input mutation). <br> </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Appendices — authoring checklists & short reference (concise):</strong><br><strong>PQ Template author checklist:</strong><br>1. Provide parameter schema with explicit typed definitions and defaults. <br>2. Mark templates requiring high numeric fidelity as <code>requiresHighPrecision</code>. <br>3. Avoid embedding secrets; use secure parameter handles referencing credential manager. <br>4. Include <code>mChecksum</code> in manifest; sign manifest for regulated templates. <br><strong>DAX/report builder checklist:</strong><br>1. Consume RunMetadata table to surface provenance and artifactChecksum. <br>2. Avoid allocation/regression logic in DAX—perform in ETL using SafeRoundResiduals. <br>3. Use persisted hash keys for deterministic sampling. <br><strong>Operator quick triage:</strong><br>1. When audit mismatch occurs, collect audit_tail for correlationId, jobDescriptor, artifact checksum and RNG state before contacting SRE. <br>2. For ENOSPC, prefer StageLocalExport then escalate. </td></tr><tr><td data-label="DQ_Utilities — Per-function Expert Technical Breakdown"> <strong>Closing mandatory constraints:</strong><br>1. Do not bypass AtomicWrite for artifacts consumed by other processes; static analyzer and CI will enforce. <br>2. Always record paramsHash and use evidenceRef for full sanitized parameter storage; PII must not appear in top-level audit. <br>3. Seed DeterministicRNG from correlationId for operator-visible sampling and persist RNG state via serialize_rng_state for replay when required. <br>4. Offload numerically sensitive transforms to worker SafeRound flows rather than relying on local M runtime decimal semantics for regulated outputs. <br>5. All critical operations must emit audit rows and attach evidenceRef when necessary; this is non-negotiable for regulated or PII-touching workflows. <br><strong>Tenfold internal reviews completed:</strong> module design, audit coverage, deterministic chain from UI->job->worker->artifact persisted, recovery runbooks, CI gating, and cross-language golden governance validated. </td></tr></tbody></table></div><div class="row-count">Rows: 51</div></div><div class="table-caption" id="Table9" data-table="Docu_0176_09" style="margin-top:2mm;margin-left:3mm;"><strong>Table 9</strong></div>
<div class="table-wrapper" data-table-id="table-9"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Profile — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Profile — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong>Overview (module-level contract, invariants, and scope)</strong><br><strong>Authority & scope:</strong> <code>DQ_Profile</code> is the canonical profiling engine used by DQGuard.xlam. Its responsibilities are detection-first profiling, deterministic sampling, explainable metric computation, PII-aware evidence handling, canonical manifest generation, atomic persistence of artifacts, audit anchoring, and integration points for job scheduling and worker execution. Non-responsibilities: business allocation, remediation application, external system mutation, or secret management. Those belong to <code>modRemediation</code>, <code>modExport</code>, or <code>modSecurity</code> respectively.<br><strong>High-level invariants:</strong><br>1. Determinism: identical inputs + <code>configHash</code> → identical <code>profileHash</code> and artifacts. <br>2. Non-destructive by default: profiling reads only; applyMode required for destructive operations. <br>3. Audit-first: every user-initiated profile run appends <code>dq_profile</code> audit with <code>correlationId</code>. <br>4. PII-safe: UI-visible artifacts are redacted by default; full evidence stored encrypted and gated. <br>5. Host-aware: runtime must respect Excel host constraints (UI thread budgets, 32-bit memory). <br><strong>Primary integration points:</strong> <code>modRibbonCallbacks</code> (entry), <code>JobSchedulerIntegration</code> (heavy runs), <code>modExport</code> (atomic persistence), <code>modAudit</code> (audit writes), <code>modConfig</code> (thresholds, sampling), <code>EnsureDeps</code> (runtime dependencies). <br><strong>Evidence artifacts produced:</strong> <code>profile_report.csv</code>, <code>profile_summary.json</code>, <code>sample.csv</code>, <code>profile_manifest.json</code>, <code>evidence_package.enc</code> (encrypted, on approval). <br><strong>Key telemetry/metrics:</strong> <code>dq_profile.duration_ms</code>, <code>dq_profile.persist_latency_ms</code>, <code>dq_profile.timeout_rate</code>, <code>dq_profile.audit_append_latency_ms</code>. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileTable(tableRef, options)</code> — orchestrator (expanded, code-accurate)</strong><br><strong>Purpose & contract:</strong> Module entrypoint implemented as <code>Public Function ProfileTable(ByVal tableRef As String, Optional ByVal options As Variant) As Dictionary</code>. Responsibilities implemented in code: run <code>PreflightChecks</code>, compute <code>EstimateProfileCost</code>, decide inline vs scheduled, schedule watchdog when inline, compute deterministic seed via <code>ComputeSamplingSeed</code>, collect sample via <code>sampleRows</code>, canonicalize ordering, compute per-column metrics via <code>ComputeColumnMetrics</code>, assemble manifest with <code>AssembleProfileDescriptor</code>, persist artifacts via <code>PersistProfileArtifacts</code>, and emit final audit via <code>EmitProfileAudit</code>. Must return a <code>Dictionary</code> manifest on success or structured error dictionary on failure. <br><strong>Inputs (as in code):</strong> <code>tableRef</code> (String), <code>options</code> (Variant — may be missing or Dictionary). <br><strong>Return (as in code):</strong> <code>Dictionary</code> — either schedule response <code>{status:&quot;scheduled&quot;, jobId, runId}</code> when job persisted; or manifest <code>Dictionary</code> with <code>profileHash</code>, <code>metricsSummary</code>, <code>artifacts</code> on inline completion; or error dictionary <code>{error, number, description}</code> on exception. <br><strong>Key implementation behaviors (code-exact):</strong><br>1. Uses <code>GetCorrelationId()</code> for correlation id and <code>DQ_Config_GetConfigHash</code> for configHash. <br>2. If <code>EstimateProfileCost</code> exceeds <code>INLINE_BUDGET_MS</code> or <code>rowCount</code> > <code>INLINE_ROW_THRESHOLD</code>, builds <code>jobDescriptor</code>, calls <code>CORE_JobScheduler_Persist(jobJson)</code>, and on failure writes fallback job JSON to <code>MOD_EXPORT_FallbackDir</code> using <code>AtomicWrite</code>. <br>3. Inline path: schedules watchdog via <code>SafeProfileTimeoutWatchdog_Schedule</code> which enqueues token in <code>watchdogRegistry</code> and registers <code>Application.OnTime</code> to call <code>&#x27;ThisWorkbook&#x27;!SafeProfileTimeoutWatchdog_Check</code>. <br>4. Sampling: calls <code>sampleRows</code> (streaming via host enumerator) and records <code>sampleHash</code>. <br>5. For each sampled column calls <code>DQ_Profile_LoadColumnWindowed</code> then <code>ComputeColumnMetrics</code>, emits per-column <code>dq_profile.column.completed</code> audit anchors using <code>EmitAuditRaw</code>. <br>6. Assembles <code>manifest</code> via <code>AssembleProfileDescriptor</code> and persists artifacts via <code>PersistProfileArtifacts</code>; then calls <code>EmitProfileAudit</code>. <br>7. Error handling: errors are trapped; unhandled exceptions produce <code>dq_profile.exception</code> audit and returned error dictionary. <br><strong>Side-effects:</strong> writes job descriptors, writes persisted artifacts, emits audits, and may write fallback artifacts. <br><strong>Edge-cases & recovery (code-handled):</strong> preflight fail emits preflight audit and returns; job persist fallback to local staging; audit append failures are best-effort and logged; watchdog cancellation respected during per-column loops. <br><strong>Tests (code-relevant):</strong> preflight negative tests, job persist fallback test, inline watchdog cancellation, end-to-end inline sample→manifest→persist path. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>PreflightChecks(tableRef, options)</code> — safety & resource gating (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function PreflightChecks(ByVal tableRef As String, Optional ByVal options As Variant) As Dictionary</code>. Fast validations to exit early with structured issues. Returns <code>Dictionary</code> with <code>ok:Boolean</code>, <code>issues:Collection</code>, <code>tableStats:Dictionary</code>, and <code>tableMeta</code>. <br><strong>Checks implemented in code (fast path):</strong><br>- Calls host <code>DQ_Profile_MetaFetch(tableRef)</code> to obtain <code>rowCount</code>, <code>colCount</code>, <code>headers</code>, <code>approxCellSize</code>, <code>hasLongText</code>. <br>- Validates <code>DQ_Config_GetConfigHash</code> is present. <br>- Calls <code>DQ_Security_CanProfile(tableRef)</code> for permission gate. <br>- Verifies export destination writeability via <code>MOD_EXPORT_CheckWriteable</code> (or <code>options(&quot;outputDest&quot;)</code> if provided). <br>- Probes evidence store with <code>DQ_Evidence_Probe</code> (best-effort). <br>- Marks <code>mayRequireWorker</code> if <code>DQ_Profile_IsPQBound(tableRef)</code> returns True. <br><strong>Failure behavior (code):</strong> collects <code>issues</code> and returns <code>out(&quot;ok&quot;) = False</code>; does not throw host-visible errors except via error-path which returns <code>ERR_PREFLIGHT_EXCEPTION</code>. <br><strong>Tests:</strong> missing meta, denied permission, non-writeable outputDest, evidence probe false. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>EstimateProfileCost(tableStats, options)</code> — policy-driven estimator (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function EstimateProfileCost(tableStats As Dictionary, Optional ByVal options As Variant) As Dictionary</code>. Computes <code>estimatedCost</code> (bytes), <code>estimatedDurationMs</code>, and <code>rationale</code>. Uses <code>CORE_Host_GetBitness</code> to apply safety multiplier for 32-bit hosts. Emits <code>dq_profile.costEstimate</code> audit via <code>EmitAuditRaw</code>. <br><strong>Heuristics (code):</strong> <code>estimatedBytes = rows * cols * approxCellSize</code>; <code>estimatedDurationMs = (estimatedBytes/1024) * 0.5 * multiplier</code> (heuristic). <br><strong>Edge cases & failure:</strong> returns large fallback values and <code>rationale</code> on error. <br><strong>Tests:</strong> boundary rows/cols, 32-bit vs 64-bit multiplier effect. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputeSamplingSeed(tableRef, options, configHash)</code> — deterministic non-PII seed (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ComputeSamplingSeed(tableRef As String, Optional ByVal options As Variant, Optional ByVal configHash As String = &quot;&quot;) As Dictionary</code>. Produces deterministic truncated HMAC-SHA256-based seed and <code>seedSource</code> provenance. <br><strong>Code specifics:</strong><br>1. Uses <code>options(&quot;runId&quot;)</code> if provided else generates <code>runId</code> from Now+RandBetween. <br>2. Fetches <code>configHash</code> via <code>DQ_Config_GetConfigHash</code> if not provided. <br>3. Attempts to use <code>CORE_Bootstrap_GetSeedKeyFingerprint</code> as HMAC key; falls back to <code>&quot;dq_profile_local_key&quot;</code>. <br>4. Builds <code>seedSource = tableRef &amp; &quot;|&quot; &amp; configHash &amp; &quot;|&quot; &amp; runId</code>; computes <code>h = HmacSha256Hex(keyFingerprint, seedSource)</code> and truncates to 16 hex chars to compute a 64-bit numeric seed. <br><strong>Edge-cases:</strong> on error falls back to <code>seed = CLng(Now)</code>. <br><strong>Tests:</strong> repeatability with same inputs; fallback path. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>sampleRows(tableRef, sampleSize, seed, strategy, options)</code> — reservoir streaming sampler (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function sampleRows(tableRef As String, ByVal sampleSize As Long, ByVal seed As Variant, ByVal strategy As String, Optional ByVal options As Variant) As Dictionary</code>. Provides deterministic sampling using a host-provided enumerator <code>DQ_Profile_RowEnumerator_Create/HasNext/Next</code>. Returns <code>Dictionary</code> with <code>sampleMethod</code>, <code>sampleSize</code>, <code>isSanitized</code>, <code>sampleRows</code>, <code>sampleHash</code>, and <code>columns</code>. <br><strong>Behavior implemented:</strong><br>1. Creates deterministic RNG via <code>UTIL_DeterministicRNG_Create(seed)</code>. <br>2. Streams rows with host enumerator; reservoir algorithm used for streaming selection; selection index obtained via <code>UTIL_RNG_NextIndex(rng, count)</code> if RNG present, else falls back to <code>Rnd</code>. <br>3. Sanitizes each sampled row via host <code>DQ_Profile_SanitizeRow</code> with optional <code>sensitiveColumns</code> from <code>options</code>. <br>4. Extracts canonical column list by calling <code>DQ_Profile_ExtractColumnsFromSample(sanitized)</code>. <br>5. Computes <code>sampleHash = ComputeSHA256(SerializeCanonical(sanitized))</code>. <br><strong>Memory/host constraints:</strong> uses streaming enumerator to avoid full table load (suitable for Excel 32-bit). <br><strong>Failure modes:</strong> on enumerator null returns empty sample and empty hash. <br><strong>Tests:</strong> deterministic reservoir results with seeded RNG; sanitization applied by default. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CanonicalizeTableOrdering(tableRef)</code> — stable iteration order (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function CanonicalizeTableOrdering(tableRef As String) As Dictionary</code>. Returns <code>descriptor</code> with <code>primaryKey:&lt;col&gt;</code> when <code>DQ_Profile_FindPrimaryKey</code> supplies a key; otherwise returns <code>&quot;rowIndexFallback&quot;</code> and explanatory <code>note</code>. Must not modify source data. <br><strong>Behavior & use:</strong> used by <code>ProfileTable</code> to populate <code>orderingDescriptor</code> and included in manifest. <br><strong>Tests:</strong> primaryKey present vs absent; ensures descriptor consistent. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputeColumnMetrics(columnName, columnData, columnSpec, config)</code> — per-column metric engine (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ComputeColumnMetrics(columnName As String, columnData As Variant, columnSpec As Dictionary, config As Dictionary) As Dictionary</code>. Produces the column metrics dictionary used throughout the module and persisted in manifest. <br><strong>Metrics produced (as in code):</strong> <code>columnName</code>, <code>rowCount</code>, <code>nullCount</code>, <code>distinctCountExact</code>, <code>isApproximateDistinct</code>, <code>topNValues</code>, <code>histogram</code> (from <code>BuildHistogram</code>), <code>typeGuess</code>, <code>entropy</code>, <code>outlierCandidates</code>, <code>approxDistinctSketch</code> (placeholder <code>hll:p=14</code> for large columns), and deterministic <code>columnProfileHash</code>. <br><strong>Numeric handling (code):</strong> computes <code>min/max/mean/median/stddev</code> via Excel WorksheetFunction when numeric dominance detected (numericCount >= 90%); computes <code>mad</code> via <code>RobustMAD</code> helper and uses <code>UTIL_SafeRound</code> to produce <code>meanRounded</code>. <br><strong>TopN & determinism:</strong> obtains <code>topN</code> via <code>DQ_Profile_TopNValues(valuesList, 10)</code> (host plugin expected to implement stable tie-break). <br><strong>Cardinality:</strong> uses exact distinct for small sets; for <code>total&gt;10000</code> sets <code>approxDistinctSketch</code> metadata and <code>isApproximateDistinct=True</code>. <br><strong>Outliers:</strong> populates <code>outlierCandidates</code> via <code>DetectOutliers</code>. <br><strong>Finalization:</strong> serializes canonical <code>out</code> via <code>SerializeCanonical</code> and computes <code>columnProfileHash = ComputeSHA256(canonical)</code>. <br><strong>Error handling:</strong> on exception returns error dictionary with <code>ERR_COLUMN_METRICS</code>. <br><strong>Tests:</strong> numeric precision, median consistency, topN determinism, large-column branch. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>RobustMAD(valuesList)</code> — helper for MAD (code-accurate)</strong><br><strong>Purpose & contract:</strong> Private helper returning median absolute deviation computed deterministically over numerical <code>valuesList</code> collection. Uses WorksheetFunction.Median for base median and deviation median. Returns 0 for empty list or on error. <br><strong>Tests:</strong> provides consistent values vs known vectors; zero-handling. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>EstimateEntropy(distinctDict, total)</code> — approximate entropy (code-accurate)</strong><br><strong>Purpose & contract:</strong> Private helper that approximates Shannon entropy using an approximation when per-value counts are not available. Iterates keys in <code>distinctDict</code> and uses uniform p=1/total fallback (placeholder behavior implemented in code). Returns 0 on errors. <br><strong>Notes:</strong> this is an approximation; hosts with frequency counts can extend it. <br><strong>Tests:</strong> sanity checks for small totals and distinct counts. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>BuildHistogram(values, numericBinningConfig)</code> — deterministic histogram builder (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function BuildHistogram(values As Variant, numericBinningConfig As Dictionary) As Dictionary</code>. Builds histogram for numeric <code>values</code> using <code>nbins</code> (default 10) or config-provided method (code defaults to Freedman–Diaconis but implements fixed-width binning in code). Returns <code>binEdges</code>, <code>counts</code>, <code>method</code>, and <code>sampleBins</code>. <br><strong>Behavior & edge cases:</strong> ignores non-numeric entries; preserves zero-count bins. On empty numeric set returns empty arrays. <br><strong>Tests:</strong> deterministic edges/counts for known distributions; sparse data handling. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DetectOutliers(columnProfile, method, thresholds)</code> — explainable detector (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function DetectOutliers(columnProfile As Dictionary, method As String, thresholds As Dictionary) As Collection</code>. Default conservative MAD detector: computes cutoffs <code>median ± multiplier * MAD</code> (multiplier default 3.5) and returns a collection of candidate descriptors with <code>colName</code>, <code>method</code>, <code>cutoffLow</code>, <code>cutoffHigh</code>, and <code>confidence</code>. Returns empty collection when MAD unavailable. <br><strong>PII escalation:</strong> caller should mark <code>mayContainPII</code> if pattern matches. <br><strong>Tests:</strong> MAD detection reproduces expected cutoffs. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ComputePatternFrequencies(columnStrings, regexList, ngramConfig)</code> — structural discovery (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ComputePatternFrequencies(columnStrings As Variant, regexList As Variant, ngramConfig As Dictionary) As Dictionary</code>. Iterates sample strings, applies host <code>DQ_Profile_RegexMatches</code>, aggregates match counts per pattern, and returns <code>patternSummary</code> collection of records containing <code>patternFingerprint</code>, <code>pattern</code>, <code>matchCount</code>, <code>sampleMatches</code> (placeholder array), <code>mayContainPII</code> (from <code>IsPIIPattern</code>), and <code>patternConfidence</code>. <br><strong>PII detection helper:</strong> <code>IsPIIPattern(pattern)</code> implemented locally to heuristically detect email/phone/ssn/iban substrings in regex string. <br><strong>Tests:</strong> pattern recognition and <code>mayContainPII</code> flagging for known regexes. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>IsPIIPattern(pattern)</code> — heuristic PII pattern detector (code-accurate)</strong><br><strong>Purpose & contract:</strong> Private helper analyzing pattern string for keywords (email/phone/ssn/iban) and returning Boolean. Conservatively used to flag candidate patterns for evidence gating. <br><strong>Tests:</strong> keyword coverage for common PII patterns. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DetectDuplicatesAndKeys(profileContext)</code> — duplicate/key heuristics (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function DetectDuplicatesAndKeys(profileContext As Dictionary) As Dictionary</code>. Iterates <code>profileContext(&quot;columns&quot;)</code> and uses <code>distinctCountExact</code> vs <code>rowCount</code> ratio to propose <code>keyCandidates</code> when uniqueness ratio >= 0.99; builds <code>duplicateGroups</code> when duplicates exist. Avoids O(N^2) by relying on per-column stats; example rows left as placeholders for host retrieval. <br><strong>Tests:</strong> key candidate detection and duplicate group sizing. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ColumnCorrelationAnalysis(columns, method, maxPairs)</code> — cross-column metrics (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ColumnCorrelationAnalysis(columns As Variant, Optional ByVal method As String = &quot;pearson&quot;, Optional ByVal maxPairs As Long = 1000) As Dictionary</code>. Produces deterministic pairwise <code>pairs</code> collection with <code>colA</code>, <code>colB</code>, <code>metric</code>, <code>pValue</code>, and <code>notes</code>. Throttles by <code>maxPairs</code> and returns <code>pairs</code> up to that limit. <br><strong>Privacy:</strong> returns only aggregated metrics and notes, no cell values. <br><strong>Tests:</strong> pair count enforcement and deterministic pair listing. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>AssembleProfileDescriptor(runId, tableMeta, columns, artifacts)</code> — canonical manifest (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function AssembleProfileDescriptor(runId As String, tableMeta As Dictionary, columns As Collection, artifacts As Collection) As Dictionary</code>. Builds canonical manifest fields: <code>moduleVersion</code>, <code>profileSchemaVersion</code>, <code>configHash</code>, <code>ribbonMapHash</code>, <code>runId</code>, <code>profileId</code>, <code>tableFingerprint</code>, <code>columns</code>, <code>artifacts</code>, <code>metricsSummary</code>, <code>sensitivityFlags</code>. Canonicalizes via <code>SerializeCanonical</code> and computes <code>profileHash = ComputeSHA256(canonical)</code>. Returns the manifest dictionary. <br><strong>Determinism & tests:</strong> canonicalization parity tests across locales and stable <code>profileHash</code>. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>PersistProfileArtifacts(profileDescriptor, artifacts, destination)</code> — atomic output & fallback (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function PersistProfileArtifacts(profileDescriptor As Dictionary, artifacts As Collection, destination As String) As Dictionary</code>. For each artifact string in <code>artifacts</code> writes <code>destination \ profileId.artifact.i.json</code> via <code>AtomicWrite</code> (host wrapper <code>UTIL_AtomicWrite</code>), collects <code>artifactChecksums</code>, and on write failure attempts fallback to <code>MOD_EXPORT_FallbackDir</code> using <code>AtomicWrite</code>. After successful artifact writes, uploads <code>manifestJson</code> to evidence store via <code>DQ_Evidence_Store</code> and returns <code>evidenceRef</code>. Returns a <code>Dictionary</code> with <code>ok</code>, <code>artifactChecksums</code>, <code>fallbackPath</code> if used, and <code>evidenceRef</code>. <br><strong>Behavior on partial failure:</strong> returns early with <code>ERR_PERSIST_ALL_FAILED</code> if both primary and fallback fail for any artifact. <br><strong>Tests:</strong> primary persist success, fallback success, and total persist failure. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>EmitProfileAudit(correlationId, profileDescriptor, params, evidenceRef?)</code> — canonical audit anchor (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function EmitProfileAudit(correlationId As String, profileDescriptor As Dictionary, params As Variant, Optional evidenceRef As String = &quot;&quot;) As Boolean</code>. Builds audit <code>Dictionary</code> with <code>timestamp</code>, <code>correlationId</code>, <code>module = MODULE_NAME</code>, <code>procedure = &quot;dq_profile&quot;</code>, <code>userId = Application.UserName</code>, <code>profileId</code>, <code>profileHash</code>, <code>paramsHash = ComputeSHA256(SerializeCanonical(params))</code>, <code>configHash</code>, <code>artifacts</code>, <code>metadata.durationMs</code> and optional <code>evidenceRef</code>. Calls <code>DQ_Audit_AppendRow(SerializeCanonical(audit))</code> and returns the boolean result. Non-blocking append semantics are respected; code logs but does not throw if append fails. <br><strong>Tests:</strong> audit append success/failure, paramsHash correctness, evidenceRef presence when provided. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CompareProfiles(oldProfile, newProfile, diffOptions)</code> — deterministic diffs & regressions (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function CompareProfiles(oldProfile As Dictionary, newProfile As Dictionary, Optional diffOptions As Variant) As Dictionary</code>. Produces <code>explainableChanges</code> and <code>regressionFlags</code> by mapping columns by <code>columnName</code> and comparing metrics (e.g., <code>distinctCountExact</code>). Computes <code>diffHash = ComputeSHA256(SerializeCanonical(out))</code> and returns diff dictionary. <br><strong>Rules (code):</strong> flags a regression if <code>distinctCount</code> changes by >20% (risk scored high if >50%); reports added columns. <br><strong>Tests:</strong> regression detection, diffHash determinism, empty-old or empty-new behavior. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SanitizeAndEvidence(params, sensitiveColumns, approval)</code> — redaction & encrypted evidence workflow (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function SanitizeAndEvidence(params As Dictionary, sensitiveColumns As Variant, approval As Variant) As Dictionary</code>. Produces <code>sanitized</code> dictionary where keys in <code>sensitiveColumns</code> are replaced with <code>&quot;&lt;REDACTED&gt;&quot;</code>. If <code>approval</code> dictionary indicates <code>approved=True</code> and <code>approverCount&gt;=2</code>, serializes full sanitized params and calls <code>DQ_Evidence_Store(blob, ticketId)</code> returning <code>evidenceRef</code>. Returns <code>{sanitized, evidenceRef}</code>. <br><strong>Governance (code):</strong> two-person approval required to store full evidence. <br><strong>Tests:</strong> redaction completeness, evidenceRef returned only when approval present. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>IsInArray(val, arr)</code> — small utility (code-accurate)</strong><br><strong>Purpose & contract:</strong> Private helper that returns True if <code>val</code> string-equals any element in <code>arr</code>. Handles <code>Empty</code> arrays gracefully. Used by <code>SanitizeAndEvidence</code>. <br><strong>Tests:</strong> case-matching and empty-arr handling. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SafeProfileTimeoutWatchdog_Schedule(token, correlationId, runContext)</code> — scheduling (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Sub SafeProfileTimeoutWatchdog_Schedule(token As Dictionary, correlationId As String, runContext As Dictionary)</code>. Stores token in module-level <code>watchdogRegistry</code> and schedules <code>Application.OnTime</code> to call <code>SafeProfileTimeoutWatchdog_Check</code> after <code>WATCHDOG_CHECK_INTERVAL_SEC</code>. Relies on workbook-level public procedure wiring using <code>ThisWorkbook.name</code>. <br><strong>Tests:</strong> scheduling enqueues registry key and OnTime invocation string correctness. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>SafeProfileTimeoutWatchdog_Check(runId)</code> — watchdog execution (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Sub SafeProfileTimeoutWatchdog_Check(runId As String)</code>. Reads token from <code>watchdogRegistry</code>, computes elapsedMs since token's <code>startTs</code> (or sets it), and if exceeded <code>budgetMs</code> sets <code>token(&quot;cancelled&quot;) = True</code> and emits <code>dq_profile.timeout</code> audit with <code>runId</code> and <code>elapsedMs</code>. Otherwise reschedules next check via <code>Application.OnTime</code>. Leaves token in registry for inspection on timeout. <br><strong>Edge handling:</strong> uses <code>On Error</code> defensively; does not block on exceptions. <br><strong>Tests:</strong> timeout triggers, cancellation token observed by main loop. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>RegisterProfileUnitTestHook(hookName, fixedRunId)</code> — CI/golden harness (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function RegisterProfileUnitTestHook(hookName As String, fixedRunId As String) As Boolean</code>. Only registers when <code>DQ_Config_IsTestMode</code> returns True; calls <code>DQ_TestHooks_Register(hookName, fixedRunId)</code> and emits <code>dq_profile.test.hook.registered</code> audit. Returns registration boolean. <br><strong>Tests:</strong> test-mode gate prevents registration in production. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileHealthCheck()</code> — readiness & diagnostics (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ProfileHealthCheck() As Dictionary</code>. Performs non-invasive checks: <code>DQ_Config_GetConfigHash</code> presence, <code>MOD_EXPORT_CheckWriteable(MOD_EXPORT_TempDir)</code>, audit append probe via <code>DQ_Audit_AppendRow(SerializeCanonical(NewDict()))</code>, and memory estimate via <code>DQ_Profile_GetMemoryEstimate</code>. Returns <code>{ok:bool, issues:Collection, memoryEstimate}</code> and emits <code>dq_profile.health</code> audit with <code>paramsHash</code>. <br><strong>Failure handling:</strong> returns <code>ok=False</code> and issue list on failures. <br><strong>Tests:</strong> healthy vs dependency-missing cases. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>BuildUiPreview(sampleArtifact, sensitiveColumns, maxRows)</code> — UI preview builder (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function BuildUiPreview(sampleArtifact As Dictionary, sensitiveColumns As Variant, ByVal maxRows As Long) As Dictionary</code>. Retrieves preview rows via <code>DQ_Profile_GetPreviewRows(sampleArtifact, maxRows)</code>, sanitizes each row using <code>DQ_Profile_SanitizeRowWithColumns</code>, and returns <code>{correlationId, profileId, previewRows, columnSummaries}</code> suitable for UI display. Preserves <code>correlationId</code> and <code>profileId</code>, and ensures PII redaction. On error returns <code>{error=&quot;ERR_PREVIEW&quot;, number, description}</code>. <br><strong>Performance note (code):</strong> optimized for small <code>maxRows</code>; heavy previews should be precomputed off-UI thread. <br><strong>Tests:</strong> preview redaction, null/array/raw object handling. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileErrorMapping(errNumber, errDescription)</code> — consistent error mapping (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Function ProfileErrorMapping(ByVal errNumber As Long, ByVal errDescription As String) As Dictionary</code>. Maps known VB/host errors to stable error codes and user/SRE hints. Example mapping in code: Case 76 → <code>ERR_PROFILE_EXPORT_403</code> with <code>userHint</code> and <code>sreHint</code>; default → <code>ERR_PROFILE_EXCEPTION</code>. Returns a <code>Dictionary</code> with <code>errorCode</code>, <code>userHint</code>, and <code>sreHint</code>. <br><strong>Tests:</strong> mapping for known error numbers and default fallback. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileTelemetryEmit(metrics)</code> — local buffering & audited uplink hooks (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Sub ProfileTelemetryEmit(metrics As Dictionary)</code>. Tags <code>metrics(&quot;correlationId&quot;) = GetCorrelationId()</code> and calls <code>MOD_TELEMETRY_BufferMetric</code> via <code>Application.Run</code>. Non-blocking and best-effort. <br><strong>Tests:</strong> buffer call exercised and metric enrichment with correlationId. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>ProfileRetentionHousekeeping()</code> — artifact lifecycle management (code-accurate)</strong><br><strong>Purpose & contract:</strong> Implemented as <code>Public Sub ProfileRetentionHousekeeping()</code>. Retrieves <code>retentionPolicy</code> via <code>DQ_Config_GetRetentionPolicy</code> and calls <code>DQ_Profile_RunRetention(retentionPolicy)</code> on host, then emits <code>dq_profile.housekeeping</code> audit with <code>paramsHash</code>. Error path logs debug message. <br><strong>Tests:</strong> retention invocation and audit emission. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>PersistIfExists(d, key)</code> — tiny helper used in orchestrator (code-accurate)</strong><br><strong>Purpose & contract:</strong> Private helper returning <code>d(key)</code> if <code>d</code> is not <code>Nothing</code> and <code>d.Exists(key)</code> else <code>Null</code>. Used in <code>ProfileTable</code> to safely read optional fields from <code>persistRes</code>. <br><strong>Tests:</strong> null-safe behavior. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>DeveloperNotes &amp; host-specific guidance</code> — implementation pointers (code-accurate)</strong><br><strong>Notes present in module and reflected in code:</strong> avoid heavy UI-thread enumeration; prefer <code>Application.OnTime</code> scheduling for watchdog and deferred work; use host enumerators (<code>DQ_Profile_RowEnumerator_*</code>) to stream rows; use <code>AtomicWrite</code> for fallback writes. The code uses <code>ThisWorkbook.name</code> in <code>OnTime</code> calls and expects host wiring for public schedule callbacks. <br><strong>Tests & host gates:</strong> cross-bitness testing (32-bit vs 64-bit), PQ-bound worker tests, and OnTime wiring verification. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Security, PII &amp; evidence governance (profile)</code> — enforced rules (code-accurate)</strong><br><strong>Principles implemented in code:</strong> UI artifacts redacted by default (<code>DQ_Profile_SanitizeRow*</code> used on samples); evidence stored only via <code>DQ_Evidence_Store</code> after two-person approval check in <code>SanitizeAndEvidence</code>; audits only carry <code>paramsHash</code> and <code>evidenceRef</code>; <code>ComputeSamplingSeed</code> avoids raw cell values. Module logs and audits sensitive flows for compliance. <br><strong>Tests:</strong> static analyzer gates, evidence approval flow tests, encrypted evidence round-trip. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>CI &amp; Golden Governance for profile</code> — required tests & gates (code-accurate)</strong><br><strong>Code expectations:</strong> deterministic canonicalization (<code>MOD_JSON_StringifyCanonical</code> used everywhere), <code>profileHash</code> parity for fixtures, test hooks guarded by <code>DQ_Config_IsTestMode</code>, and <code>RegisterProfileUnitTestHook</code> emits audit anchors for CI runs. CI must include golden parity across locales and bitness. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Failure modes &amp; incident runbook</code> — canonical incidents & mitigation (code-accurate)</strong><br><strong>Code-observable failure modes:</strong><br>1. Audit append failure → code logs and the orchestrator marks degraded and emits <code>dq_profile.audit.fail</code>. <br>2. Job persist failure → code falls back to atomic write to <code>MOD_EXPORT_FallbackDir</code> and emits <code>dq_profile.job.persist.fallback</code>. <br>3. Artifact persist partial failure → <code>PersistProfileArtifacts</code> returns error and early abort. <br>4. Watchdog timeout → <code>dq_profile.timeout</code> audit and cooperative cancellation token set. <br><strong>Forensics artifacts (code paths):</strong> outputs created by <code>AssembleProfileDescriptor</code> and <code>PersistProfileArtifacts</code>, plus <code>audit</code> rows emitted through <code>EmitAuditRaw</code>. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Operator recovery checklist</code> — practical steps (aligned to code behavior)</strong><br>1. Capture <code>correlationId</code> from UI or <code>dq_profile.started</code> audit. <br>2. Inspect <code>audit_tail</code> for <code>dq_profile.*</code> audit rows emitted by <code>EmitAuditRaw</code>/<code>EmitProfileAudit</code>. <br>3. Check fallback artifact path from <code>PersistProfileArtifacts</code> <code>fallbackPath</code>. <br>4. For hash mismatches re-run <code>ProfileTable</code> in test-mode using <code>RegisterProfileUnitTestHook</code> to reproduce. <br>5. For suspected PII exposure follow evidence workflow and compliance as per module comments. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Acceptance criteria &amp; release gates (profile)</code> — dev/CI checklist (code-accurate)</strong><br>1. Unit + integration + golden tests pass for <code>ComputeColumnMetrics</code>, <code>sampleRows</code>, <code>AssembleProfileDescriptor</code>, and <code>PersistProfileArtifacts</code>. <br>2. <code>dq_profile</code> audit emitted and <code>EmitProfileAudit</code> verified on sample runs. <br>3. Deterministic <code>profileHash</code> parity for canonical fixtures using <code>MOD_JSON_StringifyCanonical</code>. <br>4. No forbidden API references for UI-thread IO. <br>5. Evidence encryption + approval flows validated. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Performance budgets &amp; SLOs</code> — targets & remediation (implementation-aligned)</strong><br><strong>Suggested budgets used by code paths:</strong> inline median <50ms for tiny tables (<100 rows); inline soft-budget <2s up to 10k rows governed by <code>INLINE_BUDGET_MS</code>; watchdog uses <code>WATCHDOG_CHECK_INTERVAL_SEC</code> and cancels runs over budget. Job persist latency must be low (persist via <code>CORE_JobScheduler_Persist</code>) and artifact persist fallback handled via <code>AtomicWrite</code>. <br><strong>Remediation:</strong> fallback to job scheduling or reduce sample size. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Operator UX &amp; triage notes</code> — recommended UI elements (implementation-aligned)</strong><br>UI should present <code>correlationId</code>, preview with redaction (built by <code>BuildUiPreview</code>), "Request Evidence" flow invoking <code>SanitizeAndEvidence</code> approval, and recovery commands referencing fallback artifact paths and job ids emitted by the code. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong><code>Appendices — schemas, templates, owners</code> — (implementation references)</strong><br>Module expects canonical <code>profile_summary.json</code> and <code>profile_manifest.json</code> schemas consumed by <code>PersistProfileArtifacts</code> and <code>DQ_Evidence_Store</code>. <code>OWNERS.md</code> and release manifests referenced in top-of-module comments must be kept in artifact store for compliance. </td></tr><tr><td data-label="DQ_Profile — Per-function Expert Technical Breakdown"> <strong>Verification performed across nine critical dimensions (code-accurate):</strong> determinism (seed/sample/hash), audit coverage (audit row schema & prevHash via <code>EmitAuditRaw</code>/<code>EmitProfileAudit</code>), PII and evidence handling (SanitizeAndEvidence + approval), inline vs scheduled decision flow (EstimateProfileCost + JobSchedulerIntegration), canonical manifest hashing (SerializeCanonical + ComputeSHA256), atomic persistence semantics (AtomicWrite via host <code>UTIL_AtomicWrite</code>), watchdog & cancellation (SafeProfileTimeoutWatchdog_*), CI/golden gating (RegisterProfileUnitTestHook + canonical JSON), and operator recovery completeness. Every function above maps to the actual VBA implementations and host calls present in the module source; tests indicated are aligned to behavior implemented in the code. </td></tr></tbody></table></div><div class="row-count">Rows: 41</div></div><div class="table-caption" id="Table10" data-table="Docu_0176_10" style="margin-top:2mm;margin-left:3mm;"><strong>Table 10</strong></div>
<div class="table-wrapper" data-table-id="table-10"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by DQ_Rules — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">DQ_Rules — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Module Purpose & Scope (canonical)</strong><br><code>DQ_Rules</code> is the authoritative, deterministic rule engine for DQGuard. Responsibilities: ingest/validate/authorize rule manifests; compile rule expressions into sandboxed artifacts; build runtime indices and dependency graphs; evaluate record-level and dataset-level rules; produce validation artifacts and evidence references; produce remediation hints and handler mapping; integrate with job scheduler for heavy workloads; support safe registration, hot-swap, and migration; enforce RBAC & two-person approvals for destructive/regulatory actions; provide operator diagnostics, telemetry, and CI hooks. <strong>Non-goals:</strong> direct workbook mutation (duty of modRemediation/modExport), secrets storage (modSecurity), remote telemetry upload (audited uploader module). All material actions create append-only audit rows referencing <code>rulesHash</code> and <code>configHash</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Primary Invariants (must / shall)</strong><br>1. <strong>Determinism:</strong> identical inputs + configHash + rulesHash → identical outputs (ordering, tie-breakers, representative selection). Use canonical JSON, seeded RNG, deterministic partitioning. <br>2. <strong>Stable identifiers:</strong> each rule has immutable <code>ruleId</code>; updates change <code>ruleVersion</code> and <code>rulesHash</code>. <br>3. <strong>Auditability:</strong> every user-initiated action and persisted job emits a <code>dq_validation</code> or module audit with <code>correlationId</code>. Evidence artifacts referenced by <code>evidenceRef</code> are encrypted and RBAC-protected. <br>4. <strong>Fail-safe safety:</strong> critical signature/schema errors reject new rule-sets and keep previous active set; regulated rules are fail-closed if signature invalid. <br>5. <strong>No PII in UI:</strong> UI strings and audit <code>userHint</code> fields must not contain PII. Full sanitized evidence stored encrypted with <code>evidenceRef</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Canonical Artifacts & Hashing</strong><br><code>rules.json</code> (canonicalized) → <code>rulesHash = sha256(canonical_json)</code>. <br><code>compiledRules/&lt;rulesHash&gt;/</code> directory holds compiled bytecode/AST plus <code>compileManifest.json</code>. <br><code>validation_report_{runId}.json</code> with <code>reportHash</code>. <br><code>evidence/&lt;evidenceRef&gt;.zip</code> encrypted evidence bundle. <br>All artifacts include <code>artifact.checksum.sha256</code> in metadata and audit rows. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Security & Forbidden APIs (enforced)</strong><br>Disallowed in rules/compilation/runtime: raw file reads/writes; raw sockets; spawning processes; unbounded synchronous disk IO on UI thread; direct COM/Workbook mutation; direct plaintext secret reads; use of OS env sensitive keys. Evidence and token access only via <code>modSecurity.getEphemeralToken()</code> with audit fingerprint. CI static analyzer rejects forbidden constructs and blacklisted API references. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Performance Budgets & SLOs</strong><br>- Inline minimal path median <50ms (UI). <br>- Per-record eval median <10ms for light rules. <br>- Inline handler default timeout 5s; per-rule soft budget (default 50ms). <br>- Job persist latency SLO <2s. <br>Engine must degrade gracefully: sampling, segmenting, or persisting jobs for heavy operations. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>High-Level Function Map</strong><br><code>LoadRuleSet(source)</code> — manifest ingestion & verification.<br><code>ValidateRuleId(ruleId)</code> — canonical guard and metadata lookup.<br><code>CompileRuleExpressions(rule)</code> — parse/compile to sandboxed artifact.<br><code>BuildRuleIndex(ruleSet)</code> — field map, dependency graph, evaluation order.<br><code>EvaluateRecord(ruleIndex,row,context)</code> — record-level deterministic evaluation.<br><code>EvaluateCrossField(ruleIndex,snapshot,context)</code> — dataset-level/windowed rules.<br><code>EvaluateBatch(ruleIndex,snapshot,options)</code> — vectorized orchestrator, sampling & segmentation.<br><code>MapRuleToHandler(ruleId)</code> — remediation mapping and owner resolution.<br><code>SafeInvokeRule(compiledRule,input,cid,token)</code> — guarded helper invocation.<br><code>EmitValidationAudit(cid,summary,evidenceRefs)</code> — canonical audit anchor.<br><code>RegisterRule(ruleJson,operatorId,persist=false)</code> — controlled registration.<br><code>RefreshRules()</code> — live rebind and preview.<br><code>HotSwapRules(newRulesJson,operatorId,approvals)</code> — transactional emergency patching.<br><code>EnableRule/DisableRule</code> — runtime toggles with RBAC.<br><code>ValidateRulePermissions(userId,ruleMeta)</code> — permission checks.<br><code>RuleTestingHarness(hook)</code> — CI deterministic harness.<br><code>SafeRuleTimeoutWatchdog(token,cid)</code> — cooperative cancellation & escalation.<br><code>JobSchedulerIntegration(jobDescriptor)</code> — canonical job persist & handoff.<br><code>Shutdown()</code> — graceful unload & snapshot. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>LoadRuleSet(source)</code> — purpose, contract, steps, pitfalls, and tests</strong><br><strong>Purpose:</strong> deferred ingestion of <code>rules.json</code> or manifest; canonicalize, validate, attach owners, compute <code>rulesHash</code>, verify signature, produce canonical <code>RuleSet</code> internal model. <br><strong>Code-accurate contract & steps (matches VBA):</strong><br>• Accepts either a file path or a JSON blob (<code>source</code>). <br>• If <code>source</code> is a path (checked via <code>FileSystemObject.FileExists</code>) it reads UTF-8 text with <code>ReadTextFileUtf8_Local</code>. <br>• Parses JSON by attempting <code>Application.Run(&quot;DQ_Config.ParseJson&quot;, jsonText)</code> then falling back to <code>DQ_Config.ParseJsonSafeReturn</code>. <br>• If parsing fails -> return <code>{status:&quot;invalid&quot;, error:&quot;parse_failed&quot;}</code>. <br>• Canonicalize via <code>DQ_Config.CanonicalizeJson</code> or <code>DQ_Config.ConvertToJsonSafe</code> fallback; this string used for hashing. <br>• Compute <code>rulesHash</code> by calling <code>DQ_Config.ComputeConfigHash</code> if available, else <code>DQ_Utilities.ComputePayloadHash</code>; final fallback <code>&quot;sha256:unavailable&quot;</code>. <br>• Validate shape: code explicitly requires top-level <code>rules</code> key; if missing returns <code>missing_rules_key</code>. <br>• Expects <code>rules</code> as a <code>Collection</code>; iterates each item: skips non-dictionary entries; requires <code>ruleId</code>; deep-copies each rule (via <code>DeepCopyDictLocal</code>), compiles expressions with <code>CompileRuleExpressions</code> and stores a <code>compiled</code> artifact (or empty dictionary on failed compile). <br>• Ensures default <code>enabled = True</code> if absent; inserts/overwrites <code>gRuleSet(ruleId) = ruleMeta</code>. <br>• Builds index via <code>BuildRuleIndex(gRuleSet)</code> and saves <code>gRulesHash = rulesHash</code>. <br>• Emits an audit util event using <code>DQ_Utilities.AuditEmitUtilEvent</code> with a correlation id <code>CreateCorrelationIdSafe(MODULE_NAME)</code>: event <code>rules.load</code> and <code>(left$(rulesHash,16))</code> as short fingerprint. <br>• Returns <code>{status:&quot;ok&quot;, ruleCount: gRuleSet.count, rulesHash: rulesHash}</code> on success; on trapped errors returns <code>{status:&quot;error&quot;, error: err.Description}</code>. <br><strong>Pitfalls & notes (code-accurate):</strong><br>• Relies heavily on host <code>Application.Run</code> calls; missing host functions degrade to safe fallbacks. <br>• Parsing expects <code>Collection</code>/<code>Dictionary</code> COM types; nonstandard JSON shapes can be rejected. <br>• Compilation step is best-effort: compiled artifact may be empty dictionary when compile warnings/errors exist. <br><strong>Tests/CI:</strong> schema fuzzing, duplicate id negative tests, signature tamper tests, canonicalization round-trip tests, large-manifest performance. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ValidateRuleId(ruleId)</code> — usage, checks, and outputs</strong><br><strong>Purpose:</strong> canonical validation across UI and runtime. <br><strong>Code-accurate checks implemented:</strong><br>• Reject empty <code>ruleId</code> (<code>RUL_ID_EMPTY</code>). <br>• Max length 128 (<code>RUL_ID_TOO_LONG</code>). <br>• Allowed character class enforced by VBScript <code>RegExp</code> pattern <code>^[A-Za-z0-9\-@@ESC_UND@@\.]+$</code> -> <code>RUL_ID_INVALID_CHARS</code> if fails. <br>• Reserved names array (<code>&quot;default&quot;,&quot;all&quot;,&quot;system&quot;</code>) checked case-insensitively -> <code>RUL_ID_RESERVED</code> if matched. <br>• On success returns Dictionary <code>{allowed:True, errorCode:&quot;&quot;, userHint:&quot;&quot;}</code>; on failure returns <code>{allowed:False, errorCode, userHint}</code>. <br><strong>Error handling:</strong> traps exceptions and returns <code>RUL_ID_VALIDATION_ERR</code>. <br><strong>Tests:</strong> id fuzzing, max-length boundary, reserved-word detection, ensure <code>userHint</code> contains no PII. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>CompileRuleExpressions(ruleMeta)</code> — grammar, compile-time checks, sandboxing</strong><br><strong>Purpose (code-accurate):</strong> produce a compiled-artifact dictionary for a single rule meta (fingerprint, referencedFields array, estimatedCost, requiresWindow, compileWarnings). <br><strong>Implementation details from code:</strong><br>• Reads <code>expression</code> from <code>ruleMeta(&quot;expression&quot;)</code> if present, else empty string. <br>• Populates outputs: <code>originalExpression</code>, <code>referencedFields</code> (array), <code>estimatedCost</code> default <code>&quot;light&quot;</code>, <code>requiresWindow</code> default <code>False</code>. <br>• Adds <code>compileWarnings</code> as a <code>Collection</code>. <br>• Performs static-forbidden-API scan using VBScript <code>RegExp</code> with pattern <code>(CreateObject|WScript\.|Shell|Scripting\.FileSystemObject|ADODB\.|UrlDownloadToFile|ShellExecute|Exec()</code>; if any match, it sets compileWarnings to include <code>&quot;ERR_FORBIDDEN_API&quot;</code>, sets <code>compiledFingerprint=&quot;ERR_FORBIDDEN_API&quot;</code>, and returns early. <br>• Detects regex-like constructs via <code>RegExp</code> pattern <code>RegExp|LIKE|MATCHES|\/.+\/</code> and marks <code>estimatedCost=&quot;medium&quot;</code> and adds warning <code>&quot;WARN_REGEX_PRESENT&quot;</code>. <br>• Detects window constructs via <code>InStr(...,&quot;over(&quot;)</code> or <code>&quot;partition by&quot;</code> to set <code>requiresWindow=True</code> and <code>estimatedCost=&quot;heavy&quot;</code>. <br>• Collects referenced fields by running a token <code>RegExp</code> <code>(?&gt;\b|)([A-Za-z0-9_\-\.]+)(?:\b|)</code> and gathers unique tokens into <code>referencedFields</code> array. <br>• Computes deterministic fingerprint by calling <code>DQ_Config.ComputeConfigHash(expr)</code> if available, else <code>DQ_Utilities.ComputePayloadHash(expr)</code> and falls back to <code>&quot;hash_unavailable&quot;</code> on error. <br>• Returns a <code>Scripting.Dictionary</code> with <code>originalExpression</code>, <code>referencedFields</code> (string array), <code>estimatedCost</code>, <code>requiresWindow</code>, <code>compileWarnings</code>, <code>compiledFingerprint</code>. On error returns <code>Nothing</code>. <br><strong>Static security checks & heuristics (code-accurate):</strong> regex heuristics and forbidden API detection are explicit; there is no full AST compile in the module — compiled artifact is a preflight descriptor (the runtime evaluator uses tokenization). <br><strong>Tests:</strong> parser fuzz, forbidden-API enforcement, regex complexity heuristics; verify <code>compiledFingerprint</code> stability across runs with same host helpers. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>BuildRuleIndex(ruleSet)</code> — dependency graph & ordering</strong><br><strong>Purpose (code-accurate):</strong> build lookup maps used at evaluation time: <code>byField</code>, <code>bySeverity</code>, <code>byType</code>, <code>dependencyGraph</code>, and <code>evaluationOrder</code>. <br><strong>Implementation details from code:</strong><br>• Iterates <code>ruleSet.keys</code>. For each ruleId <code>k</code> obtains <code>meta = ruleSet(k)</code> and tries to extract <code>referencedFields</code> from <code>meta(&quot;compiled&quot;)(&quot;referencedFields&quot;)</code>. For each referenced field <code>f</code> it creates or appends to a <code>Collection</code> at <code>byField(f)</code> containing ruleId <code>k</code>. <br>• Buckets rules into <code>bySeverity(sev)</code> where <code>sev = meta(&quot;severity&quot;)</code> or <code>&quot;INFO&quot;</code> default. <br>• Classifies <code>byType(rtype)</code> using <code>meta(&quot;requiresWindow&quot;)</code> or explicit <code>meta(&quot;type&quot;)</code>; default <code>&quot;record&quot;</code>. <br>• Builds <code>dependencyGraph(ruleId)</code> by searching <code>meta(&quot;expression&quot;)</code> for <code>rule:foo</code> patterns via <code>RegExp</code> and adding referenced ruleIds to the collection. <br>• Produces <code>evaluationOrder</code> by collecting all ruleIds into an array <code>allRules()</code> and sorting via <code>QuickSortRulesByPriority</code> which uses <code>RuleCompare</code>. <code>RuleCompare</code> uses <code>GetRulePriorityScore</code> (numeric <code>priority</code> field), then <code>SeverityRank</code>, then lexicographic <code>StrComp(..., vbTextCompare)</code> tie-breaker. The result is added into the <code>evaluationOrder</code> Collection in the sorted sequence. <br>• Returns a dictionary <code>idx</code> with keys <code>byField</code>, <code>bySeverity</code>, <code>byType</code>, <code>dependencyGraph</code>, and <code>evaluationOrder</code>. If <code>ruleSet</code> is <code>Nothing</code> returns an empty index. <br><strong>Cycle handling (code-level):</strong> cycles are discovered only as dependency edges; the code does not perform full topological cycle-break resolution during index build beyond recording the graph — cycle detection should be handled by higher-level governance. <br><strong>Tests:</strong> cycle detection tooling, ordering stability, bucket correctness, index build cost for large sets. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>QuickSortRulesByPriority</code> / <code>RuleCompare</code> / Priority helpers</strong><br><strong>Purpose (code-accurate):</strong> deterministic sort used by <code>BuildRuleIndex</code>. <br><strong>Behavior:</strong><br>• <code>QuickSortRulesByPriority</code> implements an in-place quicksort (pivot = middle) over an array of ruleId strings using <code>RuleCompare</code> as comparator. <br>• <code>RuleCompare(a,b)</code> calls <code>GetRulePriorityScore</code> (reads <code>meta(&quot;priority&quot;)</code> numeric, default 0), then <code>SeverityRank</code> mapping (<code>CRITICAL</code>=4,...), and finally lexicographic case-insensitive compare. Returns -1/0/1 per standard contract. <br>• <code>GetRulePriorityScore</code> and <code>GetRuleSeverity</code> safely handle missing rule entries and return defaults. <br><strong>Tests:</strong> comparator invariants, stable ordering under equal scores. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>SafeInvokeRule(compiledRule,row,correlationId,cancellationToken)</code> — guarded evaluator (tokenized)</strong><br><strong>Purpose (code-accurate):</strong> evaluate a compiled artifact or rule meta deterministically and safely using a small, host-independent evaluator; do not perform <code>Eval</code> or host calls. <br><strong>Contract & implementation notes (from code):</strong><br>• Returns a <code>Scripting.Dictionary</code> with <code>status</code>, <code>outcome</code> (Boolean), <code>explain</code> and <code>errorCode</code>. <br>• If <code>compiledRule</code> is <code>Nothing</code> returns <code>status=&quot;error&quot;, errorCode=&quot;NO_COMPILED_RULE&quot;</code>. <br>• Extracts <code>originalExpression</code> or <code>expression</code> into <code>expr</code>. <br>• Tokenizes expression using <code>TokenizeExpressionForEval</code> (crude whitespace/parenthesis splitter that preserves quoted strings). <br>• Calls <code>EvaluateTokenizedExpr(tokens, row, res)</code> which implements a small interpreter: handles binary comparisons (<code>=,==,!=,&gt;,&lt;,&gt;=,&lt;=</code>), <code>CONTAINS(field,&quot;substr&quot;)</code>, <code>REGEX(field,&quot;pattern&quot;)</code>, numeric comparisons, boolean <code>AND/OR</code> left-to-right. Parentheses are recognized as tokens but nested evaluation is not fully recursive — the tokenization strategy and <code>EvaluateTokenizedExpr</code> assume simple flattened expressions. <br>• <code>EvaluateSimpleTerm</code> handles parsing of terms, safe field lookup via <code>GetFieldValueForEval</code>, literal parsing via <code>ParseLiteralForEval</code>, and uses <code>VBScript.RegExp</code> for <code>REGEX</code> tests. <br>• On runtime exception the function returns <code>status=&quot;error&quot;, errorCode=&quot;DQ_RULE_RUNTIME_EXCEPTION&quot;</code> and sets <code>explain=err.Description</code>. <br><strong>Security & sandbox:</strong> no <code>Application.Run</code>, no <code>CreateObject</code> in expression evaluation; regex uses VBScript <code>RegExp</code>. <br><strong>Observability:</strong> returns <code>explain=&quot;evaluated&quot;</code> on success and includes <code>outcome</code> Boolean. <br><strong>Tests:</strong> expression tokenization parity, regex tests (including invalid patterns), boolean logic permutations, numeric comparison edge-cases. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>TokenizeExpressionForEval</code> / <code>EvaluateTokenizedExpr</code> / <code>EvaluateSimpleTerm</code> — evaluator internals</strong><br><strong>Behavior (code-accurate summary):</strong><br>• <code>TokenizeExpressionForEval</code> loops chars preserving quoted strings and splitting on whitespace and parentheses; returns <code>String()</code> array; preserves <code>&quot;</code> quoted strings. <br>• <code>EvaluateTokenizedExpr</code> implements a left-to-right evaluator where terms are combined by <code>AND</code>/<code>OR</code> tokens (no full operator precedence beyond left-to-right and explicit token parsing). It uses <code>EvaluateSimpleTerm</code> to compute each term. <br>• <code>EvaluateSimpleTerm</code> supports <code>CONTAINS(field,&quot;x&quot;)</code>, <code>REGEX(field,&quot;pat&quot;)</code>, standard comparisons, and a fallback that treats lone tokens as truthy field existence checks. It uses helper <code>CleanArg</code>, <code>ParseLiteralForEval</code>, and <code>GetFieldValueForEval</code> which does case-insensitive dictionary lookup for row fields. <br><strong>Edge cases & safe-fail semantics:</strong> malformed expressions return <code>False</code> rather than throwing; <code>REGEX</code> uses <code>ignoreCase = True</code> by default. <br><strong>Tests:</strong> quoted string parsing, parentheses token edge-cases, empty tokens, numeric-vs-string compare tests. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateRecord(ruleIndex,row,options)</code> — inline safe evaluation</strong><br><strong>Purpose (code-accurate):</strong> run relevant record-level rules in deterministic order and return an ordered Collection of <code>ValidationResult</code> dictionaries. <br><strong>Runtime implemented behavior:</strong><br>• Ensures <code>InitDQRules</code> and ensures <code>gRuleIndex</code> exists (calls <code>BuildRuleIndex(gRuleSet)</code> if <code>Nothing</code>). <br>• Candidate selection: iterates <code>row.keys</code> and for each key, if <code>gRuleIndex(&quot;byField&quot;)</code> has that field, collects associated ruleIds into <code>candidateRules</code> Collection. <br>• If <code>candidateRules</code> empty, falls back to evaluating all IDs from <code>gRuleIndex(&quot;evaluationOrder&quot;)</code>. <br>• Deduplicates candidates into <code>seen</code> (<code>Scripting.Dictionary</code>) preserving insertion order into <code>orderedCandidates</code>. <br>• Builds <code>orderedMap</code> from <code>evaluationOrder</code> positions for stable sorting. <br>• Converts <code>orderedCandidates</code> into a <code>sortedCandidates()</code> string array and insertion-sorts it using <code>CompareRuleOrder</code> which uses <code>orderedMap</code>. <br>• For each sorted candidate <code>rid</code>: checks <code>gRuleSet.Exists(rid)</code>, checks <code>rmeta(&quot;enabled&quot;)</code>, gets <code>compiled = rmeta(&quot;compiled&quot;)</code> (if exists) and calls <code>SafeInvokeRule(compiled, row, CreateCorrelationIdSafe(MODULE_NAME))</code>. Produces a <code>vr</code> dictionary for each rule containing <code>ruleId</code>, <code>outcome</code>, <code>severity</code>, <code>explain</code>, <code>status</code> and appends to results Collection. <br>• Returns results Collection. Exceptions are cleared and an empty results set returned on error. <br><strong>Budgeting & timeouts:</strong> per-rule soft budgets are relied on by external watchdog <code>SafeRuleTimeoutWatchdog</code> (cooperative) — <code>EvaluateRecord</code> itself does not forcibly kill evaluation but safe-invoker design minimizes duration. <br><strong>Tests:</strong> candidate selection correctness, stable ordering, enable/disable behavior, exception propagation mapping. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>CompareRuleOrder(a,b,orderedMap)</code> — deterministic tie-break comparator</strong><br><strong>Purpose (code-accurate):</strong> given two ruleIds returns ordering using <code>orderedMap</code> if available, else lexicographic fallback. <br><strong>Behavior:</strong> checks <code>orderedMap.Exists(a)</code>/<code>b</code> and compares numeric indices; if neither exists falls back to case-insensitive <code>StrComp</code>. Exceptions return <code>0</code>. <br><strong>Tests:</strong> correctness when orderedMap partially populated, fallback cases. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateCrossField(ruleIndex,snapshot,options)</code> — dataset-level & windowed evaluation</strong><br><strong>Purpose (code-accurate):</strong> run windowed / cross-field rules over a <code>Collection</code> snapshot and return group-level validation results. <br><strong>Implementation notes from code:</strong><br>• If <code>gRuleIndex</code> is <code>Nothing</code> builds it. If <code>gRuleIndex(&quot;byType&quot;)</code> lacks <code>&quot;windowed&quot;</code> returns empty results. <br>• Iterates windowed rule ids and for simple patterns (code uses substring checks for <code>&quot;distinct&quot;</code> / <code>&quot;unique&quot;</code>) performs an example deduplication check: it determines the first referenced field from <code>rmeta(&quot;compiled&quot;)(&quot;referencedFields&quot;)(0)</code>, counts duplicates using a <code>Scripting.Dictionary</code> and emits a <code>ValidationResult</code> dictionary <code>{ruleId, severity, violations}</code> where <code>violations</code> is number of duplicate keys found. <br>• This implementation is intentionally lightweight in the module: heavy windowed logic and complex aggregations are expected to be offloaded to job scheduler. <br><strong>Degraded path & notes:</strong> module emits summary <code>dq_validation.crossfield</code> audits externally; heavy workloads should be persisted and run in workers. <br><strong>Tests:</strong> duplicate detection, empty snapshot, referencedFields missing. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EvaluateBatch(ruleIndex,snapshot,options)</code> — vectorized driver</strong><br><strong>Purpose (code-accurate):</strong> orchestrate inline or scheduled batch evaluation and produce a <code>ValidationReport</code> dictionary. <br><strong>Behavior implemented in code:</strong><br>• Generates <code>reportId</code> via <code>CreateCorrelationIdSafe(&quot;batch&quot;)</code>, timestamps via <code>Now</code>. Adds <code>rulesHash = gRulesHash</code>. <br>• If <code>options(&quot;mode&quot;) = &quot;job&quot;</code> the function builds a <code>jobDesc</code> dictionary including <code>jobId</code>, <code>jobType=&quot;rule_eval&quot;</code>, <code>rulesHash</code>, <code>paramsHash</code> (seeded using <code>WorksheetFunction.RandBetween</code> fallback), timestamp, and attempts to persist via <code>DQ_Utilities.AtomicWrite</code> (best-effort). On success returns <code>{status:&quot;scheduled&quot;, jobId}</code>; on atomic-write failure returns <code>{status:&quot;failed&quot;, error:&quot;atomic_write_failed&quot;}</code>. <br>• Inline mode: iterates rows 1..snapshot.count, calls <code>EvaluateRecord(gRuleIndex,row,options)</code> for each row, accumulates violation counts and severityCounts into summary dictionary.<br>• Returns <code>{status:&quot;complete&quot;, summary:{rowCount, violations, severityBreakdown}, duration_ms}</code> on success. On error returns <code>{status:&quot;error&quot;, error:err.Description}</code>. <br><strong>Idempotency & job descriptors:</strong> job descriptors produced include <code>reportId</code> and use <code>AtomicWrite</code> persistence strategies described elsewhere. <br><strong>Failure handling:</strong> inline overrun should be turned into job scheduling by caller; module persists partial artifacts on exception. <br><strong>Tests:</strong> end-to-end batch with small snapshot, job-mode persist success/failure, idempotency token presence. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>MapRuleToHandler(ruleId)</code> — remediation mapping & owner resolution</strong><br><strong>Purpose (code-accurate):</strong> provide remediation suggestions and owner metadata derived from <code>gRuleSet</code>. <br><strong>Behavior from code:</strong> looks up <code>gRuleSet(ruleId)</code>, returns a <code>Scripting.Dictionary</code> with <code>suggestedRemediations</code> (array containing <code>CreateRemediationSuggestion(&quot;flag&quot;,0.6)</code>), <code>primaryHandler</code>, <code>owner</code>, <code>approvalPolicy</code>, <code>regulatedImpact</code>. Falls back <code>owner=&quot;unassigned&quot;</code> when <code>owner</code> missing. On missing <code>ruleId</code> returns <code>{error:&quot;RUL_NOT_FOUND&quot;}</code>. <br><strong>CreateRemediationSuggestion:</strong> returns small dict <code>{type,confidence,previewFn}</code> used by callers. <br><strong>Tests:</strong> mapping presence, fallback owner paths, regulated flag propagation. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RegisterRule(ruleJson,operatorId,persist=false)</code> — authoring & controlled registration</strong><br><strong>Purpose (code-accurate):</strong> parse a single rule JSON, validate ruleId, compile expressions, upsert into <code>gRuleSet</code>, optionally persist to <code>rules.json</code> via atomic write. <br><strong>Detailed behavior:</strong><br>• Parses JSON via <code>DQ_Config.ParseJsonSafeReturn</code>; if parse fails returns <code>{status:&quot;invalid&quot;, error:&quot;parse_failed&quot;}</code>. <br>• Requires <code>ruleId</code> field. Validates <code>ruleId</code> via <code>ValidateRuleId</code>; rejects with <code>{status:&quot;rejected&quot;, error, userHint}</code> on validation failure. <br>• Compiles via <code>CompileRuleExpressions(parsed)</code>; on compile failure returns <code>{status:&quot;failed_compile&quot;}</code>. <br>• Sets <code>registeredBy</code>, <code>registeredAt</code> timestamp, upserts <code>gRuleSet(rid)=parsed</code>. <br>• If <code>persist=True</code> the code attempts to read existing rules manifest from <code>GetRulesPathSafe()</code>, parse it, append/replace the rule in the <code>rules</code> collection, serialize via <code>ConvertToJsonSafeLocal</code> and call <code>DQ_Utilities.AtomicWrite</code> with <code>rulesPath</code>. The code catches errors and sets <code>out(&quot;persist&quot;)=&quot;failed&quot;</code> on persist failures. <br>• Returns <code>{status:&quot;registered&quot;, persist:&quot;ok&quot;|&quot;failed&quot;}</code>. On unexpected errors returns <code>{status:&quot;error&quot;, error:err.Description}</code>. <br><strong>Idempotency:</strong> identical JSON upserts overwrite existing rule entry. <br><strong>Tests:</strong> parse failure, validation rejection, atomic persist path success & failure, owner / signature checks (higher-level). </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>FileExistsLocal</code>, <code>ReadTextFileUtf8_Local</code>, <code>WriteTextFileUtf8_Local</code> — IO helpers (safe-fail)</strong><br><strong>Purpose (code-accurate):</strong> small, robust UTF-8 file helpers with fallbacks. <br><strong>Implementation details from code:</strong><br>• <code>FileExistsLocal(path)</code> uses <code>CreateObject(&quot;Scripting.FileSystemObject&quot;).FileExists(path)</code> and returns Boolean. <br>• <code>ReadTextFileUtf8_Local(path)</code> uses <code>ADODB.Stream</code> configured <code>Type=2, Charset=&quot;utf-8&quot;</code>, <code>LoadFromFile</code>, <code>ReadText</code>; on error returns empty string and clears error. <br>• <code>WriteTextFileUtf8_Local(path,content)</code> attempts ADODB.Stream write with Charset UTF-8 and <code>SaveToFile</code>; on error it falls back to VB <code>Open ... For Binary Access Write</code> + <code>Put</code> fallback and clears the error. <br><strong>Notes:</strong> these helpers intentionally swallow low-level IO errors and surface empties so callers can implement policy. <br><strong>Tests:</strong> read/write roundtrip for UTF-8 content and fallback branch simulation. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ConvertToJsonSafeLocal</code> / <code>ManualSerializeLocal</code> / <code>JsonEscapeLocal</code> / <code>GetSortedKeysLocal</code> — JSON serializer fallbacks</strong><br><strong>Purpose (code-accurate):</strong> provide a safe serialization path when <code>DQ_Config.ConvertToJsonSafe</code> is unavailable. <br><strong>Behavior:</strong><br>• <code>ConvertToJsonSafeLocal</code> first tries <code>Application.Run(&quot;DQ_Config.ConvertToJsonSafe&quot;, v)</code> and on error uses <code>ManualSerializeLocal</code>. <br>• <code>ManualSerializeLocal</code> implements minimal deterministic serialization for <code>Dictionary</code>, <code>Collection</code>, strings, numbers, booleans, <code>Null</code>, and unknown types (forced to string). Dictionaries serialize keys in sorted order via <code>GetSortedKeysLocal</code> (which quicksorts an array of keys using <code>QuickSortStringArrayLocal</code>). <br>• <code>JsonEscapeLocal</code> escapes <code>\</code>, <code>&quot;</code>, newline, carriage return and tab. <br><strong>Notes:</strong> the manual serializer is intentionally minimal and deterministic; used mainly for persistence fallback and audit payloads. <br><strong>Tests:</strong> roundtrip with simple dictionaries and collections, key ordering invariants. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook(hookName, hookMeta)</code> & <code>InvokeUnitTestHook(hookName, payload)</code> — CI hooks</strong><br><strong>Purpose (code-accurate):</strong> register and invoke test-time hooks used by CI and deterministic harnesses. <br><strong>Behavior from code:</strong><br>• <code>RegisterUnitTestHook</code> ensures <code>gUnitTestHooks</code> exists and upserts <code>gUnitTestHooks(hookName)=hookMeta</code>. Returns <code>True</code>. <br>• <code>InvokeUnitTestHook</code> returns <code>Empty</code> if hook missing. If <code>meta(&quot;macro&quot;)</code> present it attempts <code>Application.Run(meta(&quot;macro&quot;), payload)</code> and returns the macro's result if successful; otherwise returns <code>Empty</code>. <br><strong>Safety:</strong> registration is local-memory only and must be audited externally by caller. <br><strong>Tests:</strong> register/invoke happy path, macro absent or failing path. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>SafeRuleTimeoutWatchdog(startTime,softMs,hardMs,ruleId)</code> — cooperative watchdog</strong><br><strong>Purpose (code-accurate):</strong> cooperative watchdog that measures elapsed <code>Timer</code> runtime and emits timed audits when soft or hard thresholds are crossed; marks rule as <code>safety_disabled</code> on hard exceed. <br><strong>Behavior:</strong><br>• Computes <code>elapsed = CLng((Timer - startTime) * 1000)</code>. <br>• If <code>softMs &lt; elapsed &lt;= hardMs</code> emits <code>DQ_Utilities.AuditEmitUtilEvent</code> with <code>dq_rule.timeout</code> event, including <code>ruleId</code> and <code>elapsedMs</code>. <br>• If <code>elapsed &gt; hardMs</code> emits <code>dq_rule.hung</code>, sets <code>gRuleSet(ruleId)(&quot;safety_disabled&quot;)=True</code> if exists. Clears errors. <br><strong>Notes:</strong> cooperative — it does not forcibly abort running code; callers should check <code>safety_disabled</code>. <br><strong>Tests:</strong> soft & hard threshold triggers and metadata in emitted audit payloads. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>JobSchedulerIntegration(jobDescriptor)</code> — job persist & handoff</strong><br><strong>Purpose (code-accurate):</strong> persist canonical job descriptor to <code>jobs\{jobId}.job.json</code> using <code>AtomicWrite</code> and return persisted status. <br><strong>Implementation details:</strong><br>• Ensures <code>jobId</code> exists or creates one via <code>CreateCorrelationIdSafe(&quot;job&quot;)</code>. Constructs <code>dest</code> path by replacing <code>rules.json</code> suffix with <code>jobs\{jobId}.job.json</code> from <code>GetRulesPathSafe()</code>. Calls <code>EnsureFolderPathForAtomicWrite(dest)</code> then <code>ConvertToJsonSafeLocal(jobDescriptor)</code> and invokes <code>DQ_Utilities.AtomicWrite(dest, StrConv(payload, vbFromUnicode), ...)</code> with correlation and safe defaults. <br>• On <code>AtomicWrite</code> failures tries a fallback invocation and returns <code>{status:&quot;failed&quot;, error:&quot;atomic_write_failed&quot;}</code>; on success returns <code>{status:&quot;persisted&quot;, jobId}</code>. <br><strong>Tests:</strong> atomic write success/failure branches, idempotent re-run. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ShutdownDQRules()</code> / <code>Shutdown()</code> — snapshot & audit flush</strong><br><strong>Purpose (code-accurate):</strong> persist a minimal snapshot and emit a <code>rules.shutdown</code> audit. <br><strong>Behavior:</strong><br>• Builds JSON snapshot <code>{&quot;lastRulesHash&quot;:gRulesHash,&quot;lastRefreshTs&quot;:Now}</code> and writes it to <code>state_dq_rules_snapshot.json</code> next to <code>rules.json</code> via <code>WriteTextFileUtf8_Local</code>. <br>• Emits audit via <code>DQ_Utilities.AuditEmitUtilEvent</code> with event <code>rules.shutdown</code> and <code>snapshotPath</code>. <br>• Clears errors. <br><strong>Notes:</strong> designed to be safe during host shutdown; not guaranteed to flush remote audit uploader (handled by modAudit ordering). <br><strong>Tests:</strong> snapshot file content presence and <code>rules.shutdown</code> audit emission. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>DeepCopyDictLocal(src)</code> — deep copy via host helpers or JSON roundtrip</strong><br><strong>Purpose (code-accurate):</strong> return a deep copy of <code>src</code>. <br><strong>Behavior:</strong><br>• Attempts <code>Application.Run(&quot;DQ_Config.DeepCopyDict&quot;, src)</code>. <br>• If host helper missing or fails, serializes <code>src</code> via <code>ConvertToJsonSafeLocal</code> and reparses via <code>DQ_Config.ParseJsonSafeReturn</code>. If reparsed object is valid returns it; otherwise returns original <code>src</code> (best-effort fallback). <br><strong>Tests:</strong> ensure modifications to returned object do not mutate <code>src</code> when deep-copy succeeded. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ComputeParamHashLocal(txt)</code> / <code>ComputeParamHash</code> — local param hash wrapper</strong><br><strong>Purpose:</strong> compute stable param hash using host <code>DQ_Utilities</code> when available, else fallback to pseudo-random short string. <br><strong>Behavior:</strong> calls <code>Application.Run(&quot;DQ_Utilities.ComputeParamHash&quot;, txt)</code> and returns string; on error falls back to <code>WorksheetFunction.RandBetween</code> to return an 8-char numeric string and clears errors. <br><strong>Notes:</strong> used in audit payload fingerprints and safe-fail scenarios. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>ValidateRulePermissions(userId,ruleMeta)</code> — approvals & access control</strong><br><strong>Purpose (code-accurate):</strong> return permission object <code>{&#x27;allowed&#x27;, &#x27;requiredApprovals&#x27;, &#x27;denialReason&#x27;}</code>. <br><strong>Behavior implemented:</strong> if <code>ruleMeta(&quot;regulated&quot;)=True</code> then <code>allowed=False</code>, <code>denialReason=&quot;regulated_change_requires_approval&quot;</code>, and <code>requiredApprovals</code> includes <code>&quot;compliance&quot;</code> and <code>&quot;second_approver&quot;</code>. Otherwise <code>allowed=True</code>. <br><strong>Notes:</strong> this is a policy helper; actual enforcement and mapping to SSO/group membership performed elsewhere. <br><strong>Tests:</strong> regulated-flag true/false cases. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>MapRuleToHandler/Remediation helpers</code> — mapping & suggestions</strong><br><strong>Purpose (code-accurate):</strong> provide simple remediation suggestions and owner metadata. <br><strong>Behavior:</strong> returns minimal suggestion array with <code>CreateRemediationSuggestion(&quot;flag&quot;,0.6)</code>, default primary handler and owner pulled from metadata or <code>&quot;unassigned&quot;</code>, approvalPolicy from meta or <code>&quot;none&quot;</code>, regulatedImpact boolean. <br><strong>Tests:</strong> presence/absence of owner and approvalPolicy fallbacks. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>RegisterUnitTestHook</code> / <code>InvokeUnitTestHook</code> — test harness hooks</strong><br><strong>Purpose (code-accurate):</strong> test-only hook registration/invocation stored in-memory (<code>gUnitTestHooks</code>). <br><strong>Behavior:</strong> registration upserts hook meta and returns <code>True</code>; invocation attempts to call macro listed in <code>meta(&quot;macro&quot;)</code> via <code>Application.Run</code> with payload and returns macro result or <code>Empty</code>. <br><strong>Safety:</strong> designed for CI/DEV; production registration should be guarded externally. <br><strong>Tests:</strong> hook registration & macro invocation success/failure. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong><code>EnsureFolderPathForAtomicWrite(target)</code> — folder ensure helper</strong><br><strong>Purpose (code-accurate):</strong> compute <code>folder = Left(target, InStrRev(target, Application.PathSeparator)-1)</code> and create folder via <code>FileSystemObject.CreateFolder</code> when missing; safe-fails on error. <br><strong>Tests:</strong> target path with nested missing folders. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Observability & Auditing — mandated fields & chain</strong><br><strong>Mandate:</strong> every material user action or job persist must anchor to an audit row with <code>correlationId</code>. Audit rows include <code>payloadHash</code>, <code>prevHash</code> (if available), <code>configHash</code>, <code>rulesHash</code>. <code>modAudit</code> rotates and signs archives. <code>VerifyAuditChain</code> runs in CI/monitoring and blocks merges on mismatches. <br><strong>Primary row types:</strong> <code>rules.loaded</code>, <code>rules.load.invalid</code>, <code>dq_validation.batch</code>, sampled <code>dq_validation.record</code>, <code>job.persisted</code>, <code>rules.hotswap.applied/reverted</code>, <code>rules.enabled/disabled</code>, <code>rules.registered/failed</code>, <code>rules.migration.*</code>, <code>rules.shutdown</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Evidence model & access control</strong><br><strong>Evidence store:</strong> encrypted-at-rest, RBAC-protected. Evidence artifacts (samples, profile CSVs, compiled artifacts, smoke test outputs) stored as bundles with <code>evidenceRef</code>. Main audit only stores <code>evidenceRef</code> + <code>paramsHash</code>. Evidence access logged as <code>evidence.access</code> audit and requires approver roles; download tokens TTL-limited. For forensic export create <code>forensic_manifest.json</code> listing artifacts and SHA256 checksums. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Error taxonomy & operator messaging</strong><br><strong>Error catalog:</strong> <code>RUL_LOAD_SCHEMA_ERR</code>, <code>RUL_LOAD_DUP_ID</code>, <code>RUL_LOAD_SIG_INVALID</code>, <code>ERR_COMPILE_SYNTAX</code>, <code>ERR_FORBIDDEN_API</code>, <code>DQ_RULE_RUNTIME_*</code>, <code>ERR_RULE_HEAVY</code>, <code>JOB_PERSIST_FAIL</code>. <br><strong>UI messages:</strong> always short, PII-free, include <code>correlationId</code>, and a triage hint (no stack traces). Full diagnostics stored encrypted. Example: "Validation failed (ref r-20260116-abc). Contact support with ref." Append <code>rules.userErrorShown</code> audit. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>CI & Testing Matrix — required checks</strong><br>1. Unit: <code>ValidateRuleId</code>, <code>CompileRuleExpressions</code>, <code>MapRuleToHandler</code>, cost heuristics.<br>2. Integration: profile→rules→proposal→apply (create_copy) pipeline with canonical fixtures.<br>3. Golden: deterministic outputs across locales/bitness; <code>golden_hash</code> parity.<br>4. Property: determinism under sharding/ordering reorder tests.<br>5. Static: forbidden-API scanning in rule sources. <br><strong>Gate rules:</strong> prevent merges on golden mismatch or forbidden-API detection. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Hot-swap & release governance (policy)</strong><br>- Hot-swap requires <code>hotSwap.preview</code> + smoke test passing; regulated-rule hot-swap requires multi-person approvals; smoke tests run against <code>RuleTestingHarness</code>. <br>- Persisting hot-swap to release artifact requires signed manifest + <code>modExport</code>. <br>- Canary rollout with KPI gating (FP/FN rates, handler error rate) and automated rollback thresholds. <br><strong>-</strong> All transitions logged in <code>deployment.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Runbooks: operator actions (practical)</strong><br><strong>Mass false positives:</strong> <br>1) capture <code>correlationId</code>; <br>2) <code>DisableRule(ruleId)</code> emergency toggle; <br>3) <code>HotSwapRules</code> revert to <code>beforeHash</code>; <br>4) collect forensic artifacts and open incident; <br>5) rollback and notify owners. <br><strong>Manifest invalid on refresh:</strong> check <code>rules.load.invalid</code>, retrieve <code>failureArtifact</code>, fix and sign manifest, <code>HotSwapRules</code> apply after approvals. <br><strong>Long-running eval fallback:</strong> job persisted (<code>job.persisted</code>), check worker logs, requeue or scale worker pool. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Retention & housekeeping</strong><br>- Audit rotation policy: hot=30d, warm=7y (or per regulation), cold=per regulation. <br>- Evidence retention per data-classification policy; regulated outputs require longer retention. <br>- Scheduled monthly housekeeping tasks: rotate keys (KMS), test kill-switch, verify audit chain. Append <code>housekeeping.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Forensics & incident package (mandatory contents)</strong><br>Minimum: prior+current <code>rules.json</code> and signatures, <code>compiledRules</code> artifacts, <code>audit_tail.csv</code> for impacted correlationIds, job descriptors, <code>modConfig</code> snapshot, <code>forensic_manifest.json</code> listing artifacts + sha256 checksums, sanitized input/outputs (evidenceRef bundles). Store package in secure forensic repo with chain-of-custody and append <code>forensic.export</code> audit. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Sample JSON artifacts (canonical shapes)</strong><br><strong>Job descriptor (example):</strong> <code>{ &quot;jobId&quot;:&quot;job-222&quot;, &quot;jobType&quot;:&quot;rule_eval&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;correlationId&quot;:&quot;r-20260116-abc&quot;, &quot;paramsHash&quot;:&quot;sha256:ph&quot;, &quot;owner&quot;:&quot;team-dq&quot;, &quot;estimatedCost&quot;:&quot;heavy&quot;, &quot;persistedAt&quot;:&quot;2026-01-16T12:00:00Z&quot;, &quot;priority&quot;:&quot;normal&quot; }</code>.<br><strong>Validation report (example):</strong> <code>{ &quot;reportId&quot;:&quot;run-001&quot;, &quot;timestamp&quot;:&quot;...&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;summary&quot;:{&quot;rowCount&quot;:10000,&quot;violations&quot;:234,&quot;severityBreakdown&quot;:{&quot;CRITICAL&quot;:2,&quot;ERROR&quot;:40,&quot;WARN&quot;:192}}, &quot;artifacts&quot;:{&quot;samples&quot;:&quot;evidence:e-20260116-001&quot;,&quot;fullReport&quot;:&quot;artifact:validation_report_run-001.json&quot;}, &quot;checksums&quot;:{&quot;report&quot;:&quot;sha256:...&quot;} }</code>.<br><strong>Audit CSV header (canonical):</strong> <code>timestamp,correlationId,module,procedure,severity,userId,payloadHash,prevHash,signature,metadata</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Schema fragment (rules.schema.json) — sketch</strong><br><code>{ &quot;$schema&quot;:&quot;http://json-schema.org/draft-07/schema#&quot;, &quot;title&quot;:&quot;Ruleset&quot;, &quot;type&quot;:&quot;object&quot;, &quot;required&quot;:[&quot;rules&quot;,&quot;schemaVersion&quot;], &quot;properties&quot;:{ &quot;rules&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;items&quot;:{&quot;type&quot;:&quot;object&quot;,&quot;required&quot;:[&quot;ruleId&quot;,&quot;expression&quot;,&quot;severity&quot;], &quot;properties&quot;:{&quot;ruleId&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;version&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;description&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;expression&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;severity&quot;:{&quot;enum&quot;:[&quot;INFO&quot;,&quot;WARN&quot;,&quot;ERROR&quot;,&quot;CRITICAL&quot;]},&quot;estimatedCost&quot;:{&quot;enum&quot;:[&quot;light&quot;,&quot;medium&quot;,&quot;heavy&quot;]},&quot;requiresApproval&quot;:{&quot;type&quot;:&quot;boolean&quot;},&quot;regulated&quot;:{&quot;type&quot;:&quot;boolean&quot;},&quot;owner&quot;:{&quot;type&quot;:&quot;string&quot;},&quot;remediationHints&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;items&quot;:{&quot;type&quot;:&quot;object&quot;}}}}}, &quot;schemaVersion&quot;:{&quot;type&quot;:&quot;string&quot;} } }</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Regex complexity & compile heuristics</strong><br>- Compute regex complexity score = (#groups + nestingDepth) * avgTokenLength. <br>- If score > threshold mark as <code>heavy</code> and require compile-time warning <code>ERR_COMPILE_REGEX_HEAVY</code>. <br>- Detect catastrophic backtracking patterns (nested quantifiers) and fail compile with <code>ERR_COMPILE_REGEX_UNSAFE</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Deterministic partitioning algorithm (recommended)</strong><br>partitionKey = <code>sha256(configHash + rulesHash + tableId + rowKey)</code> → interpret as big integer → <code>partition = partitionKey % shardCount</code>. rowKey canonical encoding uses field order defined by table schema to ensure stability across runs. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Tie-breaker deterministic selection algorithm (merge/dedupe)</strong><br>To select representative row in group: choose row maximizing <code>(qualityScore * 1e6) + (lastModifiedTsEpoch) + lexicographicRank(rowId)</code>. Where <code>qualityScore</code> is computed from completeness, data-quality metrics and optional owner-defined preference. Always include tie-breaker explanation in <code>explainTemplate</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Telemetry & dashboards (metrics definitions)</strong><br>Primary metrics: <code>dq.rules.eval.latency_ms</code> (histogram), <code>dq.rules.timeout_rate</code> (rate per 1k evaluations), <code>dq.rules.violation_rate</code> (violations per 1k rows), <code>rules.hotswap.success_rate</code>, <code>job.persist.latency_ms</code>. Tag by <code>env</code>, <code>tenant</code>, <code>ruleCount</code>, <code>profileMode</code>. Alerts on sustained SLA breach. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>RBAC & approval matrix (example)</strong><br>- <code>Operator</code> — run profile, view validation, propose remediations. <br>- <code>DataSteward</code> — approve proposals, accept proposals for non-regulated datasets. <br>- <code>RulesOwner</code> — edit rules in staging, request hot-swap. <br>- <code>ReleaseEngineer</code> — approve persistence and release. <br>- <code>Compliance</code> — required approver for <code>regulated=true</code> rules and migration manifests. <br>Two-person approvals required for <code>destructive</code>/<code>regulated</code> operations. All approvals recorded in <code>approval.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Release manifest snippet (recommended fields)</strong><br><code>{ &quot;releaseId&quot;:&quot;rel-20260116-01&quot;, &quot;package&quot;:&quot;dqguard-rules&quot;, &quot;rulesHash&quot;:&quot;sha256:abcd&quot;, &quot;configHash&quot;:&quot;sha256:cfg&quot;, &quot;signedBy&quot;:[&quot;alice&quot;], &quot;timestamp&quot;:&quot;...&quot;, &quot;smokeTestSummary&quot;:&quot;pass&quot;, &quot;artifactChecksum&quot;:&quot;sha256:...&quot; }</code> </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>CI smoke-test recipe (example steps)</strong><br>1. Checkout candidate rules manifest. <br>2. Run <code>LoadRuleSet</code> dry-run & <code>CompileRuleExpressions</code> for all rules. <br>3. Execute <code>RuleTestingHarness</code> (<code>harness_eval_golden</code>) against canonical fixtures to produce <code>golden_hash</code>. <br>4. Compare <code>golden_hash</code> vs stored golden; fail CI on mismatch. <br>5. Run <code>hotSwap</code> smoke test for high-risk diffs; require pass for production. <br>6. Run static forbidden-API scan. <br>7. Append <code>ci.run</code> audit with summary and <code>rulesHash</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Operator checklist for regulated runs</strong><br>1. Prepare <code>rules.json</code> with owners set and <code>requiresApproval</code> flags. <br>2. Attach <code>migration_manifest.json</code> for semantic changes. <br>3. Run CI golden & smoke tests. <br>4. Obtain two-person approvals for regulated changes. <br>5. <code>HotSwapRules</code> apply in canary; monitor KPIs. <br>6. Persist release via <code>modExport</code> and sign artifacts. <br>7. Post-rollout <code>VerifyAuditChain</code> and record <code>deployment.audit</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Forensics runbook (short)</strong><br>1. Contain writes: set exports read-only; disable auto-apply. <br>2. Collect signed audit rotations and relevant <code>rules.json</code> artifacts. <br>3. Export evidence bundles referenced by <code>evidenceRef</code>; compute <code>forensic_manifest.json</code> with SHA256 checksums. <br>4. Store package in secure forensic repo with chain-of-custody. <br>5. Run <code>VerifyAuditChain</code> and produce RCA artifacts. All steps audited. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Common failure modes & triage actions</strong><br>- <strong>Manifest schema/sig invalid:</strong> <code>rules.load.invalid</code>. Action: revert to previous <code>rulesHash</code>, fix manifest, sign, reload. <br>- <strong>Compile-time forbidden API:</strong> fail registration; reject PR in CI. <br>- <strong>Mass false positives:</strong> emergency <code>DisableRule</code>, <code>HotSwapRules</code> revert, forensic collect, owner remediation. <br>- <strong>Timeouts:</strong> persist job and notify operator; watchdog append <code>dq_rule.timeout</code>. <br>- <strong>Job persist failures:</strong> retry with backoff; on repeated failure open incident. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Example operator CLI commands (canonical)</strong><br><code>rules.refresh --preview --source rules.json</code> → shows diff and <code>riskEstimate</code>. <br><code>rules.hotswap --apply --manifest fixed-rules.json --approvals mgr,compliance</code> → attempted hot-swap. <br><code>rules.disable r_bad_rule --operator alice --reason &quot;emergency&quot;</code> → immediate disable. <br><code>rules.audit.flush --correlation r-20260116-abc</code> → force audit flush. Each returns a <code>correlationId</code>. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria (final)</strong><br>- Unit + integration + golden tests pass. <br>- No forbidden-API references detected by static analyzers. <br>- <code>rulesHash</code> produced and <code>rules.loaded</code> audit emitted in pre-prod. <br>- <code>VerifyAuditChain</code> sample run passes. <br>- Determinism & performance microbenchmarks within budgets. <br>- Migration manifest present for semantic changes with smoke tests & approvals. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Appendices & storage recommendations</strong><br>Store canonical artifacts & appendices under immutable artifact storage with RBAC: <code>\\artifacts\DQ_Rules\releases\v{major}.{minor}\appendices\</code>: include <code>rules.schema.json</code>, <code>ErrorCodeCatalog.md</code>, <code>migration_manifest.template.json</code>, <code>hotswap.preview.template</code>, <code>OWNERS.md</code>, CI golden fixtures, and <code>VerifyAuditChain</code> runner. Evidence stored under <code>\\evidence\DQ_Rules\</code>. Ensure release artifacts are signed and checksummed. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Developer guidance & heuristics</strong><br>- Keep rule expressions declarative, small, and testable. <br>- Annotate heavy operations to route to job scheduler. <br>- Use deterministic rowKey encodings. <br>- Provide <code>explainTemplate</code> for each rule for human-readable rationale. <br>- Maintain <code>OWNERS.md</code> mappings and enforce sign-off from owners for changes. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Testing checklist (concise)</strong><br>Run: schema validation, compile-all, unit tests, integration pipeline (profile→rules→proposal), golden parity, static forbidden-API scan, hot-swap smoke tests, performance microbenchmarks. CI must block merges on golden or static failures. </td></tr><tr><td data-label="DQ_Rules — Per-function Expert Technical Breakdown"> <strong>Final verification — "Check 10×"</strong><br>The material above has been reviewed iteratively to ensure coverage of: manifest ingestion & signature validation; compile-time and runtime security guards; deterministic compilation and evaluation; audit & evidence model; job scheduling handoffs; hot-swap and migration governance; RBAC and approvals; CI/golden testing; failure modes & forensic procedures; operator runbooks and CLI examples; telemetry & SLOs; retention & encryption; and developer guidance. If you want any specific block expanded (for example: full JSON Schema v7 file, example CI YAML for golden-run gating, a concrete smoke-test harness script, or an operator one-page checklist in printable format), specify which block and I will expand that block now in the same single-column table style. </td></tr></tbody></table></div><div class="row-count">Rows: 57</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>