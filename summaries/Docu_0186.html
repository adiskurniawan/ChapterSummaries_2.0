<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1769244404">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0186_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modMatch — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modMatch — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Scope & Intent (concise):</strong> This document expands <code>modMatch</code> into an implementation-grade blueprint that engineers, data-platform teams, finance, and auditors can use to design, implement, test, and operate a deterministic fixed-asset matching subsystem. It covers per-row semantics for <code>CapexTransactionRow</code>, <code>AssetRow</code>, <code>CandidateListEntry</code>, function-level contracts for every major routine, detailed worked examples covering edge-cases, conceptual Power Query pilot guidance, conceptual DAX measures for operations, exhaustive CI/golden parity strategy, observability and runbooks, policy-migration processes, and governance controls. All numbered lists use <code>&lt;br&gt;</code> line breaks for downstream rendering consistency. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Executive summary (single paragraph):</strong> <code>modMatch</code> deterministically maps AP/Capex evidence to canonical asset records by: canonicalizing inputs with <code>modCanonical</code> primitives; generating reproducible <code>matchSignals</code> for each candidate asset; computing fixed-point <code>partialScore</code>s using <code>policySnapshot.matchingWeights</code>; aggregating into an auditable <code>candidateList</code> per <code>capexRow</code>; persisting append-only <code>candidateMappingIndex</code> artifacts with sha256 checksums; providing audit bundles and PII-gated retrieval; enabling bulk alias acceptance workflows; supporting deterministic recompute on policy changes with migration/canary manifests; and integrating with compute, preview, export, apply and reconciliation flows. Determinism, fixed-point arithmetic, canonical serialization ordering, evidence-first immutability, and auditable manifests are non-negotiable. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Per-row canonical narratives — extremely detailed</strong> <br><br> <strong>CapexTransactionRow (forensic-first narrative):</strong> <br>Purpose: a single unit of AP/Capex evidence used to identify candidate links to assets and to provide the provenance for capitalization decisions. This row must be treated as immutable canonical evidence once ingested (corrections create new rows with <code>correctionOf</code>). The <code>capexRow</code> is the primary input to <code>modMatch</code> and must expose both human-friendly and machine-canonical fields for deterministic matching. <br><br>Canonical fields and semantics (each bullet is a required or strongly recommended canonical field): <br>1. <code>capexRowId</code> (string, deterministic): generated as <code>sha256(sourceFingerprint | fileOffset | canonicalKey)</code> where <code>canonicalKey</code> is a deterministic concatenation of required canonicalized fields such as sanitized invoiceRef and normalized amountMinorUnits; invariant: same bytes and same canonicalVersion produce identical <code>capexRowId</code>. <br>2. <code>sourceFingerprint</code> (sha256): fingerprint of the original file or API payload normalized for newline and encoding; used to link to ingest manifests. <br>3. <code>rawPayloadRef</code> (evidenceRef): pointer to original raw bytes and provenance metadata including file offset/row index. <br>4. <code>transactionDate</code> (ISO <code>YYYY-MM-DD</code>): canonical date string. Ambiguous parses recorded in <code>parseAttemptLogs</code> under <code>issues[]</code>. <br>5. <code>vendorRaw</code> and <code>vendorCanonical</code> (string): raw vendor name preserved; <code>vendorCanonical</code> token created by applying NFKC normalization, punctuation normalization (policy-controlled), whitespace collapse and casefolding; vendor alias expansion uses <code>policySnapshot.vendorAliasMap</code>. <br>6. <code>invoiceRef</code> and <code>invoiceRefCanonical</code> (nullable): canonical token preserved and normalized; partial or multi-invoice patterns preserved as arrays for multi-invoice matching. <br>7. <code>poNumber</code> (nullable) with canonical tokenization. <br>8. <code>descriptionRaw</code> and <code>descriptionCanonical</code> (text & tokens): raw description preserved; canonical tokens derived using exact canonicalization rules used across <code>assetIndex</code> builds. <code>descriptionTokens</code> must include n-gram forms and token frequency for efficient seed retrieval. <br>9. <code>amount</code> (canonical decimal string), <code>amountMinorUnits</code> (integer), <code>scale</code> (integer): numeric canonicalization must always include integer minor units and scale parameter. Negative-zero normalization must be enforced (<code>-0.00</code> => <code>0.00</code>). <br>10. <code>currency</code> (ISO 4217) and optional <code>fxRateRef</code> metadata for multi-currency flows. <br>11. <code>costCenter</code>, <code>projectCode</code>, <code>accountReference</code> (optional structured fields): used in heuristics and mapping to GL. <br>12. <code>signConvention</code> and <code>originalSignRepresentation</code> captured to preserve source semantics. <br>13. <code>capexRowChecksum</code> (sha256): computed over canonical serialization in defined field order excluding transient provenance fields. <br><br>For matching: <code>CapexTransactionRow</code> must expose normalized tokens used by <code>modMatch</code> such as <code>invoiceRefCanonical</code>, <code>poNumber</code>, <code>descriptionTokens[]</code>, <code>vendorCanonical</code>, and the numeric <code>amountMinorUnits</code>. Capture parse issues in <code>issues[]</code> and never drop raw evidence. Corrections create new <code>capexRow</code> with <code>correctionOf</code> reference to older fingerprint. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>AssetRow (match-target narrative):</strong> <br>Purpose: canonical representation of an asset used as a deterministic target for mapping capex evidence. AssetRows must be stable, identifiable, and fully indexed with tokens and structured identifiers to maximize signal precision. AssetRow revisions are immutable; changes create new revision rows and maintain <code>assetRevisionId</code> linkages. <br><br>Per-field semantics and forensic handling: <br>1. <code>assetId</code> (string): authoritative deterministic identifier; if source ERP tag exists it is used verbatim for <code>assetTag</code> and included in <code>assetId</code> generation if configured; otherwise deterministic hash recipe described in <code>modCanonical</code> must be used. <br>2. <code>assetTag</code> (nullable string) plus <code>assetTagCanonical</code> for exact-match seeds. <br>3. <code>serialNumber</code>, <code>modelNumber</code>, <code>manufacturer</code> as strong match identifiers when present. <br>4. <code>descriptionRaw</code>, <code>descriptionCanonicalTokens[]</code> with token frequencies and n-grams precomputed for efficient Jaccard or token-overlap scoring. <br>5. <code>vendorOwnership</code> and <code>vendorCanonical</code> to allow vendor-level boosts. <br>6. <code>location</code>, <code>costCenter</code>, <code>projectCode</code>: mapped canonical values enable heuristics against capex <code>costCenter</code>. <br>7. <code>category</code> (policy category key) used to apply category-specific matching and capitalization hints. <br>8. <code>assetRowChecksum</code> (sha256) computed on canonical field serialization excluding provenance. <br><br>Indexing and usage: assetIndex must include inverted token indexes for <code>assetTagCanonical</code>, <code>serialNumber</code>, <code>descriptionTokens</code>, <code>vendorTokens</code>, <code>modelNumber</code> and a historical mapping index referencing capexRow patterns. Asset revisions are linked; <code>modMatch</code> must always reference <code>assetRowChecksum</code> for auditability rather than mutable fields. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>CandidateListEntry (canonical target row narrative):</strong> <br>Purpose: single candidate record output by <code>modMatch</code> representing a scored mapping between a <code>capexRow</code> and an <code>assetId</code>. CandidateListEntries drive analyst UIs, automatic capitalization decisions, and are persisted to the <code>candidateMappingIndex</code> for forensic replay. <br><br>Essential fields and invariants: <br>1. <code>capexRowId</code> (string): the input that generated candidates. <br>2. <code>assetId</code> (string): candidate target. <br>3. <code>candidateScore</code> (policy decimal string) plus <code>candidateScoreInt</code> (fixed-scale integer) used for deterministic ordering. <br>4. <code>matchSignals[]</code> (array): each signal as <code>{name, normalizedValue, rawEvidenceRefs[], signalConfidenceContributionInt}</code> using integer scaled values to avoid FP drift. <br>5. <code>rank</code> (1..N) after tie-breakers applied. <br>6. <code>candidateRowChecksum</code> (sha256): canonicalized candidate string hash used for idempotent persistence. <br>7. <code>scoringVectorUsedRef</code> pointer to <code>policySnapshot.matchingWeights</code> and <code>policyHash</code>. <br>8. <code>rationale</code>: deterministic human-readable summary assembled from <code>matchSignals</code> showing weighted contributions (but assembled deterministically from canonical fields). <br>9. <code>createdTs</code>, <code>createdBy</code> metadata in persisted candidateMapping record but excluded from <code>candidateRowChecksum</code> to keep artifact stable across persistence attempts (unless policy explicitly requires inclusion). <br><br>Audit invariant: Given identical <code>capexRow.checksum</code>, <code>assetIndex.checksum</code>, <code>policyHash</code> and <code>canonicalVersion</code>, recomputing <code>FindAssetCandidates</code> returns identical <code>candidateList</code> and <code>candidateRowChecksum</code>. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>CandidateMappingIndexRow (persisted artifact narrative):</strong> <br>Purpose: append-only persisted record storing canonical <code>candidateList[]</code> for a given <code>capexRow</code> and the manifest metadata required for forensic playback. The index is the ground truth for analyst review and migration parity. <br><br>Fields and storage invariants: <br>1. <code>candidateMappingRef</code> (object store path) <br>2. <code>capexRowId</code> <br>3. <code>candidateMappingChecksum</code> (sha256 of canonical serialization) <br>4. <code>policyHash</code>, <code>scoringVectorVersion</code>, <code>assetIndexChecksum</code>, <code>runHash</code> optional <br>5. <code>createdBy</code>, <code>createdTs</code>, <code>correctionOf</code> optional <br>6. <code>evidenceRefs[]</code> pointing to <code>capexIngestManifest</code> and <code>assetIndex</code> snapshot <br><br>Storage contract: writes are idempotent keyed by <code>candidateMappingChecksum</code>; duplicates returned as existing ref; corrections create new records referencing <code>correctionOf</code>. Evidence access to raw payloads is approval-gated and logged with chain-of-custody audit rows. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>MatchSignal (atomic narrative):</strong> <br>Purpose: atomic, auditable feature computed deterministically from canonicalized fields; signals are the primitive inputs to scoring. <br><br>Canonical signal properties: <br>1. <code>name</code> (canonical string): signal identifier such as <code>invoiceRefExact</code>, <code>assetTagInDescription</code>, <code>serialNumberExact</code>, <code>vendorAliasScore</code>, <code>amountProximity</code>, <code>descriptionTokenOverlap</code>, <code>historicalMappingStability</code>. <br>2. <code>rawEvidenceRefs[]</code>: pointers to the fields used to compute the signal (e.g., <code>capexRow.capexRowChecksum</code>, <code>assetRow.assetRowChecksum</code>). <br>3. <code>normalizedValue</code> (integer scaled by <code>policySnapshot.signalScale</code>) to avoid floating point variations. <br>4. <code>signalScale</code> & <code>normalizationNotes</code> recorded in the <code>signalTrace</code> for reproducibility. <br>5. <code>signalContributionInt</code>: signal's contribution to the integer-partialScore computed as <code>normalizedValue * weightInt</code> using <code>policySnapshot.matchingWeights</code>. <br><br>All signal computations are recorded in the <code>signalTrace</code> and included in audit bundles. Signal normalization rules are part of <code>policySnapshot</code> and must change only under documented migration manifests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function-level contracts — exhaustive, deterministic, auditable</strong> <br>All functions below are specified with: inputs, outputs, responsibilities, invariants, failure modes, observability metrics, CI tests, and runbook actions. Each function emits audit event(s) on critical lifecycle transitions and writes manifests to evidence store as required. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>FindAssetCandidates(capexRow, assetIndex, policySnapshot, options)</code><br><br><strong>Purpose:</strong> orchestrate seed retrieval, per-candidate signal computation, scoring, deterministic ordering, optional persistence and emission of audit events for a single <code>capexRow</code>. This function is intended to be called in both interactive (analyst preview) and batch (compute) contexts; deterministic behavior must be preserved across both. <br><br><strong>Inputs:</strong> <br>1. <code>capexRow</code> (canonical <code>CapexTransactionRow</code>) <br>2. <code>assetIndex</code> (snapshot used for matching) <br>3. <code>policySnapshot</code> containing <code>matchingWeights</code>, <code>signalScale</code>, <code>scoreScale</code>, <code>vendorBoosts</code>, <code>minConfidence</code>, <code>maxCandidates</code>, <code>tieBreakerPolicy</code>, <code>canonicalVersion</code>, <code>policyHash</code> <br>4. <code>options</code> (<code>{mode: &quot;strict&quot;|&quot;tolerant&quot;, persist: boolean, maxSearchCandidates: integer, runId: optional, runHash: optional seed}</code>) <br><br><strong>Outputs:</strong> <br>1. <code>candidateList[]</code> ordered (see canonical fields earlier) <br>2. <code>diagnostics</code> with timings, <code>exhaustiveCount</code>, <code>issues[]</code> (parse or tokenization issues), <code>assetIndexRef</code> <br>3. (Optional) <code>candidateMappingRef</code> if <code>persist=true</code> <br>4. Audit event <code>fa.match.find</code> emitted with <code>correlationId</code>, <code>policyHash</code>, <code>capexRowId</code>, <code>candidateMappingChecksum</code> if persisted <br><br><strong>Detailed responsibilities (step-by-step):</strong> <br>1. Pre-validation: verify <code>capexRow.capexRowChecksum</code> and <code>capexRow</code> fields required for matching present; if <code>strict</code> mode and required fields missing, abort with <code>fa.match.input_invalid</code>; in <code>tolerant</code> mode continue and record issues. <br>2. Index selection & prefetching: based on <code>vendorCanonical</code>, <code>costCenter</code> and <code>descriptionTokens</code>, determine assetIndex shards to consult and prefetch to memory with timeout and retries. <br>3. Candidate seeding (deterministic priority): <br>&nbsp;&nbsp;&nbsp;&nbsp;a. Exact invoiceRef / PO→assetTag cross-reference lookup. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Exact assetTag / serialNumber / modelNumber match. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. Historical mapping index lookups for similar descriptions or vendor patterns. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. Token-based seeding from description tokens using precomputed token→asset buckets sorted by token frequency and inverse-document-frequency to prioritize discriminative tokens. <br>4. Pre-score pruning: limit seeds to <code>options.maxSearchCandidates</code> or <code>policySnapshot.maxCandidatesPrune</code> to bound CPU costs; document <code>prunedCount</code> in diagnostics. <br>5. For each seed candidate invoke <code>ScoreMatchSignals</code> to compute <code>matchSignals</code> and <code>partialScoreInt</code> (integer). <br>6. Aggregate & normalize by calling <code>BuildCandidateList</code> passing <code>runHash</code> for tie-break deterministic seed. <br>7. If <code>options.persist</code> => call <code>PersistCandidateMapping</code> and attach <code>candidateMappingRef</code> and <code>candidateMappingChecksum</code> into result and audit event. <br>8. Return <code>candidateList</code> and <code>diagnostics</code>. <br><br><strong>Invariants:</strong> <br>1. Deterministic outputs given identical <code>capexRow.checksum</code>, <code>assetIndex.checksum</code>, <code>policyHash</code>, <code>canonicalVersion</code>, and <code>runHash</code>. <br>2. All numeric math performed using integer arithmetic scaled by config values in <code>policySnapshot</code>. <br>3. Canonicalization functions used prior to any tokenization or matching. <br><br><strong>Failure modes & remediation:</strong> <br>1. Asset index partition unavailable → emit <code>fa.match.index_unavailable</code>, retry with exponential backoff; if persistent create manual triage ticket and mark <code>capexRow</code> mapping as <code>requires_manual_review</code>. <br>2. Signal normalization failure (e.g., ambiguous date or number) → mark the specific signal weak, add to <code>issues[]</code>, continue with degraded scoring. <br>3. Policy weight vector invalid or missing → abort with <code>fa.match.invalid_policy</code>; do not persist candidate mapping. <br><br><strong>Observability metrics & tags:</strong> <code>match.find.latencyMs</code>, <code>match.find.candidateCount</code>, <code>match.find.lowConfidenceRate</code>, <code>match.find.indexErrors</code>; tags include <code>policyHash</code>, <code>runId</code>, <code>operatorId</code> and <code>capexRowId</code>. <br><br><strong>CI tests:</strong> deterministic candidateList parity with golden fixtures; throughput tests for seeded workloads; error-path tests (index unavailability, malformed inputs); property tests for idempotency. <br><br><strong>Operator runbook (short):</strong> on <code>fa.match.index_unavailable</code> verify assetIndex storage, prefetch logs, and re-run after index rebuild; on <code>fa.match.low_confidence_spike</code> run analytics to find top unclassified vendors and open alias mapping workshop. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>ScoreMatchSignals(capexRow, assetRow, policySnapshot)</code><br><br><strong>Purpose:</strong> compute a deterministic set of <code>matchSignals</code> and an integer <code>partialScore</code> representing the contribution of this asset candidate to the overall candidate ranking. This function is small but critical to parity. <br><br><strong>Inputs:</strong> <code>capexRow</code>, <code>assetRow</code>, <code>policySnapshot</code> containing <code>signalScale</code>, <code>amountProximityScale</code>, <code>matchingWeights</code> (scaled integers), <code>featureNormalization</code> rules, and <code>canonicalVersion</code>. <br><br><strong>Outputs:</strong> <code>{ matchSignals[], partialScoreInt, signalTrace[] }</code> where <code>partialScoreInt</code> is a scaled integer representing the dot-product result of signals and scaled weights. <br><br><strong>Detailed responsibilities & deterministic algorithm:</strong> <br>1. Canonicalize all compared text fields using <code>modCanonical.NormalizeText</code> with <code>policySnapshot.canonicalVersion</code>. <br>2. Compute atomic signals: <br>&nbsp;&nbsp;&nbsp;&nbsp;a. <code>invoiceRefExact</code> boolean: 1 if <code>capexRow.invoiceRefCanonical</code> equals any <code>assetRow.identifiers</code> canonicalized. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. <code>poNumberExact</code> boolean. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. <code>assetTagExact</code> boolean. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. <code>serialNumberExact</code> boolean. <br>&nbsp;&nbsp;&nbsp;&nbsp;e. <code>assetTagInDescription</code> boolean computed by token inclusion with deterministic tokenization. <br>&nbsp;&nbsp;&nbsp;&nbsp;f. <code>descriptionTokenOverlap</code> integer computed as scaled Jaccard-like score: <code>overlap / union * signalScale</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;g. <code>vendorAliasMatchScore</code> integer representing matched alias exactness or fuzzy similarity scaled by <code>signalScale</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;h. <code>amountExact</code> boolean and <code>amountProximity</code> integer computed as <code>max(0, signalScale - (abs(amountDiffMinorUnits) / amountProximityScale))</code> clipped to 0..signalScale. <br>&nbsp;&nbsp;&nbsp;&nbsp;i. <code>historicalMappingStability</code> integer computed as count of historical mappings for this asset in defined lookback window scaled to signalScale. <br>3. Scale all signals to integers using <code>policySnapshot.signalScale</code> to preserve cross-runtime parity and avoid FP drift. <br>4. For each signal compute <code>contributionInt = normalizedSignalValue * weightInt</code> where <code>weightInt</code> is <code>policySnapshot.matchingWeights[signalName]</code>. Use safe big-integer arithmetics to avoid overflow. <br>5. Sum all <code>contributionInt</code> values to produce <code>partialScoreInt</code>. <br>6. Assemble <code>signalTrace</code> entries with exact normalized values, evidence refs and scaled contributions for audit. <br>7. Return <code>matchSignals</code>, <code>partialScoreInt</code>, and <code>signalTrace</code>. <br><br><strong>Invariants:</strong> <br>1. Recomputing <code>ScoreMatchSignals</code> with same canonical inputs and <code>policySnapshot</code> yields identical <code>partialScoreInt</code>. <br>2. All scales and weight vector versions used are recorded in outputs to allow replay. <br><br><strong>Failure modes & remediation:</strong> <br>1. Undersized <code>signalScale</code> leading to rounding/truncation -> raise <code>fa.match.scale_too_small</code> in diagnostics and recommend migration manifest to increase scale. <br>2. Overflow -> use larger integer type or reduce scale and run parity tests. <br><br><strong>Observability:</strong> counts of per-signal nulls, distribution of signal values, <code>signal.computeMs</code>. <br><br><strong>CI tests:</strong> per-signal unit tests across locale permutations, integer arithmetic overflow tests, cross-runtime parity tests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BuildCandidateList(capexRow, prelimCandidates[], policySnapshot, runHash)</code><br><br><strong>Purpose:</strong> normalize <code>partialScoreInt</code>s into final <code>candidateScore</code> decimals, apply policy-level adjustments (vendor boosts, historical boosts, blacklist/allowlist), filter by thresholds, deterministically rank and apply tie-breakers, and prepare <code>candidateList</code> for persistence. <br><br><strong>Inputs:</strong> <br>1. <code>capexRow</code> <br>2. <code>prelimCandidates[]</code> each <code>{assetRowRef, partialScoreInt, matchSignals[], signalTrace[]}</code> <br>3. <code>policySnapshot</code> values: <code>scoreScale</code>, <code>minConfidence</code>, <code>autoAcceptThreshold</code>, <code>vendorBoosts</code>, <code>historicalBoostFactor</code>, <code>blacklist</code>, <code>allowlist</code>, <code>maxCandidates</code>, <code>tieBreakerPolicy</code>, <code>canonicalVersion</code> <br>4. <code>runHash</code> string used as seeded deterministic fallback for tie-breakers <br><br><strong>Outputs:</strong> <code>candidateList[]</code> with canonicalized fields and <code>buildDiagnostics</code> including <code>exhaustiveCount</code>, <code>filteredCount</code>, <code>tieBreakTrace</code>, and <code>scoreAdjustmentLog</code>. <br><br><strong>Responsibilities & deterministic algorithm steps:</strong> <br>1. Normalize <code>partialScoreInt</code> to <code>candidateScoreInt</code> by applying <code>scoreScale</code> normalization and rounding rules internal to <code>policySnapshot</code> (always integer math). Keep both integer and decimal string forms for display. <br>2. Apply policy-level transforms: <br>&nbsp;&nbsp;&nbsp;&nbsp;a. Vendor-specific boost: if <code>capexRow.vendorCanonical</code> present in <code>policySnapshot.vendorBoosts</code>, add <code>vendorBoostInt</code> to <code>candidateScoreInt</code> for assets linked to that vendor. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Historical mapping factor: if <code>historicalMappingStability</code> present multiply or add <code>historicalBoostFactorInt</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. Cost-center mismatch penalty applied as deterministic subtraction. Each adjustment recorded in <code>scoreAdjustmentLog</code>. <br>3. Evaluate <code>minConfidence</code> threshold: remove any candidate with <code>candidateScoreInt &lt; minConfidenceInt</code> unless <code>policySnapshot.allowLowConfidenceForManualReview</code> is true and <code>capexRow</code> flagged for manual triage. If all candidates fall below minConfidence, select top <code>policySnapshot.minCandidatesForManual</code> candidates to pass into manual review queue with <code>lowConfidence</code> flag. <br>4. Enforce <code>blacklist</code>/<code>allowlist</code>: remove blacklisted assets; if <code>allowlist</code> is configured, remove candidates not in allowlist unless manual review overrides. Record removals in <code>buildDiagnostics</code>. <br>5. Deterministic ordering: sort by <code>candidateScoreInt</code> descending. For equal scores, invoke <code>ResolveTieBreakers</code> passing <code>tieBreakerPolicy</code> and <code>runHash</code>. The tie-breaker algorithm is deterministic and must persist used seeds. <br>6. Truncate the list to <code>policySnapshot.maxCandidates</code> while recording <code>exhaustiveCount</code> and <code>truncated</code> boolean if truncation occurred. <br>7. Compute <code>candidateRowChecksum</code> for each candidate using canonical field order and canonical separators; exclude non-canonical metadata. <br>8. Construct human-readable deterministic <code>rationale</code> assembled from matchSignals contributions ordered by absolute contribution descending. <br>9. Return <code>candidateList</code> and <code>buildDiagnostics</code>. <br><br><strong>Invariants:</strong> candidate ordering and checksums are reproducible given identical inputs and <code>runHash</code>; all computation uses integer arithmetic. <br><br><strong>Failure modes & remediation:</strong> <br>1. Weight vector update causing ordering drift -> create <code>recomputeManifest</code> and perform canary. <br>2. Tie-break PRNG mismatch -> provide canonical LCG library and run parity tests. <br><br><strong>Observability:</strong> <code>candidate.build.timeMs</code>, <code>candidate.filteredCount</code>, <code>candidate.truncatedCount</code>, <code>tieBreaker.occurrences</code>. <br><br><strong>CI tests:</strong> ordering parity with seeded <code>runHash</code>, score adjustment fixture tests, threshold behavior tests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>ResolveTieBreakers(candidateList, runHash, tieBreakerPolicy)</code><br><br><strong>Purpose:</strong> provide deterministic resolution when candidates share identical integer scores. Tie-break logic is ordered and policy-controlled and documents the exact comparator used for audit. <br><br><strong>Inputs:</strong> <code>candidateList</code> with equal-score groups, <code>runHash</code> string (optional), and <code>tieBreakerPolicy</code> such as ordered comparators: <code>preRoundedAmount</code>, <code>historicalMappingStability</code>, <code>lexicographicAssetId</code>, <code>seededPRNG</code>. <br><br><strong>Outputs:</strong> <code>candidateList</code> with ranks finalized and <code>tieBreakTrace</code> documenting comparator usage and seed values where applicable. <br><br><strong>Deterministic algorithm & responsibilities:</strong> <br>1. Identify all groups where <code>candidateScoreInt</code> equality exists. <br>2. Apply comparators in policy-specified order: <br>&nbsp;&nbsp;&nbsp;&nbsp;a. Numeric comparators (e.g., preRoundedAmount) compare canonical integer values. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Historical stability count next. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. Lexicographic comparator (canonical ascii ordering of <code>assetId</code>). <br>&nbsp;&nbsp;&nbsp;&nbsp;d. Fallback seeded PRNG: compute deterministic seed string <code>sha256(runHash | capexRowId | sortedCanonicalCandidateIds)</code> and pass into canonical LCG producing deterministic permutations used to order remaining ties. <br>3. Persist <code>tieBreakerSeed</code> and LCG parameters in <code>tieBreakTrace</code> and include in <code>buildDiagnostics</code>. <br>4. Return updated <code>candidateList</code>. <br><br><strong>Invariants & requirements:</strong> <br>1. The exact composition of PRNG seed and LCG parameters must be documented in <code>policySnapshot</code> or <code>depreciationRunManifest</code> so replay is possible. <br>2. Use canonical ascii ordering for lexicographic comparisons to avoid locale-dependent drift. <br><br><strong>Failure modes:</strong> mismatch between PRNG implementations across languages -> parity diffs; remedy: ship canonical PRNG library or use hash-based lexicographic fallback. <br><br><strong>CI tests:</strong> seed-based tie-breaker parity tests, lexicographic fallback tests, trace verification. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>PersistCandidateMapping(candidateList, capexRow, operatorContext)</code><br><br><strong>Purpose:</strong> persist canonical candidate mapping to the <code>candidateMappingIndex</code> in an append-only, idempotent way; attach required metadata for forensic replay and auditing; return evidence ref and checksums. <br><br><strong>Inputs:</strong> <code>candidateList</code>, <code>capexRow.capexRowId</code>, <code>operatorContext</code> (<code>operatorId</code>, <code>runId</code>, <code>mode</code>), <code>evidenceStoreClient</code>. <br><br><strong>Outputs:</strong> <code>candidateMappingRef</code> (object store path), <code>candidateMappingChecksum</code> (sha256), audit event <code>fa.capex.candidate_persisted</code> with <code>candidateMappingRef</code>. <br><br><strong>Persistence contract (explicit):</strong> <br>1. Canonical serialization: sort <code>candidateList</code> by rank ascending and serialize using canonical field order with <code>|</code> separator and no trailing newline; compute <code>candidateMappingChecksum = sha256(serialized)</code>. <br>2. Idempotent write: test evidence store index for <code>candidateMappingChecksum</code>. If present return existing ref. If absent, persist atomic record including <code>policyHash</code>, <code>assetIndexChecksum</code>, <code>runHash</code>, <code>operatorContext</code> and <code>createdTs</code>. <br>3. Correction handling: persist new record with <code>correctionOf</code> referencing previous checksum when analyst corrects mapping. <br>4. Evidence access: do not embed raw PII in stored record; store only <code>evidenceRefs</code> to raw payloads. Access to raw evidence requires <code>approvalRef</code> which is logged. <br><br><strong>Invariants:</strong> persisted candidateMapping rows are immutable; <code>candidateMappingChecksum</code> is the unique idempotency key. <br><br><strong>Failure modes & remediation:</strong> object store failures -> local durable staging and retry; duplicate writes detected and returned as idempotent. <br><br><strong>Observability:</strong> <code>candidate.persist.latencyMs</code>, <code>candidate.persist.failures</code>, <code>persistRetryCount</code>. <br><br><strong>CI tests:</strong> idempotency replay tests, canonical serialization parity tests, staging failure recovery tests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>CandidateMappingAudit(capexRowId, candidateMappingRef, detailLevel, approvalRef)</code><br><br><strong>Purpose:</strong> assemble a reproducible audit bundle containing the capexRow, top N assetRows, matchSignals, scoring vector used, and policy snapshot to support compliance review. Enforce PII access gating. <br><br><strong>Inputs:</strong> <code>capexRowId</code>, <code>candidateMappingRef</code>, <code>detailLevel</code> (<code>summary | full</code>), <code>approvalRef</code> optional for PII reveal. <br><br><strong>Outputs:</strong> <code>auditBundleRef</code>, <code>auditBundleHash</code>, <code>auditSummary</code> with <code>evidenceRefs</code>; if PII requested, include chain-of-custody entries linking approval. <br><br><strong>Assembly responsibilities:</strong> <br>1. Rehydrate <code>capexRow</code> raw bytes, candidateMapping record and each referenced <code>assetRow</code> up to configured <code>detailLevel</code> top N. <br>2. Include <code>signingVectorUsedRef</code>, <code>policySnapshotRef</code>, <code>assetIndexChecksum</code>, <code>runHash</code> if present. <br>3. Redact PII by default; if <code>approvalRef</code> included and valid, include the raw elements and persist chain-of-custody metadata in the audit manifest. <br>4. Canonically serialize audit bundle and compute <code>auditBundleHash</code> for integrity; persist to evidence store. <br><br><strong>Invariants:</strong> audit bundle must be re-creatable from persisted <code>candidateMappingChecksum</code> and <code>policySnapshot</code>; <code>auditBundleHash</code> must match recompute for parity. <br><br><strong>Failure modes & remediation:</strong> missing raw evidence -> <code>fa.audit.missing_evidence</code>; PII request without approval -> deny and record <code>fa.audit.pii_access_denied</code>. <br><br><strong>CI tests:</strong> audit bundle parity fixtures, PII gating tests, missing evidence handling. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BulkAliasAcceptance(acceptedMappings[], operatorContext)</code><br><br><strong>Purpose:</strong> support authoritative business acceptance of alias→asset mappings in bulk, enabling deterministic replays and propagating impacts to candidate mappings and compute runs. All acceptances are additive (generate new mapping records) and are approval-gated when affecting capitalization thresholds. <br><br><strong>Inputs:</strong> <code>acceptedMappings[]</code> each <code>{ aliasPattern, canonicalAlias, assetId, acceptanceReason, sampleCapexRefs[] }</code>, <code>operatorContext</code> (<code>operatorId</code>, <code>approvalEvidenceRef</code>) <br><br><strong>Outputs:</strong> <code>bulkAcceptanceRef</code>, <code>bulkAcceptanceManifest</code> with <code>acceptanceHash</code>, <code>affectedCapexList</code> for recompute, audit event <code>fa.match.bulk_accept</code>. <br><br><strong>Responsibilities & deterministic flow:</strong> <br>1. Validate <code>assetId</code> existence and canonicalize <code>aliasPattern</code> using <code>modCanonical</code>. <br>2. Persist acceptance record atomically with <code>createdBy</code> and <code>approvals[]</code>. <br>3. Produce <code>affectedCapexList</code> by querying <code>candidateMappingIndex</code> for capexRows matching alias pattern or overlapping description tokens deterministically. <br>4. If acceptance could affect capitalization decisions above regulated thresholds, require <code>policySnapshot.approvalMatrix</code> approvals; pending approvals do not affect automated runs. <br>5. Do not mutate historical candidateMappingIndex entries; instead produce new annotation records with <code>correctionOf</code> linking to prior candidateMapping checksums. <br>6. Emit audit event and include <code>acceptanceHash</code>. <br><br><strong>Invariants:</strong> acceptance records are immutable; any reversal of acceptance requires a new acceptance record flagged as <code>revertOf</code>. <br><br><strong>Failure modes:</strong> conflicting acceptances -> produce <code>acceptance_conflict</code> diagnostics and require manual resolution; missing approvals -> mark <code>pendingApproval</code> and do not change automated scoring. <br><br><strong>CI tests:</strong> replay acceptance and recompute, conflict detection, approval gating. <br><br><strong>Runbook:</strong> for large acceptance deployments schedule incremental recompute for <code>affectedCapexList</code> and circulate preview artifacts to analysts. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>RecomputeCandidateScoresOnPolicyChange(oldPolicyHash, newPolicySnapshot, affectedCapexRefs, assetIndexSnapshot, runContext)</code><br><br><strong>Purpose:</strong> deterministically recompute candidate lists for a set of capexRows when policy matching weights or normalization rules change; create recompute evidence bundles and impact KPIs for migration governance and canary review. <br><br><strong>Inputs:</strong> <code>oldPolicyHash</code>, <code>newPolicySnapshot</code>, <code>affectedCapexRefs[]</code>, <code>assetIndexSnapshot</code> (fixed snapshot used in prior runs), <code>runContext</code> (<code>runId</code>, <code>operatorId</code>, <code>migrationId</code>, <code>canaryPlanId</code>, <code>seed</code>) <br><br><strong>Outputs:</strong> <code>recomputeResults[]</code> per capexRow with diffs, <code>recomputeManifest</code> capturing <code>impactKPIs</code>, <code>recomputeRunHash</code>, and audit <code>fa.policy.matching.recompute</code>. <br><br><strong>Responsibilities & deterministic algorithm:</strong> <br>1. Validate <code>assetIndexSnapshot</code> is identical to prior run snapshot via checksum; abort with <code>fa.match.recompute.index_mismatch</code> if mismatch. <br>2. For each capexRow in <code>affectedCapexRefs</code> rehydrate prior candidateMapping entries by <code>oldPolicyHash</code>. <br>3. Re-run <code>FindAssetCandidates</code> deterministically using <code>newPolicySnapshot</code> and the same <code>assetIndexSnapshot</code> and <code>runContext.seed</code>. <br>4. Compute per-capex diffs: <code>oldCandidateMappingChecksum</code>, <code>newCandidateMappingChecksum</code>, <code>rankDelta</code>, <code>scoreDelta</code>, <code>capitalizationDecisionChange</code> boolean. <br>5. Aggregate global KPIs: <code>pctCapexWithCandidateChange</code>, <code>avgScoreDelta</code>, <code>pctCapitalizationDecisionChange</code>, <code>topAffectedVendors</code> list. <br>6. Persist <code>recomputeManifest</code> and representative sample bundles for governance review. <br>7. If KPIs exceed migration thresholds in <code>migrationManifest</code>, mark as <code>migration_hotstop</code> and emit alert. <br><br><strong>Invariants:</strong> recompute is isolating <code>policy</code> as the only variable; <code>assetIndexSnapshot</code> must be identical to isolate policy effect. <br><br><strong>Failure modes & remediation:</strong> abort and investigate index mismatch; if <code>migration_hotstop</code> occurs, pause promotion and initiate governance review. <br><br><strong>Observability & KPIs:</strong> <code>recompute.durationMs</code>, <code>recompute.impactPct</code>, <code>migration.hotstopCount</code>. <br><br><strong>CI tests:</strong> canary fixture recompute tests, impact KPI enforcement tests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>modMatch.TestHarness_RunAll(testConfig)</code><br><br><strong>Purpose:</strong> single-call harness used by CI to exercise unit, integration, property and golden parity tests for <code>modMatch</code>; return structured test results and parity artifacts for gating. <br><br><strong>Inputs:</strong> <code>testConfig</code> with flags <code>unit</code>, <code>integration</code>, <code>golden</code>, <code>property</code>, <code>envTags</code> for targeted execution. <br><br><strong>Outputs:</strong> <code>testReport</code> with per-test statuses, failing diffs, <code>parityFailures[]</code>, <code>artifactRefs</code>, and <code>exitCode</code>. <br><br><strong>Responsibilities:</strong> <br>1. Run unit tests for <code>ScoreMatchSignals</code> per-signal correctness with locale permutations. <br>2. Run integration tests for <code>FindAssetCandidates</code> and <code>BuildCandidateList</code>. <br>3. Execute golden parity tests comparing <code>candidateMappingChecksum</code> outputs across PQ pilot and backend implementations. <br>4. Generate <code>parityArtifacts</code> for failing cases. <br>5. Block merges when golden tests fail on protected branches. <br><br><strong>Invariants:</strong> tests are deterministic and rely only on canonicalization primitives and policy snapshot fixtures included in test artifacts. <br><br><strong>Failure modes & remediation:</strong> non-deterministic failures -> capture environment discrepancy and record for debug; fix by aligning <code>canonicalVersion</code>. <br><br><strong>CI metrics:</strong> <code>ci.tests.durationMs</code>, <code>ci.parityFailureRate</code>. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Extended worked examples — ultra-detailed narratives with edge-cases</strong> <br><br> <strong>Example 1 — Multi-invoice capitex split across assets (complex component assembly):</strong> <br>Context: Two invoices, INV-A and INV-B, represent charges for a chassis and an accessory. INV-A lacks assetTag but has PO linked to project; INV-B includes accessory part number matching <code>assetTag</code> of AS-000789. <br>Detailed steps & deterministic outcomes: <br>1. Ingest: <code>LoadCapexTransactions</code> canonicalizes both rows; <code>capexRowId</code> created per canonical recipe; <code>descriptionTokens</code> extracted including part numbers. <br>2. Candidate seeds: INV-B seeds directly to AS-000789 via <code>assetTagInDescription</code> and <code>invoiceRef</code> mapping producing high <code>partialScoreInt</code>. INV-A seeds via PO→project mapping to an asset in the same project with medium score. <br>3. <code>ScoreMatchSignals</code>: INV-B signals strong <code>assetTagInDescription</code> and <code>amountProximity</code>; INV-A signals PO link and vendor mapping. Both candidateLists produced deterministically. <br>4. <code>BuildCandidateList</code>: policy <code>componentPolicy</code> indicates <code>create_component</code> for accessory-type materials under threshold; <code>BuildCandidateList</code> applies <code>categoryHint</code> from tokenized description to choose <code>create_component</code> and yields a top candidate that becomes a new component asset creation suggestion. <code>candidateRowChecksum</code> persisted. <br>5. <code>ComputeDepreciation</code> (caller) consumes persisted candidate mapping and either appends cost to parent or creates a component asset with deterministic <code>assetRevisionId</code> computed from <code>sha256(parentAssetRowChecksum | capexRowChecksum | decisionTimestampCanonical)</code>. <br>6. Analyst review sees JE preview showing component creation lines and asset-level traceability; acceptance triggers <code>GenerateJEExport</code> and <code>ApplyCorrections</code> per approvals. <br>Edge nuances: if INV-A included an explicit GL expense account reference, <code>BuildCandidateList</code> flags <code>policySnapshot.capitalizationOverrides</code> and surfaces decision in <code>rationale</code> for analyst review rather than auto-capitalizing. <br><br> <strong>Example 2 — Ambiguous numeric locales & amount proximity pathologies:</strong> <br>Context: capexRow's amount string "1.234,56" ambiguous between European thousand/decimal conventions. <br>Detailed handling: <br>1. <code>LoadCapexTransactions</code> stores <code>rawAmountString</code> and attempts parsing based on <code>options.sourceCulture</code>; if ambiguous, <code>issues[]</code> includes <code>CNV_NUM_LOCALE_AMBIGUOUS</code>. <br>2. In <code>ScoreMatchSignals</code>, numeric parsing failure leads to amount signals marked weak and <code>amountProximity</code> computed conservatively (zero contribution) while other signals are used. <code>FindAssetCandidates</code> documents in diagnostics that numeric signals were disabled for this row. <br>3. <code>CandidateList</code> may include lower confidence entries; <code>candidate.persist</code> still occurs with <code>lowConfidence</code> flag for analyst review. <br>Remediation: analyst selects <code>decimalLocale</code> override or corrects source file and re-ingests; re-run matching with <code>correctionOf</code> linking. <br><br> <strong>Example 3 — Rounding and tie-breaker deterministic seed application:</strong> <br>Context: two candidate assets produce identical scaled integer candidateScore due to symmetric signals. <br>Resolution: <br>1. <code>ResolveTieBreakers</code> applies comparators; preRounded amounts equal, historical mapping counts equal, lexicographic assetId tie remains. <br>2. Deterministic PRNG invoked with seed = <code>sha256(runHash | capexRowId | canonicalCandidateIds)</code> and canonical LCG parameters yield consistent ordering; <code>tieBreakTrace</code> persisted. <br>3. Choice recorded in <code>candidateMappingIndex</code> and included in <code>auditBundle</code> so auditors can reproduce why a specific asset was preferred. <br><br> <strong>Example 4 — Units-of-Production method missing usage data:</strong> <br>Context: an asset is configured as UoP and requires <code>usageThisPeriod</code> for accurate preRounded allocations. <br>Flow: <br>1. <code>ComputeDepreciation</code> marks schedule rows with <code>requiresManualInput</code> and emits <code>fa.depn.run.requires_manual_input</code> with examples. <br>2. <code>modMatch</code> traces candidate mappings unaffected, but the JE suggestions include <code>requiresManualData</code> flag; analysts are shown the evidence and asked to collect <code>usage</code> data. <br>3. After data is supplied and persisted in an approved evidence row <code>capexRowCorrection</code>, <code>ComputeDepreciation</code> re-runs for specific <code>assetRevisionId</code>s and new schedules are emitted. <br>Governance note: UoP assets missing usage default to manual review policy. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Power Query (PQ) conceptual guidance — pilots, parity, anti-patterns, steps (no code)</strong> <br><br> <strong>When to use PQ for <code>modMatch</code>:</strong> <br>1. Use PQ for rapid analyst-driven pilots, preview generation, diagnostic runs and to validate canonicalization recipes against backend implementations on small cohorts (recommendation: < 5k capex rows). <br>2. Do not use PQ for production matching at scale (10k+ assets) because of memory, compute and numeric precision limitations; PQ is a preview and parity tool, not the deterministic backend for full runs. <br><br> <strong>PQ architecture pattern for pilots:</strong> <br>1. Parameterize queries: <code>Capex_Staging(headerSynonyms, decimalLocale, sampleSize)</code>, <code>Asset_Staging(headerSynonyms, locale)</code> and <code>PolicySnapshotParam(policyJson)</code> to make transformations inspectable and reproducible. <br>2. Implement canonicalization as discrete named steps so analysts can inspect intermediate outputs (e.g., <code>Step_TrimAndNormalize</code>, <code>Step_TokenizeDescription</code>, <code>Step_ComputeMinorUnits</code>). <br>3. Persist PQ preview artifacts with <code>preview_manifest</code> including <code>previewHash</code> computed from canonical serialization in PQ (host provided hash function or external helper). <br><br> <strong>Canonicalization steps in PQ (conceptual):</strong> <br>1. Text normalization: if host functions support Unicode normalization use them; otherwise apply diacritic mapping tables maintained in query tables, apply deterministic punctuation normalization and whitespace collapse; ensure same tokenization rules as backend. <br>2. Tokenization: produce <code>descriptionTokens</code> by splitting on canonical separators, trimming, and deduplicating tokens; compute token frequency and bigram tokens as separate query steps. <br>3. Numeric parsing: pre-replace thousands separators; unify decimal separator based on <code>decimalLocale</code>; parse to numeric; compute <code>amountMinorUnits</code> as rounding to <code>roundingScale</code> and converting to integer by multiplying by <code>10^scale</code>. Where PQ lacks precision, represent high-precision intermediates as canonical strings and flag for backend recompute. <br>4. Policy hash: compute local <code>policyHash</code> by canonical string composition of the policy table rows (sorted deterministically) and host hash function; persist <code>policyHash</code> constant in preview manifest. <br><br> <strong>Scoring & pruning in PQ (conceptual):</strong> <br>1. Implement limited <code>fn_ScoreCandidate</code> as a parameterized custom function with deterministic integer math where host types allow; otherwise compute equivalent scaled integers using text math and strings to avoid floating drift. <br>2. Use buffered table joins and group-by operations instead of per-row external calls to avoid slow PQ custom function loops. <br>3. For seeded tie-breaker, emulate deterministic seed by computing <code>sha256</code> string inside PQ if available; ensure the seed composition and LCG steps match backend canonical library. <br><br> <strong>Anti-patterns and mitigations in PQ:</strong> <br>1. Per-row custom functions that call into web APIs or heavy lookups — avoid, they do not scale. <br>2. Intensive in-memory joins on large indices — mitigate by sampling for preview or offloading to backend. <br>3. Relying on PQ numeric precision for high-precision arithmetic — instead produce stringified high-precision intermediates and mark for backend recompute; include <code>requiresBackendRecompute</code> flag. <br><br> <strong>Testing PQ parity:</strong> <br>1. Create golden fixtures in PQ that include <code>policyHash</code>, <code>assetIndexChecksum</code> and <code>candidateMappingChecksum</code> for sample sets. <br>2. Run backend parity jobs to replay PQ inputs and assert identical <code>runHash</code> and <code>candidateMappingChecksum</code>; log <code>fa.verify.parity.failed</code> on mismatch and produce <code>pqParityReport</code> enumerating mismatches and suspected causes. <br><br> <strong>Operational PQ preview flow:</strong> <br>1. Analysts run PQ preview to create a <code>preview_manifest</code> with <code>previewHash</code> and zipped artifacts including <code>candidate_preview.csv</code>. <br>2. Backend parity job replays with exact same <code>policyHash</code> and inputs and asserts parity; mismatches block promotion until resolved. <br>3. For parity mismatches, record diagnostics in <code>pqParityReport</code> and escalate to engineering to align canonical primitives. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX measures & reporting patterns (no code snippets) — for modMatch operations</strong> <br><br> <strong>Design principles for DAX modeling:</strong> <br>1. Use canonical keys as relationships: <code>capexRowId</code>, <code>candidateMappingChecksum</code>, <code>policyHash</code>, <code>runId</code>, <code>previewHash</code>. <br>2. Avoid exposing raw PII on analyst dashboards; use tokenized values and evidenceRef drillthrough which requires approval. <br>3. Create measures that surface triage workflows, migration impacts, and the health of matching signals. <br><br> <strong>Core measures (conceptual descriptions):</strong> <br>1. <code>CandidateAverageScore</code> — average of <code>candidateScore</code> over selected period or vendor; useful for monitoring scoring drift. <br>2. <code>LowConfidenceCount</code> — count of candidate lists where top candidate < <code>autoAcceptThreshold</code> to drive analyst queues. <br>3. <code>TopSignalContributors</code> — distribution by <code>matchSignal.name</code> of signal contribution shares across accepted mappings to tune weights. <br>4. <code>CandidateAcceptanceRate</code> — accepted mappings vs suggested mappings over a rolling window to measure analyst adoption. <br>5. <code>MappingDriftRate</code> — proportion of capexRows where <code>oldCandidateMappingChecksum</code> != <code>newCandidateMappingChecksum</code> during a policy recompute; critical for migration KPIs. <br><br> <strong>Advanced operational measures and alerts:</strong> <br>1. <code>RunParityFailureCount</code> — number of runs where recomputed <code>candidateMappingChecksum</code> differs from stored golden checksums; triggers immediate engineering review. <br>2. <code>TieBreakerInvocationRate</code> — proportion of mappings where seeded tie-breaker used; high values may indicate low-signal data requiring upstream improvements. <br>3. <code>CandidatePersistFailureRate</code> — monitor object store persistence issues for evidence continuity. <br><br> <strong>Reporting & UX patterns:</strong> <br>1. Triage dashboard shows <code>LowConfidenceCount</code> by vendor/cost center with top 20 examples and <code>CandidateMappingAudit</code> drillthrough for analysts. <br>2. Migration dashboard visualizes <code>MappingDriftRate</code>, <code>capitalizationDecisionChangePct</code>, and <code>impactKPIs</code> for canary cohorts; provide quick filters for <code>policyHash</code> and <code>canaryPlanId</code>. <br>3. Provide downloadable audit bundle summaries for compliance packaging; ensure PII gating on exports and log chain-of-custody events. <br><br> <strong>Materiality & auditor controls:</strong> expose <code>autoAcceptThreshold</code>, <code>manualReviewThreshold</code> as slicers so auditors can simulate different governance settings without regenerating runs; display the active thresholds on captions. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>CI / Golden parity matrix, tests, and fixtures (exhaustive)</strong> <br><br> <strong>Unit test matrix (detailed):</strong> <br>1. <code>modCanonical</code> text normalization: Unicode NFKC, whitespace collapse, punctuation normalization, diacritic removal toggles, Turkish locale casefolding edge-cases. <br>2. Numeric parsing: ambiguous locale strings, negative-zero normalization, thousand separator removal, decimal normalization, rounding to minor units. <br>3. <code>ScoreMatchSignals</code> per-signal correctness: invoiceRef exactness, token overlap, amount proximity scaling, vendor alias fuzzy matching and bounds. <br>4. Fixed-point integer math: ensure <code>signalScale</code>, <code>scoreScale</code> produce identical integer outputs across runtimes for sample inputs. <br><br> <strong>Integration test matrix (detailed):</strong> <br>1. End-to-end <code>FindAssetCandidates</code> with golden <code>assetIndexSnapshot</code> and <code>capexRowFixture</code> verifying <code>candidateMappingChecksum</code>. <br>2. <code>BuildCandidateList</code> ordering and tie-breakers with seeded <code>runHash</code>. <br>3. Persist and rehydrate candidateMappingIndex entries and audit bundle assembly. <br>4. BulkAliasAcceptance and subsequent recompute flows. <br><br> <strong>Golden parity tests (policy & runtime parity):</strong> <br>1. Golden fixtures: <code>policySnapshot.json</code> canonicalized, <code>assetIndex</code> snapshot CSV canonical format and <code>capex</code> fixture files with expected <code>candidateMappingChecksum</code>. <br>2. Execute across PQ pilot and backend implementations and assert identical checksums. <br>3. Block protected branch merges on golden diff failures; require documented migration manifest and canary plan for policy changes causing golden diffs. <br><br> <strong>Property tests (invariants):</strong> <br>1. Order-independence: input row ordering should not affect candidateList for a given capexRow. <br>2. Idempotency: identical persist calls must return same <code>candidateMappingRef</code> and not create duplicates. <br>3. Deterministic tie-break reproducibility across seeds. <br><br> <strong>Performance & load tests (recommended matrix):</strong> <br>1. Single-node and distributed throughput: <code>FindAssetCandidates</code> for 10k, 100k, 1M assets in <code>assetIndex</code> with 10k capexRows per minute target. <br>2. Latency targets: <code>match.find.latencyP50</code> target < 50ms warm; P95 < 500ms depending on index sharding. <br>3. Persistence throughput: candidateMapping persist throughput and object store write latency characterization. <br><br> <strong>Security & privacy tests:</strong> PII redaction rules for <code>CandidateMappingAudit</code>, access-control tests for evidence retrieval requiring <code>approvalRef</code>, scanning persisted artifacts for accidental raw PII exposures. <br><br> <strong>Golden fixtures maintenance:</strong> Golden fixtures are authoritative artifacts stored in evidence store with <code>legalTags</code> and retention controls; any changes to canonicalization primitives or <code>policySnapshot</code> require migration manifest and re-generation of golden fixtures with cross-runtime parity verification. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Observability, telemetry, SLOs & incident runbooks (detailed)</strong> <br><br> <strong>Audit events (must be emitted):</strong> Each audit row includes <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code> or <code>candidateMappingChecksum</code>, <code>operatorId</code>, <code>paramsHash</code> or <code>policyHash</code>. <br>1. <code>fa.match.find</code> — per-capexRow find run. <br>2. <code>fa.capex.candidate_persisted</code> — on candidate persist. <br>3. <code>fa.match.bulk_accept</code> — on bulk alias acceptance. <br>4. <code>fa.match.recompute</code> — on policy recompute runs. <br>5. <code>fa.match.audit_requested</code> — on audit bundle retrieval. <br>6. <code>fa.verify.parity.failed</code> — when CI or parity job detects mismatch. <br><br> <strong>Evidence store conventions:</strong> append-only object store with <code>createdTs</code>, <code>checksum</code>, <code>retentionPolicy</code>, <code>legalTags</code>. Raw PII artifacts require explicit <code>approvalRef</code> for retrieval. All evidence retrievals generate chain-of-custody audit rows. <br><br> <strong>Key SLOs & suggested targets:</strong> <br>1. <code>match.find.latencyP50</code> < 50ms for warm caches on small indices. <br>2. <code>candidate.persist.latencyP50</code> < 200ms. <br>3. <code>ci.parityFailureRate</code> target 0 for protected branches. <br>4. <code>recompute.duration</code> for canary cohorts acceptable within defined windows in migration manifest. <br><br> <strong>Monitoring & alerts to configure:</strong> <br>1. Alert on <code>match.find.latency</code> P95 breaches to scale index or warm caches. <br>2. Alert on <code>candidate.persist.failures</code> to investigate object store health. <br>3. Alert on <code>ci.parityFailureRate</code> non-zero in protected branches. <br>4. Alert on <code>migration_hotstop</code> events generated by recompute runs. <br><br> <strong>Incident triage runbook (explicit steps):</strong> <br>1. Capture <code>correlationId</code> and <code>capexRowId</code> for the issue. <br>2. Retrieve <code>candidateMappingRef</code>, <code>assetIndexChecksum</code>, <code>policySnapshot</code> via evidenceRefs. <br>3. Re-run <code>FindAssetCandidates</code> locally with same inputs and <code>runHash</code> to reproduce. <br>4. If <code>candidateMappingChecksum</code> mismatch persists, gather <code>parityArtifact</code> and escalate to engineering with full evidence bundle. <br>5. If mis-posted JE or export exists, consult <code>applyDescriptor</code> and attempt <code>RevertJEs</code>; if revert impossible, assemble <code>forensic_manifest</code> and coordinate with GL/compliance teams. <br>6. Persist all investigation actions as audit rows. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Migration manifest & policy-change governance (complete process & required fields):</strong> <br><br><strong>Purpose:</strong> manage semantic changes to matching policy (weights, signal normalization, vendor boosts) with controlled canaries, parity testing, KPIs and rollback plans. <br><br><strong>Minimal required fields for <code>migrationManifest</code>:</strong> <br>1. <code>migrationId</code> <br>2. <code>author</code> <br>3. <code>createdTs</code> <br>4. <code>changeRationale</code> <br>5. <code>affectedPolicyRows[]</code> showing before/after canonicalized rows <br>6. <code>sampleFixtures[]</code> each with <code>fileRef</code> and <code>goldenChecksums</code> <br>7. <code>estimatedAffectedCount</code> <br>8. <code>canaryPlan</code> including cohort sizes, execution steps, monitoring windows and KPIs to observe <br>9. <code>rollbackPlan</code> describing snapshot refs and revert steps <br>10. <code>approvals[]</code> with role, approver id and timestamp <br>11. <code>testMatrix</code> listing unit/integration/golden tests to run pre-promotion <br><br><strong>Promotion lifecycle (explicit steps):</strong> <br>1. Draft migration manifest and register in policy governance system; include <code>sampleFixtures</code> representing typical and edge cases. <br>2. Execute canary plan against a small cohort (e.g., 1% assets) and monitor KPIs like <code>MappingDriftRate</code>, <code>capitalizationDecisionChangePct</code>, <code>DepnExpenseDeltaPct</code> for at least two cycles defined by policy. <br>3. If KPIs within thresholds and required approvals captured, promote policy snapshot and persist <code>migrationManifest</code> and canary results. <br>4. If KPIs exceed thresholds, abort promotion and produce <code>migration_hotstop</code> with sample diffs for remediation. <br>5. For regulated GL domains require compliance signature in <code>approvals[]</code> before any <code>ApplyCorrections</code> using the new policy. <br>6. Persist promotion event <code>fa.policy.migration.completed</code> with evidence refs and migration manifest. <br><br><strong>Governance invariants:</strong> any semantic change to <code>matchingWeights</code> or <code>featureNormalization</code> must be accompanied by a migration manifest; golden parity tests are blocking for protected branches. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Operational playbook & runbook snippets (concise but complete)</strong> <br><br> <strong>Common operations and CLI-like flows:</strong> <br>1. <code>match.find --capex &lt;capexRowId&gt; --policyRef &lt;policyHash&gt; --runId &lt;runId&gt;</code> → runs <code>FindAssetCandidates</code> for a single row and returns <code>candidateList</code> and <code>candidateMappingRef</code>. <br>2. <code>match.bulk-accept --manifest &lt;bulkAcceptRef&gt; --operator alice</code> → persists <code>BulkAliasAcceptance</code> and returns <code>affectedCapexList</code>. <br>3. <code>match.recompute --migration &lt;migrationId&gt; --canaryPlan &lt;planId&gt;</code> → runs <code>RecomputeCandidateScoresOnPolicyChange</code> for canary cohorts. <br>4. <code>match.audit --capex &lt;capexRowId&gt; --detail full --approval &lt;approvalRef&gt;</code> → produces <code>auditBundleRef</code>. <br><br> <strong>Triage steps for common faults:</strong> <br>1. Invalid ingest (<code>fa.asset.ingest.invalid</code> or <code>CNV_NUM_LOCALE_AMBIGUOUS</code>): fetch <code>assetIngestManifest</code> and <code>capexIngestManifest</code>, correct headerMap or locale parameter, re-ingest with <code>correctionOf</code> referencing prior <code>sourceFingerprint</code>. <br>2. Index outage (<code>fa.match.index_unavailable</code>): check index cluster health, restart index shards, and rebuild <code>assetIndex</code> from <code>assetIngestManifest</code> if necessary; re-run affected <code>capexRows</code> from staged list. <br>3. Golden parity failure in CI (<code>fa.verify.parity.failed</code>): fetch failing <code>parityArtifact</code>, compare <code>policyHash</code> and <code>canonicalVersion</code>, run local parity tests, and if policy change cause, open <code>migrationManifest</code>. <br>4. Mapping drift post-migration (<code>migration_hotstop</code>): pause promotion, gather <code>recomputeManifest</code>, review sample diffs, adjust <code>matchingWeights</code> or revert to prior <code>policyHash</code> and re-run parity tests. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Security, privacy & PII handling (strict rules)</strong> <br><br> 1. Raw PII (employee IDs, personal names, addresses) must only be stored in encrypted evidence blobs with <code>legalTags</code> and retrieval approval gating via <code>approvalRef</code>. <br>2. Analyst-facing artifacts (candidateMapping CSV, preview manifests) must contain tokenized PII only. <br>3. <code>CandidateMappingAudit</code> includes PII only when <code>approvalRef</code> is present and logs chain-of-custody audit rows with approver and timestamp. <br>4. All endpoints returning evidence refs must authenticate and authorization checks must confirm role-based access per <code>policySnapshot.approvalMatrix</code>. <br>5. Evidence store must enforce append-only semantics and cryptographic checksums to prevent tampering. <br>6. CI must include static analysis for secrets and PII leakage scans in build artifacts. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Performance & architecture guidance (detailed):</strong> <br><br> <strong>Scale tiers & recommended platform choices:</strong> <br>1. PQ pilot: suitable for small fleets (< ~5k capex rows) and interactive previews. <br>2. Backend worker pool with sharded <code>assetIndex</code> and parallel <code>FindAssetCandidates</code> workers: recommended for 10k+ assets and enterprise workloads. <br><br> <strong>Parallel compute model:</strong> <br>1. Shard by <code>assetId</code> or <code>vendor</code> to ensure deterministic ordering within shards; ensure canonical ordering across shards when producing global artifacts or checksums. <br>2. Compute per-capexRow operations are embarrassingly parallel; use fixed seeds and stable partitioning to guarantee reproducibility. <br>3. Use durable job manifests capturing <code>runId</code>, <code>runHash</code>, <code>assetIndexChecksum</code>, and <code>changedAssetRevisionIds[]</code> to enable selective recompute. <br><br> <strong>Storage pattern:</strong> <br>1. Object store for large artifacts (persisted candidateMappingIndex rows, preview zips, audit bundles). <br>2. Small relational store for manifests and fast evidence ref lookups (manifests table keyed by <code>runHash</code>, <code>policyHash</code>). <br>3. <code>assetIndex</code> snapshots stored both as serialized object store snapshots and binary memory-mapped indices for fast worker loading. <br><br> <strong>Autoscaling & batch windows:</strong> <br>1. Schedule heavy recompute windows for close periods; autoscale workers based on queue depth and SLO targets. <br>2. Use canary windows with gradual ramp-ups for policy promotions. <br><br> <strong>Deterministic reproducible pipelines:</strong> <br>1. All worker processes must read exact <code>policyHash</code>, <code>assetIndexChecksum</code>, and <code>runHash</code> before processing; any deviation must fail fast. <br>2. Use canonical LCG and canonical serialization libraries to avoid runtime drift. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria & release gates (explicit):</strong> <br><br> 1. Unit tests pass for canonicalization and signal math across locales. <br>2. Integration tests validate <code>FindAssetCandidates</code> end-to-end with canonical fixtures and expected checksums. <br>3. Golden parity tests pass across PQ pilot and backend runs; any golden diffs block merges on protected branches. <br>4. Migration manifests required for any change to <code>matchingWeights</code>, <code>signalNormalization</code>, <code>tieBreakerPolicy</code>, or <code>canonicalVersion</code>, with canary plan and KPIs executed successfully before promotion. <br>5. Two-person approval required for direct-posting to regulated GL ranges; ephemeral token issuance and applyDescriptor persistence required before mutation. <br>6. Evidence & retention enforced for regulated artifacts; parity verification jobs scheduled and passing. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Appendices — canonical field orders, templates, and checklists (complete)</strong> <br><br> <strong>Appendix A — Canonical CandidateList serialization field order (required for checksum):</strong> <br>1. <code>capexRowId</code> <br>2. <code>candidateRank</code> <br>3. <code>assetId</code> <br>4. <code>candidateScore</code> (fixed-scale decimal string) <br>5. <code>candidateScoreInt</code> (integer) <br>6. <code>matchSignals</code> serialized as sorted-by-name ascending <code>name:normalizedValue:rawEvidenceRef</code> segments concatenated with <code>;</code> <br>7. <code>scoringVectorUsedRef</code> <br>8. <code>policyHash</code> <br>9. <code>assetIndexChecksum</code> <br>10. <code>runHash</code> <br>11. <code>createdTs</code> (canonical ISO) <br>12. <code>candidateRowChecksum</code> <br><br> <strong>Appendix B — CandidateMappingManifest keys (conceptual):</strong> <br> - <code>candidateMappingRef</code> <br> - <code>capexRowId</code> <br> - <code>candidateMappingChecksum</code> <br> - <code>policyHash</code> <br> - <code>scoringVectorVersion</code> <br> - <code>assetIndexChecksum</code> <br> - <code>runHash</code> <br> - <code>createdBy</code> <br> - <code>createdTs</code> <br> - <code>correctionOf</code> optional <br><br> <strong>Appendix C — RecomputeManifest keys (conceptual):</strong> <br> - <code>recomputeRunId</code> <br> - <code>migrationId</code> <br> - <code>oldPolicyHash</code> <br> - <code>newPolicyHash</code> <br> - <code>assetIndexChecksum</code> <br> - <code>affectedCapexCount</code> <br> - <code>pctCapexWithCandidateChange</code> <br> - <code>pctCapitalizationDecisionChange</code> <br> - <code>impactKPIs</code> <br> - <code>recomputeRunHash</code> <br> - <code>createdTs</code> <br><br> <strong>Appendix D — Run verification checklist (operational):</strong> <br>1. Confirm <code>policyHash</code> equals approved snapshot for the run. <br>2. Verify presence and checksums of <code>assetIngestChecksum</code> and <code>capexIngestChecksum</code> in run manifests. <br>3. Recompute <code>candidateMappingChecksum</code> locally using canonical serialization and compare to persisted value. <br>4. Confirm <code>tieBreakTrace</code> is present when seeded tie-breaker invoked and seed persisted in run manifest. <br>5. Confirm candidateMapping persisted evidence refs resolve and PII access gating enforced. </td></tr><tr><td data-label="modMatch — Per-function Expert Technical Breakdown"> <strong>Closing operational note (concise):</strong> This ultra-detailed expansion of <code>modMatch</code> provides per-row canonical narratives, exhaustive function-level contracts with deterministic math and canonicalization rules, extended worked examples, PQ pilot guidance, DAX conceptual measures and reporting patterns, complete CI/golden parity requirements, observability, runbooks, migration governance, and operational templates. The blueprint enforces determinism, auditability, and governance; implementers must ensure integer arithmetic, canonical primitives, and evidence-first persistency are present in every runtime. If you want next artifacts (choose one or more): <br>1. Formal JSON Schema for <code>CapexTransactionRow</code>, <code>CandidateListEntry</code>, <code>candidateMappingManifest</code> and <code>recomputeManifest</code> with exact field ordering for canonical hashing. <br>2. Canonical CSV golden fixtures and expected sha256 checksums for <code>candidateMapping</code> golden tests. <br>3. Step-by-step Power Query canonicalization recipe with intermediate expected outputs for pilot teams. <br>4. Compact runbook PDF summarizing triage steps and commands for operations teams. <br>Specify which artifacts to produce and the environment preference; artifacts will be produced following the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 29</div></div><div class="table-caption" id="Table2" data-table="Docu_0186_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modDepreciationEngine — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modDepreciationEngine — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Preface & Intent (concise):</strong> This document is the canonical, implementation-grade specification for <code>modDepreciationEngine</code>. It consolidates fully expanded per-row forensic narratives, exact canonicalization & hashing recipes, exhaustive function-level contracts (inputs, outputs, invariants, failure modes, telemetry, CI tests, runbook actions), extended worked examples capturing edge-case nuance, conceptual Power Query pilot guidance (anti-patterns and mitigations), conceptual DAX reporting patterns tuned for reconciliation and operational observability, full testing and CI/golden parity prescriptions, and operator runbooks including migration governance. The content is implementation-neutral (VBA, backend workers, PQ) and intentionally prescriptive: follow the canonical recipes verbatim to obtain reproducible <code>runHash</code>, <code>previewHash</code>, and artifact checksums. All numbered lists use <code>&lt;br&gt;</code> line breaks for deterministic downstream rendering. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Audience & usage:</strong> <br> This reference is for engineers implementing <code>modDepreciationEngine</code> (VBA prototypes, Python/Go backend services), finance/asset accountants validating outputs, and compliance/audit teams verifying deterministic evidence chains. Use it as the single source of truth when writing code, creating golden fixtures, authoring policy migration manifests, or operating the pipeline in production. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Glossary (short):</strong> <br> <code>canonicalVersion</code> — version of canonicalization recipe used for hashing. <br> <code>policySnapshot</code> — canonical policy object with <code>policyHash</code>. <br> <code>evidenceRef</code> — immutable pointer to stored object. <br> <code>assetRowChecksum</code>, <code>capexRowChecksum</code>, <code>scheduleRowChecksum</code>, <code>runHash</code>, <code>previewHash</code> — <code>sha256:</code> prefixed checksums over canonicalized payloads. <br> <code>minorUnits</code> — integer representation of monetary values scaled by <code>10^scale</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Canonical row narratives — expanded per-field forensic semantics</strong> <br> <strong>AssetRow (ultra-detailed):</strong> <br> Purpose: canonical atomic snapshot representing a capital asset at a discrete point in time; used for deduplication, audit, depreciation input and forensic replay. <br> Primary invariants: identical raw evidence + identical <code>canonicalVersion</code> + identical header mapping produce the same <code>assetRowChecksum</code>. <br> Per-field semantics (exhaustive): <br> 1. <code>assetId</code> — authoritative deterministic id used as referent across systems. Construction rules: if source <code>assetTag</code> present and policy allows use, canonicalize token and use <code>sha256(canonicalAssetTag)</code>; otherwise build <code>canonicalAssetKey</code> from canonicalized <code>descriptionToken|acquisitionDate|locationToken</code> and compute <code>sha256(canonicalAssetKey)</code>. Persist mapping from source key → assetId in evidence index. Invariance: deterministic across re-ingests provided canonicalization and header mapping unchanged. <br> 2. <code>assetTag</code> — preserve original printed form in <code>rawPayloadRef</code>. Produce <code>assetTagToken</code> for matching by applying Unicode NFKC, trim, collapse whitespace to U+0020, casefold, strip diacritics if policy allows. Document locale exceptions (e.g., Turkish dotted/dotless i) in <code>policySnapshot.localeHandling</code>. <br> 3. <code>description</code> — store raw text and <code>descriptionToken</code> produced using same canonical text recipe as <code>assetTag</code>. Keep a <code>descriptionFingerprint</code> (short hash) for quick similarity searches. <br> 4. <code>category</code> — controlled-codelist string; canonicalization must map source synonyms via <code>policySnapshot.categorySynonyms</code> (manifest this mapping). Unmapped values become <code>Unclassified</code> and added to <code>assetIngestManifest.issues[]</code> with top-k examples for mapping owners. Changing category semantics requires <code>migrationManifest</code>. <br> 5. <code>location</code> — canonical site code preferred; if only free text, apply location dictionary mapping; include <code>locationMappingConfidence</code> and <code>locationMappingTrace[]</code> describing steps. <br> 6. <code>custodianEmployeeId</code> — display tokenized pseudonym on analyst surfaces (e.g., <code>emp:XXXX</code>). Raw PII is stored encrypted; retrieval of raw requires <code>approvalRef</code> and emits chain-of-custody audit. Document pseudonymization algorithm for reproducibility. <br> 7. <code>acquisitionDate</code> — canonicalize to <code>YYYY-MM-DD</code>; if time-of-day is required by policy use <code>YYYY-MM-DDTHH:MM:SSZ</code>; record <code>rawDateString</code> and <code>parseAttemptLogs</code> with parse outcomes and heuristics used. For ambiguous parse outcomes record <code>issues[]</code>. <br> 8. <code>acquisitionCost</code> — store canonical decimal string and also <code>amountMinorUnits</code> (integer) plus <code>roundingScale</code> (scale used for canonicalization). Parsing rules: remove thousands separators, normalize decimal separator to <code>.</code> before parse; if ambiguous locale record <code>sourceCulture</code>. Negative-zero maps to <code>0.00</code>. For pre-rounded internal math record <code>internalPrecisionScale</code> in manifests; internal precision is not part of canonical hashing unless explicitly requested. <br> 9. <code>currency</code> — ISO4217 canonical; if missing use <code>assetIngestManifest.defaultCurrency</code> and log <code>issues[]</code>. <br> 10. <code>usefulLifeMonths</code> — integer; if missing, derive from <code>policySnapshot.categoryDefaults</code>; set <code>usefulLifeSource</code> to <code>policy_default</code> or <code>asset_override</code> and record <code>overrideReason</code> + <code>overrideBy</code> for traceability. Values ≤ 0 are invalid and must set <code>requiresManualOverride</code> with <code>diagnostic</code>. <br> 11. <code>depreciationMethod</code> — <code>SL|DDB|SYD|UnitsOfProduction|Custom</code>; default from <code>policySnapshot.categoryDefaults</code>. If <code>Custom</code> include <code>methodDefinitionRef</code> in <code>evidenceRefs</code>. <br> 12. <code>salvageValue</code> — decimal in asset currency; if missing use <code>policySnapshot.salvageDefaults</code> and record provenance. <br> 13. <code>componentOf</code> & <code>componentRole</code> — link to parent assetId when componentized. <code>componentRole</code> values control capitalization treatment (<code>capitalized_into_parent</code> vs <code>separately_depreciable_component</code>). If component added, ensure <code>assetRevisionId</code> created and child-parent snapshots persisted. <br> 14. <code>assetRowChecksum</code> — sha256 over canonical field ordering string; do not include transient provenance fields. Prefix <code>sha256:</code> in persisted manifest. <br> 15. <code>rawPayloadRef</code>, <code>evidenceRefs[]</code>, <code>provenance[]</code> — append-only lists pointing to stored raw files, offsets and operator actions. Evidence retrieval requires <code>approvalRef</code> for PII. <br> Forensic best practices: always persist <code>assetRowChecksum</code> and raw evidence before any downstream transform; include canonicalVersion in manifest; record <code>correctionOf</code> when re-ingesting corrected files. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>CapexTransactionRow (ultra-detailed):</strong> <br> Purpose: represent AP/PO/CAPEX evidence and candidate mappings to assets. <br> Per-field semantics: <br> 1. <code>capexRowId</code> — deterministic id computed from <code>sourceFingerprint|fileOffset|canonicalTokens</code> to produce stable id across replays. <br> 2. <code>transactionDate</code> — canonicalize to <code>YYYY-MM-DD</code>; store <code>rawDateString</code> and <code>parseAttemptLogs</code>. <br> 3. <code>amount</code> — canonical decimal string and <code>amountMinorUnits</code> integer + <code>scale</code>; record <code>originalSignRepresentation</code> (if source had separate debit/credit columns) and <code>signConvention</code> used to canonicalize. <br> 4. <code>vendor</code>, <code>invoiceRef</code>, <code>poNumber</code> — store raw and canonical tokens; run vendor normalization using <code>policySnapshot.vendorDictionary</code>. Preserve <code>vendorRaw</code> and <code>vendorToken</code>. <br> 5. <code>costCenter</code> — preserved raw and canonical mapping; mapping missing flagged to <code>issues[]</code>. <br> 6. <code>assetIdCandidates[]</code> — structured candidate list: for each candidate include <code>assetId</code>, <code>candidateScore</code> (0..1 with documented weights), <code>matchSignals[]</code> (e.g., <code>invoiceRefExact</code>, <code>assetTagInDescription</code>, <code>vendorCoOccur</code>), <code>candidateRowChecksum</code> (to separate mapping state from raw evidence). Sorting deterministic: <code>candidateScore</code> desc → <code>assetId</code> lexicographic → seeded fallback. Persist scoring vector used in <code>manifest.policySnapshot.matchingWeights</code>. <br> 7. <code>capitalCandidate</code> — boolean computed using <code>policySnapshot.capitalizationThreshold</code> and policy overrides; store <code>capitalReason</code> and <code>capitalConfidence</code>. <br> 8. <code>capexRowChecksum</code> — sha256 over canonical row string excluding transient matching heuristics; persisted to evidence store. <br> 9. <code>issues[]</code> — parsing issues, low-confidence flags, ambiguous currency, missing invoiceRef; low-confidence items increment <code>capex.ingest.unmappedCount</code> and route to the analyst mapping queue. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>DepreciationScheduleRow (ultra-detailed):</strong> <br> Purpose: atomic, auditable per-period schedule entry used to produce JE proposals and reconcile to GL. <br> Per-field semantics and invariants: <br> 1. <code>scheduleId = sha256(assetRevisionId|periodStart|periodEnd|policyHash)</code> — immutable once created; new policyHash or assetRevisionId yields new scheduleId. Persist old schedule rows for forensic trace. <br> 2. <code>assetId</code>, <code>assetRevisionId</code> — link back to canonical asset snapshot. <br> 3. <code>periodStart</code> / <code>periodEnd</code> — canonical ISO dates with <code>dayCountBasis</code> recorded (e.g., <code>actual/actual</code>, <code>30/360</code>) and <code>businessDayAdjustment</code> if applied. <br> 4. <code>preRoundedAmount</code> — high-precision decimal string computed at <code>policyInternalPrecision</code> (e.g., 6 decimals or more); persist as string to avoid cross-runtime float skew. <br> 5. <code>depreciationAmount</code> — final rounded decimal per <code>roundingScale</code>. Also store <code>amountMinorUnits</code> to keep integer parity. <br> 6. <code>accumulatedDepreciationToDate</code>, <code>bookValueStart</code>, <code>bookValueEnd</code> — computed deterministically. <code>bookValueEnd</code> = <code>bookValueStart</code> - <code>depreciationAmount</code>. Validate <code>bookValueEnd</code> never below zero after enforcement step. <br> 7. <code>method</code> & <code>methodParams</code> — capture method type and exact parameter set used (e.g., <code>DDB {factor:2.0}</code>, <code>UoP {totalExpectedUsage:10000}</code>). <code>methodParams</code> must be fully specified to permit deterministic replay. <br> 8. <code>prorationFactor</code>, <code>prorationBasis</code>, <code>daysInPeriod</code>, <code>daysCounted</code> — store exact proration computations and trace lines so auditors can recompute. <br> 9. <code>residualAbsorbed</code> — amount absorbed in this row due to rounding residual and <code>residualRationale</code>. Always record even when zero. <br> 10. <code>scheduleRowChecksum</code> — deterministic sha256 over canonical serialization excluding transient operator comments. <br> 11. <code>evidenceRefs[]</code> — pointers to contributing <code>assetRowChecksum</code>, <code>capexRowChecksums</code>, <code>policyHash</code> and run manifest. <br> Revisioning: if asset revised then new schedule rows are produced; prior schedule rows are retained with immutable checksums and evidentiary links to revision snapshots. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>EventRows — Disposal / Revaluation / Impairment (ultra-detailed):</strong> <br> Purpose: represent discrete events that materially change asset accounting. <br> Per-field semantics: <br> 1. <code>eventId</code>, <code>assetId</code>, <code>eventDate</code> — canonical identifiers. <br> 2. <code>eventType</code> — <code>Disposal|Revaluation|Impairment|Other</code>. <br> 3. <code>proceeds</code>, <code>proceedsMinorUnits</code>, <code>proceedsCurrency</code>, <code>fxRateRef</code> — if proceeds currency differs from book currency persist <code>fxRateRef</code> and conversion steps. Record <code>fxConversionAudit</code> showing rate used, rate source <code>fa_fx_&lt;ref&gt;</code>, and rounding steps. <br> 4. <code>adjustedBookValue</code>, <code>gainLossRecognized</code> — computed deterministically using canonical NBV and proceeds conversion; attach <code>taxTreatment</code> object specifying deferred/taxable handling. <br> 5. <code>revalBasis</code> & <code>revalInputs[]</code> — for revaluations capture method (market, appraisal, index), input values, and evidenceRefs to appraisals/indices. <br> 6. <code>approvalRef</code> — pointer to regulatory/finance approval required before recognition; cannot be applied without approval when policy mandates. <br> 7. <code>eventRowChecksum</code> & <code>rawPayloadRef</code>. <br> Forensics: event rows must always reference the <code>depreciationRunManifest</code> in which they were considered; event application is an explicit apply operation producing new <code>assetRevisionId</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>JE_Line & JE_Bundle (ultra-detailed):</strong> <br> Purpose: structured set of journal lines delivered as preview and export artifacts for GL loaders. <br> Key contracts: <br> 1. <code>jeLineId</code>, <code>jeId</code>, <code>jeBundleSequence</code> — unique ids and deterministic ordering for idempotent posting. Preserve <code>jeBundleSequence</code> in export files; compute <code>jeChecksum</code> over ordered <code>jeLines[]</code> + <code>jeMetadata</code>. <br> 2. <code>account</code> — canonical GL account string or mapping key. GL account resolution uses <code>policySnapshot.mappingOverrides</code> and <code>mappingSuggestion</code> entries when absent. <br> 3. <code>debitCredit</code> — <code>Debit</code> or <code>Credit</code> consistent with <code>exportSpec</code> sign convention. <br> 4. <code>amount</code> and <code>amountMinorUnits</code> — canonical amounts at <code>roundingScale</code>. <br> 5. <code>narrative</code> — deterministic templates embedding <code>assetId</code> and evidenceRefs; templates come from <code>policySnapshot.jeTemplateSpec</code>. <br> 6. <code>costCenter</code>, <code>currency</code>, <code>period</code> — included for downstream allocation and reconciliation. <br> 7. <code>evidenceRefs[]</code>, <code>confidenceScore</code>, <code>confidenceBreakdown</code> — provide analyst triage signals. <br> 8. Balancing invariant: each <code>jeId</code> must balance to zero at <code>roundingScale</code>; if there is a micro imbalance apply deterministic absorption or fail preview if over tolerance. <br> Audit: JE bundles persisted with <code>previewHash</code> and <code>exportChecksum</code> and recorded in <code>depreciationRunManifest</code> for traceability. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Canonicalization & hashing — precise recipes for parity</strong> <br> 1. <strong>Text normalization:</strong> apply Unicode NFKC then perform deterministic trimming (remove leading/trailing whitespace), collapse any sequence of whitespace (including tabs, NBSP) into single U+0020, map known punctuation variants to canonical characters per <code>policySnapshot.punctuationMap</code> (e.g., en-dash → hyphen), then <code>casefold()</code> using Unicode casefold; optional diacritic removal controlled via <code>policySnapshot.localeHandling</code>. Persist original raw field in evidence. Document any locale-specific exceptions in <code>policySnapshot.localeHandling</code>. <br> 2. <strong>Numeric canonicalization:</strong> remove thousands separators (both <code>,</code> and locale-specific), normalize decimal separator to <code>.</code> before parsing; if ambiguous locale then record <code>sourceCulture</code> and <code>parseAttemptLogs</code>. Compute <code>amountMinorUnits = round(value * 10^scale)</code> where <code>scale = roundingScale</code> or explicit field <code>scale</code>. For preRounded internal math, use <code>policyInternalPrecision</code> (e.g., 6 or 8 decimals) and keep results in string format. Normalize negative zero to positive zero for canonical strings. <br> 3. <strong>Date/time canonicalization:</strong> use <code>YYYY-MM-DD</code> for date-only fields. If time-of-day permitted use <code>YYYY-MM-DDTHH:MM:SSZ</code> normalized to UTC; canonicalize sub-second to three digits and deterministic rounding rules for milliseconds. Always store <code>rawDateString</code> on ambiguous parse. <br> 4. <strong>Serialization ordering & separators:</strong> each canonical model defines an exact field order. Produce canonical serialization strings by concatenating fields using <code>|</code> as separator. Embedded <code>|</code> characters within field content must be escaped using a canonical escape token <code>\uE000</code> (private use) or an explicit escape sequence documented in <code>policySnapshot</code>. Do not append trailing newline; canonical string ends exactly with the last field text. <br> 5. <strong>Lists & arrays:</strong> embed arrays as JSON-compact strings with deterministic ordering of object keys; arrays that are logically unordered must be sorted deterministically (lexicographically or via canonical key) before embedding. <br> 6. <strong>Hashing & manifest stamping:</strong> encode canonical string as UTF-8, compute SHA-256 hex digest in lowercase, and prefix with <code>sha256:</code> in manifests. Include <code>canonicalVersion</code> and <code>policyHash</code> where relevant in manifests to ensure identity includes canonicalization recipe and policy semantics. <br> 7. <strong>Deterministic tie-breakers:</strong> where deterministic selection required, apply rules in order: (a) pick candidate with highest primary metric (e.g., absolute preRounded amount), (b) if tied choose lexicographically smallest <code>assetId</code> or <code>rowId</code>, (c) if still tied produce deterministic seeded fallback using <code>sha256(runHash|elementIdentifiers)</code> and map hex subset to an integer for final ordering. Record seed composition in <code>depreciationRunManifest</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Engine overview — ComputeDepreciationRun (orchestrator, expanded):</strong> <br> Purpose: deterministic engine producing per-asset schedules, candidate treatment decisions, JE proposals, and immutable run manifest. <br> Pre-conditions: <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policySnapshot</code> persisted and referenced by checksums; evidence store accessible; <code>params</code> include <code>periodStart</code>, <code>periodEnd</code>, <code>runId</code> (used as optional deterministic seed), <code>roundingScaleOverride</code> optional, <code>mode</code> (<code>strict|tolerant</code>). <br> High-level responsibilities & outputs: <br> 1. Validate inputs (<code>ValidateInputsAndPreChecks</code>) and produce <code>validationReport</code>; in <code>strict</code> mode abort on fatal errors, in <code>tolerant</code> mode mark <code>issues[]</code> but continue for non-fatal rows. <br> 2. Emit audit <code>fa.depn.run.start{runId,paramsHash,policyHash,correlationId}</code>. <br> 3. Run <code>EvaluateCapitalizationDecision</code> for capex rows to deterministically match and score candidates; persist <code>candidateMappingIndex</code>. <br> 4. Materialize accepted candidate decisions into immutable asset revisions via <code>AugmentAssetRevision</code>; persist <code>assetRevisionId</code> and link to prior snapshots. <br> 5. For each assetRevision compute <code>depreciationStart</code> using <code>DetermineDepreciationStartAndProration</code>. <br> 6. Select method-specific computation and execute <code>ComputeMethod_*</code> to produce high-precision <code>preRoundedPeriods[]</code>. <br> 7. Centralize rounding via <code>PreRoundAndRoundValues</code> to ensure identical rounding logic across methods. <br> 8. Compute residuals and absorb using <code>ResidualAbsorptionAndAdjustFinalPeriod</code> according to deterministic rules and possible group-level absorption policies. <br> 9. Enforce NBV constraints and apply deterministic final period adjustments when required; flag <code>requiresManualOverride</code> if outside policy tolerances. <br> 10. Evaluate impairment/revaluation signals producing <code>RevaluationProposal[]</code> (non-mutative). <br> 11. Aggregate per-period schedules into JE proposals using <code>GenerateScheduledJEProposals</code> as preview artifacts. <br> 12. Assemble <code>depreciationRunManifest</code> with <code>runHash = sha256(canonicalManifest)</code>, persist run manifest and per-run artifacts into evidence store, and emit <code>fa.depn.run.completed{runId,runHash}</code>. <br> Detailed invariants: given identical canonical inputs and same <code>policyHash</code>, <code>canonicalVersion</code>, and <code>runId</code> seed, outputs (schedule rows, JE proposals, run manifest) must be byte-for-byte identical across platforms. <br> Failure handling: fatal canonical mismatches abort in <code>strict</code> mode; non-fatal missing inputs (UoP usage, FX rates) mark <code>requiresManualInput</code> and queue assets for analyst action; unresolved critical failures raise <code>fa.depn.run.fail</code>. <br> Determinism & seeding: any pseudo-random fallback must use <code>DeterministicSeedFromRunHash(runHash,context)</code> and never system time or platform RNG without an explicit deterministic seed. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Function-level breakdowns — complete contracts (expanded)</strong> <br> <strong>ComputeDepreciationRun(assetRows[], capexRows[], policySnapshot, params)</strong> <br> Purpose: orchestrate the end-to-end compute for the requested period; produce deterministic schedules, suggested JEs, and run manifest. <br> Inputs: <code>assetRows[]</code> canonical, <code>capexRows[]</code> canonical, <code>policySnapshot</code> (with <code>policyHash</code>), <code>params</code> (periodStart, periodEnd, runId, roundingScaleOverride, mode). <br> Outputs: <code>DepreciationSchedule[]</code>, <code>SuggestedJEs[]</code>, persisted <code>depreciationRunManifest</code> (<code>fa_depn_run_&lt;runId&gt;_&lt;runHash&gt;.json</code>), audit events. <br> Responsibilities (detailed): <br> 1. Call <code>ValidateInputsAndPreChecks</code> to assert canonical parity; produce <code>validationReport</code>. <br> 2. Emit audit start event and set <code>correlationId</code>. <br> 3. Build asset index keyed by <code>assetId</code>, <code>assetTagToken</code>, <code>descriptionFingerprint</code> to support candidate mapping. <br> 4. For each capexRow flagged for processing call <code>EvaluateCapitalizationDecision</code> and persist <code>candidateList</code> and <code>capitalizationDecision</code> objects; route ambiguous decisions to <code>analystMappingQueue</code>. <br> 5. Where decisions accepted (auto or manual), invoke <code>AugmentAssetRevision</code> to create immutable asset revision(s) with deterministic <code>assetRevisionId</code>. <br> 6. For each asset revision compute <code>depreciationStart</code> and <code>prorationFactor</code> using <code>DetermineDepreciationStartAndProration</code>. <br> 7. Dispatch method-specific computation (<code>ComputeMethod_SL</code>, <code>_DDB</code>, <code>_SYD</code>, <code>_UoP</code>, <code>_Custom</code>) producing <code>preRoundedPeriods[]</code> for the asset. <br> 8. Aggregate preRounded values and call <code>PreRoundAndRoundValues</code> to obtain final <code>depreciationAmount</code> for each period and <code>roundingDelta</code>. <br> 9. Collect all per-asset rounded periods and compute canonical totals; call <code>ResidualAbsorptionAndAdjustFinalPeriod</code> to deterministically absorb residuals and produce <code>residualAbsorbed</code> entries. <br> 10. Run <code>EnforceNBVAndFinalAdjustments</code> to ensure NBV >= 0; persist <code>adjustmentReason</code> if corrections applied. <br> 11. Evaluate impairment signals producing <code>RevaluationProposal[]</code> without mutating asset records; proposals require explicit apply flows to become effective. <br> 12. Aggregate schedule rows using <code>jeTemplateSpec</code> to produce <code>SuggestedJEs[]</code> via <code>GenerateScheduledJEProposals</code>. <br> 13. Assemble and persist <code>depreciationRunManifest</code> using <code>AssembleDepreciationRunManifest</code>. <br> 14. Persist schedules via <code>PersistSchedulesAtomic</code> and emit <code>fa.depn.run.completed</code>. <br> Invariants: reproducibility across environments; every persistent artifact includes <code>canonicalVersion</code> and <code>policyHash</code>. <br> Failure modes & remediation: <br> - Missing <code>policyHash</code> or invalid <code>policySnapshot</code> schema → emit <code>fa.depn.run.invalid_policy</code> and abort. <br> - Missing usage (UoP) → mark rows with <code>requiresManualInput</code> and emit <code>fa.depn.run.requires_manual_input</code> with sample asset list. <br> - FX rate table missing for cross-currency disposals → emit <code>fa.depn.run.fx_missing</code> and either halt (strict) or queue (tolerant) per <code>params.mode</code>. <br> Observability & telemetry: <code>depn.run.durationMs</code>, <code>schedulesGenerated</code>, <code>jeProposalCount</code>, <code>residualAdjustmentsCount</code>, <code>requiresManualInputCount</code>, <code>depn.run.cpuMs</code>. <br> CI tests: full-run golden fixtures asserting <code>runHash</code>; property tests for ordering independence and idempotency; method-specific unit tests. <br> Runbook excerpt: on <code>fa.depn.run.requires_manual_input</code> inspect manifest <code>requiresManualAssetList</code>, obtain missing fields (usage, salvage, life overrides), annotate asset revisions and re-run <code>ComputeDepreciationRun</code> for affected <code>assetRevisionIds</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>ValidateInputsAndPreChecks(inputs) — contract:</strong> <br> Purpose: lightweight but deterministic gating validations ensuring canonical parity and minimal schema correctness before compute. <br> Inputs: <code>assetRows[]</code>, <code>capexRows[]</code>, <code>policySnapshot</code>, <code>params</code>. <br> Outputs: <code>validationReport</code> containing <code>fatalErrors[]</code>, <code>warnings[]</code>, <code>diagnostics[]</code>. <br> Responsibilities: <br> 1. Ensure <code>policyHash</code> present and <code>policySnapshot</code> passes schema validation; compute <code>policyHashCandidate</code> from canonical serialization and assert equality if <code>policyHash</code> provided. <br> 2. Verify canonical serialization of <code>assetRows</code> and <code>capexRows</code> and compute <code>assetIngestChecksum</code>/<code>capexIngestChecksum</code> if not provided. <br> 3. Confirm required numeric and date fields parse to canonical formats; collect parse diagnostics and row-level <code>issues[]</code>. <br> 4. Ensure <code>roundingScale</code> present either in params or policySnapshot. <br> 5. Detect duplicate <code>assetRowChecksum</code> collisions and record suspected duplicates for analyst resolution. <br> Invariants: deterministic diagnostics for identical inputs. <br> Failure modes: fatal canonical inconsistencies cause <code>fa.depn.run.invalid_input</code> and abort; non-fatal field parse failures recorded in manifest. <br> Observability: <code>validation.latencyMs</code>, <code>validation.errors</code>. <br> CI tests: header permutation invariance, multi-locale numeric parsing, canonical checksum parity tests. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>EvaluateCapitalizationDecision(capexRow, assetIndex, policySnapshot) — contract:</strong> <br> Purpose: deterministic scoring and decision engine that maps capex transactions to assets and produces <code>capitalizationDecision</code>. <br> Inputs: <code>capexRow</code>, <code>assetIndex</code>, <code>policySnapshot</code>. <br> Outputs: <code>capitalizationDecision</code> including <code>decisionCode</code>, <code>evidenceRefs</code>, <code>decisionConfidence</code>, <code>candidateList[]</code>, <code>decisionTimestampCanonical</code>. <br> Responsibilities: <br> 1. Apply rule chain in strict order: invoiceRef exact match → assetTag token found in description → vendor-PO-asset historical co-occurrence → amount threshold → cost center mapping → vendor allowlist override. <br> 2. For each signal emit <code>matchSignal</code> with weight from <code>policySnapshot.matchingWeights</code> and compute <code>candidateScore</code> as weighted sum; use scaled integers for weights to avoid floating mismatch. <br> 3. Produce ordered <code>candidateList[]</code> and deterministic tiebreakers. <br> 4. If <code>candidateScore</code> < <code>policySnapshot.minMappingConfidence</code> route transaction to analyst queue with <code>capex.ingest.unmappedCount++</code>. <br> 5. Persist <code>candidateRowChecksum</code> and the <code>matchingWeights</code> vector used for audit. <br> Invariants: identical inputs + weights → identical <code>candidateList[]</code>. <br> Failure modes: ambiguous vendor names or OCR-noisy descriptions → low confidence, manual queue. <br> Observability: <code>candidateAverageScore</code>, <code>mapping.latencyMs</code>. <br> CI tests: seeded scoring reproducibility, noise tolerance fixture tests. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>AugmentAssetRevision(assetRow, capexRow, decision, policySnapshot, timestampCanonical) — contract:</strong> <br> Purpose: create immutable new asset revision when additions/components/revisions occur. <br> Inputs: base <code>assetRow</code>, <code>capexRow</code> (or eventRow), <code>decision</code> object, <code>policySnapshot</code>, <code>timestampCanonical</code>. <br> Outputs: <code>assetRevisionRow</code> persisted and <code>assetRevisionId = sha256(assetRowChecksum|capexRowChecksum|decisionTimestampCanonical)</code> returned. <br> Responsibilities: <br> 1. Compute deterministic <code>assetRevisionId</code>. <br> 2. Record <code>additionTreatment</code> (append_cost/create_component/restart_depn) with precise rationale <code>decisionRationale</code>. <br> 3. Persist new revision atomically; ensure prior revision remains immutable. <br> 4. Update evidence indexes linking <code>assetRowChecksum</code>, <code>capexRowChecksum</code>, and <code>assetRevisionId</code>. <br> Failure modes: persistence failure → retry with backoff; if persistent, emit <code>fa.depn.run.asset_revision_fail</code> and mark affected assets as <code>incompleteRevision</code>. <br> Observability: <code>asset.revisionsCreated</code>, <code>asset.revision.persistLatency</code>. <br> CI tests: idempotency of multiple identical decisions producing same <code>assetRevisionId</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>DetermineDepreciationStartAndProration(assetRevisionRow, policySnapshot, params) — contract:</strong> <br> Purpose: compute canonical <code>depreciationStart</code> and proration attributes for an asset revision. <br> Inputs: <code>assetRevisionRow</code>, <code>policySnapshot</code> (proration rules), <code>params.periodStart/End</code>. <br> Outputs: <code>depreciationStartDate</code>, <code>prorationFactor</code>, <code>prorationBasis</code>, <code>daysInPeriod</code>, <code>daysCounted</code>, <code>prorationTrace[]</code>. <br> Responsibilities: <br> 1. Select <code>startDateField</code> per policy (<code>acquisitionDate</code> or <code>inServiceDate</code>), falling back to <code>acquisitionDate</code> when missing and flagging <code>issues[]</code>. <br> 2. Apply day-count conventions (<code>actual/actual</code>, <code>30/360 US</code>, <code>30/360 ISDA</code>) and half-month rules if configured. <br> 3. If policy config specifies business-day adjustments apply calendar adjustments using deterministic business-day calendars referenced by <code>policySnapshot.calendarRef</code>. Store <code>daysInPeriod</code> and <code>daysCounted</code>. <br> 4. Persist <code>prorationTrace[]</code> showing computation steps for audit. <br> Failure modes: ambiguous dates produce <code>requiresManualInput</code>. <br> Observability: <code>proration.ambiguousDatesCount</code>. <br> CI tests: leap-year proration, month-end transitions, business-day adjustments parity. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>ComputeMethod_SL / ComputeMethod_DDB / ComputeMethod_SYD / ComputeMethod_UoP / ComputeMethod_Custom — contracts (group):</strong> <br> Purpose: method-specific pre-rounded math producing <code>preRoundedPeriods[]</code> for each assetRevision. <br> Shared inputs: <code>costMinorUnits</code>, <code>salvageMinorUnits</code>, <code>usefulLifeMonths</code> or <code>totalExpectedUsage</code>, <code>prorationFactor</code>, <code>policyInternalPrecision</code>. <br> Shared outputs: <code>preRoundedPeriods[]</code> (high-precision decimals as strings), <code>methodParams</code> fully specified, <code>diagnostics[]</code>. <br> Shared responsibilities: <br> 1. Perform high-precision internal math at <code>policyInternalPrecision</code> (e.g., 6+ decimals). <br> 2. Do not round to <code>roundingScale</code> until <code>PreRoundAndRoundValues</code>. <br> 3. Produce <code>preRoundedAmount</code> for each scheduled period and return method parameters for deterministic replay. <br> Method-specific behaviors: <br> - <strong>SL:</strong> evenly divide (cost - salvage) across <code>usefulLifeMonths</code>; apply <code>prorationFactor</code> to first/last month where applicable; record <code>usefulLifeSource</code>. <br> - <strong>DDB:</strong> compute <code>rate = ddbFactor / (usefulLifeMonths/12)</code> converted to monthly equivalent; for each period apply rate to opening book value; deterministically switch to SL when remaining DDB decrement would over-depreciate compared to SL remainder; record <code>switchPeriod</code> and <code>switchRationale</code>. <br> - <strong>SYD:</strong> compute annual SYD numerator/denominator and map to monthly fractions deterministically; ensure month-splits are consistent with <code>prorationBasis</code>. <br> - <strong>UoP:</strong> compute per-period allocation as ((cost - salvage) * usageThisPeriod / totalExpectedUsage); missing usage triggers <code>requiresManualInput</code>. <br> - <strong>Custom:</strong> accept user-supplied deterministic algorithm via <code>methodDefinitionRef</code>; changes to custom definitions must go through <code>migrationManifest</code>. <br> Failure modes: zero or negative life → <code>requiresManualOverride</code>. <br> Observability: method-specific metrics: <code>sl.rows</code>, <code>ddb.switchCount</code>, <code>syd.checks</code>, <code>uop.missingUsageCount</code>. <br> CI tests: per-method golden fixtures, switch-to-SL parity checks, UoP missing usage workflows. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>PreRoundAndRoundValues(preRoundedValue, policyInternalPrecision, roundingScale, roundingMode) — contract:</strong> <br> Purpose: perform deterministic pre-rounding and final rounding with audit trails. <br> Inputs: <code>preRoundedValue</code> (string numeric at internal precision), <code>policyInternalPrecision</code>, <code>roundingScale</code>, <code>roundingMode</code> (default round-half-to-even). <br> Outputs: <code>roundedValue</code> (string), <code>roundingDelta</code>, <code>preRoundedSerialized</code>. <br> Responsibilities: <br> 1. Represent <code>preRoundedValue</code> as scaled integer using <code>policyInternalPrecision</code> (i.e., multiply by <code>10^policyInternalPrecision</code> and store integer as string if necessary). <br> 2. Apply rounding mode deterministically to <code>roundingScale</code> by performing integer division with tie-breaking per banker's rules. Do not rely on platform <code>Round</code> functions whose implementations vary. <br> 3. Persist <code>preRoundedSerialized</code>, <code>roundedValue</code>, and <code>roundingDelta</code> in scheduleRow for forensic audit. <br> 4. For half cases implement exact round-half-to-even algorithm in integer arithmetic. <br> Failure modes: overflow in integer scaling → fallback to string-based big decimal arithmetic or raise <code>CNV_NUM_OVERFLOW</code>. <br> Observability: <code>rounding.tiesCount</code>, <code>rounding.ops</code>. <br> CI tests: tie rounding cases (e.g., x.5 *), large-scale precision tests covering overflow boundaries. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>ResidualAbsorptionAndAdjustFinalPeriod(canonicalTotalMinorUnits, roundedPeriods[], groupingPolicy, runHash) — contract:</strong> <br> Purpose: compute canonical residual and deterministically absorb it into chosen target period(s) to ensure total equals canonical total. <br> Inputs: <code>canonicalTotalMinorUnits</code>, <code>roundedPeriods[]</code> (minor-units integers), <code>groupingPolicy</code> (asset-level or group-level absorption), <code>runHash</code> (seed). <br> Outputs: updated <code>roundedPeriods[]</code>, <code>residualAbsorbed</code> entries per period, <code>residualRationale</code> recorded. <br> Responsibilities: <br> 1. Compute <code>residual = canonicalTotalMinorUnits - sum(roundedPeriods)</code>. <br> 2. If <code>residual == 0</code> record no-op and persist. <br> 3. If <code>residual != 0</code> select absorption target deterministically: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. Choose period(s) with highest absolute <code>preRoundedAmount</code> metric. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. If tie, choose lexicographically smallest <code>assetId</code> followed by <code>scheduleId</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;c. If still tied, compute <code>DeterministicSeedFromRunHash(runHash, context)</code> and map to integer modulo candidate count. <br> 4. Apply residual to target period(s) by adding/subtracting integer residual and record <code>residualAbsorbed</code> in scheduleRow. <br> 5. For group-level policies distribute residual across assets deterministically per policy-specified rules (e.g., proportional to preRounded absolutes then lexicographic tie-break). <br> 6. If <code>|residual| &gt; policySnapshot.residualToleranceMinorUnits</code> emit <code>fa.depn.run.residual_exceeds_tolerance</code>. <br> Invariants: post-absorption <code>sum(roundedPeriods) == canonicalTotalMinorUnits</code>. <br> Observability: <code>residual.absorptionsCount</code>, <code>residual.totalMinorUnits</code>. <br> CI tests: fixtures with tie-case equal preRounded values across assets, group-level absorption and parity checks. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>EnforceNBVAndFinalAdjustments(scheduleRows) — contract:</strong> <br> Purpose: ensure Net Book Value (NBV) never becomes negative due to rounding or cumulative adjustments and make deterministic final-period corrections when needed. <br> Inputs: <code>scheduleRows[]</code> with accumulated fields computed. <br> Outputs: adjusted scheduleRows with <code>adjustmentReason</code> and <code>adjustedAmount</code> fields; <code>nbvAdjustmentsCount</code> metric. <br> Responsibilities: <br> 1. For each asset validate <code>bookValueEnd</code> >= 0; if violation is detected determine minimal deterministic correction to final period (reduce final period depreciation by required amount or re-absorb residual to restore NBV) with <code>adjustmentReason = &quot;negative_nbv_corrected&quot;</code>. <br> 2. If deterministic correction exceeds <code>policySnapshot.nbvAdjustmentToleranceMinorUnits</code> emit <code>fa.depn.run.adjustment_exceeds_tolerance</code> and mark asset for manual review. <br> 3. Persist <code>adjustedAmount</code> and resulting <code>bookValueEnd</code>. <br> Invariants: not to create negative NBV and keep overall canonical totals consistent (accounting for residuals). <br> Observability: <code>nbv.adjustmentsCount</code>, <code>nbv.adjustedMinorUnits</code>. <br> CI tests: negative NBV edge cases due to prior rounding and revaluation interactions. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>EvaluateImpairmentAndRevaluationProposals(assetRevisionRow, externalIndicators, policySnapshot) — contract:</strong> <br> Purpose: non-mutative detection of impairment/revaluation signals and construction of actionable proposals for analyst review. <br> Inputs: <code>assetRevisionRow</code>, <code>externalIndicators</code> (impairment signals, indices, appraisals), <code>policySnapshot</code>. <br> Outputs: <code>RevaluationProposal[]</code> with suggested JE consequences and <code>evidenceRefs</code>. <br> Responsibilities: <br> 1. Apply policy-defined impairment thresholds (e.g., fair value decreases > X% or indicators present) and determine whether a proposal is required. <br> 2. When triggered build <code>RevaluationProposal</code> objects containing proposed adjustments, JE lines, <code>taxTreatment</code> impacts, and approvals required. <br> 3. Do not mutate <code>assetRow</code> or schedule rows; proposals are queued for analyst approval and explicit <code>ApplyCorrections</code>. <br> 4. Persist <code>proposalChecksum</code> for reproducibility. <br> Observability: <code>impairment.proposalsCount</code>, <code>impairment.requiresApprovalCount</code>. <br> CI tests: impairment trigger fixtures, revaluation JE suggestion validation. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>GenerateScheduledJEProposals(scheduleRows, jeTemplateSpec, policySnapshot) — contract:</strong> <br> Purpose: aggregate schedule rows into balanced, evidence-backed JE preview bundles ready for analyst review. <br> Inputs: <code>scheduleRows[]</code>, <code>jeTemplateSpec</code> (export mapping & sign conventions), <code>policySnapshot.mappingOverrides</code>. <br> Outputs: <code>SuggestedJEs[]</code> (bundles with <code>jeLines[]</code>), preview artifact <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>, <code>previewManifest</code>. <br> Responsibilities: <br> 1. Map schedule categories to GL accounts using <code>policySnapshot.mappingOverrides</code>. Where mapping missing produce <code>mappingSuggestion</code> entries included in preview artifact. <br> 2. Group schedule rows deterministically by posting keys defined in <code>jeTemplateSpec</code> (e.g., <code>GLAccount|costCenter|currency|period</code>). Persist group ordering. <br> 3. Aggregate debits and credits applying consistent <code>roundingScale</code>. <br> 4. Validate each JE bundle balances at <code>roundingScale</code>. If micro-imbalance ≤ <code>policySnapshot.bundleImbalanceToleranceMinorUnits</code> apply deterministic intra-bundle residual absorption and record <code>residualAbsorbedBy</code> and rationale. If imbalance > tolerance fail preview for those bundles and mark as action required. <br> 5. Compute <code>confidenceScore</code> per bundle from mapping completeness, DQ penalty (e.g., missing costCenter), and manual flags; include <code>confidenceBreakdown</code> for analyst transparency. <br> 6. Package artifact as deterministic zip containing canonical <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>; compute <code>previewHash = sha256(canonicalPreviewManifest)</code>. Persist artifact to evidence store. <br> Observability: <code>je.preview.count</code>, <code>je.preview.unbalancedCount</code>, <code>preview.latencyMs</code>. <br> CI tests: bundle balancing across permutations, mapping suggestion injection, preview manifest goldens. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>AssembleDepreciationRunManifest(evidenceRefs, policyHash, params, counts) — contract:</strong> <br> Purpose: canonical assembly of run manifest including inputs, counts, param hash and policy hash; compute <code>runHash</code> and persist manifest. <br> Inputs: <code>evidenceRefs</code> (assetIngestChecksum, capexIngestChecksum, fxTableRef, etc.), <code>policyHash</code>, <code>params</code>, <code>counts</code> (schedules, jeProposals). <br> Outputs: persisted <code>depreciationRunManifest</code> JSON with <code>runHash = sha256(canonicalManifest)</code> and evidenceRef returned. <br> Responsibilities: <br> 1. Create canonical manifest string using specified field ordering and serialization rules. <br> 2. Include <code>canonicalVersion</code> and <code>policyHash</code>. <br> 3. Compute <code>runHash</code> and prefix <code>sha256:</code>. <br> 4. Persist atomically and emit <code>fa.depn.run.completed{runId,runHash}</code>. <br> Observability: <code>manifest.persistLatency</code>, <code>manifest.sizeBytes</code>. <br> CI tests: manifest canonicalization parity across runtimes. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>PersistSchedulesAtomic(scheduleRows, manifestRef, storagePath) — contract:</strong> <br> Purpose: persist schedule rows in canonical CSV/JSON atomically into evidence store. <br> Inputs: <code>scheduleRows[]</code>, <code>manifestRef</code>, <code>storagePath</code>. <br> Outputs: persisted <code>schedules.csv</code>, <code>schedulesChecksum</code>, evidenceRef. <br> Responsibilities: <br> 1. Serialize scheduleRows using canonical field order and <code>|</code> separators where required; compute <code>sha256</code> over canonical payload. <br> 2. Write to temp path then atomic rename to final path to avoid partial artifacts. <br> 3. Update manifest with <code>schedulesChecksum</code> and evidenceRef. <br> Failure modes: write failures should attempt retries with backoff; if persistent, stage locally and emit <code>fa.depn.schedules.persist_fail</code> with remediation steps. <br> CI tests: artifact checksum parity, atomic-rename behavior under simulated failure conditions. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>EmitAuditEvent(eventType, details, correlationId, evidenceRefs) — contract:</strong> <br> Purpose: create mandatory audit rows for lifecycle transitions and run events. <br> Inputs: <code>eventType</code>, structured <code>details</code> dictionary, <code>correlationId</code>, <code>evidenceRefs[]</code>. <br> Outputs: persisted audit row with <code>createdTs</code>, <code>operatorId</code>, <code>paramsHash</code>. <br> Responsibilities: ensure audit entries are append-only, tamper-evident (include checksum over entry), and include <code>runHash</code>/<code>exportChecksum</code> when applicable. <br> Observability: audit event throughput, audit persist latency. <br> CI tests: expected audit sequence tests for nominal run. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>GenerateJEExport(acceptedJEs, exportSpec, operatorId) — contract (summary):</strong> <br> Purpose: transform accepted JE suggestions into validated loader payloads, compute <code>exportChecksum</code> and persist export artifacts. <br> Inputs: <code>acceptedJEs[]</code>, <code>exportSpec</code> (column order, sign convention, date format), <code>operatorId</code>. <br> Outputs: <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>, <code>exportManifest</code> persisted, audit <code>fa.je.exported</code>. <br> Responsibilities: <br> 1. Validate acceptedJEs match <code>exportSpec</code> (columns, types, sign conventions); failure yields deterministic diagnostics. <br> 2. Re-validate balance at <code>roundingScale</code>; fail export if unbalanced. <br> 3. Serialize deterministically (UTF-8 with canonical escaping) and compute <code>exportChecksum</code>. <br> 4. Persist artifact atomically with <code>exportManifest</code>. <br> Observability: <code>export.latencyMs</code>, <code>export.sizeBytes</code>. <br> CI tests: golden export files, loader simulation acceptance tests. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>ApplyCorrections(acceptedJEs or exportPath, mode, operatorId, approvals) — contract (summary):</strong> <br> Purpose: orchestrate authoritative application of JE bundles; ensure safety controls and record revert metadata. <br> Inputs: <code>acceptedJEs</code> or <code>exportPath</code>, <code>mode</code> (<code>create_export | post_direct</code>), <code>operatorId</code>, <code>approvals</code> (evidenceRef). <br> Outputs: <code>applyDescriptor</code> (persisted before any mutation), <code>applyResult</code>, <code>postedJournalIds[]</code> (for <code>post_direct</code>), <code>revertDescriptor</code>. <br> Responsibilities: <br> 1. Validate approval gating per <code>policySnapshot.approvalMatrix</code>; require two-person approval for regulated postings. <br> 2. Persist <code>applyDescriptor</code> atomically prior to any mutative action. <code>applyDescriptor</code> must include <code>applyId</code>, <code>beforeChecksums</code> (assetIngestChecksum, capexIngestChecksum, runHash), <code>approvalsRef</code>, <code>operatorId</code>, <code>mode</code>, <code>applyTs</code>. <br> 3. Execute posting: for <code>create_export</code> return artifact path; for <code>post_direct</code> request ephemeral credentials from secure token service, post with idempotency token derived from <code>applyId</code>, capture <code>postedJournalIds</code>. <br> 4. Record per-JE statuses and allow governed retry logic for partial failures. <br> 5. Persist <code>revertDescriptor</code> capturing sufficient data to revert successfully posted bundles if necessary. <br> Observability: <code>apply.successRate</code>, <code>apply.partialFailureCount</code>. <br> CI tests: idempotency replay, approval gating tests, ephemeral token lifecycle tests. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>RevertJEs(applyId, operatorId) — contract (summary):</strong> <br> Purpose: attempt automated reversal of applied JE bundles and produce manual artifacts when automatic reversal unsupported. <br> Inputs: <code>applyId</code>, <code>operatorId</code>. <br> Outputs: <code>revertDescriptor</code> persisted, <code>revertResult</code> with statuses. <br> Responsibilities: <br> 1. Retrieve <code>applyDescriptor</code> and confirm <code>postedJournalIds</code> exist; if missing return <code>fa.revert.noSnapshot</code>. <br> 2. Compute <code>revertId = sha256(applyId + normalizedRevertTs)</code> and check prior reverts to ensure idempotent no-op. <br> 3. Call GL reversal endpoint with ephemeral credentials and idempotency tokens; capture responses. <br> 4. If GL lacks rollback endpoint produce <code>reversalArtifact.csv</code> and <code>forensic_manifest</code> for manual processing; mark <code>pending_manual_revert</code>. <br> Observability: <code>revert.automatedSuccessRate</code>, <code>revert.pendingManualCount</code>. <br> CI tests: idempotency replay, partial revert error handling. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>ReconcileFAtoGL(assetScheduleAgg, glBalances, tolerances) — contract (summary):</strong> <br> Purpose: compute deterministic join and variance metrics between subledger and GL control balances and propose remediations. <br> Inputs: <code>assetScheduleAgg</code> grouped by <code>controlGLAccount|costCenter|currency|period</code>, <code>glBalances</code>, <code>tolerances</code> (abs & pct). <br> Outputs: <code>fa_recon_report</code> with exceptions and <code>reconManifest</code>. <br> Responsibilities: <br> 1. Full outer join producing <code>Matched</code>, <code>FAOnly</code>, <code>GLOnly</code>. <br> 2. Compute <code>Variance = SubledgerAmount - GLAmount</code>, <code>AbsVariance</code>, <code>RelativeVariancePct</code>. <br> 3. Apply materiality: if <code>GLAmount==0</code> use absolute threshold; else relative threshold. <br> 4. For exceptions attach sample <code>evidenceRefs</code> and propose remediation actions (re-run JE export, mapping corrections, manual adjustments with approvals). <br> Observability: <code>recon.exceptionsCount</code>, <code>recon.timeMs</code>. <br> CI tests: tolerance boundary testing, sample evidence selection parity. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Cross-cutting helpers & primitives (contracts):</strong> <br> 1. <code>ComputeSHA256Hex(canonicalString)</code> — deterministic encoding: UTF-8 → SHA-256 hex lowercase; return <code>sha256:&lt;hex&gt;</code>. Use vetted cryptographic library or COM helper for cross-platform parity. <br> 2. <code>CanonicalSerialize(objectModel, schemaDef)</code> — deterministic serializer implementing fixed field order, <code>|</code> separators, JSON-compact lists with ordered keys; used across manifests and row checksums. <br> 3. <code>DecimalHelpers</code> — fixed-point integer math with helper functions: <code>ToMinorUnits(decimalString, scale)</code>, <code>FromMinorUnits(int, scale)</code>, <code>Add</code>, <code>Sub</code>, <code>Mul</code>, <code>Div</code> using integer arithmetic to avoid floating drift; implement string-based big-decimal fallback for scales beyond platform integer range. <br> 4. <code>DeterministicSeedFromRunHash(runHash, context)</code> — compute <code>sha256(runHash|context)</code> and map deterministic integer via hex substring; used only for deterministic tie-breakers. <br> 5. <code>PersistAtomic(payload, finalPath, metadata)</code> — write to temp file then atomic rename; persist metadata atomically. Return evidenceRef. <br> Testing guidance: unit tests for each helper with extreme and cross-runtime parity fixtures. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Extended worked examples — fully expanded narratives & forensic traces</strong> <br> <strong>Example A — Complex capitalization with multi-invoice addition and component assembly (expanded trace):</strong> <br> 1. Ingest assets and capex files: two invoices INV-2026-100 ($12,500 USD) and INV-2026-101 ($2,200 USD) linked to same PO. INV-2026-101 description includes part number "AS-000789" matching an existing <code>assetTag</code>. <code>LoadCapexTransactions</code> normalizes vendor names and description tokens; candidate mapping yields <code>candidateScore=0.62</code> for INV-2026-100 (vendor/PO match) and <code>candidateScore=0.93</code> for INV-2026-101 (assetTag exact). Both capex rows persisted with <code>capexRowChecksum</code> and <code>rawPayloadRef</code>. <br> 2. <code>policySnapshot</code> contains <code>componentPolicy</code> that for <code>IT</code> category prescribes <code>create_component</code> for accessory invoices under <code>capitalizationThreshold</code> override when <code>accessoryReason=&#x27;expansion&#x27;</code>. Policy includes <code>matchingWeights</code> used during mapping. Persist <code>policyHash</code>. <br> 3. <code>ComputeDepreciationRun</code> runs <code>EvaluateCapitalizationDecision</code> and decides INV-2026-101 maps to <code>AS-000789</code> with <code>create_component</code> (decisionConfidence=0.93). The engine calls <code>AugmentAssetRevision</code> to create a new component asset revision with <code>componentOf=AS-000789</code> and deterministic <code>assetRevisionId = sha256(assetRowChecksum|capexRowChecksum|decisionTs)</code>. Persist component revision evidence. <br> 4. Depreciation schedules are recomputed: parent asset retains original <code>depreciationStart</code>; component inherits default <code>usefulLifeMonths</code> for accessory category per <code>policySnapshot</code>. Schedules produced include <code>preRoundedAmount</code> for each period, <code>depreciationAmount</code> after rounding, and <code>residualAbsorbed</code> fields; schedule rows link <code>evidenceRefs</code> to both capex invoice checksums and <code>assetIngestManifest</code>. <br> 5. <code>GenerateScheduledJEProposals</code> groups lines per <code>jeTemplateSpec</code>. The preview artifact <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> contains <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, and <code>preview_manifest.json</code>. Preview indicates component lines flagged with <code>componentOf</code> and <code>componentRole</code> for GL mapping and reconciliation. ConfidenceBreakdown includes high mapping confidence for INV-2026-101 and lower for INV-2026-100. <br> 6. Analysts accept preview; <code>GenerateJEExport</code> creates <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code>. Apply gating: total posting exceeds regulated threshold so <code>ApplyCorrections</code> requires two-person approval; <code>applyDescriptor</code> persisted prior to posting. Post uses ephemeral token; on success <code>postedJournalIds[]</code> returned and stored in apply evidence. <br> 7. Audit chain: every step emits <code>fa.*</code> events: <code>fa.capex.ingest</code>, <code>fa.depn.run.completed</code>, <code>fa.je.preview.generated</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start/complete</code>. Each event includes <code>correlationId</code> linking for forensic replay. <br> Forensics: a compliance auditor can retrieve <code>depreciationRunManifestRef</code> and re-run canonical serialization using <code>canonicalVersion</code> and <code>policyHash</code> to reproduce the same <code>runHash</code>. If policy changed since run, manifest shows <code>policyHash</code> used enabling exact replay. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Example B — Mid-period partial disposal with cross-currency proceeds (expanded trace):</strong> <br> 1. Disposal event ingestion: <code>eventRow</code> with <code>assetTag=AS-000456</code>, <code>eventDate=2026-07-15</code>, proceeds <code>EUR 2,200.00</code>. Persist <code>eventRowChecksum</code>. <br> 2. Asset record: <code>assetRevision</code> shows book value and accumulated depreciation in USD (book NBV = $1,900.00). <code>policySnapshot</code> references official FX table <code>fxRates_20260715</code> with EUR→USD rate 1.0833 and <code>fxPolicy</code> indicating <code>midMarketRate</code> with <code>roundingScale_override=2</code>. <code>ComputeDepreciationRun</code> applies <code>fxRateRef</code> to convert proceeds: proceedsUSD = 2,200 * 1.0833 = 2,383.26 with explicit <code>fxConversionAudit</code> showing rate and steps; rounding rules applied per <code>policySnapshot</code>. <br> 3. Compute gain/loss deterministically: <code>gain = proceedsUSD - NBV = 2,383.26 - 1,900.00 = 483.26</code>. Prepare JE suggestions: Debit <code>Cash</code> 2,383.26; Debit <code>AccumulatedDepreciation</code> 8,200.00; Credit <code>AssetCost</code> 10,000.00; Credit <code>GainOnDisposal</code> 483.26. Each JE line includes <code>eventRowChecksum</code>, <code>fxRateRef</code>, and <code>policyHash</code> in <code>evidenceRefs</code>. <br> 4. Policy gating: disposals above $2,000 require <code>taxTeamApproval</code>. Preview contains <code>approvalRef</code> field and <code>GenerateJEExport</code> blocks apply until approval included. When approval appended, <code>ApplyCorrections</code> posts the approved JE and the <code>applyDescriptor</code> and <code>postedJournalIds</code> are persisted. <br> 5. Reconciliation: <code>ReconcileFAtoGL</code> will match disposal postings to GL control accounts and report variances if GL posted different amounts or exchange rates; <code>reconManifest</code> contains <code>evidenceRefs</code> back to <code>fxRateRef</code> and <code>applyDescriptor</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Example C — Rounding pathologies & deterministic residuals (expanded):</strong> <br> 1. Asset: cost 1,000.00, salvage 0.00, useful life 3 months, roundingScale = 2. Pre-rounded monthly expense = 333.333333... at <code>policyInternalPrecision</code>. <br> 2. <code>PreRoundAndRoundValues</code> produces three rounded months of 333.33 each (rounded half-to-even rules applied consistently), totals 999.99 leaving residual +0.01. <br> 3. <code>ResidualAbsorptionAndAdjustFinalPeriod</code> computes absorption target: highest absolute preRounded amount equal for all months; second tie-breaker lexicographic <code>assetId</code> selects the specific period deterministically; apply +0.01 to that period making it 333.34. Persist <code>residualRationale</code> and <code>residualAbsorbed</code>. <br> 4. For batch-level policies requiring aggregated balancing (e.g., cost center-level zeroing), algorithm must be configured via <code>policySnapshot.batchResidualPolicy</code> and tested with property tests to ensure deterministic group-level behavior. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Example D — Units-of-Production with missing usage & analyst flow (expanded):</strong> <br> 1. Asset with <code>UnitsOfProduction</code> method expects total 10,000 units. No usage provided for period in capex/asset feeds. <code>ComputeMethod_UoP</code> marks asset as <code>requiresManualInput</code> and emits <code>fa.depn.run.requires_manual_input</code> with <code>requiresManualAssetList</code> referencing <code>assetRevisionId</code>. <br> 2. Analyst receives queue item, sources usage data from telemetry (e.g., machine counters) or manual logs, creates an <code>assetRevision</code> with <code>manualInputs</code> containing <code>usageByPeriod[]</code>, and re-runs <code>ComputeDepreciationRun</code> for the affected <code>assetRevisionId</code>. <br> 3. Engine recomputes UoP schedule deterministically; prior proposals are superseded by new run artifacts; reconciliation uses <code>depreciationRunManifest.changedAssetRevisionIds[]</code> to scope downstream reprocessing. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Policy migration & canary example (expanded):</strong> <br> 1. Proposed policy change: reduce default <code>usefulLifeMonths</code> for <code>IT</code> category from 36 → 30. Prepare <code>migrationManifest</code> capturing <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after), <code>sampleFixtures[]</code> with expected <code>runHash</code> change deltas, <code>estimatedAffectedCount</code>, <code>canaryPlan</code> targeting 1% cohort, <code>rollbackPlan</code>, <code>approvals[]</code>, and <code>testMatrix</code>. <br> 2. Execute canary: create new <code>policySnapshot</code> <code>fa_policy_&lt;newPolicyHash&gt;.json</code> but do not promote; run <code>ComputeDepreciationRun</code> against the small cohort with <code>policyHash</code> parameter; persist <code>runHash</code> for canary. <br> 3. Monitor KPIs across two cycles: <code>DepnExpenseDeltaPct</code>, <code>RunParityChange</code>, <code>SuggestionAcceptanceRate</code>. If KPIs within thresholds and approvals captured, promote new <code>policyHash</code> for production runs and persist <code>migrationManifest</code> evidence. If unacceptable, perform atomic pointer swap to prior <code>policyHash</code> and re-run smoke checks then document findings. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Conceptual Power Query (PQ) pilot guidance (expanded, no code):</strong> <br> When to use PQ: analyst-driven parity checks, preview artifact generation, header correction, and small-cohort pilots (recommend ≤ 5k assets depending on complexity). PQ is ideal for highly interactive tasks and mapping sanity checks before backend scale runs. <br> PQ architecture pattern for pilot flows: <br> 1. Parameterized staging queries: <code>AssetMaster_Staging(headerMap, decimalLocale, sampleLimit)</code>, <code>Capex_Staging</code>, <code>PolicySnapshot_Param</code>. <br> 2. Layered canonicalization steps as separate named queries for inspectability: <code>Step01_NormalizeBytes</code>, <code>Step02_TextNormalize</code>, <code>Step03_ParseNumbersWithCulture</code>, <code>Step04_DeriveMinorUnits</code>, <code>Step05_MethodPreviewPreRounded</code>. <br> 3. Keep policy snapshots under source control as parameterized JSON; compute <code>policyHash</code> in PQ by canonicalizing policy representation and hashing via helper function or external helper; persist <code>policyHash</code> in preview manifest. <br> PQ canonicalization constraints & mitigations: <br> - PQ lacks arbitrary-precision decimal math in many hosts; for preRounded internal precision represent high-precision values as strings or offload to an external microservice for final math. <br> - Avoid per-row custom function loops; instead vectorize transformations, use <code>Table.Buffer</code> carefully, and minimize expensive merges. <br> - Large in-memory joins may time out; perform sampling for preview in PQ and use backend for full runs. <br> PQ parity testing: produce <code>pqParityReport</code> comparing <code>runHash</code> and <code>previewHash</code> to backend run; record exact mismatches and suspected root causes (locale parsing, rounding implementation differences). <br> Operational flow with PQ: generate preview artifact and <code>previewHash</code>, upload artifact to evidence store and produce <code>preview_manifest</code> with <code>previewHash</code>. Backend parity job replays inputs and asserts <code>runHash</code> parity; mismatches generate <code>fa.verify.parity.failed</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX measures & reporting patterns (expanded, no code):</strong> <br> Modeling: use canonical keys (<code>assetId</code>, <code>assetRevisionId</code>, <code>policyHash</code>, <code>runId</code>, <code>previewHash</code>) as relationships; tokenized identifiers for UI. Avoid showing raw PII in visuals; show evidenceRef links with access control gating. <br> Core measures: <br> 1. <code>DepreciationExpense</code> — sum of <code>DepSchedule[depreciationAmount]</code> per period.<br> 2. <code>AccumulatedDepreciation</code> — cumulative sum up to selected period.<br> 3. <code>NetBookValue</code> — computed per asset as <code>cost - accumulatedDepreciationToDate</code> or aggregated across assets.<br> 4. <code>FA_ReconVariance</code> — <code>SUM(Subledger[AccumulatedDep]) - SUM(GL[AccumulatedDep])</code> providing primary variance for reconciliation visuals.<br> 5. <code>BeyondToleranceFlag</code> — dynamic materiality check using parameter thresholds: <code>IF(ABS(GLAmount)=0, ABS(Variance)&gt;AbsThreshold, ABS(Variance)/ABS(GLAmount)&gt;TolerancePct)</code>. <br> Advanced operational measures: <br> 1. <code>SuggestionAcceptanceRate</code> — fraction of suggested JEs accepted: <code>DIVIDE(COUNTROWS(AcceptedJEs), COUNTROWS(SuggestedJEs), 0)</code>. <br> 2. <code>RunParityDeltaCount</code> — count of runs where recomputed <code>runHash</code> differs from expected; used to flag parity failures. <br> 3. <code>OpenManualActions</code> — count of schedule rows with <code>requiresManualInput = TRUE</code>. <br> UX & drillthrough patterns: allow analysts to click a variance cell to drill to a detail page containing sample schedule rows, linked preview artifact metadata and evidenceRefs. Provide <code>requestApproval</code> CTA producing approval manifests to expedite evidence retrieval where approvals are required. <br> Materiality & user controls: expose absolute and percentage thresholds as slicers in reports so auditors can switch between strict and lenient views without re-running the engine; ensure exported CSVs include threshold values in captions. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Testing strategy & CI / golden parity (exhaustive guidance):</strong> <br> Unit tests (must cover): <br> 1. Canonicalization: text normalization across unicode edge cases, diacritics, punctuation mappings, NFKC behaviors and locale-specific casefolding.<br> 2. Numeric parsing: thousand separators, locale decimal separators, negative-zero normalization, minor-units rounding. <br> 3. Date parsing across ambiguous formats and leap-year behavior. <br> 4. Method math: SL, DDB (including switch-to-SL scenarios), SYD distribution, UoP with fractional usage and missing usage behaviors. <br> 5. Rounding & residual absorption determinism including tie-break rules. <br> Integration tests (must cover): <br> 1. End-to-end ingest→compute→preview→export flows covering multi-currency, disposals, revaluations, component assembly, and UoP exceptions. <br> 2. Policy changes applied via <code>migrationManifest</code> and canary cohort validation. <br> Golden parity tests (must enforce): <br> 1. Maintain canonical fixtures for <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policyHash</code>, <code>runHash</code>, <code>previewHash</code>, and <code>exportChecksum</code>. <br> 2. Run golden fixtures across PQ pilot, backend workers, and local prototypes; all environments must match golden checksums exactly. <br> Property tests: ordering independence, header synonym invariance, idempotency of apply/revert flows. <br> Performance & load tests: schedule computation throughput at target sizes (1k, 10k, 100k); preview artifact generation latency for 100/500/1000 rows; stress tests for candidate mapping with high-noise OCR data. <br> Security & compliance tests: PII redaction scan on artifacts and UI surfaces, ephemeral token lifecycle tests, static analysis for secrets in repo. <br> CI gating: failing golden or property tests block merges; policy migrations cannot be promoted without a <code>migrationManifest</code> and successful canary KPIs. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Observability, audit architecture & SLOs (detailed):</strong> <br> Audit events: mandatory event types include <code>fa.asset.ingest</code>, <code>fa.capex.ingest</code>, <code>fa.policy.loaded</code>, <code>fa.depn.run.start</code>, <code>fa.depn.run.completed</code>, <code>fa.depn.run.requires_manual_input</code>, <code>fa.je.preview.generated</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start</code>, <code>fa.je.apply.complete</code>, <code>fa.je.apply.fail</code>, <code>fa.je.revert</code>, <code>fa.recon.report.generated</code>, <code>fa.policy.migration.*</code>. Each audit record must include <code>correlationId</code>, <code>evidenceRefs[]</code>, <code>context</code> (runHash or exportChecksum), <code>operatorId</code>, <code>paramsHash</code>, <code>status</code> and <code>createdTs</code>. <br> Evidence store conventions: append-only object store containing the artifact payload, <code>checksum</code>, <code>canonicalVersion</code>, <code>policyHash</code> tag, <code>retentionPolicy</code>, and <code>legalTags</code>; retrieval of raw PII artifacts gated by <code>approvalRef</code> and generates chain-of-custody audit rows. <br> Key SLO examples: <br> 1. <code>PlanBuildLatencyP50</code> target < 200ms for small plans. <br> 2. <code>PreviewLatencyP50</code> target < 2s for previews ≤ 500 rows. <br> 3. <code>ApplySuccessRate</code> target > 99% in <code>create_export</code> mode. <br> 4. <code>GoldenParityFailureRate</code> target 0 for protected branches. <br> Parity verification job: scheduled daily job that recomputes <code>runHash</code> and <code>reportHash</code> for stored artifacts and emits <code>verify.parity.failed</code> when mismatches occur; failures escalate to owners with <code>correlationId</code> and evidence bundle. <br> Incident triage runbook (explicit steps): <br> 1. Capture <code>correlationId</code> and <code>runId</code> immediately. <br> 2. Retrieve <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policySnapshot</code>, <code>previewArtifact</code> via evidenceRefs. <br> 3. Inspect <code>issues[]</code> and <code>mappingSuggestions</code> for parsing or mapping errors. <br> 4. If posted exports exist attempt <code>RevertJEs</code> using <code>applyDescriptor</code>; if revert impossible assemble <code>forensic_manifest</code> and escalate to GL/compliance. <br> 5. Persist all investigative steps as audit rows with <code>correlationId</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Failure modes & operator runbooks (comprehensive):</strong> <br> <strong>Fault A — malformed ingest:</strong> <br> 1. Symptom: <code>fa.asset.ingest.invalid</code> with <code>rowsFailed</code> > 0. <br> 2. Triage: fetch <code>assetIngestManifest</code> via evidenceRef, review <code>headerMap</code> and <code>issues[]</code>, sample <code>rawPayloadRef</code>. <br> 3. Remediation: correct headers using <code>headerMap</code> override or update mapping and re-run <code>LoadAssetMaster</code> with <code>correctionOf</code> linking to previous <code>sourceFingerprint</code>. Persist new <code>assetIngestManifest</code> referencing the correction. <br> 4. Post-check: re-run <code>ComputeDepreciationRun</code> for delta set. <br> <strong>Fault B — mapping backlog spike:</strong> <br> 1. Symptom: <code>capex.ingest.unmappedCount</code> spike. <br> 2. Triage: run <code>modMatch</code> analytics to rank unmapped items by total value and frequency; sample OCR-noisy descriptions. <br> 3. Remediation: produce <code>mappingSuggestions</code> using alias acceptance workflows, present top suggestions to business owners for bulk acceptance; after acceptance run <code>ComputeDepreciationRun</code> for affected assets. <br> <strong>Fault C — JE export rejected by GL loader:</strong> <br> 1. Symptom: GL loader returns rejection listing line-level errors. <br> 2. Triage: fetch <code>exportManifest</code>, run local test import against a GL test environment, run <code>modExport.ValidateExportSpec</code> to detect spec mismatches. <br> 3. Remediation: adjust <code>exportSpec</code> (date formats, sign conventions), regenerate export; if prior direct-post occurred and is irreversible, run <code>RevertJEs</code> and coordinate re-post with corrected payloads. <br> <strong>Fault D — post-apply mismatches discovered during reconciliation:</strong> <br> 1. Triage: fetch <code>applyDescriptor</code>, <code>postedJournalIds[]</code>, and <code>fa_recon_report</code>. <br> 2. Remediation: attempt <code>RevertJEs</code> for the apply; if unsuccessful prepare <code>forensic_manifest</code> and coordinate manual corrective posting with GL team. <br> <strong>Emergency policy rollback:</strong> <br> 1. Symptom: mass parity delta after policy promotion. <br> 2. Steps: atomically switch pointer back to prior <code>policyHash</code>, run smoke-preview comparisons across representative fixtures, and if parity restored persist <code>policy.hotSwap.auditChain</code> and notify stakeholders. <br> Forensic escalation: when root cause unknown, preserve all evidenceRefs, capture <code>correlationId</code>, and open investigation ticket attaching <code>depreciationRunManifest</code> and <code>assetIngestManifest</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Migration manifest & policy-change governance (detailed):</strong> <br> Minimal manifest fields: <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (planId, cohortSizes, KPIs), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> Lifecycle steps: <br> 1. Draft migration manifest and register in governance tracker. <br> 2. Execute canary cohort per <code>canaryPlan</code> recording <code>runHash</code> deltas and KPIs for at least two cycles. <br> 3. If KPIs within thresholds and approvals captured, promote policy snapshot; persist <code>migrationManifest</code> as evidence and emit <code>fa.policy.migration.completed</code>. <br> 4. If KPIs fail, rollback to prior policyHash and document findings; do not retroactively modify <code>runHash</code> of prior evidence. <br> Regulatory controls: for GL ranges requiring compliance sign-off ensure <code>approvals[]</code> include compliance signatures before any <code>ApplyCorrections</code> using the new policy. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Artifact naming, checksum & storage conventions (concise):</strong> <br> 1. <code>asset_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code> <br> 2. <code>capex_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code> <br> 3. <code>fa_policy_&lt;policyHash&gt;.json</code> <br> 4. <code>fa_depn_run_&lt;runId&gt;_&lt;runHash&gt;.json</code> <br> 5. <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> (must contain <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>) <br> 6. <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code> + <code>export_manifest.json</code> <br> 7. <code>apply_&lt;applyId&gt;.json</code> persisted atomically prior to mutative steps <br> 8. <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code> <br> Checksums: always <code>sha256:</code> prefix over canonicalized payload; include <code>canonicalVersion</code> and <code>policyHash</code> in manifests; store artifacts under append-only evidence store with <code>retentionPolicy</code> and <code>legalTags</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Performance, scale & architecture recommendations (expanded):</strong> <br> 1. PQ pilot for small cohorts (~up to 5k assets) for interactive previews; backend services recommended for 10k+. <br> 2. Scale model: per-asset schedule computation is embarrassingly parallel; shard by <code>assetId</code> ranges or <code>category</code> while preserving deterministic ordering within shards (persist shard assignment). <br> 3. Incremental recompute: manifest should capture <code>changedAssetRevisionIds[]</code> enabling targeted recompute for minor changes. <br> 4. Storage: use object store for large artifacts + small relational store for manifests/indices to support fast evidenceRef resolution. <br> 5. Autoscaling: scale workers based on queue depth and SLO targets; schedule heavy compute windows for close runs. <br> 6. Observability: set SLO-based alerts on PlanBuildLatency, PreviewLatency, ApplyFailureRate, GoldenParityFailure. <br> 7. For large fleets implement worker pool with deterministic per-shard seed assignment derived from <code>runHash</code> + <code>shardId</code> to ensure reproducible shard-local ordering and tie-breaker parity. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Operator CLI patterns & examples (conceptual):</strong> <br> 1. <code>fa.build-run --period 2026-01 --policyRef fa_policy_20260101 --operator alice</code> → triggers ingest+compute and returns <code>runId</code> and <code>depreciationRunManifestRef</code>. <br> 2. <code>fa.preview --run &lt;runId&gt; --sample 500 --operator alice</code> → produces <code>previewRef</code> + <code>previewHash</code>. <br> 3. <code>fa.suggest-je --preview &lt;previewRef&gt; --operator alice</code> → suggested JEs and <code>jePreviewHash</code>. <br> 4. <code>fa.generate-je --preview &lt;previewRef&gt; --accept &lt;suggestionIds&gt; --exportSpec ERP_JE_v1 --operator alice</code> → generates <code>FA_JE_Export_&lt;runId&gt;.csv</code> and emits <code>fa.je.exported</code>. <br> 5. <code>fa.apply --export &lt;exportPath&gt; --mode post_direct --operator alice --approvalId ap-321 --approver bob</code> → persist <code>applyDescriptor</code> then post direct with ephemeral tokens; emits <code>fa.je.apply.*</code>. <br> 6. <code>fa.revert --applyId &lt;applyId&gt; --operator alice</code> → attempts automated revert and writes <code>fa.je.revert</code>. <br> CLI safety: <code>applyDescriptor</code> persisted prior to mutative actions; idempotency tokens derived from <code>applyId</code>. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria & release gates (explicit):</strong> <br> 1. Unit tests proving deterministic canonicalization, hashing parity and method math across locales. <br> 2. Integration tests verifying ingest→compute→preview→export flows produce expected artifacts with canonical checksums. <br> 3. Golden parity tests asserting <code>policyHash</code>, <code>runHash</code>, <code>previewHash</code>, <code>exportChecksum</code>; failing diffs block merges. <br> 4. Any semantic policy change must include <code>migrationManifest</code> and canary execution; KPIs within thresholds and approvals recorded before promotion. <br> 5. Direct posting to GL requires two-person approval plus ephemeral credential issuance; <code>applyDescriptor</code> persisted before posting. <br> 6. Evidence retention & parity verification jobs scheduled and passing. </td></tr><tr><td data-label="modDepreciationEngine — Per-function Expert Technical Breakdown"> <strong>Appendices & available follow-ups:</strong> <br> Choose one or more artifacts to generate next: <br> 1. Formal JSON Schema for <code>AssetRow</code>, <code>DepreciationScheduleRow</code>, <code>applyDescriptor</code>, <code>recon_report</code> with exact field ordering used for canonical hashing. <br> 2. Canonical CSV golden fixtures with expected <code>sha256:</code> checksums for <code>policyHash</code>, <code>runHash</code>, and <code>previewHash</code> (suitable for CI golden tests). <br> 3. Step-by-step Power Query canonicalization recipe expressed as named transform steps with expected intermediate outputs (for PQ pilots). <br> 4. Compact operator runbook PDF summarizing triage steps and CLI commands. <br> Indicate desired artifact(s) and target runtime (VBA prototype, Python backend, PQ pilot); selected artifacts will be produced following the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 45</div></div><div class="table-caption" id="Table3" data-table="Docu_0186_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modJEGenerator — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modJEGenerator — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Preface & intent (concise):</strong> This mega-spec exhaustively expands <code>modJEGenerator</code> to an evidence-first, deterministic, auditable, production-ready design. It documents per-row semantics (JE_Line, JE_Bundle, ScheduleRow, DisposalRow, MappingSuggestionRow), every function's contract (inputs, outputs, responsibilities, invariants, failure modes, telemetry, CI tests, runbook steps), extended worked examples capturing nuance and edge-cases, conceptual Power Query (PQ) pilot guidance including anti-patterns and parity mitigations, and conceptual DAX measures and UX patterns tuned for reconciliation, triage and operational observability. All numbered lists in this document use <code>&lt;br&gt;</code> line breaks for downstream rendering consistency. This document is intended for engineers (VBA/backend), QA, analysts, SRE, compliance and auditors. Implementers must follow canonical serialization and hashing recipes and persist <code>policyHash</code>, <code>canonicalVersion</code>, and <code>runHash</code> with every artifact. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Scope & constraints:</strong> <br> 1. Non-mutative preview flows: <code>modJEGenerator</code> does not alter canonical schedules or policy artifacts; preview artifacts and manifests are appended to Evidence Store only. <br> 2. Deterministic outputs: identical canonical inputs, <code>policyHash</code>, <code>canonicalVersion</code>, and <code>runId</code> must produce identical <code>jeProposals[]</code>, <code>jeBundleChecksum</code>s and <code>previewHash</code>. <br> 3. Evidence-first: every line and bundle references <code>evidenceRefs[]</code> to <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>scheduleRowChecksums[]</code>, and applicable event row checksums. <br> 4. PII minimization: analyst surfaces show tokenized identifiers; raw PII available only through approval workflows that emit chain-of-custody audit rows. <br> 5. Golden parity: CI must assert parity across PQ pilot and backend; failing parity blocks promotion. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Canonical models — per-row narratives, exhaustive semantics & forensic handling</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>JE_Line (exhaustive forensic narrative):</strong> <br> Purpose: atomic accounting instruction (one debit or credit) in a suggested JE bundle derived from subledger schedules or event rows used to post to GL. <br> Field-level semantics and forensic handling: <br> • <code>jeLineId</code> (string): deterministic id computed from canonical components: <code>sha256(jeBundleSequence | account | debitCredit | amountMinorUnits | sortedLineSourceRefs)</code>; record the generation recipe in <code>preview_manifest</code> for replay. <br> • <code>jeId</code> (string): bundle id; deterministic <code>jeBundleSequence</code> used to order bundles within a run; <code>sequenceSeed</code> recorded in <code>depreciationRunManifest</code>. <br> • <code>account</code> (string): canonical GL account code resolved via <code>ResolveGLMapping</code>; mapping origin recorded (<code>mappingOverrideRef</code> or <code>mappingHeuristicRef</code>). <br> • <code>debitCredit</code> (enum): explicit, do not rely on sign inference; canonicalizer must persist <code>debitCredit</code> exactly. <br> • <code>amount</code> (string): canonical decimal string zero-padded to <code>roundingScale</code>; also store <code>amountMinorUnits</code> integer and <code>scale</code> to avoid floating ambiguity. <br> • <code>preRoundedAmount</code> (string): high-precision pre-rounding decimal recorded for forensic verification; <code>internalPrecision</code> documented in the <code>depreciationRunManifest</code>. <br> • <code>narrative</code> (string): resolved templated narrative from <code>jeTemplateSpec</code>; template and resolved narrative persisted; PII tokenization enforced unless <code>approvalRef</code> present. <br> • <code>lineSource[]</code> (array): canonicalized and deterministically sorted list of contributing <code>scheduleRowChecksum</code> / <code>disposalRowChecksum</code> / <code>capexRowChecksum</code>. <br> • <code>confidence</code> (decimal 0..1): per-line mapping confidence value computed in <code>ResolveGLMapping</code>. Persist <code>mappingScoreVector</code> used. <br> • <code>dqFlags[]</code> (array): standardized DQ codes (e.g., <code>DQ_MISSING_USAGE</code>, <code>DQ_CURRENCY_MISMATCH</code>, <code>DQ_NEGATIVE_NBV</code>) with remediation suggestions. <br> Forensic invariants: JE_Line must include <code>evidenceRefs[]</code> linking to original schedule/event/capex artifacts; line-level checksums optional but bundle-level <code>jeBundleChecksum</code> is mandatory for atomic identity. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>JE_Bundle / Proposed JE (exhaustive forensic narrative):</strong> <br> Purpose: atomic candidate grouping of JE_Lines to be previewed, exported, and possibly applied. Bundles must be balanced at configured rounding scale or explicitly marked <code>unbalanced</code>. <br> Field-level semantics and forensic handling: <br> • <code>jeId</code> and <code>jeBundleSequence</code> (string/int): stable deterministic ordering; record <code>sequenceSeed</code> in <code>depreciationRunManifest</code>. <br> • <code>bundlePostingKey</code> (string): canonical grouping key (e.g., <code>controlGLAccount|costCenter|currency|period</code>) computed per <code>jeTemplateSpec.postingKeySpec</code> using canonical tokenization. <br> • <code>jeLines[]</code>: ordered by <code>jeTemplateSpec.lineOrder</code> or deterministic fallback <code>(account, assetId, scheduleId)</code>. Order method recorded in <code>preview_manifest</code>. <br> • <code>bundleCurrency</code> and <code>bundleRoundingScale</code>: inherited from <code>jeTemplateSpec</code> with currency overrides persisted. <br> • <code>jeBundleChecksum</code> (sha256 prefixed): computed over canonical serialization of the bundle (metadata then ordered lines) using <code>canonicalVersion</code> — stored in bundle metadata and preview manifest. <br> • <code>confidenceScore</code> (0..1) and <code>confidenceBreakdown</code>: score plus labeled components (mappingCompleteness, dqPenalty, historicalStability, manualFlags) and <code>matchingWeights</code> pointer. Store the scoring vector used. <br> • <code>evidenceRefs[]</code>: required pointers to <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>scheduleRowChecksums[]</code>, <code>policyHash</code>. Optional: <code>applyDescriptorRef</code> if a prior application existed for same lines. <br> • <code>previewStatus</code> (enum): <code>balanced | residual_absorbed | unbalanced | requiresMappingResolution | requiresApproval</code>. <br> Forensic invariants: <code>jeBundleChecksum</code> identifies the proposal; any re-computation for parity must use same <code>canonicalVersion</code>, <code>policyHash</code> and field order. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>DepreciationScheduleRow (JE consumer narrative):</strong> <br> Purpose: canonical atomic scheduled depreciation posting for one period and asset revision. JE generator treats schedule rows as immutable inputs. <br> Minimum JE generation fields: <code>scheduleRowChecksum</code>, <code>assetId</code>, <code>periodStart</code>, <code>periodEnd</code>, <code>depreciationAmount</code> (rounded string), <code>preRoundedAmount</code>, <code>accumulatedDepreciationToDate</code>, <code>bookValueEnd</code>, <code>method</code>, <code>methodParams</code>, <code>prorationFactor</code>, <code>daysInPeriod</code>, <code>daysCounted</code>, and <code>evidenceRefs[]</code> pointing to asset and capex evidence. <br> Forensic invariants: schedule rows must remain immutable; any analyst override must create a new <code>assetRevisionId</code> and new schedule rows; do not mutate existing schedule rows. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>DisposalRow / RevaluationRow (JE consumer narrative):</strong> <br> Purpose: event rows for disposals, revaluations, or impairments that produce event-specific JE bundles. <br> Required fields: <code>eventRowChecksum</code>, <code>assetId</code>, <code>eventType</code>, <code>eventDate</code>, <code>proceeds</code> (canonical decimal + <code>amountMinorUnits</code>), <code>proceedsCurrency</code>, <code>fxRateRef</code> (when cross-currency), <code>adjustedBookValue</code>, <code>gainLossRecognized</code>, <code>taxTreatment</code> object, <code>approvalRef</code> if policy mandates approval, <code>evidenceRefs[]</code>. <br> Forensic invariants: when cross-currency, persist <code>fxRateRef</code> and <code>fxTableHash</code>; <code>jeProposal</code> for event must include these refs. <code>GenerateJEExport</code> and <code>ApplyCorrections</code> enforce <code>approvalRef</code> presence when required. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>MappingSuggestionRow (auxiliary narrative):</strong> <br> Purpose: recorded suggestions to remedy unmapped bundles; used by analysts to bulk-accept mapping overrides. <br> Fields: <code>suggestionId</code>, <code>postingKey</code>, <code>candidateGLAccount</code>, <code>score</code>, <code>matchTrace[]</code> (signal-by-signal explanation), <code>exampleScheduleRefs[]</code>, <code>estimatedImpact</code> (canonical decimal), <code>createdTs</code>, <code>createdBy</code>. Persist <code>suggestionManifest</code>. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Canonicalization & hashing rules (JE-focused parity recipe):</strong> <br> 1. Text: apply Unicode NFKC normalization → trim leading/trailing whitespace → collapse any sequence of whitespace to a single U+0020 → map common punctuation to canonical equivalents where policy requires (e.g., en-dash to hyphen) → casefold for canonical tokens; record <code>rawField</code> in evidence for forensic replay. <br> 2. Numbers: always persist <code>amountMinorUnits</code> + <code>scale</code>. For hashing serialize decimal string zero-padded to <code>scale</code>. Avoid floating point everywhere; use high-precision integer math for preRounded sums using <code>internalPrecision</code> specified in <code>policySnapshot</code>. <br> 3. Dates: <code>YYYY-MM-DD</code> for dates; if time-of-day permitted use <code>YYYY-MM-DDTHH:MM:SSZ</code> normalized to UTC with deterministic ms rounding rules. Preserve <code>rawDateString</code> on parse failures with <code>issues[]</code>. <br> 4. Serialization ordering: each model has exact canonical field order. Use <code>|</code> as the inter-field separator for canonical strings and escape embedded <code>|</code> with an escape token when policy requires. No trailing newline; end canonical string with last field. <br> 5. Encoding & hashing: UTF-8 encode canonical string and compute sha256 hex; prefix result with <code>sha256:</code> in manifests. Always include <code>canonicalVersion</code> as part of manifest; run-level <code>runHash</code> and policy hashes must include <code>canonicalVersion</code>. <br> 6. Deterministic tie-breakers: candidate selection uses: highest absolute preRounded metric → lexicographic <code>assetId</code> or <code>rowId</code> → seeded deterministic fallback using <code>runHash</code> concatenated with canonical element identifiers; record tie-break rationale in <code>depreciationRunManifest</code>. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Function-level breakdowns — exhaustive contracts, defenses, tests, telemetry & runbook steps</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>AggregateSchedulesToJEs(scheduleRows, jeTemplateSpec, policySnapshot, params)</strong> — <br> <strong>Signature (logical):</strong> Inputs: <code>scheduleRows[]</code> (iterable of canonical schedule row dictionaries), <code>jeTemplateSpec</code> (postingKeySpec, lineRules, roundingScale, lineOrder, exportOrder, bundleTolerance), <code>policySnapshot</code> (mappingOverrides, matchingWeights, assetLevelPosting), <code>params</code> (runId, sourceRunHash, operatorId, seed optional). Outputs: <code>jeProposals[]</code> (ordered), <code>aggregateIndex</code> mapping postingKey→scheduleRowRefs, <code>jePreviewStats</code> (summary counters/diagnostics), persisted <code>previewManifestRef</code>. <br> <strong>Stepwise responsibilities (explicit numbered list with <code>&lt;br&gt;</code> line breaks):</strong> <br> 1. Validate inputs and assert <code>policySnapshot.policyHash</code> present; if missing abort with <code>fa.je.preview.invalid_policy</code>. <br> 2. Compute <code>sequenceSeed = sha256(runId | sourceRunHash | canonicalVersion)</code> and persist in run manifest. <br> 3. For each scheduleRow compute <code>postingKey</code> per <code>jeTemplateSpec.postingKeySpec</code> and canonicalize components with <code>CanonicalizeText</code>. Append <code>scheduleRowChecksum</code> to <code>aggregateIndex[postingKey]</code> preserving deterministic insertion; use stable sort for keys if needed. <br> 4. Iterate postingKeys in deterministic sort order and call <code>GroupAndAggregateLines</code> to produce <code>jeLines[]</code>. <br> 5. Validate and balance each candidate <code>jeLines[]</code> with <code>ValidateAndBalanceJE</code> using <code>jeTemplateSpec.roundingScale</code> and <code>jeTemplateSpec.bundleTolerance</code>. <br> 6. If balanced or residual absorbed, compute <code>confidenceScore</code> via <code>ComputeConfidenceScore</code> and <code>jeBundleChecksum</code> using <code>BuildJEBundleChecksum</code>; if not balanced, mark <code>previewStatus=&#x27;unbalanced&#x27;</code> and include diagnostics. <br> 7. Aggregate telemetry counters and diagnostics into <code>jePreviewStats</code>. <br> 8. Persist provisional proposals to staging; call <code>PackagePreviewArtifact</code> to build <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>. <br> 9. Emit <code>fa.je.preview.generated</code> audit event with evidenceRef and telemetry. <br> <strong>Invariants:</strong> <br> - Deterministic grouping and ordering for identical canonical inputs. <br> - Balanced bundles must sum to zero at roundingScale unless explicitly <code>unbalanced</code>. <br> <strong>Failure modes & remediation:</strong> <br> - Missing mappings → mark proposals <code>requiresMappingResolution</code>; call <code>SuggestMappingOverrides</code> and route suggestions to analysts; acceptances are persisted as mappingOverrides and trigger targeted re-run. <br> - Rounding imbalance beyond tolerance → mark <code>unbalanced</code>; remediation via mapping fixes, policy tolerance change (requires migration manifest) or manual analyst adjustment. <br> - Evidence store persist failure → stage locally and retry with exponential backoff; if persistent escalate with <code>correlationId</code>. <br> <strong>Observability & telemetry:</strong> <code>je.preview.durationMs</code>, <code>je.preview.bundlesCreated</code>, <code>je.preview.unbalancedBundles</code>, <code>je.preview.avgConfidenceScore</code>, <code>je.preview.packagingMs</code>. <br> <strong>CI tests:</strong> deterministic grouping with seeded fixtures; residual tie-breaker tests; golden <code>jeBundleChecksum</code> fixtures; cardinality explosion stress tests. <br> <strong>Operator runbook (concise numbered):</strong> <br> 1. On <code>fa.je.preview.unbalanced</code>, download <code>preview_zip</code> and <code>preview_manifest</code>, inspect <code>balanceDiagnostics</code>. <br> 2. If mapping gaps present, run <code>SuggestMappingOverrides</code>; present suggestions to owners for bulk acceptance; acceptances persist as mappingOverrides and re-run <code>AggregateSchedulesToJEs</code> for affected postingKeys only. <br> 3. If packaging failed due to storage errors, retrieve staging artifact and upload via ops tool; mark manifest updated and re-emit audit event. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>GroupAndAggregateLines(postingKey, scheduleRefs, jeTemplateSpec, policySnapshot, params)</strong> — <br> <strong>Signature:</strong> Inputs: <code>postingKey</code>, <code>scheduleRefs[]</code> deterministic list, <code>jeTemplateSpec</code>, <code>policySnapshot</code>, <code>params</code> (runId, sequenceSeed). Outputs: <code>jeLines[]</code> candidate array and <code>aggregateDiagnostics</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Retrieve schedule rows by checksum preserving <code>scheduleRefs</code> order; validate required fields; collect <code>preRoundedAmount</code> as high-precision integer using <code>internalPrecision</code>. <br> 2. For each scheduleRow map to one or more target GL lines via <code>jeTemplateSpec.lineRules</code>; rules may produce debit and credit splitting (e.g., tax withholding). <br> 3. Accumulate per-target-line <code>preRoundedSum</code> using integer minor-units arithmetic at <code>internalPrecision</code>. <br> 4. Apply canonical rounding to <code>jeTemplateSpec.roundingScale</code> using <code>round-half-to-even</code> or policy override; compute <code>roundedAmount</code> and per-line <code>roundingDelta</code>. <br> 5. Create <code>jeLine</code> object(s) with <code>preRoundedAmount</code> string, <code>roundedAmount</code> string, <code>amountMinorUnits</code> int, <code>lineSourceRefs[]</code> sorted, <code>narrative</code> resolved with <code>assetId</code>, and <code>dqFlags</code>. <br> 6. Enforce asset-level breakout rules: if <code>policySnapshot.assetLevelPosting[category]=true</code>, create separate lines per asset; if breakout exceeds <code>params.assetBreakoutLimit</code>, produce consolidation suggestion and set <code>aggregateDiagnostics.assetBreakoutSuggested=false</code>. <br> <strong>Invariants:</strong> <br> - Sum(preRoundedAmounts) equals canonical group total. <br> - Deterministic line ordering defined by <code>jeTemplateSpec.lineOrder</code> or fallback. <br> <strong>Failure modes & remediation:</strong> <br> - Missing GL mapping for required line → <code>aggregateDiagnostics.requiresMappingResolution=true</code> and return partial lines with placeholders. <br> - Excessively granular breakout → create consolidation recommendation and route to mapping owners. <br> <strong>Observability:</strong> <code>je.group.rowsAggregated</code>, <code>je.group.lineCount</code>, <code>je.group.roundingDeltaTotal</code>. <br> <strong>CI tests:</strong> numeric parity across locales, asset-breakout stress scenarios, consolidation heuristics correctness. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>ResolveGLMapping(scheduleRow, policySnapshot, jeTemplateSpec, params)</strong> — <br> <strong>Signature:</strong> Inputs: <code>scheduleRow</code>, <code>policySnapshot</code> (mappingOverrides, mappingRules, historicalIndex), <code>jeTemplateSpec</code>, <code>params</code> (runHash, operatorHints). Outputs: <code>mappingResult</code> (GLAccount, costCenter, narrativeTemplate, mappingConfidence, mappingTrace, mappingScoreVector). <br> <strong>Responsibilities (exhaustive):</strong> <br> 1. Evaluate explicit mapping overrides precedence order: <code>assetId</code> override → <code>assetTag</code> override → <code>category</code> override → <code>postingKey</code> override → <code>jeTemplateSpec.defaultMappings</code>. <br> 2. If none found, run heuristic scorer combining invoiceRef exactness, description tag match, vendor→GL historical mapping, costCenter inference, PO references, and previous-run stability signals in <code>policySnapshot.historicalMappingIndex</code>. <br> 3. Assemble <code>mappingScoreVector</code> with labeled signal contributions and compute <code>mappingConfidence</code> normalized to [0,1]. <br> 4. If multiple candidates equal top score tie-break by lexicographic <code>GLAccount</code> then <code>assetId</code> then seeded PRNG using <code>sha256(runHash | postingKey | scheduleRowChecksum)</code> to ensure deterministic fallback. <br> 5. If mappingConfidence < <code>policySnapshot.lowConfidenceThreshold</code> mark <code>requiresManualMapping=true</code>. <br> 6. Produce <code>mappingTrace[]</code> lines documenting each signal and weight; persist pointer to <code>policySnapshot.matchingWeights</code> used. <br> <strong>Invariants:</strong> <br> - Mapping decisions reproducible with identical <code>policySnapshot</code> and <code>runHash</code>. <br> <strong>Failure modes & remediation:</strong> <br> - No mapping found → create <code>mappingSuggestion</code> and persist; route to analyst for acceptance. <br> - Ambiguous mapping for tax-sensitive accounts → mark <code>requiresComplianceApproval</code>. <br> <strong>Observability:</strong> <code>mapping.calls</code>, <code>mapping.lowConfidenceCount</code>, <code>mapping.ambiguousCount</code>. <br> <strong>CI tests:</strong> precedence matrix tests, seeded tie-break reproducibility tests, mappingTrace parity tests. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>ValidateAndBalanceJE(jeLines, roundingScale, bundleToleranceMinorUnits, params)</strong> — <br> <strong>Signature:</strong> Inputs: <code>jeLines[]</code> with <code>roundedAmount</code> and <code>preRoundedAmount</code>, <code>roundingScale</code>, <code>bundleToleranceMinorUnits</code> integer, <code>params</code> (runHash, postingKey). Outputs: <code>balanced</code> boolean, <code>adjustedLines[]</code>, <code>balanceDiagnostics</code>. <br> <strong>Responsibilities (explicit algorithmic steps):</strong> <br> 1. Convert each <code>roundedAmount</code> to integer <code>amountMinorUnits</code> and compute <code>totalDebitMinorUnits</code> and <code>totalCreditMinorUnits</code>. <br> 2. Compute <code>imbalance = totalDebitMinorUnits - totalCreditMinorUnits</code>. <br> 3. If <code>imbalance == 0</code> return <code>balanced=true</code>. <br> 4. If <code>|imbalance| &lt;= bundleToleranceMinorUnits</code> apply deterministic intra-bundle residual absorption: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. Build candidate absorber list sorted by absolute <code>preRoundedAmountMinorUnits</code> descending. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. Resolve ties by <code>account</code> lexicographic ordering; if still tied use seeded PRNG seed = <code>sha256(runHash | postingKey | jeBundleSequence)</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;c. Choose first candidate that remains non-negative after adjusting by <code>-imbalance</code>; if none found escalate to manual review. <br> &nbsp;&nbsp;&nbsp;&nbsp;d. Adjust absorber <code>roundedAmount</code> by <code>-imbalance</code>, update <code>amountMinorUnits</code> and record <code>residualAbsorbed</code> and <code>residualRationale</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;e. Recompute totals and assert balanced. <br> 5. If <code>|imbalance| &gt; bundleToleranceMinorUnits</code> return <code>balanced=false</code> with <code>balanceDiagnostics</code> containing imbalance magnitude, candidateAbsorbers, and suggested remediation steps. <br> <strong>Invariants:</strong> <br> - Post-absorption totals must exactly balance at roundingScale unless <code>unbalanced</code>. <br> <strong>Failure modes & remediation:</strong> <br> - Absorption would flip the sign of absorber line → skip candidate; if no candidate possible, mark <code>unbalanced</code> and require analyst remediation. <br> - Immutable lines (policy) excluded from absorber candidates; result may be <code>unbalanced</code>. <br> <strong>Observability:</strong> <code>je.validation.unbalancedCount</code>, <code>je.validation.residualAbsorbedCount</code>, <code>je.validation.absorptionFailures</code>. <br> <strong>CI tests:</strong> rounding pathology test suite, absorber selection tie-break reproducibility, negative-line protection tests. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>ComputeConfidenceScore(jeProposal, policySnapshot, params)</strong> — <br> <strong>Signature:</strong> Inputs: <code>jeProposal</code> metadata (mappingCompleteness, dqFlags, historicalStability, manualFlags), <code>policySnapshot.matchingWeights</code>, <code>params</code> (runHash). Outputs: <code>confidenceScore</code> 0..1, <code>confidenceBreakdown</code>, <code>scoreVectorUsed</code>. <br> <strong>Responsibilities:</strong> <br> 1. Read <code>policySnapshot.matchingWeights</code> and document the pointer; if absent, use documented default weights and set <code>confidenceFallback=true</code>. <br> 2. Compute sub-scores: <br> &nbsp;&nbsp;&nbsp;&nbsp;- <code>mappingCompleteness</code> = fraction of lines mapped. <br> &nbsp;&nbsp;&nbsp;&nbsp;- <code>dqPenalty</code> = normalized penalty aggregated across <code>dqFlags</code> using penalty weights. <br> &nbsp;&nbsp;&nbsp;&nbsp;- <code>historicalStability</code> = historical mapping agreement metric from <code>policySnapshot.historicalMappingIndex</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;- <code>manualFlagPenalty</code> = binary or scaled penalty if any <code>requiresManualInput</code> flags present. <br> 3. Compute weighted sum using <code>matchingWeights</code> → clamp to [0,1]. <br> 4. Attach <code>confidenceBreakdown</code> and persist <code>scoreVectorUsed</code> for audit parity. <br> <strong>Invariants:</strong> deterministic for identical inputs and weights. <br> <strong>Failure modes:</strong> missing weights produce fallback. <br> <strong>Observability & CI tests:</strong> distribution and sensitivity tests, seeded reproducibility checks. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>BuildJEBundleChecksum(jeProposal, canonicalVersion)</strong> — <br> <strong>Signature:</strong> Inputs: <code>jeProposal</code> canonical object and <code>canonicalVersion</code>. Outputs: <code>jeBundleChecksum</code> <code>sha256:&lt;hex&gt;</code>, <code>canonicalString</code> optionally persisted in debug mode. <br> <strong>Responsibilities (explicit):</strong> <br> 1. Serialize <code>jeProposal</code> fields in exact canonical order per schema: <code>jeMetadata</code> ordered fields → ordered <code>jeLines[]</code> → per-line ordered fields. <br> 2. Apply NFKC to text fields, escape <code>|</code> separators if used, format numbers zero-padded to roundingScale, format dates to <code>YYYY-MM-DD</code>. <br> 3. UTF-8 encode canonical string and compute sha256 hex; prefix <code>sha256:</code>. <br> 4. Persist <code>jeBundleChecksum</code> in <code>jeProposal.metadata</code> and reference <code>canonicalVersion</code>. Optionally persist <code>canonicalString</code> to evidence only when <code>debugMode=true</code> with encryption at rest. <br> <strong>Invariants:</strong> canonical serialization must be identical across runtimes implementing same canonical rules. <br> <strong>Failure modes & CI tests:</strong> parity tests across runtimes, debug canonical snapshots. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>PackagePreviewArtifact(jeProposals, schedulesCsv, policySnapshot, runId, operatorId, previewPackagingSpec)</strong> — <br> <strong>Signature:</strong> Inputs: <code>jeProposals[]</code>, <code>schedulesCsv</code> canonical string, <code>policySnapshot</code>, <code>runId</code>, <code>operatorId</code>, packagingSpec. Outputs: <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>, <code>previewManifest</code> persisted, <code>previewHash</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Render <code>suggestedJEs.csv</code> deterministically using <code>jeTemplateSpec.exportOrder</code> and stable ordering by <code>jeBundleSequence</code> then <code>jeLineId</code>. <br> 2. Build <code>preview_manifest.json</code> with fields: <code>runId</code>, <code>policyHash</code>, <code>previewHash</code> placeholder, <code>rowsCount</code>, <code>jeBundlesCount</code>, <code>evidenceRefs[]</code>, <code>operatorId</code>, <code>createdTs</code>, <code>canonicalVersion</code>, <code>roundingScale</code>. <br> 3. Create ZIP containing canonical <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>. <br> 4. Compute <code>previewHash</code> as sha256 of canonical <code>preview_manifest</code> string; update manifest and re-zip if packaging spec requires manifest-hash-in-zip. <br> 5. Persist ZIP atomically to Evidence Store with retention and legal tags; return evidenceRef. <br> 6. Emit audit <code>fa.je.preview.generated</code> referencing preview artifact. <br> <strong>Invariants:</strong> artifact name must be <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> consistent with manifest. <br> <strong>Failure modes & remediation:</strong> atomic persist failures must trigger staging and retries; escalate to ops on persistent failure. <br> <strong>Observability & CI tests:</strong> packaging latency, manifest parity checks, zip checksum tests. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>PersistPreviewArtifact(previewPath, evidenceStoreClient, previewManifest)</strong> — <br> <strong>Signature:</strong> Inputs: local previewPath, evidenceStore client, <code>previewManifest</code>. Outputs: <code>evidenceRef</code>, <code>persistStatus</code>. <br> <strong>Responsibilities:</strong> <br> 1. Compute artifact checksum and verify local integrity. <br> 2. Upload artifact using evidenceStore atomic write primitives; on success write manifest pointer; set retentionPolicy and legalTags metadata. <br> 3. Emit <code>fa.evidence.persist</code> audit event. <br> <strong>Failure modes & remediation:</strong> partial upload → delete partial artifact if possible; else mark <code>orphanedArtifact</code> and notify ops with staging path. <br> <strong>CI tests:</strong> simulated storage exceptions, atomic-write tests. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>SuggestMappingOverrides(unmappedBundles, historicalIndex, operatorHints, policySnapshot)</strong> — <br> <strong>Signature:</strong> Inputs: <code>unmappedBundles[]</code>, <code>historicalIndex</code>, <code>operatorHints</code>, <code>policySnapshot</code>. Outputs: <code>mappingSuggestions[]</code>, <code>suggestionManifestRef</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. For each <code>unmappedBundle</code> compute candidates via heuristics: invoiceRef co-occurrence, vendor→GL historical mapping, category defaults, cost center inference, and description token matching. <br> 2. Score candidates using <code>policySnapshot.matchingWeights</code> and produce <code>matchTrace[]</code> lines documenting each signal and weight contribution. <br> 3. Present <code>mappingSuggestions</code> ranked by score with example schedule rows and <code>estimatedImpact</code> for analyst acceptance. <br> 4. Persist <code>suggestionManifest</code> and expose an API/UI for bulk acceptance that will produce <code>fa.mapping.override</code> audit rows upon acceptance and trigger targeted <code>AggregateSchedulesToJEs</code> re-runs. <br> <strong>Invariants:</strong> deterministic suggestions given same inputs and seed. <br> <strong>Failure modes & remediation:</strong> low-confidence suggestions flagged for manual mapping and owners notified. <br> <strong>Observability & CI tests:</strong> suggestion acceptance rate, ranking parity tests, OCR/noise robustness tests. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>ExportSuggestedJEsToTemplate(acceptedJEs, exportSpec, operatorId)</strong> — <br> <strong>Signature:</strong> Inputs: <code>acceptedJEs[]</code>, <code>exportSpec</code> (fieldMap, dateFormat, numberFormat, signConvention), <code>operatorId</code>. Outputs: <code>payloadString</code> (CSV/JSON/XML), <code>exportChecksum</code> (<code>sha256:&lt;hex&gt;</code>), <code>exportManifest</code>. <br> <strong>Responsibilities (explicit):</strong> <br> 1. Validate acceptedJEs conform to <code>exportSpec</code> schema and column order; return deterministic diagnostics on mismatch. <br> 2. Normalize numbers/dates and apply sign conventions. <br> 3. Ensure each JE bundle balances in exported representation; if not, fail with explicit bundle IDs and reasons. <br> 4. Compute <code>exportChecksum</code> and persist <code>exportManifest</code> including <code>operatorId</code>, <code>createdTs</code>, <code>evidenceRefs</code>. <br> <strong>Failure modes & remediation:</strong> schema mismatch requires operator correction or exportSpec update approved by governance. <br> <strong>CI tests:</strong> loader acceptance tests, export format golden fixtures. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>EmitPreviewAuditEvents(previewManifest, operatorId, telemetryClient)</strong> — <br> <strong>Signature:</strong> Inputs: <code>previewManifest</code>, <code>operatorId</code>, telemetry client. Outputs: auditEventRefs persisted. <br> <strong>Responsibilities:</strong> <br> 1. Emit <code>fa.je.preview.generated</code> audit row with <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code>, <code>previewHash</code>, <code>operatorId</code>, <code>paramsHash</code>. <br> 2. Emit telemetry metrics (bundlesCreated, unbalancedCount, avgConfidence, packagingMs) to SLO dashboards. <br> 3. Ensure audit events persisted before user-facing notifications. <br> <strong>Failure modes & remediation:</strong> audit store unavailability → persist local stub and escalate after N retries. <br> <strong>CI tests:</strong> audit event schema verification, retry correctness. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Cross-cutting primitives and helpers (detailed)</strong> <br> <strong>CanonicalSerialize(obj, fieldOrder)</strong> — stable serializer implementing NFKC, whitespace collapse, deterministic JSON compacting for arrays, stable sort for unordered sets, number formatting to <code>scale</code>, date formatting, and <code>|</code> escaping. Field order passed explicitly; serializer must be tested for parity across environments. <br> <strong>ComputeSHA256(bytes)</strong> — wrapper returning <code>sha256:&lt;hex&gt;</code> using vetted crypto library or service; do not implement bespoke crypto. <br> <strong>ToMinorUnits(decimalString, scale, sourceCulture)</strong> — canonical numeric parse with thousand-sep clean, decimal separator canonicalization, and integer minor-units output; returns diagnostics on ambiguous locale parse. <br> <strong>DeterministicSort(keys, comparator)</strong> — stable sort helper guaranteeing identical ordering across runtimes. <br> <strong>SafeWriteAtomic(path, payload, evidenceStoreClient)</strong> — writes atomically to evidence store; on partial failure ensures cleanup and returns deterministic error codes for ops to act on. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Extended worked examples — ultra-detailed, forensic step-by-step</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Example 1 — Complex capitalization across multiple invoices + component creation + mapping override (full forensic trace):</strong> <br> Steps and evidence trail: <br> 1. Invoices INV-2026-100 ($12,500 USD) and INV-2026-101 ($2,200 USD) received. <code>LoadCapexTransactions</code> normalizes descriptions, parses numbers to <code>amountMinorUnits</code>, calculates <code>capexRowChecksum</code>, and produces <code>capexIngestManifest</code>. <code>capexIngestManifest</code> includes <code>sourceFingerprint</code>, <code>rowsCount</code>, <code>issues[]</code> and candidateMappingIndex entry for INV-2026-101 referencing <code>assetIdCandidate=AS-000789</code> with <code>candidateScore=0.93</code>. <br> 2. <code>policySnapshot</code> indicates <code>componentPolicy</code> for <code>IT</code> category: accessories treated as <code>create_component</code> when accessoryReason='expansion'. <code>ComputeDepreciation</code> consumes <code>capexIngestManifest</code> and produces <code>assetRevisionId = sha256(assetRowChecksum | capexRowChecksum | decisionTsCanonical | policyHash)</code>; new component asset row persisted with <code>componentOf=AS-000789</code>. <code>depreciationRunManifest.changedAssetRevisionIds[]</code> lists the new revision. <br> 3. Schedules computed for parent and component separately; schedule rows include <code>preRoundedAmount</code>, <code>depreciationAmount</code>, <code>prorationFactor</code> if applicable, and <code>evidenceRefs[]</code> referencing asset rows and capex rows. All schedule rows have immutable <code>scheduleRowChecksum</code>. <br> 4. <code>AggregateSchedulesToJEs</code> groups postingKeys and calls <code>ResolveGLMapping</code>: component depreciation uses <code>policySnapshot.mappingOverrides</code> to map to sub-account 6120-ACC; <code>ResolveGLMapping</code> writes <code>mappingTrace[]</code> showing override path and <code>mappingConfidence=1.0</code>. <code>jeProposals[]</code> created for parent and component; <code>jeBundleChecksum</code>s computed using <code>BuildJEBundleChecksum</code>. <br> 5. <code>PackagePreviewArtifact</code> creates <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> containing canonical <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code> with <code>evidenceRefs[]</code> pointing to asset revision and capex artifacts. Audit <code>fa.je.preview.generated</code> emitted. <br> 6. Analyst accepts mapping override via UI; acceptance persists <code>fa.mapping.override</code> with <code>mappingOverrideRef</code> and triggers targeted re-run of <code>AggregateSchedulesToJEs</code> for affected postingKeys only; new preview artifact produced and evidence persisted. <br> Forensic ability: auditors replay decisions by pulling <code>capexIngestManifest</code>, <code>assetIngestManifest</code>, <code>depreciationRunManifest</code>, <code>preview_manifest</code>, and <code>mappingOverrideRef</code>. Deterministic checksums allow verification of identical outputs. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Example 2 — Disposal with cross-currency proceeds and approval gating (trace & edge nuance):</strong> <br> Steps and forensic detail: <br> 1. DisposalRow for <code>AS-000456</code> inserted with <code>proceeds=EUR 2,200</code> and <code>eventRowChecksum</code> recorded. <code>ComputeDepreciation</code> references <code>fxRates_20260715</code> manifest which includes <code>fxTableChecksum</code> and <code>canonicalVersion</code>. <code>ComputeDepreciation</code> converts proceeds to USD using <code>fxRateRef</code> producing <code>proceedsUSD=2,383.26</code> canonical (rounded per <code>roundingScale</code>). <br> 2. Engine computes <code>gainLossRecognized = proceedsUSD - NBV</code> deterministically. It produces disposal schedule rows and a disposal event <code>jeProposal</code> with lines referencing <code>disposalRowChecksum</code> and <code>fxRateRef</code>. <code>jeProposal.previewStatus=&#x27;requiresApproval&#x27;</code> because <code>policySnapshot</code> flags disposals above $2,000 require <code>taxTeamApproval</code>. <br> 3. <code>PackagePreviewArtifact</code> persists preview and <code>preview_manifest</code> includes <code>requiresApproval=true</code> and <code>approvalInstructions</code> and emits <code>fa.je.preview.generated</code>. <code>GenerateJEExport</code> can create export artifact but <code>ApplyCorrections</code> <code>post_direct</code> blocks without <code>approvalRef</code>. <br> 4. Analyst requests approval via <code>approvalRequest</code> CTA; the approval process persists <code>approvalRef</code> and audit <code>fa.approval.granted</code> then <code>ApplyCorrections</code> can proceed for <code>post_direct</code> with ephemeral credentials and idempotency token derived from <code>applyId</code>. <br> Forensic trace: all FX references, disposalRowChecksum, approvalRef and applyDescriptor stored in Evidence Store. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Example 3 — Large-scale rounding pathology and deterministic batch residual absorption (detailed):</strong> <br> Scenario: 10,000 assets each with 3-month life cause recurring monthly preRounded amounts 333.333... roundingScale=2 leads to aggregate residual +100.00. <br> Resolution path: <br> 1. <code>AggregateSchedulesToJEs</code> computes per-postingKey preRounded sums and rounding deltas. It aggregates to <code>batchResidual=+100.00</code> and records this in <code>depreciationRunManifest.batchResidualSummary</code>. <br> 2. <code>policySnapshot.batchResidualPolicy = &quot;costCenterAggregateAbsorption&quot;</code>. Algorithm: group residuals by <code>costCenter</code>, compute per-asset preRounded absolute contributions, and absorb deterministically by selecting highest preRounded amounts first within each costCenter. Tie-breakers resolve by smallest <code>assetId</code> then seeded PRNG <code>sha256(runHash|costCenter)</code>. <br> 3. Adjusted schedule rows receive <code>residualAbsorbed</code> updates and <code>residualRationale</code>. <code>jeProposals</code> include absorption lines where required. <code>preview_manifest</code> includes <code>batchResidualSummary</code> and the absorption rationale. <br> 4. Auditors validate absorption by replaying <code>depreciationRunManifest</code> and verifying canonicalized sums and deterministic tie-break choices. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Example 4 — Units-of-Production missing usage metrics and manual-input workflow (detailed):</strong> <br> Steps: <br> 1. Asset method <code>UnitsOfProduction</code> expects <code>totalExpectedUsage=10000</code>; <code>usageThisPeriod</code> absent. <code>ComputeDepreciation</code> flags schedule rows with <code>requiresManualInput=true</code> and emits <code>fa.depn.run.requires_manual_input</code> containing sample rows and <code>runId</code>. <br> 2. <code>AggregateSchedulesToJEs</code> includes affected rows in <code>jeProposals</code> but sets <code>confidenceScore</code> low and marks <code>jeLines</code> with <code>dqFlags</code> referencing missing usage. <code>preview_manifest</code> surfaces these for analysts. <br> 3. Analyst adds usage via <code>fa.manualInputs.add</code> which persists <code>manualInputRef</code> and triggers targeted <code>ComputeDepreciation</code> for <code>changedAssetRevisionIds[]</code>. New schedules and <code>jeProposals</code> are generated. <br> Forensic trace: <code>manualInputRef</code> links, <code>assetRevisionId</code> changes, and <code>depreciationRunManifest</code> entries are preserved for replay and audit. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Edge-case patterns and defensive design behaviors (expanded)</strong> <br> 1. <strong>PostingKey cardinality explosion:</strong> when <code>postingKey</code> count exceeds <code>params.postingKeyCardinalityThreshold</code> the pipeline automatically switches to chunked processing: deterministic shard assignment by hashed postingKey ranges, produce partial preview artifacts per shard with stable ordering, and assemble an index manifest referencing chunk artifacts; <code>depreciationRunManifest</code> records chunk order and composition. <br> 2. <strong>Immutable policyHash checks:</strong> if <code>AggregateSchedulesToJEs</code> detects <code>policyHash</code> mismatch vs provided <code>depreciationRunManifest.policyHash</code>, fail with <code>fa.je.preview.invalid_policy_version</code> and require run to be re-run with correct <code>policyHash</code>. <br> 3. <strong>Missing scheduleRow fields (preRoundedAmount) or negative NBV:</strong> schedule rows flagged <code>requiresManualOverride</code>; <code>jeProposals</code> include these rows but with <code>requiresManualInput</code> flagged and <code>confidenceScore</code> reduced to force analyst attention. <br> 4. <strong>GL loader constraints incompatible with policy-level breakout:</strong> produce <code>mappingSuggestion</code> recommending consolidation mapping and estimated reconciliation impact; escalate if loaders require strict formats. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Power Query (PQ) conceptual guidance for pilots (expanded, no code snippets)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>When PQ is appropriate for JE preview pipelines:</strong> <br> - Analyst previews for small cohorts (< ~5k assets depending on complexity), interactive mapping acceptance, early canonicalization parity checks against backend. PQ is not appropriate for enterprise-wide production runs (10k+ assets). <br> <strong>PQ pilot architecture pattern:</strong> <br> 1. Create small number of parameterized queries: <code>AssetMaster_Staging</code>, <code>Capex_Staging</code>, <code>Schedules_Preview</code>, and <code>JE_Template_Param</code>. <br> 2. Expose <code>headerSynonyms</code>, <code>decimalLocale</code>, <code>roundingScale</code> as query parameters for analyst correction and parity experiments. <br> 3. Implement canonicalization steps with explicit step names: <code>TextNormalize</code>, <code>ParseAmounts</code>, <code>ComputeAmountMinorUnits</code>, <code>DateISO</code>, <code>ComputePreRounded</code>. Keep intermediate outputs inspectable for parity debugging. <br> 4. Compute <code>policyHash</code> locally in PQ by deterministically serializing <code>policySnapshot</code> rows (stable key order) into compact string and compute deterministic hash via host function or helper service; include <code>canonicalVersion</code> constant within PQ. <br> <strong>Canonicalization steps in PQ (conceptual):</strong> <br> 1. Text normalization: use <code>Text.Trim</code> and <code>Text.Clean</code> for spaces; implement diacritic mapping tables if <code>Text.Normalize</code> unavailable; casefold using <code>Text.Lower</code>. <br> 2. Numeric parsing: replace thousand separators, unify decimal separator to <code>.</code> then use <code>Number.FromText</code> with explicit culture; compute <code>amountMinorUnits</code> by rounding to <code>roundingScale</code> and multiply by 10^scale; store both integer and decimal forms. <br> 3. Date parsing: <code>Date.FromText</code> with explicit format and capture <code>rawDateString</code> for failures logged to <code>issues[]</code>. <br> 4. Package preview: render canonical <code>schedules.csv</code> and <code>suggestedJEs.csv</code> in correct column order, compute <code>preview_manifest.json</code> string, and then host automation or backend helper composes the ZIP and persists to Evidence Store. <br> <strong>PQ anti-patterns and mitigations (expanded):</strong> <br> 1. Per-row custom functions: anti-pattern for large samples; vectorize transformations with table joins and aggregated transforms; use <code>Table.Buffer</code> judiciously. <br> 2. High-precision decimal math: PQ lacks arbitrary precision; represent <code>preRoundedAmount</code> as string and validate parity by mirroring computations in backend for production promotion. <br> 3. In-memory heavy joins: sample for preview and offload full-run joins to backend. <br> <strong>PQ parity testing:</strong> <br> 1. Produce PQ golden fixtures: canonical <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code> and compute <code>previewHash</code> in PQ run. <br> 2. Backend parity job replays PQ canonicalization for sample inputs; any mismatches create <code>pqParityReport</code> enumerating differences (locale parsing, rounding mode, string normalization). <br> <strong>Operational PQ flow:</strong> analyst builds preview in PQ → PQ writes preview artifact via host automation to Evidence Store → backend parity job replays canonicalization and checks <code>previewHash</code> equality → mismatch triggers <code>fa.verify.parity.failed</code> and blocks promotion. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX measures, reporting patterns & UX (no code snippets)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Modeling guidance & relationships:</strong> <br> - Use canonical keys: <code>assetId</code>, <code>policyHash</code>, <code>runId</code>, <code>previewHash</code>, <code>jeBundleSequence</code> as foreign keys. <br> - Tokenize PII and restrict raw evidence retrieval behind <code>approval</code> flows invoked from reports (CTAs create <code>approvalRequest</code> artifacts). <br> - Maintain dimension tables for <code>policySnapshot</code>, <code>jeTemplateSpec</code>, <code>depreciationRunManifest</code> to allow slicers by policyHash and canonicalVersion. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Core DAX measures & patterns (conceptual):</strong> <br> 1. <code>DepreciationExpense</code>: period-sum of <code>DepSchedule[depreciationAmount]</code>. <br> 2. <code>AccumulatedDepreciation</code>: sum of <code>DepSchedule[accumulatedDepreciationToDate]</code>. <br> 3. <code>NetBookValue</code>: sum of <code>DepSchedule[bookValueEnd]</code>. <br> 4. <code>FA_ReconVariance</code>: SUM(Subledger[AccumulatedDep]) - SUM(GL[AccumulatedDep]). <br> 5. <code>BeyondToleranceFlag</code>: dynamic materiality test toggled by parameterized thresholds. <br> 6. <code>SuggestionAcceptanceRate</code>: ratio of accepted to suggested JEs. <br> <strong>Operational DAX measures for JE preview UX:</strong> <br> - <code>JE_Bundles_Suggested</code> distinct count of <code>Preview[jeId]</code>. <br> - <code>JE_Bundles_Accepted</code> distinct count of <code>AcceptedJEs[jeId]</code>. <br> - <code>JE_Unbalanced_Count</code> count where <code>previewStatus=&#x27;unbalanced&#x27;</code>. <br> - <code>Avg_Confidence</code> average <code>Preview[confidenceScore]</code>. <br> <strong>Drillthrough & UX patterns:</strong> <br> - Clicking an <code>unbalanced</code> cell opens a drillthrough page showing <code>jeLines</code>, <code>mappingTrace</code>, <code>evidenceRefs</code> and <code>estimatedImpact</code>. <br> - CTAs on drillthrough: <code>requestMappingChange</code>, <code>requestManualAdjustment</code>, <code>acceptBundle</code>, <code>rejectBundle</code> — each action creates an auditable manifest and updates evidence store records. <br> <strong>Materiality & scenario toggles:</strong> expose absolute and percentage materiality thresholds as runtime parameters; measures should reflect selected threshold clearly in captions and exported audit CSVs. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Testing strategy & exhaustive CI / golden parity matrix (expanded)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Unit tests (JE-generator-specific):</strong> <br> 1. <code>ResolveGLMapping</code> precedence and tie-breaker reproducibility across locales. <br> 2. <code>GroupAndAggregateLines</code> rounding parity across scales and numeric localization. <br> 3. <code>ValidateAndBalanceJE</code> residual absorption tests across tie-break scenarios. <br> 4. <code>BuildJEBundleChecksum</code> canonicalization parity tests across PQ pilot and backend runner. <br> <strong>Integration tests:</strong> <br> 1. ingest→compute→aggregate→preview roundtrips for representative fixtures including disposals, revaluations, and components. <br> 2. mapping override acceptance flows, bulk acceptance and targeted re-run test. <br> <strong>Golden parity tests:</strong> <br> - Maintain canonical fixtures for <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>, <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> and expected checksums. <br> - CI validates parity across PQ pilot and backend; any diff blocks merges. <br> <strong>Property tests:</strong> <br> - Input row-order independence, header synonym robustness, idempotency of preview packaging and apply/revert flows, deterministic PRNG seeds reproducibility. <br> <strong>Performance & load tests:</strong> <br> - Preview generation latency: 100 rows P50 < 500ms; 500 rows P50 < 2s; 5k rows measured for backend scaling. <br> <strong>Security & compliance tests:</strong> <br> - PII redaction verification on analyst surfaces, evidence access approval tests, ephemeral token lifecycle tests for post flows. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Observability, auditing architecture & SLOs (expanded)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Mandatory audit events:</strong> <br> - <code>fa.je.preview.generated</code>, <code>fa.je.bundle.unbalanced</code>, <code>fa.je.mapping.suggestion</code>, <code>fa.evidence.persist</code>, <code>fa.mapping.override</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start/complete/fail</code>, <code>fa.je.revert</code>. Each audit includes <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code> or <code>exportChecksum</code>, <code>operatorId</code>, <code>paramsHash</code>. <br> <strong>Evidence store conventions:</strong> append-only, artifact metadata: <code>createdTs</code>, <code>checksum</code>, <code>retentionPolicy</code>, <code>legalTags</code>, <code>canonicalVersion</code>. Raw PII access requires <code>approvalRef</code> and emits chain-of-custody audit rows. <br> <strong>Key SLOs examples:</strong> <br> 1. <code>PreviewLatencyP50</code> target < 2s for <=500 rows. <br> 2. <code>PreviewPackagingSuccessRate</code> target >= 99.9%. <br> 3. <code>ApplySuccessRate</code> target > 99% (create_export mode). <br> 4. <code>GoldenParityFailureRate</code> target 0% in protected branches. <br> <strong>Parity verification job:</strong> daily job recomputes <code>previewHash</code> for stored artifacts and emits <code>verify.parity.failed</code> when mismatches occur; investigations open immediately with <code>correlationId</code> logged. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Failure modes, mitigation & exhaustive operator runbooks (expanded)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Fault A — malformed ingest / invalid schedule rows:</strong> <br> 1. Symptom: <code>fa.asset.ingest.invalid</code> or <code>fa.capex.ingest.partial</code> and <code>rowsFailed</code> > 0. <br> 2. Triage: capture <code>correlationId</code>, fetch ingest manifest and raw evidence, examine <code>issues[]</code> for encoding, header mapping or parse errors. <br> 3. Remediation: correct headerMap and re-run <code>LoadAssetMaster</code> with <code>correctionOf</code> linking to prior <code>sourceFingerprint</code>; apply fixes to upstream data provider and re-ingest. <br> <strong>Fault B — mapping backlog spike:</strong> <br> 1. Symptom: <code>capex.ingest.unmappedCount</code> spike. <br> 2. Triage: run <code>SuggestMappingOverrides</code> to rank unmapped items by total value and frequency. <br> 3. Remediation: present bulk mapping suggestions to owners; after acceptance re-run targeted <code>AggregateSchedulesToJEs</code>. <br> <strong>Fault C — JE export rejected by GL loader:</strong> <br> 1. Symptom: GL loader returns line-level errors. <br> 2. Triage: fetch <code>exportManifest</code>, simulate import in test GL system, run export schema validation. <br> 3. Remediation: correct <code>exportSpec</code> and re-export; if postings already applied, run <code>RevertJEs</code> and reapply corrected export. <br> <strong>Fault D — partial apply failure / unexpected GL state:</strong> <br> 1. Symptom: <code>apply.partialFailureCount</code> > 0. <br> 2. Triage: retrieve <code>applyDescriptor</code> and postedJournalIds; analyze per-JE error codes returned by GL. <br> 3. Remediation: attempt governed retries for transient errors; for permanent errors create <code>forensic_manifest</code> and escalate to GL/compliance teams. Use <code>RevertJEs</code> where safe. <br> <strong>Emergency policy rollback plan:</strong> <br> 1. Symptom: parity delta after policy promotion causing material variances. <br> 2. Steps: perform pointer swap to prior <code>policyHash</code>, run smoke-preview comparisons across canonical fixtures; if parity restored log <code>policy.hotSwap.auditChain</code> and notify stakeholders; if not, escalate and run canary analysis. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Migration manifest & policy-change governance (expanded)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Required fields for migration manifest:</strong> <br> - <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedSpecFields[]</code> before/after, <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (cohort sizes, KPIs), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> <strong>Lifecycle:</strong> <br> 1. Draft manifest and register in policy governance. <br> 2. Execute canary per plan on sample cohort; monitor KPIs for at least two cycles. <br> 3. If KPIs within thresholds and approvals captured promote snapshot and persist manifest; otherwise rollback to prior <code>policyHash</code>. <br> 4. For regulated GL ranges require compliance signatures in <code>approvals[]</code> and schedule controlled rollout. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Artifact naming & canonical storage conventions (JE artifacts):</strong> <br> - <code>assetIngestManifest</code>: <code>asset_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br> - <code>capexIngestManifest</code>: <code>capex_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br> - <code>policySnapshot</code>: <code>fa_policy_&lt;policyHash&gt;.json</code>. <br> - <code>depreciationPreview</code>: <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>. <br> - <code>jeExport</code>: <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>. <br> - <code>applyDescriptor</code>: <code>apply_&lt;applyId&gt;.json</code> persisted prior to mutative actions. <br> - <code>recon_report</code>: <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code>. <br> Checksum policy: sha256 over canonicalized payloads; record <code>checksumAlgorithm</code> and <code>canonicalVersion</code> in manifest metadata. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Performance, scale & architecture recommendations (expanded)</strong> </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Scale tiers & compute model:</strong> <br> 1. PQ pilot: suitable for previewing small cohorts up to a few thousand assets with careful vectorization. <br> 2. Backend/warehouse: recommended for fleets >= 10k assets using parallel compute. <br> 3. Sharding: per-asset schedule computation is embarrassingly parallel; shard by <code>assetId</code> ranges or <code>category</code> ensuring deterministic ordering within shards. <br> 4. Incremental recompute: support partial recompute triggered by <code>changedAssetRevisionIds[]</code> to avoid full-run compute for minor changes; <code>depreciationRunManifest</code> should record changed asset ids to enable partial replay. <br> 5. Storage pattern: object store for large artifacts, canonical manifests in relational store for fast lookup, and small evidence index for resolution. <br> 6. Autoscaling & batch windows: schedule compute windows for close runs; scale workers based on queue depth and SLO targets; monitor <code>depn.run.durationMs</code>. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Operator CLI patterns & examples (expanded)</strong> <br> 1. <code>fa.build-run --period 2026-01 --policyRef fa_policy_20260101 --operator alice</code> → runs ingest & compute and returns <code>runId</code> and <code>depreciationRunManifestRef</code>. <br> 2. <code>fa.preview --run &lt;runId&gt; --sample 500 --operator alice</code> → produces preview artifact and <code>previewHash</code>. <br> 3. <code>fa.suggest-je --preview &lt;previewRef&gt; --operator alice</code> → creates suggested JEs and <code>jePreviewHash</code>. <br> 4. <code>fa.generate-je --preview &lt;previewRef&gt; --accept &lt;suggestionIds&gt; --exportSpec ERP_JE_v1 --operator alice</code> → writes <code>FA_JE_Export_&lt;runId&gt;.&lt;ext&gt;</code> and <code>fa.je.exported</code>. <br> 5. <code>fa.apply --export &lt;exportPath&gt; --mode post_direct --operator alice --approvalId ap-321 --approver bob</code> → enforces ephemeral token issuance and two-person approval; emits <code>fa.je.apply.start</code> and <code>fa.je.apply.complete/fail</code>. <br> 6. <code>fa.revert --applyId &lt;applyId&gt; --operator alice</code> → triggers <code>RevertJEs</code> and logs <code>fa.je.revert</code>. <br> 7. <code>fa.policy.migrate --manifest &lt;manifestRef&gt; --operator alice</code> → executes migration canary per manifest and logs outcomes. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria & release gates (JE generator focused)</strong> <br> 1. Unit tests for canonicalization and method math parity pass across locales and runtimes. <br> 2. Integration tests validate ingest→compute→aggregate→preview→export flows on canonical fixtures and expected artifact checksums. <br> 3. Golden parity tests ensure <code>jeBundleChecksum</code>, <code>previewHash</code>, and <code>exportChecksum</code> match expected values across PQ pilot and backend; failing golden tests block merges. <br> 4. Migration manifest required for semantic policy changes and canary executed with KPIs and approvals recorded before promotion. <br> 5. Governance: direct posting requires two-person approval and ephemeral token issuance; audit completeness required for all mutative steps. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Appendices — templates, runbook checklists & evidence retrieval patterns (concise)</strong> <br> <strong>Appendix A — migrationManifest template fields:</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedSpecFields[]</code>, <code>sampleFixtures[]</code>, <code>estimatedAffectedCount</code>, <code>canaryPlan</code>, <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> <strong>Appendix B — run verification checklist:</strong> <br> 1. Confirm <code>policyHash</code> equals approved policy snapshot. <br> 2. Verify presence of <code>assetIngestChecksum</code> and <code>capexIngestChecksum</code> in <code>depreciationRunManifest</code>. <br> 3. Recompute <code>runHash</code> locally with canonicalizer and compare to persisted <code>runHash</code>. <br> 4. Confirm <code>previewHash</code> parity for analyst previews. <br> 5. Verify <code>jePreviewArtifact</code> balanced and validated against <code>jeTemplateSpec</code>. <br> <strong>Appendix C — evidence & retrieval security checklist:</strong> <br> 1. Tokenize PII on analyst surfaces; raw PII retrieval requires <code>approvalRef</code> and produces chain-of-custody audit rows. <br> 2. Ephemeral tokens for GL posting; never persist token material in logs. <br> 3. Static analysis for plaintext secrets in repo and secure key management for evidence encryption keys. </td></tr><tr><td data-label="modJEGenerator — Per-function Expert Technical Breakdown"> <strong>Closing operational note (concise):</strong> <code>modJEGenerator</code> must be evidence-first, deterministic, and auditable. Every mapping, rounding, absorption, and packaging decision must trace to canonical evidenceRefs and be reproducible by re-running canonical serialization using the same <code>policyHash</code>, <code>canonicalVersion</code>, and <code>runHash</code>. Next extractable artifacts available on request (choose one or more): <br> • Formal JSON Schema for <code>JE_Line</code>, <code>JE_Bundle</code>, <code>preview_manifest</code> with exact canonical field ordering. <br> • Canonical CSV test fixtures and expected <code>jeBundleChecksum</code> / <code>previewHash</code> golden samples. <br> • Power Query step-by-step canonicalization recipe for a JE preview pilot (mapping PQ function names to canonical operations). <br> • Compact runbook PDF summarizing triage steps and CLI commands for operations teams. <br> Specify desired artifact(s) and target environment (VBA host vs backend) and artifacts will be produced following the canonical recipes in this specification. </td></tr></tbody></table></div><div class="row-count">Rows: 48</div></div><div class="table-caption" id="Table4" data-table="Docu_0186_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modExport — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modExport — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Purpose & scope (concise):</strong> The <code>modExport</code> module is the authoritative component that converts analyst-accepted journal entry suggestions into deterministic, auditable, loader-ready export artifacts and canonical manifests; validates mapping and balancing rules; applies deterministic rounding and residual absorption; persists artifacts atomically (or with secure staging and manual promotion) into an append-only Evidence Store; emits audit events for every operator and automated action; supports approval gating for regulated ranges; produces idempotent apply descriptors; and provides traceable revert descriptors for safe rollbacks. All artifacts must be canonicalized according to <code>canonicalVersion</code> and hashed using <code>sha256:</code>. This document expands every per-row narrative, defines complete function contracts, supplies exhaustive examples and edge cases, gives conceptual Power Query guidance for pilots, and outlines conceptual DAX measures and reporting patterns — no code snippets. Every numbered list uses <code>&lt;br&gt;</code> line breaks. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Canonical models — ultra-detailed per-row narratives, invariants, and forensic handling</strong> <br><br> <strong>ExportArtifactRow — full narrative:</strong> <br> Purpose: an immutable representation of the final serialized payload (CSV/JSON/XML) that will be delivered to a downstream GL loader or staged for later posting. <br> Fields & behavior: <br> 1. <code>artifactId</code> (string): deterministic id computed as <code>sha256(artifactPath|exportChecksum|canonicalVersion)</code> to avoid collisions and enable fast lookups. <br> 2. <code>artifactName</code> (string): filename following canonical pattern <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>; storage backends must be considered when choosing characters. <br> 3. <code>exportChecksum</code> (string): <code>sha256:&lt;hex&gt;</code> computed over exact UTF-8 bytes of <code>payloadBytes</code>. <br> 4. <code>rowsCount</code> (integer): number of serialized payload lines; if logical → payload mapping differs (e.g., multi-line narratives), record <code>logicalRows</code> and <code>payloadRows</code>. <br> 5. <code>byteSize</code> (integer): exact number of bytes written; used to validate streaming chunking and for storage billing reconciliation. <br> 6. <code>encoding</code> (string): <code>UTF-8</code> canonical; if conversion occurred record <code>sourceEncoding</code> and <code>normalizationSteps</code>. <br> 7. <code>canonicalVersion</code> (string): the canonicalization engine version identifier used; required for parity. <br> 8. <code>exportSpecRef</code> (evidenceRef): pointer to the canonical <code>exportSpec</code> snapshot used. <br> 9. <code>artifactMetadata</code> (object): deterministic details: <code>delimiter</code>, <code>quoteChar</code>, <code>lineEnding</code>, <code>dateFormat</code>, <code>numberScale</code>, <code>signConvention</code>, <code>escapePolicy</code>, <code>allowEmbeddedNewlines</code>. <br> 10. <code>createdTs</code>, <code>createdBy</code>, <code>retentionPolicy</code>, <code>legalTags</code>, <code>privacyClassification</code>. <br> 11. <code>artifactRef</code> (evidenceRef): object path in the Evidence Store where the artifact is accessible. <br> Forensics & invariants: <br> • <code>artifactRef</code> when dereferenced must yield bytes hashing to <code>exportChecksum</code>. <br> • <code>artifactMetadata</code> must match the <code>exportSpecRef</code> used to generate the artifact. <br> • If artifact contains PII, <code>privacyClassification</code> must be non-null and <code>approvalsRef</code> required for retrieval; every retrieval emits a <code>chainOfCustody</code> audit record. <br> Evidence handling: <br> • Persist <code>serializedPreview</code> (first N canonical rows) as a separate evidence blob to accelerate parity checks and triage workflows; redact PII by default and record <code>previewRedactionSummary</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>ExportManifestRow — full narrative:</strong> <br> Purpose: canonical JSON manifest that documents provenance, parameters, governance, diagnostics, and references to evidence. <br> Fields & semantics: <br> 1. <code>manifestId</code> (sha256): computed over canonicalized manifest string. <br> 2. <code>artifactName</code>, <code>artifactRef</code>, <code>exportChecksum</code>. <br> 3. <code>manifestChecksum</code> (sha256) computed over canonicalized manifest bytes with fixed field ordering. <br> 4. <code>runId</code>, <code>runHash</code> linking to <code>ComputeDepreciation</code>. <br> 5. <code>policyHash</code> and <code>policySnapshotRef</code> used for mapping and thresholds. <br> 6. <code>exportSpecRef</code> and <code>exportSpecHash</code>. <br> 7. <code>rowsCount</code>, <code>logicalRowsCount</code>, <code>payloadRowsCount</code>. <br> 8. <code>rowsSample[]</code> selected deterministically using <code>rowsSampleSeed</code> derived from <code>runHash</code> with entries <code>{rowIndex,lineChecksum,evidenceRefs,notes}</code>. <br> 9. <code>operatorId</code>, <code>createdTs</code>, <code>canonicalVersion</code>, <code>paramsHash</code> for options used (rounding overrides, tolerance). <br> 10. <code>issues[]</code> — structured warnings and non-fatal problems (truncation incidents, mapping overrides, absorption records) with sample evidenceRefs. <br> 11. <code>approvalsRef</code> nullable — evidenceRef to approvals artifacts when required. <br> 12. <code>correctionOf</code> nullable — evidenceRef to earlier manifest being corrected. <br> 13. <code>retentionPolicy</code>,<code>legalTags</code>,<code>privacyClassification</code>. <br> Invariants & forensic rules: <br> • Manifest must be canonicalized with fixed field ordering and compact JSON to ensure stable <code>manifestChecksum</code>. <br> • <code>rowsSample[]</code> selection algorithm must be deterministic and reproducible across environment replays. <br> • Any mapping override must include <code>overrideBy</code>,<code>overrideReason</code>,<code>overrideChecksum</code> and persist underlying evidence. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>JEExportLine / ExportLineRow — full narrative:</strong> <br> Purpose: canonical representation of a single export payload row that maps a JE line to loader columns. <br> Fields & semantics: <br> 1. <code>lineId</code> (string): deterministic <code>sha256(jeId|lineSequence|exportSpecHash)</code> to uniquely identify a row. <br> 2. <code>jeId</code>, <code>lineSequence</code>. <br> 3. <code>exportColumns</code> (ordered object): exact string values ready for serialization per loader field order. <br> 4. <code>amountMinorUnits</code> (integer) and <code>decimalString</code> zero-padded to <code>roundingScale</code>. <br> 5. <code>currency</code> (ISO4217). <br> 6. <code>account</code> (canonical GL account) and <code>accountMappingRef</code> if computed from policy. <br> 7. <code>costCenter</code> canonical string and <code>costCenterMappingRef</code>. <br> 8. <code>narrativeToken</code> tokenized narrative and <code>rawNarrativeRef</code> to evidence when PII redaction applied. <br> 9. <code>evidenceRefs[]</code> linking to schedule rows, depreciation run manifest, capex ingest manifest, or validation artifacts. <br> 10. <code>lineChecksum</code> (sha256) computed over canonical pre-escaped row string. <br> 11. <code>escapeDiagnostics</code> object capturing escapes/truncations with <code>fieldName</code>, <code>originalLength</code>, <code>truncatedValue</code>, <code>overrideReason</code>, <code>overrideBy</code>, <code>overrideTs</code>. <br> Forensics & invariants: <br> • <code>lineChecksum</code> assists auditors to find matching preview rows and source JE suggestions. <br> • Any truncation/override must preserve <code>rawNarrativeRef</code> for forensic replay unless policy forbids retention of PII. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>ValidationReportRow — full narrative:</strong> <br> Purpose: persistent diagnostics produced by <code>ValidateExportSpec</code> and other validation steps; used to triage blocking failures before artifact creation. <br> Fields & semantics: <br> 1. <code>reportId</code>, <code>specHash</code>, <code>ok</code> boolean. <br> 2. <code>errors[]</code> structured as <code>{code,severity,sampleRow,sampleRowRef,suggestedFix,diagnosticHints}</code>. <br> 3. <code>warnings[]</code> non-blocking anomalies. <br> 4. <code>mappingSuggestions[]</code> with <code>field</code>, <code>suggestedMapping</code>, <code>confidence</code>, <code>evidenceRefs</code>. <br> 5. <code>createdTs</code>, <code>generatedBy</code>, <code>paramsHash</code>. <br> Governance: <br> • Persisted and attached to manifest when present; used to auto-populate operator tickets or to auto-apply low-risk mapping overrides when allowed by policy with recorded <code>approvalsRef</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>StagingRecordRow — full narrative:</strong> <br> Purpose: secure temporary storage record used when atomic persist to Evidence Store is impossible due to storage faults, ACLs, or other transient issues; supports controlled manual promotion and forensic trail. <br> Fields & semantics: <br> 1. <code>stagingRef</code>, <code>payloadPath</code>, <code>computedChecksum</code>, <code>createdTs</code>, <code>createdBy</code>. <br> 2. <code>reason</code> enum (<code>ACL|quota|timeout|serviceOutage|manualHold</code>). <br> 3. <code>promoteStatus</code> (<code>pending|promoted|failed</code>) and <code>promotionAudit[]</code>. <br> 4. <code>stagingRetentionPolicy</code> and <code>expiryTs</code>. <br> Rules: <br> • Staging must be encrypted and access-controlled; manual promotion requires <code>forensic_manifest</code> and <code>approvalsRef</code>; staging artifacts must expire automatically per <code>stagingRetentionPolicy</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>ApplyDescriptorRow (export subset) — full narrative:</strong> <br> Purpose: the immutable descriptor persisted prior to any mutative apply operations (post_direct) to ensure idempotency, reverts, and forensic replay. <br> Fields & semantics: <br> 1. <code>applyId</code> (uuid), <code>applyDescriptorRef</code>. <br> 2. <code>exportArtifactRef</code>, <code>exportManifestRef</code>. <br> 3. <code>beforeChecksums</code> containing <code>assetIngestChecksum</code>,<code>capexIngestChecksum</code>,<code>depreciationRunHash</code>. <br> 4. <code>operatorId</code>, <code>mode</code> (<code>create_export | post_direct</code>), <code>approvalsRef</code> required for regulated ranges. <br> 5. <code>idempotencyToken</code> derived from <code>applyId</code> for GL calls. <br> Rules: <br> • Must be persisted before any mutative API calls; used by reversion logic to compute <code>revertDescriptor</code>. <br> • <code>applyDescriptor</code> content is immutable; corrections require a new <code>applyDescriptor</code> with <code>correctionOf</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Per-field forensic & retention rules (global):</strong> <br> • Preserve <code>rawFieldRef</code> for any transformed or truncated export field unless policy forbids retention of PII. <br> • Every override must include <code>overrideReason</code>,<code>overrideBy</code>,<code>overrideTs</code>,<code>overrideChecksum</code>. <br> • PII handling: tag artifacts with <code>privacyClassification</code>, require <code>approvalsRef</code> for access, and record <code>chainOfCustody</code> on every access. <br> • Never log secret tokens; ephemeral credentials must not be persisted in artifacts or logs. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Canonicalization & hashing recipes — exhaustive export rules</strong> <br> 1. <strong>Text normalization:</strong> apply Unicode NFKC to canonical strings; trim leading/trailing whitespace; collapse sequences of whitespace (tabs, NBSP, multiple spaces, various line separators) to a single U+0020 for canonical tokens. Preserve original raw fields in evidence. Optionally casefold per <code>exportSpec</code> or <code>policySnapshot</code>. Strip or map diacritics only when policy allows; document mapping table in <code>policySnapshot.localeHandling</code>. <br> 2. <strong>Numeric canonicalization:</strong> compute <code>amountMinorUnits = round_half_to_even(amount, roundingScale) × 10^roundingScale</code>; record <code>decimalString</code> zero-padded to <code>roundingScale</code>; negative zero normalized to <code>0.00</code> form; record <code>amountOriginalString</code> in evidence for forensic audit. <br> 3. <strong>Date/time canonicalization:</strong> default <code>YYYY-MM-DD</code> for dates; if time included normalize to UTC with deterministic millisecond rounding; record <code>sourceTimeZone</code> and <code>parseAttempts</code> in <code>issues[]</code>. <br> 4. <strong>Serialization ordering & escaping:</strong> strictly use <code>exportSpec.fieldOrder</code>; use deterministic escaping: always quote fields containing delimiter/quote/newline; escape quotes by doubling; if loader disallows embedded newlines and a field contains them, fail row and add to <code>issues[]</code> unless approved override exists. <br> 5. <strong>Hashing & prefixes:</strong> canonical strings -> UTF-8 -> compute SHA-256; prefix with <code>sha256:</code> in all manifests. <br> 6. <strong>Deterministic tie-breakers:</strong> for residual absorption or candidate selection use tie-breaker sequence: (a) largest absolute <code>preRoundedAmount</code>; (b) lexicographically smallest <code>lineId</code>/<code>assetId</code>; (c) deterministic seed derived from <code>runHash</code>. Document and test tie-breakers exhaustively. <br> 7. <strong>Sampling:</strong> <code>rowsSample[]</code> chosen deterministically by hashing (<code>SHA256(runHash|rowIndex) mod rowsCount</code>) ensuring reproducible samples across replays. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function-level breakdowns — complete contracts (inputs, outputs, responsibilities, invariants, failure modes, observability, CI tests, runbooks)</strong> <br><br> <strong>Function:</strong> <code>GenerateJEExport(acceptedJEs, exportSpecRef, operatorId, options)</code> <br> <strong>Signature / Purpose:</strong> orchestrate full export workflow: validation, mapping, balancing validation and deterministic absorption, payload assembly, deterministic serialization, checksum computation, manifest assembly, and atomic persistence (or staging), emitting final audit events and returning <code>ExportResult</code>. <br> <strong>Inputs:</strong> <br> • <code>acceptedJEs[]</code> canonical JE objects including <code>jeId</code>, <code>jeLines[]</code>, <code>evidenceRefs[]</code>, <code>acceptedBy</code>, <code>acceptedTs</code>. <br> • <code>exportSpecRef</code> evidenceRef pointing to canonical <code>exportSpec</code>. <br> • <code>operatorId</code> string. <br> • <code>options</code> object: <code>{roundingScaleOverride?, validateOnly?, stagingOnFailure?, toleranceAbsoluteMinorUnits?, previewOnly?, previewRowLimit?}</code>. <br> <strong>Outputs:</strong> <br> • <code>ExportResult</code> object: <code>{ok: bool, artifactRef?, manifestRef?, exportChecksum?, perBundleStatus[], errors[], warnings[], stagingRef?}</code> returned synchronously. <br> <strong>Detailed responsibilities — deterministic stepwise flow (each numbered item uses <code>&lt;br&gt;</code> line breaks):</strong> <br> 1. <strong>Resolve and canonicalize <code>exportSpec</code>:</strong> fetch <code>exportSpecRef</code>, compute <code>specHash</code>, verify that <code>specHash</code> is approved by governance when required; record <code>specHash</code> in manifest. <br> 2. <strong>Run <code>ValidateExportSpec</code>:</strong> produce <code>ValidationReport</code>; if <code>ok=false</code> and <code>options.validateOnly=true</code> return the report; if <code>ok=false</code> and not validateOnly fail with <code>fa.je.export.invalid_spec</code> and persist report. <br> 3. <strong>Per-bundle balancing:</strong> for each JE call <code>ValidateBundleBalance(jeBundle, roundingScale)</code> using either <code>exportSpec.numberScale</code> or <code>options.roundingScaleOverride</code>; record <code>unbalancedJeIds</code>. <br> 4. <strong>Tolerance & approvals:</strong> if <code>unbalancedJeIds</code> non-empty evaluate <code>toleranceAbsoluteMinorUnits</code>; if within tolerance and operator provided <code>approvalsRef</code> or policy allows system absorption, apply deterministic residual absorption and record <code>absorptionAction</code> in <code>issues[]</code>; otherwise abort and return <code>fa.je.export.unbalanced</code>. <br> 5. <strong>Build <code>payloadRows</code> via <code>BuildExportPayload</code>:</strong> map all <code>acceptedJEs</code> to <code>payloadRows</code> in exact <code>exportSpec.fieldOrder</code>; capture <code>payloadDiagnostics</code> and <code>mappingMissing[]</code>. <br> 6. <strong>If <code>mappingMissing[]</code> non-empty:</strong> if policy requires mapping, fail and produce mapping artifact for analyst; else apply approved fallback mapping with recorded <code>mappingOverrides</code> noted in manifest. <br> 7. <strong>Assemble preview:</strong> call <code>BuildSerializedPreview(payloadRows, exportSpec, previewRowLimit, redactPII=true)</code> to produce <code>serializedPreview</code> and <code>previewChecksum</code> persisted as evidence. <br> 8. <strong>Serialize final payload:</strong> call <code>SerializePayload(payloadRows, exportSpec)</code> to produce <code>payloadBytes</code> and <code>serializationDiagnostics</code>. <br> 9. <strong>Compute <code>exportChecksum</code>:</strong> <code>ComputeExportChecksum(payloadBytes, canonicalVersion)</code> returns <code>sha256:&lt;hex&gt;</code>. <br> 10. <strong>Build <code>exportManifest</code>:</strong> <code>BuildExportManifest(runId, exportChecksum, exportSpecRef, rowsCount, operatorId, extraMeta)</code> to assemble canonical manifest with deterministic field ordering and compute <code>manifestChecksum</code>. <br> 11. <strong>Persist artifact & manifest atomically:</strong> call <code>PersistExportArtifact(payloadBytes, exportManifest, storageOptions)</code> which must commit both artifact and manifest atomically; if atomic persist impossible and <code>options.stagingOnFailure</code> true then create <code>stagingRef</code> and emit <code>fa.je.export.warning</code>. <br> 12. <strong>Emit audit & return result:</strong> on success emit <code>fa.je.exported{artifactRef,manifestRef,exportChecksum,runId,operatorId,paramsHash}</code> and return <code>ExportResult.ok=true</code> including <code>artifactRef</code> and <code>manifestRef</code>; on failure return structured error diagnostics. <br> <strong>Invariants:</strong> <br> • Given identical <code>acceptedJEs</code>, identical <code>exportSpecRef</code>, identical <code>canonicalVersion</code>, identical <code>policyHash</code> and identical <code>options</code>, the <code>exportChecksum</code> and <code>manifestChecksum</code> must be identical across runs and runtimes (parity). <br> • No mutating downstream apply may occur without persisted <code>exportManifest</code> and <code>artifactRef</code>. <br> <strong>Failure modes & remediation:</strong> <br> • <code>ValidateExportSpec</code> fails: fix <code>exportSpec</code> or transform accepted JEs; re-run and persist <code>correctionOf</code> links. <br> • Unbalanced bundles: accept deterministic absorption within policy tolerances with approvals, or correct JE logic and re-run. <br> • Persist failure: retry limited exponential backoff, then stage and notify operators with <code>stagingRef</code>; manual promotion required. <br> <strong>Observability & telemetry:</strong> <br> • Metrics: <code>je.export.latencyMs</code>, <code>je.export.rowsCount</code>, <code>je.export.unbalancedCount</code>, <code>je.export.failureRate</code>, <code>je.export.stagingCount</code>, <code>export_checksum</code> tag for traces. <br> • Logs: structured logs must include <code>correlationId</code>, <code>runHash</code>, <code>specHash</code>, <code>operatorId</code>, and <code>paramsHash</code>. <br> <strong>CI tests & golden parity:</strong> <br> • Maintain golden fixtures for common <code>exportSpec</code> shapes and dataset sizes; assert <code>exportChecksum</code> and <code>manifestChecksum</code> match across PQ pilot and backend CI. <br> • Unit tests for tie-breaker determinism, rounding, and numeric invariants across locales. <br> <strong>Operator runbook excerpt:</strong> <br> 1. On <code>fa.je.export.invalid_spec</code> download <code>ValidationReport</code>, fix spec or mapping, add <code>approvalsRef</code> if needed, re-run export with <code>correctionOf</code> link. <br> 2. On <code>fa.je.export.unbalanced</code> examine <code>unbalancedJeIds</code> and <code>preRounded</code> amounts, accept deterministic absorption with approvals or fix bundles and re-run. <br> 3. On <code>fa.je.export.warning</code> with <code>stagingRef</code> follow Manual Promotion checklist: verify checksum, obtain approvals, promote artifact to Evidence Store, record <code>correctionOf</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>ValidateExportSpec(exportSpec, acceptedJEs, policySnapshotRef)</code> <br> <strong>Purpose:</strong> assert that the <code>exportSpec</code> is complete and that <code>acceptedJEs</code> can be unambiguously mapped to the loader payload format without loss or ambiguous transformations. <br> <strong>Inputs:</strong> <code>exportSpec</code> (fields[], types[], order[], formattingRules), <code>acceptedJEs[]</code>, optional <code>policySnapshotRef</code>. <br> <strong>Outputs:</strong> <code>ValidationReport {ok, errors[], warnings[], mappingSuggestions[], specHash}</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Verify required fields exist in exact loader order; produce <code>MISSING_COLUMN</code> errors for absent fields. <br> 2. Validate field types and lengths against sample <code>acceptedJEs</code> rows and produce <code>TYPE_MISMATCH</code> or <code>LENGTH_OVERFLOW</code> errors with deterministic sample conversions suggested. <br> 3. Detect ambiguous sign conventions versus <code>exportSpec.signConvention</code> and produce <code>SIGN_CONVENTION_AMBIGUOUS</code> with example conversions. <br> 4. Check date format and numeric scale parity; suggest <code>culture</code> or <code>dateFormat</code> adjustments for ambiguous locales. <br> 5. Consult <code>policySnapshotRef</code> to suggest default mappings for accounts or cost centers when missing; assign confidence scores and attach evidenceRefs. <br> 6. Compute deterministic <code>specHash</code> over canonicalized spec and include in report. <br> <strong>Invariants:</strong> deterministic <code>ValidationReport</code> for identical inputs. <br> <strong>Failure modes & remediation:</strong> <br> • Missing column: update <code>exportSpec</code> or transform payload to include derived column; if a mapping fallback is used record <code>mappingOverride</code> in manifest and require <code>approvalsRef</code> where policy mandates. <br> <strong>Observability & CI tests:</strong> <code>spec.validation.timeMs</code>, schema fuzzing tests across locales, sign permutations. <br> <strong>Runbook:</strong> attach <code>ValidationReport</code> to analyst ticket and record <code>approvalsRef</code> after remediation. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>ValidateBundleBalance(jeBundle, roundingScale, toleranceAbsoluteMinorUnits)</code> <br> <strong>Purpose:</strong> validate each JE bundle balances at the export rounding scale and deterministically correct small imbalances with absorption guided by policy. <br> <strong>Inputs:</strong> <code>jeBundle</code> (jeId, jeLines[] with preRoundedAmounts), <code>roundingScale</code>, <code>toleranceAbsoluteMinorUnits</code> (e.g., 1 for one minor unit). <br> <strong>Outputs:</strong> <code>BundleValidation {balanced, imbalanceMinorUnits, absorptionAction, adjustedLines[], requiresManualOverride}</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Compute <code>amountMinorUnits</code> for each line by rounding preRounded amounts using <code>round_half_to_even</code> at <code>roundingScale</code>. <br> 2. Compute <code>imbalance = sumDebits - sumCredits</code> in minor units. <br> 3. If <code>imbalance == 0</code> set <code>balanced=true</code>. <br> 4. If <code>|imbalance| &lt;= toleranceAbsoluteMinorUnits</code> perform deterministic absorption: pick <code>targetLine</code> by highest absolute <code>preRoundedAmount</code>; tie-break by lexicographically smallest <code>lineId</code>; adjust <code>targetLine</code> by <code>-imbalance</code>; record <code>absorptionAction</code> with <code>rationale</code>, <code>targetLineId</code>, <code>appliedBy=system</code>, <code>appliedTs</code>, and <code>absorptionChecksum</code>. <br> 5. If <code>|imbalance| &gt; tolerance</code> set <code>requiresManualOverride=true</code> and produce <code>unbalancedBundleReport</code> for analyst correction. <br> <strong>Invariants:</strong> deterministic absorption; repeated runs must produce identical adjustments. <br> <strong>Failure modes & remediation:</strong> manual override required for larger imbalances; provide sample preRounded totals and rounding delta. <br> <strong>CI tests:</strong> parity tests for tie-breaker selection, rounding edge cases, and idempotence under reorderings. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BuildExportPayload(acceptedJEs, exportSpec, policySnapshotRef)</code> <br> <strong>Purpose:</strong> deterministically map <code>acceptedJEs</code> into <code>payloadRows</code> that exactly match <code>exportSpec.fieldOrder</code> and types; return mapping diagnostics and missing mapping suggestions. <br> <strong>Inputs:</strong> <code>acceptedJEs[]</code>, canonical <code>exportSpec</code>, optional <code>policySnapshotRef</code>. <br> <strong>Outputs:</strong> <code>{payloadRows[], payloadDiagnostics[], mappingMissing[]}</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. For each <code>jeLine</code> produce an ordered record matching every field in <code>exportSpec.fieldOrder</code>. <br> 2. Apply <code>signConvention</code>: if <code>SignedAmount</code> produce signed amount column, else produce separate debit/credit columns per spec. <br> 3. Numeric canonicalization: compute <code>amountMinorUnits</code> and <code>decimalString</code> zero-padded to <code>exportSpec.numberScale</code>. <br> 4. Date formatting: apply <code>exportSpec.dateFormat</code>, convert to UTC if needed; record <code>sourceTimeZone</code> transformations in diagnostics. <br> 5. Narrative handling: canonicalize and enforce length constraints; when truncation occurs record <code>escapeDiagnostics</code> with <code>overrideReason</code> and persist <code>rawNarrativeRef</code> for forensic replay. <br> 6. Policy lookups: resolve GL account and cost center via <code>policySnapshotRef</code>; when missing record <code>mappingMissing[]</code> with suggested mapping and <code>confidence</code> score. <br> 7. Create <code>lineChecksum</code> for canonical pre-escaped string for each row and attach. <br> <strong>Invariants:</strong> mapping deterministic and reproducible; <code>lineChecksum</code> stable across replays. <br> <strong>Failure modes & remediation:</strong> mapping gaps create mapping artifacts for analyst resolution; truncation must be recorded. <br> <strong>Telemetry & CI tests:</strong> mapping coverage metrics, truncation rate tests, cross-locale numeric conversions. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BuildSerializedPreview(payloadRows, exportSpec, previewRowLimit=50, redactPII=true)</code> <br> <strong>Purpose:</strong> create a compact preview artifact for parity checks and analyst review without exposing raw PII unless specifically approved. <br> <strong>Inputs:</strong> <code>payloadRows[]</code>, <code>exportSpec</code>, <code>previewRowLimit</code>, <code>redactPII</code>. <br> <strong>Outputs:</strong> <code>{serializedPreviewText, previewChecksum, previewRows[]}</code> persisted as evidence. <br> <strong>Responsibilities:</strong> <br> 1. Select <code>previewRows</code> deterministically using either the first N rows or a deterministic sampling algorithm seeded by <code>runHash</code> to ensure reproducibility. <br> 2. Redact PII fields with deterministic tokenization if <code>redactPII==true</code>; record <code>redactionSummary</code> in preview manifest. <br> 3. Serialize preview rows using same <code>SerializePayload</code> rules to ensure parity; compute <code>previewChecksum</code>. <br> <strong>Invariants:</strong> preview selection and serialization deterministic across replays. <br> <strong>Failure modes:</strong> if preview inadvertently contains PII and policy disallows exposure, block and require <code>approvalsRef</code>. <br> <strong>CI tests:</strong> preview checksum parity across PQ and backend runs; PII redaction tests. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>SerializePayload(payloadRows, exportSpec)</code> <br> <strong>Purpose:</strong> deterministically serialize <code>payloadRows</code> to bytes for the loader format per <code>exportSpec</code> with platform-independent escaping and formatting. <br> <strong>Inputs:</strong> <code>payloadRows[]</code>, <code>exportSpec</code> (delimiter, quoteChar, lineEnding, encoding, trailingNewline flag). <br> <strong>Outputs:</strong> <code>{payloadBytes, serializationDiagnostics}</code>. <br> <strong>Responsibilities:</strong> <br> 1. Determine canonical row ordering — default <code>jeId</code> then <code>lineSequence</code> unless explicit <code>exportSpec.orderBy</code> is present. <br> 2. For each field apply NFKC normalization, escape rules, numeric formatting (zero-padded), and date formatting. <br> 3. Use <code>\n</code> default line endings unless <code>exportSpec.lineEnding</code> requires <code>\r\n</code>; avoid trailing whitespace and trailing newline unless requested. <br> 4. Return <code>payloadBytes</code> and <code>serializationDiagnostics</code> for any normalization or failing rows. <br> <strong>Invariants:</strong> identical inputs -> identical bytes across platforms. <br> <strong>Failure modes & remediation:</strong> unencodable characters handled by normalization with recorded diagnostics; irrecoverable rows cause export abort with explicit error report. <br> <strong>CI tests:</strong> cross-OS newline and escaping matrices, multi-byte char handling. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>ComputeExportChecksum(payloadBytes, canonicalVersion)</code> <br> <strong>Purpose:</strong> compute <code>sha256:&lt;hex&gt;</code> over exact bytes and return hash plus canonicalVersion metadata for reproducibility. <br> <strong>Inputs:</strong> <code>payloadBytes</code>, <code>canonicalVersion</code>. <br> <strong>Outputs:</strong> <code>{exportChecksum, canonicalVersion}</code>. <br> <strong>Responsibilities:</strong> compute SHA-256 over bytes and return prefixed <code>sha256:</code> string; record <code>canonicalVersion</code>. <br> <strong>Invariants:</strong> identical bytes -> identical checksum across languages and OS. <br> <strong>Failure modes:</strong> if recomputed checksum differs during parity job, artifact is quarantined and forensic investigation triggered. <br> <strong>CI tests:</strong> cross-runtime checksum parity. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>PersistExportArtifact(payloadBytes, exportManifest, storageOptions)</code> <br> <strong>Purpose:</strong> atomically persist artifact bytes and canonical manifest to Evidence Store with required metadata; return evidence refs or staging ref on fallback. <br> <strong>Inputs:</strong> <code>payloadBytes</code>, canonical <code>exportManifest</code>, <code>storageOptions</code> (pathPattern, encryptionPolicy, retentionPolicy, legalTags). <br> <strong>Outputs:</strong> <code>{artifactRef, manifestRef, persisted:true|false, stagingRef?}</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Attempt atomic write using object store atomic rename or server-side commit; if supported, write object to temp path and call atomic promote; write manifest last referencing artifact path. <br> 2. If atomic rename not supported implement two-phase commit: write temp objects, validate checksum, rename to final names, write manifest; use write lease to reduce race conditions. <br> 3. Attach object metadata: <code>checksum</code>, <code>canonicalVersion</code>, <code>createdTs</code>, <code>operatorId</code>, <code>retentionPolicy</code>, <code>legalTags</code>. <br> 4. On partial failure attempt cleanup; if unsuccessful and <code>stagingOnFailure</code> allowed write <code>stagingRef</code> to secure staging and emit <code>fa.je.export.warning</code>. <br> <strong>Invariants:</strong> reading <code>artifactRef</code> post-persist returns bytes hashing to <code>exportChecksum</code>. <br> <strong>Failure modes & remediation:</strong> ACL/permission errors -> fail and emit <code>fa.je.export.access_error</code>; staging -> manual promotion runbook. <br> <strong>CI tests:</strong> atomicity emulation across different object store implementations, ACL simulation, retention metadata verification. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BuildExportManifest(runId, exportChecksum, exportSpecRef, rowsCount, operatorId, createdTs, extraMeta)</code> <br> <strong>Purpose:</strong> construct canonical <code>export_manifest</code> JSON using fixed field order for deterministic hashing; persist and return <code>manifestRef</code>. <br> <strong>Inputs:</strong> run and artifact metadata plus <code>extraMeta</code> (approvalsRef, issues[], mappingOverrides[]). <br> <strong>Outputs:</strong> <code>{exportManifest, manifestChecksum}</code> persisted evidence. <br> <strong>Responsibilities:</strong> <br> 1. Populate manifest fields: <code>artifactName</code>, <code>artifactRef</code> placeholder, <code>exportChecksum</code>, <code>runId</code>, <code>runHash</code>, <code>policyHash</code>, <code>exportSpecRef</code>, <code>operatorId</code>, <code>createdTs</code>. <br> 2. Include <code>rowsCount</code>, <code>rowsSample[]</code> computed deterministically, <code>issues[]</code>, <code>approvalsRef</code>, <code>paramsHash</code>. <br> 3. Canonicalize JSON using fixed field ordering and compact encoding; compute <code>manifestChecksum</code>. <br> 4. Persist manifest to Evidence Store and link <code>manifestRef</code> in object metadata of artifact. <br> <strong>Invariants:</strong> manifest canonicalization stable and reproducible; <code>manifestChecksum</code> must match persisted bytes. <br> <strong>CI tests:</strong> manifest canonicalization parity fixtures; sample selection reproducibility tests. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>FormatExportErrorReport(reportItems, serializedPreview, exportSpecRef)</code> <br> <strong>Purpose:</strong> produce deterministic, operator-friendly diagnostic reports persisted to Evidence Store and used in ticketing. <br> <strong>Inputs:</strong> <code>reportItems[]</code> (errors/warnings), <code>serializedPreview</code>, <code>exportSpecRef</code>. <br> <strong>Outputs:</strong> <code>errorReportRef</code> evidenceRef and <code>shortSummary</code> for UI. <br> <strong>Responsibilities:</strong> <br> 1. Group similar errors, attach sample rows for each error, provide deterministic suggested fixes, and reference relevant evidenceRefs. <br> 2. Persist report and attach to issue tracking system with <code>correlationId</code>. <br> <strong>Runbook:</strong> auto-open critical tickets on fatal errors with <code>errorReportRef</code> attached; include <code>correlationId</code> and <code>runId</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>PromoteStagingArtifact(stagingRef, targetPath, operatorId, approvalsRef)</code> <br> <strong>Purpose:</strong> securely promote a staged artifact to Evidence Store after operator verification, compliance sign-off, and checksum verification. <br> <strong>Inputs:</strong> <code>stagingRef</code>, <code>targetPath</code>, <code>operatorId</code>, <code>approvalsRef</code>. <br> <strong>Outputs:</strong> <code>{artifactRef, promotionAuditRef, promoted:true|false}</code>. <br> <strong>Responsibilities:</strong> <br> 1. Recompute checksum of staged bytes and compare to <code>stagingRef.computedChecksum</code>. <br> 2. Verify <code>approvalsRef</code> for PII or policy gated artifacts. <br> 3. Move artifact atomically to final Evidence Store path or upload and validate checksum if atomic move not possible; create <code>forensic_manifest</code> capturing promotion metadata and attach <code>promotionAuditRef</code>. <br> 4. Emit <code>fa.je.export.manual_promotion</code>. <br> <strong>Invariants:</strong> promoted artifact bytes must match recomputed checksum. <br> <strong>Failure modes:</strong> mismatch -> abort and escalate forensic investigation. <br> <strong>Runbook:</strong> manual promotion checklist defined in Appendix C. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Function:</strong> <code>BuildExportManifestForCorrection(originalManifestRef, correctedPayloadBytes, operatorId, reason)</code> <br> <strong>Purpose:</strong> when re-exporting to correct errors, build new manifest that references <code>correctionOf</code> the original manifest and preserves chain-of-custody. <br> <strong>Inputs:</strong> <code>originalManifestRef</code>, <code>correctedPayloadBytes</code>, <code>operatorId</code>, <code>reason</code>. <br> <strong>Outputs:</strong> <code>correctedManifestRef</code>, <code>correctedArtifactRef</code>, <code>correctionOf</code> link persisted. <br> <strong>Responsibilities:</strong> <br> 1. Compute corrected <code>exportChecksum</code> and build canonical manifest with <code>correctionOf</code> original manifestRef. <br> 2. Persist artifact & manifest atomically; emit <code>fa.je.export.corrected</code>. <br> 3. Ensure <code>correctionOf</code> is discoverable in audit and reconciliation UI. <br> <strong>Invariants:</strong> corrections preserve original evidence and reasoning; revertable with <code>revertDescriptor</code> if apply occurred. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Cross-function governance, security & operational controls (global)</strong> <br> 1. <strong>Approval gating:</strong> exports exceeding configured thresholds (total value, region risk, presence of PII) require <code>approvalsRef</code> in manifest; <code>GenerateJEExport</code> must validate presence and fail otherwise. <br> 2. <strong>Idempotency & naming:</strong> artifact names include <code>exportChecksum</code> to ensure idempotent naming; downstream <code>applyDescriptor</code> contains <code>idempotencyToken</code> and <code>beforeChecksums</code> to avoid duplicate postings. <br> 3. <strong>Atomicity:</strong> artifact and manifest must be atomic; where atomic writes unsupported implement two-phase commit and <code>stagingRef</code>. <br> 4. <strong>PII & access:</strong> PII-containing artifacts are labelled and retrieval requires <code>approvalsRef</code> and emits <code>chainOfCustody</code>. <br> 5. <strong>Secrets & ephemeral tokens:</strong> ephemeral tokens used for GL posting only; tokens must not be persisted in logs or manifests; token issuance and usage are audited. <br> 6. <strong>Telemetry & SLOs:</strong> sample SLOs: <code>ExportLatencyP50</code> < 2s for <=500 rows; <code>PersistSuccessRate</code> > 99.5%; <code>GoldenParityFailureRate</code> = 0 in protected branches. <br> 7. <strong>Golden parity & migration governance:</strong> semantic changes to canonicalization or <code>exportSpec</code> require a <code>migrationManifest</code>, canary runs, and approvals; failing golden diffs block protected merges. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Exhaustive worked examples — expanded narratives, edge cases, and forensic trails</strong> <br><br> <strong>Example 1 — Standard successful export (detailed forensic trace):</strong> <br> 1. Analysts accept 120 JE bundles (540 payload lines) for <code>runId=RUN-2026-07-10-01</code>. <br> 2. <code>GenerateJEExport</code> invoked with <code>exportSpecRef=ERP_JE_v1_ref</code>, <code>operatorId=alice</code>. <br> 3. <code>ValidateExportSpec</code> returns <code>ok=true</code> and <code>specHash</code> recorded. <br> 4. <code>ValidateBundleBalance</code> executes — all bundles balanced at roundingScale=2. <br> 5. <code>BuildExportPayload</code> maps 540 rows producing <code>lineChecksum</code> for each line and <code>payloadDiagnostics</code> empty. <br> 6. <code>BuildSerializedPreview</code> selects deterministic sample of 50 rows seeded by <code>runHash</code>; redacts PII; stores <code>previewChecksum</code>. <br> 7. <code>SerializePayload</code> produces 42KB bytes; <code>ComputeExportChecksum</code> yields <code>sha256:abcd...</code>. <br> 8. <code>BuildExportManifest</code> includes <code>rowsSample</code>, <code>previewChecksum</code>, <code>paramsHash</code>; computes <code>manifestChecksum</code>. <br> 9. <code>PersistExportArtifact</code> writes artifact and manifest atomically; system emits <code>fa.je.exported{artifactRef,manifestRef}</code>. <br> 10. Downstream <code>ApplyCorrections</code> uses the persisted artifact and <code>applyDescriptor</code> to create <code>idempotencyToken</code> prior to posting. <br> Forensics: auditors can verify <code>serializedPreview</code> and recompute <code>exportChecksum</code> locally to validate artifact integrity; mapping decisions visible via <code>lineChecksum</code> → evidenceRefs linking back to source schedules. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Example 2 — Missing required <code>CostCenter</code> column and operator fallback (detailed):</strong> <br> 1. <code>ValidateExportSpec</code> fails with <code>MISSING_COLUMN: CostCenter</code>. <br> 2. <code>ValidationReport</code> contains <code>mappingSuggestion</code> that <code>costCenter</code> can be derived from <code>scheduleRow.costCenter</code> or replaced with <code>&#x27;UNALLOCATED&#x27;</code> fallback. <br> 3. Operator accepts fallback and records <code>approvalsRef</code> because fallback changes posting detail; the decision is stored in <code>exportManifest.mappingOverrides</code> with <code>overrideChecksum</code> referencing the sample mapping evidence. <br> 4. <code>BuildExportPayload</code> applies mappingOverride, <code>lineChecksum</code> records transformation, and export proceeds. <br> Governance: frequency of such overrides is monitored; repeated overrides for same category require policy update and a <code>migrationManifest</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Example 3 — Rounding pathology and group residual absorption (detailed):</strong> <br> 1. Thousands of small amounts produce per-bundle rounding residues aggregating to a non-trivial group residual for a cost center. <br> 2. Policy specifies batch absorption per <code>absorptionGroupKey = costCenter|currency|period</code>. <br> 3. <code>GenerateJEExport</code> groups payload rows by <code>absorptionGroupKey</code>, computes <code>groupResidual = canonicalTotal - sumRoundedPeriods</code>. <br> 4. For each group perform deterministic absorption selecting the <code>targetLine</code> with highest absolute <code>preRoundedAmount</code>, tie-break lexicographically by <code>lineChecksum</code>; record <code>absorptionSummary</code> with <code>absorbedAmount</code> and <code>targetLineId</code>. <br> 5. Attach <code>absorptionSummary</code> to manifest for auditor review. <br> Forensics: material absorption rules and preRounded values provide an audit trail proving deterministic and non-arbitrary adjustments. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Example 4 — Persist failure due to ACL and manual promotion (detailed):</strong> <br> 1. <code>GenerateJEExport</code> completes serialization and computes checksum but final write to the Evidence Store fails with ACL error. <br> 2. Module retries thrice and then writes artifact to secure local staging and issues <code>stagingRef</code>. <br> 3. Emit <code>fa.je.export.warning{stagingRef}</code> and alert infra & compliance. <br> 4. Operator runs <code>PromoteStagingArtifact</code>, recomputes checksum locally, gathers compliance approvals <code>approvalsRef</code>, and then moves artifact to Evidence Store using an atomic server operation (or re-upload and verify checksum). <br> 5. Persist final manifest linking <code>correctionOf</code> to staging attempt and emit <code>fa.je.export.manual_promotion</code>. <br> Forensics: <code>forensic_manifest</code> captures staging, computed checksum, promotion audit history, and <code>approvalsRef</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Example 5 — Export exceeding approval threshold (detailed):</strong> <br> 1. Policy requires two approvers for exports where <code>sum(abs(amount))</code> > $1,000,000. <br> 2. <code>GenerateJEExport</code> runs, computes <code>totalAmount</code> > threshold, and writes a draft <code>export_manifest</code> with status <code>draft</code> and <code>approvalsRef</code> placeholder; emits <code>fa.je.export.requires_approvals</code>. <br> 3. Governance UI collects two approvers; upon capture <code>approvalsRef</code> persisted. <br> 4. <code>GenerateJEExport</code> finalizes artifact and manifest with <code>approvalsRef</code>; <code>ApplyCorrections</code> allowed only when an <code>applyDescriptor</code> persists that references <code>approvalsRef</code>. <br> Audit: approvals recorded with <code>approverId</code>,<code>approvalTs</code>,<code>signatureHash</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Example 6 — Cross-currency asset with FX normalization (detailed):</strong> <br> 1. Asset schedule in EUR attached to export spec expecting USD posting. <br> 2. Policy mandates FX normalization using canonical FX rate table snapshot <code>fxSnapshotRef</code> included in <code>policySnapshot</code>. <br> 3. <code>BuildExportPayload</code> converts amounts using <code>fxRate</code> and records <code>fxRateRef</code> and <code>fxUsed</code> in <code>lineDiagnostics</code>. <br> 4. <code>BuildExportManifest</code> includes <code>fxSnapshotRef</code> and <code>fxRatesApplied[]</code> for audit. <br> 5. Parity tests validate FX conversion deterministically. <br> Forensics: <code>fxSnapshotRef</code> plus <code>amountMinorUnits</code> original and converted ensure full traceability of FX calculations. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Power Query (PQ) — conceptual guidance for pilots (no code)</strong> <br> <strong>When to use PQ:</strong> PQ is appropriate for rapid prototypes, analyst previews, mapping experiments, and small fleet exports typically under a few thousand rows. PQ should be used during design and early validation but not for enterprise production exports that require high precision, parallelism, and strong parity guarantees. <br> <strong>PQ architectural pattern (conceptual):</strong> <br> 1. Parameterize <code>ExportSpec_Params</code> and <code>PolicyMapping_Staging</code> as named queries to enable analysts to iterate on column order, delimiter, dateFormat, numberScale, signConvention. <br> 2. Create <code>AcceptedJEs_Staging</code> as table input to PQ (Excel sheet or dataflow) with <code>jeId</code>, <code>jeLineId</code>, <code>amount</code>, <code>currency</code>, <code>accountHint</code>, <code>costCenterHint</code>, <code>narrative</code>. <br> 3. Implement <code>fn_MapToExportColumns</code> as a buffered function that performs policy mapping joins and deterministic text normalization; avoid iterative per-row invokes where possible to reduce compute overhead. <br> 4. Compute <code>serializedPreview</code> using <code>Text.Combine</code> of canonical fields and use a host hashing helper (Power Automate or external service) to compute <code>previewHash</code> because PQ lacks robust hashing primitives. <br> <strong>Canonicalization in PQ (conceptual):</strong> <br> 1. Text: use <code>Text.Trim</code>, replace exotic whitespace, use an explicit diacritic mapping table for deterministic mapping when platform lacks built-in normalization; use <code>Text.Lower</code> only per policy. <br> 2. Numbers: pre-replace thousand separators, unify decimal separator to <code>.</code>, then parse with explicit culture; compute <code>amountMinorUnits</code> by rounding and integer multiplication. <br> 3. Dates: parse with explicit culture and preserve <code>rawDateString</code> when parse fails; flag parse attempts in an <code>issues</code> column. <br> <strong>PQ limitations & mitigations:</strong> <br> 1. PQ decimal precision may be insufficient for preRounded high precision; represent intermediate preRounded values as strings and validate using the backend. <br> 2. PQ per-row custom functions are slow — vectorize transforms using table operations. <br> 3. PQ cannot perform atomic evidence persistence or zip packaging reliably — use host automation to assemble final preview artifacts and persist to evidence store. <br> <strong>PQ parity testing:</strong> maintain PQ golden fixtures that include <code>previewHash</code> expected values and run PQ pilot tasks to compare <code>previewHash</code> with backend <code>previewHash</code>; any mismatch must be investigated and a migration manifest considered for canonicalization changes. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX — measures, reporting patterns, and operational UX for exports (no code)</strong> <br> <strong>Modeling guidance:</strong> <br> 1. Model <code>ExportManifest</code>, <code>ExportArtifact</code>, <code>ExportEvent</code>, <code>ValidationReport</code>, <code>ParityJob</code>, and <code>ApplyDescriptor</code> as tables; join on <code>runId</code>, <code>manifestChecksum</code>, <code>artifactRef</code>. <br> 2. Keep <code>issues[]</code> and <code>mappingSuggestions[]</code> denormalized into separate tables for filtering and drillthrough. <br> <strong>Core measures (descriptive):</strong> <br> 1. <code>ExportsCount</code> — count of <code>ExportManifest</code> rows. <br> 2. <code>ExportedRowsSum</code> — sum of <code>ExportArtifact.rowsCount</code>. <br> 3. <code>ExportLatencyMedianMs</code> — median of <code>ExportEvent.durationMs</code>. <br> 4. <code>ExportFailureRate</code> — ratio of manifests with status <code>failed</code> to total manifests. <br> 5. <code>GoldenParityFailures</code> — count of <code>ParityJob</code> rows with <code>parity=&#x27;failed&#x27;</code>. <br> 6. <code>AverageUnbalancedBundles</code> — average <code>unbalancedCount</code> in manifests. <br> <strong>Advanced operational ratios:</strong> <br> 1. <code>SuggestionAcceptanceRate</code> — accepted JEs / suggested JEs. <br> 2. <code>ManualPromotionRate</code> — manual promotions / total exports. <br> 3. <code>MappingCoveragePct</code> — 1 - (mappingMissingRows / totalPayloadRows). <br> <strong>Operational visuals & drillthroughs:</strong> <br> 1. Time series of <code>ExportLatencyMedianMs</code> annotated by <code>policyHash</code> change events. <br> 2. Matrix <code>operatorId × status</code> with counts and average <code>rowsCount</code> with drillthrough to <code>export_manifest</code> and <code>serializedPreview</code>. <br> 3. Exception table for manifests where <code>unbalancedCount&gt;0</code> or <code>issues[]</code> non-empty with quick actions: open mapping ticket, trigger re-export, or initiate manual promotion. <br> <strong>Materiality & parameterization:</strong> expose slicers for <code>toleranceAbsoluteMinorUnits</code>, <code>policyHash</code>, and <code>previewSampleSize</code>; measures must use slicer values deterministically to ensure reproducible investigation filters. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Testing strategy & exhaustive CI / golden parity matrix (export-focused)</strong> <br> <strong>Unit tests (must include):</strong> <br> 1. Text canonicalizer tests across locales for whitespace collapse, diacritics mapping, punctuation mapping. <br> 2. Numeric canonicalization tests for rounding modes (<code>round_half_to_even</code>) and amountMinorUnits correctness including negative values. <br> 3. <code>ValidateBundleBalance</code> absorption tie-breaker tests, idempotence under reorderings, and tolerance boundary tests. <br> 4. <code>SerializePayload</code> escaping matrix tests for fields containing delimiter, quotes, and newlines across many edge cases. <br> <strong>Integration tests (must include):</strong> <br> 1. End-to-end ingest→compute→preview→accept→export tests using canonical fixtures; assert <code>exportChecksum</code> and <code>manifestChecksum</code>. <br> 2. ACL and object store failure simulations to test staging and manual promotion workflows. <br> <strong>Golden parity tests:</strong> <br> 1. Maintain canonical fixtures for each <code>exportSpec</code> variant (small/medium/large). <br> 2. CI runs across PQ pilot, local developer, and backend cluster to assert <code>exportChecksum</code>/<code>manifestChecksum</code> parity; any divergence blocks merges and requires <code>migrationManifest</code> if intended. <br> <strong>Property tests:</strong> <br> 1. Reproducibility: identical inputs produce identical checksums. <br> 2. Order invariance tests where appropriate (or explicit documentation when ordering matters). <br> <strong>Performance & load tests:</strong> <br> 1. Serialization throughput benchmarks at 1k/10k/100k row sizes. <br> 2. Persist throughput and chunking tests for artifacts >100MB including streaming hash verification. <br> <strong>Security tests:</strong> <br> 1. PII leakage scanning in preview and artifacts. <br> 2. Ensure compliance metadata present and enforced. <br> <strong>Release gating:</strong> <br> 1. Golden parity failures block protected branches. <br> 2. Any canonicalization or <code>exportSpec</code> semantics change requires a <code>migrationManifest</code> and canary results with approvals before production promotion. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Observability, auditing, SLOs & incident run-books (export path — comprehensive)</strong> <br> <strong>Mandatory audit events:</strong> <br> 1. <code>fa.je.preview.generated</code> — preview artifact created with <code>previewHash</code>. <br> 2. <code>fa.je.exported</code> — successful export artifact & manifest persisted with <code>artifactRef</code> and <code>manifestRef</code>. <br> 3. <code>fa.je.export.invalid_spec</code> — validation failure with <code>ValidationReportRef</code>. <br> 4. <code>fa.je.export.unbalanced</code> — unbalanced bundles detected with <code>unbalancedJeIds</code>. <br> 5. <code>fa.je.export.warning</code> — staging due to persist failure with <code>stagingRef</code>. <br> 6. <code>fa.je.export.manual_promotion</code> — manual promotion audit. <br> 7. <code>fa.je.export.requires_approvals</code> — manifest requires approvals. <br> Each audit row includes <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code>, <code>exportChecksum</code>, <code>operatorId</code>, and <code>paramsHash</code>. <br> <strong>Evidence store conventions:</strong> append-only, immutable objects with metadata <code>checksum</code>, <code>canonicalVersion</code>, <code>retentionPolicy</code>, <code>legalTags</code>. Access to PII artifacts requires <code>approvalsRef</code> and records <code>chainOfCustody</code> entries detailing <code>requestorId</code>, <code>approvalsRef</code>, <code>actionTs</code>. <br> <strong>SLO examples:</strong> <br> 1. <code>ExportLatencyP50</code> < 2s for ≤ 500 rows. <br> 2. <code>ExportPersistP95</code> < 4s for small artifacts (<100KB). <br> 3. <code>PersistSuccessRate</code> > 99.5%. <br> 4. <code>GoldenParityFailureRate</code> = 0 in protected branches. <br> <strong>Parity verification job:</strong> scheduled daily job recomputes <code>exportChecksum</code> and <code>manifestChecksum</code> for persisted artifacts and compares to stored values; mismatches emit <code>verify.parity.failed</code> and quarantine artifact pending forensic review. <br> <strong>Incident triage runbook (export):</strong> <br> 1. Capture <code>correlationId</code>, <code>runId</code>, and immediate audit events. <br> 2. Retrieve <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policySnapshot</code>, <code>export_manifest</code>, and <code>serializedPreview</code> via evidenceRefs. <br> 3. Recompute serialization locally using canonical <code>exportSpecRef</code> and <code>canonicalVersion</code>; compare <code>exportChecksum</code>. <br> 4. If mismatch: quarantine artifact, notify infra & compliance, run forensic investigation, and re-run <code>GenerateJEExport</code> to produce replacement artifact with <code>correctionOf</code> link. <br> 5. If validation errors: correct spec or mapping, record <code>approvalsRef</code>, re-run and persist <code>correctionOf</code>. <br> 6. Document all steps as audit rows including <code>investigatorId</code> and actions taken. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Failure modes, remediation & operator runbooks (exhaustive)</strong> <br> <strong>A — Invalid export spec (<code>fa.je.export.invalid_spec</code>)</strong> <br> 1. Symptom: <code>ValidationReport.errors[]</code> non-empty. <br> 2. Triage: download <code>ValidationReport</code>, review sample rows and <code>mappingSuggestions</code>. <br> 3. Remediation: update <code>exportSpec</code> or apply mappingOverride; if override is low risk apply and record <code>approvalsRef</code>, else raise mapping ticket and re-run export. <br> <strong>B — Unbalanced bundles (<code>fa.je.export.unbalanced</code>)</strong> <br> 1. Symptom: <code>unbalancedJeIds</code> list non-empty. <br> 2. Triage: fetch offending bundles and <code>preRounded</code> amounts; inspect roundingScale and tolerance. <br> 3. Remediation: accept deterministic absorption (within tolerance) and record <code>approvalsRef</code> or correct underlying <code>acceptedJEs</code> and re-run. <br> <strong>C — Persist failure / staging (<code>fa.je.export.warning</code>)</strong> <br> 1. Symptom: stagingRef persisted due to storage write failure. <br> 2. Triage: verify staged <code>computedChecksum</code>, check bucket ACLs and infra health. <br> 3. Remediation: manual promotion with compliance sign-off, or re-run export after infra fix; record <code>correctionOf</code>. <br> <strong>D — Golden parity failure after merge</strong> <br> 1. Symptom: CI golden tests fail for export fixtures. <br> 2. Triage: inspect canonicalization changes in diffs; if change intended create <code>migrationManifest</code>, run canary, and secure approvals; if unintended revert commit. <br> 3. Remediation: follow migration manifest process or revert and close incident. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Migration manifest & exportSpec governance (detailed process)</strong> <br> <strong>When <code>exportSpec</code> or canonicalization semantics change:</strong> <br> 1. Draft <code>migrationManifest</code> containing <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedSpecRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> with expected <code>exportChecksum</code>, <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (cohort IDs and sizes), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> 2. Execute canary: run export on canary cohorts; compute <code>exportChecksum</code> and <code>previewHash</code> and compare with expected golden fixtures; monitor KPIs such as <code>ExportChecksumDeltaPct</code>, <code>ApplyFailureRate</code>, <code>SuggestionAcceptanceRate</code> over at least two cycles. <br> 3. If KPIs within thresholds and approvals captured, persist new <code>exportSpec</code> as canonical snapshot and promote via <code>fa.policy.migration.completed</code>; otherwise rollback and record findings. <br> 4. For regulated GL ranges require compliance signoff in <code>approvals[]</code> and schedule controlled rollout with additional monitoring. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Artifact naming, checksums & storage conventions — explicit rules</strong> <br> 1. Export artifact naming: <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>. <br> 2. Export manifest naming: <code>export_manifest_&lt;runId&gt;_&lt;manifestChecksum&gt;.json</code>. <br> 3. Preview artifact naming: <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> containing <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, and <code>preview_manifest.json</code>. <br> 4. Staging naming: <code>fa_export_staging_&lt;runId&gt;_&lt;stagingRef&gt;.tmp</code> with TTL and clearly visible <code>stagingRetentionPolicy</code>. <br> 5. Hashing policy: <code>sha256</code> over canonical bytes; manifest must include <code>checksumAlgorithm</code> and <code>canonicalVersion</code>. <br> 6. Object metadata: persist <code>createdTs</code>, <code>operatorId</code>, <code>retentionPolicy</code>, <code>legalTags</code>, <code>privacyClassification</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Performance, scale & architectural guidance (expanded)</strong> <br> 1. PQ pilot for small cohorts and interactive work up to a few thousand rows; backend compute for production use beyond that. <br> 2. Parallelization model: shard <code>payloadRows</code> deterministically by <code>shardKey</code> (e.g., <code>modHash(jeId) % N</code>) and process shards in parallel; final output must reassemble shards using deterministic global ordering (<code>jeId</code> then <code>lineSequence</code>). <br> 3. Streaming & chunk hashing: for artifacts >100MB implement chunked uploads with incremental SHA-256 or tree hashing and record per-chunk checksums in manifest to allow partial replay and verification. <br> 4. Atomic persist: prefer storage with server-side atomic rename; if unavailable implement two-phase commit emulation with staging and promotion. <br> 5. Caching: cache policy lookups keyed by <code>policyHash</code> in worker processes to ensure parity across parallel workers and reduce latency. <br> 6. Autoscaling & scheduling: scale worker pool by queue depth and scheduled close windows; prewarm caches and policy snapshots before close windows. <br> 7. Monitoring & alerts: set alerts for <code>je.export.latency</code>, <code>persistFailureRate</code>, <code>manualPromotionRate</code>, and <code>GoldenParityFailureRate</code>. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Operator CLI patterns & recommended commands (descriptive)</strong> <br> 1. <code>fa.generate-je --previewRef &lt;previewRef&gt; --exportSpecRef &lt;specRef&gt; --operator alice</code> → validate mapping and produce <code>serializedPreview</code> and <code>ValidationReport</code> if issues found. <br> 2. <code>fa.export.run --runId &lt;runId&gt; --exportSpecRef &lt;specRef&gt; --operator alice</code> → perform full export, persist artifact & manifest or provide <code>stagingRef</code> on fallback. <br> 3. <code>fa.export.promote --stagingRef &lt;stagingRef&gt; --operator alice --approvalsRef &lt;ap-123&gt;</code> → promote staged artifact to Evidence Store via <code>PromoteStagingArtifact</code>. <br> 4. <code>fa.export.verify --manifestRef &lt;manifestRef&gt;</code> → recompute checksum and report parity boolean. <br> 5. <code>fa.export.replay --manifestRef &lt;manifestRef&gt; --operator alice</code> → non-mutative local replay of serialization for parity debugging and diagnostics. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Acceptance criteria & release gating — strict checklist</strong> <br> 1. Unit tests confirm deterministic canonicalization, rounding/residual absorption behavior, method math parity across locales. <br> 2. Integration tests validate ingest→compute→preview→accept→export flows with canonical fixtures and expected <code>exportChecksum</code>/<code>manifestChecksum</code>. <br> 3. Golden parity tests for each <code>exportSpec</code> shape assert exact checksums across PQ pilot and backend; failing golden diffs block merges. <br> 4. Any semantic change to canonicalization or <code>exportSpec</code> must be accompanied by <code>migrationManifest</code> and canary validation with recorded approvals before production promotion. <br> 5. Two-person approval enforced for direct posting to regulated GL ranges; ephemeral token issuance enforced. <br> 6. Evidence and retention policies enforced for all artifacts and manifests. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Appendices — templates, checklists, and runbook artifacts (conceptual)</strong> <br> <strong>Appendix A — <code>export_manifest</code> canonical fields template:</strong> <br> <code>manifestId</code>, <code>artifactName</code>, <code>artifactRef</code>, <code>exportChecksum</code>, <code>manifestChecksum</code>, <code>runId</code>, <code>runHash</code>, <code>policyHash</code>, <code>exportSpecRef</code>, <code>rowsCount</code>, <code>payloadRowsCount</code>, <code>rowsSample[]</code>, <code>operatorId</code>, <code>createdTs</code>, <code>canonicalVersion</code>, <code>paramsHash</code>, <code>approvalsRef</code>, <code>issues[]</code>, <code>mappingOverrides[]</code>, <code>correctionOf</code>, <code>retentionPolicy</code>, <code>legalTags</code>. <br> <strong>Appendix B — export verification checklist:</strong> <br> 1. Recompute <code>exportChecksum</code> from retrieved artifact to confirm parity. <br> 2. Verify <code>exportSpecRef</code> matches approved loader spec. <br> 3. Confirm <code>approvalsRef</code> present if policy thresholds exceeded. <br> 4. Confirm <code>manifestChecksum</code> equals computed manifest hash. <br> <strong>Appendix C — manual artifact promotion checklist (detailed):</strong> <br> 1. Retrieve <code>stagingRef</code> artifact and recompute <code>sha256</code> locally. <br> 2. Create <code>forensic_manifest</code> with <code>stagingRef</code>, computedChecksum, <code>operatorId</code>, <code>reason</code> for staging. <br> 3. Obtain compliance sign-off and persist <code>approvalsRef</code>. <br> 4. Promote artifact to Evidence Store via atomic move or server API; verify final artifact <code>sha256</code> equals computedChecksum. <br> 5. Persist the new <code>export_manifest</code> with <code>correctionOf</code> pointing to original staging attempt; emit <code>fa.je.export.manual_promotion</code>. <br> <strong>Appendix D — emergency parity triage checklist:</strong> <br> 1. Record <code>correlationId</code> and <code>runId</code> immediately. <br> 2. Retrieve <code>serializedPreview</code>, <code>export_manifest</code>, <code>ValidationReport</code>, <code>stagingRef</code> if present. <br> 3. Recompute canonical serialization and <code>exportChecksum</code> locally; compare with persisted value. <br> 4. If mismatch: quarantine artifact, open infra & compliance tickets, re-generate export and persist replacement artifact with <code>correctionOf</code>. <br> 5. If canonicalization has changed unexpectedly, create <code>migrationManifest</code> and run canary cohort. </td></tr><tr><td data-label="modExport — Per-function Expert Technical Breakdown"> <strong>Closing operational note (concise):</strong> This ultra-comprehensive <code>modExport</code> specification contains exhaustive per-row narratives, complete function-level contracts and deterministic recipes (inputs, outputs, responsibilities, invariants, failure modes, observability, CI tests, and runbook actions), extended worked examples including edge cases and forensic steps, conceptual Power Query pilot guidance, and conceptual DAX reporting and alerting patterns — all designed to ensure reproducible exports, forensic replayability, and strong governance. Follow canonicalization and <code>canonicalVersion</code> strictly to achieve golden parity across environments. <br> If you want one or more follow-up artifacts produced next, choose from: <br> 1. Formal JSON Schema for <code>export_manifest</code>, <code>ExportLineRow</code>, and <code>ExportArtifactRow</code> with exact canonical field ordering for hashing. <br> 2. A set of canonical CSV test fixtures and expected <code>sha256</code> checksums for golden CI (small, medium, large datasets). <br> 3. A step-by-step Power Query canonicalization recipe with expected intermediate outputs for PQ pilots. <br> 4. A compact operations runbook PDF summarizing triage steps, CLI examples, and emergency procedures. <br> Specify the artifacts you want and the target environment (object store type, loader format, region policy), and they will be produced following the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 40</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>