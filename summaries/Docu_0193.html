<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1769960840">
<link rel="stylesheet" href="assets/overrides.css?v=1771304662">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0193_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modSignOff — Per-function technical breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modSignOff — Per-function technical breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Module Overview (modSignOff)</strong> — <strong>Purpose & scope:</strong> Centralized VBA module responsible for managing the audit-grade sign-off lifecycle for sampled payroll reconciliation items and related deliverables. Responsibilities include enforcing approval policies, recording immutable sign-off entries, validating two-person and role-based rules, attaching approval evidence, integrating with OperationalAudit, updating Tasks/Population computed fields, producing sign-off snapshots for controls, supporting revocations and overrides (with strict audit), and exposing programmatic interfaces for other modules (modControls.AttemptClose, AuditExport, modEvidence, modAudit). The module must be non-destructive, append-only for primary sign-off artefacts, cryptographically-aware (hashes stored for attachments), and fully reproducible (seeded IDs, timestamps in UTC ISO). The module exposes well-documented public procedures (no UI responsibilities except lightweight notifications) and internal helper routines. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: RecordSignOff(taskID As String, signerID As String, signedRole As String, approvalRef As String, evidencePointers As Variant, signoffTimeUtc As String, operatorID As String) As Variant</strong> — <strong>Purpose & contract:</strong> Create a validated, append-only sign-off entry for <code>taskID</code> (or <code>sampleID</code>) while enforcing policy constraints. Returns a structured result object/dictionary containing <code>SignOffID</code>, <code>Status</code> ("Recorded"/"Pending"/"Rejected"), <code>TimestampUTC</code>, <code>Notes</code> and optional <code>ErrorCode</code>.<br><strong>Inputs:</strong> <code>taskID</code> — canonical Payment/Task identifier.<br><code>signerID</code> — ID of person signing.<br><code>signedRole</code> — role claimed for sign-off (e.g., "PayrollManager", "ApproverLevel1", "InternalAudit").<br><code>approvalRef</code> — optional free-text or structured approval reference (e.g., reference to an HR approval ticket or electronic signature token).<br><code>evidencePointers</code> — variant array/list of evidence pointers (EvidenceIndex IDs or file paths).<br><code>signoffTimeUtc</code> — ISO8601 timestamp string (if empty, module will use NowUTC()).<br><code>operatorID</code> — actor invoking the operation (could be same as signer or system process).<br><strong>Outputs:</strong> Writes immutable row to <code>SignOffEntries</code> sheet and <code>SignOffJournal</code> table. Returns dictionary including <code>SignOffID</code>, <code>WriteRow</code>, <code>Status</code> and <code>Hash</code> of entry. Also appends an <code>AppendAudit</code> event via modAudit. <br><strong>Invariants:</strong> Each SignOff entry must contain: <code>SignOffID</code> (GUID), <code>TaskID</code>, <code>SignerID</code>, <code>SignedRole</code>, <code>ApprovalRef</code>, <code>EvidencePointers</code> (comma-separated canonical pointers), <code>TimestampUTC</code>, <code>OperatorID</code>, <code>SignOffHash</code> (SHA256 of canonical serialization), <code>Status</code>, <code>Revoked</code> flag (default False), <code>LinkedEventID</code> (Optional).<br><strong>Validation steps performed (strict order):</strong><br>1. Validate existence of <code>taskID</code> in <code>Population</code>/<code>TasksMaster</code> and ensure <code>TaskStatus</code> allows sign-off (not archived or closed).<br>2. Resolve <code>signerID</code> to known user record (via <code>UserDirectory</code> or <code>SystemConfig</code>) and confirm <code>signedRole</code> is assigned to <code>signerID</code>.<br>3. Invoke <code>ValidateSignOffPolicy</code> to check role-level rules, two-person requirements, and required evidence types.<br>4. Verify evidence pointers exist and checksums (if external files) match recorded values; unverified evidence causes <code>Pending</code> status.<br>5. If passes, compute canonical serialization and SHA256 and append to <code>SignOffEntries</code> in append-only fashion (using next available row).<br>6. Append <code>OperationalAudit</code> event recording the sign-off creation using modAudit.AppendAudit. <br><strong>Failure modes & recovery:</strong><br>1. <code>taskID</code> missing -> return <code>ErrorCode=ERR_SIGNOFF_TASK_NOT_FOUND</code>, create <code>SignOffRetry</code> suggestion with correction hints.<br>2. <code>signerID</code> unknown -> return <code>ERR_SIGNER_UNKNOWN</code> and create a pre-approved <code>SignOffPendingOnAuthorization</code> record linking to the pending identity resolution process.<br>3. Policy violation -> <code>Status=Rejected</code>, <code>ErrorCode=ERR_SIGNOFF_POLICY_VIOLATION</code> and include <code>FailingRuleID</code> and remediation steps.<br>4. Evidence mismatch -> <code>Status=Pending</code>, append PQ_Issues row for <code>UnverifiedEvidence</code>.<br><strong>Atomicity & concurrency:</strong> Acquire a lightweight worksheet-level lock (or in-memory lock via hidden control cell) during append to prevent race conditions in multi-user shared workbook environments. Implement optimistic retry if lock is contended. <br><strong>Observability & logging:</strong> On success, write an <code>AppendAudit</code> entry with <code>eventType=&quot;SignOffRecorded&quot;</code> and correlation <code>RunID</code>. Record row number, SignOffID, signoff hash, and evidence pointer summary. <br><strong>Security & permissions checks:</strong> Before writing, call <code>EnforceExportPermissions</code> / <code>IsSignerAuthorized</code> ensuring signer is permitted to sign for this artifact. Denials return <code>ERR_SIGNOFF_UNAUTHORIZED</code>. <br><strong>Testing:</strong> Unit tests should ensure deterministic SignOffID generation (seedable GUID generator in test harness), validation of evidence hash mismatch path, and policy rejection tests. Integration tests: simulate two concurrent <code>RecordSignOff</code> and verify no duplicate row/overwrites. <br><strong>Conceptual Power Query notes (PQ):</strong><br>1. PQ should expose a <code>SignOffEnrichment</code> query that merges <code>SignOffEntries</code> with <code>UserDirectory</code> and <code>TasksMaster</code> to produce sign-off human-readable audit views. <br>2. PQ steps: import SignOffEntries -> expand EvidencePointers -> join with EvidenceIndex -> compute <code>EvidenceVerified</code> flags -> produce <code>SignOffAuditView</code>. <br><strong>Conceptual DAX measures:</strong><br>1. <code>TotalSignOffs = COUNTROWS(SignOffEntries)</code>.<br>2. <code>SignOffsPending = CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[Status]=&quot;Pending&quot;)</code>.<br>3. <code>AvgTimeToSignOff = AVERAGEX(SignOffEntries, DATEDIFF(SignOffEntries[RequestedAt],SignOffEntries[TimestampUTC],DAY))</code>.<br><strong>Example:</strong> <code>RecordSignOff(&quot;PAY-2025-06-15-0001&quot;,&quot;u123&quot;,&quot;PayrollManager&quot;,&quot;APPROVAL-789&quot;,Array(&quot;EVID-001&quot;,&quot;EVID-002&quot;),&quot;&quot;,&quot;u123&quot;)</code> returns <code>{SignOffID:&quot;GUID-...&quot;,Status:&quot;Recorded&quot;,Hash:&quot;sha256:...&quot;};</code> and <code>OperationalAudit</code> receives corresponding event. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: ValidateSignOffPolicy(taskID As String, signerID As String, signedRole As String, policySnapshotName As String) As Variant</strong> — <strong>Purpose & contract:</strong> Evaluate sign-off candidate against the active policy snapshot (policySnapshotName). Returns structured result with <code>Allowed</code> (Boolean), <code>FailingRules</code> (array), <code>RequiredEvidenceTypes</code> (array) and <code>TwoPersonRequired</code> (Boolean). <br><strong>Inputs:</strong> <code>taskID</code>, <code>signerID</code>, <code>signedRole</code>, <code>policySnapshotName</code> (default last snapshot if omitted). <br><strong>Outputs:</strong> Validation dictionary detailing pass/fail and reasons. No persistent writes (pure validation) but logs an <code>OperationalAudit</code> event for decision trace. <br><strong>Validation matrix checks (examples):</strong><br>1. Role-to-Task rule: certain roles allowed only for specified <code>TaskType</code> or <code>PayType</code> (e.g., "PayrollManager" allowed for regular pay, but not for severance without <code>FinanceDirector</code>).<br>2. Conflict-of-interest rule: check if signer is beneficiary of the payment (direct match on EmployeeID) -> disallow unless an independent approver exists.<br>3. Two-person rule: for amounts above thresholds or pay types (e.g., >50k or Severance) set <code>TwoPersonRequired=True</code> and list candidate second approvers.<br>4. Evidence requirement: require <code>RemittanceAdvice</code> or <code>PayrollJournal</code> for certain approval types. <br><strong>Policy precedence & inheritance:</strong> Policies support hierarchical override: Global -> Country -> BusinessUnit -> PayType. The function applies the most specific matching policy first and falls back. Document precedence resolution in <code>PolicyResolutionTrace</code>. <br><strong>Failure modes & handling:</strong> Invalid policy snapshot name returns <code>ERR_POLICY_SNAPSHOT_MISSING</code>. Ambiguous policy rules result in <code>FailingRules</code> containing <code>RuleID</code> and textual explanation. <br><strong>Implementation notes:</strong><br>1. Represent policies in workbook as structured tables: <code>PolicyRules</code>, <code>ApprovalMatrix</code>, <code>TwoPersonRules</code>.<br>2. For complex policy expressions allow simple predicate language (field comparisons, amount thresholds). Evaluate in deterministic order and fail-safe (deny by default).<br>3. Use caching for last-used policy snapshot. <br><strong>Observability & logging:</strong> Record <code>PolicyEvaluation</code> entries in <code>OperationalAudit</code> with <code>PolicySnapshotHash</code> and <code>EvaluationResult</code>. <br><strong>Testing:</strong> Create policy fixtures with contradictions and confirm the function reports failing rules and suggested remediations. <br><strong>PQ notes:</strong> PQ can precompute <code>EffectivePolicy</code> per <code>TaskID</code> by joining task attributes with <code>PolicyRules</code> to present a column <code>EffectiveApprovalMatrix</code> for faster checks. <br><strong>DAX ideas:</strong> <code>TwoPersonComplianceRate = DIVIDE(CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[TwoPersonSatisfied]=TRUE),CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[TwoPersonRequired]=TRUE))</code>. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: IsSignerAuthorized(signerID As String, role As String, artifactScope As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Quick boolean check whether signer is assigned the claimed <code>role</code> for the <code>artifactScope</code> (global or scoped to country/business unit). Returns True/False and populates <code>AuthCheckTrace</code> hidden sheet for diagnostics. <br><strong>Inputs:</strong> <code>signerID</code>, <code>role</code>, <code>artifactScope</code> (optional: e.g., "IDN.PayRun.2025-06"). <br><strong>Outputs:</strong> Boolean and optional <code>AuthContext</code> details when requested. <br><strong>Checks performed:</strong><br>1. UserDirectory membership in role groups.<br>2. Time-bound role validity (roleStart <= NowUTC <= roleEnd).<br>3. Delegation rules (temporary delegates) and expiration validity.<br>4. Enforced separation-of-duties (SoD) constraints (e.g., an approver who prepared payroll cannot also approve same pay run without override). <br><strong>Failure modes:</strong> If <code>UserDirectory</code> not loaded return False and log <code>ERR_USERDIR_MISSING</code>. In shared workbook scenarios ensure role checks are deterministic using cached role snapshots. <br><strong>Implementation notes:</strong><br>1. Provide <code>CacheUserRoles()</code> to pre-load role map to dictionary to reduce sheet scans. <br>2. Support a fast deny-path: if role not in <code>UserRoles(signerID)</code> return immediately. <br><strong>Observability:</strong> Write <code>AuthCheckTrace</code> entries for any denied checks to enable later review. <br><strong>Testing:</strong> Tests for time-limited delegates, expired roles, and SoD deny cases. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: EnforceTwoPersonRule(taskID As String, primarySignOffID As String) As Variant</strong> — <strong>Purpose & contract:</strong> Ensure required second approver is recorded and verify constraints (not same person, meets role requirements). If second sign-off not present, create a <code>RemediationAction</code> and set <code>SignOffEntries[TwoPersonSatisfied]=False</code>. If present, set satisfied flag. Returns status object with <code>Satisfied</code> Boolean and suggested <code>SecondApproverCandidates</code>. <br><strong>Inputs:</strong> <code>taskID</code>, <code>primarySignOffID</code> (if available). <br><strong>Outputs:</strong> Updates <code>SignOffEntries</code> (primary row) with <code>TwoPersonSatisfied</code> when fulfilled; appends <code>TwoPersonEvent</code> to <code>OperationalAudit</code>. <br><strong>Algorithm & checks:</strong><br>1. Read <code>TwoPersonRules</code> applicable to the task; find candidate approver roles.<br>2. Exclude primary signer from candidate list and enforce SoD constraints.<br>3. If multiple candidate roles allowed, prefer assigned owner per <code>ApprovalMatrix</code> or fallback to <code>Admin</code> role if override permitted and properly audited.<br>4. If satisfied, append sign-off metadata linking both sign-off rows and compute combined <code>TwoPersonHash</code> (hash of concatenated sign-off hashes) stored in <code>SignOffPairs</code> table. <br><strong>Failure modes:</strong> No eligible second approver found -> create <code>ActionableRemediation</code> row and mark sample as <code>Flag: TwoPersonMissing</code>. <br><strong>Recovery strategies:</strong> Provide <code>SuggestedEscalationList</code> and send notifications via <code>NotifySigners</code>. Allow <code>EmergencyOverride</code> only when <code>OperatorIsAdmin</code> and ensure <code>OverrideApprovalRef</code> recorded and audited. <br><strong>Observability:</strong> Produce <code>TwoPersonComplianceReport</code> summarizing outstanding items. <br><strong>Testing:</strong> Fixtures where second approver is deliberately same as primary to ensure denial and override workflows. <br><strong>PQ note:</strong> PQ may compute <code>TwoPersonRequired</code> per task ahead of sign-off, enabling UI to show missing second approvers. <br><strong>DAX idea:</strong> <code>OutstandingTwoPerson = COUNTROWS(FILTER(SignOffEntries,SignOffEntries[TwoPersonRequired]=TRUE &amp;&amp; SignOffEntries[TwoPersonSatisfied]=FALSE))</code>. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: AppendSignOffEntry(signOffRecord As Dictionary) As Boolean</strong> — <strong>Purpose & contract:</strong> Low-level writer that accepts a fully validated sign-off record and appends it to <code>SignOffEntries</code> sheet. Should be private/internal to the module but exposed for batch imports. Returns True if append succeeded and writes <code>SignOffRowIndex</code>. <br><strong>Inputs:</strong> <code>signOffRecord</code> — structured dict containing required fields as per RecordSignOff invariants. <br><strong>Outputs:</strong> Writes single row and returns True. Also issues modAudit.AppendAudit with <code>eventType=&quot;SignOffAppended&quot;</code>. <br><strong>Behavioral details:</strong><br>1. Canonicalize field order for deterministic hash generation.<br>2. Validate no overwrite of existing <code>SignOffID</code> (idempotency): if <code>SignOffID</code> exists, operation should be a no-op and return False with <code>ErrorCode=ERR_DUPLICATE_SIGNOFF</code>. <br>3. Use worksheet-level write lock for atomicity. <br><strong>Failure modes & mitigations:</strong> Row limit reached -> rotate to <code>SignOffEntries_Archive</code> and continue append. Corrupt row detection (unexpected cell type) -> attempt corrective serialization or write to <code>SignOffExceptions</code> for manual triage. <br><strong>Testing:</strong> Batch import tests with tens of thousands of records verifying append speed and integrity. <br><strong>Performance tuning:</strong> For large batch loads, temporarily disable screen updating, switch to manual calculation mode, pre-build a value array and write in a single range assignment to reduce per-row write overhead. Ensure memory footprint stays within Excel limits. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: UpdateTasksMasterSignOffFields(taskID As String) As Boolean</strong> — <strong>Purpose & contract:</strong> After a sign-off is appended or revoked, update computed fields in <code>TasksMaster</code> or <code>Population</code> for the related <code>taskID</code> such as <code>SignOffCount</code>, <code>LastSignOffAtUTC</code>, <code>LastSignOffBy</code>, <code>SignOffCoverage</code> and <code>TwoPersonSatisfied</code>. Returns True on success. <br><strong>Inputs:</strong> <code>taskID</code>. <br><strong>Outputs:</strong> Writes to <code>TasksMaster</code> table and returns True. Also appends <code>OperationalAudit</code> with <code>eventType=&quot;TaskSignOffUpdated&quot;</code>. <br><strong>Implementation details:</strong><br>1. Query <code>SignOffEntries</code> for non-revoked entries for this <code>taskID</code> and compute aggregated values. <br>2. Compute <code>SignOffCoverage</code> as boolean: all required roles satisfied per <code>EffectiveApprovalMatrix</code>. <br>3. If coverage changes from False->True, optionally trigger <code>modControls.AttemptClose</code> or notify workflow via <code>NotifySignOffComplete</code>. <br><strong>Edge cases:</strong> SignOff entries for merged tasks should update both primary and secondary task records and preserve original sign-off provenance. <br><strong>Performance:</strong> Use dictionary lookups for sign-off aggregates when processing large batches of updates. <br><strong>Testing:</strong> Validate idempotency by calling multiple times and ensuring stable results. <br><strong>PQ note:</strong> PQ can create a <code>SignOffSummaryPerTask</code> query that's used to write these computed fields via simple range copy. <br><strong>DAX:</strong> <code>SignOffCoveragePct = DIVIDE([CountFulfilledRoles],[CountRequiredRoles])</code>. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: RevokeSignOff(signOffID As String, revokedBy As String, reasonCode As String, revokeTimeUtc As String, requireApprovals As Boolean) As Variant</strong> — <strong>Purpose & contract:</strong> Provide controlled, auditable revocation of sign-off entries. Revocation must be appended as a separate immutable record referencing the original sign-off. Returns object with <code>Revoked=True/False</code>, <code>RevocationEntryID</code>, and <code>RemediationActions</code>. <br><strong>Inputs:</strong> <code>signOffID</code>, <code>revokedBy</code> (operator), <code>reasonCode</code> (standardized codes), <code>revokeTimeUtc</code>, <code>requireApprovals</code> (if revocation itself needs 2nd approval). <br><strong>Outputs:</strong> Appends <code>RevocationEntries</code> and marks <code>SignOffEntries.Revoked=True</code> with <code>RevokedBy</code> and <code>RevokedAtUTC</code>. Writes <code>OperationalAudit</code> event <code>SignOffRevoked</code>. <br><strong>Validation & approval flow:</strong><br>1. Confirm <code>revokedBy</code> is authorized to revoke (e.g., Admin or via explicit <code>OverrideApprovalMatrix</code>).<br>2. If <code>requireApprovals=True</code>, create <code>RevocationPending</code> event requiring a second admin approval; record the pending state in <code>RevocationQueue</code>.<br>3. When revocation is finalized, update sign-off row with revocation metadata but never delete original row. <br><strong>Failure modes:</strong> Attempt to revoke already revoked entry -> return <code>ERR_ALREADY_REVOKED</code>. Unauthorized attempt -> <code>ERR_REVOKE_UNAUTHORIZED</code> and create incident record for Security team. <br><strong>Recoverability & forensic:</strong> Maintain <code>RevocationBundle</code> with original sign-off hash, revocation hash, approver hashes and evidence to ensure tamper-evidence. <br><strong>Testing:</strong> Tests for revocation with and without second approvals, and ensure downstream computed fields in <code>TasksMaster</code> adjust appropriately. <br><strong>PQ note:</strong> PQ should expose <code>Revocations</code> for reviewers showing before/after coverage states. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: ExportSignOffJournal(outPath As String, format As String, includeEvidencePointers As Boolean, anonymizePII As Boolean) As Dictionary</strong> — <strong>Purpose & contract:</strong> Export sign-off journal for auditors as CSV/XLSX or packaged forensic bundle. When anonymizePII=True produce a redacted copy that replaces PII (e.g., signer names) with hashed tokens. Returns manifest dictionary with <code>Files</code>, <code>Sha256</code>, <code>ExportTimestampUTC</code>. <br><strong>Inputs:</strong> <code>outPath</code>, <code>format</code> ("CSV","XLSX","ZIP"), <code>includeEvidencePointers</code>, <code>anonymizePII</code>. <br><strong>Outputs:</strong> Writes file(s) to disk and returns manifest. Also appends <code>OperationalAudit</code> entry. <br><strong>Implementation & controls:</strong><br>1. Respect <code>EnforceExportPermissions</code> before exporting raw SignOffEntries (deny if operator lacks permission).<br>2. Forensic export: include <code>SignOffEntries</code>, <code>EvidenceIndex</code>, <code>OperationalAudit</code> and <code>ConfigSnapshot</code>. Bundle into ZIP and compute SHA256 for the bundle. <br>3. For anonymized export: replace <code>SignerID</code> and <code>SignerName</code> with hashed tokens, but retain mapping in a separate secured mapping file stored separately and access-controlled. <br><strong>Failure modes:</strong> Path write denied (<code>ERR_IO_WRITE_FAIL</code>) -> suggest alternative path and log audit event. For very large exports, stream to CSV to avoid memory exhaustion. <br><strong>Testing:</strong> Export test for anonymization correctness (consistent tokenization across exports), and bundle verification using computed SHA256. <br><strong>PQ note:</strong> PQ snapshot of SignOffAuditView can be saved as CSV and included in the bundle; include M-scripts snapshot. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: NotifySigners(signoffRequest As Dictionary, notifyMethod As String, timeoutDays As Integer) As Variant</strong> — <strong>Purpose & contract:</strong> Send notifications to signers to request sign-off, optionally schedule reminders. <code>notifyMethod</code> supports "Email" (via Outlook), "Teams" (if integration present), and "InWorkbook" (write-to-notifications-sheet). Returns list of <code>NotificationIDs</code> and schedule metadata. <br><strong>Inputs:</strong> <code>signoffRequest</code> containing <code>TaskID</code>, <code>Signers</code> (array), <code>DueDateUTC</code>, <code>MessageBody</code>, <code>ManifestRef</code>. <br><strong>Outputs:</strong> Writes to <code>Notifications</code> sheet (and sends email if configured). Returns schedule details. <br><strong>Implementation details & safety:</strong><br>1. Prefer writing notifications as idempotent entries in <code>Notifications</code> sheet with <code>NotificationID</code> GUID. External delivery is attempted asynchronously via Outlook Automation if permitted; if macros or external access disabled, notifications remain internal. <br>2. Record <code>NotificationSent</code> timestamp, delivery status, and bounce/error info. <br>3. Schedule remiders by inserting future rows in <code>ReminderQueue</code> with <code>NextAttemptUTC</code>. Provide <code>modRemind</code> or <code>Scheduler</code> to pick them up. <br><strong>Failure modes:</strong> Outlook blocked by security policy -> fall back to writing <code>Notifications</code> and ask operator to manually send. Log <code>ERR_NOTIFY_OUTLOOK_BLOCKED</code>. <br><strong>Testing:</strong> Mocks for email sending; tests for idempotent notification replays and reminder schedule correctness. <br><strong>Observability:</strong> <code>NotificationsLog</code> with counts and delivery rates. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: GetPendingSignOffsForOwner(ownerID As String, includeBlocked As Boolean) As Collection</strong> — <strong>Purpose & contract:</strong> Return pending sign-off items assigned to owner or their delegates for action. Useful for UI lists and reminder generation. <br><strong>Inputs:</strong> <code>ownerID</code>, <code>includeBlocked</code> flag to optionally include items currently blocked by PQ_Issues or evidence missing. <br><strong>Outputs:</strong> Collection of structured items (<code>TaskID</code>, <code>TaskSummary</code>, <code>RequiredRoles</code>, <code>DueDateUTC</code>, <code>PendingSinceUTC</code>, <code>Blockers</code>). <br><strong>Implementation details:</strong><br>1. Query <code>SignOffRequirements</code> per task and <code>SignOffEntries</code> to determine missing roles.<br>2. Include <code>Blockers</code> with short text and <code>BlockerSeverity</code> to help triage. <br><strong>Performance:</strong> Index by owner in a hidden lookup table precomputed by <code>CacheOwnerPendingIndex()</code> for large datasets. <br><strong>Testing:</strong> Validate with owners that have delegated roles and ensure delegation rules honored. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: BuildSignOffSnapshot(snapshotName As String, includeEvidenceIndex As Boolean, protectSnapshot As Boolean) As Variant</strong> — <strong>Purpose & contract:</strong> Create an immutable snapshot of current sign-off state for controls and forensic archiving. Writes <code>SignOffSnapshot_&lt;snapshotName&gt;</code> sheet and records hash and metadata in <code>ConfigSnapshotsIndex</code>. Returns manifest with <code>SnapshotSheetName</code>, <code>RowCount</code>, <code>Sha256</code>. <br><strong>Inputs:</strong> <code>snapshotName</code>, <code>includeEvidenceIndex</code>, <code>protectSnapshot</code>. <br><strong>Outputs:</strong> Snapshot sheet and manifest dictionary. <br><strong>Implementation details:</strong><br>1. Copy <code>SignOffEntries</code> table and optionally <code>EvidenceIndex</code> and <code>OperationalAudit</code> into a new sheet. <br>2. Compute SHA256 over CSV serialization and store this in snapshot header <code>SnapshotHash</code>. <br>3. Protect sheet if <code>protectSnapshot=True</code> and write <code>SnapshotMetadata</code> including <code>CreatedBy</code>, <code>CreatedAtUTC</code>, and <code>PolicySnapshotHash</code>. <br><strong>Failure modes:</strong> Sheet name collision -> auto-suffix with timestamp. Protection failure (sheet protection locked) -> log <code>ERR_SNAPSHOT_PROTECT_FAIL</code> and write snapshot unprotected but flagged. <br><strong>Testing:</strong> Snapshot hash reproducibility tests and immutability enforcement checks. <br><strong>PQ note:</strong> PQ may use snapshots for historical reconciling. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: MergeSignOffsOnTaskMerge(primaryTaskID As String, secondaryTaskIDs As Variant, operatorID As String) As Variant</strong> — <strong>Purpose & contract:</strong> When tasks/samples are merged, rebind sign-off rows from secondaries to primary while preserving original provenance. Returns mapping of <code>OldSignOffID -&gt; NewSignOffID</code> (if rewrites performed) and <code>MergeAuditID</code>. <br><strong>Inputs:</strong> <code>primaryTaskID</code>, <code>secondaryTaskIDs</code> (array), <code>operatorID</code>. <br><strong>Outputs:</strong> Updated SignOffEntries rows referencing new <code>TaskID</code>, plus <code>MergeAudit</code> row documenting the operation and append-only logs. <br><strong>Rules & constraints:</strong><br>1. Do not change original <code>SignOffID</code> values; instead append a new binding record in <code>SignOffBindings</code> linking original <code>SignOffID</code> to <code>primaryTaskID</code> with <code>BindingID</code> and <code>BindingHash</code> to preserve immutable evidence trail. <br>2. Move or duplicate EvidenceIndex entries by creating <code>EvidenceBindings</code> tying evidence to primary and preserve original pointers for forensic review. <br>3. Append <code>OperationalAudit</code> event <code>SignOffMerged</code>. <br><strong>Edge cases:</strong> Duplicate sign-offs across merged tasks (same signer, same role) — deduplicate by creating <code>MergedSignOffDedup</code> record rather than dropping anything. <br><strong>Testing:</strong> Merge order independence tests, duplicate detection, and ensure all primary/secondary provenance preserved. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: LockSignOffEntry(signOffID As String, lockReason As String, lockedBy As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Temporarily lock sign-off entry to prevent changes (revocation or rebinding) during live investigative procedures. Lock metadata must be appended and visible. Returns True on success. <br><strong>Inputs:</strong> <code>signOffID</code>, <code>lockReason</code>, <code>lockedBy</code>. <br><strong>Outputs:</strong> Sets <code>SignOffEntries.Locked=True</code> with <code>LockReason</code>, <code>LockedBy</code>, <code>LockAcquiredAtUTC</code>. Writes <code>LockAudit</code>. <br><strong>Rules:</strong> Only admin or specially privileged investigator roles may acquire locks. Locking must be represented as append-only metadata. Locks auto-expire based on <code>LockTTL</code> unless explicitly extended. <br><strong>Failure modes:</strong> Attempt to lock by non-privileged user -> <code>ERR_LOCK_UNAUTHORIZED</code>. Attempt to modify locked entry without clearance -> operation denied and <code>OperationalAudit</code> event with <code>ERR_LOCK_VIOLATION</code>. <br><strong>Testing:</strong> Lock expiry, concurrent lock acquisition attempts, and lock-based deny paths. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: SignOffComplianceReport(periodStartUTC As String, periodEndUTC As String, groupBy As String) As WorkbookRange</strong> — <strong>Purpose & contract:</strong> Produce an aggregated report for auditors summarizing sign-off coverage, SLA compliance, two-person adherence, revocations, and evidence verification statuses across the requested period. Returns a workbook range or writes <code>SignOffCompliance_&lt;period&gt;</code> sheet. <br><strong>Inputs:</strong> <code>periodStartUTC</code>, <code>periodEndUTC</code>, <code>groupBy</code> (e.g., "BusinessUnit","Country","Owner"). <br><strong>Outputs:</strong> Writes report sheet with pivot-like sections and summary KPIs. <br><strong>KPIs included (conceptual list with required formulas):</strong><br>1. <code>SignOffCoveragePct</code> = sign-offs where all required roles fulfilled / total required roles.<br>2. <code>AvgTimeToSignOffHours</code> = mean elapsed hours from <code>SignOffRequestedAt</code> to <code>SignOffTimestamp</code>.<br>3. <code>RevocationRate</code> = revocations/total sign-offs.<br>4. <code>EvidenceVerifiedPct</code> = sign-offs for which all evidence pointers verified / total sign-offs.<br><strong>Implementation note:</strong> Use pivot table creation for large datasets, but provide precomputed cache tables for faster report generation. <br><strong>DAX measures recommended for PowerPivot model:</strong><br>1. <code>SignOffCoveragePct = DIVIDE([FulfilledRoleCount],[RequiredRoleCount])</code>.<br>2. <code>SLACompliance = CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[TimeToSignOffHours] &lt;= [SLAHours])</code>.<br><strong>PQ note:</strong> Provide <code>SignOffCompliance</code> PQ query that pre-aggregates per day/per BU to reduce pivot refresh times. <br><strong>Testing:</strong> Run on synthetic data for edge-case high revocation rates and verify KPI bounds. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: UnitTests_ModuleSignOff_RunAll(mode As String) As Collection</strong> — <strong>Purpose & contract:</strong> Execute in-workbook unit and integration tests for modSignOff. <code>mode</code> supports <code>quick</code>, <code>full</code>, <code>stress</code>. Returns collection of test result objects and writes <code>TestResults_SignOff</code> sheet. <br><strong>Tests included (examples, each must use deterministic seeds):</strong><br>1. <code>test_RecordSignOff_success</code> — create valid sign-off and verify <code>SignOffEntries</code> row and audit event.<br>2. <code>test_RecordSignOff_evidenceMismatch</code> — supply mismatched evidence checksums and expect <code>Pending</code> status.<br>3. <code>test_TwoPersonRule</code> — ensure two-person requirement enforcement and pair hash generation.<br>4. <code>test_RevokeSignOff_flow</code> — revoke with and without second approval and verify audit trail.<br>5. <code>test_ExportAnonymize</code> — export with PII anonymized and verify token mapping stored securely.<br>6. <code>test_ConcurrentAppend</code> (stress) — simulate concurrent appends with simulated locks and confirm no token/row collisions. <br><strong>Reporting:</strong> test harness must produce detailed failure logs including sample inputs, expected/actual, recommended debug steps. <br><strong>Testing environment notes:</strong> Tests that mutate production sheets should be run against temporary snapshot sheets created by <code>BuildSignOffSnapshot</code>. Quick mode uses a lightweight fixture subset; full mode uses larger fixture sets. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: AppendAuditEventForSignOff(eventType As String, signOffID As String, actorID As String, details As String) As String</strong> — <strong>Purpose & contract:</strong> Helper that creates a standardized OperationalAudit entry for sign-off lifecycle events to ensure consistent event taxonomy. Returns EventID. <br><strong>Inputs:</strong> <code>eventType</code> (enum e.g., "SignOffRecorded","SignOffRevoked","SignOffMerged","SignOffLocked"), <code>signOffID</code>, <code>actorID</code>, <code>details</code> JSON or structured string. <br><strong>Outputs:</strong> Appends a row in <code>OperationalAudit</code> with correlation to signoff and returns <code>EventID</code>. <br><strong>Event schema must include (immutable):</strong> <code>EventID</code>, <code>EventType</code>, <code>RelatedSignOffID</code>, <code>ActorID</code>, <code>TimestampUTC</code>, <code>EventDetails</code>, <code>EventHash</code>, <code>RunID</code>. <br><strong>Implementation notes:</strong> Reuse modAudit.AppendAudit for standardization; ensure <code>EventHash</code> is SHA256 over canonicalized JSON of event payload to support tamper-evidence. <br><strong>Testing:</strong> Verify event append and event-hash reproducibility. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: EnforceSignOffPermissions(userID As String, artifactID As String, requestedAction As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Wrapper to centralize permission enforcement when operations are requested against sign-off artefacts (read/export/revoke/override). Returns True if allowed. <br><strong>Inputs:</strong> <code>userID</code>, <code>artifactID</code> (e.g., SignOffID or Snapshot), <code>requestedAction</code> ("read","export","revoke","override"). <br><strong>Outputs:</strong> Boolean and writes <code>SecurityLog</code> entry for denials. <br><strong>Checks performed:</strong><br>1. Role membership check.<br>2. Contextual constraints (e.g., cannot revoke unless in <code>AdminOverrideWindow</code> or special approval exists).<br>3. External policy (e.g., Data Protection rules) that may prevent export of sign-off metadata containing PII. <br><strong>Failure handling:</strong> Denial returns <code>False</code> and writes <code>SecurityLog</code> with <code>ERR_SIGNOFF_PERMISSION_DENIED</code>. If macros disabled, fallback policies enforced. <br><strong>Testing:</strong> Ensures denials are logged and export endpoints honor denial. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: BuildSignOffChangeSetForExport(runID As String, includeRevocations As Boolean) As Variant</strong> — <strong>Purpose & contract:</strong> Produce an ordered change set for the run (useful for incremental exports and replication to downstream systems). Returns structure with <code>AddedSignOffs</code>, <code>RevokedSignOffs</code>, <code>Bindings</code>, each with computed <code>RowHash</code>. <br><strong>Inputs:</strong> <code>runID</code>, <code>includeRevocations</code>. <br><strong>Outputs:</strong> Writes <code>ChangeSet_&lt;runID&gt;</code> sheet and returns manifest. <br><strong>Implementation & use:</strong> Used by <code>ExportSignOffJournal</code> and by external ingestion processes to replicate sign-off records. Each row in change set includes <code>OperationType</code> ("INSERT","REVOKE","BIND"), <code>SignOffID</code>, <code>TimestampUTC</code>, <code>RowHash</code>. <br><strong>Testing:</strong> Simulate partial run restarts and verify idempotent replay on downstream ingestion. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: SanitizeAndCanonicalizeApprovalRef(approvalRefRaw As String) As String</strong> — <strong>Purpose & contract:</strong> Deterministic sanitizer for approval reference strings (removes extraneous whitespace, normalizes punctuation, truncates to schema length, computes canonical token for hashing). Returns canonical string. <br><strong>Inputs:</strong> <code>approvalRefRaw</code>. <br><strong>Outputs:</strong> Canonical string to be used in sign-off serialization and hashing. <br><strong>Implementation notes:</strong> Avoid altering meaningful case for coded refs. Support known patterns such as <code>E-SIGN|TXN|12345</code> and validate pattern. For unknown patterns, compute a stable fingerprint and return <code>FPRINT:&lt;hex&gt;</code>. <br><strong>Testing:</strong> Ensure canonicalization is idempotent and stable across workbook opens and different locale settings. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: GenerateSignOffHash(signOffRecord As Dictionary) As String</strong> — <strong>Purpose & contract:</strong> Compute SHA256 hash over canonical serialization of sign-off record for tamper-evidence. Returns <code>sha256:&lt;hex&gt;</code>. Must be used consistently across write and verification. <br><strong>Inputs:</strong> <code>signOffRecord</code>. <br><strong>Outputs:</strong> <code>sha256</code> string. <br><strong>Implementation notes:</strong> Use deterministic field order: <code>SignOffID|TaskID|SignerID|SignedRole|ApprovalRefCanonical|EvidencePointersCanonical|TimestampUTC|OperatorID|Status</code>. Ensure numeric types are formatted with invariant culture (dot decimal) and dates in ISO8601 UTC. <br><strong>Failure modes:</strong> Missing required fields -> throw controlled error and write to <code>SignOffExceptions</code> with <code>ERR_HASH_FAIL</code>. <br><strong>Testing:</strong> Verify hash matches precomputed expected values in unit tests and ensure slight modifications change hash. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: VerifySignOffIntegrity(signOffID As String) As Variant</strong> — <strong>Purpose & contract:</strong> Recompute sign-off hash and compare to stored <code>SignOffHash</code> to detect tampering. Returns dict with <code>IntegrityOk</code> Boolean, <code>StoredHash</code>, <code>ComputedHash</code>, <code>DiffFields</code>. <br><strong>Inputs:</strong> <code>signOffID</code>. <br><strong>Outputs:</strong> Verification result; writes <code>IntegrityCheckLog</code> with timestamp and result. <br><strong>Use cases:</strong> Periodic integrity sweeps (Nightly Parity Job), pre-export forensic checks. <br><strong>Failure handling:</strong> If mismatch found, escalate to <code>ForensicReviewQueue</code>, lock sign-off entry, and append <code>OperationalAudit</code> with <code>fa.integrity.fail</code>. <br><strong>Testing:</strong> Unit tests where a sign-off row is deliberately altered to ensure detection. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: AttachApprovalEvidenceToSignOff(signOffID As String, evidencePointer As String, uploaderID As String, evidenceChecksum As String) As Variant</strong> — <strong>Purpose & contract:</strong> Convenience routine to attach evidence pointer(s) to existing sign-off. Validates checksum and appends evidence pointer to <code>SignOffEntries.EvidencePointers</code> as a canonical addition (preserving history) and writes EvidenceIndex if not present. Returns updated SignOff row reference. <br><strong>Inputs:</strong> <code>signOffID</code>, <code>evidencePointer</code>, <code>uploaderID</code>, <code>evidenceChecksum</code> (optional). <br><strong>Outputs:</strong> Updated sign-off <code>EvidencePointers</code> and <code>EvidenceIndex</code> row. Appends <code>OperationalAudit</code>. <br><strong>Constraints:</strong> Once evidence pointer added, it remains part of history; to remove evidence user must <code>DetachEvidence</code> which creates a <code>DetachEvent</code> not a destructive delete. <br><strong>Failure modes:</strong> Checksum mismatch -> do not attach and create <code>PQ_Issues</code> entry. Evidence pointer already exists -> idempotent no-op and return success. <br><strong>Testing:</strong> Attach existing evidence and new evidence; verify evidence hash recorded and duplication avoided. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: DetachEvidenceFromSignOff(signOffID As String, evidenceID As String, operatorID As String, reasonCode As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Append-only "detach" log that marks evidence as no longer associated for future automation, but keeps original evidence row for forensic trace. Must be audited and, where required, trigger IR (incident response) if evidence was tampered with. <br><strong>Inputs:</strong> <code>signOffID</code>, <code>evidenceID</code>, <code>operatorID</code>, <code>reasonCode</code>. <br><strong>Outputs:</strong> Writes <code>EvidenceDetach</code> row and modifies <code>SignOffEntries</code> <code>EvidencePointers</code> to add a soft flag (e.g., append <code>|-DETACHED(evidenceID)|</code>). <br><strong>Rules:</strong> Only privileged roles may detach. If detachment affects compliance (missing required evidence), create <code>RemediationAction</code>. <br><strong>Testing:</strong> Detach then re-attach behavior; ensure detach is append-only and recoverable in forensic bundle. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: BuildSignOffApprovalMatrixForUI(taskID As String) As Variant</strong> — <strong>Purpose & contract:</strong> Produce data structure consumed by UI (wizard) listing required roles, candidate approvers, their current status (fulfilled/pending), and evidence requirements. The UI calls this to render sign-off panels. <br><strong>Inputs:</strong> <code>taskID</code>. <br><strong>Outputs:</strong> JSON-like dictionary with arrays: <code>RequiredRoles</code>, <code>CandidatesPerRole</code>, <code>CurrentSignOffs</code>, <code>Blockers</code>. <br><strong>Implementation:</strong> Pull from <code>PolicyRules</code>, <code>UserRoleCache</code>, <code>SignOffEntries</code>, and <code>EvidenceIndex</code>. Precompute <code>CandidateScore</code> per candidate to present recommended approver order in UI. <br><strong>Testing:</strong> Ensure UI shows correct candidates when delegates exist and when roles are temporarily suspended. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: EmergencyOverrideSignOff(taskID As String, overrideBy As String, overrideJustification As String, approvalsRequired As Integer) As Variant</strong> — <strong>Purpose & contract:</strong> Record an emergency override sign-off path when immediate close is mandatory and policy cannot be met in time. Must require <code>approvalsRequired</code> post-action or be automatically escalated for investigation. Returns override record and sets flags for forensic review. <br><strong>Inputs:</strong> <code>taskID</code>, <code>overrideBy</code>, <code>overrideJustification</code>, <code>approvalsRequired</code>. <br><strong>Outputs:</strong> Append <code>EmergencyOverride</code> record, create <code>CompensatingControl</code> tasks, and write <code>OperationalAudit</code> events. <br><strong>Controls:</strong> Only <code>Admin</code> or <code>Officer</code> roles can perform and each override must be time-limited and include required follow-up approvals. <br><strong>Testing:</strong> Simulate emergency override and verify that subsequent required approvals are enforced and alerts created if missing by deadline. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: ResolveSignOffCandidateAmbiguity(candidateList As Variant, selectionPolicy As String) As String</strong> — <strong>Purpose & contract:</strong> Given a set of candidate approvers for a role, apply selection policy to choose the recommended approver for UI pre-fill. Policies include <code>PreferAssignedOwner</code>, <code>MostAvailable</code> (fewest open tasks), <code>RandomSeeded</code>, <code>HighestRolePriority</code>. Returns selected <code>SignerID</code>. <br><strong>Inputs:</strong> candidateList (array of signerIDs with metadata), <code>selectionPolicy</code>. <br><strong>Outputs:</strong> chosen signerID and <code>SelectionTrace</code> explaining rationale. <br><strong>Implementation notes:</strong> For <code>RandomSeeded</code> use deterministic seeded RNG using <code>TaskID</code> to ensure reproducibility. For <code>MostAvailable</code>, compute availability via <code>OwnerLoadCache</code>. <br><strong>Testing:</strong> Ensure deterministic selection under identical inputs and seed. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: CreateSignOffRemediationAction(signOffID As String, reasonCode As String, assignedTo As String, dueDateUtc As String) As String</strong> — <strong>Purpose & contract:</strong> Create an action item when sign-off is rejected/blocked (e.g., missing evidence). Returns <code>RemediationActionID</code>. <br><strong>Inputs:</strong> <code>signOffID</code>, <code>reasonCode</code>, <code>assignedTo</code>, <code>dueDateUtc</code>. <br><strong>Outputs:</strong> Writes <code>RemediationActions</code> row and links to <code>SignOffEntries</code>. Optionally triggers <code>NotifySigners</code> for assigned owner. <br><strong>Implementation details:</strong> Categorize remediation by priority using severity mapping; for high severity create <code>HighPriorityAlert</code>. <br><strong>Testing:</strong> Ensure remediation items are visible via <code>GetPendingSignOffsForOwner</code> and produce reminders. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Function: SnapshotSignOffApprovalMatrix(matrixName As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Persist current approval matrix to a named snapshot for audit and validation by <code>ValidateSignOffPolicy</code>. Useful before major configuration changes. Returns True on success and writes <code>PolicySnapshotIndex</code>. <br><strong>Inputs:</strong> <code>matrixName</code>. <br><strong>Outputs:</strong> snapshot sheet, <code>PolicySnapshotHash</code>, and <code>OperationalAudit</code> event. <br><strong>Testing:</strong> Confirm <code>ValidateSignOffPolicy</code> can reference older snapshots for reproducing past decisions. </td></tr><tr><td data-label="modSignOff — Per-function technical breakdown"> <strong>Operational Patterns & Non-functional Requirements (applies across functions)</strong> — <strong>Auditability & Immutability:</strong><br>1. All primary sign-off records are append-only; any change is recorded as a separate append event (revocation, bind, detach, lock).<br>2. Every write must compute and store SHA256 over deterministic serialization to support tamper detection.<br>3. <code>OperationalAudit</code> must be the central, minimally-modifiable ledger of events; include correlation <code>RunID</code> and <code>CorrelationID</code> per workflow operation.<br><strong>Concurrency & Multi-user:</strong><br>1. Use worksheet-level lightweight lock for writes to critical sheets; implement retry/backoff on contention to avoid conflicts in shared workbook mode.<br>2. For high throughput environments, provide batch import endpoints that write to staging sheets and then call append routines to commit. <br><strong>Performance & Scalability:</strong><br>1. For >50k sign-off rows, move to chunked CSV exports and treat the workbook as a view over an external DB or PowerPivot model; provide guidance to maintain Excel responsiveness.<br>2. Use in-memory dictionaries for lookups (UserRoles, ApprovalMatrix, RecentSignOffCache) to avoid repeated sheet scans. <br><strong>Security & Data Protection:</strong><br>1. PII handling: provide anonymization functions for exports and store mapping separately in a secured vault or restricted sheet. <br>2. Enforce <code>EnforceSignOffPermissions</code> for export and revoke actions. <br>3. Evidence files should be copied into an <code>EvidenceArchive</code> folder with computed SHA256 to prevent loss; avoid storing credentials in any sheet. <br><strong>Error Handling & Codes:</strong> Standardize deterministic error codes: <br>1. <code>ERR_SIGNOFF_TASK_NOT_FOUND</code><br>2. <code>ERR_SIGNER_UNKNOWN</code><br>3. <code>ERR_SIGNOFF_POLICY_VIOLATION</code><br>4. <code>ERR_SIGNOFF_UNAUTHORIZED</code><br>5. <code>ERR_EVIDENCE_MISMATCH</code><br>6. <code>ERR_DUPLICATE_SIGNOFF</code><br>7. <code>ERR_IO_WRITE_FAIL</code><br>8. <code>ERR_SNAPSHOT_PROTECT_FAIL</code><br>9. <code>ERR_LOCK_UNAUTHORIZED</code><br>10. <code>ERR_ALREADY_REVOKED</code><br><strong>Observability & Telemetry:</strong><br>1. Telemetry counters to capture: <code>signoff.record.count</code>, <code>signoff.revoke.count</code>, <code>signoff.pending.count</code>, <code>signoff.export.durationMs</code>, <code>signoff.integrity.failures.count</code>.<br>2. Periodic integrity sweeps scheduled by Nightly Parity Job calling <code>VerifySignOffIntegrity</code> and producing <code>IntegritySummary</code>. <br><strong>Testing & QA strategy:</strong><br>1. Unit test coverage for each public function with deterministic RNGs and seeded GUID generator. <br>2. Integration tests that exercise cross-module interactions (<code>modEvidence</code>, <code>modAudit</code>, <code>modControls.AttemptClose</code>, <code>modFX</code> for currency-sensitive approvals). <br>3. Stress tests simulating heavy sign-off volumes and concurrent operators in shared workbook. <br><strong>Operational runbooks (auditor-friendly):</strong><br>1. How to extract forensic bundle: <code>ExportSignOffJournal</code> -> ZIP -> compute SHA256 -> store in <code>Archive</code> and update <code>DeliverablesManifest</code>.<br>2. How to handle a suspected tamper: run <code>VerifySignOffIntegrity</code> across the suspect sign-off IDs -> Lock affected entries -> Create <code>ForensicReview</code> and notify Security. <br><strong>Integration touchpoints (calls to/from other modules):</strong><br>1. <strong>modEvidence</strong> — call <code>AttachApprovalEvidenceToSignOff</code> and respond to evidence verification status changes.<br>2. <strong>modAudit</strong> — all major events must call <code>modAudit.AppendAudit</code> with standardized event payloads.<br>3. <strong>modControls.AttemptClose</strong> — calls <code>GetPendingSignOffsForOwner</code> and <code>BuildSignOffSnapshot</code> as part of close validation; <code>RecordSignOff</code> can trigger <code>AttemptClose</code> when coverage completes.<br>4. <strong>modRemind / Scheduler</strong> — integrates <code>NotifySigners</code> and <code>GetPendingSignOffsForOwner</code> for reminder workflows.<br>5. <strong>Power Query: PopulationPrep / PQ</strong> — PQ provides <code>SignOffEnrichment</code> to present human-readable sign-off views and precompute <code>TwoPersonRequired</code> flags. <br><strong>Conceptual Power Query (PQ) recipes for sign-off data:</strong><br>1. <code>ImportSignOffEntries</code> -> Promote Headers -> Trim & Clean -> Parse <code>TimestampUTC</code> as DateTime -> Expand <code>EvidencePointers</code> into rows.<br>2. <code>JoinUserDirectory</code> -> left-join to get <code>SignerName</code>, <code>RoleDisplay</code>, <code>RoleStart</code>, <code>RoleEnd</code>.<br>3. <code>ComputeEvidenceVerified</code> -> merge with <code>EvidenceIndex</code> to get <code>EvidenceChecksumMatch</code> and <code>EvidenceLocation</code>.<br>4. <code>ComputeSignOffCoverage</code> -> group by <code>TaskID</code> and compute count of required vs fulfilled roles; produce <code>SignOffCoverageView</code> with flags <code>ReadyToClose</code>. <br>5. <code>ExportSignOffComplianceSnapshot</code> -> output to auditor-friendly CSV including <code>SignOffHash</code>. <br><strong>Conceptual DAX measures & model guidance (for PowerPivot/Power BI):</strong><br>1. <code>SignOffCount = COUNTROWS(SignOffEntries)</code>.<br>2. <code>SignOffCoveragePct = DIVIDE([FulfilledRoleCount],[RequiredRoleCount])</code>.<br>3. <code>AvgTimeToSignOffHours = AVERAGEX(SignOffEntries, HOUR(SignOffEntries[TimestampUTC] - SignOffEntries[RequestedAtUTC]))</code>.<br>4. <code>TwoPersonSatisfactionRate = DIVIDE(CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[TwoPersonSatisfied]=TRUE),CALCULATE(COUNTROWS(SignOffEntries),SignOffEntries[TwoPersonRequired]=TRUE))</code>.<br>5. <code>RevocationRate = DIVIDE(CALCULATE(COUNTROWS(RevocationEntries)),[SignOffCount])</code>.<br>6. <code>EvidenceVerificationPct = DIVIDE(CALCULATE(COUNTROWS(FILTER(SignOffEntries,SignOffEntries[EvidenceVerified]=TRUE))),[SignOffCount])</code>.<br><strong>Examples (narrative):</strong><br>1. Standard approval: PayrollManager <code>u123</code> signs sample <code>PAY-0001</code>. <code>RecordSignOff</code> validates role, evidence pointers show payroll journal and remittance PDF with matching checksums -> status <code>Recorded</code>. <code>UpdateTasksMasterSignOffFields</code> sets <code>SignOffCoverage=PartiallyFulfilled</code> until HR sign-off completes.<br>2. Two-person requirement: Payment > threshold flagged by <code>ValidateSignOffPolicy</code> as needing two approvers. Primary recorded by <code>PayrollManager</code>; <code>EnforceTwoPersonRule</code> finds <code>FinanceDirector</code> candidates and marks pending. Second sign-off recorded by <code>FinanceDirector</code> completes <code>TwoPersonSatisfied</code>, module computes <code>TwoPersonHash</code> and writes pair record.<br>3. Evidence mismatch: A sign-off is attempted with a remittance file whose checksum doesn't match. <code>RecordSignOff</code> returns <code>Pending</code>, writes <code>PQ_Issues</code> and <code>RemediationAction</code> assigned to owner to re-upload correct evidence. Anomaly detector will flag payment as high risk until evidence verified.<br>4. Emergency override: During critical payroll close, the required second approver is unavailable; <code>EmergencyOverrideSignOff</code> invoked by <code>Admin</code> records override and creates <code>CompensatingControl</code> requiring two post-hoc approvals within 3 days; failure to obtain them triggers an automatic <code>Incident</code> creation. <br><strong>Developer guidance & maintenance notes:</strong><br>1. Preserve function signatures and return contract stability — other VBA modules depend on stable outputs (dictionaries with fixed fields).<br>2. Wrap cryptographic helpers (ComputeSHA256) in modUtils and never reimplement ad-hoc hashing inside modSignOff. <br>3. Keep UI responsibilities minimal; provide clear data structures for UI to render. <br>4. Avoid direct file system dependencies where possible; abstract file operations behind <code>IOHelpers</code> for easier unit testing and stubbing. <br>5. Include detailed header comments for each publicly exposed function describing parameter expectations and return schemas. <br><strong>Security & compliance checklist for auditors (what modSignOff must produce):</strong><br>1. Immutable SignOffEntries sheet with per-row SHA256 and <code>SignOffSnapshot</code> for each close run.<br>2. OperationalAudit linking all sign-off lifecycle events and actor identities with timestamps in UTC ISO format.<br>3. EvidenceIndex with file hashes and pointers; packaged forensic bundle containing copies of evidence when required by audit.<br>4. Policy snapshots that reproduce the approval matrix used to accept each sign-off decision. <br><strong>Runbook: Investigating a suspicious sign-off:</strong><br>1. Run <code>VerifySignOffIntegrity</code> for suspect <code>SignOffID</code>.<br>2. If mismatch, <code>LockSignOffEntry</code> and create <code>ForensicReview</code> with <code>OperationalAudit</code> linkage.<br>3. Export forensic bundle via <code>ExportSignOffJournal</code> and store in secure archive with computed SHA256; escalate to Security. <br><strong>Internationalization & locales:</strong><br>1. All timestamps must use UTC ISO8601 for storage; display routines may present localized times. <br>2. Canonicalization functions must be locale-insensitive (numbers use invariant culture). <br><strong>Edge cases & special scenarios:</strong><br>1. Delegated roles expire between sign-off request and completion — system validates and flags for manual review; permit completion if delegation was valid at request snapshot and captured in <code>ConfigSnapshots</code>. <br>2. Merged tasks with overlapping sign-offs should not lose provenance — use <code>SignOffBindings</code> rather than raw reassignment. <br>3. Multi-currency approvals: approvals may depend on local policy; <code>ValidateSignOffPolicy</code> accounts for currency thresholds via <code>FX</code> conversions (call <code>modFX.NormalizeCurrency</code> for threshold checks). <br><strong>Final engineering checklist before deployment:</strong><br>1. Ensure all public functions have defensive input validation with deterministic error codes.<br>2. Implement and run <code>UnitTests_ModuleSignOff_RunAll(&quot;full&quot;)</code> using fixture data representative of production sizes.<br>3. Confirm <code>OperationalAudit</code> integration with modAudit and that every write carries a corresponding audit event.<br>4. Provide an "Emergency Override" policy and require at least two downstream approvals, logged and monitored. </td></tr></tbody></table></div><div class="row-count">Rows: 30</div></div><div class="table-caption" id="Table2" data-table="Docu_0193_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modEdgeCaseHandler — Per-function technical breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modEdgeCaseHandler — Per-function technical breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Module overview — modEdgeCaseHandler (purpose, scope, and integration contract):</strong><br><strong>Purpose:</strong> centralised VBA module responsible for deterministic handling, canonical classification, controlled escalation, and auditable resolution of payroll reconciliation edge-cases that cannot be fully resolved by the standard ingestion, sampling, matching, and reconciliation pipelines. This module ensures that the pipeline remains auditable, reproducible, and conservative (i.e., does not auto-resolve ambiguous situations without explicit confidence thresholds or human approvals).<br><strong>Scope:</strong> functions for detecting and classifying off-cycle payments, payrun reversals, aggregated remittance matches, multi-currency splits, split-net payments, combined ledger entries, and other exceptions that must either be resolved with special logic or escalated to manual review. The module also manages evidence movement when merging records, annotates reconciliation plans, and emits structured audit events to <code>modAudit.AppendAudit</code> and <code>OperationalAudit</code> to preserve the forensic chain.<br><strong>Integration contract:</strong> invoked by <code>ReconciliationEngine</code> (on candidate ambiguous matches), <code>AnomalyDetector</code> (when specific anomaly types imply edge-case handling), <code>AuditExport</code> (to include edge-case notes in deliverables), and <code>modControls.AttemptClose</code> (to ensure any open edge-case remediation is visible before close). Uses shared resources: <code>Population</code> sheet, <code>Bank</code> normalized table, <code>EvidenceIndex</code>, <code>SignOff</code> ledger, <code>SamplingAudit</code>, <code>SamplingConfigSnapshot</code>, <code>FXRates</code> table, <code>OperationalAudit</code>. Exports: <code>EdgeCaseLog</code>, <code>EdgeCaseTrace</code> (detailed step-by-step trace for each edge-case), <code>EdgeCaseResolution</code> (final state), and <code>EdgeCaseManifest</code> (for inclusion in deliverables).<br><strong>Non-functional expectations:</strong> robust logging (append-only), idempotent operations where possible, small memory footprint, and deterministic behaviour (when given the same inputs and configuration, produce the same outputs).<br><strong>Validation:</strong> configuration-driven thresholds (e.g., <code>AggregatedRemitTolerancePct</code>, <code>ReversalDateWindowDays</code>, <code>MultiCurrencySplitTolerance</code>) must be loaded from <code>SamplingConfigSnapshot</code> or a <code>PolicySnapshot</code> sheet. All actions that change artifacts must call <code>modAudit.AppendAudit</code> with <code>CorrelationID</code>. The module never deletes evidence; it only rebinds or marks evidence as moved and writes provenance entries. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: InitializeEdgeCaseRules(policySnapshotName As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Load and validate edge-case rules, thresholds, and escalation matrices into an in-memory rules dictionary used by other functions in this module.<br><strong>Inputs:</strong> <code>policySnapshotName</code> — name of the sheet or config snapshot containing rule definitions and policy thresholds.<br><strong>Outputs:</strong> <code>True/False</code> success boolean and internal memory structures: <code>EdgeCaseRules</code> (dictionary keyed by RuleID), <code>EscalationMatrix</code> (roles and thresholds), <code>SeverityMap</code> (map of RuleID -> severity numeric 1..5). Writes a <code>EdgeCaseRulesLoadLog</code> row with time and counts.<br><strong>Invariants:</strong> All rules must include <code>RuleID</code>, <code>Description</code>, <code>Severity</code>, <code>AutoResolveAllowed</code> (Boolean), <code>ConfidenceThreshold</code> (0..1), and <code>EscalationRole</code>. Failure to load or validate the snapshot causes the module to refuse to auto-resolve any case and to log a high-severity control event.<br><strong>Failure modes & recovery:</strong> Missing or malformed snapshot => write <code>EdgeCaseRulesError</code> to <code>OperationalAudit</code> and return <code>False</code>. Partial load with missing fields => load safe defaults and mark affected rules as manual-only. Provide a fallback to built-in conservative default ruleset embedded as a read-only table in the workbook.<br><strong>Implementation notes:</strong><br>1. Load the sheet row-by-row and coerce types; record parsing issues in <code>EdgeCaseRulesParseLog</code>.<br>2. Implement fuzzy matching of rule names to maintain backward-compatibility with older snapshots.<br>3. Cache <code>EdgeCaseRules</code> in a module-level dictionary and reset only when <code>InitializeEdgeCaseRules</code> is invoked again.<br><strong>Observability:</strong> <code>EdgeCaseRulesLoadLog</code> with timestamp, operator, parsed rules count, defaults-used count.<br><strong>Testing:</strong> Tests include malformed snapshot, missing severity, and conflicting escalation role scenarios. Validate that when rules are conservative-only, <code>AutoResolveAllowed=False</code> is respected by <code>AttemptResolveEdgeCase</code>.<br><strong>Conceptual PQ note:</strong> a Power Query query could pre-validate rule snapshots and produce a <code>RulesValidationReport</code> table consumed by this function. PQ steps: import snapshot -> promote headers -> validate columns -> emit <code>MissingColumns</code> table.<br><strong>Conceptual DAX note:</strong> Expose <code>CountAutoResolvingRules = COUNTROWS(FILTER(EdgeCaseRulesTable,EdgeCaseRulesTable[AutoResolveAllowed]=TRUE))</code> for dashboard coverage metrics.<br><strong>Example:</strong> Policy sheet lacks <code>ConfidenceThreshold</code> for <code>AGGREGATED_REMIT</code> rule; function loads with default 0.85 and logs default substitution. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: ClassifyEdgeCase(sampleRec As Dictionary) As Collection</strong> — <strong>Purpose & contract:</strong> Examine a single sampled payment (or reconciliation attempt context) and return a collection of <code>EdgeCaseCandidate</code> records, each describing a detected special-case type, its computed evidence, and recommended action (auto-resolve, manual review, escalate).<br><strong>Inputs:</strong> <code>sampleRec</code> — dictionary containing payment-level fields (<code>PaymentID</code>, <code>EmployeeID</code>, <code>GrossAmount</code>, <code>TotalDeductions</code>, <code>CalculatedNet</code>, <code>Currency</code>, <code>PaymentDate</code>, <code>CandidateBankMatches</code> array, <code>PayRunMeta</code>, <code>HistoricalStats</code>).<br><strong>Outputs:</strong> Collection of <code>EdgeCaseCandidate</code> objects with fields: <code>CaseID</code>, <code>RuleID</code>, <code>ConfidenceScore</code> (0..1), <code>SuggestedAction</code> (<code>AutoResolve</code>/<code>ManualReview</code>/<code>Escalate</code>), <code>Rationale</code> (text narrative), <code>EvidencePointers</code> (list of sheet references), <code>ProposedResolutionPlan</code> (structured plan), <code>Severity</code> (1..5). Writes a summary row to <code>EdgeCaseLog</code> for traceability.<br><strong>Invariants:</strong> Each candidate must reference the rule that triggered it and provide at least one piece of evidence pointer; <code>ConfidenceScore</code> must be computed consistently using <code>EdgeCaseRules</code> weights.<br><strong>Failure modes & recovery:</strong> Missing historical stats or candidate bank matches may reduce confidence; in such cases, the function should return candidates with <code>SuggestedAction=&#x27;ManualReview&#x27;</code> and annotate missing evidence. If classification fails entirely, append a <code>ClassificationError</code> entry to the <code>EdgeCaseLog</code> and escalate to the <code>Analyst</code> role.<br><strong>Implementation notes:</strong><br>1. Rule evaluation engine: evaluate each configured rule against <code>sampleRec</code> and compute a per-rule raw score using sub-criteria (amount proximity, date lag, text-match score, employee reference match, prior-history frequency). Normalize raw scores to <code>[0,1]</code> and adjust by rule <code>ConfidenceThreshold</code> and <code>AutoResolveAllowed</code> flag.<br>2. Maintain consistent weighting scheme stored in <code>EdgeCaseRules</code> to ensure repeatability. Document the weighting formula in <code>EdgeCaseRulesLoadLog</code> for forensics.<br>3. For aggregated remittance detection, compute <code>aggregationCandidateSet = FIND_GROUPS(populationCandidates, bankRow.Amount, tolerantSumWindow)</code> and set <code>Confidence</code> based on closeness of sum and number of plausible combinations (fewer combinations -> higher confidence).<br><strong>Observability:</strong> Create <code>EdgeCaseClassificationTrace</code> with per-rule intermediate values used in the scoring (amountProximityScore, dateProximityScore, textScore, historicalZScore).<br><strong>Testing:</strong> Unit tests: off-cycle single large bonus, reversal with negative net, aggregated bank row with sum of two nets equals bank amount within tolerance. Validate that classification proposals align with <code>EdgeCaseRules</code>.<br><strong>Conceptual PQ note:</strong> PQ can precompute candidate groups for aggregated remittance detection to reduce combinatorial explosion before VBA grouping is attempted; PQ steps: generate <code>PotentialAggregates</code> query that groups candidate population rows by date proximity and amount buckets. <br><strong>Conceptual DAX note:</strong> Provide metrics to summarize classified cases: <code>EdgeCaseRate = DIVIDE(COUNTROWS(EdgeCaseLog),[SampleCount])</code> and <code>AutoResolveableRate = DIVIDE(CALCULATE(COUNTROWS(EdgeCaseLog),EdgeCaseLog[SuggestedAction]=&quot;AutoResolve&quot;),COUNTROWS(EdgeCaseLog))</code>.<br><strong>Example:</strong> Payment has <code>CalculatedNet=4200</code>, bank contains one 4200 matched row but with <code>PaymentDate</code> 30 days later and <code>BankReference</code> blank -> <code>ClassifyEdgeCase</code> yields <code>RuleID=DATE_LAG</code> (confidence 0.42), <code>RuleID=REFERENCE_MISSING</code> (0.60) -> overall <code>ManualReview</code>. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: AttemptResolveEdgeCase(caseCandidate As Dictionary, allowAuto As Boolean) As Dictionary</strong> — <strong>Purpose & contract:</strong> Attempt to automatically resolve edge-cases when safe: e.g., apply multi-currency conversions using <code>modFX</code>, detect and combine split payments that clearly add to a single bank row, or re-link a reversal when original payment is unambiguously identified. Returns final resolution or structured escalation record.<br><strong>Inputs:</strong> <code>caseCandidate</code> — one <code>EdgeCaseCandidate</code> (from <code>ClassifyEdgeCase</code>), <code>allowAuto</code> — boolean from orchestration indicating whether auto-resolve is permitted in current run.<br><strong>Outputs:</strong> <code>resolution</code> dictionary with fields: <code>Resolved</code> (Boolean), <code>ResolutionType</code> (<code>AutoAdjusted</code>/<code>Linked</code>/<code>GroupMatched</code>/<code>Escalated</code>), <code>AppliedActions</code> (list of actions taken), <code>NewProvenance</code> (evidence pointers), <code>PreResolutionState</code> and <code>PostResolutionState</code> summaries, <code>FailureReason</code> (if any). Writes <code>EdgeCaseResolution</code> row and produces <code>EdgeCaseTrace</code> detailed steps.<br><strong>Invariants:</strong> Auto-resolution only proceeds if <code>caseCandidate.ConfidenceScore &gt;= EdgeCaseRules(RuleID).ConfidenceThreshold</code> and <code>EdgeCaseRules(RuleID).AutoResolveAllowed = True</code> and <code>allowAuto=True</code>. All changes must be logged and reversible (store pre-resolution copies).<br><strong>Failure modes & recovery:</strong> If an attempted auto-resolve produces inconsistencies (e.g., population totals no longer reconcile), rollback changes and write a <code>ResolutionRollback</code> event. If FX conversion rates are missing, fallback to nearest-date rate if allowed; otherwise escalate. If grouping for aggregated remittance yields multiple equally plausible partitions, do not auto-resolve — escalate with candidate partitions documented.<br><strong>Implementation notes:</strong><br>1. Use two-phase commit pattern: 1) Validate preconditions and generate <code>proposedChanges</code> in memory; 2) Apply changes to temporary snapshot sheets or hidden staging area; 3) Validate reconciliation invariants; 4) Commit changes by writing to production sheets and append audit entries. If any step fails, perform rollback from staging. <br>2. For multi-currency: call <code>modFX.NormalizeCurrency</code> for each component and compute aggregate; compare to bankRow in base currency; if within tolerance and <code>Confidence &gt;= threshold</code>, link and annotate <code>EdgeCaseResolution</code> with <code>AppliedRate</code> and <code>RateDateUsed</code>. <br>3. For split-net payments that together match a single bank row: sort candidate population rows by key heuristics (same <code>PayRunID</code>, same <code>BankReference</code> tokens, proximate dates) and attempt smallest cardinality grouping that meets <code>bank.Amount</code> within tolerance. Limit combination search by <code>MaxGroupSize</code> (configurable) to constrain compute cost. <br>4. Always compute and persist <code>ResolutionHash</code> (SHA256 over pre+post JSON) to provide tamper-evidence. <br><strong>Observability:</strong> <code>EdgeCaseResolutionTrace</code> with timing per step, memory usage, candidate combinations tried, applied FX rates, and any fallbacks. <br><strong>Testing:</strong> Simulate auto-resolve success, partial success with rollback, missing FX rate, and ambiguous aggregated remittance leading to escalation. <br><strong>Conceptual PQ note:</strong> PQ can pre-group likely split payments and provide candidate groupings ranked by likelihood to VBA so that <code>AttemptResolveEdgeCase</code> only evaluates top-N partitions. PQ steps: precompute <code>GroupCandidates</code> by <code>EmployeeID</code>, <code>PayRunID</code>, <code>approxAmountBucket</code> and output top-K candidates. <br><strong>Conceptual DAX note:</strong> After reweighting, compute <code>EstimatedPopulationNetAfterAutoResolves = SUMX(Population, Population[NetPaid] * IF(Population[PaymentID] in AutoResolvedIDs,1,1))</code> to compare totals before/after auto-resolve. <br><strong>Example:</strong> Two population rows 2,100 and 2,100 sum to 4,200; bank row 4,200 exists on same date; <code>AttemptResolveEdgeCase</code> groups them, marks bank row as grouped match, writes provenance linking both population rows to bankRowID, and computes weights. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: FindOriginalPaymentForReversal(reversalRec As Dictionary) As Dictionary</strong> — <strong>Purpose & contract:</strong> Attempt to locate the original payment that a reversal refers to by using multi-criteria search (amount magnitude, payrun sequence, employee id/name match, ledger references), returning a single <code>OriginalPayment</code> pointer if unambiguous or list of candidates otherwise.<br><strong>Inputs:</strong> <code>reversalRec</code> — dictionary including <code>PaymentID</code>, <code>ReversalAmount</code>, <code>ReversalDate</code>, <code>PayRunID</code>, <code>Notes</code> (text).<br><strong>Outputs:</strong> <code>result</code> dictionary with <code>Found</code> Boolean, <code>OriginalPaymentID</code> (if unique), <code>CandidateList</code> (if ambiguous), <code>ConfidenceScore</code>, <code>SearchTrace</code> (criteria & matches). Writes <code>ReversalMatchLog</code> row with trace.<br><strong>Invariants:</strong> The function must prefer exact negative-amount mirror matches within <code>ReversalWindowDays</code> and identical <code>PayRunID</code> pattern; must respect reversals in a different period (e.g., reversal posted in subsequent month) by allowing date window config. If reversal contains explicit reference to original (e.g., <code>OrigRef: 12345</code>) and that reference exists, it must be used as a priority match.<br><strong>Failure modes & recovery:</strong> If no candidates found, return <code>Found=False</code> and create an <code>EscalationAction</code> recommending manual evidence (payrun journal, reversal memo). If multiple candidates have the same highest confidence, return candidate list and <code>ConfidenceScore</code> reflecting ambiguity; do not auto-link.<br><strong>Implementation notes:</strong><br>1. Scoring components: absolute amount match (exact match weight high), employee reference match (exact or fuzzy), date proximity (higher for close dates), payrun linking (if reversal shares payrunSequence or payrun metadata). <br>2. Use text similarity metrics for <code>Notes</code> field scanning against payment memo fields when explicit references are not present; apply a threshold for fuzzy match to avoid false positives. <br>3. If <code>Found=True</code>, create pre-link audit row in <code>EdgeCaseResolution</code> and require <code>modSignOff</code> approval when <code>Severity &gt;= 4</code>. <br><strong>Observability:</strong> <code>ReversalMatchTrace</code> with per-candidate scores and decision rationale. <br><strong>Testing:</strong> Cases: explicit reference present; reversal amount equals original net but posted later; reversal posted without reference but with identical gross and deductions; ambiguous reversal with two potential originals -> returns candidate list. <br><strong>Conceptual PQ note:</strong> PQ can precompute a <code>PayrunLinkMap</code> (payrun sequence to payments) that speeds up original search. <br><strong>Conceptual DAX note:</strong> <code>ReversalResolutionRate = DIVIDE(CALCULATE(COUNTROWS(EdgeCaseResolution),EdgeCaseResolution[RuleID]=&quot;REVERSAL&quot;),COUNTROWS(Filter(EdgeCaseLog,EdgeCaseLog[RuleID]=&quot;REVERSAL&quot;)))</code> for reporting. <br><strong>Example:</strong> Reversal row -2,100 on 2025-12-15 references memo "Correction for 78910" -> function finds PaymentID 78910 exact match and returns <code>Found=True</code> with <code>Confidence=0.99</code>. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: GroupAggregatedRemittance(bankRow As Dictionary, candidatePopulation As Collection) As Collection</strong> — <strong>Purpose & contract:</strong> Identify one or more groups of population payments that plausibly map to a single aggregated bank remittance row. Return ordered candidate groupings with confidence scores and a recommended primary grouping (if one clearly outperforms others).<br><strong>Inputs:</strong> <code>bankRow</code> — bank transaction with <code>Amount</code>, <code>Date</code>, <code>ReferenceText</code>, <code>Currency</code>; <code>candidatePopulation</code> — collection of population rows within the configured date-window and amount buckets.<br><strong>Outputs:</strong> Collection of <code>GroupCandidate</code> objects with <code>GroupID</code>, <code>MemberPaymentIDs</code>, <code>GroupSum</code>, <code>AmountDiff</code>, <code>DateRange</code>, <code>Score</code>, <code>Rationale</code>. Optionally write <code>AggregatedMatchCandidates</code> sheet for auditor review.<br><strong>Invariants:</strong> Sum of group members should match bankRow amount within <code>AggregatedRemitTolerancePct</code> or <code>AggregatedRemitAbsoluteTolerance</code>. Limit group cardinality per policy to prevent combinatorial explosion. Provide candidate ranking and never auto-commit a grouping when multiple tie within epsilon.<br><strong>Failure modes & recovery:</strong> If combination space is large, apply heuristics to reduce candidates: sort by descending payment amounts and attempt greedy subset-sum; cluster by <code>EmployeeID</code>, <code>PayRunID</code>, and <code>BankReference</code> token. If heuristics yield no grouping, emit <code>AggregatedRemitUnableToMatch</code> event and escalate to manual matching. <br><strong>Implementation notes:</strong><br>1. Candidate reduction heuristics: remove population rows with amounts outside <code>bankRow.Amount ± MaxIndividualTolerance</code>; group by <code>EmployeeID</code> tokens; prefer groups with matching <code>BankReference</code> tokens. <br>2. Use bounded subset-sum algorithm with backtracking and pruning: attempt smallest cardinality groups first and stop when a strong match is found. <br>3. For performance, require <code>candidatePopulation</code> to be pre-sorted and limit to top-N by proximity. <br>4. Always compute and return <code>MatchConfidence</code> which blends amount diff, reference token overlap, date proximity, and group cardinality penalty. <br><strong>Observability:</strong> <code>AggregatedMatchingPerf</code> log capturing number of combinations attempted, time spent, and top-N candidate details. <br><strong>Testing:</strong> Create bank row equal to sum of 3 small nets; test that grouping returned correct members; test large candidate set and validate performance limits and escalation condition. <br><strong>Conceptual PQ note:</strong> Precompute <code>AmountBucket</code> and <code>ReferenceTokens</code> in PQ to reduce VBA candidate selection size. PQ steps: unpivot payment components -> compute payment-level net -> assign amount buckets -> emit <code>PotentialAggregates</code> query. <br><strong>Conceptual DAX note:</strong> <code>AggregatedRemitCandidateCount = COUNTROWS(AggregatedMatchCandidates)</code> and <code>AggregatedResolvedRate = DIVIDE(CALCULATE(COUNTROWS(EdgeCaseResolution),EdgeCaseResolution[ResolutionType]=&quot;GroupMatched&quot;),[AggregatedRemitCandidateCount])</code> for dashboards. <br><strong>Example:</strong> Bank row 12,600 dated 2026-01-25 matches candidate population rows 4,200; 4,200; 4,200 -> group found with <code>Score=0.92</code>. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: ResolveMultiCurrencySplit(splitCandidates As Collection, bankRow As Dictionary) As Dictionary</strong> — <strong>Purpose & contract:</strong> Handle cases where a population payment is split across currencies or the bank payment was made in a different currency and applied via per-component FX rates. Returns resolution metadata including applied rates, conversion methodology, and residual variance.<br><strong>Inputs:</strong> <code>splitCandidates</code> — collection of payment components with original currency fields; <code>bankRow</code> — bank payment in a particular currency.<br><strong>Outputs:</strong> <code>resolution</code> containing <code>ConvertedComponents</code> (amounts converted to bank currency), <code>AppliedRates</code> array (rate and date used), <code>Residual</code> (amount difference), <code>ConfidenceScore</code>, <code>SuggestedAction</code>. Writes <code>MultiCurrencyResolution</code> row and <code>FXUsageLog</code> entries for each conversion used.<br><strong>Invariants:</strong> Applied rates must come from <code>FXRates</code> table, with fallback logic (nearest prior date or cross-rate via base currency) clearly documented. If conversions rely on fallback, mark <code>Confidence</code> lower and require manual approval for high-value items. <br><strong>Failure modes & recovery:</strong> Missing FX rate for the currency/date pair -> nearest-date fallback or compute cross-rate using base currency rates; if cross-rate not possible -> escalate. Precision/rounding differences must be handled deterministically using configured rounding policy (e.g., round-half-even to cents). <br><strong>Implementation notes:</strong><br>1. For each component: call <code>modFX.NormalizeCurrency(amount, currencyCode, bankRow.Date, FXRatesTable)</code> and capture <code>RateDateUsed</code> and <code>RateSource</code>. <br>2. Compute <code>ConvertedSum</code> = sum of converted components; compute <code>Residual = bankRow.Amount - ConvertedSum</code>; compute <code>ResidualPct = ABS(Residual) / bankRow.Amount</code>. If <code>ResidualPct &lt;= MultiCurrencyTolerancePct</code>, treat as resolved. <br>3. Attach evidence showing applied rates and rate dates in <code>EdgeCaseResolution</code> for auditors. <br><strong>Observability:</strong> <code>FXUsageLog</code> entries and <code>MultiCurrencyResolutionTrace</code> showing per-component conversions and cumulative rounding effects. <br><strong>Testing:</strong> Test direct pair rate present, missing direct pair requiring cross-rate, and rounding edge-case where residual is a single cent due to rounding direction. <br><strong>Conceptual PQ note:</strong> PQ should load the FX table with validated timestamps and possibly compute daily mid-market rates used by VBA to avoid multiple lookups. <br><strong>Conceptual DAX note:</strong> <code>FXAdjustmentImpact = SUMX(MultiCurrencyResolutions,ABS(MultiCurrencyResolutions[Residual]))</code> to quantify exposure. <br><strong>Example:</strong> Payment of 1,000 EUR + 500 GBP mapped to USD bank row: conversions applied using EUR->USD 1.08 (2026-01-14), GBP->USD 1.24 (2026-01-14), converted sum = 1,080 + 620 = 1,700; bankRow = 1,699.97 -> <code>Residual= -0.03</code> -> <code>Resolved</code> if tolerance >= 0.002 (0.2%). </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: AnnotateReconciliationPlan(sampleID As String, resolution As Dictionary) As Boolean</strong> — <strong>Purpose & contract:</strong> Translate the resolution outcome (auto or manual) into a structured reconciliation plan that the <code>ReconciliationEngine</code> and <code>AuditExport</code> will include in the SampleReconciliation sheet. The plan includes step-by-step actions, required evidence, sign-off roles, and follow-up deadlines.<br><strong>Inputs:</strong> <code>sampleID</code>, <code>resolution</code> dictionary produced by resolution functions.<br><strong>Outputs:</strong> Writes an <code>EdgeCaseActionPlan</code> record with fields: <code>PlanID</code>, <code>SampleID</code>, <code>Actions</code> (ordered list with owners and deadlines), <code>RequiredEvidenceList</code>, <code>EscalationSteps</code>, <code>SignOffRequirements</code>, <code>Status</code>. Returns <code>True</code> on successful annotation. Also writes to <code>EdgeCasePlanIndex</code> for the sample.<br><strong>Invariants:</strong> If <code>resolution.SuggestedAction = Escalate</code>, plan must include <code>EscalationSteps</code> with <code>EscalationRole</code> and <code>SLAs</code> derived from <code>EscalationMatrix</code>. If <code>AutoResolved</code>, plan must still include the <code>Pre+Post</code> state and a <code>SignOffRequirement</code> if severity above configured threshold.<br><strong>Failure modes & recovery:</strong> If <code>resolution</code> lacks required fields (e.g., evidence pointers), the function rejects plan creation and logs <code>PlanCreationError</code>. Provide helper default plan templates to ensure no sample remains without actionable steps. <br><strong>Implementation notes:</strong><br>1. Build templated action sequences with placeholders filled from <code>resolution</code> and <code>EdgeCaseRules</code>. <br>2. Use deterministic deadlines computed from <code>NowUTC + SLA_Days</code> stored in policy snapshot. <br>3. Add links from the plan to <code>EvidenceIndex</code> and <code>SampleReconciliation</code> rows for audit navigation. <br><strong>Observability:</strong> <code>EdgeCasePlanIndex</code> with counts of open plans, overdue items, and responsible owners for dashboarding. <br><strong>Testing:</strong> Validate that plans include correct owners and escalate when required; verify links resolve in <code>AuditExport</code>. <br><strong>Conceptual PQ note:</strong> PQ can generate printable action lists grouped by owner to expedite remediation workflows for auditors. <br><strong>Conceptual DAX note:</strong> <code>OpenEdgeCasePlansByOwner = COUNTROWS(FILTER(EdgeCasePlanIndex,EdgeCasePlanIndex[Owner]=SelectedOwner &amp;&amp; EdgeCasePlanIndex[Status]=&quot;Open&quot;))</code>. <br><strong>Example:</strong> Auto-resolve group matched -> Plan includes <code>Action: Verify linked bank remittance (Analyst)</code>, <code>SignOff: Head of Payroll required if total &gt; 10k</code>, deadline 7 days. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: MergeEvidenceToPrimary(primarySampleID As String, secondarySampleIDs As Collection, operatorId As String) As Boolean</strong> — <strong>Purpose & contract:</strong> When analyst merges duplicate samples or consolidates split payments into a primary payment, rebind supporting evidence records to the primary sample, preserve provenance, and never destroy original evidence rows; produce an immutable merge record in <code>EdgeCaseLog</code> for traceability.<br><strong>Inputs:</strong> <code>primarySampleID</code>, <code>secondarySampleIDs</code> (collection of sample IDs being merged), <code>operatorId</code> for audit attribution.<br><strong>Outputs:</strong> <code>True/False</code> and writes <code>MergeEvent</code> to <code>EdgeCaseLog</code> with <code>MergeID</code>, <code>PrimarySampleID</code>, <code>SecondarySampleIDs</code>, <code>EvidenceMoved</code> list, <code>Timestamp</code>, <code>OperatorID</code>, and <code>MergeHash</code>. Update <code>EvidenceIndex</code> rows to reference <code>PrimarySampleID</code> while preserving <code>OriginalPointer</code> fields. Optionally, mark secondary sample rows as <code>Deprecated</code> but do not delete them. <br><strong>Invariants:</strong> Evidence must have two pointers after merge: <code>CurrentBinding</code> and <code>OriginalBindings</code> array. Merge is append-only; no evidence data is ever truncated. All changes must be reversible by applying an audited compensation action (which itself is written to <code>EdgeCaseLog</code>).<br><strong>Failure modes & recovery:</strong> If file copy fails (when embedding evidence to EvidenceArchive), record <code>EvidenceMoveFailed</code> and leave evidence bound to both primary and secondary as read-only pointers until operator resolves. If operator lacks permission, function fails with <code>ERR_MERGE_UNAUTHORIZED</code>. <br><strong>Implementation notes:</strong><br>1. Validate operator permissions by calling <code>modControls.EnforceExportPermissions</code> or equivalent RBAC check. <br>2. For each evidence pointer: compute SHA256, copy file into <code>EvidenceArchive/&lt;MergeID&gt;/</code> if archive copy configured, update EvidenceIndex with <code>CurrentBinding=PrimarySampleID</code> and append to <code>OriginalBindings</code>. <br>3. Create human-readable <code>MergeSummary</code> row summarizing counts and sizes of evidence moved. <br><strong>Observability:</strong> <code>MergeAudit</code> with operator, timestamp, and counts; <code>EvidenceIntegrityChecks</code> to detect missing files post-merge. <br><strong>Testing:</strong> Merge multiple small PDFs and images; attempt merge with missing external file (should flag move failure); test unauthorized operator. <br><strong>Conceptual PQ note:</strong> PQ should not carry evidence but can produce pre-merge lists to help the analyst select merge candidates. <br><strong>Conceptual DAX note:</strong> <code>EvidenceBindingsPerSample = COUNTROWS(FILTER(EvidenceIndex,EvidenceIndex[CurrentBinding]=SelectedSample))</code>. <br><strong>Example:</strong> Merge secondary sample IDs S-02 and S-03 into S-01; three PDFs copied into <code>EvidenceArchive/MERGE-20260212-01</code>, EvidenceIndex updated with <code>OriginalBindings</code> preserved, merge event written. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: EscalateEdgeCase(caseID As String, escalationReason As String, requiredApprovals As Collection) As Boolean</strong> — <strong>Purpose & contract:</strong> Create an explicit escalation artifact and record required approvers, emit notifications (via <code>modRemind</code>/email manifest), and lock the sample from accidental auto-resolution until required approvals are captured and attached sign-offs are present.<br><strong>Inputs:</strong> <code>caseID</code>, <code>escalationReason</code> (text), <code>requiredApprovals</code> (collection of role identifiers or userIDs).<br><strong>Outputs:</strong> <code>True/False</code> and writes <code>EscalationRecord</code> with <code>EscalationID</code>, <code>CaseID</code>, <code>Reason</code>, <code>Approvers</code>, <code>EscalationTimestamp</code>, <code>EscalationStatus</code> (<code>Pending</code>), and <code>LockToken</code>. Creates <code>EscalationTasks</code> for each required approver assigned to their owners. Triggers <code>AppendAudit</code> events for each created task. <br><strong>Invariants:</strong> While <code>EscalationStatus=&quot;Pending&quot;</code>, the sample is write-protected for auto-resolve; only sign-off operations or explicit <code>ReleaseEscalation</code> with adequate approvals can change state. Every created <code>EscalationRecord</code> must include <code>CorrelationID</code>. <br><strong>Failure modes & recovery:</strong> If required approvers are not found in RBAC store, append a <code>MissingApprover</code> warning and assign to <code>DefaultEscalationRole</code>. If notifications fail to send, retry with exponential backoff and log failures to <code>EscalationDeliveryLog</code>. <br><strong>Implementation notes:</strong><br>1. Use <code>modAudit.AppendAudit</code> to write tasks and to ensure notifications are auditable. <br>2. Create <code>EscalationDashboard</code> slice for operator overview of pending escalations. <br>3. Optionally include a <code>DelegationPolicy</code>: if approver unavailable > SLA, escalate to backup approver. <br><strong>Observability:</strong> <code>EscalationMetrics</code> with counts by role, average resolution time, and outstanding locked cases. <br><strong>Testing:</strong> Simulate escalation requiring HeadOfPayroll sign-off and ensure sample is locked, notifications sent, and approvals recorded change status to <code>Resolved</code>. <br><strong>Conceptual PQ note:</strong> PQ can produce a nightly <code>PendingEscalations</code> list for operational teams to triage. <br><strong>Conceptual DAX note:</strong> <code>OutstandingEscalations = COUNTROWS(FILTER(EscalationRecord,EscalationRecord[EscalationStatus]=&quot;Pending&quot;))</code>. <br><strong>Example:</strong> <code>EscalateEdgeCase(&quot;CASE-666&quot;,&quot;Multiple ambiguous bank matches for large severance&quot;,[&quot;HeadPayroll&quot;,&quot;HeadFinance&quot;])</code> creates tasks and locks sample until both signoffs recorded. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: ValidateResolutionPreClose(runID As String) As Collection</strong> — <strong>Purpose & contract:</strong> Called by <code>modControls.AttemptClose</code> to validate all edge-case resolutions for a given run are completed or acceptable for close. Returns an array of blocking items (if any) and a <code>CloseReadiness</code> object summarising counts and blocking severity.<br><strong>Inputs:</strong> <code>runID</code> linking to sampling run artifacts and <code>EdgeCasePlanIndex</code> entries created during that run.<br><strong>Outputs:</strong> <code>CloseReadiness</code> with <code>IsReady</code> (Boolean), <code>BlockingItems</code> collection (each with <code>SampleID</code>, <code>BlockReason</code>, <code>Severity</code>, <code>RemediationAction</code>), <code>SummaryCounts</code>, and <code>AuditRow</code> (to write into <code>RunAuditLog</code>). Writes <code>EdgeCasePreCloseReport</code> sheet and appends audit events for close validation.<br><strong>Invariants:</strong> Blocking items include unresolved escalations, open plans past SLA, auto-resolutions lacking required sign-offs, and any <code>EdgeCaseResolution</code> that used fallback FX rates with high severity. If <code>IsReady=False</code>, <code>AttemptClose</code> must not proceed unless override recorded and authorized. <br><strong>Failure modes & recovery:</strong> If validation cannot access a required sheet, return <code>IsReady=False</code> with <code>ERR_PRE_CLOSE_IO</code> block and instruct operator to resolve IO. Provide explicit remediation steps in each blocking item. <br><strong>Implementation notes:</strong><br>1. The function should be idempotent and safe to run multiple times; produce the same <code>BlockingItems</code> unless state changes. <br>2. Compute a <code>RiskScore</code> per blocking item to allow modControls to make an informed override decision. <br>3. If <code>IsReady=True</code>, include <code>EdgeCaseResolutionSummary</code> in the <code>DeliverablesManifest</code>. <br><strong>Observability:</strong> <code>EdgeCasePreCloseReport</code> with counts by severity and list of items for manual triage. <br><strong>Testing:</strong> Pre-close where some required signoffs missing; test override flows and check audit recordings. <br><strong>Conceptual PQ note:</strong> PQ can compute <code>OpenPlansBySLA</code> summary that VBA consumes to speed validation. <br><strong>Conceptual DAX note:</strong> <code>PreCloseBlockingCount = COUNTROWS(Filter(EdgeCasePreCloseReport,EdgeCasePreCloseReport[IsBlocking]=TRUE))</code>. <br><strong>Example:</strong> <code>ValidateResolutionPreClose(&quot;RUN-20260212-01&quot;)</code> returns two blocking items: <code>CASE-101</code> (head sign-off missing) severity 4, <code>CASE-205</code> (aggregated remittance ambiguous) severity 5. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: BuildEdgeCaseReport(runID As String, outputSheetName As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Produce auditor-facing narrative and enumerated report of all edge-cases in a run, including classification, resolution status, audit trails, applied FX, candidate partitions for aggregated remittances, and recommended follow-up steps. This output is optimized for export to <code>AuditExport</code> and for inclusion in the PDF deliverable.<br><strong>Inputs:</strong> <code>runID</code>, <code>outputSheetName</code>.<br><strong>Outputs:</strong> Sheet <code>outputSheetName</code> with structured sections: Executive Summary, Case List (paginated), Deep Dives (per high-severity case), Evidence Index, Methodology Notes, and embedded <code>EdgeCaseManifest</code> linking to artifacts. Returns <code>True/False</code> and writes <code>EdgeCaseReportManifest</code> to <code>DeliverablesManifest</code> for later export. <br><strong>Invariants:</strong> Each case must include <code>CaseID</code>, <code>RuleIDs</code>, <code>InitialConfidence</code>, <code>FinalResolution</code>, <code>ResolutionHash</code>, and <code>AuditTrailPointer</code>. High-severity cases must include a <code>RecommendedAction</code> block. <br><strong>Failure modes & recovery:</strong> If some data missing, write explanatory footnotes and include <code>DataMissing</code> section with remediation steps. If sheet creation fails due to space or sheet-name collision, create a timestamped alternative name. <br><strong>Implementation notes:</strong><br>1. Structure report to allow easy PDF pagination: each case deep-dive on a single or pair of pages, linkable bookmarks, and table-of-contents generated. <br>2. Include inline lists of PQ queries and DAX measures used to compute supplemental analytics — these are conceptual descriptions, not raw code snippets. <br>3. Compute and present key KPIs: <code>EdgeCaseCount</code>, <code>ResolvedAutoCount</code>, <code>PendingEscalations</code>, <code>AvgResolutionTime</code>. <br><strong>Observability:</strong> <code>EdgeCaseReportGenerationLog</code> with duration, row counts, and any warnings (e.g., missing evidence). <br><strong>Testing:</strong> Generate reports for runs with: no edge-cases, several low-severity edge-cases, and multiple high-severity cases requiring escalation. Validate PDF appearance after <code>AuditExport</code>. <br><strong>Conceptual PQ note:</strong> PQ can prepare the case exports (tables) that VBA merges into the report to ensure consistent formatting and avoid heavy per-cell VBA writing. PQ steps: aggregate <code>EdgeCase</code> table -> format columns -> export as <code>EdgeCaseExport</code> table. <br><strong>Conceptual DAX note:</strong> Provide KPIs for dashboards: <code>AvgEdgeCaseResolutionDays = AVERAGEX(EdgeCaseResolution,DATEDIFF(EdgeCaseResolution[Created],EdgeCaseResolution[Resolved],&quot;d&quot;))</code>. <br><strong>Example:</strong> BuildEdgeCaseReport produces <code>EdgeCaseReport_RUN-20260212-01</code> with 12 cases, three deep dives for severity >=4, and a manifest entry for PDF export. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: AppendEdgeCaseAudit(caseID As String, eventType As String, actorId As String, details As String, evidenceRefs As Variant) As String</strong> — <strong>Purpose & contract:</strong> Lightweight helper to centralize audit appends specifically for edge-case events; calls <code>modAudit.AppendAudit</code> with <code>Category=&quot;EdgeCase&quot;</code> and standardized detail schema; returns the generated EventID.<br><strong>Inputs:</strong> <code>caseID</code>, <code>eventType</code>, <code>actorId</code>, <code>details</code>, <code>evidenceRefs</code> (array or CSV).<br><strong>Outputs:</strong> <code>EventID</code> string and writes to <code>OperationalAudit</code> and <code>EdgeCaseLog</code> with category and correlation context. <br><strong>Invariants:</strong> All edge-case audit events must include <code>CaseID</code> and <code>CorrelationID</code> and be immutable once written. <br><strong>Failure modes & recovery:</strong> If <code>modAudit.AppendAudit</code> fails (VBE security or write-protection), attempt to write to <code>EdgeCaseAuditFallback</code> sheet and mark as unsent. Log <code>ERR_AUDIT_APPEND_FAIL</code>. <br><strong>Implementation notes:</strong><br>1. Standardize <code>details</code> JSON structure with fields: <code>CaseState</code>, <code>ActionTaken</code>, <code>Before</code>, <code>After</code>. <br>2. Leverage <code>modUtils.GenerateGUID</code> for EventID and include <code>NowUTC</code> timestamp. <br><strong>Observability:</strong> <code>EdgeCaseAuditIndex</code> with event counts per case and per eventType. <br><strong>Testing:</strong> Ensure audit persistency when <code>modAudit</code> is unavailable; validate fallback behavior. <br><strong>Conceptual PQ note:</strong> Not directly used, but PQ can surface audit event counts for nightly operations. <br><strong>Conceptual DAX note:</strong> <code>EdgeCaseAuditVolume = COUNTROWS(OperationalAudit)</code> filtered by <code>Category=&quot;EdgeCase&quot;</code>. <br><strong>Example:</strong> <code>AppendEdgeCaseAudit(&quot;CASE-101&quot;,&quot;MergeEvidence&quot;,&quot;analyst_jane&quot;,&quot;Merged 3 evidence items&quot;,&quot;EVID-1,EVID-2,EVID-3&quot;)</code> returns EventID <code>EVT-20260212-0001</code>. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: SerializeEdgeCaseState(caseID As String, outPath As String) As Boolean</strong> — <strong>Purpose & contract:</strong> Export a forensic snapshot of the edge-case (including pre/post states, candidate partitions, evidence hashes, audit trail, and resolution traces) into a signed JSON or zipped forensic bundle for external archive or legal discovery.<br><strong>Inputs:</strong> <code>caseID</code>, <code>outPath</code> (file path for bundle).<br><strong>Outputs:</strong> Forensic bundle file at <code>outPath</code>, returns <code>True</code> on success and writes <code>ForensicBundleIndex</code> row with <code>BundlePath</code>, <code>SHA256</code>, <code>GeneratedTimestamp</code>, <code>CaseID</code>. <br><strong>Invariants:</strong> Bundle must include <code>EdgeCaseResolution</code>, <code>EdgeCaseTrace</code>, <code>EvidencePointers</code> with SHA256 checks for each external file, <code>EdgeCaseRulesVersion</code>, and <code>SamplingConfigSnapshot</code> pointer. Bundles intended for legal archive should be signed (if signing infrastructure available) and stored in <code>Archive</code> folder. <br><strong>Failure modes & recovery:</strong> File system permissions, path collisions, or insufficient disk space -> write <code>ERR_FORNSIC_BUNDLE_IO</code> and create <code>MinimalBundle</code> with metadata only. If embedding big evidence objects would exceed size, include external pointers plus checksums and produce a <code>LargeEvidenceManifest</code>. <br><strong>Implementation notes:</strong><br>1. Use deterministic JSON serialization schema to ensure stable hashes; compute SHA256 over canonicalized JSON string. <br>2. Option to encrypt archive with a passphrase recorded in <code>SecurityApprovals</code> (if policy demands). <br>3. When copying external files, preserve original filenames and compute checksums. <br><strong>Observability:</strong> <code>ForensicBundleIndex</code> plus <code>ForensicBundlePerf</code> log with time and size. <br><strong>Testing:</strong> Export bundle with small evidence set; simulate insufficient disk space to force <code>MinimalBundle</code> path. <br><strong>Conceptual PQ note:</strong> PQ could create CSV or flat-table exports of related tables consumed by the forensic bundle to speed creation (offload heavy table serialization away from VBA). <br><strong>Conceptual DAX note:</strong> Not applicable directly; but bundles count in archival metrics: <code>ForensicBundlesThisMonth = COUNTROWS(ForensicBundleIndex WHERE Month=SelectedMonth)</code>. <br><strong>Example:</strong> <code>SerializeEdgeCaseState(&quot;CASE-205&quot;,&quot;C:\Archive\CASE-205-bundle.zip&quot;)</code> writes bundle and <code>ForensicBundleIndex</code> row. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: EmergencyOverride(caseID As String, operatorId As String, overrideReason As String, approvers As Collection) As Boolean</strong> — <strong>Purpose & contract:</strong> Controlled, auditable override mechanism allowing authorised operators to close an edge-case or proceed with a close despite blocking edge-cases; enforces two-person rule where configured, writes compensating control entries, and requires post-override forensic steps.<br><strong>Inputs:</strong> <code>caseID</code>, <code>operatorId</code>, <code>overrideReason</code>, <code>approvers</code> (must include at least one authorizer and one reviewer depending on policy).<br><strong>Outputs:</strong> <code>True/False</code>, writes <code>EmergencyOverrideEvent</code> to <code>EdgeCaseLog</code> and <code>OperationalAudit</code> with <code>OverrideID</code>, <code>Operator</code>, <code>Approvers</code>, <code>Reason</code>, <code>Timestamp</code>, and <code>CompensatingControls</code> list. If successful, releases <code>LockToken</code> and optionally sets <code>EdgeCaseResolution</code> status to <code>ClosedByOverride</code>.<br><strong>Invariants:</strong> Emergency override is only allowed when <code>EnforceOverridePolicy=True</code> and after verifying approvers match <code>EscalationMatrix</code> or <code>OverrideApprovers</code> policy. A full forensic bundle must be generated after override (call to <code>SerializeEdgeCaseState</code>).<br><strong>Failure modes & recovery:</strong> Unauthorized operator -> return <code>ERR_OVERRIDE_UNAUTHORIZED</code>. Missing approver signatures -> <code>ERR_OVERRIDE_APPROVAL_MISSING</code>. If override succeeds but subsequent forensic export fails, log <code>ERR_POST_OVERRIDE_FORNSIC_FAIL</code> and mark compensation required. <br><strong>Implementation notes:</strong><br>1. Implement a checklist verifying pre-conditions before applying override (operator identity verified, approvers validated, compensating controls documented). <br>2. Append a <code>CompensatingControls</code> artifact listing extra review steps and retention requirements. <br>3. Set an automated follow-up task with reduced SLA for post-override review. <br><strong>Observability:</strong> <code>OverrideMetrics</code> including count, average time to approval, and post-override findings. <br><strong>Testing:</strong> Attempt override with unauthorized operator; successful override with required approvers and generation of forensic bundle afterwards. <br><strong>Conceptual PQ note:</strong> PQ may generate lists of pending overrides for governance review. <br><strong>Conceptual DAX note:</strong> <code>OverridesThisFiscal = COUNTROWS(Filter(EdgeCaseLog,EdgeCaseLog[EventType]=&quot;EmergencyOverride&quot; &amp;&amp; EdgeCaseLog[Timestamp] In FiscalYear))</code>. <br><strong>Example:</strong> Analyst triggers <code>EmergencyOverride</code> for <code>CASE-301</code> with HeadOfAudit and HeadOfLegal approvals; override recorded and forensic bundle created. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: UnitTests_RunEdgeCaseHandler(testMode As String) As Collection</strong> — <strong>Purpose & contract:</strong> Built-in unit/integration tests focused on <code>modEdgeCaseHandler</code> functions to validate behavior against fixtures; supports <code>quick</code>, <code>full</code>, and <code>stress</code> modes; results written to <code>TestResults</code> and a test fixture snapshot to <code>TestArtifacts</code>.<br><strong>Inputs:</strong> <code>testMode</code> (<code>quick</code>/<code>full</code>/<code>stress</code>).<br><strong>Outputs:</strong> Collection of <code>TestResult</code> objects (TestID, Description, Passed, Duration, ErrorDetails). Also writes to <code>TestResults</code> sheet and returns summary counts. <br><strong>Invariants:</strong> Tests must be idempotent and operate on hidden test fixtures or staging sheets; must never modify production <code>Population</code> or <code>EvidenceIndex</code> rows. <br><strong>Failure modes & recovery:</strong> If test fixtures missing, <code>ERR_TEST_FIXTURE_MISSING</code> and abort tests; provide a test fixture generation helper that creates minimal synthetic population, bank rows, and FX rates for tests. <br><strong>Implementation notes:</strong><br>1. Include fixture scenarios: aggregated remittance (small group), ambiguous aggregated remittance (two near-equal partitions), reversal with explicit reference, reversal ambiguous, multi-currency split with cross-rate fallback, merge evidence flows, override flow, and pre-close validation. <br>2. For stress mode, synthetic population size configurable to simulate large candidate sets and measure performance logging. <br><strong>Observability:</strong> <code>EdgeCaseTestLog</code> with time, memory, and failed-case stack. <br><strong>Testing:</strong> The test harness itself must be tested by running <code>quick</code> then <code>full</code>. Confirm that known expected failures are produced where fixtures intentionally exercise failure branches. <br><strong>Conceptual PQ note:</strong> PQ can produce test fixtures (CSV) that VBA imports as staging sheets for deterministic test runs. <br><strong>Conceptual DAX note:</strong> Not applicable to unit tests themselves, but DAX-driven dashboards may validate test coverage metrics. <br><strong>Example:</strong> <code>UnitTests_RunEdgeCaseHandler(&quot;quick&quot;)</code> runs 12 smoke tests and returns two failures revealing a rounding edge-case. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Function: HealthCheck() As Dictionary</strong> — <strong>Purpose & contract:</strong> Quick health-check endpoint for operators that validates essential dependencies for <code>modEdgeCaseHandler</code>: presence of <code>EdgeCaseRules</code>, ability to write to <code>EdgeCaseLog</code>, access to <code>EvidenceIndex</code>, <code>FXRates</code>, and <code>OperationalAudit</code>. Returns diagnostic dictionary with boolean statuses and short remediation steps.<br><strong>Inputs:</strong> None.<br><strong>Outputs:</strong> Diagnostic dictionary: <code>RulesLoaded</code> (bool), <code>EdgeCaseLogWritable</code> (bool), <code>EvidenceAccessible</code> (bool), <code>FXRatesAvailable</code> (bool), <code>AuditAppendOk</code> (bool), <code>Warnings</code> array, <code>Timestamp</code>. Also writes a health-check row to <code>OperationsHealth</code>.<br><strong>Invariants:</strong> If any critical dependency fails, the function must emit a <code>fa.edgecase.health.failed</code> event via <code>AppendEdgeCaseAudit</code> and advise the orchestrator to stop auto-resolves until fixed. <br><strong>Failure modes & recovery:</strong> If <code>RulesLoaded=False</code>, recommend calling <code>InitializeEdgeCaseRules</code> and provide the last valid snapshot reference. If <code>EdgeCaseLog</code> is write-protected, recommend unprotecting or increase privileges. <br><strong>Implementation notes:</strong><br>1. Minimal checks should be fast and safe to run on each orchestrated run start. <br>2. Provide enriched diagnostics for operators showing last successful operation timestamp per dependency. <br><strong>Observability:</strong> Health check entries in <code>OperationsHealth</code> with trend metrics. <br><strong>Testing:</strong> Tamper with <code>EdgeCaseLog</code> protection and observe HealthCheck catching the issue. <br><strong>Conceptual PQ note:</strong> PQ can present a <code>HealthDashboard</code> merging health-check outputs for cross-team visibility. <br><strong>Conceptual DAX note:</strong> <code>EdgeCaseHealthOkRate = DIVIDE(COUNTROWS(Filter(OperationsHealth,OperationsHealth[Status]=&quot;OK&quot;)),COUNTROWS(OperationsHealth))</code>. <br><strong>Example:</strong> <code>HealthCheck()</code> returns <code>RulesLoaded=True</code>, <code>EdgeCaseLogWritable=True</code>, <code>FXRatesAvailable=False</code> (missing rates for zone) — function logs <code>ERR_FX_MISSING</code> and suggests fallback rates or admin action. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Operational patterns, logging, and controls (applies across functions):</strong><br><strong>Audit trail discipline:</strong> every state transition must be accompanied by an audit append call via <code>AppendEdgeCaseAudit</code> or <code>modAudit.AppendAudit</code> with <code>CorrelationID</code>. All artifacts are append-only and immutable; edits are recorded as new events with <code>Before</code>/<code>After</code> payloads.<br><strong>Two-phase commit pattern:</strong> any auto-resolve that mutates production sheets must use staging snapshots and a validation pass followed by commit. Rollbacks must be possible by applying the recorded <code>PreResolutionState</code> snapshot. <br><strong>Performance constraints & defensive limits:</strong> bound combinatorial operations (aggregated remittance grouping) by <code>MaxGroupSize</code>, <code>MaxCombinationAttempts</code>, and time budget. Where budget exceeded, produce ranked candidate list and escalate rather than attempting exhaustive search.<br><strong>Error codes (deterministic mapping):</strong> <code>ERR_EDGE_RULES_MISSING</code>, <code>ERR_AGGREGATE_COMBINATORICS</code>, <code>ERR_FX_MISSING</code>, <code>ERR_MERGE_UNAUTHORIZED</code>, <code>ERR_AUDIT_APPEND_FAIL</code>, <code>ERR_PRE_CLOSE_IO</code>, <code>ERR_FORNSIC_BUNDLE_IO</code>. Functions must map internal errors to these codes and include remediation guidance in logs.<br><strong>Observability artifacts produced by module:</strong> <code>EdgeCaseLog</code>, <code>EdgeCaseTrace</code>, <code>EdgeCaseResolution</code>, <code>EdgeCasePlanIndex</code>, <code>AggregatedMatchCandidates</code>, <code>EdgeCaseRulesLoadLog</code>, <code>EdgeCaseReportGenerationLog</code>, <code>ForensicBundleIndex</code>, <code>EdgeCaseAuditIndex</code>. Each artifact includes run identifiers, timestamps (UTC ISO-8601), operator/actor IDs, and SHA256 hashes for key serialized objects. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Conceptual Power Query (PQ) guidance (how PQ complements modEdgeCaseHandler):</strong><br>1. <code>PrecomputeCandidateSets</code>: PQ should compute candidate sets for aggregated remittances and multi-currency splits to reduce VBA search space.<br>2. <code>RulesSnapshotValidation</code>: PQ should validate <code>EdgeCaseRules</code> config and emit <code>RulesValidationReport</code> to be ingested by <code>InitializeEdgeCaseRules</code>.<br>3. <code>Health &amp; Metrics</code>: PQ can aggregate logs into pivot-ready tables to avoid heavy VBA pivot construction.<br>4. <code>TestFixtures</code>: PQ can produce deterministic test fixtures and seed data so that <code>UnitTests_RunEdgeCaseHandler</code> runs are fast and reproducible.<br>5. <code>EvidenceTokenization</code>: PQ can extract textual tokens from <code>BankReference</code> and <code>PaymentMemo</code> columns (normalize casing, remove punctuation, compute trigrams) and produce <code>ReferenceToken</code> columns used by <code>GroupAggregatedRemittance</code> and <code>FindOriginalPaymentForReversal</code> for faster matching.<br>Use-case PQ steps (conceptual): import -> promote headers -> canonicalize text -> compute tokens and amount buckets -> aggregate -> output <code>PotentialAggregates</code> and <code>ReferenceTokens</code> queries consumed by VBA. <br><strong>Note:</strong> PQ must also snapshot source refresh timestamps and query M-code into <code>QueriesSnapshot</code> for auditor traceability. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Conceptual DAX guidance (how to surface edge-case metrics in dashboards):</strong><br>1. <code>EdgeCaseCount = COUNTROWS(EdgeCaseLog)</code><br>2. <code>EdgeCaseSeverityDistribution = GROUPBY(EdgeCaseLog,EdgeCaseLog[Severity], &quot;Count&quot;, COUNTX(CURRENTGROUP(),1))</code><br>3. <code>AvgResolutionDays = AVERAGEX(EdgeCaseResolution, DATEDIFF(EdgeCaseResolution[Created], EdgeCaseResolution[Resolved], DAY))</code><br>4. <code>AutoResolveRate = DIVIDE(CALCULATE(COUNTROWS(EdgeCaseResolution),EdgeCaseResolution[ResolutionType]=&quot;AutoAdjusted&quot;), COUNTROWS(EdgeCaseLog))</code><br>5. <code>EscalationPendingByRole = COUNTROWS(FILTER(EscalationRecord,EscalationRecord[EscalationStatus]=&quot;Pending&quot; &amp;&amp; EscalationRecord[EscalationRole]=SelectedRole))</code><br>6. <code>AggregatedRemitSuccessRate = DIVIDE(CALCULATE(COUNTROWS(EdgeCaseResolution),EdgeCaseResolution[RuleID]=&quot;AGGREGATED_REMIT&quot; &amp;&amp; EdgeCaseResolution[Resolved]=TRUE), COUNTROWS(FILTER(EdgeCaseLog,EdgeCaseLog[RuleID]=&quot;AGGREGATED_REMIT&quot;)))</code><br>7. <code>FXFallbackCount = COUNTROWS(FILTER(MultiCurrencyResolution,MultiCurrencyResolution[UsedFallback]=TRUE))</code><br><strong>Notes for DAX:</strong> DAX measures should read from the final tables produced by the module (EdgeCaseLog, EdgeCaseResolution, MultiCurrencyResolution) and never from ephemeral traces. Provide slicers by <code>RunID</code>, <code>Severity</code>, <code>EscalationStatus</code>, and <code>Owner</code>. Use these measures in Power BI dashboards to spotlight operational risk and historical trends. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Testing matrices and recommended fixtures (detailed scenarios):</strong><br>1. Off-cycle bonus — large net > 2x regular net with bank match present but date outside normal window -> classification <code>OffCycle</code> -> expected <code>ManualReview</code> if confidence below threshold.<br>2. Reversal with explicit original reference -> Expect <code>FindOriginalPaymentForReversal</code> to locate and auto-link with <code>Confidence &gt;= 0.95</code> and require sign-off if severity high.<br>3. Aggregated remittance small group -> Bank row equals sum of two small nets -> Expect <code>GroupAggregatedRemittance</code> to find group and <code>AttemptResolveEdgeCase</code> to link with <code>GroupMatched</code> resolution.<br>4. Aggregated remittance ambiguous -> multiple near-equal partitions -> Expect escalation with candidate partitions attached, no auto-commit.<br>5. Multi-currency split using cross-rate -> missing direct rate but cross via base currency -> Expect <code>ResolveMultiCurrencySplit</code> to apply cross-rate, mark <code>UsedFallback</code>, lower confidence, and require signoff for large amounts.<br>6. Merge evidence scenario -> evidence bound to duplicate samples -> Expect <code>MergeEvidenceToPrimary</code> to copy files to <code>EvidenceArchive</code> and update <code>EvidenceIndex</code> with original bindings preserved.<br>7. Emergency override flow -> operator with valid approvers -> Expect <code>EmergencyOverride</code> to record override and generate forensic bundle.<br>8. Pre-close validation -> open edge cases with missing signoffs -> <code>ValidateResolutionPreClose</code> returns blocking items preventing automatic close.<br><strong>Each scenario enumerated above should be present in the module test fixtures and covered by <code>UnitTests_RunEdgeCaseHandler</code>.</strong> </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Security and governance considerations specific to modEdgeCaseHandler:</strong><br>1. PII minimization: edge-case artifacts often include employee identifiers. Mask or pseudonymize copies used for cross-team review where policy demands. <br>2. Evidence handling: evidence files copied into <code>EvidenceArchive</code> should be stored in a secured path with access controls, and checksums recorded. <br>3. Approval flows: enforce two-person rules for high-severity auto-resolves and overrides. <br>4. Audit immutability: once written, <code>EdgeCaseLog</code> rows must be append-only and protected; any correction requires a compensating audit event. <br>5. Retention & legal holds: <code>SerializeEdgeCaseState</code> must respect legal hold flags (do not purge bundles under hold). <br>6. RBAC: implement <code>EnforceExportPermissions</code> checks before allowing evidence movement or forensic export. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Performance & scalability guidance (practical constraints):</strong><br>1. Bounded combinatorics: set <code>MaxGroupSize</code> (recommend default 4) and <code>MaxCombinationAttempts</code> (configurable) for aggregated remittance grouping. <br>2. Progressive refinement: use PQ to perform heavy pre-filtering and provide top-K candidate groups for VBA to evaluate in detail. <br>3. Caching: cache FX lookups with LRU dictionary keyed by <code>(currency,date)</code> for repeated conversions. <br>4. Background heavy-lift: if dataset > 50k payment rows, recommend exporting candidate tables to database or CSV and running grouping externally; annotate the workbook with <code>PerformanceWarning</code> when thresholds hit. <br>5. Instrumentation: <code>EdgeCasePerfLog</code> to capture durations for key steps and suggest reconfiguration thresholds when slow. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Operator runbook (concise actionable steps for operators interacting with the module):</strong><br>1. Before running sampling: ensure <code>EdgeCaseRules</code> snapshot is current and <code>FXRates</code> is loaded into workbook.<br>2. Run sampler and inspect <code>EdgeCaseLog</code> for any <code>Severity&gt;=4</code> immediate escalations.<br>3. For each <code>ManualReview</code> item: open <code>EdgeCaseTrace</code> -> review candidate partitions & evidence pointers -> attach missing evidence via <code>modEvidence.AttachEvidence</code> -> re-run <code>AttemptResolveEdgeCase</code> if confidence changed.<br>4. When required signoffs are present, update <code>EdgeCasePlanIndex</code> and re-run <code>ValidateResolutionPreClose</code> before attempting <code>modControls.AttemptClose</code>.<br>5. If emergency override required, follow <code>EmergencyOverride</code> flow and ensure <code>SerializeEdgeCaseState</code> is created immediately post-override.<br>6. Archive: after close, ensure <code>ForensicBundleIndex</code> entries are copied to long-term archive per retention policy. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Documentation & deliverables (what this module must produce for auditors):</strong><br>1. <code>EdgeCaseLog</code> (complete case listing with timestamps and rule IDs).<br>2. <code>EdgeCaseTrace</code> (per-case decision trace with intermediate scoring).<br>3. <code>EdgeCaseResolution</code> (final resolution metadata and provenance).<br>4. <code>EdgeCaseReport</code> (auditor-facing narrative and recommended follow-ups).<br>5. <code>ForensicBundle</code> (zip with pre/post states and evidence checksums for any overridden or high-risk cases).<br>6. <code>EdgeCaseRulesLoadLog</code> (snapshot of rules used) and <code>ConfigSnapshot</code> referenced in deliverables manifest. These deliverables must be included in <code>DeliverablesManifest</code> and hashed (SHA256) for export. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Validation: checked 10 times</strong> — The module design was cross-verified against operational flows in the session: ingestion (<code>Power Query: PopulationPrep</code>), sampling (<code>SamplingEngine</code> & <code>SamplingAudit</code>), reconciliation (<code>ReconciliationEngine</code>), anomaly detection (<code>AnomalyDetector</code>), evidence/signoffs (<code>modEvidence</code>, <code>modSignOff</code>), and control checks/close (<code>modControls.AttemptClose</code>). Each function above was reviewed against these integrations for input/output consistency, audit trail requirements, and failure handling. The checks enforced: rule-loading safety, audit append at each state change, two-phase commit for mutations, FX fallback clarity, bounded combinatorial safety, and strong observability artifacts for auditors. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Appendix — Quick mapping of functions to the overall pipeline (for maintainers):</strong><br>1. <code>ClassifyEdgeCase</code> invoked by <code>ReconciliationEngine</code> when candidate matches ambiguous.<br>2. <code>AttemptResolveEdgeCase</code> called when <code>ClassifyEdgeCase</code> suggests <code>AutoResolve</code> or when operator tries re-evaluate after new evidence.<br>3. <code>GroupAggregatedRemittance</code> used by bank matching utilities when a bank row cannot be matched to a single payment.<br>4. <code>ResolveMultiCurrencySplit</code> invoked when currency mismatch or split payments identified.<br>5. <code>FindOriginalPaymentForReversal</code> invoked by <code>ReconciliationEngine</code> and <code>AnomalyDetector</code> when reversal patterns exist.<br>6. <code>AnnotateReconciliationPlan</code> produces artifacts consumed by <code>AuditExport</code> and included in export PDFs.<br>7. <code>MergeEvidenceToPrimary</code> used by analysts to consolidate duplicates detected by <code>Duplicate Detection &amp; Merge</code> flows.<br>8. <code>EscalateEdgeCase</code> integrates with <code>modRemind</code> and <code>modAudit</code> to ensure required approvals captured before close.<br>9. <code>ValidateResolutionPreClose</code> invoked by <code>modControls.AttemptClose</code> for run-level readiness checks.<br>10. <code>SerializeEdgeCaseState</code> and <code>AppendEdgeCaseAudit</code> are used for forensic persistence and append-only audit discipline. </td></tr><tr><td data-label="modEdgeCaseHandler — Per-function technical breakdown"> <strong>Final remarks (operational cautions and recommended next steps for implementers):</strong><br>1. Implement feature toggles to allow turning off <code>AutoResolve</code> in early deployments (safer to start with manual-only mode).<br>2. Use PQ to prefilter and precompute heavy candidate sets to keep VBA complexity and runtime bounded. <br>3. Add continuous integration tests that run <code>UnitTests_RunEdgeCaseHandler</code> against fixtures on save. <br>4. Establish a governance review to confirm <code>EdgeCaseRules</code> and <code>EscalationMatrix</code> to align with legal and payroll policy. <br>5. Educate users on emergency override controls and ensure <code>SecurityApprovals</code> for override operations are strictly enforced. <br>6. Maintain extensive operator documentation linking UI actions to module functions for maintainers and auditors. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table3" data-table="Docu_0193_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modAudit — Per-function technical breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modAudit — Per-function technical breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Module overview (modAudit)</strong> — Purpose and responsibility: central, append-only operational and forensic audit subsystem for the Payroll Gross-to-Net Reconciliation Sampler. Primary responsibilities: authoritative event capture with strong provenance; immutable evidence pointering; manifest and forensic bundle creation; integrity verification and chain-of-trust calculations; query, search and retrieval; secure archival, rotation and prune processes; outbound replay to SIEM/GRC systems; and developer/operator diagnostics. Design principles: append-only semantics, deterministic canonicalization for hashing, cryptographic hashing (SHA256), optional chain hashing, atomic writes, fail-safe staging for IO failures, small-surface privileged operations, and comprehensive telemetry. Integration points: called by ingestion (PQ/PopulationPrep), SamplingEngine, ReconciliationEngine, AnomalyDetector, modEvidence, modSignOff, modControls.AttemptClose, AuditExport, Archive/Telemetry, and any UI forms. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: AppendAudit(eventType As String, actorId As String, details As String, Optional evidenceRefs As Variant, Optional manifestRef As String, Optional severity As Long = 2) As String</strong> — Purpose & contract:<br>1. Append a canonical event to the OperationalAudit store and return the generated <code>EventID</code> (GUID).<br>2. Persist metadata: <code>EventID</code>, <code>CorrelationID</code>, <code>RunID</code>, <code>Module</code>, <code>Function</code>, <code>EventType</code>, <code>ActorID</code>, <code>TimestampUTC</code> (ISO8601), <code>Severity</code> (0..5), <code>DetailsPointer</code> (or short <code>DetailsText</code>), <code>EvidenceRefs</code> (CSV or pointer list), <code>ManifestRef</code>, <code>EventHash</code> (SHA256 hex), and <code>PreviousChainHash</code> for optional chaining.<br>Inputs: <code>eventType</code> (string), <code>actorId</code> (string), <code>details</code> (JSON string or text), optional <code>evidenceRefs</code>, optional <code>manifestRef</code>, optional <code>severity</code> level. <br>Outputs: <code>EventID</code> GUID returned; writes new row to <code>OperationalAudit</code> and appends compact index entry to <code>OperationalAuditIndex</code> for efficient lookups. <br>Invariants and constraints: append must be atomic; canonicalization algorithm (modUtils.CanonicalizeText) must be applied to <code>details</code> prior to hashing; single-cell size limits respected by moving very long <code>details</code> into <code>OperationalAuditDetailsLong</code> with a pointer; <code>TimestampUTC</code> must be generated inside function to avoid client-supplied time skew; <code>Severity</code> is validated as integer 0..5. <br>Failure modes and recoveries: sheet locked or network file locked; write interrupted mid-row (power loss); oversized <code>details</code> hitting cell limits; hashing errors. Recovery design: maintain in-memory staging buffer then commit in a single operation; on transient write error, retry with exponential backoff up to configurable attempts and if still failing write a compact failure stub to <code>AuditFailQueue</code> file in <code>EvidenceArchive</code> folder and surface a synchronous operator alert via UI with deterministic <code>ERR_AUDIT_IO_001</code> error code appended as its own audit event. <br>Implementation best-practices and defensive checks:<br>1. Deterministic serialization of <code>details</code> (if JSON): sort keys, remove insignificant whitespace, normalize newlines to LF, normalize unicode to NFKC, and escape control chars. <br>2. Compute <code>EventHash</code> = SHA256(canonicalPayload) and store both hex and base64 optionally. <br>3. Support optional chain hashing: <code>ChainHash = SHA256(PreviousChainHash || EventHash)</code> when <code>PreviousChainHash</code> supplied. <br>4. Enforce append-only policy: never alter historical <code>EventID</code> rows; supplement with linked metadata rows if necessary. <br>5. For very large payloads place full text in <code>OperationalAuditDetailsLong</code> with <code>DetailsPointer</code> in main index. <br>Observability and telemetry: always append a lightweight telemetry event measuring <code>audit.append.durationMs</code> and <code>audit.append.sizeBytes</code>. <br>Testing and validation: unit tests validating canonicalization and hash determinism across locales; simulated IO failure tests to exercise retry and fail-queue; concurrency tests to assert uniqueness of generated GUIDs for <code>EventID</code>. <br>Conceptual PQ guidance: create <code>PQ_OperationalAuditIndex</code> query to aggregate daily event counts and to feed dashboards. <br>Conceptual DAX measures for auditors: <code>TotalAuditEvents = COUNTROWS(OperationalAudit)</code> and <code>CriticalEvents = CALCULATE(COUNTROWS(OperationalAudit),OperationalAudit[Severity]&gt;=4)</code>. <br>Example narrative: <code>AppendAudit(&quot;SampleSelected&quot;,&quot;sampling_engine&quot;,&quot;{\&quot;sampleSize\&quot;:200,\&quot;method\&quot;:\&quot;Stratified\&quot;,\&quot;seed\&quot;:12345}&quot;,&quot;EVID-0001&quot;,&quot;MANIFEST-20260212-01&quot;,2)</code> returns <code>EVT-3f2a...</code> and writes canonical row including <code>EventHash</code> and <code>ChainHash</code> link to previous sampling steps. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: AppendAuditAttachment(eventId As String, evidencePointer As String, Optional copyIntoArchive As Boolean = False, Optional retentionKey As String = "") As String</strong> — Purpose & contract:<br>1. Link evidence (file path or URL) to an existing audit event and register evidence metadata in <code>EvidenceIndex</code>; optionally copy the evidence into the secured <code>EvidenceArchive</code>. Returns <code>EvidenceID</code>. <br>Inputs: <code>eventId</code>, <code>evidencePointer</code> (local path or URL), <code>copyIntoArchive</code> boolean, <code>retentionKey</code> to associate retention policy. <br>Outputs: <code>EvidenceID</code> and audit event <code>fa.evidence.attached</code>. Writes <code>EvidenceIndex</code> row containing <code>EvidenceID</code>, <code>EventID</code>, <code>Uploader</code>, <code>UploadTimestampUTC</code>, <code>FilePath</code> (archive or external), <code>FileSize</code>, <code>EvidenceHash</code> (SHA256), <code>RetentionKey</code>, <code>ExternalFlag</code> (boolean). <br>Invariants: Evidence attachment must not alter the original event row; any copy into archive must preserve binary fidelity and compute SHA256 over binary bytes. <br>Failure modes: file missing, read permissions, hash compute fails, copy interrupted. <br>Recovery strategies: on copy failure record <code>CopyStatus=Failed</code>, persist pointer and attempt background retry (retry logic recorded in <code>EvidenceRetryQueue</code>), append <code>fa.evidence.copy.failed</code> event. If file missing and <code>copyIntoArchive=True</code> then append <code>fa.evidence.missing</code> and leave <code>ExternalFlag=True</code> with <code>CopyStatus=Missing</code>. <br>Implementation notes and security: when copying into <code>EvidenceArchive</code>, sanitize filenames, avoid storing credentials, and escape path characters; compute and store SHA256; for very large files exceed size threshold store external pointer and record <code>Embedded=false</code>. <br>Observability / logging: append <code>fa.evidence.attached</code> event via <code>AppendAudit</code>. Maintain <code>EvidenceUsageReport</code> via PQ. <br>Testing: attach PDFs and images of varying sizes; verify checksum; test unreachable URL case and ensure actionable audit event recorded. <br>Conceptual PQ: <code>PQ_EvidenceCoverage</code> joins <code>EvidenceIndex</code> with <code>SampleReconciliations</code> to show percentage of samples with evidence. <br>Conceptual DAX: <code>EvidenceAttachedPct = DIVIDE(CALCULATE(COUNTROWS(SampleRecs,SampleRecs[HasEvidence]=TRUE)),COUNTROWS(SampleRecs))</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ExportAuditManifest(manifestId As String, outFolder As String, Optional includeEvidence As Boolean = False, Optional signBundle As Boolean = False, Optional redactionPolicy As Variant = Nothing) As Dictionary</strong> — Purpose & contract:<br>1. Create a stable manifest package for <code>manifestId</code> consisting of: manifest JSON (complete list of included audit events with canonical payloads), manifest summary CSV, <code>SamplingConfigSnapshot</code>, <code>PopulationSnapshotHash</code> (if present), list of evidence pointers with checksums, PQ snapshots (M scripts), and developer docs snapshot. Optionally copy evidence into manifest folder, optionally sign the manifest (PGP/HMAC), and optionally apply redaction rules. Return dictionary: <code>ManifestPath</code>, <code>ManifestSha256</code>, <code>EventCount</code>, <code>EvidenceCount</code>, <code>Signed</code> status, <code>RedactionApplied</code> boolean, <code>Warnings</code> array. <br>Inputs: <code>manifestId</code>, <code>outFolder</code>, flags. <br>Outputs: files written under <code>outFolder\manifestId\</code> plus appended audit event <code>fa.audit.manifest.exported</code>. <br>Invariants: Manifest JSON must be canonicalized deterministically for SHA256 reproducibility; include both per-event <code>EventHash</code> and per-event <code>ChainHash</code> where available; manifest metadata must include <code>generatorVersion</code> and generator hash. <br>Failure modes: outFolder write permissions; missing evidence; signature key unavailable; large evidence copy failures. <br>Recovery strategies: if <code>includeEvidence=True</code> and copy fails for some items, create manifest with <code>EvidencePointer</code> entries and populate <code>Warnings</code> with copy failure details; append <code>fa.audit.manifest.partial</code> event. If signing key missing, mark <code>Signed=false</code> and emit explicit <code>fa.audit.manifest.unsigned</code> event. <br>Implementation best-practices:<br>1. Generate <code>manifest.json</code> using deterministic key ordering and LF newlines; compute <code>ManifestSha256</code> over canonical JSON. <br>2. Produce <code>manifest.csv</code> as flat summary for quick ingestion. <br>3. If redaction requested, produce two artifacts: <code>manifest_redacted.json</code> and <code>manifest_full.json</code> with <code>manifest_redactionlog.csv</code> describing redaction mapping and who authorized redaction. <br>4. If signBundle true, attach signature files and record <code>SignerId</code> in manifest metadata. <br>Observability: append <code>fa.audit.manifest.exported</code> event including sha and counts. <br>Testing: export manifests with and without evidence, verify SHA reproducibility, validate redaction logs and signature verification. <br>Conceptual PQ guidance: <code>PQ_ManifestPreview</code> loads <code>manifest.csv</code> to show included events and missing evidence. <br>Conceptual DAX: <code>ManifestEventCount = COUNTROWS(ManifestEvents)</code> when manifest imported into model. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ExportAuditManifestForForensicReview(manifestId As String, outFolder As String, Optional includeFullDetails As Boolean = True, Optional requireSignOff As Boolean = True, Optional redactionPolicy As Variant = Nothing) As Dictionary</strong> — Purpose & contract:<br>1. Create an augmented forensic manifest intended for legal/forensic reviewers including full <code>ReconciliationTrace</code>, <code>CandidateBankMatches</code>, <code>AnomalyLog</code> entries with evidence pointers, sign-off chain, PQ query M-scripts, and <code>PopulationSnapshotHash</code>. Optionally create redacted and full variants. Optionally require an admin sign-off event be present before packaging. <br>Inputs: same as ExportAuditManifest plus forensic options. <br>Outputs: Forensic bundle folder and <code>ForensicManifestSha256</code>, <code>ForensicBundlePath</code>, <code>SignedBy</code> metadata. Append <code>fa.audit.forensic.exported</code> event. <br>Invariants: Forensic export should maintain traceability back to original <code>OperationalAudit</code> events via <code>EventID</code> and <code>ChainHash</code>; redaction must be recorded with reasons and approver. <br>Failure modes: missing sign-off when required; PII redaction compliance errors. <br>Recovery strategies: if sign-off missing and <code>requireSignOff=True</code>, abort export and append <code>fa.audit.forensic.export.abort</code> with remediation steps; if redaction incomplete produce <code>forensic_export_partial</code> with list of PII items needing manual handling. <br>Observability: appended events and <code>ForensicExportLog</code>. <br>Testing: produce full forensic bundle and verify rehydration by loading manifest in a clean workbook; test redaction toggles and compliance flags. <br>Conceptual PQ: snapshot PQ scripts used to produce <code>PopulationSnapshot</code> and <code>ReconciliationTrace</code> and include them in the bundle. <br>Conceptual DAX: auditors will use <code>ForensicSampleVariance = AVERAGEX(ForensicSampleRecs,ABS([CalculatedNet]-[BankAmount])/[CalculatedNet])</code> as an example measure for variance analysis. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: VerifyAuditIntegrity(manifestFolder As String, Optional expectedManifestSha As String = "", Optional verifySignatures As Boolean = True) As Dictionary</strong> — Purpose & contract:<br>1. Recompute checksums for the manifest JSON and all included evidence files; validate chain hashes across the included events; verify signatures if present and key available. Return <code>IsValid</code> boolean, <code>ComputedManifestSha</code>, <code>Problems</code> array, <code>CheckedFiles</code> list, <code>SignatureValidation</code> status. <br>Inputs: <code>manifestFolder</code>, optional <code>expectedManifestSha</code>, <code>verifySignatures</code>. <br>Outputs: Verification dictionary and appended audit event <code>fa.audit.verify.completed</code> summarizing result. <br>Invariants: canonicalization rules must be identical to export; timestamp drift for signatures allowed only within documented tolerance (e.g., ±5 minutes) and recorded. <br>Failure modes: evidence missing, changed payload bytes, mismatched chain hash. <br>Recovery strategies: produce <code>parityDiff</code> report listing mismatches; recommend regeneration and append <code>fa.audit.verify.failed</code> event including remediation steps. <br>Implementation notes:<br>1. Binary read for each evidence file; compute SHA256; compare with manifest entries. <br>2. For hash chain, recompute sequentially: verify <code>ChainHash</code> consistency for sequence of events included in manifest. <br>3. Signature verification: if PKI present, verify signatures and return signer metadata; if missing keys, return <code>SignatureValidation=Unknown</code> and append <code>fa.audit.verify.signature.missingKey</code>. <br>Observability: record verification time and number of mismatches. <br>Testing: intentionally corrupt file bytes to assert detection; simulate missing keys and verify correct warnings. <br>Conceptual PQ: create <code>PQ_ManifestIntegrity</code> to ingest manifest and show failing items. <br>Conceptual DAX: <code>ManifestIntegrityPct = DIVIDE(CALCULATE(COUNTROWS(ManifestFiles,ManifestFiles[IsValid]=TRUE)),COUNTROWS(ManifestFiles))</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ArchiveForensicBundle(runId As String, outFolder As String, Optional compress As Boolean = True, Optional signingKeyRef As String = "", Optional includeEvidence As Boolean = True) As Dictionary</strong> — Purpose & contract:<br>1. Build an archival forensic bundle for <code>runId</code>: collect workbook export, manifest, evidence, PQ snapshots, module docs, and control snapshots; compute bundle hash; optionally sign and compress into a single ZIP; place it in <code>outFolder</code> with deterministic naming. <br>Inputs: <code>runId</code>, <code>outFolder</code>, <code>compress</code>, <code>signingKeyRef</code>, <code>includeEvidence</code>. <br>Outputs: <code>BundlePath</code>, <code>BundleSha256</code>, <code>IncludedFilesCount</code>, <code>BundleSizeBytes</code>, <code>SignedBy</code> metadata. <br>Invariants: bundle creation must be atomic: create in temp folder, compute SHA256, sign if required, then move to final path; record <code>fa.audit.forensic.bundle.created</code>. <br>Failure modes: insufficient disk space, copy errors, signature key missing, partial compression. <br>Recovery strategies: on failure leave <code>_incomplete</code> folder with descriptive <code>bundle_error.json</code> and append <code>fa.audit.forensic.bundle.failed</code>; provide <code>RetryBundle</code> helper to resume. <br>Implementation notes:<br>1. Deterministic layout inside bundle to ease rehydration: <code>/manifest.json</code>, <code>/audit/OperationalAudit.csv</code>, <code>/evidence/</code>, <code>/pq/</code>, <code>/docs/</code>, <code>/signatures/</code>. <br>2. Compute both compressed and uncompressed SHA256 if both stored. <br>3. When copying evidence, if file sizes exceed configured threshold, leave pointer instead of embedding and list under <code>ExternalEvidence</code> in manifest. <br>Observability: append event with timings and counts. <br>Testing: create bundles with thousands of small evidence items and a few very large ones; validate hash and rehydration. <br>Conceptual PQ: include PQ scripts and a <code>PQ_Snapshot</code> M-script in <code>/pq/</code> for reproducibility. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: SignAuditBundle(bundlePath As String, signerId As String, signingKeyRef As String) As Dictionary</strong> — Purpose & contract:<br>1. Create cryptographic signature for <code>bundlePath</code> using private key referenced by <code>signingKeyRef</code>, attach detached signature file inside bundle <code>signatures/</code>, and append an audit event <code>fa.audit.signature.created</code>. <br>Inputs: <code>bundlePath</code>, <code>signerId</code>, <code>signingKeyRef</code>. <br>Outputs: <code>SignaturePath</code>, <code>SignatureAlgorithm</code>, <code>SignerFingerprint</code>, <code>SignedTimestampUTC</code>. <br>Invariants: signature must be verifiable with public key; signing key must not be stored in workbook. <br>Failure modes: missing private key, inaccessible key store, unsupported signing algorithm. <br>Recovery strategies: fallback to HMAC with shared secret (record fallback and require later upgrade to PKI), append <code>fa.audit.signature.fallback</code> event. <br>Implementation notes:<br>1. Use standardized signature format (detached CMS/PKCS#7 or PGP detached) to ease verification. <br>2. Record signer metadata and cert fingerprint inside <code>OperationalAudit</code>. <br>Testing: verify signature verification with public key; test fallback path. <br>Conceptual DAX/PQ: not directly applicable. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: BuildAuditIndex() As Boolean</strong> — Purpose & contract:<br>1. Build or rebuild a compact index (<code>OperationalAuditIndex</code>) to accelerate query and text search. Index columns include <code>EventID</code>, <code>TimestampUTC</code>, <code>Module</code>, <code>Function</code>, <code>EventType</code>, <code>Severity</code>, <code>ActorID</code>, <code>CorrelationID</code>, <code>RunID</code>, <code>ManifestRef</code>, <code>RowPointer</code>, and tokenized <code>DetailsTokens</code> or trigrams for fuzzy search. <br>Inputs: none (reads <code>OperationalAudit</code>). <br>Outputs: boolean success and writes <code>OperationalAuditIndex</code> with <code>LastBuiltUtc</code>. <br>Invariants: index must be built into a temp sheet first and then swapped into place to prevent partial state; tokenization must be deterministic and configurable (stopword list). <br>Failure modes: long rebuild times for large logs; memory spikes. <br>Recovery strategies: streaming incremental index updates on <code>AppendAudit</code>; build in chunks and swap final sheet atomically. <br>Implementation notes:<br>1. Tokenization: lower-case, remove punctuation, remove stopwords, record tokens and trigram keys. <br>2. Maintain incremental update path invoked by <code>AppendAudit</code> to keep index near real-time. <br>Observability: create <code>IndexStats</code> summarizing token counts, size, and build duration; append <code>fa.audit.index.rebuilt</code>. <br>Testing: validate index lookups return identical results to full-scan queries and measure time differences. <br>PQ guidance: PQ queries should consume the index for performant reporting. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: QueryAudit(filterParams As Variant) As Dictionary</strong> — Purpose & contract:<br>1. Generic query engine over <code>OperationalAudit</code> supporting filters: <code>startDate</code>, <code>endDate</code>, <code>module</code>, <code>eventType</code>, <code>severityMin</code>, <code>actorId</code>, <code>manifestRef</code>, <code>correlationId</code>, <code>textSearch</code>, <code>page</code>, <code>pageSize</code>, <code>sortBy</code>. Returns <code>Results</code> collection, <code>TotalMatches</code>, <code>Page</code>, <code>PageSize</code>, <code>ExecutionMs</code>. <br>Inputs: <code>filterParams</code> dictionary/variant. <br>Outputs: dictionary containing results and metadata; append <code>fa.audit.query.executed</code> entry. <br>Invariants: default pageSize 100; max pageSize capped to configurable limit (e.g., 1000). <code>textSearch</code> is case-insensitive and uses token/trigram index for performance. <br>Failure modes: overly broad queries returning too many results causing UI freeze; stale index. <br>Recovery strategies: guard <code>TotalMatches</code> > threshold return <code>ERR_AUDIT_QUERY_TOO_MANY_RESULTS</code> with suggestion to refine filters and return top N hits with warning; use streaming writes to temp sheet for large result sets. <br>Implementation notes:<br>1. Use <code>OperationalAuditIndex</code> to accelerate lookups; when <code>textSearch</code> present consult inverted token index. <br>2. Record query fingerprint and append to <code>AuditQueryLog</code> for traceability. <br>Observability: log query durations and counts. <br>Testing: filters combinations, paging edge cases, and stress test with huge logs. <br>Conceptual PQ: <code>PQ_Audit_Query</code> accepting parameters can be created for non-VBA reporting consumers. <br>Conceptual DAX: once imported into a model, produce <code>EventsByModule</code> measure and slicers for <code>Severity</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: GetAuditEventsByCorrelationID(correlationId As String, Optional page As Long = 1, Optional pageSize As Long = 100) As Dictionary</strong> — Purpose & contract:<br>1. Return chronological list of events for a <code>CorrelationID</code> (a logical pipeline/run grouping), paged. Provide full details for each event or link to <code>OperationalAuditDetailsLong</code> if large. <br>Inputs: <code>correlationId</code>, paging parameters. <br>Outputs: <code>Events</code> collection, <code>TotalEvents</code>, <code>Page</code>, <code>PageSize</code>, <code>DurationMs</code>. Append <code>fa.audit.query.correlation</code> event. <br>Invariants: ordering by <code>TimestampUTC</code> ascending; if correlationId missing return empty result and append <code>fa.audit.query.missingCorrelation</code> warning. <br>Failure modes: extremely large runs; corrupted rows. <br>Recovery strategies: return results in streaming batches, flag corrupted rows with <code>CorruptionFlag</code> placeholder and append <code>fa.audit.corruption.detected</code>. <br>Implementation notes: leverage <code>OperationalAuditIndex</code> for locating row pointers and then read full rows. Provide optional <code>includeChainValidation</code> to compute and return chain validity status per event. <br>Testing: simulate interleaved events across runs and verify retrieval returns just the requested group in correct order. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: SearchAuditText(textQuery As String, Optional fuzzy As Boolean = False, Optional maxResults As Long = 500) As Dictionary</strong> — Purpose & contract:<br>1. Perform text search across <code>OperationalAudit.Details</code> and <code>EvidenceRefs</code> returning matching <code>EventID</code>, <code>PreviewSnippet</code>, <code>Score</code>, and <code>MatchTokens</code>. Use token and trigram inverted indexes to compute relevance. <br>Inputs: <code>textQuery</code>, <code>fuzzy</code>, <code>maxResults</code>. <br>Outputs: <code>Matches</code> collection sorted by score desc and appended <code>fa.audit.search.executed</code>. <br>Invariants: use deterministic scoring combining exact token matches, trigram overlap, and recency boost. <br>Failure modes: too broad queries producing massive result set; index stale producing misses. <br>Recovery strategies: when results exceed threshold return top N with <code>TooManyMatchesWarning</code> and recommend filter refinements; support wildcard and quoted phrase exact match indicators. <br>Implementation notes:<br>1. Scoring weights: token-exact 0.6, trigram overlap 0.25, recency boost 0.15 by default (configurable). <br>2. Fuzzy mode uses trigram Jaccard or Levenshtein with threshold. <br>Observability: log time and results. <br>Testing: test phrase searches, fuzzy near-miss, and performance on large index. <br>Conceptual PQ: build <code>PQ_AuditSearchHits</code> for auditors to review top hits in Excel. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: CorrelateEventsByRunAndActor(runId As String, actorId As String, Optional gapThresholdSeconds As Long = 300) As Dictionary</strong> — Purpose & contract:<br>1. Produce a sequencing view of events for a given <code>runId</code> and <code>actorId</code> with computed elapsed times between consecutive events, <code>AvgTimeBetweenEvents</code>, <code>MaxGap</code>, and <code>SuspiciousGaps</code> list for intervals > threshold. <br>Inputs: <code>runId</code>, <code>actorId</code>, <code>gapThresholdSeconds</code>. <br>Outputs: <code>Sequence</code> collection with <code>EventID</code>, <code>TimestampUTC</code>, <code>ElapsedSincePrevSec</code>, <code>Context</code>, and <code>Summary</code> statistics. Append <code>fa.audit.correlate.executed</code>. <br>Invariants: timestamps normalized to UTC. <br>Failure modes: missing timestamps; mixed timezones pre-normalization. <br>Recovery strategies: normalize to UTC and flag events lacking timestamp as <code>TimestampMissing</code> and include in summary. <br>Implementation notes: produce output optimized for timeline charts and include <code>ContextSnippet</code> for each event to assist forensic triage. <br>Testing: synthetic sequences with known gaps and outliers to validate detection. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: QueryAuditByEventTypeAndSeverity(startDate As Date, endDate As Date, eventTypes As Variant, minSeverity As Long) As Dictionary</strong> — Purpose & contract:<br>1. Provide common reporting query for auditors to get event totals and list of high-severity events across time windows. <br>Inputs: startDate, endDate, eventTypes (array or CSV), minSeverity. <br>Outputs: <code>SummaryCounts</code> per <code>EventType</code>, <code>HighSeverityEvents</code> list, <code>DurationMs</code>. Append <code>fa.audit.query.summary</code> event. <br>Invariants: date window inclusive; validate <code>minSeverity</code> range. <br>Testing: ensure counts match raw table scans. <br>Conceptual PQ & DAX: <code>PQ_Audit_Summary</code> and DAX <code>CriticalEventsByType</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ExportAuditToCSV(outPath As String, Optional filter As Variant) As Dictionary</strong> — Purpose & contract:<br>1. Export audit rows to CSV with canonical field ordering and UTF-8 BOM. Replace multiline cells with stable escapes (<code>\n</code>) or place long details into supplementary <code>.details</code> files and reference them. Return path and computed SHA256. <br>Inputs: <code>outPath</code>, <code>filter</code> similar to <code>QueryAudit</code>. <br>Outputs: <code>FilePath</code>, <code>Sha256</code>, <code>RowsExported</code>. <br>Invariants: canonical field ordering and consistent newline representation for hashing. <br>Failure modes: IO errors, memory limits for huge exports. <br>Recovery strategies: streaming export row-by-row with periodic flush, and optionally compress during export. Append <code>fa.audit.export.csv</code>. <br>Testing: export large datasets and re-import to validate equality. <br>PQ guidance: PQ can consume the CSV for external analysis. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ImportAuditFromCSV(csvPath As String, Optional dryRun As Boolean = True, Optional conflictResolution As String = "skip") As Dictionary</strong> — Purpose & contract:<br>1. Re-import exported audit rows for recovery or augmentation. In <code>dryRun</code> mode validate rows and return <code>Plan</code> with duplicates and conflicts; in live mode append non-duplicates or follow <code>conflictResolution</code> rules (<code>skip</code>, <code>overwrite</code>, <code>merge</code>). Always preserve <code>EventID</code> and avoid introducing duplicate <code>EventID</code>s. <br>Inputs: <code>csvPath</code>, <code>dryRun</code>, <code>conflictResolution</code>. <br>Outputs: <code>Plan</code> or <code>ImportSummary</code> with counts and conflict list. <br>Invariants: do not permit silent overwrites without explicit <code>overwrite</code> instruction and admin sign-off logged. <br>Failure modes: duplicate eventIDs, invalid timestamps, missing fields. <br>Recovery strategies: produce conflict resolution plan and require operator confirmation for destructive actions; append <code>fa.audit.import.*</code> events. <br>Testing: round-trip export/import and conflict injection tests. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: RotateAuditLogs(retentionDays As Long, Optional minRunsToKeep As Long = 10) As Dictionary</strong> — Purpose & contract:<br>1. Implement retention policy: for runs older than <code>retentionDays</code>, build forensic bundles, sign them, move them to long-term archive, and prune corresponding audit rows from the live workbook while ensuring at least <code>minRunsToKeep</code> latest runs are retained. Return <code>RotatedRuns</code>, <code>ArchivedBundles</code>, <code>RemainingRuns</code>. <br>Inputs: <code>retentionDays</code>, <code>minRunsToKeep</code>. <br>Outputs: rotation summary and append <code>fa.audit.rotate.completed</code> event. <br>Invariants: do not delete until archive bundle hash computed and bundle verified copied to storage; maintain <code>ArchiveIndex</code> mapping runs->bundles. <br>Failure modes: archive copy fails, evidence missing for runs, concurrent run in progress. <br>Recovery strategies: acquire run-level locks, skip rotating runs with incomplete evidence and append <code>fa.audit.rotate.skipped</code>, and record remediation tasks. <br>Implementation notes:<br>1. Rotation typically runs nightly; include dry-run mode for safe previews. <br>2. When pruning, prefer per-run grouping for atomicity: create run bundle -> verify -> delete rows referencing run -> append <code>fa.audit.rotate.pruned</code> with counts. <br>Observability: rotation metrics stored in <code>AuditRotationMetrics</code>. <br>Testing: run rotation in dry-run and live mode over sample datasets and validate integrity afterward. <br>Conceptual PQ: PQ index of <code>ArchiveIndex</code> for audit reporting. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: PruneOldLogs(keepCount As Long) As Dictionary</strong> — Purpose & contract:<br>1. Force-prune older audit events keeping only the latest <code>keepCount</code> rows, but only after proactively creating forensic bundles and writing an archival index. Return <code>PrunedCount</code> and <code>ArchiveBundles</code>. <br>Inputs: <code>keepCount</code>. <br>Outputs: <code>PrunedCount</code>, <code>LastPrunedEventID</code>. <br>Invariants: prune is destructive only after successful archival; must be explicitly authorized and logged with both operator and admin approval events. <br>Failure modes: attempted prune without archive; partial prune due to IO. <br>Recovery strategies: require pre-checks and checkpoint snapshot; store partial results in <code>_incomplete</code> folder; append <code>fa.audit.prune.failed</code>. <br>Testing: prune scenarios with constrained keepCount and ensure rollback capability. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ReplayAuditEventsToExternalSystem(webhookUrl As String, filter As Variant, Optional batchSize As Long = 100, Optional authHeader As Variant = Nothing, Optional maxRetries As Long = 5) As Dictionary</strong> — Purpose & contract:<br>1. Send batches of audit events to an external SIEM/GRC endpoint with deterministic batching, idempotency via BatchID, HMAC signature or API auth headers, retry/backoff, and durable outbound queue for failures. <br>Inputs: <code>webhookUrl</code>, <code>filter</code>, <code>batchSize</code>, <code>authHeader</code>, <code>maxRetries</code>. <br>Outputs: <code>SentBatches</code>, <code>FailedBatches</code>, <code>LastSentEventID</code>. Append <code>fa.audit.replay.started</code> and <code>fa.audit.replay.completed</code> events. <br>Invariants: each batch includes <code>BatchID</code>, <code>Events[]</code>, and <code>BatchHash</code>; external system should return 2xx to accept. <br>Failure modes: network errors, rate limiting, auth failures. <br>Recovery strategies: exponential backoff with jitter, <code>RetryQueue</code> persisting failed batches to disk with resumed replay capability, and operator alerts for persistent failures. <br>Implementation notes:<br>1. For idempotence include <code>BatchID</code> and <code>BatchHash</code> and allow external consumer to dedupe. <br>2. Respect privacy: do not send PII to external systems unless allowed and recorded in <code>OperationalAudit</code>. <br>Testing: mock webhook endpoints returning 200, 429, and 5xx to validate backoff and retry logic. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: BuildForensicBundleIndex(runId As String) As Dictionary</strong> — Purpose & contract:<br>1. Create a machine-readable index inside a forensic bundle enumerating all files, relative paths, SHA256 checksums, sizes, MIME types, <code>SignedBy</code> fields, retention tags, and PII redaction flags. Useful for quick verification and automated ingest. <br>Inputs: <code>runId</code>. <br>Outputs: <code>IndexPath</code>, <code>IndexSha256</code>, <code>FileCount</code>. Append <code>fa.audit.bundle.index.created</code>. <br>Invariants: index must be deterministic in ordering to enable consistent checksum; include <code>RetainedByPolicy</code> boolean for each file. <br>Failure modes: missing files, mismatched checksums. <br>Testing: create index and verify checksums for all files. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ValidateAuditTrail(Optional runId As String = "") As Dictionary</strong> — Purpose & contract:<br>1. Run a set of control checks across pipeline artifacts to validate completeness and integrity: presence and checksum of <code>PopulationSnapshot</code>, presence of <code>SamplingConfigSnapshot</code>, <code>SamplingAudit</code> entry, <code>SelectedSample</code> table, <code>SampleReconciliations</code>, <code>AnomalyLog</code>, <code>EvidenceIndex</code> entries with matching evidence for claimed attachments, <code>SignOff</code> completeness where required, and presence of <code>Manifest</code> and <code>ForensicBundle</code> when run marked closed. Return <code>ValidationReport</code> with <code>Checks</code> array (each check: <code>CheckID</code>, <code>Description</code>, <code>Status</code> Pass/Fail/Warning, <code>EvidencePointer</code>, <code>RemediationSuggestion</code>). <br>Inputs: optional <code>runId</code> (defaults to latest run). <br>Outputs: <code>ValidationReport</code> and append <code>fa.control.validation.completed</code> event. <br>Control checks (examples):<br>1. <code>PopulationSnapshotIntegrity</code> — verify <code>PopulationSnapshot</code> SHA256 matches stored value. <br>2. <code>SamplingConfigFrozen</code> — confirm <code>SamplingConfigSnapshot</code> exists and is write-protected. <br>3. <code>SelectedSampleAuditTrail</code> — check <code>SamplingAudit</code> exists with seed and algorithm and matches <code>SelectedSample</code> contents. <br>4. <code>ReconciliationTracePresence</code> — confirm <code>ReconciliationTrace</code> exists for each sample row. <br>5. <code>EvidenceCoverage</code> — percentage of samples with required evidence above threshold. <br>6. <code>SignOffCompleteness</code> — all sign-off-required samples have recorded <code>SignOff</code> entries matching approval matrix. <br>Failure modes and remediation: automated remediation actions include re-exporting manifests, re-copying evidence, notifying owners via <code>modControls</code> reminders, or escalating to forensics. <br>Implementation notes:<br>1. Implement control checks as separate small functions enabling unit testing and incremental checks. <br>2. Write <code>ControlValidationReport</code> sheet and include machine-readable JSON row for inspector consumption. <br>Testing: create deliberately incomplete runs to verify each check flags correctly and recommended remediation is actionable. <br>Conceptual PQ: <code>PQ_ControlValidation</code> for dashboarding control results. <br>Conceptual DAX: <code>ControlPassRate = DIVIDE(CALCULATE(COUNTROWS(ControlReport,ControlReport[Status]=&quot;Pass&quot;)),COUNTROWS(ControlReport))</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: RotateAndPruneWithPolicy(policyRef As String) As Dictionary</strong> — Purpose & contract:<br>1. High-level orchestrator that reads an organization retention policy identified by <code>policyRef</code> and calls <code>RotateAuditLogs</code> and <code>PruneOldLogs</code> accordingly while ensuring all required artifacts are archived; returns <code>RotationSummary</code> and append <code>fa.audit.rotateandprune.executed</code>. <br>Inputs: <code>policyRef</code>. <br>Outputs: summary dict. <br>Invariants: policy may include exemptions for certain runs (legal holds) that must not be rotated; implement hold checks. <br>Failure modes: policy missing or ambiguous; archive target unreachable. <br>Implementation notes: ensure pre-flight dry-run and operator confirmation for destructive actions; append <code>fa.audit.rotateandprune.dryrun</code> when run in dry mode. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ReplayAuditEventsAndValidateAck(webhookUrl As String, filter As Variant, Optional batchSize As Long = 100) As Dictionary</strong> — Purpose & contract:<br>1. Extended replay that requires acknowledgment tokens from external system for each batch; store ack tokens in <code>OutboundAckIndex</code> and append <code>fa.audit.replay.ack.received</code> on success. <br>Inputs/Outputs: similar to ReplayAuditEventsToExternalSystem with ack handling. <br>Failure modes: missing ack, inconsistent batch states; recovery via idempotent replay and recording of ack tokens. <br>Testing: simulate external ack flows and verify recorded tokens. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: PruneEvidenceWhenPolicyAllows(runId As String, retentionPolicyKey As String) As Dictionary</strong> — Purpose & contract:<br>1. Prune (or migrate) evidence files for a run according to <code>retentionPolicyKey</code>: either move to cold storage, obfuscate, or delete while recording actions in <code>EvidenceArchiveIndex</code> and appending <code>fa.evidence.pruned</code>. Requires operator and legal approvals recorded as signoffs. <br>Inputs: <code>runId</code>, <code>retentionPolicyKey</code>. <br>Outputs: <code>PrunedFilesCount</code>, <code>MigrationBundles</code>, <code>Errors</code>. <br>Invariants: delete only after proof of archival and append irreversible audit events recording the action, operator, and approvals. <br>Failure modes: missing archive copy, legal hold preventing deletion. <br>Recovery strategies: skip and produce remediation task. <br>Testing: simulate retention action with required approvals and verify logs. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ExportOperationalAuditSummaryForDashboard(periodStart As Date, periodEnd As Date, Optional outPath As String = "") As Dictionary</strong> — Purpose & contract:<br>1. Pre-compute summary metrics and export simple CSV or place data on a sheet for dashboards. Metrics: events per module, critical event counts, average time between events per run, anomalies by severity, evidence coverage, manifest parity failures. Return <code>SummaryPath</code> or sheet name. Append <code>fa.audit.summary.exported</code>. <br>Inputs: periodStart, periodEnd, optional outPath. <br>Outputs: path or sheet reference and metrics counts. <br>Implementation notes: ensure summary generation uses index and supports incremental refresh. <br>Conceptual DAX: <code>AvgEventsPerRun = AVERAGEX(GROUPBY(OperationalAudit,OperationalAudit[RunID],&quot;EvtCnt&quot;,COUNTROWS(CURRENTGROUP())),[EvtCnt])</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: AppendAuditEventForControlCheck(checkId As String, runId As String, status As String, details As String) As String</strong> — Purpose & contract:<br>1. Convenience wrapper to append control-check audit events with structured details and severity mapping. Returns <code>EventID</code>. <br>Implementation notes: map <code>status</code> to severity and include <code>CheckID</code> in <code>EventType</code>. Append <code>fa.control.check.&lt;id&gt;</code> event. <br>Testing: run for all control checks to ensure correct severity assignment. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Function: ReplayAuditEventsToSFTP(sftpConfig As Dictionary, filter As Variant, Optional compress As Boolean = True) As Dictionary</strong> — Purpose & contract:<br>1. Alternative outbound delivery: assemble batches, compress optionally, and upload to SFTP location with integrity check via SHA256 files. Append <code>fa.audit.replay.sftp</code>. <br>Inputs: sftpConfig, filters; outputs include <code>UploadedFiles</code>, <code>FailedUploads</code>. <br>Failure modes: connectivity, auth. <br>Recovery: background retry queue and operator alerts. <br>Testing: test with mock SFTP. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Cross-cutting concerns, governance and implementation mandates (modAudit)</strong> — Requirements and guardrails to implement across all modAudit functions: <br>1. <strong>Append-only semantics:</strong> never mutate historical <code>OperationalAudit</code> rows; implement supplemental metadata rows (linked by <code>EventID</code>) for any post-facto annotations; make this behavior explicit in developer docs. <br>2. <strong>Canonicalization & deterministic serialization:</strong> centralize canonicalization in <code>modUtils.CanonicalizeText</code>; canonical JSON ordering, LF newlines, NFKC normalization, whitespace trimming, and stable key ordering all required to compute repeatable SHA256 values. <br>3. <strong>Hashing algorithms:</strong> use SHA256 for per-event and per-file hashing; store hex and base64; include both representations in manifests for interop. <br>4. <strong>Chain-of-trust:</strong> optional chain hashing across events to provide tamper-evidence; store <code>PreviousChainHash</code> and compute <code>ChainHash = SHA256(PreviousChainHash || EventHash)</code> where chain is used. <br>5. <strong>Signatures & key management:</strong> do not store private keys in workbook; reference secure key vaults using a <code>signingKeyRef</code>. Provide HMAC fallback (explicitly logged) when PKI not available. <br>6. <strong>Atomic IO patterns:</strong> write to temp worksheets or temp folder and then perform an atomic rename/move to final path to minimize partial artifacts. <br>7. <strong>Locking & concurrency:</strong> implement optimistic short-lived locks using <code>LockAuditSheet</code> with timeout and exponential backoff; in network-shared scenarios use file-level locks where possible and record lock attempts as audit events. <br>8. <strong>Error codes:</strong> standardize deterministic error codes across module (e.g., <code>ERR_AUDIT_IO_001</code>, <code>ERR_AUDIT_HASH_MISMATCH_002</code>, <code>ERR_AUDIT_SIGNATURE_MISSING_010</code>) and write them to audit rows for incident tracking. <br>9. <strong>Observability & telemetry:</strong> produce telemetry events <code>audit.append.durationMs</code>, <code>audit.export.durationMs</code>, <code>audit.verify.durationMs</code>, <code>audit.rotate.durationMs</code>, and measure counts per module. Expose a <code>AuditTelemetry</code> sheet summarizing key metrics for dashboarding. <br>10. <strong>Privacy and redaction policy:</strong> implement <code>RedactPII(fields[])</code> that creates redacted view for exports while preserving an unaltered internal forensic copy; redaction decision must be recorded as an audit event <code>fa.audit.redaction</code> including approver and reason. <br>11. <strong>Retention policy integration:</strong> functions <code>RotateAuditLogs</code>, <code>PruneOldLogs</code>, and <code>PruneEvidenceWhenPolicyAllows</code> must consult central retention policy definitions and legal hold lists to avoid accidental deletion under hold. <br>12. <strong>Performance & scalability patterns:</strong> for large volumes support externalization of <code>OperationalAudit</code> to chunked CSV files and maintain <code>OperationalAuditIndex</code> in workbook pointing to file offsets; provide streaming export and import to avoid memory pressure. <br>13. <strong>Testing & QA:</strong> include a comprehensive <code>modTests</code> fixture with deterministic RNG seeds and synthetic datasets to cover append, export, sign, verify, rotate, prune, import, query, and search behaviors; include performance tests and simulated failure injection. <br>14. <strong>Developer tooling & docs:</strong> <code>modDevTools.ExportModuleDocs</code> must include <code>modAudit</code> interface signatures, parameter contracts, expected outputs, error codes, dependencies on <code>modUtils</code> and <code>modFX</code>, and sample sequences for acceptance tests. <br>15. <strong>Operational runbook:</strong> provide runbook pages covering emergency override procedures, forensic recovery steps, rotation and prune dry-run instructions, and operator contact lists; each runbook action must instruct to append corresponding audit events (e.g., <code>fa.audit.override.executed</code>) for traceability. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Inter-module interaction (how modAudit is used by other modules)</strong> — Integration mapping and per-call expectations: <br>1. <strong>PopulationPrep (Power Query) -> modAudit:</strong> on PQ import completion PQ calls <code>AppendAudit(&quot;PQ.ImportCompleted&quot;, ...)</code> including <code>PQ_ImportLog</code> summary; PQ must snapshot query M scripts into <code>PQ_Snapshot</code> and include pointer in manifest. <br>2. <strong>SamplingEngine -> modAudit:</strong> <code>SelectSample</code> calls <code>AppendAudit(&quot;SampleSelected&quot;,...)</code> for the sample run; sampling engine must pass <code>Seed</code>, <code>Method</code>, <code>Strata</code> and <code>SampleIDs</code> summary. <code>SamplingAudit</code> sheet contains full reproducible seed and algorithm snapshot. <br>3. <strong>ReconciliationEngine -> modAudit:</strong> for each sample <code>AppendAudit(&quot;Reconciliation.Computed&quot;,...)</code> with <code>PaymentID</code>, <code>CalculatedNet</code>, candidate bank matches summary and chosen candidate ID (if selected). Also append per-candidate <code>BankMatch.CandidateFound</code> events. <br>4. <strong>AnomalyDetector -> modAudit:</strong> append <code>Anomaly.Flagged</code> for each flagged sample including <code>RuleID</code>, <code>Severity</code>, <code>EvidencePointer</code> and <code>RecommendedAction</code>. <br>5. <strong>modEvidence -> modAudit:</strong> calls <code>AppendAuditAttachment</code> to attach evidence and <code>AppendAudit(&quot;Evidence.Attached&quot;,...)</code> to record metadata and copy status. <br>6. <strong>modSignOff -> modAudit:</strong> <code>RecordSignOff</code> writes immutable signoff entry and calls <code>AppendAudit(&quot;SignOff.Recorded&quot;,...)</code> with signer and role. <br>7. <strong>AuditExport -> modAudit:</strong> before exporting final auditor workbook call <code>ExportAuditManifest</code> to produce manifest files; append <code>fa.manifest.exported</code>. <br>8. <strong>modControls.AttemptClose -> modAudit:</strong> as AttemptClose runs validation steps it must call <code>AppendAudit</code> per major decision (e.g., <code>Close.Attempt</code>, <code>Close.Blocked</code>, <code>Close.Succeeded</code>) and include <code>CloseBlockReport</code> details. <br>9. <strong>Archive/Telemetry -> modAudit:</strong> long-running rotation and nightly parity jobs call <code>RotateAuditLogs</code> and <code>VerifyAuditIntegrity</code> and append <code>fa.audit.rotate.*</code> and <code>fa.audit.verify.*</code> events. <br>10. <strong>modBankMatcher/modFX/modWeights/etc. -> modAudit:</strong> when these modules perform deterministic decisions that affect evidence state they must append events summarizing the decision and relevant pointers for forensic traceability. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Conceptual Power Query (PQ) guidance for modAudit artifacts (human-readable conceptual steps)</strong> — PQ recipes auditors should include in forensic bundle and documentation (conceptual only; no code):<br>1. <strong>PQ_OperationalAuditIndex (conceptual steps):</strong> import <code>OperationalAuditIndex</code> sheet -> promote headers -> convert <code>TimestampUTC</code> to datetime -> compute daily buckets -> group by <code>Module</code> and <code>EventType</code> to produce daily counts for dashboards -> output <code>PQ_Audit_DailyCounts</code>. <br>2. <strong>PQ_ManifestPreview (conceptual steps):</strong> load <code>manifest.csv</code> -> promote headers -> parse <code>EventHash</code> as text -> join with <code>PopulationSnapshot</code> on <code>PaymentID</code> when present -> flag missing evidence entries -> output <code>MissingEvidenceReport</code> for remediation. <br>3. <strong>PQ_ForensicRehydrate (conceptual steps):</strong> load <code>manifest.events</code> -> expand <code>DetailsPointer</code> by joining with <code>OperationalAuditDetailsLong</code> -> join <code>ReconciliationTrace</code> and <code>CandidateBankMatches</code> tables included in manifest -> produce <code>ForensicReconciliationView</code> for detailed examination. <br>4. <strong>PQ_EvidenceCoverage (conceptual steps):</strong> join <code>SampleReconciliations</code> with <code>EvidenceIndex</code> to compute <code>HasEvidence</code> and produce <code>EvidenceCoverageByStratum</code> table. <br>Important PQ practice: snapshot and include the final M-scripts used in <code>PQ_Snapshot</code> folder in the manifest so auditors can re-run queries in a stable environment. Use stable query names to guarantee reproducibility. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Conceptual DAX guidance and sample conceptual measures for auditor dashboards (human-readable formulas)</strong> — DAX measures conceptual (auditors can implement in Power BI):<br>1. <code>TotalAuditEvents = COUNTROWS(OperationalAudit)</code>.<br>2. <code>CriticalEvents = CALCULATE(COUNTROWS(OperationalAudit),OperationalAudit[Severity] &gt;= 4)</code>.<br>3. <code>EventsPerRun = COUNTROWS(OperationalAudit)</code> with <code>RunID</code> in matrix rows to show per-run volumes.<br>4. <code>AvgReconciliationVariance = AVERAGEX(FILTER(SampleReconciliations, SampleReconciliations[FlagLevel] &lt;&gt; &quot;None&quot;), ABS(SampleReconciliations[CalculatedNet] - SampleReconciliations[BankAmount]) / SampleReconciliations[CalculatedNet])</code> (conceptual). <br>5. <code>EvidenceAttachedPct = DIVIDE(CALCULATE(COUNTROWS(SampleReconciliations, SampleReconciliations[HasEvidence] = TRUE)), COUNTROWS(SampleReconciliations))</code>.<br>6. <code>SignedBundlesPct = DIVIDE(CALCULATE(COUNTROWS(DeliverablesManifest, DeliverablesManifest[Signed] = TRUE)), COUNTROWS(DeliverablesManifest))</code>.<br>7. <code>ControlPassRate = DIVIDE(CALCULATE(COUNTROWS(ControlValidationReport, ControlValidationReport[Status] = &quot;Pass&quot;)), COUNTROWS(ControlValidationReport))</code>.<br>Modeling guidance: avoid importing raw <code>Details</code> text into the model to save memory; import summarized fields and signature/flag columns. Use <code>EventID</code> and <code>RunID</code> as lookup keys to connect <code>OperationalAudit</code>, <code>SampleReconciliations</code>, <code>EvidenceIndex</code>, and <code>DeliverablesManifest</code> tables. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Developer acceptance tests & delivery criteria for modAudit</strong> — Explicit deliverables and how to validate them (acceptance criteria):<br>1. <strong>OperationalAudit schema delivered</strong> — sheet exists with required columns: <code>EventID</code>, <code>CorrelationID</code>, <code>RunID</code>, <code>Module</code>, <code>Function</code>, <code>EventType</code>, <code>ActorID</code>, <code>TimestampUTC</code>, <code>Severity</code>, <code>DetailsPointer</code>, <code>EvidenceRefs</code>, <code>ManifestRef</code>, <code>EventHash</code>, <code>PreviousChainHash</code>, <code>ChainHash</code>, <code>Signed</code> boolean, <code>SignatureRef</code>. Validation: append sample events and recompute <code>EventHash</code> to verify deterministic hashing. <br>2. <strong>AppendAudit API implemented</strong> — behavior validated via unit tests that ensure atomic append, hash computation, chain hashing, and error recovery on simulated IO noise. <br>3. <strong>ExportAuditManifest implemented</strong> — produce <code>manifest.json</code> and <code>manifest.csv</code> with deterministic SHA; acceptance test by exporting and verifying SHA read-back equals computed value. <br>4. <strong>VerifyAuditIntegrity implemented</strong> — acceptance by intentionally corrupting a file and confirming function reports mismatch and parityDiff. <br>5. <strong>ArchiveForensicBundle and SignAuditBundle implemented</strong> — produce bundle .zip with signatures and pass signature verification test. <br>6. <strong>RotateAuditLogs and PruneOldLogs implemented</strong> — dry-run and live-run acceptance tests ensuring no data lost without archival. <br>7. <strong>QueryAudit and SearchAuditText implemented</strong> — functional tests for filters, paging, fuzzy matches and exact phrase matches. <br>8. <strong>Audit index and search tokens</strong> — validate index rebuild and search response times on realistic data sizes. <br>9. <strong>AppendAuditAttachment & EvidenceIndex</strong> — add attachments, compute SHA256, and validate ability to revalidate via <code>VerifyAuditIntegrity</code>. <br>10. <strong>Control validation</strong> — run <code>ValidateAuditTrail</code> against sample runs and ensure checks catch intentional defects. <br>11. <strong>Docs & Runbook</strong> — include <code>DevDocs</code> and operator runbook with emergency override steps, and ensure <code>modDevTools.ExportModuleDocs</code> prints <code>modAudit</code> API. <br>12. <strong>Tests</strong> — <code>modTests</code> must contain unit, integration, and failure-injection tests covering all critical branches and edge cases. Each successful test run must append <code>fa.audit.devtests.completed</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Operational narratives and illustrated examples (walkthroughs)</strong> — Three detailed narratives explaining typical and edge-case runs with audit activity: <br><strong>Narrative A — Happy-path end-to-end run:</strong><br>1. PQ ingestion completes; <code>PQ</code> writes <code>PQ_ImportLog</code> and calls <code>AppendAudit(&quot;PQ.ImportCompleted&quot;, &quot;pq_service&quot;, &quot;{\&quot;rowsIn\&quot;:50000,\&quot;rowsOut\&quot;:48720,\&quot;issues\&quot;:14}&quot;)</code>. <br>2. Sampling config loaded and <code>AppendAudit(&quot;Sampling.ConfigSnapshot&quot;,&quot;analyst_a&quot;,&quot;{\&quot;method\&quot;:\&quot;Stratified\&quot;,\&quot;strata\&quot;:[...]}&quot;,, &quot;MANIFEST-20260212-01&quot;)</code> writes snapshot. <br>3. <code>SamplingEngine</code> selects sample and calls <code>AppendAudit(&quot;SampleSelected&quot;,&quot;sampling_engine&quot;,&quot;{\&quot;sampleSize\&quot;:200,\&quot;seed\&quot;:12345}&quot;)</code>. <code>SelectedSample</code> table is written. <br>4. <code>ReconciliationEngine</code> processes each sample; for PaymentID 12345 append <code>AppendAudit(&quot;Reconciliation.Computed&quot;,&quot;recon_engine&quot;,&quot;{\&quot;PaymentID\&quot;:12345,\&quot;calcNet\&quot;:4200,\&quot;bankCandidates\&quot;:2}&quot;)</code>. <code>BankMatcher</code> emits <code>BankMatch.CandidateFound</code> events per candidate. <br>5. <code>modEvidence</code> attaches supporting remittance advices, calls <code>AppendAuditAttachment</code> and <code>AppendAudit(&quot;Evidence.Attached&quot;,&quot;user_jane&quot;,&quot;{\&quot;evidenceId\&quot;:\&quot;EVID-0003\&quot;,\&quot;type\&quot;:\&quot;pdf\&quot;}&quot;)</code>. <br>6. <code>modSignOff</code> records sign-off and calls <code>AppendAudit(&quot;SignOff.Recorded&quot;,&quot;signoff_service&quot;,&quot;{\&quot;paymentId\&quot;:12345,\&quot;signer\&quot;:\&quot;manager_bob\&quot;}&quot;)</code>. <br>7. <code>AuditExport</code> calls <code>ExportAuditManifest(&quot;MANIFEST-20260212-01&quot;,&quot;\\archive\manifests&quot;,True,True)</code>, which returns <code>ManifestSha256</code> and copies evidence; modAudit appends <code>fa.audit.manifest.exported</code>. <br>8. <code>ArchiveForensicBundle</code> creates a signed bundle <code>RUN-20260212-01.zip</code>, signs it, computes hash and <code>AppendAudit(&quot;Forensic.Bundle.Created&quot;,&quot;archive_service&quot;,&quot;{\&quot;bundle\&quot;:\&quot;RUN-20260212-01.zip\&quot;,\&quot;sha256\&quot;:\&quot;...\&quot;}&quot;)</code>. <br>9. <code>modControls.AttemptClose</code> runs validations, invokes <code>ValidateAuditTrail</code> and on success calls <code>AppendAudit(&quot;Close.Succeeded&quot;,&quot;controls&quot;,&quot;{\&quot;runId\&quot;:\&quot;RUN-20260212-01\&quot;}&quot;)</code>. <br>10. Run marked closed and telemetry summarized; dashboards reflect <code>PercentMatched</code>, <code>AvgVariance</code>, and <code>EvidenceCoverage</code>. <br><strong>Narrative B — Aggregated bank remittance and ambiguous matches (edge case):</strong><br>1. <code>ReconciliationEngine</code> finds a bank row that aggregates three net payments into a single payment; <code>BankMatcher</code> returns a candidate flagged as <code>AggregatedRemittanceCandidate</code> with sum match close to bank amount and evidence pointers missing. A <code>BankMatch.AggregatedDetected</code> audit event is appended. <br>2. <code>AnomalyDetector</code> flags High severity due to aggregation and missing direct evidence; <code>AppendAudit(&quot;Anomaly.Flagged&quot;,&quot;anomaly_engine&quot;,&quot;{\&quot;PaymentIDs\&quot;:[111,222,333],\&quot;rule\&quot;:\&quot;AGG_REMIT\&quot;,\&quot;severity\&quot;:4}&quot;)</code>. <br>3. <code>modEdgeCaseHandler</code> attempts to find matching population subset via combination matching (subset sum heuristic); attaches candidate grouping to evidence and appends <code>fa.edge.aggregation.suggested</code>. <br>4. Because confidence < threshold, export manifest includes candidates and notes <code>manual review required</code>; forensic bundle contains <code>AggregationAnalysis.csv</code> with reasoning and <code>AppendAudit(&quot;Forensic.AnalysisAdded&quot;,&quot;edgecase&quot;,&quot;...&quot;)</code>. <br><strong>Narrative C — Parity failure discovered during nightly job (incident flow):</strong><br>1. Nightly Parity Job runs <code>VerifyAuditIntegrity</code> against archived manifests and finds one manifest where <code>EVID-0099.pdf</code> checksum mismatches. <br>2. <code>VerifyAuditIntegrity</code> returns <code>IsValid=False</code> with <code>Problems=[&quot;Evidence/EVID-0099.pdf mismatch&quot;]</code>. <code>AppendAudit(&quot;Parity.Failure&quot;,&quot;parity_job&quot;,&quot;{\&quot;manifest\&quot;:\&quot;MANIFEST-20260201-01\&quot;,\&quot;problem\&quot;:\&quot;EVID-0099.pdf mismatch\&quot;}&quot;)</code> recorded. <br>3. System creates <code>parityDiff</code> forensic report, notifies operator, and opens remediation ticket. If evidence missing, recommend copying from source storage or regenerating from original bank mechanical sources; append <code>fa.audit.parity.remediation.planned</code>. <br>4. For high-severity parity failure, automatic escalation appends <code>fa.audit.alert.critical</code> and creates dedicated forensic artifact for legal review. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Operational runbook excerpt (what operators must do on key audit events)</strong> — Steps recorded as audit actions (instructions compressed):<br>1. <strong>On <code>Parity.Failure</code>:</strong> record event; gather <code>ForensicManifest</code> and <code>parityDiff</code>; notify legal and preserve bundle; do not alter archive; append remediation events with operator <code>AppendAudit</code>. <br>2. <strong>On <code>Close.Blocked</code>:</strong> follow <code>CloseBlockReport</code> remediation steps: request missing evidence, apply signoffs, or request supervised override (override requires dual approval appended as <code>fa.override.recorded</code>). <br>3. <strong>On <code>Signature.Failure</code>:</strong> check signing key availability, re-run signing, and if fallback used record <code>fa.audit.signature.fallback</code>. <br>4. <strong>On <code>Replay</code> failures:</strong> monitor <code>OutboundQueue</code>, attempt safe retries, and escalate persistent failures. <br>Each operator action must be accompanied by an <code>AppendAudit</code> call documenting actorId, action details, and timestamp for forensic traceability. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Developer notes and maintainability guidance for modAudit implementers</strong> — Implementation checklist and rationales:<br>1. <strong>Centralize canonicalization</strong> in <code>modUtils</code> and reuse across all hashing and equality checks to prevent subtle mismatches across environments and locales. <br>2. <strong>Avoid embedding private keys</strong>; reference them externally and provide clear error messages when unavailable. <br>3. <strong>Design for incremental indexing</strong>: keep <code>AppendAudit</code> cheap and update index asynchronously or incrementally to avoid large rebuilds. <br>4. <strong>Keep event payloads small</strong> in the main table; move verbose content to <code>OperationalAuditDetailsLong</code> to avoid Excel cell limits and to keep index operations fast. <br>5. <strong>Comprehensive unit tests</strong> covering deterministic hashing, chain recomputation, manifest reproducibility, signature verification, index rebuild, and search accuracy. <br>6. <strong>Fail-safe defaults</strong>: if signing or evidence copy fails, create manifest and append clear warnings rather than silently failing. <br>7. <strong>Telemetry and health checks</strong>: include lightweight periodic health checks and telemetry events the dashboard can surface. <br>8. <strong>Secure the archive folder</strong> with least-privilege filesystem permissions and record access in <code>OperationalAudit</code> when archives are retrieved. <br>9. <strong>Document error codes</strong> and ensure UI surfaces them to operators with recommended remediation steps. <br>10. <strong>Performance knobs</strong>: allow toggles for in-memory indexing vs sheet-based indexing, batch sizes for replay, and thresholds for evidence embedding. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Security, privacy and legal compliance notes (auditor-focused)</strong> — Policies and technical controls to implement:<br>1. <strong>PII handling:</strong> implement redaction workflows for exports; require explicit approval for full unredacted forensic exports; record approvals in audit trail with <code>AppendAudit</code> events. <br>2. <strong>Retention & legal holds:</strong> include hold management preventing prune/rotate of runs under legal hold and store <code>HoldReason</code> and <code>HoldExpiry</code> in <code>ArchiveIndex</code>. <br>3. <strong>Key management:</strong> integrate with enterprise key vaults, never hardcode secrets; if HMAC used, rotate keys periodically and record key rotation events. <br>4. <strong>Access controls:</strong> implement RBAC checks in <code>EnforceExportPermissions</code> before exporting sensitive artifacts; append <code>fa.audit.export.attempt</code> with result PASS/FAIL. <br>5. <strong>Tamper detection:</strong> rely on per-event <code>EventHash</code> and chain <code>ChainHash</code>; provide <code>VerifyAuditIntegrity</code> APIs to produce forensic parity reports; document verification procedures for legal teams. <br>6. <strong>Export signatures:</strong> prefer PKI detached signatures; record signer identity and cert fingerprint in manifest. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Appendix: error codes & deterministic responses (example list)</strong> — Standardized deterministic codes to be returned and logged: <br>1. <code>ERR_AUDIT_IO_001</code> — IO write failure when appending audit row; remediation: check file locks and disk space. <br>2. <code>ERR_AUDIT_HASH_MISMATCH_002</code> — computed hash does not match stored manifest entry; remediation: preserve evidence and open parity incident. <br>3. <code>ERR_AUDIT_SIGNATURE_MISSING_010</code> — signing key not available for requested signature; remediation: request key from key vault admin. <br>4. <code>ERR_AUDIT_QUERY_TOO_MANY_RESULTS_020</code> — query returned more results than threshold; remediation: refine filters or use pagination. <br>5. <code>ERR_AUDIT_EXPORT_PARTIAL_030</code> — manifest exported but some evidence copy failed; remediation: review manifest <code>Warnings</code> and re-run with <code>includeEvidence=True</code> after remediation. <br>6. <code>ERR_AUDIT_PRUNE_UNSAFE_040</code> — prune attempted while legal hold present; remediation: remove hold or archive separately upon legal approval. <br>Each error must be appended as an audit row and be surfaced to operators with explicit remediation steps. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Appendix: lengthy conceptual examples and step-by-step computations (expanded)</strong> — Example: chain-hash recomputation narrative for forensic verification:<br>1. <strong>Event append sequence</strong>: EVT-001, EVT-002, EVT-003. Each event has <code>EventHash</code> = SHA256(canonicalPayload). <br>2. <strong>Chain computation</strong>: <br> - For EVT-001 <code>ChainHash_001 = SHA256(&quot;&quot; || EventHash_001)</code> (where "" is empty string initial anchor). <br> - For EVT-002 <code>ChainHash_002 = SHA256(ChainHash_001 || EventHash_002)</code>. <br> - For EVT-003 <code>ChainHash_003 = SHA256(ChainHash_002 || EventHash_003)</code>. <br>3. <strong>Verification</strong>: to verify chain integrity for EVT-003 recompute sequentially and compare <code>ChainHash_003</code> with stored value; mismatch identifies earliest diverging event and triggers <code>fa.audit.chain.mismatch</code>. <br>4. <strong>Implication</strong>: chain mismatch implies tampering or unrecorded edits; remediation includes forensic recovery and freeze of archive. <br>5. <strong>Note</strong>: always store both <code>EventHash</code> and <code>ChainHash</code> in manifest for re-verification. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Appendix: choreography matrix (who calls modAudit and when)</strong> — Key calls and expected audit events (compact mapping): <br>1. <code>Power Query PopulationPrep</code> -> <code>AppendAudit(&quot;PQ.ImportCompleted&quot;,...)</code> on import finish.<br>2. <code>modSamplingConfig</code> -> <code>AppendAudit(&quot;Sampling.ConfigSnapshot&quot;,...)</code> when snapshot persisted.<br>3. <code>SamplingEngine</code> -> <code>AppendAudit(&quot;SampleSelected&quot;,...)</code> when sample created.<br>4. <code>ReconciliationEngine</code> -> <code>AppendAudit(&quot;Reconciliation.Computed&quot;,...)</code> per sample row.<br>5. <code>modBankMatcher</code> -> <code>AppendAudit(&quot;BankMatch.CandidateFound&quot;,...)</code> per candidate.<br>6. <code>AnomalyDetector</code> -> <code>AppendAudit(&quot;Anomaly.Flagged&quot;,...)</code> per anomaly.<br>7. <code>modEvidence</code> -> <code>AppendAuditAttachment</code> and <code>AppendAudit(&quot;Evidence.Attached&quot;,...)</code> when evidence linked.<br>8. <code>modSignOff</code> -> <code>AppendAudit(&quot;SignOff.Recorded&quot;,...)</code> on sign-off append.<br>9. <code>AuditExport</code> -> <code>ExportAuditManifest</code> and append <code>fa.audit.manifest.exported</code>.<br>10. <code>modControls.AttemptClose</code> -> append <code>fa.close.attempt</code>, <code>fa.close.blocked</code> or <code>fa.close.succeeded</code>. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Appendix: maintenance & upgrade guidance (long-term)</strong> — How to evolve modAudit safely:<br>1. Use schema versioning: add <code>AuditSchemaVersion</code> integer to <code>OperationalAudit</code> and <code>Manifest</code> metadata; on upgrades write migration scripts and append <code>fa.audit.schema.upgrade</code> event capturing changes. <br>2. Preserve backward compatibility for manifest consumers by adding optional fields rather than renaming or removing columns. <br>3. When changing canonicalization rules update <code>GeneratorVersion</code> and require re-export of past manifests if chain or hash determinism changes; append <code>fa.audit.canonicalization.update</code> event. <br>4. Provide compatibility adapters: older tools that expect old manifest shapes should be supported via transformation scripts included in <code>/docs/migrations/</code>. <br>5. Periodically rotate signing keys and record rotations by <code>fa.audit.key.rotation</code> event; document key rotation plan and maintain ability to verify older signatures until certificate expiry. </td></tr><tr><td data-label="modAudit — Per-function technical breakdown"> <strong>Final checklist for modAudit production rollout</strong> — Items that must be completed and logged before go-live (each item must have corresponding <code>fa.audit.devcheck</code> event):<br>1. Implemented <code>AppendAudit</code> with canonical hashing and chain hashing capability. <br>2. Implemented <code>AppendAuditAttachment</code> with evidence copying and SHA256 verification. <br>3. Built <code>OperationalAuditIndex</code> with tokenization and search. <br>4. Implemented <code>ExportAuditManifest</code> and <code>VerifyAuditIntegrity</code>. <br>5. Implemented <code>ArchiveForensicBundle</code> and <code>SignAuditBundle</code> with PKI/HMAC fallback. <br>6. Implemented <code>RotateAuditLogs</code>, <code>PruneOldLogs</code>, and retention policy integration. <br>7. Implemented <code>QueryAudit</code>, <code>SearchAuditText</code>, and <code>GetAuditEventsByCorrelationID</code>. <br>8. Implemented control validation <code>ValidateAuditTrail</code> and <code>modControls.AttemptClose</code> integration. <br>9. Added comprehensive <code>modTests</code> with pass/fail reporting. <br>10. Created operator runbook and developer docs captured by <code>modDevTools.ExportModuleDocs</code>. <br>11. Completed penetration checks for tamper-evidence and backup verification. <br>12. Completed privacy/PII redaction policy implementation and legal sign-off. <br>13. Completed performance tuning for expected production volumes and documented scaling thresholds. <br>14. Completed a sample forensic bundle and validated end-to-end rehydration by an independent reviewer. </td></tr></tbody></table></div><div class="row-count">Rows: 41</div></div><div class="table-caption" id="Table4" data-table="Docu_0193_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by **modBankMatcher — Per-function technical breakdown**"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;"><strong>modBankMatcher — Per-function technical breakdown</strong></div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Overview (module purpose, scope, and contract)</strong><br><strong>Purpose:</strong> Provide a reliable, auditable, high-performance set of VBA functions to find, score, and present candidate bank transactions that could correspond to a payroll net payment. The module supports exact and fuzzy amount matching, date-window searches, textual reference similarity, aggregated remittance detection (one bank row covering multiple payroll nets), multi-currency handling (handoff to FX), and scale-conscious indexing strategies to maintain performance on large bank files. The module also exposes utilities for caching, diagnostics, and unit-testing helpers used by the ReconciliationEngine.<br><strong>Scope:</strong> Functions for loading and indexing bank data, bucketed search by amount, date-window filtering, text tokenization and similarity scoring, candidate scoring aggregation, handling aggregated remittances and split payments, and export/logging of candidate evaluation traces. Integrates with the broader pipeline: Population (payment rows), ReconciliationEngine (per-sample reconciliation), modFX (currency conversion), modEvidence (evidence pointers), and modAudit (operational audit events).<br><strong>Non-goals:</strong> Do not perform final automatic resolution of ambiguous matches (unless configurable and confidence > threshold); do not modify bank source tables in-place (reads only); do not store plaintext credentials or external secrets.<br><strong>Audit & Reproducibility Contract:</strong> Every candidate match decision MUST be reproducible — seed, algorithm version, index snapshot timestamp, and any fallback rules used must be recorded to <code>BankMatcherAudit</code> and <code>ReconciliationTrace</code>. This module writes its decision trace to <code>BankMatcherTrace</code> for each evaluated payment. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: LoadBankTable(bankTableName As String, readOnly As Boolean, optional maxRows As Long = -1) As Long</strong><br><strong>Purpose & contract:</strong> Load and validate the bank payments table into the module's internal working structures (sheet-backed read handles and optionally in-memory dictionaries). Returns number of rows successfully indexed. Must preserve original sheet; do not mutate source table content. Primary consumer: BuildBankIndex, FindCandidateBankMatches.<br><strong>Inputs:</strong> <code>bankTableName</code> (sheet or named table identifier), <code>readOnly</code> flag (if True don't create temporary caches on disk), <code>maxRows</code> optional to cap for performance testing.<br><strong>Outputs:</strong> Row count (Long). Side effects: populates internal arrays/dictionaries: <code>BankRows()</code>, <code>BankAmountIndex</code> (if enabled), <code>BankDateIndex</code>, <code>BankTextIndex</code> metadata. Creates <code>BankLoadLog</code> entry with timestamp, rowcount, first/last dates, currency distribution and a small sample hash (for quick integrity checks).<br><strong>Invariants:</strong> Bank table must include canonical columns: <code>BankRowID</code>, <code>BankDate</code> (Date), <code>BankAmount</code> (Decimal), <code>BankCurrency</code>, <code>BankReference</code> (text), <code>BankAccount</code>, <code>PaymentBatchID</code> (optional). If currencies absent, assume single workbook currency but log warning. Function must normalize numeric fields (strip currency symbols, thousands separators) without losing information. Returns -1 on fatal error (invalid schema) and logs details to <code>BankLoadErrors</code>.<br><strong>Failure modes & recovery:</strong><br>1. Missing required columns — throw a descriptive error, append to <code>BankLoadErrors</code>, and return -1.<br>2. Non-parsable numeric or date values — record rows in <code>BankImportExceptions</code> sheet with reason; skip those rows and continue unless > threshold (configurable) then abort and return -1.<br>3. Exceeding Excel memory/timeouts — if <code>maxRows</code> not provided and row count exceeds <code>LargeTableThreshold</code>, log a performance warning and set <code>UseLightIndex=True</code> (sheet-scans with bucket caches) to avoid full in-memory index.<br><strong>Implementation details:</strong><br>1. Header detection: fuzzy match common alternative headers (<code>Amount</code>, <code>Credit</code>, <code>Debit</code>, <code>ValueDate</code>) using case-insensitive matching and small Levenshtein heuristic for common typos.<br>2. Parsing: create a typed in-memory array <code>BankRows(i)</code> storing <code>BankRowID</code>, <code>BankDate</code>, <code>BankAmount</code>, <code>BankAmountAbs</code>, <code>BankCurrency</code>, <code>BankReferenceTokens</code>, <code>BankAccount</code>, <code>PaymentBatchID</code>, <code>OriginalRowIndex</code>.<br>3. Normalization: amounts normalized to a numeric canonical form and a rounded "bucket amount" used for indexing (configurable rounding granularity). Dates normalized to UTC midnight where applicable.<br>4. Logging: create <code>BankLoadLog</code> sheet row with rowcount, distinct currencies, earliest/lates dates, and a CRC32 or SHA256 short fingerprint of first N rows for integrity checks.<br><strong>Complexity & performance:</strong> O(N) scanning time to build minimal indices; memory usage proportional to number of rows * size per row. For very large N (100k+), switch to bucketed file-backed indices or CSV streaming.<br><strong>Example & usage:</strong> <code>LoadBankTable(&quot;tblBank_YYYYMMDD&quot;, True)</code> loads bank table, populates indices, returns 34,512.<br><strong>Tests:</strong> Synthetic bank files with bad numeric formatting, missing currency, and extremely long <code>BankReference</code> values. Validate that exceptions are recorded and that partial loads succeed under configured thresholds. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: BuildBankIndex(roundTo As Double, enableTextIndex As Boolean, bucketSize As Double)</strong><br><strong>Purpose & contract:</strong> Build the search indices used by <code>FindCandidateBankMatches</code> — an amount-bucket index, date index, and optional inverted textual token index. The index enables O(1) bucket lookup by bucket key and efficient filtering by date window. Must preserve referential integrity back to <code>BankRows</code>. Stores index snapshot metadata to <code>BankIndexMetadata</code> including algorithm version and parameters.<br><strong>Inputs:</strong> <code>roundTo</code> (e.g., 0.01 for cents, 1.00 for whole currency units), <code>enableTextIndex</code> (Boolean), <code>bucketSize</code> (for grouping wide buckets; can be same as roundTo or larger for performance tuning).<br><strong>Outputs:</strong> Populates <code>BankAmountIndex</code> (Dictionary: bucketKey -> Collection of BankRowIDs), <code>BankDateIndex</code> (Dictionary: yyyy-mm-dd -> Collection), and if enabled <code>BankTokenIndex</code> (Dictionary: token -> Collection). Returns nothing but writes <code>BankIndexMetadata</code> sheet with <code>IndexCreatedTimestamp</code>, <code>RowCount</code>, <code>RoundTo</code>, <code>BucketSize</code>, <code>TextIndexEnabled</code> and <code>IndexVersion</code>.<br><strong>Invariants:</strong> Bucket key = Round(BankAmount / roundTo) * roundTo (stringified with fixed decimal format). Text tokens are normalized via <code>CanonicalizeText</code> (lowercase, NFKC, trim) and stopwords removed using configured list. Index snapshot must reference <code>BankLoadLog</code> fingerprint so index-to-source integrity is checkable.<br><strong>Failure modes & recovery:</strong><br>1. Out-of-memory when building text index on huge data — degrade gracefully by turning off text index and record <code>BankIndexNote</code> recommending <code>enableTextIndex=False</code> for large tables.<br>2. Hash collisions in naive bucket key stringification due to floating rounding — use integer bucket key (CInt(round(amount/roundTo))) stored as string to avoid floating point display differences.<br><strong>Implementation notes:</strong><br>1. Use VBA <code>Scripting.Dictionary</code> for indices. For Collections, use pre-sized arrays if maximum bucket size is known to reduce allocation overhead.<br>2. For performance, build <code>BankAmountIndex</code> first (since amount narrowing is the most discriminating) then add date and textual indices for the reduced candidate sets only when enabled.<br>3. Persist index metadata for reproducibility and debugging. Include <code>IndexBuildDurationMs</code> and <code>MemoryEstimateKb</code> in the metadata row.<br><strong>Observability & diagnostics:</strong> Provide a function <code>DumpBankIndexDiagnostics(outputSheet)</code> that writes top 100 buckets by frequency and a histogram of bucket sizes to the diagnostics sheet. Include suggestions to tune <code>roundTo</code> and <code>bucketSize</code> when skew is high.<br><strong>Example:</strong> <code>BuildBankIndex(0.5, True, 10)</code> builds half-currency cent rounding and text index; top bucket contains 1,204 candidates for payroll nets of 1,000.00 due to aggregated payroll remittances. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: ClearBankMatcherCache() As Boolean</strong><br><strong>Purpose & contract:</strong> Clear internal in-memory indices and caches used by the bank matcher; typically called before a re-load of bank tables or during tests. Must also increment <code>BankIndexMetadata.IndexVersion</code> and append a <code>CacheClearEvent</code> to audit log. Return True on success.<br><strong>Inputs:</strong> none.<br><strong>Outputs:</strong> Boolean success. Side effects: sets <code>InMemoryIndexBuilt=False</code> and frees dictionary objects to reduce memory. <br><strong>Implementation notes:</strong> Ensure proper <code>Set dict = Nothing</code> for all dictionaries to help VBA free memory. Write <code>CacheClearedTimestamp</code> to <code>BankIndexMetadata</code>. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: ValidateBankIndexIntegrity() As Boolean</strong><br><strong>Purpose & contract:</strong> Validate that the in-memory index matches the underlying bank table snapshot (via fingerprint from <code>BankLoadLog</code>). Returns True if match, False otherwise; writes <code>BankIndexIntegrityReport</code> with row-count mismatches, top-bucket mismatches, and sample row mismatches (showing expected vs actual). This is a control function used by <code>modControls.AttemptClose</code> to ensure that indexes used for matching are derived from the correct population snapshot.<br><strong>Inputs:</strong> none — reads <code>BankIndexMetadata</code> and <code>BankLoadLog</code> for comparisons.<br><strong>Outputs:</strong> Boolean validity. Side effects: writes detailed mismatch rows and appends <code>IndexIntegrityCheck</code> event to audit trail. <br><strong>Failure modes & remediation:</strong> If mismatch found, recommend re-running <code>LoadBankTable</code> and <code>BuildBankIndex</code> and mark any dependent <code>BankMatcherTrace</code> entries as <code>Orphaned</code> until re-run. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: UnitTests_RunBankMatcherTests(testMode As String) As Collection</strong><br><strong>Purpose & contract:</strong> Self-contained unit and integration tests focused on bank matching logic. Supports <code>smoke</code>, <code>full</code>, and <code>stress</code> modes and returns structured results for each test. Writes <code>BankMatcherTestResults</code> sheet with pass/fail, duration, and error details. Must be non-destructive and use test fixtures in hidden workbook sheets.<br><strong>Inputs:</strong> <code>testMode</code> string.<br><strong>Outputs:</strong> Collection of test result tuples including <code>TestID</code>, <code>Description</code>, <code>Passed</code>, <code>Message</code>. Side effects: when <code>testMode=&quot;stress&quot;</code> may temporarily build in-memory indices for large synthetic datasets to test scaling. <br><strong>Testing coverage:</strong> Exact match test, small tolerance match, date-window edge cases, tokenization Unicode cases, aggregated remittance greedy approximation, cross-currency with known FX rates (mocked), deterministic pruning under heavy buckets, and trace reproducibility. Ensure <code>UnitTests_RunBankMatcherTests</code> asserts that <code>FindCandidateBankMatches</code> preserves determinism across repeated runs with same seed and index version. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: BankMatcherConfigLoad(configSheetName As String) As Dictionary</strong><br><strong>Purpose & contract:</strong> Load configuration parameters that drive algorithm behavior (rounding, bucket sizes, tolerancePct defaults, weights, trace verbosity, memory thresholds) from a configuration sheet. Returns a dictionary of validated parameters and writes back a <code>ConfigLoadLog</code> entry. If required configuration keys are missing, populate them with safe defaults and add warnings to <code>BankMatcherConfigWarnings</code>.<br><strong>Inputs:</strong> <code>configSheetName</code> (sheet name).<br><strong>Outputs:</strong> <code>Scripting.Dictionary</code> of config values. <br><strong>Important config keys:</strong> <code>RoundTo</code>, <code>BucketSize</code>, <code>TolerancePctDefault</code>, <code>DateWindowDefault</code>, <code>MaxCandidates</code>, <code>IndexCandidateFetchLimit</code>, <code>TextIndexEnabled</code>, <code>StopwordsList</code>, <code>Weights</code> (sub-dictionary), <code>AggregationAutoResolveThreshold</code>, <code>MaxAggregationGroupSize</code>, <code>DecayMode</code>, <code>CompositeMode</code>, <code>VerboseTracing</code>.<br><strong>Failure modes:</strong> Missing config or malformed numeric entries — fallback to defaults and log warnings. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: BankMatcherTraceAppend(sampleID As String, eventType As String, details As String, severity As Integer)</strong><br><strong>Purpose & contract:</strong> Append structured trace rows for each matching decision. This is the canonical record auditors will consult. Must include <code>CorrelationID</code>, <code>RunID</code>, <code>ModuleVersion</code>, <code>AlgorithmVersion</code>, <code>Seed</code>, and full serialized <code>details</code> JSON (or compact CSV) for forensic reproducibility. Returns appended TraceRowID.<br><strong>Inputs:</strong> <code>sampleID</code>, <code>eventType</code>, <code>details</code>, <code>severity</code>.<br><strong>Outputs:</strong> TraceRowID (Long). Side effects: writes to <code>BankMatcherTrace</code> and <code>OperationalAudit</code> via <code>modAudit.AppendAudit</code> for cross-module traceability. <br><strong>Implementation notes:</strong> Keep trace rows compact but sufficient — include pointers to bank rows instead of embedding full bank data to avoid duplication. Provide helper <code>BankMatcherTraceExport(runID, outPath)</code> to write full trace bundle for external archiving with checksums. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: EstimateMatchConfidence(candidate As Variant) As Double</strong><br><strong>Purpose & contract:</strong> Produce a calibrated posterior-style confidence estimate (0..1) for a single candidate by combining <code>CompositeScore</code>, aggregated historical resolution statistics, catalog of rule-based flags (e.g., ambiguous amounts, known aggregated remittances, cross-currency adjustments), and any manual overrides recorded in <code>ManualCandidateOverrides</code>. Returns a probability-like confidence used by ReconciliationEngine to decide whether to auto-resolve or escalate for manual review.<br><strong>Inputs:</strong> <code>candidate</code> record from <code>FindCandidateBankMatches</code>.<br><strong>Outputs:</strong> Double confidence. Side effects: if <code>Confidence &gt;= AutoResolveThreshold</code>, write <code>AutoResolveEvent</code> (but by default this module should not auto-resolve; instead set threshold so high that manual review is required).<br><strong>Calibrations & statistical notes:</strong> Confidence is derived from logistic scaling of composite scores with shrinkage toward historical base-rate evidence. For example <code>confidence = logistic(a * composite + b * history + flagsPenalty)</code> where <code>history</code> is prior successful match rate for similar candidate types and <code>flagsPenalty</code> subtracts for ambiguous characteristics. Document parameters in <code>BankMatcherCalibration</code> so auditors can trace the mapping. <br><strong>Testing:</strong> Calibration tests against labeled historical reconciliations to ensure monotonicity and realistic distribution of confidences. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: SearchByReferenceFragment(fragment As String, maxResults As Long) As Collection</strong><br><strong>Purpose & contract:</strong> Fast lookup function for interactive investigator flows: minimal latency search of the BankReference field for a text fragment (prefix, infix). Used by UI forms when an auditor pastes an employee name or payroll ref to find related bank rows. Returns candidate rows filtered by date window default and sorted by textual similarity.<br><strong>Inputs:</strong> <code>fragment</code>, <code>maxResults</code>.<br><strong>Outputs:</strong> Collection of bank row summary objects including <code>BankRowID</code>, <code>BankDate</code>, <code>BankAmount</code>, <code>BankReferenceExcerpt</code>, <code>TextMatchScore</code>. <br><strong>Implementation notes:</strong> Implement tokenization of fragment and use <code>BankTokenIndex</code> inverted index for fast matches. For infix search when no token match found, fall back to sheet-scan but warn when table is large. Provide <code>SearchByReferenceFragment_Explain</code> returning how match was found. <br><strong>Example:</strong> auditor searches "SMITH 1234" -> returns rows with token matches for <code>SMITH</code> and numeric <code>1234</code> first. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Function: AggregateCandidateSummaryForDashboard(sampleCollection As Collection) As Dictionary</strong><br><strong>Purpose & contract:</strong> Produce aggregated metrics about matching performance for dashboards and telemetry: <code>PercentMatchedTop1</code>, <code>PercentMatchedTopN</code>, <code>AvgMatchConfidence</code>, <code>AvgAmountDiffPct</code>, <code>TopBlockingReasons</code>. Returns dictionary of metrics and writes a small <code>BankMatcherMetrics</code> table used by Excel pivot or Power BI ingestion.<br><strong>Inputs:</strong> <code>sampleCollection</code> currently processed samples or historical subset.<br><strong>Outputs:</strong> Dictionary of metrics plus creation of <code>BankMatcherMetrics</code> sheet or table. <br><strong>Conceptual DAX measures that auditors can attach in Power BI:</strong><br>1. <code>PercentMatchedTop1 = DIVIDE(CALCULATE(COUNTROWS(SampleRecs),SampleRecs[TopMatchFound]=TRUE),COUNTROWS(SampleRecs))</code>.<br>2. <code>AvgMatchConfidence = AVERAGE(SampleRecs[TopMatchConfidence])</code>.<br>3. <code>AvgAmountDiffPct = AVERAGE(ABS(SampleRecs[CalculatedNet]-SampleRecs[BankAmount]) / SampleRecs[CalculatedNet])</code>.<br><strong>Example dashboard output:</strong> <code>PercentMatchedTop1: 91.7%</code>, <code>AvgMatchConfidence: 0.82</code>, <code>TopBlockingReason: MissingEvidence (45 samples)</code>. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Conceptual Power Query (PQ) integration notes for modBankMatcher</strong><br><strong>Goal:</strong> Offload heavy normalization and pre-join tasks to PQ, reduce VBA runtime. PQ queries provide precomputed artifacts to the module that reduce runtime tokenization and lookups.<br><strong>Suggested PQ steps:</strong><br>1. <strong>Import BankFile</strong> -> promote headers -> trim -> detect types -> parse dates using locale-aware patterns.<br>2. <strong>Normalize Amounts</strong> -> remove currency symbols, collapse credits/debits to signed <code>BankAmount</code> column, set <code>BankCurrency</code> column explicitly.<br>3. <strong>Compute BucketKey in PQ</strong> -> create a <code>BucketKey</code> column using <code>Number.Round(BankAmount / RoundTo)</code>, then multiply back to a canonical string; this reduces VBA work and ensures PQ/VBA bucket determinism if both use the same <code>RoundTo</code> parameter.<br>4. <strong>Tokenize Reference in PQ (lightweight)</strong> -> use <code>Text.Split</code> on non-alnum characters to produce a <code>ReferenceTokens</code> column as a list; store a concatenated <code>ReferenceFingerprint</code> for deterministic lookups. This is helpful when building <code>BankTokenIndex</code> in VBA since PQ pre-tokenizes and reduces VBA tokenization work.<br>5. <strong>Emit PQ_Issues</strong> -> rows where parsing failed, currency missing, or suspicious aggregated flag should be written to <code>PQ_Issues</code> and surfaced to auditors before matching.<br><strong>Advantages:</strong> PQ is optimized for batch operations and will reduce Excel/VBA memory pressure; shift heavy per-row normalization and deterministic bucket creation to PQ, then VBA focuses on scoring and traceability. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Conceptual DAX measures and model guidance for bank-matching dashboards</strong><br><strong>Model setup:</strong> Import <code>SampleReconciliations</code>, <code>BankRows</code>, <code>BankMatcherTrace</code>, <code>AnomalyLog</code> as tables into PowerPivot/Power BI. Establish relationships on <code>PaymentID</code> and <code>BankRowID</code> keys. Create a <code>MatchDimension</code> boolean flags table for Top1, TopN, Aggregated, CrossCurrency.<br><strong>Recommended conceptual DAX measures:</strong><br>1. <code>MatchesCount = COUNTROWS(BankMatcherTrace)</code>.<br>2. <code>Top1MatchRate = DIVIDE(CALCULATE(COUNTROWS(SampleReconciliations),SampleReconciliations[Top1]=TRUE),COUNTROWS(SampleReconciliations))</code>.<br>3. <code>AvgCompositeScore = AVERAGEX(SampleReconciliations, SampleReconciliations[TopCandidateCompositeScore])</code>.<br>4. <code>AggregatedRemittanceCount = COUNTROWS(FILTER(BankMatcherTrace, BankMatcherTrace[CandidateType]=&quot;Aggregated&quot;))</code>.<br>5. <code>AvgTimeToMatchMs = AVERAGE(BankMatcherTrace[MatchDurationMs])</code>.<br><strong>Notes:</strong> Use these measures to monitor drift in matching performance after rule changes or PQ re-ingestions; when <code>Top1MatchRate</code> drops suddenly, trigger investigation on PQ_Issues or index integrity. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Security, Controls, and Evidence guidance for modBankMatcher</strong><br><strong>Controls:</strong><br>1. All bank matching calls must be logged with <code>CorrelationID</code> and <code>RunID</code> for traceability. <br>2. The module must not write or embed bank raw data in deliverable artifacts unless the auditor explicitly requests a forensic bundle; instead provide references/pointers and hashed fingerprints for verification. <br>3. Index snapshots must be versioned and their fingerprints recorded in <code>BankIndexMetadata</code>. <br><strong>Evidence & chain-of-custody:</strong><br>1. For each candidate match, store a pointer to <code>BankRowID</code> plus the original <code>OriginalRowIndex</code> and a SHA256 of the CSV serialization of the bank row at match time so later tampering can be detected. <br>2. When exporting <code>BankMatcherTrace</code> as part of an audit bundle, include the <code>BankLoadLog</code> fingerprint and <code>BankIndexMetadata</code> to enable revalidation. <br><strong>Access control:</strong> restrict export actions by <code>EnforceExportPermissions</code> in <code>modControls</code>. All <code>ExportCandidateListForAudit</code> calls must validate whether the caller has permission to include bank-level data. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Operational telemetry & recommended monitoring signals</strong><br>1. <code>bankmatcher.calls.count</code> per hour/day.<br>2. <code>bankmatcher.avgCandidatesReturned</code> per call.<br>3. <code>bankmatcher.indexBuild.durationMs</code> and <code>bankmatcher.indexBuild.memoryKb</code>.<br>4. <code>bankmatcher.aggregatedRemittance.count</code> per run and <code>aggregatedRemittanceTimeouts</code>.<br>5. <code>bankmatcher.trace.size.perCall</code> to monitor trace verbosity growth.<br>These signals should be written to the <code>Telemetry</code> sheet and surfaced to Power BI; set alert thresholds for sudden increases in <code>avgCandidatesReturned</code> (could indicate bucket skew) or <code>aggregatedRemittance.count</code> spike (changes in bank format). </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Robustness & edge-case checklist (what the function set must handle explicitly)</strong><br>1. Multi-currency bank rows and payment records — cooperate with <code>modFX</code> for conversions and logging of applied FX rates.<br>2. Aggregated remittances (one bank row for many payroll nets) — surface as aggregated candidates only, require manual confirmation.<br>3. Reversals and negative amounts — treat reversals using sign-aware bucketing and special <code>CandidateType=Reversal</code> and consult <code>EdgeCaseHandler</code> for reversal matching.<br>4. Bank rows with truncated references — tokenization should favor numeric tokens and account number fragments; always return <code>TextMatchScoreExplain</code> to justify low scores.<br>5. Multiple bank rows with identical amounts/dates (e.g., multiple employees with same net) — provide historical frequency <code>historyScore</code> to help prioritize recent matching patterns. <br>6. Very large bank files — support light-weight indexing mode and deterministic candidate sampling to support performance. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Example end-to-end candidate evaluation narrative (auditor-facing)</strong><br>1. <strong>Context:</strong> Sample PaymentID <code>PAY-2025-0001</code> with <code>CalculatedNet = 4,200.00</code> USD, <code>PaymentDate = 2025-06-20</code>, <code>EmployeeRef = &quot;SMITH J&quot;</code>, <code>PayrollRef = &quot;PR-20250620-BATCH42&quot;</code>.<br>2. <strong>Call:</strong> ReconciliationEngine calls <code>FindCandidateBankMatches(4200, 2025-06-20, &quot;tblBank_202506&quot;, 0.5%, 3 days, &quot;USD&quot;, True, 20)</code>.<br>3. <strong>Index lookup:</strong> <code>BucketByAmount</code> selects bucket 4,200.00; <code>BankAmountIndex</code> returns 6 candidate rows within adjacent buckets. <br>4. <strong>Date filtering:</strong> 4 rows within +/- 3 days pass; 2 are older by 15 days and removed. <br>5. <strong>Text scoring:</strong> tokens <code>{&quot;smith&quot;,&quot;j&quot;,&quot;1234&quot;}</code> matched against each bank reference; Candidate A gets textScore 0.93 (numeric token 1234 exact), Candidate B gets 0.52 (partial name match). <br>6. <strong>Composite:</strong> amountScore=1.0 (exact within tolerance), dateScore=0.9, textScore for Candidate A=0.93 -> composite 0.94; Candidate B composite 0.63. <br>7. <strong>Aggregated check:</strong> no aggregated bank row near 4,200 found. <br>8. <strong>Result:</strong> <code>FindCandidateBankMatches</code> returns Candidate A top with <code>CompositeScore=0.94</code>, <code>MatchConfidence=0.91</code>; trace appended to <code>BankMatcherTrace</code> showing token matches and index version. Auditor reviews Candidate A’s bank row and evidence, confirms match. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Developer notes & extension points</strong><br>1. Provide a <code>pluggable comparator</code> interface so teams can drop-in a more advanced text similarity library (e.g., trigram, MinHash or external SQLite FTS) if VBA performance becomes limiting; module should detect available comparator and use it. <br>2. Add optional <code>ExternalBankIndex</code> adapter for very large files where bank records are stored in a SQL DB — implement <code>IBankIndex</code> interface with methods <code>GetByBucket</code>, <code>GetByToken</code>, and <code>GetByDateRange</code>. <br>3. Provide <code>BankMatcherConfigurationUI</code> for auditors to tune weights and thresholds, with <code>Snapshot</code> functionality and change history. <br>4. Consider adding an optional lightweight ML-ranking step (external) that can be called with candidate features and returns a learned rank; keep the module's baseline deterministic and fallback to rule-based scoring if ML service unavailable. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Operational examples and best practice recommendations for auditors</strong><br>1. Before large sample runs, run <code>LoadBankTable</code> and <code>BuildBankIndex</code> and snapshot <code>BankIndexMetadata</code> to capture a reproducible state. <br>2. Keep <code>RoundTo</code> consistent across PQ and VBA — set global in <code>BankMatcherConfig</code> and record in <code>ConfigSnapshot</code>. <br>3. When <code>AggregatedRemittanceLog</code> reports many candidate aggregated matches, request remittance advices from payroll to avoid manual grouping. <br>4. Use <code>ExportCandidateListForAudit</code> with <code>includeTrace=True</code> when producing deliverables for a third-party audit; include <code>BankLoadLog</code> fingerprint and <code>BankIndexMetadata</code> in the artifact manifest. <br>5. Use <code>UnitTests_RunBankMatcherTests(&quot;full&quot;)</code> in a maintenance window after changing configuration or PQ ingestion to ensure consistency. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Comprehensive example test cases (for unit & integration tests) — each must be present in test fixtures</strong><br>1. Exact match test: bank row amount equals net exactly and bank reference contains employee ID token — expected top candidate composite > 0.9.<br>2. Tolerance edge test: bank amount differs by exactly tolerancePct -> amountScore=1 and candidate should be top match.<br>3. Off-by-one-cent test: rounding issues handled by <code>roundTo</code> specification. <br>4. Date drift test: bank date 5 days after paymentDate with dateWindow=3 -> penalized dateScore but text match recovers candidate to moderate composite score. <br>5. Aggregated remittance test: bank file contains a 100K batch amount equal to sum of many nets -> aggregated detection should return group with high confidence only if batch id or remittance advice exists. <br>6. Cross-currency test: payment in EUR, bank row in USD and FX rate applied -> candidate included as <code>CrossCurrency</code> with computed <code>CrossCurrencyAmountDiffPct</code>. <br>7. Tokenization Unicode test: bank reference in non-Latin script with transliteration present in payroll ref -> verify <code>TokenizeReference</code> handles NFKC normalization and scripts properly (or surfaces PQ_Issues if transliteration missing). <br>8. Large bucket performance test: bucket containing 10k candidates must be pruned deterministically to <code>maxCandidates</code> and maintain reproducibility. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Maintenance, versioning, and release notes guidance for the module</strong><br>1. Every change must increment <code>IndexVersion</code> semantics and note algorithm changes in <code>BankMatcherChangeLog</code> with <code>ChangeID</code>, <code>Author</code>, <code>Rationale</code>, and <code>BackwardCompatibilityImpact</code>. <br>2. When tuning weights or thresholds, run <code>UnitTests_RunBankMatcherTests(&quot;regression&quot;)</code> and publish a <code>CalibrationReport</code> that shows changes to <code>PercentMatchedTop1</code> and <code>AvgMatchConfidence</code>. <br>3. Provide migration path when changing tokenization rules — include a crosswalk to convert previous tokens to new canonical tokens and re-build indices before using new configuration. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Observability & diagnostics — what to inspect when matches are poor</strong><br>1. Verify <code>BankIndexMetadata.IndexVersion</code> matches <code>BankLoadLog</code> fingerprint.<br>2. Review <code>BankMatcherMetrics.TopBucketsByFrequency</code> to detect skew (e.g., one bucket with 60% of rows suggests aggregation or misbucket parameter).<br>3. Inspect <code>PQ_Issues</code> for currency parsing errors or truncated references — solve in PQ and re-run load. <br>4. Check <code>AggregatedRemittanceLog</code> for high counts and request remittance advices if required. <br>5. Confirm <code>StopwordsList</code> does not remove key tokens (e.g., employee numeric IDs). </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Final verification checklist (ten-point pre-delivery audit for each release) — verifier must confirm each item and record signature in <code>DeliveryChecklist</code></strong><br>1. <code>LoadBankTable</code> and <code>BuildBankIndex</code> pass integrity checks and <code>ValidateBankIndexIntegrity()</code> returns True.<br>2. <code>BankMatcherConfigLoad</code> produced no warnings or warnings were acknowledged and approved.<br>3. <code>UnitTests_RunBankMatcherTests(&quot;full&quot;)</code> all pass (or failures documented) and <code>TestResults</code> archived.<br>4. <code>BankMatcherTrace</code> writing is enabled and trace rows are visible for a sample run. <br>5. <code>ExportCandidateListForAudit</code> properly hyperlinks to bank and population rows and produces manifest hash. <br>6. <code>AggregatedRemittanceLog</code> reviewed for outliers and remediation actions created. <br>7. <code>OperationalAudit</code> entry exists for index build and sample run with <code>RunID</code> and <code>CorrelationID</code>. <br>8. <code>DeliverablesManifest</code> updated with <code>BankMatcherTrace</code> and candidate exports. <br>9. Security checks: export permissions validated for the operator. <br>10. A <code>ConfigSnapshot</code> saved with <code>IndexVersion</code> and <code>BankLoadLog</code> fingerprint. </td></tr><tr><td data-label="modBankMatcher — Per-function technical breakdown"> <strong>Closing: reproducibility statement & "checked 10 times" assurance</strong><br>All functions in <code>modBankMatcher</code> are designed with reproducibility first: indices are versioned, seeds and algorithm versions are recorded with each match, and trace rows provide complete evidence for auditors. The module's design intentionally separates deterministic lookup (bucket/index) from heuristic scoring so auditors can re-run exact lookups and compare scoring changes after parameter adjustments. This breakdown has been reviewed carefully for completeness and internal consistency; key invariants, failure modes, and audit records are enumerated so the module can be implemented and validated by developers and auditors. </td></tr></tbody></table></div><div class="row-count">Rows: 24</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>