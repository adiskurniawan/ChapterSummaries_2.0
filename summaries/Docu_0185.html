<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Tables Viewer v2.1</title>
<style>:root{--main-header-height:56px;} .table-wrapper{opacity:0;min-height:24px;transition:opacity .12s linear}</style>
<link rel="stylesheet" href="assets/style.css?v=1759925496">
<link rel="stylesheet" href="assets/overrides.css?v=1769244403">
</head><body>
<div id="tables-viewer" role="region" aria-label="Tables viewer">
<div id="stickyMainHeader">
<div id="tv-header">
<div><h1>Tables Viewer v2.1</h1></div>
<div style="display:flex;gap:8px;align-items:center;">
<input id="searchBox" class="tv-search" type="search" placeholder="Search" aria-label="Search tables" />
<button id="modeBtn" type="button" onclick="toggleMode()" aria-label="Toggle theme">Theme</button>
<button id="toggleAllBtn" type="button" aria-label="Toggle all" onclick="toggleAllTables()">Collapse All Tables</button>
<button id="copyAllPlainBtn" class="copy-btn" type="button" onclick="copyAllTablesPlain()" aria-label="Copy all tables as plain text">Copy All Tables (Plain Text)</button>
<button id="copyAllTablesBtn" class="copy-all-btn" type="button" onclick="copyAllTablesMarkdown()" aria-label="Copy All Tables (Markdown)">Copy All Tables (Markdown)</button>
<button id="copyAllMdBtn" style="display:none" aria-hidden="true"></button>
<button id="resetAllBtn" type="button" onclick="resetAllTables()" aria-label="Reset All Tables">Reset All Tables</button>
</div></div>
<script>
(function(){
  function ensureDelegation(){
    try {
      var vis = document.getElementById('copyAllTablesBtn');
      var alias = document.getElementById('copyAllMdBtn');
      if(!vis || !alias) return;
      alias.addEventListener = function(type, listener, options){
        vis.addEventListener(type, listener, options);
      };
      alias.removeEventListener = function(type, listener, options){
        vis.removeEventListener(type, listener, options);
      };
      Object.defineProperty(alias, 'onclick', {
        set: function(fn){ vis.onclick = fn; },
        get: function(){ return vis.onclick; },
        configurable: true
      });
      alias.focus = function(){ vis.focus(); };
      alias.blur = function(){ vis.blur(); };
    } catch(e) {
      try{ console && console.warn && console.warn('alias delegation failed', e); }catch(_){} 
    }
  }
  if(document.readyState === 'loading'){
    document.addEventListener('DOMContentLoaded', ensureDelegation);
  } else {
    ensureDelegation();
  }
})();
</script>
<noscript><div style='color:#b91c1c'>JavaScript is disabled. Tables will be shown statically. For large tables enable JS for virtualization.</div></noscript>
<div id="tocBar" role="navigation" aria-label="Table of contents"><ul><li class="toc-item"><a class="toc-link" href="#Table1">Table 1</a></li>
<li class="toc-item"><a class="toc-link" href="#Table2">Table 2</a></li>
<li class="toc-item"><a class="toc-link" href="#Table3">Table 3</a></li>
<li class="toc-item"><a class="toc-link" href="#Table4">Table 4</a></li>
<li class="toc-item"><a class="toc-link" href="#Table5">Table 5</a></li></ul></div></div>
<div class="table-caption" id="Table1" data-table="Docu_0185_01" style="margin-top:2mm;margin-left:3mm;"><strong>Table 1</strong></div>
<div class="table-wrapper" data-table-id="table-1"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Project 005 — Fixed Asset Register and Depreciation Overview"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Project 005 — Fixed Asset Register and Depreciation Overview</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Preface & Intent (concise):</strong> This expanded document elaborates the Project 005 canonical specification into deeply detailed operator-level narratives for each canonical model row, exhaustive function-level contracts per VBA module, extended worked examples capturing nuance and edge-cases, conceptual Power Query (PQ) pilot guidance including anti-patterns and scale mitigations, and conceptual DAX reporting patterns and measures tuned for reconciliation and operational observability. The document is organized to support implementers and auditors: every function includes inputs, outputs, responsibilities, invariants, failure modes, CI tests, observability signals, and runbook actions. All numbered lists use <code>&lt;br&gt;</code> line breaks for downstream rendering consistency. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Canonical Row Narratives — expanded per-field semantics and forensic handling</strong> <br> <strong>AssetRow (expanded narrative):</strong> The <code>AssetRow</code> is the canonical unit of representation for an asset across the pipeline. It must be treated as an audited snapshot: the ingest pipeline preserves raw payload location and minimal PII surface on analyst views while storing full raw evidence encrypted with evidenceRef pointers. The <code>assetId</code> is the deterministic anchor used across all downstream artifacts and must be reproducible by any implementation that follows the canonicalization recipes. The <code>assetTag</code> is preserved verbatim in evidence; in the canonical token space it is normalized by Unicode NFKC, trimmed, whitespace-collapsed, optionally diacritic-stripped and casefolded. The <code>acquisitionCost</code> is stored as a canonical decimal string <em>and</em> an integer <code>amountMinorUnits</code> paired with <code>roundingScale</code> to avoid floating-point ambiguity. For multi-currency or cross-border procurements the asset row must reference <code>acquisitionCost</code>, <code>currency</code>, and an optional <code>fxRateRef</code> when conversion is necessary for canonical GL posting. The <code>componentOf</code> field requires special handling: component relationships are represented by a parent <code>assetId</code> pointer and a <code>componentRole</code> describing whether the component is capitalized as part of the parent or tracked as separate depreciable sub-components. Each <code>AssetRow</code> must include <code>assetRowChecksum</code> computed on the canonical serialization excluding transient provenance fields. Preserve context for any field override (for example <code>usefulLifeMonths</code> set by analyst override) with explicit <code>usefulLifeSource = &quot;policy_override&quot; | &quot;asset_override&quot; | &quot;policy_default&quot;</code>, and include <code>overrideReason</code> and <code>overrideBy</code> to ensure traceable human decisions. <br><br> <strong>CapexTransactionRow (expanded narrative):</strong> <code>CapexTransactionRow</code> captures accrual/PO/AP evidence that may map to assets. Ingest must normalize vendor names with a vendor dictionary and preserve <code>invoiceRef</code> and <code>poNumber</code> for candidate matching. The <code>amount</code> canonicalization must preserve original sign semantics by recording <code>signConvention</code> and <code>originalSignRepresentation</code> plus a normalized signed <code>amount</code>. Candidate mapping should produce structured <code>matchSignals</code> that detail why a mapping succeeded (e.g., <code>signal:invoiceRefExact</code>, <code>signal:assetTagInDescription</code>, <code>signal:vendorAssetCoOccur</code>). Confidence scores must be reproducible: implement weight vectors in policySnapshot with clear documentation and store the scoring vector used in the manifest so that the same inputs give identical scores across runtimes. Record <code>capexRowChecksum</code> excluding volatile fields like candidateScore to preserve evidence identity independent of matching heuristics. If a row has multiple plausible candidates, persist all candidates with deterministic ordering by descending score and tie-breakers resolved lexicographically by <code>assetId</code>. <br><br> <strong>DepreciationScheduleRow (expanded narrative):</strong> Each <code>DepreciationScheduleRow</code> is an atomic representation of the scheduled depreciation for a distinct period. Store both <code>preRoundedAmount</code> and <code>depreciationAmount</code> (post-rounding) alongside <code>prorationFactor</code>, <code>roundingScale</code>, and <code>residualAbsorbed</code> fields. <code>methodParams</code> must be a JSON-like object capturing the exact parameters used (for DDB the factor, for UoP the totalExpectedUsage and usageThisPeriod). The <code>scheduleRowChecksum</code> includes canonicalized schedule attributes but intentionally excludes any transient operator comments. Keep <code>evidenceRefs[]</code> to point to assetRowChecksum, capexRowChecksums that contributed, and the <code>policyHash</code>. When an asset is revised (e.g., addition of cost or component creation), produce a new <code>assetRevisionId</code> and keep prior schedules immutable; link the new schedule rows to prior schedule snapshots for forensic chase. For proration, specify the exact day-count basis and business day adjustments used; for month-level proration include <code>daysInPeriod</code> and <code>daysCounted</code> fields to confirm factor computation. <br><br> <strong>DisposalRow / RevaluationRow (expanded narrative):</strong> Event rows must include precise <code>eventType</code> semantics and full <code>taxTreatment</code> objects describing deferred/taxable handling, which supports later tax provisioning. For Disposals, capture <code>proceedsCurrency</code> and, if proceeds differ from book currency, persist <code>fxRateRef</code> used and <code>proceedsMinorUnits</code>. When revaluations occur, store both <code>revalBasis</code> (market price, appraisal, index) and <code>revalInputs</code> list to permit independent verification. All event rows must compute <code>gainLossRecognized</code> deterministically and attach <code>approvalRef</code> if fiscal policy requires sign-off before recognition. <br><br> <strong>JE_Line (expanded narrative):</strong> <code>JE_Line</code> entries must maintain consistent sign conventions and narrative templates which embed <code>assetId</code> links for traceability. Each line needs <code>lineSource</code> metadata (scheduleRowId, disposalRowId) and a <code>confidence</code> field for analyst triage. When JEs are aggregated, the bundle-level <code>jeChecksum</code> is computed across canonicalized ordered <code>jeLines[]</code> and <code>jeMetadata</code> to ensure downstream loaders can map the bundle as an atomic set. Preserve <code>jeBundleSequence</code> ordering for idempotent posting. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Canonicalization & Hashing — expanded parity and edge-case rules</strong> <br> 1. <strong>Text normalization (expanded):</strong> Use Unicode NFKC normalization first. Then apply deterministic trimming (remove leading/trailing whitespace), collapse any sequence of whitespace characters into a single U+0020, optionally map common punctuation to canonical representations where policy demands (for example hyphen vs. en-dash normalization), and then casefold for canonical tokens. For languages where casefolding is lossy (e.g., Turkish), document locale-specific overrides in <code>policySnapshot.localeHandling</code>. Preserve original raw text in evidence as <code>rawField</code> and never use stripped raw text as canonical data for hashing. <br> 2. <strong>Numeric canonicalization (expanded):</strong> Always store an integer <code>amountMinorUnits</code> and <code>scale</code> for each monetary field. For a decimal field raw string, first clean thousand separators and ensure <code>.</code> is used as the decimal separator in canonical parsing; for ambiguous locales record the <code>sourceCulture</code> and store parse diagnostics in <code>issues[]</code>. Compute the canonical decimal string by zero-padding fraction digits to <code>scale</code> and ensure negative zero normalization (e.g., <code>-0.00</code> -> <code>0.00</code>). Reserve an internal high-precision scale for preRounded computations to avoid intermediate rounding skew across implementations; record that internal precision in manifests but exclude it from canonical row hashing unless explicitly required. <br> 3. <strong>Date and time canonicalization (expanded):</strong> Use <code>YYYY-MM-DD</code> for date-only fields. When policies permit time-of-day, use full ISO 8601 <code>YYYY-MM-DDTHH:MM:SSZ</code> normalized to UTC, and strip sub-second variability by normalizing milliseconds to three digits and using deterministic rounding rules. For ambiguous source dates record <code>rawDateString</code> and <code>parseAttemptLogs</code> in <code>issues[]</code>. <br> 4. <strong>Serialization ordering and separators (expanded):</strong> Each canonical model defines an exact field order. Use <code>|</code> as the inter-field separator for canonical strings, with the rule that <code>|</code> is escaped in field text by mapping to an explicit escape token in the canonicalizer when policy allows such embedded characters. Do not place trailing newline; always end canonical string with the last field and no trailing whitespace. For lists/arrays embed them as JSON-compact strings in a deterministic field order for hashing; arrays must be sorted deterministically if order is logically irrelevant. <br> 5. <strong>Hash prefixing & manifest stamping:</strong> Prefix all hashes with <code>sha256:</code> and include the canonicalization recipe version used as <code>canonicalVersion</code> in manifests. When computing run-level <code>runHash</code> or <code>policyHash</code> include <code>canonicalVersion</code> to make it explicit that hash identity depends on both content and canonicalization rules. <br> 6. <strong>Deterministic tie-breakers (expanded):</strong> Where a deterministic selection is required choose the candidate with the highest primary metric (e.g., pre-rounded absolute amount for residual absorption), then use lexicographic ordering of <code>assetId</code> or <code>rowId</code>, and finally if still tied use a deterministic pseudo-random but seeded value derived from <code>runHash</code> concatenated with canonicalized element identifiers. Document seed composition in <code>depreciationRunManifest</code> so future replays can reconstruct decisions. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Function-level breakdowns (global notes):</strong> For every function the specification requires: inputs, outputs, responsibilities, invariants, failure modes, telemetry metrics, CI tests, and operator runbook steps. The following expanded module-level contracts keep those fields explicit and exhaustive. All modules emit mandatory audit events for critical lifecycle transitions. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modIngest — expanded function-level contracts and narratives</strong> <br> <strong>Ingest asset and capex with forensic fidelity</strong> <br> <code>IngestAssetFile(sourcePath, options)</code> — <br> Inputs: <code>sourcePath</code> string; <code>options</code> dictionary: <code>mode</code> (<code>strict | tolerant</code>), <code>defaultCurrency</code>, <code>headerMap</code> override, <code>maxSampleRows</code> for manifest. <br> Outputs: <code>assetRows[]</code> (streamable list of canonical row dictionaries), <code>assetIngestManifest</code> persisted (including <code>sourceFingerprint</code>, <code>ingestChecksum</code>, <code>rowsCount</code>, <code>issues[]</code>), audit event <code>fa.asset.ingest.*</code>. <br> Responsibilities: <br> 1. Read file in streaming mode where possible to preserve low memory profile and produce <code>rawPayloadRef</code> trees per row. <br> 2. Normalize raw bytes to canonical newline and encoding, compute <code>sourceFingerprint = sha256(normalizedBytes)</code>. <br> 3. Map headers deterministically and record <code>headerMap</code> in manifest. <br> 4. For each row perform <code>NormalizeText</code>, <code>CanonicalDecimal</code>, parse dates into canonical format, compute <code>assetRowChecksum</code>, and append to output stream. <br> 5. Validate rows: in <code>strict</code> mode fail whole ingest on missing required fields; in <code>tolerant</code> mode emit <code>issues[]</code> for failing rows and continue ingesting good rows. <br> Invariants: identical input bytes and <code>options</code> produce identical <code>assetIngestManifest</code> and <code>assetRowChecksum</code> values. <br> Failure modes & remediation: <br> 1. Malformed encoding → manifest <code>fa.asset.ingest.invalid</code> with evidenceRef; remediate by converting encoding with provided platform utilities and reingest. <br> 2. File access locked → surface <code>fa.asset.ingest.io_error</code> and attempt exponential backoff retries. <br> 3. Unexpected header permutations → present <code>headerMap</code> suggestions in manifest and allow parameterized re-run. <br> Observability & telemetry: <code>asset.ingest.rowsParsed</code>, <code>asset.ingest.rowsFailed</code>, <code>asset.ingest.latencyMs</code>, <code>sourceFingerprint</code>. <br> CI tests: header synonym matrix, multi-locale numeric parsing, golden <code>ingestChecksum</code> fixtures. <br> Operator runbook: <br> 1. On <code>fa.asset.ingest.partial</code> retrieve <code>ingestManifest</code> via evidenceRef. <br> 2. Inspect <code>issues[]</code>, correct input file or <code>headerMap</code> and re-run with <code>correctionOf</code> linking to old <code>sourceFingerprint</code>. <br> <code>IngestCapexFile(sourcePath, options)</code> — mirrors asset ingest but with sign detection and candidate mapping: <br> Additional responsibilities: <br> 1. Detect sign conventions automatically and record <code>signConvention</code>. <br> 2. Run <code>FindAssetCandidates</code> to produce <code>assetIdCandidate</code> entries, persist <code>candidateMappingIndex</code> for analyst review. <br> 3. Flag <code>capitalCandidate</code> using <code>policySnapshot.capitalizationThreshold</code>. <br> Failure modes & remediation: missing invoiceRef or ambiguous vendor names lower candidate confidence → surface to analyst queue. <br> Observability: <code>capex.ingest.unmappedCount</code>, <code>candidateAverageScore</code>. <br> CI tests: sign-convention permutations, candidate mapping fixtures, currency mismatch edge-cases. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modPolicy — expanded contract and governance hooks</strong> <br> <code>LoadPolicySnapshot(policySource)</code> — <br> Inputs: policy workbook/JSON file; <code>options</code> include <code>strict</code> enforcement boolean and <code>author</code> metadata. <br> Outputs: <code>policySnapshot</code> dictionary with deterministic <code>policyHash</code> and <code>policyManifest</code>. <br> Responsibilities: <br> 1. Validate <code>policySource</code> schema and required keys. <br> 2. Canonicalize mapping rows and sort deterministically. <br> 3. Compute <code>policyHash = sha256(canonicalString)</code> and persist <code>fa_policy_&lt;policyHash&gt;.json</code>. <br> 4. Emit <code>fa.policy.loaded{policyHash}</code> audit event. <br> Governance invariants: any policy change altering numeric or mapping semantics must be accompanied by a <code>migrationManifest</code> before being used for production apply flows. <br> Failure modes: incomplete mapping rows cause <code>policy.load.invalid</code>; remediate by filling required mapping rows or providing overrides via <code>migrationManifest</code>. <br> CI tests: cross-runtime policyHash parity, property tests ensuring non-semantic fields (comments, timestamps) don't change policyHash. <br> Operator runbook: when a policy change is proposed create <code>migrationManifest</code> and register a <code>canaryPlan</code>. <br> <code>ValidatePolicyChange(oldPolicyHash, newPolicySnapshot, migrationManifestRef)</code> — <br> Responsibilities: compute semantic diffs, estimate affected asset population, produce canary cohort recommendations and KPI expectations like <code>DepnExpenseDeltaPct</code>. <br> Outputs: <code>validationReport</code> with <code>diffSummary</code>, <code>sampleFixtures</code>, and <code>canaryPlan</code> ready to execute. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modCanonical — primitives and defensive checks</strong> <br> <code>NormalizeText</code>, <code>CanonicalDecimal</code>, <code>FormatDateISO</code>, <code>ComputeSHA256</code> are small but critical primitives. Each primitive must provide deterministic outputs across platforms and expose the <code>canonicalVersion</code> used. Unit tests must include extensive unicode, numeric, and date fixtures. Provide clear error codes and remediation advice when conversion fails (e.g., <code>CNV_NUM_LOCALE_AMBIGUOUS</code>). </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modMatch — matching heuristics, score stability and audit</strong> <br> <code>FindAssetCandidates(capexRow, assetIndex, policySnapshot)</code> — <br> Responsibilities: produce reproducible candidate lists and structured <code>matchSignals</code>. Tie-breakers must be deterministic: sort by <code>candidateScore</code> descending, then <code>assetId</code> lexicographically. Candidate scoring weights must be stored in <code>policySnapshot.matchingWeights</code> and recorded in <code>candidateList</code> for audit parity. Include <code>matchTrace</code> lines describing step-by-step scoring decisions (invoice match +0.5, tag-in-desc +0.3, etc.). For historical mapping signals include <code>lastMappedRunHash</code> to indicate historical stability. Persist <code>candidateList</code> to <code>candidateMappingIndex</code> and include <code>candidateRowChecksum</code> to decouple mapping heuristics from raw evidence. CI tests: seeded candidate scoring reproducibility and handling of noisy descriptions (OCR errors, truncated descriptions). Runbook: for mapping backlog use bulk alias acceptance workflows and produce re-run artifacts referencing <code>correctionOf</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modDepreciationEngine — fully expanded algorithmic contract</strong> <br> <code>ComputeDepreciationRun(assetRows, capexRows, policySnapshot, params)</code> — This is the core deterministic engine and requires the highest level of traceability. The implementation must produce identical outputs given identical canonical inputs and the same <code>canonicalVersion</code>. <br> Inputs: <code>assetRows[]</code>, <code>capexRows[]</code>, <code>policySnapshot</code>, <code>params</code> including <code>periodStart</code>, <code>periodEnd</code>, <code>runId</code> optional seed, <code>roundingScaleOverride</code>. <br> Outputs: <code>DepreciationSchedule[]</code>, <code>ScheduledJEProposals[]</code>, <code>depreciationRunManifest</code> with <code>runHash</code>. <br> Responsibilities & stepwise algorithm (explicit numbered steps with <code>&lt;br&gt;</code> separators): <br> 1. <strong>Capitalization decisions:</strong> evaluate each capexRow against the policy rule chain—first invoiceRef exact matches to <code>assetTag</code>, then amount threshold, then vendor allowlist and cost center mapping. Record a <code>capitalizationDecision</code> object for each evaluated capexRow with <code>decisionCode</code>, <code>evidenceRefs</code>, and <code>decisionConfidence</code> (derived from candidate signals). <br> 2. <strong>Asset augmentation & revisioning:</strong> when an addition is accepted, compute a deterministic <code>assetRevisionId</code> using <code>sha256(assetRowChecksum | capexRowChecksum | decisionTimestampCanonical)</code> and persist the new asset revision row as immutable evidence. Document <code>additionTreatment</code> (<code>append_cost</code>, <code>create_component</code>, <code>restart_depn</code>) used and reason. <br> 3. <strong>Determine depreciationStart & proration:</strong> select the date used per policy <code>startDateField</code> (<code>acquisitionDate | inServiceDate</code>) and compute <code>prorationFactor</code> for first/last periods using specified proration basis (<code>days</code>, <code>months</code>, <code>half_month</code>) and day count convention. Persist <code>daysInPeriod</code> and <code>daysCounted</code>. <br> 4. <strong>Method-specific computations:</strong> implement high-precision pre-rounded math for each supported method and record <code>methodParams</code>. The engine must also include deterministic switch-to-SL logic for DDB to avoid over-depreciation. For Units-of-Production require <code>usageThisPeriod</code> input; if missing mark schedule rows as <code>requiresManualInput</code> and emit <code>fa.depn.run.requires_manual_input</code> with examples. <br> 5. <strong>Pre-rounding and rounding:</strong> compute pre-rounded values at a policy-specified high internal precision (e.g., 6 decimal places) and then apply <code>round-half-to-even</code> to the configured <code>roundingScale</code>. Persist both values and record rounding deltas. <br> 6. <strong>Residual absorption:</strong> compute <code>residual = canonicalTotal - sum(roundedPeriods)</code>, then deterministically choose absorption target using rules: highest absolute preRounded amount, then <code>assetId</code> lexicographic tie-breaker, then <code>runSeed</code> fallback. Record <code>residualAbsorbed</code> and <code>residualRationale</code>. <br> 7. <strong>Enforce NBV & adjust final period:</strong> if NBV would fall below zero due to rounding, adjust the final period by the deterministic minimum required and write <code>adjustmentReason</code> and <code>adjustedAmount</code> fields. <br> 8. <strong>Impairment & revaluation hooks:</strong> evaluate any impairment indicators; if triggered produce <code>RevaluationProposal</code> objects that include suggested JE consequences and evidenceRefs; these proposals do not mutate asset rows until accepted via apply flows. <br> 9. <strong>JE aggregation:</strong> group schedule rows by posting aggregation keys from <code>policySnapshot.jeTemplateSpec</code> and produce <code>ScheduledJEProposals</code> with <code>jeLines[]</code>. Compute <code>confidenceScore</code> from mapping completeness and DQ metrics. <br> 10. <strong>Manifest assembly:</strong> create <code>depreciationRunManifest</code> capturing the inputs, policyHash, run parameters, row counts, and compute <code>runHash = sha256(canonicalManifest)</code> where <code>canonicalManifest</code> includes canonicalVersion. Persist manifest to evidence and emit <code>fa.depn.run.completed{runId,runHash}</code>. <br> Invariants: reproducibility across runs requires identical canonical inputs, identical policyHash, and consistent canonicalVersion. <br> Failure modes & remediation: <br> 1. Missing usage for UoP method → flag <code>requiresManualInput</code> and queue asset for analyst data collection. <br> 2. Zero or negative <code>usefulLifeMonths</code> → mark <code>requiresManualOverride</code> and set <code>diagnostic</code>. <br> Observability & telemetry: <code>depn.run.durationMs</code>, <code>schedulesGenerated</code>, <code>residualAdjustmentsCount</code>, <code>requiresManualInputCount</code>, <code>jeProposalCount</code>. <br> CI tests: across-method unit tests, residual absorption parity tests with golden fixtures, cross-locale numeric parity, and property tests for idempotence. <br> Operator runbook excerpt (explicit steps): <br> 1. When <code>requiresManualInputCount</code> > 0, gather missing inputs and annotate asset revisions with <code>manualInputs</code> then rerun <code>ComputeDepreciationRun</code> for the affected subset. <br> 2. On unexpected <code>residualAbsorbed</code> distribution check the <code>preRoundedAmount</code> deltas in manifest and trace candidate decisions back to capex evidence. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modJEGenerator — expanded generation and preview semantics</strong> <br> <code>AggregateSchedulesToJEs(scheduleRows, jeTemplateSpec, policySnapshot)</code> — <br> Responsibilities: map schedules to GL accounts, construct balanced JE bundles that adhere to the downstream loader spec, compute <code>confidenceScore</code> and package preview artifacts. <br> Detailed flow: <br> 1. <strong>Mapping phase:</strong> for every scheduleRow resolve <code>category-&gt;GLAccount</code> mappings using <code>policySnapshot.mappingOverrides</code>. Where mapping is missing produce <code>mappingSuggestion</code> entries included in the <code>jePreviewArtifact</code> with example schedule rows to guide analysts. <br> 2. <strong>Grouping & aggregation:</strong> group by posting keys deterministically and compute aggregated debits and credits at <code>roundingScale</code>. Preserve per-asset breakout lines where policy requires asset-level traceability. <br> 3. <strong>Balance validation and JE residual handling:</strong> validate each JE bundle balances. If a small imbalance arises from rounding, apply deterministic residual absorption within bundle and record absorbing line and rationale. If imbalance exceeds tolerance, fail preview with <code>fa.je.preview.unbalanced</code> requiring manual remediation. <br> 4. <strong>Confidence & evidence:</strong> compute <code>confidenceScore</code> per JE and include <code>confidenceBreakdown</code> with components <code>mappingCompleteness</code>, <code>dqPenalty</code>, <code>manualFlags</code>. Attach scheduleRowRefs and <code>depreciationRunManifest</code> references. <br> 5. <strong>Preview artifact packaging:</strong> package <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code> into <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>. Include <code>previewHash</code> computed over canonical preview manifest. <br> Observability: <code>je.suggested.count</code>, <code>je.preview.latency</code>, <code>je.preview.unbalancedCount</code>. <br> CI tests: verify JE balancing across permutations, mapping completeness gating, and preview manifest golden checksums. <br> Analyst workflow: analysts open preview artifact, accept or reject suggestions, annotate reasons for manual overrides, and generate <code>acceptedJEs[]</code> which feed into export flows. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modExport & modApply — deterministic export and mutative safety controls</strong> <br> <code>GenerateJEExport(acceptedJEs, exportSpec, operatorId)</code> — <br> Responsibilities: transform acceptedJEs into precise loader payloads, validate schema, compute <code>exportChecksum</code> and persist the artifact along with <code>exportManifest</code>. <br> Flow & validations: <br> 1. <strong>Spec alignment:</strong> ensure acceptedJEs match <code>exportSpec</code> column order, field types, and sign conventions; if mismatch produce deterministic diagnostics. <br> 2. <strong>Balance & bundle validation:</strong> re-validate each bundle is balanced at <code>roundingScale</code> before serialization; fail export if not balanced. <br> 3. <strong>Serialization & naming rules:</strong> produce UTF-8 deterministic serialized payload and compute <code>exportChecksum = sha256(payload)</code>. Name artifact as <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>. <br> 4. <strong>Atomic persist:</strong> write artifact and <code>exportManifest</code> atomically and emit <code>fa.je.exported</code>. <br> Failure modes: write failure → limited retries and local staging with <code>fa.je.export.warning</code>. <br> <code>ApplyCorrections(acceptedJEs,mode,operatorId,approvals)</code> — <br> Responsibilities: orchestrate application and produce <code>applyDescriptor</code> persisted prior to any mutative action. <br> Safety & governance controls: <br> 1. Require <code>approvals</code> evidenceRef when policy requires two-person approval; validate that approvers match roles indicated in <code>policySnapshot.approvalMatrix</code>. <br> 2. Persist <code>applyDescriptor</code> atomically with fields <code>applyId</code>, <code>beforeChecksums</code> (assetIngestChecksum, capexIngestChecksum, runHash), <code>approvalsRef</code>, <code>operatorId</code>, <code>mode</code>. <br> 3. Execute posting using ephemeral credentials and idempotency tokens derived from <code>applyId</code> to guarantee safe retries. <br> 4. On partial failure record per-JE error codes and allow governed retry logic; create <code>revertDescriptor</code> capturing details necessary to revert successfully posted bundles. <br> Observability: <code>apply.successRate</code>, <code>apply.partialFailureCount</code>. <br> CI tests: idempotency replay, approval gating tests, token lifecycle validation. <br> Runbook steps: <br> 1. When direct-post returns partial failures gather <code>applyResult</code> and initiate guided retries where appropriate; if permanent errors occur create forensic manifests and escalate. <br> 2. For reverts use <code>RevertJEs(applyId,operatorId)</code> documented below. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modRevert — reversible operations and idempotent safety</strong> <br> <code>RevertJEs(applyId,operatorId)</code> — <br> Responsibilities: attempt automated reversion using GL reversal endpoints or generate manual reversal artifacts where automation is unsupported. <br> Flow and idempotency: <br> 1. Retrieve <code>applyDescriptor</code> and ensure <code>postedJournalIds</code> exist; if missing return <code>fa.revert.noSnapshot</code>. <br> 2. Compute <code>revertId = sha256(applyId + normalizedRevertTs)</code> and check if <code>revertDescriptor</code> already persisted; if so perform idempotent no-op. <br> 3. Call GL reversal endpoint for each <code>postedJournalId</code> using ephemeral credentials and idempotency tokens; capture responses. <br> 4. If GL rejects automated reversal or lacks endpoint, produce <code>reversalArtifact.csv</code> and persist <code>forensic_manifest</code> for manual processing. <br> Observability: <code>revert.automatedSuccessRate</code>, <code>revert.pendingManualCount</code>. <br> CI tests: idempotency replay, partial revert error handling, manual artifact correctness. <br> Runbook: if revert fails iterate with GL team, provide <code>forensic_manifest</code> evidence bundle, and coordinate manual posting to achieve reconciliation. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Module: modReconcile — reconciliation logic, materiality, and remediation suggestions</strong> <br> <code>ReconcileFAtoGL(assetScheduleAgg, glBalances, tolerances)</code> — <br> Responsibilities: compute deterministic join and variance metrics, attach evidence, and propose remediation actions. <br> Flow: <br> 1. Canonical grouping by <code>controlGLAccount</code>, <code>costCenter</code>, <code>currency</code>, and <code>period</code>. <br> 2. Full outer join producing <code>Matched</code>, <code>FAOnly</code>, <code>GLOnly</code>. <br> 3. Compute <code>Variance = SubledgerAmount - GLAmount</code>, <code>AbsVariance</code>, and <code>RelativeVariancePct</code>. <br> 4. Materiality decision: if GLAmount = 0 use absolute threshold; otherwise compute relative threshold. <br> 5. For exceptions attach representative sample <code>evidenceRefs</code> and propose remediation: re-run JE export, mapping correction, or manual adjustment with approvals. <br> Outputs: <code>fa_recon_report</code> with exception list and <code>reconManifest</code>. <br> Observability: <code>recon.exceptionsCount</code>, <code>recon.timeMs</code>. <br> CI tests: tolerance boundary testing, sampling accuracy on evidence selection. <br> Analyst pattern: provide drillthrough from variance rows to <code>previewArtifact</code> and underlying schedule/disposal JEs to expedite root-cause. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Examples — ultra-detailed worked narratives and edge cases</strong> <br> <strong>Example A — Complex capitalization with multi-invoice addition and component assembly (expanded):</strong> <br> 1. Invoices INV-2026-100 and INV-2026-101 are submitted for a network island purchase: a main chassis and accessory modules invoiced separately, amounts $12,500 and $2,200 respectively, currency USD. The description for INV-2026-101 contains part number that matches <code>assetTag</code> of AS-000789 for an existing server asset. <br> 2. <code>IngestCapexFile</code> normalizes invoice descriptions and candidate-matches both invoices: INV-2026-100 has no assetTag match but vendor and PO match vendor-owned project, candidateScore=0.62; INV-2026-101 matches <code>assetTag</code> AS-000789 with candidateScore=0.93. <br> 3. <code>policySnapshot</code> indicates <code>componentPolicy</code> for <code>IT</code> category prefers <code>create_component</code> for accessory modules under capitalizationThreshold override when accessoryReason='expansion'. <code>ComputeDepreciationRun</code> applies <code>append_cost</code> to main chassis but <code>create_component</code> for accessory, generating a new component asset row with <code>componentOf=AS-000789</code> and <code>assetRevisionId</code> computed as sha256 over canonical inputs. <br> 4. Depreciation schedules are recomputed deterministically: parent asset continues life from original <code>depreciationStart</code>; component inherits its own <code>usefulLifeMonths</code> per category defaults and is scheduled accordingly. JE proposals include component-related postings which, depending on policy, might be aggregated or posted separately per company GL policy. EvidenceRefs include both INV rows and <code>assetIngestManifest</code>. <br> 5. Analysts review preview artifact and accept JE proposals; <code>GenerateJEExport</code> produces <code>FA_JE_Export_&lt;runId&gt;_&lt;checksum&gt;.csv</code> with component lines flagged with <code>componentOf</code> references for GL reconciliation. <br> 6. On export apply, <code>ApplyCorrections</code> enforces two-person approval since combined postings exceed regulated thresholds. <code>applyDescriptor</code> persists before posting. <br> <strong>Edge nuance:</strong> if accessory invoice had included an <code>expense</code> account mapping in source GL reference, <code>ComputeDepreciationRun</code> must defer to <code>policySnapshot.capitalizationOverrides</code> and surface <code>capitalizationDecision</code> for analyst review rather than auto-capitalize. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Example B — Mid-period partial disposal with cross-currency proceeds (expanded):</strong> <br> 1. Disposal event row for AS-000456 occurs 2026-07-15 with proceeds €2,200. Asset currency is USD; most recent bookValueEnd (USD) is $1,900. <br> 2. <code>LoadPolicySnapshot</code> specifies official FX table reference <code>fxRates_20260715</code> which provides EUR→USD rate of 1.0833. <code>ComputeDepreciationRun</code> uses <code>fxRateRef</code> to convert proceeds to USD canonical minor units. <br> 3. Compute gain/loss deterministically: proceedsUSD = 2,200 * 1.0833 = 2,383.26 (canonical rounding rules apply), gain = proceedsUSD - NBV = 2,383.26 - 1,900.00 = 483.26. <br> 4. JE suggestions: Debit <code>Cash</code> 2,383.26; Debit <code>AccumulatedDepreciation</code> 8,200.00; Credit <code>AssetCost</code> 10,000.00; Credit <code>GainOnDisposal</code> 483.26. Each JE line references <code>disposalRowChecksum</code> and <code>fxRateRef</code>. <br> 5. If proceeds cross governmental thresholds, <code>policySnapshot</code> flags disposals > $2,000 to require <code>taxTeamApproval</code>; <code>GenerateJEExport</code> includes <code>approvalRef</code> and cannot be applied until approvals exist. <br> <strong>Edge nuance:</strong> if a disposal occurs mid-period and their policy requires proration of depreciation to disposition date, the schedule must include an adjusted partial period depreciation row with <code>prorationFactor</code> and <code>residualAbsorbed</code> adjustments if rounding created an imbalance. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Example C — Rounding pathologies and deterministically resolved residuals (expanded):</strong> <br> 1. Asset cost 1,000.00, salvage 0.00, useful life 3 months produces a theoretical monthly expense of 333.3333... recurring. With <code>roundingScale=2</code> naive rounding yields 333.33 monthly = total 999.99 residual +0.01. <br> 2. Residual absorption rule prescribes absorbing into the period with the largest absolute preRounded amount; here all equal so lexicographic <code>assetId</code> tie-breaker applies. <code>residualAbsorbed = 0.01</code> applied deterministically to chosen period creating one period 333.34. Persist <code>residualRationale</code> in schedule row to allow auditors to trace why that period received absorption. <br> 3. For large batches, residual aggregation rules must ensure batch-level and per-asset-level constraints are both respected if policy dictates such behavior. For instance, enterprise policy might require batch-level balancing where aggregate residuals for a cost center are zeroed across assets, in which case deterministic grouping and absorption rules at the grouping level must be explicitly codified and tested. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Power Query (PQ) conceptual guidance — pilots, patterns, and pitfalls</strong> <br> <strong>When PQ is appropriate:</strong> use PQ for analyst pilots, preview generation, and low-volume canonicalization where the convenience and UI interactivity outweigh scale limitations. PQ is ideal for generating <code>previewArtifact</code> for small cohorts and for performing early parity checks on canonicalization recipes against backend. <br> <strong>Architectural pattern for PQ pilots:</strong> <br> 1. Use a small number of named parameterized queries for ingest staging: <code>AssetMaster_Staging</code>, <code>Capex_Staging</code>, <code>PolicySnapshotParam</code>. <br> 2. Expose <code>headerSynonyms</code> and <code>decimalLocale</code> as query parameters for easy analyst correction. <br> 3. Implement canonicalization steps as separate queries with clear step names so intermediate outputs can be inspected. <br> 4. Generate <code>policyHash</code> locally by constructing canonical string in PQ and computing deterministic hash using available host functions or an external helper; include <code>canonicalVersion</code> constant. <br> <strong>Canonicalization steps in PQ (conceptual):</strong> <br> 1. Text normalization: apply <code>Text.Normalize</code> where available; otherwise use mapping tables for diacritics and explicit replacements. <br> 2. Numeric parsing: pre-clean thousand separators and unify decimal separators then <code>Number.FromText</code> with explicit culture. <br> 3. Date parsing: use <code>Date.FromText</code> with error capture; include <code>rawDateString</code> if parse fails. <br> 4. Compute <code>amountMinorUnits</code> by rounding to <code>roundingScale</code> and multiplying by 10^scale; store both integer and decimal forms. <br> <strong>Performance anti-patterns and mitigations:</strong> <br> 1. Per-row custom function loops: PQ custom functions that iterate per-row do not scale; instead vectorize transformations using table joins and buffers. <br> 2. Large joins in-memory can cause timeouts; mitigate by sampling for preview and offloading full runs to backend. <br> 3. High-precision decimal math is limited in PQ; for precise internal computations use backend math or represent high-precision intermediate values as strings validated by test harness. <br> <strong>Testing PQ parity:</strong> <br> 1. Create golden fixtures and run parity checks computing <code>policyHash</code>, <code>ingestChecksum</code>, and local <code>runHash</code> where possible. <br> 2. Record discrepancies in a <code>pqParityReport</code> enumerating differences and suspected causes (locale parsing, rounding differences). <br> <strong>Operational flows when PQ used for preview:</strong> <br> 1. Analysts generate preview artifact via PQ and publish artifact with <code>preview_manifest</code> including <code>previewHash</code>. <br> 2. Backend parity job replays the same inputs and <code>policyHash</code> and asserts <code>runHash</code> parity; any mismatch creates <code>fa.verify.parity.failed</code> and blocks promotion. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Conceptual DAX — measures, reporting patterns, and drillthrough UX</strong> <br> <strong>Principles for DAX modeling:</strong> Use canonical keys (assetId, policyHash, runId, previewHash) as relationships. Avoid embedding PII in model visuals; instead display tokenized identifiers with evidenceRef links that require approval to retrieve raw evidence. Build measures to support triage workflows and reconciliation signoffs. <br> <strong>Core measures (expanded):</strong> <br> 1. <code>DepreciationExpense = SUM(DepSchedule[depreciationAmount])</code> — base measure used in period visuals. <br> 2. <code>AccumulatedDepreciation = SUM(DepSchedule[accumulatedDepreciationToDate])</code> — control account comparisons. <br> 3. <code>NetBookValue = SUM(DepSchedule[bookValueEnd])</code> — used to reconcile to GL NBV control. <br> 4. <code>FA_ReconVariance = SUM(Subledger[AccumulatedDep]) - SUM(GL[AccumulatedDep])</code> — primary reconciliation variance measure. <br> 5. <code>BeyondToleranceFlag = IF(ABS(GLAmount)=0, ABS(Variance)&gt;AbsThreshold, ABS(Variance)/ABS(GLAmount)&gt;TolerancePct)</code> — dynamic materiality check that supports parameterized thresholds. <br> 6. <code>SuggestionAcceptanceRate = DIVIDE(COUNTROWS(AcceptedJEs),COUNTROWS(SuggestedJEs),0)</code> — tracks analyst adoption of suggested JEs. <br> <strong>Advanced operational measures:</strong> <br> 1. <code>RunParityDeltaCount = COUNTROWS(FILTER(RunParity, RunParity[runHash] &lt;&gt; RunParity[expectedRunHash]))</code> — detects changes post-migration. <br> 2. <code>OpenManualActions = COUNTROWS(DepSchedule WHERE requiresManualInput = TRUE)</code> — helps prioritize data collection. <br> 3. <code>TopVarianceByCategory = TOPN(10, SUMMARIZE(exceptionTable, category, &quot;Variance&quot;, SUM(exceptionTable[Variance])), [Variance], DESC)</code> — top-focused table pattern. <br> <strong>Drillthrough & UX:</strong> allow analyst to click a variance row and open a drillthrough page that displays sample schedule rows, linked <code>previewArtifact</code> metadata, and <code>evidenceRefs</code> with access-controlled retrieval links. Where approvals are required, surface an <code>approvalRequest</code> CTA that populates a standard approval manifest to expedite retrieval of encrypted PII artifacts. <br> <strong>KPI visual patterns:</strong> <br> 1. Trend line for <code>DepreciationExpense</code> by month with stacked categories; include <code>RunParity</code> markers indicating policy snapshot changes. <br> 2. Matrix showing <code>controlGLAccount</code> × <code>costCenter</code> with variance cells colored by <code>BeyondToleranceFlag</code>, allowing slicers for <code>policyHash</code> and <code>period</code>. <br> <strong>Materiality & thresholds:</strong> expose materiality thresholds as parameters so auditors can toggle between strict and lenient views without regenerating runs; make sure visual measures reflect the selected threshold clearly in captions and exportable CSVs. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Testing strategy & exhaustive CI / golden parity guidance (expanded)</strong> <br> <strong>Unit tests (must cover):</strong> canonicalization recipes for text, numeric, and date; hashing parity; method math for SL, DDB, SYD, UoP including edge-case and negative-life handling; rounding and residual absorption determinism; tie-breaker logic. <br> <strong>Integration tests (must cover):</strong> ingest→compute→preview→export flows, mapping overrides, cross-currency flows, disposal and revaluation flows. <br> <strong>Golden parity tests:</strong> maintain canonical fixtures for <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policyHash</code>, <code>runHash</code>, <code>previewHash</code>, and <code>exportChecksum</code> for a curated set of representative cases. Golden fixtures must be run in CI across all supported runtime environments (PQ pilot, backend worker pool, local dev) and mismatches must block merges for protected branches. <br> <strong>Property tests:</strong> invariants such as ordering independence of input rows, idempotency of apply/revert, and header synonym robustness. <br> <strong>Performance & load tests:</strong> schedule computation throughput at 1k, 10k, 100k assets; preview artifact generation latency for 100, 500, 1,000 rows. <br> <strong>Security tests:</strong> PII redaction scans, secrets static analysis, ephemeral token lifecycle tests. <br> <strong>Release gating:</strong> failing golden or property tests blocks merges; policy migrations require approved <code>migrationManifest</code> and successful canary KPIs before bulk promotion. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Observability, audit architecture & SLOs (expanded)</strong> <br> <strong>Mandatory audit events:</strong> <code>fa.asset.ingest</code>, <code>fa.capex.ingest</code>, <code>fa.policy.loaded</code>, <code>fa.depn.run.built</code>, <code>fa.depn.preview</code>, <code>fa.je.suggested</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start/complete/fail</code>, <code>fa.je.revert</code>, <code>fa.recon.report.generated</code>, <code>fa.disposal.suggested</code>, <code>fa.policy.migration</code>. Each audit row includes <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code> or <code>exportChecksum</code>, <code>operatorId</code>, and <code>paramsHash</code>. <br> <strong>Evidence store conventions:</strong> append-only object storage with <code>createdTs</code>, <code>checksum</code>, <code>retentionPolicy</code>, <code>legalTags</code>. Evidence retrieval is approval-gated; raw PII artifacts require explicit <code>approvalRef</code> on retrieval and generate chain-of-custody audit rows. <br> <strong>Key SLOs (examples and suggested targets):</strong> <br> 1. <code>PlanBuildLatencyP50</code> target < 200ms for small plans. <br> 2. <code>PreviewLatencyP50</code> target < 2s for <= 500 rows. <br> 3. <code>ApplySuccessRate</code> target > 99% in <code>create_export</code> mode. <br> 4. <code>GoldenParityFailureRate</code> target 0 in protected branches. <br> <strong>Parity verification job:</strong> scheduled daily job that recomputes <code>runHash</code> and <code>reportHash</code> for stored artifacts and emits <code>verify.parity.failed</code> on mismatch; investigations must be opened immediately with correlationId logged. <br> <strong>Incident triage runbook (explicit steps):</strong> <br> 1. Capture <code>correlationId</code> and <code>runId</code> immediately. <br> 2. Retrieve <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policySnapshot</code>, and <code>previewArtifact</code> via <code>evidenceRefs</code>. <br> 3. Inspect <code>issues[]</code> and <code>mappingSuggestions</code> for parsing or mapping errors. <br> 4. If posted exports exist attempt <code>RevertJEs</code>; if revert impossible assemble <code>forensic_manifest</code> and escalate to GL/compliance. <br> 5. Persist all investigation steps as audit rows. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Failure modes, mitigation & operator runbooks (exhaustive patterns)</strong> <br> <strong>Fault A — malformed ingest:</strong> <br> 1. Symptom: <code>fa.asset.ingest.invalid</code> with <code>rowsFailed</code> > 0. <br> 2. Triage: capture <code>correlationId</code>, fetch <code>assetIngestManifest</code> and raw evidence, analyze <code>issues[]</code>. <br> 3. Remediation: correct headers via <code>modIngest</code> headerMap override, repair encoding or separator conventions, re-run ingest with <code>correctionOf</code> linking to previous <code>sourceFingerprint</code>. <br> <strong>Fault B — mapping backlog spike:</strong> <br> 1. Symptom: <code>capex.ingest.unmappedCount</code> spike. <br> 2. Triage: run <code>modMatch</code> analytics to rank unmapped items by total value and frequency. <br> 3. Remediation: produce <code>mappingSuggestions</code> with example rows and present to business owners for bulk acceptance; after acceptance re-run preview. <br> <strong>Fault C — JE export rejected by GL loader:</strong> <br> 1. Symptom: GL loader returns rejection listing line-level errors. <br> 2. Triage: fetch <code>exportManifest</code>, simulate import in test system, run <code>modExport.ValidateExportSpec</code> to detect spec mismatches. <br> 3. Remediation: correct <code>exportSpec</code> and re-export, or if direct-post already occurred, run <code>RevertJEs</code> and reapply corrected export. <br> <strong>Emergency policy rollback:</strong> <br> 1. Symptom: mass parity delta after policy promotion causing large variances. <br> 2. Steps: perform atomic pointer swap to prior <code>policyHash</code>, run smoke-preview comparisons across representative fixtures, and if parity restored escalate change record and notify stakeholders. Persist <code>policy.hotSwap.auditChain</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Migration manifest & policy-change governance — expanded process</strong> <br> <strong>Minimal manifest fields required:</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (planId, cohortSizes, KPIs), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> <strong>Lifecycle process:</strong> <br> 1. Draft manifest and register in policy governance system. <br> 2. Execute canary per <code>canaryPlan</code> on small cohort and monitor KPIs for at least two cycles. <br> 3. If KPIs within thresholds and approvals captured, promote policy snapshot and persist manifest; otherwise rollback and document findings. <br> 4. For regulated GL ranges require compliance signature before any <code>ApplyCorrections</code> using new policyHash. <br> Evidence: persist canary results and <code>migrationManifest</code> as canonical evidence. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Artifact naming, checksum, and storage conventions (expanded)</strong> <br> 1. <code>assetIngestManifest</code>: <code>asset_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br> 2. <code>capexIngestManifest</code>: <code>capex_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br> 3. <code>policySnapshot</code>: <code>fa_policy_&lt;policyHash&gt;.json</code>. <br> 4. <code>depreciationPreview</code>: <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> (contains canonical <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>). <br> 5. <code>jeExport</code>: <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code> and <code>export_manifest.json</code>. <br> 6. <code>applyDescriptor</code>: <code>apply_&lt;applyId&gt;.json</code> persisted prior to mutative actions. <br> 7. <code>recon_report</code>: <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code>. <br> Checksum policy: use <code>sha256</code> over canonicalized payloads and include <code>checksumAlgorithm</code> in manifest. Artifacts stored with <code>retentionPolicy</code> and <code>legalTags</code> and with explicit <code>canonicalVersion</code> metadata. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Performance, scale & architecture recommendations (expanded)</strong> <br> 1. <strong>Scale tiers:</strong> PQ pilot up to a few thousand assets; backend/warehouse recommended for 10k+ assets. <br> 2. <strong>Parallel compute model:</strong> per-asset schedule computation is embarrassingly parallel; shard by <code>assetId</code> ranges or category while ensuring deterministic ordering within shards to preserve hashing parity. <br> 3. <strong>Incremental recompute patterns:</strong> support incremental recomputation triggered by <code>assetRevisionId</code> to avoid full-run compute for minor changes; manifest <code>depreciationRunManifest</code> should capture <code>changedAssetRevisionIds[]</code> to enable partial replay. <br> 4. <strong>Storage pattern:</strong> object store for large artifacts and signed manifest metadata in a small relational store for fast query and evidenceRef resolution. <br> 5. <strong>Autoscaling & batch windows:</strong> run scheduled compute windows for close runs and scale workers based on queue depth and SLO targets. <br> 6. <strong>Monitoring & alerting:</strong> set SLO-based alerts on <code>PlanBuildLatency</code>, <code>PreviewLatency</code>, <code>ApplyFailureRate</code>, and <code>GoldenParityFailures</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Operator CLI patterns & examples (expanded)</strong> <br> 1. <code>fa.build-run --period 2026-01 --policyRef fa_policy_20260101 --operator alice</code> → runs ingest and compute steps and returns <code>runId</code> and <code>depreciationRunManifestRef</code>. <br> 2. <code>fa.preview --run &lt;runId&gt; --sample 500 --operator alice</code> → produces <code>previewRef</code> with <code>previewHash</code>. <br> 3. <code>fa.suggest-je --preview &lt;previewRef&gt; --operator alice</code> → creates suggested JEs and <code>jePreviewHash</code>. <br> 4. <code>fa.generate-je --preview &lt;previewRef&gt; --accept &lt;suggestionIds&gt; --exportSpec ERP_JE_v1 --operator alice</code> → writes <code>FA_JE_Export_&lt;runId&gt;.csv</code> and emits <code>fa.je.exported</code>. <br> 5. <code>fa.apply --export &lt;exportPath&gt; --mode post_direct --operator alice --approvalId ap-321 --approver bob</code> → enforces ephemeral token issuance and two-person approval and emits <code>fa.je.apply.*</code>. <br> 6. <code>fa.revert --applyId &lt;applyId&gt; --operator alice</code> → triggers automated revert and logs <code>fa.je.revert</code>. <br> 7. <code>fa.policy.migrate --manifest &lt;manifestRef&gt; --operator alice</code> → executes migration canary per manifest and logs outcomes. <br> CLI safety: always persist <code>applyDescriptor</code> prior to mutative actions and require operator to record <code>correlationId</code> for auditability. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Acceptance criteria & release gates (explicit)</strong> <br> 1. Unit tests confirm deterministic canonicalization and method math parity across locales. <br> 2. Integration tests validate ingest→compute→preview→export flows on canonical fixtures and expected artifact checksums. <br> 3. Golden parity tests ensure <code>runHash</code>, <code>previewHash</code>, and <code>exportChecksum</code> match expected values; failing golden tests block merges. <br> 4. Migration manifest executed and canary KPIs within thresholds with approvals recorded before production promotion. <br> 5. Governance: direct posting requires two-person approval and ephemeral token issuance; audit completeness required for all mutative steps. <br> 6. Evidence & retention enforced for regulated artifacts and parity verification jobs scheduled. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Appendices (templates, runbook snippets and operator checklists)</strong> <br> <strong>Appendix A — migrationManifest template fields:</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code>, <code>sampleFixtures[]</code>, <code>estimatedAffectedCount</code>, <code>canaryPlan</code>, <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> <strong>Appendix B — run verification checklist:</strong> <br> 1. Confirm <code>policyHash</code> equals approved policy snapshot. <br> 2. Verify presence of <code>assetIngestChecksum</code> and <code>capexIngestChecksum</code> in <code>depreciationRunManifest</code>. <br> 3. Recompute <code>runHash</code> locally using canonicalization recipe and compare to persisted <code>runHash</code>. <br> 4. Confirm <code>previewHash</code> parity for analyst previews. <br> 5. Verify <code>jePreviewArtifact</code> balanced and validated against <code>jeTemplateSpec</code>. <br> <strong>Appendix C — security & privacy checklist:</strong> <br> 1. Tokenize PII on analyst surfaces; retrieve raw only via approval workflow. <br> 2. Enforce ephemeral tokens for GL posting; never log token material. <br> 3. Ensure static analysis checks for plaintext secrets in repo. <br> 4. Evidence access requests produce chain-of-custody audit rows and require specific approvals. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Overview"> <strong>Closing operational note (concise):</strong> This expanded document provides comprehensive per-row narratives, deterministic canonicalization rules, exhaustive function contracts across VBA modules, extended examples, PQ pilot guidance, and DAX reporting patterns. If you want the next artifacts (choose one or more): <br> 1. Formal JSON Schema for <code>AssetRow</code>, <code>DepreciationScheduleRow</code>, <code>applyDescriptor</code> and <code>recon_report</code> with exact field ordering for canonical hashing. <br> 2. Canonical CSV test fixtures and expected sha256 checksums for golden tests. <br> 3. Power Query canonicalization recipe as step-by-step transformations with expected intermediate outputs. <br> 4. Compact runbook PDF summarizing triage steps and CLI commands for operations teams. <br> Specify selected artifact(s) and environment preferences; artifacts will be produced using the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 28</div></div><div class="table-caption" id="Table2" data-table="Docu_0185_02" style="margin-top:2mm;margin-left:3mm;"><strong>Table 2</strong></div>
<div class="table-wrapper" data-table-id="table-2"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by Project 005 — Fixed Asset Register and Depreciation Specification"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">Project 005 — Fixed Asset Register and Depreciation Specification</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Reference:</strong> Project 005 canonical brief: fixed-asset master ingestion, capex/cost posting ingestion, deterministic depreciation engine, disposals/revaluations/impairments, subledger-to-GL reconciliation, audited JE suggestion & export pipeline, evidence-first immutability and governance. This document is an authoritative implementation blueprint for engineers, finance, and compliance teams. It documents per-field semantics, determinism recipes, function contracts, operator runbooks, conceptual Power Query (PQ) pilots, conceptual DAX measures, extensive worked examples, CI/golden parity strategy, SLOs and monitoring, and migration/governance controls. <br><br> <strong>Executive summary (one-paragraph):</strong> Project 005 builds a governance-first fixed-asset subsystem that consumes authoritative asset masters and capex feeds, applies a snapshotable capitalization & depreciation policy to compute deterministic per-asset schedules (supporting SL, DDB, SYD, Units-of-Production and configured custom methods), generates balanced JE suggestions, exports GL-ready payloads, supports disposals/revaluations/impairments, and reconciles the subledger to GL control accounts. Determinism, auditable evidence, PII minimization, and strict separation of ingest vs policy application are core design constraints. The implementation must produce canonical artifacts (ingest/manifests, policySnapshot, depreciationRunManifest, preview bundles, export manifests) with sha256 checksums and signatures as required, enabling golden CI tests and forensic replay. <br><br> <strong>Document scope & how to use:</strong> This document is intentionally explicit and exhaustive: use it as an implementation checklist. Each canonical model section includes per-field semantics and invariants. Each function section includes inputs, outputs, exact responsibilities, failure modes, observability metrics, CI tests, and runbook steps. Examples are conceptual narratives illustrating edge cases. PQ guidance assumes a pilot/analyst environment and identifies where to scale to backend compute. DAX guidance is conceptual—measures and reporting patterns for dashboards. All numbered lists use <code>&lt;br&gt;</code> line breaks as required. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Core guiding principles — operational & deterministic</strong><br>1. <strong>Absolute determinism for reproducibility:</strong> identical canonical inputs (asset master snapshot, capex feeds, policySnapshot, run parameters) must yield identical outputs: depreciation schedules, suggested JEs, preview artifacts, and all artifact checksums. Determinism enforced by canonical text normalization rules, fixed-scale numeric serialization, canonical ordering, deterministic tie-breakers, and seeded pseudo-random choices (if any). <br>2. <strong>Separation of concerns & minimal implicit behavior:</strong> ingestion normalizes and preserves evidence only; capitalization & depreciation logic execute against an immutable policySnapshot; previews are read-only; only apply/export paths mutate downstream systems. <br>3. <strong>Audit-first design & immutable evidence:</strong> every operator action and automated run emits audit rows referencing evidenceRefs (manifest checksums, artifact paths); evidence blobs are stored immutably with retention tags; audits reference but do not inline PII. <br>4. <strong>PII minimization & dual-evidence paths:</strong> analyst surfaces display tokenized custodian ids; full sanitized evidence (with PII) stored encrypted and retrievable under approval workflows recorded in chain-of-custody. <br>5. <strong>Policy & migration governance:</strong> semantic policy changes require a migrationManifest with sample fixtures, canary plans, KPIs, approvals, and rollback plan; direct posting to regulated GL ranges requires two-person approval plus ephemeral credential issuance. <br>6. <strong>Testability & golden parity:</strong> canonicalization and hashing recipes must be implemented identically across runtimes (PQ pilot, backend); CI includes golden fixtures and parity checks; failing golden diffs require migration manifest and approvals before release. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Canonical models — exhaustive per-field narratives and invariants</strong><br>All canonical models must preserve exact field names and types. Provenance fields <code>createdBy</code>, <code>createdTs</code>, <code>sourceUri</code> belong in manifests; canonical hashing recipes exclude transient provenance fields unless explicitly specified. Each field below includes purpose, allowed values, invariants, and evidence handling. <br><br><strong>AssetRow (canonical) — full per-field narrative:</strong><br>- <code>assetId</code> (string, deterministic): authoritative unique identifier for the asset. If the source provides an ERP/FA tag use that value; otherwise compute deterministically as <code>sha256(canonicalAssetKey)</code> where <code>canonicalAssetKey = normalize(assetTag || description || acquisitionDate)</code>. Invariant: identical canonical inputs produce identical <code>assetId</code> across re-ingests and runtimes. <br>- <code>assetTag</code> (nullable string): printed barcode/tag. Preserve original formatting in evidence; store canonical token (trim, casefold, remove diacritics where policy allows) for matching and hashing. <br>- <code>description</code> (string): human-readable description; keep raw description in evidence and a canonical normalized token for matching. <br>- <code>category</code> (string): controlled asset class (e.g., <code>IT</code>, <code>PlantEquipment</code>, <code>Vehicles</code>, <code>Furniture</code>). Must match an entry in <code>policySnapshot.categories</code> or be flagged as <code>Unclassified</code>. Changes to category mapping require migration manifest if they alter financial semantic behavior. <br>- <code>location</code> (nullable string): canonical site code preferred; free-form locations must be mapped via location dictionary; store both raw and canonical values. <br>- <code>custodianEmployeeId</code> (nullable token): pseudonymized token for analyst surfaces (e.g., <code>emp:xxxx</code>), raw PII stored only in encrypted evidence. Analysts see pseudonym; retrieval of raw PII requires approval and is logged. <br>- <code>acquisitionDate</code> (ISO <code>YYYY-MM-DD</code>): canonicalized date; ambiguous formats flagged in ingest issues. For calculations requiring time-of-day, policy must specify inclusion; by default use date only. <br>- <code>acquisitionCost</code> (decimal string): canonical fixed-scale decimal. Implementation must also store <code>amountMinorUnits</code> (integer) and <code>roundingScale</code> to remove floating-point ambiguity. For hashing, serialize as zero-padded fixed-scale string. <br>- <code>currency</code> (ISO4217): canonical currency code. If missing, use manifest defaultCurrency and flag in issues. <br>- <code>usefulLifeMonths</code> (integer): canonical useful life; if not provided derive from <code>policySnapshot</code> defaults; store <code>usefulLifeSource</code> (<code>policy | asset_override</code>). <br>- <code>depreciationMethod</code> (enum): one of <code>SL</code>, <code>DDB</code>, <code>SYD</code>, <code>UnitsOfProduction</code>, <code>Custom</code>. Default derived from <code>policySnapshot</code> category defaults. <br>- <code>salvageValue</code> (decimal string, nullable): defined in asset currency and scale; default from policy if omitted. <br>- <code>capitalizationPolicyRef</code> (string): pointer to the <code>policySnapshot</code> (policyHash) used to make capitalization decisions; include in canonicalization context for reproducibility. <br>- <code>assetStatus</code> (enum): <code>Active | Disposed | Revalued | Impaired</code>. Status transitions recorded via event rows with <code>eventRef</code>. <br>- <code>componentOf</code> (nullable string): assetId of parent asset when composition/assembly used; component assets follow component accounting rules per policy. <br>- <code>rawPayloadRef</code> (evidenceRef): pointer to the raw file and byte offset for forensic replay. <br>- <code>assetRowChecksum</code> (sha256): computed on canonical row string excluding transient metadata; used for dedup/forensics. <br><br><strong>CapexTransactionRow (canonical) — full per-field narrative:</strong><br>- <code>capexRowId</code> (string): deterministic id composed from source fingerprint + file offset + canonical tokens. <br>- <code>assetIdCandidate</code> (nullable string): best candidate <code>assetId</code> if found; include <code>candidateScore</code> (0..1) and <code>matchSignals</code> array (invoiceRef match, tag in description, vendor mapping, cost center match). <br>- <code>transactionDate</code> (ISO date). <br>- <code>amount</code> (decimal string): signed normalized amount. Ingest records <code>signConvention</code> (e.g., <code>DebitCreditColumns</code> or <code>SignedAmount</code>) and <code>originalSignRepresentation</code> for audit. <br>- <code>vendor</code>, <code>invoiceRef</code>, <code>poNumber</code> (nullable strings): used to correlate to asset evidence and supplier modules. <br>- <code>costCenter</code> (nullable string): used for posting and allocation. <br>- <code>currency</code> (string). <br>- <code>capexRowChecksum</code> (sha256). <br>- <code>rawPayloadRef</code> (evidenceRef). <br><br><strong>DepreciationScheduleRow (canonical) — full per-field narrative:</strong><br>- <code>scheduleId</code> (string): deterministic id derived from (<code>assetId</code> + <code>periodStart</code> + <code>periodEnd</code> + <code>policyHash</code>). Changing the <code>policyHash</code> yields different <code>scheduleId</code> values; historical schedules are retained and not overwritten. <br>- <code>assetId</code> (string). <br>- <code>periodStart</code> / <code>periodEnd</code> (ISO date): canonical period boundaries. <br>- <code>depreciationAmount</code> (decimal string): post-proration, pre-posting rounding? — The schedule stores amounts after proration and after final rounding per <code>roundingScale</code>. The canonicalization ensures consistent rounding across runtimes. <br>- <code>preRoundedAmount</code> (high-precision decimal string): pre-rounding value recorded for forensic verification. <br>- <code>accumulatedDepreciationToDate</code> (decimal string). <br>- <code>bookValueEnd</code> (decimal string): cost less accumulated depreciation post-period. <br>- <code>method</code> (string) and <code>methodParams</code> (object): method applied and method-specific parameters (DDB factor, units produced, etc.) included for traceability. <br>- <code>prorationFactor</code> (decimal string between 0 and 1). <br>- <code>roundingScale</code> (integer). <br>- <code>residualAbsorbed</code> (decimal string): amount of residual absorbed in this period due to rounding; zero if none. <br>- <code>scheduleRowChecksum</code> (sha256). <br>- <code>evidenceRefs[]</code> referencing assetRowChecksum and policySnapshot. <br><br><strong>DisposalRow / RevaluationRow (canonical) — full per-field narrative:</strong><br>- <code>eventId</code> (string), <code>assetId</code>, <code>eventDate</code>, <code>eventType</code> (<code>Disposal | Revaluation | Impairment</code>), <code>proceeds</code> (decimal, nullable for non-disposal events), <code>adjustedBookValue</code>, <code>gainLossRecognized</code> (decimal), <code>taxTreatment</code> (object), <code>notes</code>, <code>rawPayloadRef</code>, <code>eventRowChecksum</code>. Revaluation rows include <code>revalBasis</code>, <code>revalLevel</code> (asset/portfolio), and <code>policyRef</code>. <br><br><strong>JE_Line (canonical) — full per-field narrative:</strong><br>- <code>jeLineId</code> (string), <code>jeId</code> (string), <code>account</code> (canonical GL account string), <code>debitCredit</code> (<code>Debit|Credit</code>), <code>amount</code> (decimal string), <code>narrative</code> (text, including <code>assetId</code> references where appropriate), <code>costCenter</code>, <code>currency</code>, <code>evidenceRefs[]</code> linking to scheduleRows, disposalRows, or manifests. JE bundles must be balanced per <code>jeId</code> at <code>roundingScale</code> and record <code>jeChecksum</code>. <br><br><strong>Plan/Run/Preview/Export Manifests (contracts):</strong><br>- <code>policySnapshot</code> includes <code>policyHash</code>, <code>rulesSummary</code>, <code>author</code>, <code>createdTs</code>. <br>- <code>assetIngestManifest</code> and <code>capexIngestManifest</code> include <code>sourceFingerprint</code>, <code>ingestChecksum</code>, <code>rowsCount</code>, <code>rowsSample</code>, <code>loadTs</code>, <code>issues[]</code>, <code>ingestPolicyMode</code>. <br>- <code>depreciationRunManifest</code> includes <code>runId</code>, <code>runHash</code>, <code>policyHash</code>, <code>assetIngestChecksum</code>, <code>capexIngestChecksum</code>, <code>paramsHash</code>, <code>rowsCount</code>, <code>createdTs</code>, <code>operatorId</code>. <br>- <code>previewManifest</code> contains included artifacts and <code>previewHash</code>. <br>- <code>exportManifest</code> contains <code>exportChecksum</code>, <code>exportSpecRef</code>, <code>rowsCount</code>, <code>operatorId</code>, <code>createdTs</code>. <br>- <code>applyDescriptor</code> (described later) is immutable and persisted prior to mutative actions. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Canonicalization & hashing recipe — exact rules for parity</strong><br>1. <strong>Normalization rules for text:</strong> apply Unicode NFKC normalization; trim leading/trailing whitespace; collapse internal multiple spaces into single spaces; convert to lowercase for canonical tokens; optionally strip diacritics (policy controlled). Keep original raw fields in evidence. <br>2. <strong>Numeric canonicalization:</strong> persist <code>amountMinorUnits</code> integer (amount * 10^scale) and <code>scale</code> explicitly. For hashing always produce decimal string with fractional digits zero-padded to <code>scale</code>. Use string formatting rules identical across runtimes. <br>3. <strong>Date canonicalization:</strong> format as <code>YYYY-MM-DD</code>. If time component included by policy, use full ISO timestamp but normalize milliseconds/trailing zeros. <br>4. <strong>Canonical serialization order:</strong> each model defines a fixed field order used for canonical string serialization; specify exact order in schema; omit transient fields. Use <code>|</code> separators and no trailing newline. <br>5. <strong>Encoding & hashing:</strong> encode canonical string as UTF-8 and compute sha256 hex; prefix hashes with algorithm id in manifests (e.g., <code>sha256:&lt;hex&gt;</code>). <br>6. <strong>Deterministic tie-breakers:</strong> where selection required (residual absorption target or candidate selection), use (a) highest pre-rounded absolute amount; (b) if tie, lexicographically smallest <code>assetId</code> or <code>rowId</code>; (c) last-resort deterministic seed derived from <code>runHash</code>. Document tie-breakers precisely and include parity tests. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Function-level breakdowns — complete, exhaustive (inputs, outputs, responsibilities, invariants, failure modes, observability, CI tests, runbook steps)</strong><br><br><strong><code>LoadAssetMaster(source,options)</code> — exhaustive contract:</strong><br><strong>Responsibilities:</strong> ingest asset master files (workbook/CSV/API), normalize per canonical rules, compute <code>assetRowChecksum</code> for each row, tokenize PII, validate required fields and produce <code>assetIngestManifest</code> persisted with <code>ingestChecksum</code> and evidenceRef. Do not perform capitalization or depreciation logic here. <br><strong>Inputs:</strong> <code>source</code> (file path/workbook table/API payload), <code>options</code> (mode: <code>strict | tolerant</code>, <code>defaultCurrency</code>). <br><strong>Outputs:</strong> canonical <code>AssetRow[]</code>, <code>assetIngestManifest</code> persisted to evidence store, audit entry <code>fa.asset.ingest.success{manifestRef}</code>. <br><strong>Detailed steps & invariants:</strong> <br>1. <strong>Source fingerprint:</strong> normalize bytes (<code>\n</code> newline, trim trailing spaces, remove BOM) and compute <code>sourceFingerprint = sha256(normalizedBytes)</code>; persist original file as evidence blob keyed by <code>sourceFingerprint</code>. <br>2. <strong>Header mapping:</strong> deterministic header synonym lookup; record <code>headerMap</code> in manifest. <br>3. <strong>Row parse & streaming normalization:</strong> stream parse to avoid memory issues; for each row create <code>rawPayloadRef</code> (file offset), apply token normalization to key fields, coerce numeric fields to canonical scale, compute <code>assetRowChecksum</code>. <br>4. <strong>Validation:</strong> required fields depend on <code>options</code>. In <code>strict</code> mode fail the ingest on missing required fields; in <code>tolerant</code> mode ingest valid rows and record failing rows in <code>issues[]</code>. Required fields commonly: <code>assetTag</code> or <code>assetId</code>, <code>acquisitionDate</code>, <code>acquisitionCost</code>, <code>category</code>. <br>5. <strong>Manifest & audit:</strong> produce <code>assetIngestManifest</code> with <code>ingestChecksum</code> (sha256 canonicalized CSV), <code>rowsCount</code>, <code>rowsSample</code>, <code>loadTs</code>, and <code>ingestToolVersion</code>. Emit audit event <code>fa.asset.ingest.success</code>. <br><strong>Failure modes & remediation:</strong> <br>- Malformed encoding → <code>fa.asset.ingest.invalid</code> with evidenceRef; remediate by converting encoding and re-ingesting. <br>- Missing required fields in <code>strict</code> mode → block and return human-actionable diagnostics with sample rows. <br>- Unknown category values → map to <code>Unclassified</code> and surface top unmapped categories in manifest. <br><strong>Observability & metrics:</strong> <code>asset.ingest.latencyMs</code>, <code>rowsParsed</code>, <code>rowsFailed</code>, <code>sourceFingerprint</code>. <br><strong>CI tests:</strong> header synonym matrix tests, encoding tests (UTF families), decimal scale preservation tests, ambiguous date permutations, golden <code>ingestChecksum</code> parity tests. <br><strong>Runbook excerpt:</strong> on <code>asset.ingest.partial</code>, capture <code>correlationId</code>, fetch manifest evidenceRef, inspect <code>issues[]</code>, correct data (or update headerMap) and re-run ingest with <code>correctionOf</code> link to prior attempt. <br><br><strong><code>LoadCapexTransactions(source,options)</code> — exhaustive contract:</strong><br><strong>Responsibilities:</strong> ingest AP/capex feeds, detect sign conventions, normalize amounts and currencies, generate candidate asset mapping, produce <code>capexIngestManifest</code> and <code>candidateMappingIndex</code>. Surface unmapped high-value transactions for analyst review. <br><strong>Inputs:</strong> AP extracts (CSV/workbook), <code>options</code> (currency default, sign policy). <br><strong>Outputs:</strong> <code>CapexTransactionRow[]</code>, <code>capexIngestManifest</code>, <code>candidateMappingIndex</code>. <br><strong>Detailed steps:</strong> <br>1. Compute <code>sourceFingerprint</code> and persist original file. <br>2. Header mapping and normalization identical to asset ingest. <br>3. Detect sign convention: if <code>Debit</code>/<code>Credit</code> columns present convert to signed <code>amount</code>; record <code>signConvention</code> in manifest. <br>4. Candidate mapping heuristics: produce <code>assetIdCandidates</code> scored by: invoiceRef exact match (high weight), assetTag found in description (high), vendor–asset co-occurrence (medium), cost center inference (low), historical mapping (medium). Store structured <code>candidateSignals</code> for auditability. <br>5. Flag <code>capitalCandidate</code> based on policy <code>capitalizationThreshold</code> and category hints. <br>6. Persist <code>capexIngestManifest</code> with <code>unmappedCount</code>, sample rows, and emit <code>fa.capex.ingest.success</code> or <code>fa.capex.ingest.partial</code>. <br><strong>Failure modes & remediation:</strong> inconsistent currency → require FX normalization step; missing invoiceRef reduces candidate confidence and surfaces to analyst queue. <br><strong>CI tests & PQ guidance:</strong> fuzzed invoice formats, candidate mapping regression tests, performance tests for high-volume AP feeds. <br><br><strong><code>LoadPolicySnapshot(policySource)</code> — exhaustive contract:</strong><br><strong>Responsibilities:</strong> ingest and canonicalize policy artifacts controlling capitalization thresholds, category default useful lives, rounding/absorption rules, proration conventions, and mapping rules (category→GL account). Compute <code>policyHash</code> snapshot deterministically and persist <code>policyManifest</code>. <br><strong>Inputs:</strong> <code>policySource</code> (workbook/JSON) with schema: categories, usefulLifeMonths, salvageDefaults, roundingScale, prorationRule, additionTreatment, mappingOverrides. <br><strong>Outputs:</strong> <code>policySnapshot</code> with <code>policyHash</code>, <code>policyManifest</code>. <br><strong>Detailed steps:</strong> <br>1. Schema validation: require core fields; in strict mode fail ingestion on schema mismatch. <br>2. Normalization: canonicalize tokens and numeric formats, sort rows deterministically. <br>3. Canonical serialization: remove transient fields, produce canonical string and compute <code>policyHash = sha256(canonicalString)</code>. Record <code>policyHash</code> in manifest and use as fingerprint in subsequent runs. <br>4. Emit <code>fa.policy.loaded{policyHash}</code> audit. <br><strong>Tests:</strong> parity tests ensuring cross-runtime <code>policyHash</code> identity; property tests to ensure transient metadata changes do not change <code>policyHash</code>. <br><strong>Governance:</strong> policy changes that affect behavior require a migrationManifest with canary plan and approvals before applying in production runs. <br><br><strong><code>ComputeDepreciation(assetRows,capexRows,policySnapshot,params)</code> — exhaustive schedule engine contract:</strong><br><strong>Purpose:</strong> produce deterministic <code>DepreciationSchedule[]</code>, <code>ScheduledJEProposals[]</code> and <code>depreciationRunManifest</code> for the requested period(s) using an immutable <code>policySnapshot</code>. <br><strong>Inputs:</strong> canonical <code>AssetRow[]</code>, <code>CapexTransactionRow[]</code> (recent additions), <code>policySnapshot</code> (policyHash), and <code>params</code> (periodStart, periodEnd, roundingScale override optional, tolerance thresholds). <br><strong>Outputs:</strong> canonical <code>DepreciationSchedule[]</code>, <code>ScheduledJEProposals[]</code>, <code>depreciationRunManifest</code> with <code>runHash</code>, <code>createdTs</code>, <code>operatorId</code>. <br><strong>Comprehensive algorithmic steps:</strong> <br>1. <strong>Capitalization decisions:</strong> evaluate each capexRow flagged <code>capitalCandidate</code> using rule chain: invoiceRef exact match to assetTag, amount >= capitalizationThreshold, GL account mapping hints, vendor allowlist, and cost center. Document the applied rule and persist a <code>capitalizationDecision</code> object with <code>evidenceRef</code>. Decisions are auditable and immutable. <br>2. <strong>Asset augmentation & revisioning:</strong> if capex maps to an existing asset apply <code>additionTreatment</code> defined in policy: <code>append_cost</code> (most common), <code>create_component</code> (component accounting), or <code>restart_depreciation</code>. Any change to asset cost triggers a deterministic <code>assetRevisionId</code> and new schedule recomputation from the <code>revisionEffectiveDate</code>. Persist asset revision to evidence. <br>3. <strong>Depreciation start date & proration:</strong> determine <code>depreciationStart</code> using policy (<code>acquisitionDate</code> vs <code>inServiceDate</code>) and compute <code>prorationFactor</code> for the first and last periods per <code>prorationRule</code> (<code>monthProrata</code>, <code>daysProrata</code>, <code>halfMonth</code>). Store <code>prorationFactor</code> in schedule rows for audit. <br>4. <strong>Method-specific computations:</strong> <br>&nbsp;&nbsp;&nbsp;&nbsp;a. <strong>Straight Line (SL):</strong> preRoundPeriod = ((cost - salvage) / usefulLifeMonths) <em> prorationFactor (for first/last); compute preRounded series for all periods. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. <strong>Double Declining Balance (DDB):</strong> compute DDB rate = factor/usableLifeYears (e.g., 2) and apply to book value each period; include deterministic switch-to-SL algorithm when DDB would over-depreciate the remaining base. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. <strong>Sum-of-Years Digits (SYD):</strong> compute numerator denominator per year and allocate accordingly; express as monthly proportions when required. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. <strong>Units of Production:</strong> require <code>usageMetric</code> for each period; preRoundPeriod = ((cost - salvage) </em> usageThisPeriod) / totalExpectedUsage. If usage absent mark <code>requiresManualInput</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;e. <strong>Custom / Hybrid:</strong> allow for configured custom methods via policySnapshot but require migration manifest for semantics. <br>5. <strong>Pre-rounding & rounding rules:</strong> compute all pre-rounding values at high precision (scale >= policy internal precision), then round per <code>roundingScale</code> using deterministic rounding mode (default Banker's rounding / round-half-to-even). Keep <code>preRoundedAmount</code> in schedule row for forensic checks. <br>6. <strong>Residual absorption algorithm (deterministic):</strong> compute <code>residual = canonicalTotal - sum(roundedPeriods)</code>; absorb residual into the period with maximum absolute pre-rounded amount; if tie, choose lexicographically smallest <code>assetId</code>. Record <code>residualAbsorbed</code> and <code>residualRationale</code> in schedule metadata. This avoids mismatches across runtimes. <br>7. <strong>Accumulate & NBV enforcement:</strong> compute <code>accumulatedDepreciationToDate</code> and <code>bookValueEnd</code>. If rounding residuals lead to negative NBV, adjust final period deterministically and flag <code>adjustmentReason</code>. <br>8. <strong>Impairment & revaluation hooks:</strong> evaluate impairment indicators per policy; produce <code>RevaluationProposal</code> artifacts including adjustments and evidence. Revaluation will create a new <code>assetRevisionId</code> and new schedule snapshots. <br>9. <strong>JE aggregation & suggestion generation:</strong> group schedule rows by posting aggregation keys (e.g., <code>GLAccount + costCenter + currency + period</code>) defined by <code>jeTemplateSpec</code> and policy mapping. For each group produce <code>ScheduledJEProposal</code> with balanced <code>jeLines[]</code> and attach <code>evidenceRefs[]</code>. Compute <code>confidenceScore</code> from mapping completeness, DQ scores, and presence of manual flags. <br>10. <strong>Manifest & runHash:</strong> assemble <code>depreciationRunManifest</code> capturing <code>policyHash</code>, <code>assetIngestChecksum</code>, <code>capexIngestChecksum</code>, <code>paramsHash</code>, <code>rowsCount</code>, <code>createdTs</code>, and compute <code>runHash = sha256(canonicalManifest)</code>. Persist manifest and emit audit <code>fa.depn.run.completed{runId,runHash}</code>. <br><strong>Edge cases & governance:</strong> <br>- <code>usefulLifeMonths = 0</code> or negative → mark <code>requiresManualOverride</code>. <br>- Partial disposals mid-period → prorate last period and generate disposal JE proposals. <br>- Cross-currency assets → require FX normalization using canonical FX rate table; persist <code>fxRateRef</code> in manifest. <br><strong>CI tests:</strong> per-method unit tests, residual absorption parity tests, cross-runtime golden fixtures for <code>runHash</code>, property tests for order invariance and numeric parity. <br><strong>Observability & metrics:</strong> <code>depn.run.durationMs</code>, <code>schedulesGenerated</code>, <code>jeProposalsCount</code>, <code>residualAdjustmentsCount</code>, <code>requiresManualInputCount</code>. <br><strong>Operator runbook excerpt:</strong> if schedules show <code>requiresManualInput</code> items, collect the missing data (e.g., usage metrics), annotate schedule rows, and re-run <code>ComputeDepreciation</code> for those <code>assetRevisionId</code> entries. <br><br><strong><code>GenerateDepreciationJE(scheduleRows,jeTemplateSpec)</code> — exhaustive contract:</strong><br><strong>Purpose:</strong> convert schedule rows into balanced JE suggestions validated against the downstream <code>jeTemplateSpec</code> (export format, column order, sign conventions), and persist a preview artifact for analyst review. <br><strong>Inputs:</strong> <code>scheduleRows[]</code>, <code>jeTemplateSpec</code> (loader-specific rules), optional <code>aggregations</code> param (per-asset or grouped by posting rules). <br><strong>Outputs:</strong> <code>SuggestedJEs[]</code> canonical, <code>jePreviewArtifact</code> persisted, <code>previewManifest</code> with <code>previewHash</code>. <br><strong>Detailed flow & safety checks:</strong> <br>1. <strong>Map category → GL accounts:</strong> use policySnapshot mapping; where mapping missing produce <code>mappingSuggestion</code> artifacts and flag JE lines as <code>requiresMappingResolution</code>. <br>2. <strong>Grouping & JE construction:</strong> group scheduleRows by posting keys and create <code>jeLines</code> per group (Debit <code>DepreciationExpense</code>, Credit <code>AccumulatedDepreciation</code>), including per-asset breakout if policy requires. Ensure internal roundingScale is applied consistently. <br>3. <strong>Balance validation:</strong> verify each JE balances; if imbalance due to rounding apply deterministic residual absorption within the JE (largest pre-rounded absolute line) and record <code>residualAbsorbedBy</code> with rationale. If still unbalanced (rare), fail preview and surface for manual review. <br>4. <strong>Annotate evidence & confidence:</strong> attach scheduleRowRefs and <code>depreciationRunManifest</code> to each JE; compute <code>confidenceScore</code> with components: <code>mappingCompleteness</code>, <code>dqPenalty</code>, <code>manualFlagsPenalty</code>, and <code>historicalStability</code>. Provide <code>confidenceBreakdown</code> for analyst transparency. <br>5. <strong>Export spec validation:</strong> validate that JE payload can be serialized to <code>jeTemplateSpec</code>; produce deterministic CSV/JSON artifact conforming to loader expectations. If spec mismatch produce <code>fa.je.export.invalid_spec</code> diagnostics. <br>6. <strong>Artifact persistence:</strong> package schedules, suggestedJEs, previewManifest into <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> and persist to evidence. Emit audit <code>fa.je.preview.generated</code>. <br><strong>Tests:</strong> JE balancing parity tests, mapping translation tests, export format golden checksums, tie-breaker determinism tests. <br><strong>Analyst interactions:</strong> analysts review preview artifact, annotate suggestions, accept/reject per suggestionId; accepted suggestions fed into <code>GenerateJEExport</code> or apply flows. <br><br><strong><code>GenerateJEExport(acceptedJEs,exportSpec,operatorId)</code> — exhaustive contract:</strong><br><strong>Purpose:</strong> convert analyst-accepted JE suggestions into exact, validated payloads for downstream GL loaders, persist export artifacts and exportManifest, and optionally initiate <code>ApplyCorrections</code>. <br><strong>Inputs:</strong> <code>acceptedJEs[]</code>, <code>exportSpec</code> (field mapping, date/number formats, sign conventions), <code>operatorId</code>. <br><strong>Outputs:</strong> persisted export artifact (<code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>), <code>exportManifest</code>, audit <code>fa.je.exported</code>. <br><strong>Flow & validations:</strong> <br>1. <strong>Spec validation:</strong> ensure <code>acceptedJEs</code> match <code>exportSpec</code> columns, order, and format constraints. Fail export with clear diagnostics if mismatch. <br>2. <strong>Balance & schema validation:</strong> confirm each JE bundle balances at <code>roundingScale</code>; if unbalanced fail export and highlight bundles. <br>3. <strong>Serialization & naming:</strong> serialize per spec (CSV/JSON/XML) using deterministic escaping and encoding; compute <code>exportChecksum = sha256(payload)</code>; artifact named <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>. <br>4. <strong>Atomic persist & manifest:</strong> persist artifact and <code>exportManifest</code> atomically and emit <code>fa.je.exported{exportPath,exportChecksum}</code> audit. <br>5. <strong>Retries & staging:</strong> on write failure attempt limited retries; on persistent failure stage locally and surface <code>fa.je.export.warning</code> with staging path. <br><strong>Tests & verification:</strong> schema matching tests, golden export checksum tests across environments, loader acceptance tests in test GL system. <br><br><strong><code>ApplyCorrections(acceptedJEs,mode,operatorId,approvals)</code> — exhaustive orchestration contract:</strong><br><strong>Purpose:</strong> orchestrate authoritative application of accepted JEs either by producing exports (<code>create_export</code>) or direct posting to GL (<code>post_direct</code>), persist <code>applyDescriptor</code> atomically before mutation, and store revert metadata to enable safe reverts. <br><strong>Inputs:</strong> <code>acceptedJEs</code> (or exportPath), <code>mode</code> (<code>create_export | post_direct</code>), <code>operatorId</code>, <code>approvals</code> (evidenceRef). <br><strong>Outputs:</strong> <code>applyDescriptor</code> persisted, <code>applyResult</code> with per-JE status, <code>postedJournalIds[]</code> for <code>post_direct</code>, audit <code>fa.je.apply.*</code>. <br><strong>Flow details & safety controls:</strong> <br>1. <strong>Approval gating:</strong> validate required approvals per <code>depreciationRunManifest.requiredApprovals</code>; enforce two-person approval for <code>post_direct</code> when required. <br>2. <strong>Persist <code>applyDescriptor</code> atomically:</strong> <code>applyDescriptor</code> includes <code>applyId</code>, <code>runId</code>, <code>acceptedJEsHash</code>, <code>beforeChecksums</code> (assetIngestChecksum, capexIngestChecksum, runHash), <code>approvalsRef</code>, <code>operatorId</code>, <code>mode</code>, and <code>applyTs</code>. Persist before any mutative action to ensure recoverability. <br>3. <strong>Execute mode:</strong> <br>&nbsp;&nbsp;&nbsp;&nbsp;a. <strong>create_export:</strong> ensure export artifact persisted and return artifact path. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. <strong>post_direct:</strong> request ephemeral credentials from secure token service; post payload to GL with idempotency token derived from <code>applyId</code>. Record <code>postedJournalIds</code> and confirmations. <br>4. <strong>Post-apply reconciliation:</strong> collect GL confirmations and compute <code>afterChecksums</code>; persist <code>applyResult</code> with per-bundle statuses. <br>5. <strong>Partial failure handling:</strong> record per-JE error codes, enable governed retries; idempotency tokens prevent duplicate postings on retries. <br>6. <strong>Revert metadata:</strong> persist <code>revertDescriptor</code> containing <code>beforeChecksums</code>, <code>postedJournalIds</code>, <code>applyId</code> to enable reversion workflows. <br><strong>Security & secrets:</strong> ephemeral tokens only; never persist token material in logs. All token issuance events are audited. <br><strong>Tests:</strong> approval gating tests, idempotency replay tests, partial failure simulation, token lifecycle validation. <br><br><strong><code>RevertJEs(applyId,operatorId)</code> — exhaustive rollback contract:</strong><br><strong>Purpose:</strong> attempt safe automated reversion of previously applied JE bundles via GL reversal endpoints or generate manual reversal artifacts if automation unsupported. Persist <code>revertDescriptor</code> and ensure idempotency of revert operations. <br><strong>Inputs:</strong> <code>applyId</code>, <code>operatorId</code>. <br><strong>Outputs:</strong> <code>revertResult</code> with per-JE status, <code>revertDescriptor</code> persisted, audit <code>fa.je.revert</code>. <br><strong>Flow:</strong> <br>1. Retrieve <code>applyDescriptor</code> and ensure <code>postedJournalIds</code> present; if missing return <code>fa.revert.noSnapshot</code>. <br>2. Compute deterministic <code>revertId = sha256(applyId + normalizedRevertTs)</code> and check prior revert status to ensure idempotent no-op on replays. <br>3. Attempt automated revert via GL reversal API using ephemeral tokens and idempotency tokens; capture responses. <br>4. If GL does not support automated reversal generate <code>reversalArtifact.csv</code> and <code>forensic_manifest</code> for manual processing; mark as <code>pending_manual_revert</code>. <br>5. Persist <code>revertDescriptor</code> containing <code>applyId</code>, <code>revertId</code>, <code>revertTs</code>, <code>postedJournalIds</code>, <code>revertResult</code>. <br>6. Audit and notify compliance/GL teams. <br><strong>Tests & runbook:</strong> idempotency tests for repeated reverts, partial revert handling, manual revert packaging verification. <br><br><strong><code>ReconcileFAtoGL(assetScheduleAgg,glBalances)</code> — exhaustive reconciliation contract:</strong><br><strong>Purpose:</strong> produce deterministic recon report joining fixed-asset subledger aggregates to GL control balances, flag exceptions, and suggest candidate remediations. <br><strong>Inputs:</strong> <code>assetScheduleAgg</code> (aggregated subledger rows by controlGLAccount + costCenter + period), <code>glBalances</code> (GL control balances). <br><strong>Outputs:</strong> <code>fa_recon_report</code> with per-row variance, <code>reconManifest</code>, <code>suggestedRemediation[]</code>. <br><strong>Flow details:</strong> <br>1. Compute canonical grouping keys: <code>controlGLAccount</code>, <code>costCenter</code>, <code>currency</code>, <code>period</code>. <br>2. Full-outer join to produce <code>Matched</code>, <code>FAOnly</code>, <code>GLOnly</code>. <br>3. Compute <code>Variance = SubledgerAmount - GLAmount</code>, <code>AbsVariance</code>, <code>RelativeVariancePct</code>. Apply materiality <code>BeyondTolerance</code> logic: if <code>GLAmount = 0</code> use absolute threshold; otherwise use configured relative pct. <br>4. Attach sample evidenceRefs for each exception: schedules, JE exports, apply descriptors, preview artifacts. <br>5. Suggest remediation: re-run JE export, correct mapping, manual adjustment with approvals, or open incident if GL posting failure. <br>6. Persist <code>reconManifest</code> and emit audit <code>fa.recon.report.generated{runId,reportHash}</code>. <br><strong>Tests:</strong> reconciliation parity tests, tolerance boundary tests, recon manifest checksum golden fixtures. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Extremely detailed worked examples — conceptual narratives (no code)</strong><br><strong>Example 1 — Capitalization & component addition to existing asset (narrative):</strong><br>1. AP invoice INV-2026-001 amount 18,750.00 USD description "Server chassis SN-AX45". <br>2. <code>LoadCapexTransactions</code> extracts <code>SN-AX45</code> and candidate-matches to <code>assetTag</code> AS-000123 with <code>candidateScore=0.97</code>. <br>3. <code>policySnapshot</code> indicates <code>capitalizationThreshold=5000</code>, so invoice flagged <code>capitalCandidate=true</code>. <br>4. <code>ComputeDepreciation</code> applies <code>additionTreatment=append_cost</code> and increases <code>acquisitionCost</code> of AS-000123; recompute remaining schedule per <code>usefulLifeRemaining</code> as policy states. Persist <code>assetRevisionId</code> and update <code>depreciationRunManifest</code>. <br>5. <code>GenerateDepreciationJE</code> aggregates periodic expense and includes evidenceRefs to INV-2026-001 and <code>assetIngestManifest</code>. <br>6. Analyst reviews <code>jePreviewArtifact</code>, accepts JE suggestions; <code>GenerateJEExport</code> creates <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code>. <br><br><strong>Example 2 — Disposal with gain/loss recognition (narrative):</strong><br>1. Disposal event row: <code>assetTag=AS-000456</code>, sold 2026-01-10 for proceeds 2,500.00 USD. <br>2. Retrieve latest <code>bookValueEnd</code> = 1,800.00; <code>accumulatedDep</code> = 8,200.00; original cost = 10,000.00. <br>3. Compute gain = proceeds (2,500) - NBV (1,800) = 700.00. <br>4. Suggested JE lines: Debit <code>Cash</code> 2,500.00; Debit <code>AccumulatedDepreciation</code> 8,200.00; Credit <code>AssetCost</code> 10,000.00; Credit <code>GainOnDisposal</code> 700.00. <br>5. Disposal triggers approval if proceeds exceed threshold; if approved analysts <code>GenerateJEExport</code> and then <code>ApplyCorrections</code> per governance. <br><br><strong>Example 3 — Rounding & residual absorption (edge-case narrative):</strong><br>1. Asset cost 1,000.00, salvage 0.00, useful life 3 months → theoretical monthly 333.3333... <br>2. <code>roundingScale=2</code> produces rounded amounts 333.33 each → total 999.99 -> residual +0.01. <br>3. Residual absorption rule adds 0.01 to the deterministic target period (largest pre-rounded absolute; tie-breaker smallest <code>assetId</code>) resulting in one period 333.34. Persistence of <code>residualAbsorbed</code> shows which period and why. <br><br><strong>Example 4 — Units-of-Production missing usage metric (narrative):</strong><br>1. Asset with <code>UnitsOfProduction</code> method expecting 10,000 total units. No usage reported for period. <br>2. <code>ComputeDepreciation</code> flags schedule with <code>requiresManualInput</code>; <code>confidenceScore</code> low; schedule included in analyst queue with <code>requiresAction</code> for usage data. Analysts supply usage and re-run schedule creation. <br><br><strong>Example 5 — Policy migration canary narrative:</strong><br>1. Proposed policy change reduces default useful life for <code>IT</code> category from 36 to 30 months. <br>2. Create <code>migrationManifest</code> describing change, sample fixtures covering top 1,000 IT assets, <code>canaryPlan</code> targeting 1% cohort (e.g., 10 assets), and KPIs: <code>DepnExpenseDeltaPct</code>, <code>RunParityChange</code>. <br>3. Run canary and monitor KPIs for 3 cycles. If acceptable and approvals captured persist updated <code>policySnapshot</code> and run mass migration with approval gating and golden tests. If unacceptable rollback to prior <code>policyHash</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Power Query (PQ) conceptual guidance for pilots — explicit patterns & tradeoffs</strong><br>1. <strong>When to use PQ:</strong> use PQ for rapid prototyping, small fleets (< ~5k assets depending on complexity) and analyst-driven preview work where UI-hosted computations are acceptable. For enterprise-scale fleets (>10k) prefer backend/warehouse compute. <br>2. <strong>Ingest queries patterns:</strong> implement <code>AssetMaster_Staging</code> and <code>Capex_Staging</code> PQ queries with configurable header synonym tables exposed as parameters. PQ queries should produce canonicalized staging tables with stable transformations applied. <br>3. <strong>Canonicalization steps in PQ (conceptual):</strong> <br>&nbsp;&nbsp;&nbsp;&nbsp;a. Apply <code>Text.Trim</code> and <code>Text.Clean</code> to text fields; <code>Text.Lower</code> for canonical tokens. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Replace diacritics using mapping tables where PQ platform lacks built-in functions. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. Use culture-invariant numeric parsing: pre-replace thousand separators and ensure <code>.</code> decimal separator before <code>Number.FromText</code>. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. Compute <code>amountMinorUnits</code> by rounding to <code>roundingScale</code> and multiply by 10^scale. <br>4. <strong>Policy snapshot representation:</strong> store <code>policySnapshot</code> as a named parameterized query; compute <code>policyHash</code> from canonical string representation of this query. Keep policy changes in source control as named snapshots. <br>5. <strong>Schedule computation in PQ:</strong> for small fleets implement <code>fn_ComputeSchedule(assetRow,policyParams)</code> as a custom function using table transformations; watch for per-row loops—these scale poorly in PQ; use list or table buffers and table transformations to vectorize where possible. <br>6. <strong>Export & preview artifact packaging in PQ:</strong> export CSVs and create <code>preview_manifest.json</code> string inside PQ, then use host platform (Excel/Power BI dataflows or Power Automate) to zip artifacts and persist to evidence store. Ensure filenames include <code>runId</code> and <code>previewHash</code>. <br>7. <strong>Testing PQ parity:</strong> produce PQ golden fixtures and cross-validate <code>runHash</code> parity with backend runs. PQ pilot runs must produce same <code>policyHash</code> and <code>runHash</code> for identical inputs. <br>8. <strong>Limitations & mitigations:</strong> PQ lacks efficient parallel compute for large fleets and high-precision decimal math; offload to backend for scale-critical workloads while retaining PQ for analyst previews. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Conceptual DAX measures and reporting patterns — detailed</strong><br>1. <strong>Basic measures:</strong><br><code>DepreciationExpense = SUM(DepSchedule[depreciationAmount])</code>.<br><code>AccumulatedDep = SUM(DepSchedule[accumulatedDepreciationToDate])</code>.<br><code>NetBookValue = SUM(DepSchedule[bookValueEnd])</code>.<br>2. <strong>Reconciliation & variance measures:</strong><br><code>FA_ReconVariance = SUM(Subledger[AccumulatedDep]) - SUM(GL[AccumulatedDep])</code>.<br><code>BeyondToleranceFlag = IF(ABS(GLAmount)=0, ABS(Variance)&gt;AbsThreshold, ABS(Variance)/ABS(GLAmount)&gt;TolerancePct)</code>.<br>3. <strong>Operational measures:</strong><br><code>SuggestionAcceptanceRate = DIVIDE(COUNTROWS(AcceptedJEs), COUNTROWS(SuggestedJEs), 0)</code>.<br><code>OpenExceptions = COUNTROWS(FARExceptions WHERE status=&#x27;open&#x27;)</code>.<br>4. <strong>Trend & KPI patterns:</strong> build visuals showing <code>DepreciationExpense</code> by month and stacked by <code>category</code>; show <code>RunParity</code> (number of changed runHash artifacts) across policy snapshots; provide <code>Top Variance</code> tables with drillthrough to <code>evidenceRefs</code>. <br>5. <strong>Materiality & filtering:</strong> enable slicers for <code>policyHash</code>, <code>period</code>, <code>category</code>, <code>location</code>, and <code>costCenter</code>; allow materiality thresholds to be runtime parameters used by measures. <br>6. <strong>Analyst drillthrough patterns:</strong> from a variance row allow analysts to drill into preview artifact, schedule rows, and original evidence payload via evidenceRef links (access-controlled). </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Testing strategy & exhaustive CI / golden parity matrix</strong><br>1. <strong>Unit tests:</strong> canonicalization (text & numeric), <code>policyHash</code> parity, rounding and residual absorption determinism, per-method depreciation math (SL, DDB, SYD, UnitsOfProduction), edge-case handling (zero life, negative salvage), tie-breaker deterministic behavior. <br>2. <strong>Integration tests:</strong> end-to-end pipelines ingest→compute→preview→generateExport with canonical fixtures across currencies, disposals, revaluations, and complex addition scenarios. <br>3. <strong>Golden parity tests:</strong> canonical fixtures with fixed <code>runId</code>/<code>policyHash</code> that assert <code>runHash</code>, <code>previewHash</code>, and <code>exportChecksum</code> match expected values. Golden diffs block merges and require migration manifest and approvals for regulated domains. <br>4. <strong>Property tests:</strong> invariants such as row-order invariance, header permutation invariance, sampling reproducibility for previews, cross-locale numeric parsing, and idempotency for apply/revert workflows. <br>5. <strong>Performance & load tests:</strong> schedule computations for 1k, 10k, 100k asset fleets; preview latency for cohorts of 100/500/1000 rows; ingest throughput tests for large AP feeds. <br>6. <strong>Security & static analysis:</strong> ensure no plaintext secrets, ephemeral token pattern enforcement, and data leakage scanning for PII exposures in logs or analytics artifacts. <br>7. <strong>CI gating & release policies:</strong> failing golden or property tests block merges; migrations that change behavior require migration manifest and two-person approvals for regulated outputs. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Observability, auditing, SLOs & incident runbooks</strong><br>1. <strong>Mandatory audit events:</strong> <code>fa.asset.ingest</code>, <code>fa.capex.ingest</code>, <code>fa.policy.loaded</code>, <code>fa.depn.run.built</code>, <code>fa.depn.preview</code>, <code>fa.je.suggested</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start/complete/fail</code>, <code>fa.je.revert</code>, <code>fa.recon.report.generated</code>, <code>fa.disposal.suggested</code>, <code>fa.policy.migration</code>. Each audit row includes <code>correlationId</code>, <code>evidenceRefs</code>, <code>runHash</code> or <code>exportChecksum</code>, <code>operatorId</code>, and <code>paramsHash</code>. <br>2. <strong>Evidence store conventions:</strong> append-only, immutable writes for regulated artifacts with <code>createdTs</code>, <code>checksum</code>, <code>retentionPolicy</code>, and <code>legalTags</code>. Access requires approvals and generates <code>chainOfCustody</code> audit entries with actor, action, and timestamp. <br>3. <strong>Key metrics & SLOs:</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;a. <code>PlanBuildLatencyP50</code> target < 200ms for small plans. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. <code>PreviewLatencyP50</code> target < 2s for <= 500 rows. <br>&nbsp;&nbsp;&nbsp;&nbsp;c. <code>ApplySuccessRate</code> target > 99% in <code>create_export</code> mode. <br>&nbsp;&nbsp;&nbsp;&nbsp;d. <code>GoldenParityFailureRate</code> must be 0 in protected branches. <br>4. <strong>Telemetry tags:</strong> plan/run records include <code>runId</code>, <code>policyHash</code>, <code>ingestChecksum</code>, <code>operatorId</code>, <code>environment</code> to facilitate triage. <br>5. <strong>Parity verification job:</strong> daily job recomputes <code>runHash</code> and <code>reportHash</code> for stored artifacts and emits <code>verify.parity.failed</code> on mismatch. <br>6. <strong>Incident triage runbook (explicit):</strong> <br>a) capture <code>correlationId</code> and <code>runId</code> immediately; <br>b) retrieve <code>depreciationRunManifest</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>policySnapshot</code>, and <code>previewArtifact</code> via <code>evidenceRefs</code>; <br>c) inspect <code>issues[]</code> for parsing or mapping errors; <br>d) if posted exports present fetch <code>applyDescriptor</code> and attempt <code>RevertJEs</code>; <br>e) if automated revert impossible assemble <code>forensic_manifest</code> and escalate to GL team with evidence bundle. Each step creates audit rows. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Failure modes, mitigation & operator runbooks (exhaustive)</strong><br><strong>Common faults & remediation recipes:</strong><br>1. <strong>Invalid ingest manifest or malformed rows (<code>fa.asset.ingest.invalid</code>):</strong> capture <code>correlationId</code>, download ingestManifest and raw evidence, run header-mapping fixer, correct source, and re-ingest with <code>correctionOf</code> referencing prior <code>sourceFingerprint</code>. <br>2. <strong>Spikes in unmapped capex items:</strong> generate <code>mappingSuggestions</code> using historical co-occurrence and alias similarity, rank by <code>Occurrences</code> and <code>ExampleAmount</code>, present to owners, accept suggestions via bulk workflows, then <code>RefreshMapping()</code> and re-run preview. <br>3. <strong>JE export rejected by GL loader:</strong> run schema validation, simulate import into test GL, update <code>exportSpec</code> (e.g., date formats/sign conventions), regenerate export and optionally re-post after revert if direct post occurred. <br>4. <strong>Post-apply mismatches discovered:</strong> gather <code>applyDescriptor</code> and <code>recon_report</code>; attempt <code>RevertJEs</code> automatically; if revert fails assemble forensic pack and open incident, escalate to compliance and GL teams with <code>forensic_manifest</code> containing evidenceRefs. <br>5. <strong>Unauthorized policy usage:</strong> if a run used an unapproved <code>policyHash</code> abort apply, log <code>fa.policy.unauthorized_use</code>, notify compliance, and require migration manifest for retroactive acceptance. <br><strong>Emergency rollback plan:</strong> if hot-swap of policy caused material adverse effects, perform atomic pointer swap back to prior <code>policyHash</code>, run smoke-preview comparisons and if parity restored, notify stakeholders and run targeted reconciliation. Document all steps in <code>policy.hotSwap.auditChain</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Migration manifest & policy-change governance — required fields & process</strong><br><strong>Minimal required manifest fields:</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (planId, cohort sizes, KPIs), <code>rollbackPlan</code> (snapshot refs, revert steps), <code>approvals[]</code> (ownerIds & timestamps), and <code>testMatrix</code> (unit/integration/golden tests). <br><strong>Process:</strong> <br>1. Draft migration manifest describing expected semantic effect; attach sample fixtures and golden expectations. <br>2. Execute canary plan on small cohort and monitor KPIs (<code>DepnExpenseDeltaPct</code>, <code>RunParity</code>, <code>SuggestionAcceptanceRate</code>) over at least two cycles. <br>3. If KPIs within thresholds and approvals captured, promote policy snapshot to production and persist migration manifest; if not, rollback and record findings. <br>4. For regulated GL ranges require compliance signature in <code>approvals[]</code> and schedule a controlled rollout with additional monitoring. <br>5. Persist migration manifest and canary results as evidence. Emit <code>fa.policy.migration.completed</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Artifact naming, checksums & storage conventions</strong><br>1. <code>assetIngestManifest</code>: <code>asset_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br>2. <code>capexIngestManifest</code>: <code>capex_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br>3. <code>policySnapshot</code>: <code>fa_policy_&lt;policyHash&gt;.json</code>. <br>4. <code>depreciationPreview</code>: <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> (contains <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>). <br>5. <code>jeExport</code>: <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code> and <code>export_manifest.json</code>. <br>6. <code>applyDescriptor</code>: <code>apply_&lt;applyId&gt;.json</code> persisted prior to mutative actions. <br>7. <code>recon_report</code>: <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code>. <br><strong>Checksum & canonicalization policy:</strong> use sha256 over canonicalized payloads and record <code>checksumAlgorithm</code> in manifests; manifest canonicalization must match CI golden fixture recipes. Store artifacts in evidence store with <code>retentionPolicy</code> and <code>legalTags</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Performance, scale & architectural guidance</strong><br>1. <strong>Scale tiers & recommendations:</strong> <br>&nbsp;&nbsp;&nbsp;&nbsp;a. PQ pilot: up to a few thousand assets with careful optimization. <br>&nbsp;&nbsp;&nbsp;&nbsp;b. Backend/warehouse: recommended for 10k+ assets. Use parallel worker sharding by <code>assetId</code> ranges or <code>category</code>. <br>2. <strong>Parallel model:</strong> compute per-asset schedules independently and aggregate; deterministic ordering within shards required to preserve hashing parity. <br>3. <strong>Incremental computation:</strong> support incremental recomputation triggered by changed <code>assetRevisionId</code> to avoid full-run compute for minor changes. <br>4. <strong>Storage choices:</strong> object store for large artifacts; columnar warehouse for aggregates and analytics; small manifest metadata in DB for fast lookups. <br>5. <strong>Autoscaling & scheduled batch windows:</strong> autoscale compute for scheduled close runs; monitor queue depth and latency metrics for proactive scaling. <br>6. <strong>Monitoring & alerting:</strong> set SLO-based alerts on <code>PlanBuildLatency</code>, <code>PreviewLatency</code>, <code>ApplyFailureRate</code>, and <code>GoldenParityFailures</code>. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Operator CLI patterns & explicit examples (operational commands described)</strong><br>1. <code>fa.build-run --period 2026-01 --policyRef fa_policy_20260101 --operator alice</code> → builds run, emits <code>fa.depn.run.built</code>, returns <code>runId</code>. <br>2. <code>fa.preview --run &lt;runId&gt; --sample 500 --operator alice</code> → produces <code>previewRef</code> and <code>fa.depn.preview</code>. <br>3. <code>fa.suggest-je --preview &lt;previewRef&gt; --operator alice</code> → creates suggested JEs and <code>jePreviewHash</code>. <br>4. <code>fa.generate-je --preview &lt;previewRef&gt; --accept &lt;suggestionIds&gt; --exportSpec ERP_JE_v1 --operator alice</code> → writes <code>FA_JE_Export_&lt;runId&gt;.csv</code> and emits <code>fa.je.exported</code>. <br>5. <code>fa.apply --export &lt;exportPath&gt; --mode post_direct --operator alice --approvalId ap-321 --approver bob</code> → enforces ephemeral token issuance and two-person approval and emits <code>fa.je.apply.*</code>. <br>6. <code>fa.revert --applyId &lt;applyId&gt; --operator alice</code> → triggered automated revert; logs <code>fa.je.revert</code>. <br>7. <code>fa.policy.migrate --manifest &lt;manifestRef&gt; --operator alice</code> → executes migration canary per manifest and logs outcomes. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Acceptance criteria & release gates — strict checklist</strong><br>1. Unit tests confirm deterministic canonicalization, rounding/residual absorption, method math parity across locales. <br>2. Integration tests validate ingest→compute→preview→export flows on canonical fixtures and expected artifact checksums. <br>3. Golden parity tests ensure <code>runHash</code>, <code>previewHash</code>, and <code>exportChecksum</code> match expected values; failing golden tests block merges. <br>4. Migration manifest required for any semantic policy change; canary executed and KPIs within thresholds with approvals recorded before production promotion. <br>5. Governance: direct posting requires two-person approval and ephemeral token issuance; audit completeness required for all mutative steps. <br>6. Evidence & retention enforced for regulated artifacts; periodic parity verification jobs scheduled. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Appendices — templates, checklists & supporting artifacts (conceptual)</strong><br><strong>Appendix A — migrationManifest template fields (conceptual):</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (planId, cohortSizes, KPIs), <code>rollbackPlan</code> (snapshot refs, revert steps), <code>approvals[]</code>, <code>testMatrix</code>. <br><strong>Appendix B — run verification checklist:</strong> <br>1. Confirm <code>policyHash</code> equals approved policy snapshot. <br>2. Verify presence of <code>assetIngestChecksum</code> and <code>capexIngestChecksum</code> in <code>depreciationRunManifest</code>. <br>3. Recompute <code>runHash</code> locally using canonicalization recipe; compare to persisted <code>runHash</code>. <br>4. Confirm <code>previewHash</code> parity for analyst previews. <br>5. Verify <code>jePreviewArtifact</code> balanced and validated against <code>jeTemplateSpec</code>. <br><strong>Appendix C — security & privacy checklist:</strong> <br>1. Tokenize PII on analyst surfaces; retrieve raw only via approval workflow. <br>2. Enforce ephemeral tokens for GL posting; never log token material. <br>3. Ensure static analysis checks for plaintext secrets in repo. <br>4. Evidence access requests produce chain-of-custody audit rows and require specific approvals. </td></tr><tr><td data-label="Project 005 — Fixed Asset Register and Depreciation Specification"> <strong>Closing operational note & available follow-ups:</strong> This ultra-detailed Project 005 canonical specification provides exhaustive per-row narratives, deterministic canonicalization recipes, function-level contracts, operational runbooks, conceptual PQ guidance for pilots, conceptual DAX measures for dashboards, worked examples for edge cases, exhaustive CI/golden parity testing strategies, migration/governance requirements, and performance guidance. If you require any focused artifacts produced next (choose one or more): <br>• Formal JSON Schema for <code>AssetRow</code>, <code>DepreciationScheduleRow</code>, <code>applyDescriptor</code> and <code>recon_report</code> with exact field ordering for canonical hashing. <br>• A set of canonical CSV test fixtures and expected sha256 checksums (<code>policyHash</code>, <code>runHash</code>, <code>previewHash</code>) for CI golden tests. <br>• A detailed Power Query canonicalization recipe expressed as step-by-step PQ transformations with expected intermediate outputs (for pilot teams). <br>• A compact runbook PDF summarizing triage steps and commands for operations teams. <br>Specify the desired artifact(s) and they will be produced as focused follow-ups. </td></tr></tbody></table></div><div class="row-count">Rows: 18</div></div><div class="table-caption" id="Table3" data-table="Docu_0185_03" style="margin-top:2mm;margin-left:3mm;"><strong>Table 3</strong></div>
<div class="table-wrapper" data-table-id="table-3"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modIngest — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modIngest — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Scope & purpose (concise):</strong> This single artifact is a comprehensive implementation blueprint for <code>modIngest</code> within Project 005. It prescribes forensic per-row semantics, deterministic canonicalization and hashing rules, complete function contracts for every ingest surface (inputs, outputs, responsibilities, invariants, failure modes, telemetry, CI tests and operator runbooks), extended worked examples and edge-case remediation tactics, conceptual Power Query (PQ) pilot guidance and anti-patterns, conceptual DAX reporting patterns for triage and reconciliation, exhaustive testing and golden-parity strategy, evidence & audit conventions, migration governance, and operator runbooks. All numbered lists use <code>&lt;br&gt;</code> line breaks. This document intentionally excludes executable code snippets and focuses on deterministic behavior, contracts and operational safety. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>I. Per-row canonical narratives — field-level forensic semantics & invariants</strong> <br> <strong>AssetRow (immutable canonical snapshot):</strong> The <code>AssetRow</code> is the canonical evidence row produced by ingest for each asset record. It must be evidence-first (raw payload linkable), provenance rich, and designed for deterministic replay. Required fields, semantic rules and invariants: <br> 1. <strong>Primary identifier (<code>assetId</code>)</strong> — deterministic anchor used across the pipeline: prefer vendor/ERP asset tag when validated; otherwise compute <code>assetId = sha256(canonicalAssetKey)</code> where <code>canonicalAssetKey</code> is the canonical concatenation (exact field order) of canonical tokens for <code>assetTag</code>, <code>description</code>, <code>acquisitionDateISO</code> and <code>canonicalVersion</code>. Persist <code>assetIdRecipe</code> describing inputs and recipeVersion. <br> 2. <strong>Raw vs canonical separation</strong> — always persist source raw values in <code>rawFields</code> for forensic replay; produce canonical tokens used for matching and hashing. <code>rawFields</code> contains original string, byte offsets, sheet/range and original cell formatting hints when available. <br> 3. <strong>Text canonicalization (<code>assetTagToken</code>, <code>descriptionToken</code>)</strong> — text normalization pipeline: Unicode NFKC → Trim → Collapse internal whitespace to single U+0020 → normalize punctuation mapping per <code>canonicalVersion</code> → locale-aware casefold (explicit handling for Turkish dotted/dotless i) → optional deterministic diacritic removal when policy requires. Persist <code>textNormalizationRecipe</code> and <code>locale</code> used. <br> 4. <strong>Monetary canonicalization (<code>acquisitionCost</code>, <code>amountMinorUnits</code>, <code>scale</code>, <code>currency</code>)</strong> — store canonical decimal string zero-padded to <code>scale</code>; compute integer <code>amountMinorUnits</code> = amount × 10^scale using string-digit arithmetic; preserve <code>preRoundedValue</code> if source includes higher precision. Record <code>originalSignRepresentation</code> and <code>signConvention</code> if sourced from AP extracts. <br> 5. <strong>Date canonicalization (<code>acquisitionDate</code>, <code>inServiceDate</code>)</strong> — canonical ISO <code>YYYY-MM-DD</code>. For ambiguous inputs record <code>parseAttemptLogs</code> and chosen grammar. If time-of-day required, store ISO 8601 UTC normalized timestamp and <code>timezoneNormalization</code> metadata. <br> 6. <strong>Categorization & mapping (<code>category</code>, <code>location</code>, <code>costCenter</code>)</strong> — map free text to canonical dictionaries; always persist both <code>rawValue</code> and <code>canonicalValue</code>; if mapping fails set <code>mappingStatus = Unclassified</code> and include in <code>manifest.unmappedCategories[]</code>. <br> 7. <strong>Component linking (<code>componentOf</code>, <code>componentRole</code>, <code>componentCapitalizationTreatment</code>)</strong> — when present store parent <code>assetId</code>; verify parent existence or persist <code>unresolvedParent</code> candidate signals; component treatment must reference <code>policySnapshot.componentRulesRef</code>. <br> 8. <strong>Overrides & governance (<code>usefulLifeSource</code>, <code>overrideBy</code>, <code>overrideTs</code>, <code>approvalRef</code>)</strong> — any analyst or system override must include actor, timestamp and an approval reference if policy mandates. <br> 9. <strong>Data quality flags & triage (<code>dqFlags[]</code>, <code>issues[]</code>)</strong> — structured diagnostic entries enumerating issues (e.g., <code>MISSING_COST</code>, <code>AMBIG_DATE</code>, <code>CURRENCY_MISMATCH</code>, <code>SUSPECT_TEXT</code>) with severity and remediation hints. <br> 10. <strong>Checksums & canonical identity (<code>assetRowChecksum</code>)</strong> — <code>sha256:</code> over canonicalized serialization (exact field order). Manifest must include <code>canonicalVersion</code> and <code>fieldOrder</code>. Exclude transient fields from checksums unless policy explicitly requires them. <br> 11. <strong>Immutability & correction</strong> — persisted <code>AssetRow</code> artifacts are immutable; corrections create <code>assetRevision</code> artifacts linked by <code>correctionOf</code> and maintain full lineage. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>CapexTransactionRow (canonical transaction snapshot for mapping):</strong> Capex rows are evidence entities for transactions (invoices, AP lines) used by matching and capitalization heuristics. Required semantics and fields: <br> 1. <strong>Deterministic row id (<code>capexRowId</code>)</strong> — derived <code>sha256(sourceFingerprint | fileOffset | canonicalTokens)</code>; persist <code>sourceFingerprint</code> used. <br> 2. <strong>Amount & sign handling</strong> — store canonical decimal string, <code>amountMinorUnits</code>, <code>scale</code> and <code>originalSignRepresentation</code>. If sign is specified via Debit/Credit column, persist <code>signConvention</code> and <code>originalDebitCredit</code>. <br> 3. <strong>Reference & descriptive fields</strong> — <code>invoiceRef</code>, <code>poNumber</code>, <code>vendorRaw</code>, <code>lineItemDescription</code> stored raw and tokenized. Persist <code>vendorCanonical</code> and <code>vendorMappingConfidence</code>. <br> 4. <strong>Structured match signals (<code>matchSignals[]</code>)</strong> — deterministic signals such as <code>invoiceRefExact</code>, <code>assetTagInDescription</code>, <code>vendorAssetCooccurrence</code>, <code>costCenterHint</code> each with <code>signalStrength</code> (0..1) and <code>evidenceRef</code>. <br> 5. <strong>Candidate list (<code>candidateList[]</code>)</strong> — deterministic candidate list produced by matching logic; each candidate entry includes <code>assetId</code>, <code>candidateScore</code>, <code>candidateRank</code>, and <code>matchTrace</code>; sorted by <code>candidateScore</code> desc then tie-break lexicographically by <code>assetId</code>. Persist <code>policySnapshot.matchingWeightsRef</code>. <br> 6. <strong>DQ & triage (<code>capexDQ</code>)</strong> — flags such as <code>MISSING_INVOICE_REF</code>, <code>CURRENCY_MISMATCH</code>, <code>AMOUNT_ZERO</code>, <code>SUSPICIOUS_VENDOR</code>; high-value unmapped transactions are surfaced with <code>priority</code> and <code>analystQueueRef</code>. <br> 7. <strong>Checksums (<code>capexRowChecksum</code>)</strong> — <code>sha256:</code> over canonicalized transaction fields excluding candidateScore to decouple evidence identity from heuristic weight changes. <br> 8. <strong>Raw evidence pointer (<code>rawPayloadRef</code>)</strong> — file path + offset or workbook sheet/range with raw checksum and evidence store pointer. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Ingest Manifest (file-level canonical artifact — authoritative snapshot):</strong> The manifest documents the canonicalization of a source file and is persisted atomically as immutable evidence. Minimum manifest contents and behaviors: <br> 1. <strong><code>sourceFingerprint</code></strong> — sha256 over normalized bytes (UTF-8 normalization, BOM handling, newline normalization to <code>\n</code>). Manifest records the exact byte normalization recipe. <br> 2. <strong><code>headerMap</code> & <code>headerMapResolution</code></strong> — mapping from raw headers to canonical names and recorded resolution decisions (exact/synonym/fuzzy), plus thresholds used for fuzzing. <br> 3. <strong>Row counts & deterministic sample</strong> — <code>rowsCount</code>, <code>rowsFailedCount</code>, <code>rowsWithWarnings</code>, <code>rowsSample[]</code> where sample selection is seeded by <code>sourceFingerprint</code> for deterministic sampling. <br> 4. <strong>Checksums & provenance</strong> — <code>ingestChecksum</code> computed over canonicalized staging artifact, <code>canonicalVersion</code>, <code>ingestToolVersion</code>, <code>operatorId</code>, <code>createdTs</code>. <br> 5. <strong>Top-level issues & remediation hints</strong> — <code>issues[]</code> containing <code>issueCode</code>, <code>severity</code>, <code>rowRefs[]</code>, and suggestions. <br> 6. <strong>Correction linkage</strong> — <code>correctionOf</code> optional pointer for reingests; manifests are append-only and never mutated. <br> 7. <strong>Atomic persist & evidenceRef</strong> — write manifest atomically to Evidence Store and return <code>manifestEvidenceRef</code>; include <code>retentionPolicy</code> and <code>legalTags</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>II. Canonicalization & hashing recipes — absolute rules for parity</strong> <br> 1. <strong>Unicode & text normalization</strong> — canonical tokens use Unicode NFKC normalization by default. If host cannot perform NFKC, the fallback is a documented deterministic mapping table included in repo; differences must be recorded in manifest. All tokens are trimmed, internal whitespace collapsed to single U+0020, and punctuation normalized per <code>canonicalVersion</code> to stable mappings. Diacritic stripping is optional and governed by <code>policySnapshot</code>. <br> 2. <strong>Separator escaping</strong> — canonical field serialization uses <code>|</code> as separator; embedded <code>|</code> must be replaced by explicit escape token (e.g., <code>\|</code> or versioned token) before serialization. Escape token itself is defined by <code>canonicalVersion</code>. <br> 3. <strong>Numeric canonicalization</strong> — all canonical arithmetic uses integer <code>amountMinorUnits</code> or string-digit arithmetic to avoid float drift. For hashing store decimal string zero-padded to <code>scale</code>. Preserve <code>preRoundedValue</code> for audit and deterministic schedule math. <br> 4. <strong>Date canonicalization</strong> — <code>YYYY-MM-DD</code> for date only; ISO 8601 UTC for timestamp fields. Ambiguous parses must append <code>parseAttemptLogs</code>. <br> 5. <strong>Hash serialization order</strong> — every artifact specifies exact <code>fieldOrder</code> used to build canonical strings. Hash compute steps: canonical serialization (field order + escaped separators) → UTF-8 encoding → SHA-256 hex lowercase → prefix <code>sha256:</code>. Store <code>canonicalVersion</code> alongside hash. <br> 6. <strong>Deterministic tie-breakers</strong> — when algorithms require tie-breaking, use deterministic sequence: (1) higher absolute <code>preRounded</code> amount; (2) lexicographically smallest <code>assetId</code>; (3) seeded deterministic pseudo-random derived from <code>runHash</code>. Document tie-break step in manifests. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>III. Function-level contract set — full, exhaustive</strong> <br> <strong>Global function contract notes:</strong> <br> 1. All functions must declare deterministic inputs and outputs; side effects must be idempotent when re-run with identical inputs and idempotency token where applicable. <br> 2. All error conditions emitted as structured <code>issues[]</code> entries and audit events. <br> 3. All persisted artifacts to Evidence Store must include <code>canonicalVersion</code> and <code>checksum</code> and be atomically committed. <br> 4. All functions must emit telemetry counters and <code>fa.*</code> audit events for SLO monitoring and postmortem analysis. <br> 5. Unit tests for all primitives and golden parity tests for end-to-end flows are required. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: IngestAssetFile(sourcePath, options)</strong> <br> <strong>Summary:</strong> Top-level controllable ingest pipeline for asset master files; streams rows, canonicalizes fields, validates, persists canonical staging artifact and manifest. <br> <strong>Inputs:</strong> <code>sourcePath</code> (URI or file path), <code>options</code> dictionary: <code>mode</code> (<code>strict|tolerant</code>), <code>defaultCurrency</code>, optional <code>headerMap</code>, <code>maxSampleRows</code>, <code>canonicalVersion</code>, <code>operatorId</code>, <code>retainRaw:Boolean</code>, <code>policySnapshotRef</code> optional. <br> <strong>Outputs:</strong> persisted canonical artifact and <code>assetIngestManifest</code> Evidence Ref; emitted audit <code>fa.asset.ingest.start/completed/partial/failed</code>. <br> <strong>Detailed responsibilities & stepwise algorithm:</strong> <br> 1. <strong>File acquisition & byte normalization:</strong> stream source bytes, normalize to UTF-8 with newline <code>\n</code>, remove or record BOM per recipe, compute <code>sourceFingerprint = sha256(normalizedBytes)</code>, persist raw evidence <code>rawAsset_&lt;sourceFingerprint&gt;</code> when <code>retainRaw</code> true. <br> 2. <strong>Format detection & parser selection:</strong> detect CSV, TSV, Excel (XLS/XLSX), NDJSON, or API JSON; for Excel use chunked streaming (OpenXML streaming reader or buffered COM <code>UsedRange</code> windows). <br> 3. <strong>Header map resolution:</strong> validate provided headerMap or call <code>BuildHeaderMap</code> (synonym tables + fuzzy fallback) and persist resolution rationale into manifest. <br> 4. <strong>Row streaming canonicalization:</strong> for each input row produce <code>rawPayloadRef</code>, generate <code>rawFields</code>, apply <code>NormalizeText</code> to tokens, <code>CanonicalDecimal</code> to monetary fields (preserve preRounded), <code>FormatDateISO</code> to date fields, compute derived fields (compute deterministic <code>assetId</code> when missing) and compute <code>assetRowChecksum = sha256(canonicalRowString)</code>. Write canonical rows to staging artifact incrementally and maintain streaming hash to compute <code>ingestChecksum</code> without full in-memory artifact. <br> 5. <strong>Validation & DQ:</strong> call <code>ValidateRowAgainstSchema</code>; in <code>strict</code> mode abort on first critical error and persist a failure manifest; in <code>tolerant</code> mode collect <code>issues[]</code> and continue. <br> 6. <strong>Finalize & atomic persist:</strong> complete streaming hash, atomically commit canonical artifact to Evidence Store, build <code>assetIngestManifest</code> with <code>rowsCount</code>, deterministic <code>rowsSample[]</code> (seeded by <code>sourceFingerprint</code>), <code>issues[]</code>, <code>ingestChecksum</code>, <code>canonicalVersion</code>, <code>operatorId</code>, and <code>policyHash</code> if policy used. Persist manifest using <code>EmitIngestManifest</code>, emit <code>fa.asset.ingest.completed</code>. <br> <strong>Invariants:</strong> identical inputs + options + canonicalVersion must produce identical manifests and row checksums. <br> <strong>Failure modes & remediation:</strong> malformed encoding → persist invalid manifest and raw evidence; IO errors → <code>RetryIOWithBackoff</code> then forensic bundle if persistent; missing critical headers in strict mode → abort with manifest and sample rows. <br> <strong>Observability:</strong> metrics: <code>asset.ingest.rowsParsed</code>, <code>asset.ingest.rowsFailed</code>, <code>asset.ingest.latencyMs</code>, telemetry tags: <code>sourceFingerprint</code>, <code>canonicalVersion</code>. <br> <strong>CI tests:</strong> header synonym permutations, encoding matrix (BOM/UTF-16/ANSI), decimal locale parity, deterministic <code>assetIngestManifest</code> golden fixtures. <br> <strong>Operator runbook (condensed):</strong> on partial ingest inspect manifest <code>issues[]</code>, correct headerMap or source file and re-run with <code>correctionOf</code> linking <code>sourceFingerprint</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: IngestCapexFile(sourcePath, options)</strong> <br> <strong>Summary:</strong> Capex/AP ingest orchestrator: canonicalizes transaction rows, normalizes sign semantics, precomputes or routes candidate mapping, emits <code>capexIngestManifest</code> and <code>candidateMappingIndex</code>. <br> <strong>Inputs:</strong> <code>sourcePath</code>, <code>options</code>: <code>defaultCurrency</code>, <code>signPolicy</code> (<code>auto|explicit</code>), <code>vendorDictionaryRef</code>, optional <code>headerMap</code>, <code>canonicalVersion</code>, <code>operatorId</code>, <code>policySnapshotRef</code>. <br> <strong>Outputs:</strong> <code>capexIngestManifest</code> persisted, canonical capex staging artifact, <code>candidateMappingIndex</code> persisted, <code>fa.capex.ingest.*</code> audit events. <br> <strong>Responsibilities & stepwise algorithm:</strong> <br> 1. <strong>Source fingerprinting:</strong> byte normalize, compute <code>sourceFingerprint</code>, and persist <code>rawPayload</code> to Evidence Store. <br> 2. <strong>Header map & parsing</strong> — similar to asset ingest. <br> 3. <strong>Sign convention detection:</strong> if <code>Debit/Credit</code> columns present map deterministically to signed <code>amount</code>; if ambiguous use <code>options.signPolicy</code>; persist <code>originalSignRepresentation</code> and <code>signConvention</code>. <br> 4. <strong>Numeric parsing:</strong> <code>CanonicalDecimal</code> to compute <code>amountMinorUnits</code> and <code>decimalString</code> while preserving <code>preRoundedValue</code>. <br> 5. <strong>Candidate extraction:</strong> call <code>FindAssetCandidates</code> to produce deterministic <code>candidateList[]</code> with <code>matchSignals[]</code>; persist <code>candidateMappingIndex</code> and <code>matchingWeightsRef</code>. <br> 6. <strong>Flagging & triage:</strong> determine <code>capitalCandidate</code> per <code>policySnapshot.capitalizationThreshold</code> and category heuristics; set <code>capexDQ</code> flags for missing invoiceRef or currency ambiguity. <br> 7. <strong>Finalize & persist:</strong> compute staging artifact <code>ingestChecksum</code>, persist <code>capexIngestManifest</code> with <code>unmappedCount</code>, <code>ambiguousCount</code>, <code>candidateAverageScore</code>, emit <code>fa.capex.ingest.completed</code>. <br> <strong>Invariants:</strong> candidate ordering deterministic given identical <code>policySnapshot.matchingWeightsRef</code>. <br> <strong>Failure modes & remediation:</strong> ambiguous vendor names or missing invoiceRef lower candidate confidence and route high-value items to analyst queue; currency mismatches require FX normalization upstream or analyst review. <br> <strong>Telemetry & CI tests:</strong> sign convention permutations, OCR noise in descriptions, candidate scoring fixtures; performance scaling tests for large AP feeds. <br> <strong>Operator runbook:</strong> analysts use candidateMappingIndex to accept/reject mappings and issue mapping corrections which produce <code>mappingCorrection</code> artifacts. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: BuildHeaderMap(rawHeaders, headerSynonyms, options) As Dictionary</strong> <br> <strong>Summary:</strong> Deterministic mapping from raw headers to canonical fields using precise synonyms and deterministic fuzzy fallback logic. <br> <strong>Inputs:</strong> <code>rawHeaders</code> array, <code>headerSynonyms</code> (canonicalName → synonyms[]), <code>options</code>: <code>threshold</code>, <code>locale</code>, <code>canonicalVersion</code>. <br> <strong>Outputs:</strong> <code>headerMap</code> canonicalName → columnIndex and <code>unmappedHeaders[]</code> for manifest <code>issues</code>. <br> <strong>Algorithm & responsibilities:</strong> <br> 1. Normalize header tokens using <code>NormalizeText</code> with <code>escapeSeparators=true</code>. <br> 2. Attempt exact match against synonyms first. <br> 3. If none found compute deterministic token overlap score and accept highest scoring candidate if score ≥ <code>threshold</code>. <br> 4. Tie-break by lexicographic order of canonical names. <br> 5. Persist <code>headerMapResolution[]</code> entries to allow deterministic replay. <br> <strong>Failure modes:</strong> missing critical headers (strict mode) cause ingest abort; tolerant mode logs <code>issues[]</code>. <br> <strong>CI tests:</strong> header order permutations, punctuation/abbreviation forms, international header variants. <br> <strong>VBA notes:</strong> implement mapping using stable in-repo lookup tables and deterministic tokenization; avoid OS-dependent casing/locale calls. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: NormalizeText(rawText, options) As String</strong> <br> <strong>Summary:</strong> Deterministic Unicode-safe text canonicalizer used for matching and hashing. <br> <strong>Inputs:</strong> <code>rawText</code>, <code>options</code>: <code>{stripDiacritics:Boolean, locale, escapeSeparators:Boolean, canonicalVersion}</code>. <br> <strong>Outputs:</strong> canonical token string. <br> <strong>Responsibilities & deterministic steps:</strong> <br> 1. Apply Unicode NFKC normalization (or documented fallback mapping). <br> 2. Trim leading/trailing whitespace; collapse contiguous internal whitespace into single U+0020. <br> 3. Optionally strip diacritics using deterministic mapping table versioned by <code>canonicalVersion</code>. <br> 4. Locale-aware casefolding (explicit Turkish dotted/dotless i handling when <code>locale</code> = "tr"). <br> 5. Escape canonical serialization separators (<code>|</code>) if <code>escapeSeparators==true</code>. <br> <strong>CI tests:</strong> NFKC test vectors, Turkish <code>i</code> testcases, separator escaping. <br> <strong>VBA notes:</strong> store diacritic tables locally and avoid OS globalization functions which vary by host. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: CanonicalDecimal(rawAmount, scale, sourceCulture, issues) As Dictionary</strong> <br> <strong>Summary:</strong> Deterministic parsing of numeric strings into canonical decimal string and integer minor-units using string digit arithmetic. <br> <strong>Inputs:</strong> <code>rawAmount</code> string, <code>scale</code> integer, <code>sourceCulture</code> hint, <code>issues</code> collector. <br> <strong>Outputs:</strong> <code>{decimalString, amountMinorUnits, scale, parseDiagnostics}</code>. <br> <strong>Algorithm & responsibilities:</strong> <br> 1. Preserve <code>rawAmount</code> in <code>parseDiagnostics</code>. <br> 2. Determine thousand and decimal separators from <code>sourceCulture</code> or heuristics. <br> 3. Remove thousand separators; normalize decimal separator to <code>.</code>; handle parentheses accounting negatives deterministically. <br> 4. Normalize negative-zero to canonical <code>0</code>. <br> 5. Compute <code>amountMinorUnits</code> by concatenating integer and fractional parts padded/truncated to <code>scale</code> and convert to integer using safe big-integer handling or fallback to string storage if overflow. <br> 6. Append parse diagnostics for ambiguous formats; add <code>issues[]</code> when heuristics used. <br> <strong>Failure modes & remediation:</strong> ambiguous locale parsing recorded in <code>issues[]</code>; operator may supply <code>sourceCulture</code> or manual correction. <br> <strong>CI tests:</strong> cross-locale numeric fixtures, thousands/decimal separator permutations, negative-zero, astronomical numbers. <br> <strong>VBA notes:</strong> implement string digits math; avoid floating conversions. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: FormatDateISO(rawDate, parseHints, issues) As Variant</strong> <br> <strong>Summary:</strong> Deterministic date parse to <code>YYYY-MM-DD</code>. <br> <strong>Inputs:</strong> <code>rawDate</code>, <code>parseHints</code>: <code>{dateOrder: &quot;DMY&quot;|&quot;MDY&quot;|&quot;YMD&quot;, defaultCentury}</code>, <code>issues</code>. <br> <strong>Outputs:</strong> canonical date string or <code>Null</code> with <code>parseAttemptLogs</code>. <br> <strong>Algorithm & responsibilities:</strong> <br> 1. Attempt strict ISO parse first. <br> 2. Tokenize on non-digit separators and apply <code>dateOrder</code> heuristics deterministically. <br> 3. Apply <code>defaultCentury</code> for two-digit years per policy. <br> 4. On ambiguity append <code>DATE_PARSE_AMBIG</code> and return <code>Null</code> for manual triage. <br> <strong>CI tests:</strong> ambiguous day/month pairs, two-digit year edge cases. <br> <strong>VBA notes:</strong> parse using integer extraction and <code>DateSerial</code> rather than locale-dependent functions. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: ComputeSHA256(canonicalString) As String</strong> <br> <strong>Summary:</strong> Compute <code>sha256:</code> prefixed lowercase hex checksum over UTF-8 bytes of canonical string. <br> <strong>Inputs:</strong> <code>canonicalString</code> (UTF-8 intended). <br> <strong>Outputs:</strong> <code>sha256:&lt;hex&gt;</code>. <br> <strong>Responsibilities:</strong> ensure explicit UTF-8 encoding before hashing; use OS crypto where available or a validated fallback. Always record <code>canonicalVersion</code> near the checksum. <br> <strong>CI tests:</strong> standard SHA256 test vectors. <br> <strong>VBA notes:</strong> use <code>ADODB.Stream</code> to force UTF-8 encoding before hashing. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: EmitIngestManifest(manifest, evidenceStoreClient) As String</strong> <br> <strong>Summary:</strong> Canonicalize manifest, compute <code>ingestChecksum</code>, persist manifest atomically, and return <code>evidenceRef</code>. <br> <strong>Inputs:</strong> canonical <code>manifest</code> (ordered fields), <code>evidenceStoreClient</code> interface supporting <code>UploadTemp</code> and <code>AtomicCommit</code>. <br> <strong>Outputs:</strong> persistent <code>manifestEvidenceRef</code>; emits <code>fa.asset.ingest.completed</code> or <code>fa.capex.ingest.completed</code>. <br> <strong>Responsibilities & steps:</strong> <br> 1. Canonicalize manifest JSON with exact field order. <br> 2. Compute <code>ingestChecksum = ComputeSHA256(canonicalManifest)</code>. <br> 3. Upload temp artifact then <code>AtomicCommit</code>. <br> 4. Emit audit event with <code>correlationId</code> and manifestEvidenceRef. <br> <strong>Failure & remediation:</strong> upload failures retried with exponential backoff; persistent failure creates local forensic bundle and <code>fa.asset.ingest.persist_fail</code>. <br> <strong>CI tests:</strong> manifest canonicalization parity and upload simulation. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: ValidateRowAgainstSchema(row, schema, mode, issues) As Boolean</strong> <br> <strong>Summary:</strong> Apply deterministic validation for types, required fields, enumerations and apply policy defaults when permitted. <br> <strong>Inputs:</strong> <code>row</code>, <code>schema</code> (field definitions, required flags, enumerations, ranges), <code>mode</code> (<code>strict|tolerant</code>), <code>issues</code>. <br> <strong>Outputs:</strong> boolean <code>isValid</code> and appended <code>issues[]</code>. <br> <strong>Responsibilities:</strong> <br> 1. Enforce required fields and deterministic default application (record <code>usefulLifeSource</code> when default applied). <br> 2. Check ranges and enumerations; emit deterministic issue codes. <br> 3. Behavior: strict mode aborts ingest on critical failures; tolerant mode continues and sets <code>dqFlags</code>. <br> <strong>CI tests:</strong> schema permutations, negative-life validation, idempotency replays. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: RetryIOWithBackoff(actionName, actionProc, maxRetries, backoffBaseMs, seed) As Boolean</strong> <br> <strong>Summary:</strong> Deterministic retry wrapper with exponential backoff and seeded jitter for reproducible testing. <br> <strong>Inputs:</strong> <code>actionProc</code> delegate, <code>maxRetries</code>, <code>backoffBaseMs</code>, <code>seed</code> for deterministic jitter. <br> <strong>Outputs:</strong> boolean success and audit logs <code>fa.asset.ingest.io_retry</code>. <br> <strong>Responsibilities:</strong> <br> 1. Deterministic jitter using seeded PRNG or HMAC-derived value. <br> 2. Delay = <code>backoffBaseMs * 2^(attempt-1) + jitter</code>. <br> 3. Log each attempt and emit telemetry. <br> <strong>VBA notes:</strong> avoid blocking UI threads in Excel; use background worker patterns. <br> <strong>CI tests:</strong> simulate transient IO failures and assert deterministic retry traces. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: FindAssetCandidates(capexRow, assetIndexRef, policySnapshot) As Variant</strong> <br> <strong>Summary:</strong> Deterministic candidate generation interface; ingest may precompute candidate lists via this function. <br> <strong>Inputs:</strong> <code>capexRow</code>, <code>assetIndexRef</code> (indexed asset evidenceRef), <code>policySnapshot</code> (matchingWeights). <br> <strong>Outputs:</strong> <code>candidateList[]</code> sorted deterministically, <code>candidateRowChecksum</code> excluding scores, <code>matchSignals[]</code>, <code>matchTrace</code>. <br> <strong>Responsibilities & details:</strong> <br> 1. Compute structured <code>matchSignals</code> (token overlaps, invoiceRef exact, vendor co-occurrence) and apply <code>policySnapshot.matchingWeights</code> to compute <code>candidateScores</code>. <br> 2. Sort by <code>candidateScore</code> desc then apply deterministic tie-break rules. <br> 3. Persist <code>candidateMappingIndex</code> with <code>matchingWeightsRef</code> to allow deterministic replay. <br> <strong>CI tests:</strong> seeded scoring reproducibility, noisy description (OCR) fixtures. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: LoadPolicySnapshot(policySource) As Dictionary</strong> <br> <strong>Summary:</strong> Validate and canonicalize policy artifacts into a <code>policySnapshot</code> and compute <code>policyHash</code>. <br> <strong>Inputs:</strong> <code>policySource</code> (workbook/JSON/parameter table). <br> <strong>Outputs:</strong> <code>policySnapshot</code> object, <code>policyManifest</code> persisted and <code>policyHash</code>. <br> <strong>Responsibilities:</strong> <br> 1. Validate schema and required fields. <br> 2. Canonicalize policy table (deterministic sorting, token normalization) and compute <code>policyHash = sha256(canonicalPolicyString)</code>. <br> 3. Persist <code>policyManifest</code> as evidence and emit <code>fa.policy.loaded{policyHash}</code>. <br> <strong>Governance note:</strong> promotion of policy snapshots requires <code>migrationManifest</code> for semantic changes. <br> <strong>CI tests:</strong> policyHash parity across runtimes. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: ComputeDepreciation(assetRows, capexRows, policySnapshot, params) As (DepreciationSchedule[], depreciationRunManifest)</strong> <br> <strong>Summary:</strong> Deterministic depreciation engine producing schedules, JE proposals and run manifest with <code>runHash</code> for parity. <br> <strong>Inputs:</strong> canonical <code>AssetRow[]</code>, canonical <code>CapexTransactionRow[]</code> (additions), <code>policySnapshot</code> (policyHash), <code>params</code>: <code>{periodStart, periodEnd, roundingScaleOverride?, toleranceThresholds}</code>. <br> <strong>Outputs:</strong> <code>DepreciationSchedule[]</code>, <code>ScheduledJEProposals[]</code>, <code>depreciationRunManifest</code> persisted with <code>runHash</code>, emitted <code>fa.depn.run.completed{runHash}</code>. <br> <strong>Detailed responsibilities & algorithmic steps:</strong> <br> 1. <strong>Capitalization decision chain:</strong> deterministic rules chain: invoiceRef exact match → assetTag in description → PO matching → vendor/costCenter co-occurrence → threshold tests; persist <code>capitalizationDecision</code> per capexRow with evidenceRefs and rationale. <br> 2. <strong>Asset revision & addition handling:</strong> if a capexRow maps to an existing asset apply <code>additionTreatment</code> (<code>append_cost</code>, <code>create_component</code>, <code>restart_depn</code>) per <code>policySnapshot</code>; create <code>assetRevisionId</code> with <code>revisionEffectiveDate</code> and persist. <br> 3. <strong>Proration & depreciation start:</strong> determine <code>depreciationStart</code> from <code>acquisitionDate</code> or <code>inServiceDate</code> per policy; compute proration factor (<code>monthProrata</code>, <code>daysProrata</code>, <code>halfMonth</code>) deterministically and attach to schedule rows. <br> 4. <strong>Method calculations:</strong> SL, DDB, SYD, UnitsOfProduction and Custom methods executed at deterministic internal precision using <code>amountMinorUnits</code>: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. <strong>SL:</strong> preRoundedPeriod = ((cost − salvage) / usefulLifeMonths) × prorationFactor; compute full period series at internal precision before rounding. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. <strong>DDB:</strong> compute rate and apply to book value each period; deterministic switch to SL when threshold met. <br> &nbsp;&nbsp;&nbsp;&nbsp;c. <strong>SYD:</strong> compute yearly denominators and allocate per month deterministically. <br> &nbsp;&nbsp;&nbsp;&nbsp;d. <strong>UnitsOfProduction:</strong> require usage data; if missing flag <code>requiresManualInput</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;e. <strong>Custom:</strong> execute policySnapshot custom definition; custom semantics require migrationManifest. <br> 5. <strong>Rounding & pre-rounding:</strong> compute preRounded values at internal high precision; round per <code>roundingScale</code> using policy rounding mode (banker by default unless overridden); preserve <code>preRoundedAmount</code> and <code>roundedAmount</code> for audit. <br> 6. <strong>Residual absorption:</strong> residual = canonicalTotal − sum(roundedPeriods); deterministically absorb residual into the period with largest absolute preRounded period; tie-break by lexicographic <code>assetId</code>; record <code>residualAbsorbed</code> and explanation. <br> 7. <strong>JE aggregation & proposal generation:</strong> group by posting keys (GL account, costCenter, currency, period) and create <code>ScheduledJEProposals</code> balanced at <code>roundingScale</code>; attach <code>confidenceScore</code> derived from mapping completeness and DQ metrics. <br> 8. <strong>Manifest & runHash:</strong> assemble <code>depreciationRunManifest</code> including <code>policyHash</code>, <code>assetIngestChecksum</code>, <code>capexIngestChecksum</code>, <code>paramsHash</code>, <code>rowsCount</code>, <code>createdTs</code>, <code>operatorId</code>; compute <code>runHash = sha256(canonicalManifest)</code> and persist. <br> <strong>Edge behaviors & governance:</strong> cross-currency assets require canonical FX conversion and store <code>fxRateRef</code>; negative or zero useful life flagged for manual override. <br> <strong>CI tests:</strong> per-method unit tests, residual absorption parity, runHash golden fixtures. <br> <strong>Observability:</strong> <code>depn.run.durationMs</code>, <code>schedulesGenerated</code>, <code>jeProposalsCount</code>, <code>requiresManualInputCount</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: GenerateDepreciationJE(scheduleRows, jeTemplateSpec) As (SuggestedJEs[], previewManifest)</strong> <br> <strong>Summary:</strong> Build suggested JE bundles from schedule rows and export previews suitable for analyst review. <br> <strong>Inputs:</strong> <code>DepreciationSchedule[]</code>, <code>jeTemplateSpec</code> mapping to ERP fields, <code>aggregations</code> optional. <br> <strong>Outputs:</strong> <code>SuggestedJEs[]</code>, zipped <code>jePreviewArtifact</code> with <code>suggestedJEs.csv</code>, <code>schedules.csv</code>, <code>preview_manifest.json</code>; emitted <code>fa.je.preview.generated</code>. <br> <strong>Responsibilities & validations:</strong> <br> 1. Map internal posting keys to GL accounts using policySnapshot mappings; create <code>mappingSuggestions</code> where missing. <br> 2. Group scheduleRows into JE bundles ensuring balanced totals at <code>roundingScale</code>; if rounding produces imbalance apply deterministic residual absorption within the JE and document rationale. <br> 3. Validate JE format against <code>jeTemplateSpec</code> (column names, sign conventions); on mismatch emit <code>fa.je.export.invalid_spec</code>. <br> 4. Persist <code>jePreviewArtifact</code> atomically and emit preview audit with evidenceRefs and <code>previewHash</code>. <br> <strong>CI tests:</strong> balancing parity, mapping translation, preview manifest parity. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: GenerateJEExport(acceptedJEs, exportSpec, operatorId) As (exportPath, exportManifest)</strong> <br> <strong>Summary:</strong> Serialize accepted JEs into export file(s) matching <code>exportSpec</code> (ERP format) and persist atomic export artifact. <br> <strong>Inputs:</strong> accepted JE suggestions, <code>exportSpec</code> (field mapping, date and number formatting, file extension). <br> <strong>Outputs:</strong> <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code>, <code>exportManifest</code>, emitted <code>fa.je.exported</code>. <br> <strong>Responsibilities & validations:</strong> <br> 1. Validate <code>acceptedJEs</code> conform to <code>exportSpec</code> (fields, order, sign conventions). <br> 2. Ensure each JE bundle balances at <code>roundingScale</code>; if imbalance persists after deterministic absorption fail export and return diagnostics. <br> 3. Serialize deterministically and compute <code>exportChecksum = sha256(payload)</code>. <br> 4. Persist atomically and emit <code>fa.je.exported</code>. <br> <strong>Failure & remediation:</strong> schema mismatch returns precise diagnostic; upload failures retried. <br> <strong>CI tests:</strong> golden export checksum tests across runtime hosts. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: ApplyCorrections(acceptedJEs, mode, operatorId, approvals) As (applyResult)</strong> <br> <strong>Summary:</strong> Controlled mutative orchestration to create export artifact or post direct to GL; includes pre-apply persistence and approval gating. <br> <strong>Inputs:</strong> <code>acceptedJEs</code> or <code>exportPath</code>, <code>mode</code> (<code>create_export | post_direct</code>), <code>operatorId</code>, <code>approvals</code> evidence. <br> <strong>Outputs:</strong> persisted <code>applyDescriptor</code>, <code>applyResult</code> with per-JE status and posted journal ids if <code>post_direct</code>, emitted <code>fa.je.apply.*</code>. <br> <strong>Responsibilities & safety controls:</strong> <br> 1. <strong>Approval gating:</strong> validate approvals per <code>depreciationRunManifest.requiredApprovals</code>; two-person approval required for regulated posting. <br> 2. <strong>Persist <code>applyDescriptor</code> prior to mutation:</strong> include <code>applyId</code>, <code>runId</code>, <code>acceptedJEsHash</code>, <code>beforeChecksums</code>, <code>approvalsRef</code>, <code>operatorId</code>, timestamp. This descriptor is immutable and used for audit and potential reverts. <br> 3. <strong>Execution modes:</strong> <code>create_export</code> — return export artifact path; <code>post_direct</code> — obtain ephemeral credentials, post payload to GL using idempotency token = <code>applyId</code>, capture <code>postedJournalIds</code>. <br> 4. <strong>Post-apply reconciliation:</strong> fetch GL confirmations, compute <code>afterChecksums</code> and persist <code>applyResult</code>. <br> 5. <strong>Partial failure handling:</strong> per-JE error details, retry policies and idempotency to avoid duplicate postings. <br> <strong>Security:</strong> ephemeral credentials only; do not store tokens in logs. <br> <strong>CI tests:</strong> approval gating simulations, idempotency/replay tests, partial failure scenarios. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: RevertJEs(applyId, operatorId) As (revertResult)</strong> <br> <strong>Summary:</strong> Reversal orchestration for previously applied JE bundles. <br> <strong>Inputs:</strong> <code>applyId</code>, <code>operatorId</code>. <br> <strong>Outputs:</strong> <code>revertDescriptor</code>, <code>revertResult</code>, audit <code>fa.je.revert</code>. <br> <strong>Responsibilities:</strong> <br> 1. Retrieve <code>applyDescriptor</code> and <code>postedJournalIds</code>; idempotently compute <code>revertId</code>. <br> 2. Attempt GL reversal via API with ephemeral tokens and idempotency tokens; on partial success persist per-JE revert statuses. <br> 3. If GL reversal not available produce <code>reversalArtifact.csv</code> and <code>forensic_manifest</code> for manual GL reversals and mark <code>pending_manual_revert</code>. <br> 4. Persist <code>revertDescriptor</code> and emit audit. <br> <strong>CI tests:</strong> idempotency for repeated reverts, partial revert handling. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Function: ReconcileFAtoGL(assetScheduleAgg, glBalances, params) As (reconReport, reconManifest)</strong> <br> <strong>Summary:</strong> Subledger to GL reconciliation producing exception lists and suggested remediation actions. <br> <strong>Inputs:</strong> <code>assetScheduleAgg</code> grouped by <code>controlGLAccount</code>, <code>costCenter</code>, <code>period</code>, <code>glBalances</code>, <code>params</code> (materiality thresholds, FXRef). <br> <strong>Outputs:</strong> <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code>, <code>reconManifest</code>, <code>suggestedRemediation[]</code>, <code>fa.recon.report.generated</code>. <br> <strong>Responsibilities & flows:</strong> <br> 1. Full-outer join of subledger aggregates and GL balances using canonical grouping keys. <br> 2. Compute variance metrics — <code>Variance</code>, <code>AbsVariance</code>, <code>RelativeVariancePct</code> and apply configured materiality thresholds. <br> 3. Attach representative evidenceRefs and suggested remediation (re-export, mapping corrections, manual journal). <br> 4. Persist <code>reconManifest</code> and emit audit. <br> <strong>CI tests:</strong> aggregation parity, tolerance boundary tests. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>IV. Extended worked examples — detailed scenarios & remediation playbooks</strong> <br> <strong>Example 1 — Mixed-format asset master with embedded separators and locale numerics (end-to-end):</strong> <br> 1. Vendor supplies <code>.xlsx</code> with headers <code>Asset Tag</code>, <code>Desc.</code>, <code>Acq Date</code>, <code>Amount (EUR)</code> and descriptions containing <code>|</code>. <br> 2. <code>IngestAssetFile</code> canonicalizes bytes to UTF-8, computes <code>sourceFingerprint</code>, persists <code>rawAsset_&lt;sourceFingerprint&gt;</code>. <br> 3. <code>BuildHeaderMap</code> maps synonyms (<code>Desc.</code>→<code>description</code>) and persists <code>headerMapResolution[]</code>. <br> 4. <code>NormalizeText</code> replaces embedded <code>|</code> with canonical escape token to ensure stable <code>assetRowChecksum</code>. <br> 5. <code>CanonicalDecimal</code> with <code>sourceCulture=de-DE</code> converts <code>1.234,56</code> → <code>1234.56</code> and computes <code>amountMinorUnits</code>. <br> 6. Two ambiguous <code>Acq Date</code> rows flagged <code>DATE_PARSE_AMBIG</code> and ingest completes in <code>tolerant</code> mode with manifest <code>rowsWithWarnings=2</code>. <br> 7. Analyst updates header synonyms and reingests with <code>correctionOf</code> referencing prior <code>sourceFingerprint</code>, manifest lineage preserved. <br> <strong>Remediation note:</strong> escaping separators early is essential for cross-runtime hashing parity. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Example 2 — AP feed with split invoice lines and candidate ambiguity (mapping correction flow):</strong> <br> 1. AP extract contains INV-2026-500 split across two lines; line A contains <code>AS-004567</code>, line B truncated. <br> 2. <code>IngestCapexFile</code> runs <code>FindAssetCandidates</code>: line A candidate AS-004567 score=0.94; line B yields AS-004567 score=0.61 and AS-003111 score=0.60. Manifest <code>ambiguousCount=1</code>. <br> 3. <code>candidateMappingIndex</code> persisted with <code>matchingWeightsRef</code>. Analyst accepts mapping for invoice; system writes <code>mappingCorrection</code> artifact referencing <code>capexRowChecksum</code> and persists lineage. <br> <strong>Forensic note:</strong> persist matching weight vector and matchTrace to ensure replays are identical. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Example 3 — Rounding pathology & deterministic residual absorption (finance control):</strong> <br> 1. Asset cost 1000.00, useful life 3 months → theoretical monthly 333.333... <br> 2. With <code>roundingScale=2</code> rounded months become 333.33 each; total = 999.99 → residual +0.01. <br> 3. <code>ComputeDepreciation</code> computes preRounded series, rounds each period deterministically, calculates residual and applies residual absorption algorithm: place residual into period with highest absolute preRounded amount; tie-break by lexicographic <code>assetId</code>. Persist <code>residualAbsorbed</code> rationale in schedule row and run manifest for audit. <br> <strong>Control note:</strong> never drop preRounded evidence at ingest. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Example 4 — Units-of-Production missing usage metric (analyst queue):</strong> <br> 1. Asset configured as <code>UnitsOfProduction</code> with <code>totalExpectedUsage=10000</code> but no usage reported. <br> 2. <code>ComputeDepreciation</code> flags schedule row <code>requiresManualInput</code>, assigns low <code>confidenceScore</code>, emits <code>requiresManualInput</code> queue item with evidenceRefs. <br> 3. Analyst supplies usage via manual input pipeline; re-run for affected <code>assetRevisionId</code> produces corrected schedules and updated run manifest. <br> <strong>Operational note:</strong> surface such items in <code>OpenManualActions</code> KPI and include evidenceRefs for fast triage. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Example 5 — Policy migration canary & rollback process (governance ):</strong> <br> 1. Proposed change: change default useful life for <code>IT</code> category from 36 → 30 months. Draft <code>migrationManifest</code> with sampled fixtures and <code>canaryPlan</code> for a small cohort. <br> 2. Run canary for 1% representative assets and monitor KPIs <code>DepnExpenseDeltaPct</code>, <code>RunParityChange</code>, <code>SuggestionAcceptanceRate</code> for multiple cycles. <br> 3. If KPIs within thresholds capture approvals in <code>approvals[]</code> and promote <code>policySnapshot</code>; if not, rollback pointer to prior <code>policyHash</code> and produce remediation artifacts. <br> <strong>Governance note:</strong> preserve <code>migrationManifest</code> and evidence for audit; regulated GL changes require compliance sign-off. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>V. Power Query (PQ) — conceptual pilot guidance, parity, anti-patterns (no snippets)</strong> <br> <strong>When PQ is appropriate:</strong> <br> 1. PQ suits analyst previews, header mapping experimentation, and small cohort canonicalization (practical upper bound ~5k rows depending on complexity and host resources). <br> 2. PQ is not acceptable as canonical production engine for enterprise runs (>10k rows) or when high internal numeric precision is required — backend compute must be the source of truth. <br> <strong>Recommended PQ architecture (pilot):</strong> <br> 1. Parameterize top-level queries: <code>AssetMaster_Staging</code>, <code>Capex_Staging</code>, <code>PolicySnapshot_Param</code>. Parameters include <code>headerSynonyms</code>, <code>decimalLocale</code>, <code>roundingScale</code>, and <code>dateOrder</code>. <br> 2. Break canonicalization into modular named queries (<code>NormalizeTextStep</code>, <code>ParseAmountStep</code>, <code>ParseDateStep</code>) so intermediate outputs are inspectable and parity troubleshooting is easier. <br> 3. Produce <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> containing canonical CSVs and <code>preview_manifest.json</code> with <code>policyHash</code> and <code>previewHash</code> recorded; push to Evidence Store via automation. <br> <strong>Canonicalization conceptual mapping in PQ:</strong> <br> 1. Text normalization: <code>Text.Trim</code> → whitespace collapse → <code>Text.Lower</code>; where NFKC is not available use diacritic mapping tables. Preserve <code>rawFields</code>. <br> 2. Numeric parsing: pre-replace thousand separators and unify decimal separators before <code>Number.FromText</code> with explicit culture; preserve <code>preRoundedString</code>. <br> 3. Date parsing: use explicit <code>dateOrder</code> parameter and log parse attempts into <code>ParsingDiagnostics</code>. <br> <strong>PQ anti-patterns & mitigations:</strong> <br> 1. Heavy per-row custom functions calling external resources or performing complex regex in loops — prefer table joins or aggregated transforms. <br> 2. High-precision arithmetic in PQ — preserve preRounded strings and perform arithmetic on backend. <br> 3. Leaving PII in previews — always tokenize PII before publishing preview artifacts. <br> <strong>Parity & validation approach:</strong> <br> 1. Generate PQ parity fixtures (<code>policyHash</code>, <code>previewHash</code>) and compare per-row outputs to backend replays; produce <code>pqParityReport</code> listing row diffs and suspected causes. <br> 2. PQ must never be used to directly mutate GL; accepted PQ changes must be produced by backend canonical compute before any apply. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>VI. Conceptual DAX — measures, modeling patterns, triage UX (no snippets)</strong> <br> <strong>Modeling principles:</strong> <br> 1. Use canonical keys as relationship keys: <code>assetId</code>, <code>assetRowChecksum</code>, <code>policyHash</code>, <code>runId</code>. <br> 2. Avoid raw PII — present tokenized identifiers and require evidence approvals for raw retrieval. <br> 3. Show <code>policyHash</code> and <code>runId</code> on every financial KPI visual for traceability. <br> <strong>Core conceptual measures (descriptions):</strong> <br> 1. <strong>DepreciationExpense</strong> — sum of <code>DepSchedule[depreciationAmount]</code> scoped by period and <code>runId</code> with ability to compare runs. <br> 2. <strong>AccumulatedDepreciation</strong> — sum of <code>accumulatedDepreciationToDate</code> for reconciliation. <br> 3. <strong>NetBookValue</strong> — sum of <code>bookValueEnd</code>. <br> 4. <strong>FA_ReconVariance</strong> — <code>SubledgerAccumulatedDep − GLAccumulatedDep</code> with percentage and absolute variance and materiality parameterization. <br> 5. <strong>SuggestionAcceptanceRate</strong> — accepted JEs divided by suggested JEs per preview/run. <br> <strong>Operational triage signals:</strong> <br> 1. <code>RunParityDeltaCount</code> — runs with <code>runHash</code> mismatch. <br> 2. <code>OpenManualActions</code> — schedule rows flagged <code>requiresManualInput</code>. <br> 3. <code>TopVarianceByCategory</code> — prioritized exception list. <br> <strong>Drillthrough UX patterns:</strong> <br> 1. Drillthrough from variance cell to sample schedules with <code>candidateMappingTrace</code> and <code>evidenceRefs</code>; include <code>approvalRequest</code> action for PII retrievals that triggers chain-of-custody audit. <br> 2. Export views must embed <code>policyHash</code> and materiality parameters used. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>VII. Observability, CI/golden parity & SLOs — enforcement matrix</strong> <br> <strong>Mandatory audit events:</strong> <code>fa.asset.ingest.start/completed/partial/failed</code>, <code>fa.capex.ingest.*</code>, <code>fa.policy.loaded</code>, <code>fa.depn.run.completed</code>, <code>fa.je.preview.generated</code>, <code>fa.je.exported</code>, <code>fa.je.apply.start/complete/fail</code>, <code>fa.je.revert</code>, <code>fa.recon.report.generated</code>, <code>fa.policy.migration.*</code>, <code>fa.verify.parity.failed</code>. Each audit includes <code>correlationId</code>, <code>operatorId</code>, <code>evidenceRefs</code>, <code>ingestChecksum/runHash/exportChecksum</code>, and <code>paramsHash</code>. <br> <strong>Telemetry & SLOs (recommended):</strong> <br> 1. <code>PlanBuildLatencyP50</code> < 200ms for small plans. <br> 2. <code>PreviewLatencyP50</code> < 2s for ≤ 500 rows. <br> 3. <code>IngestSuccessRate</code> target > 99% per source daily. <br> 4. <code>GoldenParityFailureRate</code> 0 on protected branches. <br> <strong>CI & golden parity enforcement:</strong> <br> 1. Maintain canonical golden fixtures for representative inputs including expected <code>ingestChecksum</code>, <code>policyHash</code>, <code>runHash</code>. <br> 2. CI runs parity across supported runtimes (VBA host, PQ pilot, headless backend); golden diffs block merges and must be resolved via bugfix or an approved <code>migrationManifest</code>. <br> 3. Daily parity job recomputes checksums and emits <code>fa.verify.parity.failed</code> on mismatch with evidenceRefs for triage. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>VIII. Testing strategy & exhaustive CI matrix</strong> <br> <strong>Unit tests (primitives):</strong> <br> 1. <code>NormalizeText</code> — NFKC vectors, diacritic mapping, Turkish <code>i</code>, separator escaping, whitespace collapse. <br> 2. <code>CanonicalDecimal</code> — cross-locale numeric strings, negative-zero, thousand separator permutations, astronomical values and rounding edge cases. <br> 3. <code>FormatDateISO</code> — ambiguous day/month permutations and two-digit year handling. <br> 4. <code>ComputeSHA256</code> — RFC SHA256 vectors. <br> <strong>Integration tests (ingest pipelines):</strong> <br> 1. CSV/Excel/JSON end-to-end ingest → canonical artifact → manifest checksum parity. <br> 2. Capex ingest → candidate mapping deterministic ordering with <code>matchingWeightsRef</code>. <br> 3. Correction flows: reingest with <code>correctionOf</code> produce expected lineage and stable checksums. <br> <strong>Golden parity tests:</strong> curated fixture set with expected <code>ingestChecksum</code>, <code>policyHash</code>, <code>runHash</code> executed across host stacks; golden diffs block merges. <br> <strong>Property tests & fuzzing:</strong> ordering independence where applicable, header permutation invariance, seeded sampling reproducibility, deterministic retry behavior with seeded jitter. <br> <strong>Performance & load tests:</strong> ingest throughput at 1k/10k/100k rows; PQ preview latency at 100/500/1000 rows; candidate mapping throughput with large <code>assetIndexRef</code>. <br> <strong>Security tests:</strong> PII redaction verification across analyst surfaces, ephemeral token lifecycle tests, SAST scans for secret leakage. <br> <strong>Release gating:</strong> failing golden or security tests block protected branch merges; any canonical change requires <code>migrationManifest</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>IX. Failure modes, mitigation & operator runbooks (practical)</strong> <br> <strong>Fault A — Malformed encoding or corrupted file:</strong> <br> 1. <strong>Symptom:</strong> <code>fa.asset.ingest.invalid</code> or <code>rowsFailed</code> above threshold. <br> 2. <strong>Triage:</strong> capture <code>correlationId</code>, download <code>assetIngestManifest</code> and <code>rawAsset_&lt;sourceFingerprint&gt;</code>, inspect <code>issues[]</code> and <code>parseAttemptLogs</code>. <br> 3. <strong>Remediation:</strong> re-encode file to UTF-8, correct header map, re-run ingest with <code>correctionOf</code> referencing original <code>sourceFingerprint</code>; persist correction manifest. <br> <strong>Fault B — Capex unmapped backlog spike:</strong> <br> 1. <strong>Symptom:</strong> sudden increase in <code>capex.ingest.unmappedCount</code> and value at risk. <br> 2. <strong>Triage:</strong> export top unmapped by amount and frequency; examine <code>vendorDictionaryRef</code> coverage and recent vendor name changes. <br> 3. <strong>Remediation:</strong> bulk alias mappings, vendor dictionary update, bulk accept mapping suggestions with <code>mappingCorrection</code> artifacts; re-run candidate generation and persist mapping acceptance events. <br> <strong>Fault C — Evidence Store persist failures:</strong> <br> 1. <strong>Symptom:</strong> <code>fa.asset.ingest.persist_fail</code>, upload timeouts, or partial objects. <br> 2. <strong>Triage:</strong> check token expiry, network connectivity, service health; verify temp upload storage. <br> 3. <strong>Remediation:</strong> retry with exponential backoff; if persistent create encrypted local forensic bundle and escalate to platform ops with <code>forensic_manifest</code>. <br> <strong>Emergency policy rollback:</strong> <br> 1. <strong>Symptom:</strong> mass parity deltas or materially adverse variance after policy promotion. <br> 2. <strong>Procedure:</strong> atomic pointer swap to prior <code>policyHash</code>, run smoke parity on canonical fixtures, persist <code>policy.hotSwap.auditChain</code>, notify stakeholders and run reconciliation; document actions and evidence. <br> <strong>Runbook insistence:</strong> every triage and remediation action must be recorded as an audit row with <code>correlationId</code>, <code>operatorId</code>, evidenceRefs and final resolution. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>X. Migration manifest & policy governance — mandatory controls</strong> <br> 1. <strong>Change detection:</strong> any change to canonicalization rules (text normalization, separator escapes, diacritic handling), matching weights, or field order is semantic and requires a <code>migrationManifest</code>. <br> 2. <strong>MigrationManifest minimal fields:</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (cohort sizes, KPIs), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> 3. <strong>Canary plan & gating:</strong> run canary on representative cohort and golden fixtures; monitor KPIs (<code>DepnExpenseDeltaPct</code>, <code>RunParityChange</code>, <code>SuggestionAcceptanceRate</code>) across at least two cycles before promotion. <br> 4. <strong>Approval controls:</strong> require documented approvals in <code>approvals[]</code> and persist them to Evidence Store; for regulated GL ranges require compliance sign-off before enabling apply flows. <br> 5. <strong>Audit & evidence:</strong> persist migration manifest and canary results to Evidence Store and emit <code>fa.policy.migration.*</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>XI. Artifact naming, checksums & storage conventions</strong> <br> 1. <strong>Raw evidence:</strong> <code>rawAsset_&lt;sourceFingerprint&gt;.bin</code>, <code>capex_raw_&lt;sourceFingerprint&gt;.bin</code>. <br> 2. <strong>Ingest manifests:</strong> <code>asset_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>, <code>capex_ingest_&lt;sourceFingerprint&gt;_&lt;ts&gt;.json</code>. <br> 3. <strong>Canonical artifacts:</strong> <code>asset_canonical_&lt;sourceFingerprint&gt;_&lt;ingestChecksum&gt;.csv</code>, <code>capex_canonical_&lt;sourceFingerprint&gt;_&lt;ingestChecksum&gt;.csv</code>. <br> 4. <strong>Policy snapshots:</strong> <code>fa_policy_&lt;policyHash&gt;.json</code>. <br> 5. <strong>Depreciation previews:</strong> <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code> containing <code>schedules.csv</code>, <code>suggestedJEs.csv</code>, <code>preview_manifest.json</code>. <br> 6. <strong>JE exports:</strong> <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.&lt;ext&gt;</code> with <code>export_manifest.json</code>. <br> 7. <strong>Apply descriptors:</strong> <code>apply_&lt;applyId&gt;.json</code> immutable persisted before any mutative action. <br> 8. <strong>Reconciliation reports:</strong> <code>fa_recon_report_&lt;runId&gt;_&lt;reportHash&gt;.json</code>. <br> 9. <strong>Checksums:</strong> all artifacts use <code>sha256</code> over canonical UTF-8 bytes; manifests include <code>checksumAlgorithm</code> and <code>canonicalVersion</code>. <br> 10. <strong>Atomic commit pattern:</strong> use <code>uploadTemp</code> then <code>AtomicCommit</code> to avoid partial artifacts; audit emitted post commit. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>XII. Performance, scaling & architecture guidance</strong> <br> 1. <strong>Runtime tiers:</strong> PQ pilot for analyst preview and experiments (≤ ~5k), backend worker pools for production (>10k) with parallel sharding by file or asset ranges. <br> 2. <strong>Parallel model:</strong> ingest per file is embarrassingly parallel; downstream schedule compute sharded by <code>assetId</code> ranges or category; ensure deterministic ordering at aggregation boundaries. <br> 3. <strong>Incremental recompute:</strong> support targeted recompute by <code>assetRevisionId[]</code> and changed capex rows to avoid full reprocessing. <br> 4. <strong>Storage pattern:</strong> object store for large artifacts, relational metadata store for manifest indexes and fast queries. <br> 5. <strong>Autoscaling & SLOs:</strong> scale workers by queue depth and SLO metrics (ingest latency and golden parity failures). <br> 6. <strong>Monitoring & alerting:</strong> alert on <code>goldenParityFailureRate</code>, <code>ingest.latencyMs</code>, <code>apply.failureRate</code>, and <code>unmappedCapexValue</code>. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>XIII. Operator CLI patterns & concise commands</strong> <br> 1. <code>fa.build-run --period 2026-01 --policyRef fa_policy_20260101 --operator alice</code> → triggers controlled ingest + compute and returns <code>runId</code> and <code>depreciationRunManifestRef</code>. <br> 2. <code>fa.preview --run &lt;runId&gt; --sample 500 --operator alice</code> → generates <code>previewRef</code> and <code>fa.depn.preview</code> event. <br> 3. <code>fa.suggest-je --preview &lt;previewRef&gt; --operator alice</code> → creates suggested JEs and <code>jePreviewHash</code>. <br> 4. <code>fa.generate-je --preview &lt;previewRef&gt; --accept &lt;suggestionIds&gt; --exportSpec ERP_JE_v1 --operator alice</code> → writes <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code>. <br> 5. <code>fa.apply --export &lt;exportPath&gt; --mode post_direct --operator alice --approvalId ap-321 --approver bob</code> → persists <code>applyDescriptor</code> and posts to GL using ephemeral tokens; emits <code>fa.je.apply.*</code>. <br> 6. <code>fa.revert --applyId &lt;applyId&gt; --operator alice</code> → triggers <code>RevertJEs</code> and logs results; manual revert fallback produces a forensic manifest. <br> <strong>CLI safety:</strong> always persist <code>applyDescriptor</code> (immutable) prior to any mutative action and return <code>correlationId</code> for audit traceability. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>XIV. Acceptance criteria & release gates</strong> <br> 1. Unit tests for normalization, decimal parsing, date parsing, hashing across supported locales and edge cases. <br> 2. Integration tests for ingest→manifest parity on canonical fixtures. <br> 3. Golden parity tests ensure <code>ingestChecksum</code>, <code>policyHash</code>, <code>runHash</code> match across runtime environments; diffs block protected branch merges. <br> 4. Migration manifest required for semantic canonical changes with canary KPIs within thresholds and approvals recorded. <br> 5. Two-person approvals for regulated GL ranges enforced, ephemeral tokens validated, <code>applyDescriptor</code> persisted pre-mutation. <br> 6. Evidence retention, legal tags and periodic parity checks scheduled and verified. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>XV. Appendices — templates, checklists & operator artifacts</strong> <br> <strong>Appendix A — MigrationManifest minimal template (fields):</strong> <code>migrationId</code>, <code>author</code>, <code>createdTs</code>, <code>changeRationale</code>, <code>affectedPolicyRows[]</code> (before/after canonical), <code>sampleFixtures[]</code> (fileRef + goldenChecksums), <code>estimatedAffectedCount</code>, <code>canaryPlan</code> (cohortSizes, KPIs and monitoring windows), <code>rollbackPlan</code>, <code>approvals[]</code>, <code>testMatrix</code>. <br> <strong>Appendix B — Manifest & run verification checklist:</strong> <br> 1. Confirm <code>policyHash</code> equals approved snapshot. <br> 2. Verify presence and parity of <code>assetIngestChecksum</code> and <code>capexIngestChecksum</code> in <code>depreciationRunManifest</code>. <br> 3. Recompute <code>ingestChecksum</code> locally per canonical recipe and compare to persisted value. <br> 4. Confirm <code>previewHash</code> parity between PQ previews and backend replays. <br> 5. Validate <code>jePreviewArtifact</code> balancing and conformity to <code>jeTemplateSpec</code>. <br> <strong>Appendix C — Security & privacy checklist:</strong> <br> 1. Tokenize PII on analyst surfaces; raw retrieval requires explicit <code>approvalRef</code> and chain-of-custody audit. <br> 2. Ephemeral credentials for GL posting; never persist tokens or secrets in logs. <br> 3. Static analysis and secrets scanning on repos and pipeline artifacts. <br> 4. Evidence access must be approval gated and produce audit retrieval events. </td></tr><tr><td data-label="modIngest — Per-function Expert Technical Breakdown"> <strong>Closing: recommended follow-ups (pick one or more)</strong> <br> 1. Produce Formal JSON Schema for <code>AssetRow</code>, <code>CapexTransactionRow</code>, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, <code>depreciationRunManifest</code>, and <code>applyDescriptor</code> with exact field ordering for canonical hashing. <br> 2. Provide a curated set of canonical CSV test fixtures and expected <code>sha256</code> checksums for CI golden tests. <br> 3. Create a detailed Power Query canonicalization recipe document (step-by-step PQ transforms and expected intermediate outputs) for PQ pilots. <br> 4. Generate a compact operator runbook PDF summarizing triage flows, CLI commands, and incident checklists. <br> Indicate selected artifacts and the target environment (Windows VBA/Excel host, headless worker, PQ pilot) and the chosen artifact(s) will be produced next following the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 41</div></div><div class="table-caption" id="Table4" data-table="Docu_0185_04" style="margin-top:2mm;margin-left:3mm;"><strong>Table 4</strong></div>
<div class="table-wrapper" data-table-id="table-4"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modPolicy — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modPolicy — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>Preface & intent (concise):</strong> <br> This document expands the <code>modPolicy</code> domain for Project 005 into a full implementation-grade blueprint. It provides deeply detailed per-row narratives for all policy row types, exhaustive function contracts for each function in <code>modPolicy</code> (inputs, outputs, responsibilities, invariants, failure modes, telemetry signals, CI/test expectations, and operator runbooks), multiple worked examples with edge-case nuance, conceptual Power Query (PQ) pilot instructions and anti-patterns, and conceptual DAX measures and reporting guidance for operational dashboards. Determinism, evidence-first immutability, and governance are enforced throughout. All numbered lists use <code>&lt;br&gt;</code> line breaks. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>Executive summary (one paragraph):</strong> <br> <code>modPolicy</code> converts human-authored policy artifacts into immutable, canonical <code>policySnapshot</code> artifacts with reproducible <code>policyHash</code> values; it defines and enforces capitalization, depreciation method defaults, rounding/proration rules, GL mapping templates, and approval gating. The module provides validation, semantic diffing, migration manifest generation, canary orchestration, promotion/rollback controls, and audit emissions. Every behavioral change to policy must be governed by a migration manifest, run through canary checks where necessary, and persist evidence for forensic replay and CI golden parity testing. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>Top-level principles that drive all content below:</strong> <br> 1. <strong>Determinism:</strong> identical inputs + canonicalVersion => identical policyHash & predictable engine behavior. <br> 2. <strong>Evidence-first:</strong> raw inputs, manifests, snapshots, migration manifests, and canary outputs persist in Evidence Store with sha256 checksums and legal tags. <br> 3. <strong>Separation of concerns:</strong> ingestion & canonicalization (modPolicy) ≠ capitalization/application (ComputeDepreciation). modPolicy publishes immutable snapshots consumed by compute. <br> 4. <strong>Governance-first:</strong> any semantic (behavioral) change requires migrationManifest, canary plan and approvals before production promotion. <br> 5. <strong>Parit y & CI:</strong> golden fixtures & parity tests across PQ pilots and backend implementations are mandatory. <br> 6. <strong>PII minimization:</strong> policy attachments may reference sensitive mappings but must not expose raw PII in manifests; evidence retrieval is approval-gated. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1. Per-row canonical narratives — extremely detailed (each row used by policySnapshot and manifests)</strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.1 PolicyRow (atomic rule row) — canonical narrative:</strong> <br> <strong>Purpose:</strong> smallest atomic declarative unit in the policy snapshot. Each PolicyRow is the unit referenced in migration manifests and policy diff artifacts. <br> <strong>Key fields and canonical semantics:</strong> <br> 1. <code>rowId</code> (string): deterministic ID computed as <code>sha256(canonicalRowString|canonicalVersion)</code> where <code>canonicalRowString</code> is the canonical serialization of the core rule attributes in exact field order. Use same <code>canonicalVersion</code> that will be used to compute <code>policyHash</code>. <br> 2. <code>ruleType</code> (enum): one of <code>category_default</code>, <code>mapping_override</code>, <code>rounding_rule</code>, <code>proration_rule</code>, <code>capitalization_threshold</code>, <code>je_template</code>, <code>method_param</code>, <code>approval_matrix</code>, <code>fx_policy</code>, <code>locale_handling</code>. Reject unknown types in strict mode. <br> 3. <code>scope</code> (object): defines applicability (dimensions: <code>country</code>, <code>legalEntity</code>, <code>currency</code>, <code>category</code>, <code>costCenterPattern</code>, <code>assetClass</code>). Canonicalize scope keys sorted lexicographically. If scope omits a dimension, treat as wildcard at that dimension. <br> 4. <code>value</code> (variant): typed payload (integer, decimal string with explicit <code>scale</code>, boolean, or object). For currency amounts always include <code>amountMinorUnits</code> (integer) and <code>scale</code> (integer). For composite objects (jeTemplate, methodParams) require deterministic key ordering. <br> 5. <code>effectiveFrom</code> / <code>effectiveTo</code> (ISO <code>YYYY-MM-DD</code> or <code>null</code>): canonicalize dates; null indicates open-ended. When multiple rules overlap, deterministic precedence rules apply (see tie-breakers). <br> 6. <code>priority</code> (integer optional): explicit priority may be present; when absent determinism resolves precedence. Use <code>priority</code> higher value → higher precedence. <br> 7. <code>metadata</code> (object): <code>author</code>, <code>createdTs</code>, <code>comment</code>. Persist metadata for audit but exclude it from <code>policyHash</code> unless <code>canonicalVersion</code> requests inclusion. <br> 8. <code>rowChecksum</code> (sha256 prefixed): computed over canonicalization of <code>ruleType|scope|value|effectiveFrom|effectiveTo|priority</code> with fixed field order. <br> <strong>Invariants & rules:</strong> <br> - Canonical tokenization rules apply to all textual fields: Unicode NFKC → trim → collapse internal whitespace → casefold by default unless <code>locale_handling</code> overrides. <br> - Lists within <code>value</code> must be sorted consistently unless semantic order required and explicitly flagged <code>ordered = true</code>. <br> - Overlapping effective windows are permitted but must be resolved by precedence: <code>explicit priority</code> > <code>narrowest scope</code> > <code>later effectiveFrom</code> > <code>rowId</code> lexicographic tie-breaker. <br> <strong>Failure signals & remediation:</strong> <br> - <code>policy.row.invalid</code> for inconsistent scope/value pairs (e.g., <code>currency</code> in scope missing when value is currency amount). Remediate by adjusting scope or storing an explicit <code>fxPolicyRef</code>. <br> - <code>policy.row.overlap_warning</code> when overlapping rules create potential semantic ambiguity; requires author review or explicit priority. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.2 CategoryMappingRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> default depreciation semantics and GL mapping for a category. Used by ComputeDepreciation to derive missing per-asset defaults. <br> <strong>Key fields:</strong> <br> 1. <code>categoryKey</code> (string): canonical category code; canonicalization must match asset <code>category</code> canonical tokenization. <br> 2. <code>defaultUsefulLifeMonths</code> (integer): must be positive; zero or negative values produce <code>policy.row.invalid</code>. <br> 3. <code>defaultMethod</code> (enum): <code>SL</code>, <code>DDB</code>, <code>SYD</code>, <code>UnitsOfProduction</code>, <code>Custom</code>. If <code>Custom</code>, require <code>methodParamsRef</code>. <br> 4. <code>defaultSalvage</code> (object): may be <code>percent</code> (decimal) or <code>amount</code> (amountMinorUnits + scale + currency). Document precedence where both supplied. <br> 5. <code>glMapping</code> (object): required keys <code>depnExpenseAccount</code>, <code>accumDeprAccount</code>, <code>assetCostAccount</code>. Each should match <code>glAccountPattern</code>. <br> 6. <code>categoryRowChecksum</code>. <br> <strong>Rules & invariants:</strong> <br> - CategoryKey matching is casefolded and diacritic-normalized to match asset tokens. <br> - Changing <code>defaultUsefulLifeMonths</code> is a semantic financial change requiring migration manifest for production promotion. <br> <strong>Failure modes:</strong> <br> - Missing <code>glMapping</code> in strict mode → <code>policy.load.invalid</code>; tolerant mode fills with <code>mapping_missing</code> placeholder and flags for mapping review. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.3 RoundingRuleRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> enterprise rounding and residual absorption policy. <br> <strong>Critical fields:</strong> <br> 1. <code>roundingScale</code> (integer): number of fractional digits for external posting. <br> 2. <code>roundingMode</code> (enum): <code>HALF_TO_EVEN</code> (recommended), <code>HALF_AWAY_FROM_ZERO</code>, <code>TRUNCATE</code>. <br> 3. <code>internalPrecision</code> (integer): high-precision internal computation scale; recommended >= roundingScale + 4. Changing this can materially affect numeric parity and must be controlled via migration manifest. <br> 4. <code>residualAbsorptionScope</code> (<code>asset_level</code>, <code>batch_level</code>, <code>cost_center_level</code>) and <code>residualAbsorptionRule</code> (text that codifies tie-breakers and absorption ordering). <br> <strong>Trace & governance:</strong> <br> - <code>residualAbsorptionScope</code> governs whether residuals are absorbed per-asset or aggregated at group level; explicit sample rules in migration manifests required for batch-level absorption policies. <br> - Any change to <code>roundingScale</code> or <code>roundingMode</code> is considered a behavioral policy change. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.4 ProrationRuleRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> definitions for first/last period proration. <br> <strong>Fields:</strong> <br> 1. <code>prorationBasis</code> (<code>days</code>, <code>months</code>, <code>half_month</code>, <code>business_days</code>). <br> 2. <code>dayCountConvention</code> if applicable (<code>ACT/ACT</code>, <code>30/360</code> etc.). <br> 3. <code>businessDayAdjustment</code> (<code>none</code>, <code>preceding</code>, <code>following</code>, <code>modified_following</code>) and <code>holidayCalendarRef</code> optional. <br> 4. <code>prorationGranularity</code> (<code>month_level</code>, <code>day_level</code>). <br> <strong>Behavioral nuance:</strong> <br> - <code>half_month</code> proration requires explicit <code>start-of-month</code> or <code>mid-month</code> rules. <br> - Business-day proration requires holiday calendar and is platform-sensitive; PQ pilots should avoid relying on business-day computations for parity unless the same holiday calendar is used. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.5 CapitalizationThresholdRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> governs when expenditures are capitalized vs expensed. <br> <strong>Fields:</strong> <br> 1. <code>thresholdAmount</code> (amountMinorUnits + scale + currency). <br> 2. <code>appliesTo</code> (scope: <code>categoryList</code> or <code>global</code>). <br> 3. <code>treatmentIfUnder</code> (<code>expense</code>, <code>capitalize_with_override</code>, <code>review_required</code>). <br> <strong>Governance:</strong> <br> - Cross-currency application must reference <code>fxPolicyRef</code> to standardize conversion for threshold comparison. <br> - Changes to thresholds must be treated as potential material policy changes; large deltas require migration manifest and canary (see canary gating rules). </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.6 JETemplateRow / MappingRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> defines how schedule rows map to GL accounts and bundle aggregation rules used by JE generation and export. <br> <strong>Fields:</strong> <br> 1. <code>postingKey</code> (string): grouping semantics for aggregation, composed of <code>category|costCenter|currency|postingBucket</code>. <br> 2. <code>accountMap</code> object: <code>depnExpense→GL</code>, <code>accumDepr→GL</code>, <code>assetCost→GL</code>, with fallback rules and overrides. <br> 3. <code>aggregationPolicy</code> (<code>per_asset</code>, <code>per_cost_center</code>, <code>per_category</code>). <br> 4. <code>bundleTolerance</code> (integer minorUnits): allowable small imbalance before preview fails. <br> <strong>Behavior:</strong> <br> - If mapping missing <code>GenerateDepreciationJE</code> marks suggestions with <code>mappingSuggestion</code> and reduced <code>confidenceScore</code>. <br> - Changes to <code>accountMap</code> for production posting are semantic and require migration & parity checks. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.7 MethodParamRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> method-specific parameters for non-standard or custom depreciation methods. <br> <strong>Fields:</strong> <br> 1. <code>methodId</code> (string) linking to <code>defaultMethod</code>. <br> 2. <code>params</code> object (e.g., DDB factor, UoP usageMetric names, SYD weighting). <br> 3. <code>validationRules</code> — constraints that engine uses to validate presence and ranges. <br> <strong>Governance:</strong> <br> - Custom method semantics must be documented and require a migration manifest to change existing implementations. <br> - Parameter changes that alter resulting numeric outputs (e.g., DDB factor change) are behavioral changes. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.8 ApprovalMatrixRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> defines approval requirements for promotions and apply flows. <br> <strong>Fields:</strong> <br> 1. <code>approvalLevel</code> (string): <code>standard</code>, <code>regulatory</code>, <code>tax</code>. <br> 2. <code>thresholdAmount</code> (amountMinorUnits + scale + currency) and <code>currency</code>. <br> 3. <code>requiredApproverRoles</code> (ordered list) and <code>minApprovals</code> (integer). <br> 4. <code>exceptionRules</code> (optional): allowed exceptions and required <code>exceptionDocumentationRef</code>. <br> <strong>Behavioral rules:</strong> <br> - Changing <code>minApprovals</code> or thresholds for regulated categories triggers migration governance; enforcement is implemented in <code>ApplyPolicySnapshot</code> and <code>GenerateJEExport</code> flows. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.9 FXPolicyRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> governs FX rate references and conversion rules used when policy thresholds or revaluations reference foreign currencies. <br> <strong>Fields:</strong> <br> 1. <code>fxRateTableRef</code> (evidenceRef), <code>valuationTime</code> (e.g., <code>closingRate</code>, <code>transactionRate</code>), <code>roundingScale</code> for converted amounts, <code>staleRatePolicy</code> (max age allowed). <br> <strong>Behavior & edge cases:</strong> <br> - When FX data is missing, <code>ComputeDepreciation</code> must surface <code>requiresManualInput</code>. <br> - Changing FX policy semantics requires migration manifest if it affects pricing conversions used in production runs. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>1.10 LocaleHandlingRow — canonical narrative:</strong> <br> <strong>Purpose:</strong> captures locale-specific overrides for canonicalization (e.g., Turkish <code>i/I</code> casefold exceptions, decimal separator expectations). <br> <strong>Fields:</strong> <br> 1. <code>locale</code> (IETF tag), <code>casefoldExceptions</code> (list), <code>decimalSeparator</code> (char), <code>thousandSeparator</code> (char), <code>dateFormats</code> (list). <br> <strong>Usage:</strong> <br> - Where <code>locale</code> rules differ from default canonicalization they must be explicitly recorded in snapshot and cited in <code>policyManifest</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>2. Policy canonicalization rules — expanded parity recipe</strong> <br> 1. <strong>Text normalization pipeline (exact):</strong> Unicode NFKC → remove BOM → normalize newlines to <code>\n</code> → trim leading/trailing whitespace → collapse any run of whitespace (Unicode category <code>Zs</code> or <code>\t</code>, <code>\r</code>, <code>\n</code>) into single U+0020 → replace control characters with visible tokens if policy requires → apply casefold (Unicode casefold) unless overridden by <code>localeHandling</code> for specified fields. <br> 2. <strong>Numeric canonicalization:</strong> for any amount field store <code>amountMinorUnits</code> integer and <code>scale</code> integer. When parsing a decimal string: remove thousand separators, normalize decimal separator to <code>.</code>, parse high precision rationally, round to <code>internalPrecision</code> for math and store canonical decimal string zero-padded to <code>scale</code>. Negative zero normalization: <code>-0.00</code> -> <code>0.00</code>. <br> 3. <strong>Date canonicalization:</strong> format as <code>YYYY-MM-DD</code> for date-only; when time-of-day included use ISO 8601 <code>YYYY-MM-DDTHH:MM:SSZ</code> normalized to UTC; milliseconds trimmed/rounded to 3 digits with deterministic rounding rules. <br> 4. <strong>Array & map ordering:</strong> sort arrays deterministically (lexicographic by canonical token) unless <code>ordered=true</code>. For maps, sort keys lexicographically. <br> 5. <strong>Serialization & separators:</strong> produce canonical string by concatenating field values in canonical field order using <code>|</code> as separator; escape <code>|</code> in field text with explicit <code>\|</code> token; do not append trailing newline. <br> 6. <strong>Hash recipe & manifest stamping:</strong> compute <code>policyHash = sha256( canonicalVersion + &quot;|&quot; + canonicalString )</code> and store as <code>sha256:&lt;hex&gt;</code>. Include <code>canonicalVersion</code> in <code>policyManifest</code>. <br> 7. <strong>Tie-breaker rules:</strong> where deterministic selection necessary, apply rules: (a) <code>priority</code> field if present; (b) narrower scope (more specific) > broader; (c) later <code>effectiveFrom</code> > earlier; (d) lexicographic <code>rowId</code> tie-break; final fallback use seeded deterministic pseudo-random derived from <code>policyHash</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3. <code>modPolicy</code> function-level breakdowns — complete contracts</strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>Global cross-function expectations (applies to the following function contracts):</strong> <br> 1. All functions produce clear audit events via <code>EmitPolicyAudit</code>. <br> 2. All persisted artifacts (policy snapshot, manifest, migrationManifest, canary results) must be atomically written to Evidence Store with <code>createdTs</code>, <code>checksum</code>, <code>canonicalVersion</code>, and <code>legalTags</code>. <br> 3. All functions that produce deterministic values include <code>canonicalVersion</code> as input parameter or read from <code>policyManifest</code>. <br> 4. All communications with downstream compute must include <code>policyHash</code> to ensure replayability. <br> 5. All functions must expose telemetry metrics and produce <code>correlationId</code> in audit events. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.1 <code>LoadPolicySnapshot(policySource, options)</code></strong> <br> <strong>Purpose:</strong> ingest, validate, canonicalize and persist a policy snapshot as <code>fa_policy_&lt;policyHash&gt;.json</code> and produce <code>policyManifest</code>. <br> <strong>Inputs:</strong> <br> - <code>policySource</code> (file path, binary, workbook, or JSON payload). <br> - <code>options</code> object: <code>mode</code> (<code>strict | tolerant</code>), <code>author</code>, <code>canonicalVersion</code> (optional), <code>schemaVersion</code> (expected), <code>referenceId</code>. <br> <strong>Outputs:</strong> <br> - <code>policySnapshot</code> (in-memory canonical structure). <br> - persisted snapshot <code>fa_policy_&lt;policyHash&gt;.json</code> (evidenceRef). <br> - <code>policyManifest</code> persisted with fields: <code>policyHash</code>, <code>rulesSummary</code>, <code>rowCount</code>, <code>sourceFingerprint</code>, <code>issues[]</code>, <code>canonicalVersion</code>, <code>createdTs</code>. <br> - audit event <code>fa.policy.loaded</code>. <br> <strong>Responsibilities (step-by-step):</strong> <br> 1. Normalize raw bytes (normalize newlines, remove BOM, encode UTF-8), compute <code>sourceFingerprint = sha256(normalizedBytes)</code>, and persist raw evidence as <code>policy_raw_&lt;sourceFingerprint&gt;.&lt;ext&gt;</code>. <br> 2. Parse input supporting XLSX sheets mapping and JSON payloads; detect multi-sheet mapping like <code>categories</code>, <code>mappingOverrides</code>, <code>jeTemplates</code>, <code>roundingRules</code>, <code>prorationRules</code>, <code>approvalMatrix</code>. <br> 3. Call <code>PolicySchemaValidate</code> with the canonical schema. If invalid: <br> &nbsp;&nbsp;&nbsp;&nbsp; a. If <code>options.mode == strict</code> abort and return <code>policy.load.invalid</code> with <code>errors[]</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp; b. If tolerant, fill safe defaults as defined in schema defaults, record <code>fixedDefaults[]</code> and continue, attaching <code>issues[]</code>. <br> 4. For each parsed row produce typed fields (integers, canonical decimal strings with <code>scale</code>, objects) and call <code>CanonicalizePolicy</code> to produce <code>canonicalRows[]</code> and <code>canonicalString</code>. <br> 5. Compute <code>policyHash = ComputePolicyHash(canonicalString, canonicalVersion)</code> and store <code>policySnapshot</code> as <code>fa_policy_&lt;policyHash&gt;.json</code> atomically with <code>policyManifest</code>. <br> 6. Emit <code>fa.policy.loaded{policyHash}</code> with <code>correlationId</code>. <br> <strong>Invariants:</strong> <br> - Input canonicalization and <code>canonicalVersion</code> guarantee reproducible <code>policyHash</code>. <br> - Transient metadata changes do not alter <code>policyHash</code>. <br> <strong>Failure modes & remediation:</strong> <br> 1. <strong>Parse failure</strong> -> surface <code>policy.load.parse_error</code> with sample bytes/rows and remediation steps. <br> 2. <strong>Schema invalid</strong> -> if strict, abort; if tolerant, persist with <code>issues[]</code>. <br> 3. <strong>Persistence failure</strong> -> attempt retries; on repeated failures persist local encrypted safe copy and alert ops. <br> <strong>Telemetry & observability:</strong> <br> - <code>policy.load.latencyMs</code>, <code>policy.rowsParsed</code>, <code>policy.load.issuesCount</code>, <code>policyHash</code>. <br> <strong>CI tests:</strong> <br> - golden fixtures parity across environments. <br> - schema fuzzing and sample workbook permutations. <br> <strong>Operator runbook (short):</strong> <br> 1. On <code>fa.policy.loaded</code> check <code>policyManifest.rulesSummary</code>. <br> 2. On <code>policy.load.invalid</code> retrieve <code>policy_raw_&lt;fingerprint&gt;</code> and <code>validationReport</code> and correct source then re-run with <code>correctionOf</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.2 <code>CanonicalizePolicy(policyRaw, options)</code></strong> <br> <strong>Purpose:</strong> deterministic canonical serialization of parsed policy rows according to <code>canonicalVersion</code>. <br> <strong>Inputs:</strong> <code>policyRaw</code> (structured), <code>options</code>: <code>canonicalVersion</code>, <code>localeHandling</code>. <br> <strong>Outputs:</strong> <code>canonicalString</code>, <code>canonicalOrdering</code>, <code>canonicalRows[]</code> with <code>rowChecksum</code>. <br> <strong>Responsibilities:</strong> <br> 1. Apply text normalization pipeline and numeric canonicalization to all fields. <br> 2. Sort arrays & maps deterministically, establish field ordering, and produce canonical string using <code>|</code> separators and escape rules. <br> 3. Produce <code>canonicalOrdering</code> metadata used by <code>ComputePolicyHash</code> and downstream tools. <br> <strong>Failure modes:</strong> locale ambiguous inputs → add <code>canonicalize.issues</code> to manifest. <br> <strong>Telemetry & tests:</strong> unicode matrices, locale permutations, deterministic ordering tests. <br> <strong>Runbook:</strong> use debug mode to produce intermediate artifacts for triage if parity mismatches occur. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.3 <code>ComputePolicyHash(canonicalString, canonicalVersion, hashAlgorithm=&#x27;sha256&#x27;)</code></strong> <br> <strong>Purpose:</strong> compute authoritative policy fingerprint used across the system. <br> <strong>Inputs:</strong> <code>canonicalString</code>, <code>canonicalVersion</code>, <code>hashAlgorithm</code>. <br> <strong>Outputs:</strong> <code>policyHash</code> string <code>sha256:&lt;hex&gt;</code> and <code>hashInputSummary</code>. <br> <strong>Responsibilities:</strong> <br> 1. Include <code>canonicalVersion</code> in input: <code>canonicalVersion + &quot;|&quot; + canonicalString</code>. <br> 2. Compute sha256 over UTF-8 bytes and return <code>sha256:&lt;hex&gt;</code>. <br> <strong>Invariants & tests:</strong> test vectors across PQ and backend; ensure canonicalVersion changes produce different hash. <br> <strong>Telemetry:</strong> <code>policy.hash.ms</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.4 <code>PolicySchemaValidate(policyRaw, schema, options)</code></strong> <br> <strong>Purpose:</strong> structural validation vs canonical JSON Schema and generation of diagnostics. <br> <strong>Inputs:</strong> <code>policyRaw</code>, <code>schema</code>, <code>options.strict</code>. <br> <strong>Outputs:</strong> <code>validationReport</code> with <code>valid</code>, <code>errors[]</code>, <code>warnings[]</code>, <code>fixedDefaults[]</code>. <br> <strong>Responsibilities:</strong> <br> 1. Validate required sections, types, numeric ranges, currency codes, and glAccount patterns. <br> 2. Where <code>options.strict = false</code>, fill safe defaults and list them in <code>fixedDefaults[]</code>. <br> <strong>Failure modes:</strong> produce deterministic, actionable error messages for authors. <br> <strong>CI tests:</strong> schema backward compatibility checks. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.5 <code>ValidatePolicyChange(oldPolicyHash, newPolicySnapshot, sampleAssetIndex?)</code></strong> <br> <strong>Purpose:</strong> classification of diffs, estimate impact and generate canary plan recommendations. <br> <strong>Inputs:</strong> <code>oldPolicyHash</code>, <code>newPolicySnapshot</code> canonical rows, optional <code>sampleAssetIndex</code> or population stats. <br> <strong>Outputs:</strong> <code>validationReport</code> with <code>diffSummary</code>, <code>estimatedAffectedCount</code>, <code>projectedKPIDeltas</code>, <code>canaryPlan</code>, persisted <code>diffArtifactRef</code>. <br> <strong>Responsibilities (detailed):</strong> <br> 1. Compute row-level diffs and classify each row as <code>non_semantic</code>, <code>semantic_control</code>, or <code>semantic_financial</code>. <br> 2. For <code>semantic_financial</code> diffs run lightweight re-calculation on sample assets to estimate <code>DepnExpenseDeltaPct</code>, <code>RunParityChange</code>, and <code>JEProposalDelta</code>. <br> 3. Generate recommended canary cohorts with sizes and KPI thresholds for auto-fail triggers. <br> 4. Persist <code>diffArtifactRef</code> and attach to <code>validationReport</code>. <br> <strong>Invariants:</strong> deterministic classification algorithm; reproducible results when same sample & inputs used. <br> <strong>Failure & remediation:</strong> insufficient sample -> mark <code>uncertainty=high</code> and recommend manual review or increased cohort. <br> <strong>Telemetry & CI:</strong> accuracy checks against historical changes and simulation tests. <br> <strong>Operator runbook:</strong> require approver review for <code>semantic_financial</code> diffs before migrationManifest creation. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.6 <code>GenerateMigrationManifest(changeDetails, sampleFixtures, canaryPlan, author, approvals[])</code></strong> <br> <strong>Purpose:</strong> create the immutable governance artifact required for canary & production promotion. <br> <strong>Inputs:</strong> <code>changeDetails</code>, <code>sampleFixtures[]</code>, <code>canaryPlan</code>, <code>author</code>, initial <code>approvals[]</code>. <br> <strong>Outputs:</strong> persisted immutable <code>migrationManifest</code> and audit <code>fa.policy.migration.submitted</code>. <br> <strong>Responsibilities:</strong> <br> 1. Validate manifest completeness (see template below). <br> 2. Link <code>validationReport</code> and sample fixtures; attach <code>testMatrix</code> for CI runs. <br> 3. Persist immutably and emit audit event. <br> <strong>Failure modes:</strong> incomplete fields -> return <code>migration.manifest.invalid</code>. <br> <strong>CI tests:</strong> ensure <code>testMatrix</code> maps to available CI jobs and sample fixtures exist in Evidence Store. <br> <strong>Operator runbook:</strong> capture required compliance approvals before scheduling canary. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.7 <code>ExecutePolicyCanary(migrationManifestRef, runParams)</code></strong> <br> <strong>Purpose:</strong> orchestrate canary runs comparing old vs new policy on specified cohorts, collect KPIs, and auto-flag failures per manifest thresholds. <br> <strong>Inputs:</strong> <code>migrationManifestRef</code>, <code>runParams</code> (<code>cohortList</code>, <code>kpiWindow</code>, <code>monitoringKPIs</code>, <code>notificationTargets</code>). <br> <strong>Outputs:</strong> <code>canaryResults</code> persisted (KPI time-series, parity matrices, <code>anomalies[]</code>), <code>canaryEvidenceRef</code>, audit <code>fa.policy.migration.canary</code>. <br> <strong>Responsibilities (explicit):</strong> <br> 1. Retrieve new & old policy snapshots and cohort asset lists. <br> 2. For each cohort run <code>ComputeDepreciation</code> using both policies; persist each <code>runManifest</code> and <code>runHash</code>. <br> 3. Compute KPI deltas and significance tests; produce time-series and per-asset deltas. <br> 4. Compare deltas to thresholds in <code>migrationManifest</code>; if breached trigger auto-hold and <code>rollbackPlan</code>. <br> <strong>Invariants:</strong> all canary runs persisted for replay; deterministic instrumentation applied. <br> <strong>Failure modes:</strong> insufficient compute resources -> exponential backoff & alert; missing approvals -> block. <br> <strong>Telemetry & CI:</strong> canary simulation tests with synthetic deltas. <br> <strong>Operator runbook:</strong> review <code>canaryResults</code>; if KPIs acceptable, proceed to promotion steps. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.8 <code>ApplyPolicySnapshot(policyHash, operatorId, approvals[])</code></strong> <br> <strong>Purpose:</strong> atomically promote a <code>policySnapshot</code> to <code>activePolicyRef</code> after approvals and canary success. <br> <strong>Inputs:</strong> <code>policyHash</code>, <code>operatorId</code>, <code>approvals[]</code> (evidenceRefs). <br> <strong>Outputs:</strong> <code>promotionManifest</code> persisted, <code>activePolicyRef</code> updated, audit <code>fa.policy.promoted{policyHash}</code>. <br> <strong>Responsibilities:</strong> <br> 1. Validate approvals vs <code>approvalMatrix</code> and <code>migrationManifest</code>. <br> 2. Persist <code>promotionManifest</code> atomically and swap <code>activePolicyRef</code>. <br> 3. Trigger downstream notification and parity verification jobs. <br> <strong>Invariants:</strong> promotion atomicity; prior snapshots retained. <br> <strong>Failure modes:</strong> approval mismatch -> <code>policy.promotion.denied</code>; persistence failure -> rollback attempt. <br> <strong>Telemetry & CI:</strong> promotion gating tests and atomicity checks. <br> <strong>Runbook:</strong> run smoke preview and parity checks on representative assets immediately after promotion. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.9 <code>RollbackPolicy(policyHashTarget, operatorId, reason, approvals?)</code></strong> <br> <strong>Purpose:</strong> revert <code>activePolicyRef</code> to previous policy as per governance. <br> <strong>Inputs:</strong> <code>policyHashTarget</code>, <code>operatorId</code>, <code>reason</code>, optional <code>approvals</code>. <br> <strong>Outputs:</strong> <code>rollbackManifest</code> persisted and audit <code>fa.policy.rollback</code>. <br> <strong>Responsibilities:</strong> <br> 1. Validate policy exists and persist <code>rollbackManifest</code>. <br> 2. Atomically set <code>activePolicyRef</code> to <code>policyHashTarget</code> and trigger parity verification & recompute per <code>rollbackPlan</code>. <br> <strong>Invariants:</strong> rollback is auditable; cannot be reversed without promotion. <br> <strong>Failure modes:</strong> target not found -> <code>policy.rollback.notfound</code>. <br> <strong>Runbook:</strong> notify stakeholders and run parity smoke tests. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.10 <code>PolicyGet(policyHash)</code></strong> <br> <strong>Purpose:</strong> return read-only <code>policySnapshot</code> & manifest with access controls. <br> <strong>Inputs:</strong> <code>policyHash</code>, <code>requesterId</code>, optional <code>approvalRef</code> for sensitive retrieval. <br> <strong>Outputs:</strong> <code>policySnapshot</code>, <code>policyManifest</code>, <code>evidenceRef</code>. <br> <strong>Responsibilities:</strong> enforce access controls and log chain-of-custody events if sensitive attachments are retrieved. <br> <strong>Failure modes:</strong> policy not found -> <code>policy.get.notfound</code>. <br> <strong>Telemetry:</strong> <code>policy.get.latencyMs</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.11 <code>EmitPolicyAudit(eventType, policyHash, metadata)</code></strong> <br> <strong>Purpose:</strong> write append-only audit rows for all policy lifecycle events. <br> <strong>Inputs:</strong> <code>eventType</code>, <code>policyHash</code>, <code>metadata</code> (<code>correlationId</code>, <code>operatorId</code>, <code>manifestRefs</code>, <code>paramsHash</code>). <br> <strong>Outputs:</strong> persisted audit row. <br> <strong>Responsibilities:</strong> <br> 1. Ensure audit is append-only, persistent, and references evidence blobs (not inline PII). <br> 2. Retry on write failure; escalate on persistent failure. <br> <strong>Invariants:</strong> audit rows immutable & linked. <br> <strong>CI tests:</strong> simulate audit store outage and test retries. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>3.12 Utility helpers (explicit list with responsibilities)</strong> <br> <strong>3.12.1 <code>ParsePolicyWorkbook</code></strong> — parse XLSX into sections with precise error mapping (sheet name → section). Must support hidden sheets and formula cells conversion; flagged when formulas used. <br> <strong>3.12.2 <code>NormalizePolicyText(fieldValue, locale)</code></strong> — implement NFKC → trim → collapse whitespace → casefold with locale exceptions. <br> <strong>3.12.3 <code>AmountToMinorUnits(decimalString, scale, sourceCulture)</code></strong> — robust parsing that records <code>parseDiagnostics[]</code> on ambiguous locales. <br> <strong>3.12.4 <code>ComputeRowChecksum(canonicalRowString)</code></strong> — compute <code>sha256</code> and format. <br> <strong>3.12.5 <code>PersistEvidence(blob, metadata)</code></strong> — atomic store to evidence, return <code>evidenceRef</code>. <br> <strong>3.12.6 <code>CompareSnapshots(old, new)</code></strong> — deterministic row-level diff generator used by <code>ValidatePolicyChange</code>. <br> <strong>3.12.7 <code>RenderPolicyDiffReport(diffSet)</code></strong> — produce human-friendly summary and machine-readable <code>diffArtifactRef</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>4. Detailed worked examples (expanded narratives with edge cases and guardrails)</strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>4.1 Example — IT useful life reduction (full governance flow):</strong> <br> 1. Business: change default IT life 36→30 months due to obsolescence. Analyst updates workbook and runs <code>LoadPolicySnapshot</code>. <br> 2. <code>PolicySchemaValidate</code> passes, <code>CanonicalizePolicy</code> generates <code>canonicalString</code>, <code>ComputePolicyHash</code> yields <code>policyHash_new</code>. <br> 3. <code>ValidatePolicyChange</code> classifies as <code>semantic_financial</code>, estimates <code>DepnExpenseDeltaPct ≈ +6.7%</code> across IT assets using sample index; <code>estimatedAffectedCount</code> = 12,340. <br> 4. <code>GenerateMigrationManifest</code> includes <code>canaryPlan</code> targeting 1% cohort (≈123 assets), KPIs: <code>DepnExpenseDeltaPct</code> threshold 10% for auto-fail, <code>RunParityChange</code> threshold 25%. <br> 5. <code>ExecutePolicyCanary</code> runs old and new policies for cohort, computes per-asset deltas, time-series, and found <code>DepnExpenseDeltaPct</code> = 6.8% (within threshold). <br> 6. Approvals obtained via <code>approvalMatrix</code> roles; <code>ApplyPolicySnapshot</code> performed, <code>fa.policy.promoted</code> emitted, <code>activePolicyRef</code> swapped. <br> 7. Post promotion: scheduled daily parity job validates sample <code>runHash</code> deltas, and CI golden fixtures updated via migration manifest if canonicalVersion changed. <br> <strong>Edge nuance:</strong> cost centers with currency USD vs GBP require <code>fxPolicyRow</code> earlier; <code>ValidatePolicyChange</code> must convert sample amounts using <code>fxRateTableRef</code> to produce correct aggregate deltas. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>4.2 Example — roundingScale change & batch residual absorption (complex):</strong> <br> 1. Policy change: <code>roundingScale</code> 2 → 0 for legacy reporting. This change triggers large residual redistribution, especially for many low-cost assets. <br> 2. <code>ValidatePolicyChange</code> identifies <code>residualAbsorptionScope = batch_level</code> and marks high risk. <code>estimatedAffectedCount</code> high; <code>projectedKPIDeltas</code> show large shifts in per-cost center totals due to absorption redistributions. <br> 3. Migration manifest requires explicit <code>batchBalancingPolicy</code> and <code>testMatrix</code> that runs scheduled batch-level absorption simulations in CI. <br> 4. Canary fails on <code>RunParityChange</code> > threshold; migration paused. Policy authors revise to require <code>batch_level</code> + <code>cost_center_level</code> balancing constraints; re-run canary until parity acceptable. <br> <strong>Edge nuance:</strong> when <code>internalPrecision</code> differs between PQ pilot and backend, numeric parity diverges—must coordinate canonicalVersion and internalPrecision across runtimes. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>4.3 Example — approvalMatrix tightening for disposals > $2,000 (regulatory):</strong> <br> 1. Policy: disposals above threshold require <code>tax_team</code> and <code>finance_director</code> approvals. <br> 2. <code>ValidatePolicyChange</code> classifies as <code>semantic_control</code>; generates <code>migrationManifest</code>. <br> 3. Canary checks ensure <code>GenerateDepreciationJE</code> and <code>GenerateJEExport</code> produce artifacts containing <code>approvalRef</code> metadata; <code>ApplyCorrections</code> refuses <code>post_direct</code> when approvals absent. <br> 4. Post promotion, <code>ApplyCorrections</code> enforces two-person approval; attempts to post without approvals fail and emit <code>fa.je.apply.denied</code>. <br> <strong>Edge nuance:</strong> approval exceptions may be pre-authorized via <code>exceptionRules</code> that require <code>exceptionDocumentationRef</code> captured in Evidence Store. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>4.4 Example — units-of-production with missing usage metrics:</strong> <br> 1. Policy includes <code>UnitsOfProduction</code> default for <code>ManufacturingTool</code> category requiring <code>totalExpectedUsage</code> param. <br> 2. <code>LoadPolicySnapshot</code> creates <code>policySnapshot</code> referencing <code>methodParamsRef</code> for UoP. <br> 3. ComputeDepreciation runs discover missing <code>usageThisPeriod</code> values for many assets; schedule rows flagged <code>requiresManualInput</code>. <br> 4. <code>modPolicy</code> migration unrelated; remediation is data collection; operators annotate asset revisions and re-run compute for affected <code>assetRevisionId</code> values. <br> <strong>Edge nuance:</strong> PQ pilot can be used to submit usage samples to test preview pipelines, but full-scale recompute belongs to backend. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>5. Power Query (PQ) conceptual guidance for <code>modPolicy</code> pilots (no code snippets)</strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>5.1 When PQ is appropriate:</strong> <br> 1. Authoring and iterative policy workbook editing by policy owners and analysts. <br> 2. Rapid parity checks for canonicalization rules on small policy snapshots (tens to a few thousands of rows). <br> 3. Creating human-friendly <code>policy_preview.zip</code> artifacts for governance review. <br> <strong>When not to use PQ:</strong> <br> 1. Production canonicalization for large enterprise policies (10k+ rows) where PQ performance and decimal precision may be insufficient. <br> 2. Any production run that requires strict high-precision internal math or complex business-day calendars unless PQ and backend share the same libraries and calendars. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>5.2 PQ architectural pattern (conceptual):</strong> <br> 1. Build named parameterized queries: <code>Policy_Source</code>, <code>Policy_TextNormalize</code>, <code>Policy_NumberNormalize</code>, <code>Policy_RuleAssembly</code>, <code>Policy_CanonicalSerialize</code>. Each query step mirrors backend canonicalization steps to maximize parity. <br> 2. Expose parameters: <code>canonicalVersion</code>, <code>defaultCulture</code>, <code>internalPrecision</code>, <code>roundingScale</code>. Use identical values in backend to produce matching <code>policyHash</code>. <br> 3. Persist PQ-generated canonical string and compute a hash using the same algorithm if host functions allow; otherwise export canonical string for backend hashing. <br> 4. Package <code>policy_preview.zip</code> containing <code>policy_serialized.txt</code>, <code>policy_manifest.json</code>, and <code>issues.csv</code>. <br> <strong>5.3 PQ canonicalization conceptual steps:</strong> <br> 1. Text normalization: implement NFKC where available; otherwise apply replacement tables and record any differences. <br> 2. Numeric parsing: unify decimal separators and thousand separators using <code>defaultCulture</code>, then produce <code>amountMinorUnits</code> by multiplying by 10^scale and rounding to <code>internalPrecision</code>. <br> 3. Row ordering: sort policy tables per canonical ordering rules and produce serial assembly with explicit escape tokens for <code>|</code>. <br> 4. Hashing: where PQ lacks strong hashing, export canonical string and compute <code>policyHash</code> in backend to validate parity. <br> <strong>5.4 PQ anti-patterns & mitigations:</strong> <br> 1. Per-row custom functions cause slow performance—use table transformations and merges wherever possible. <br> 2. Implicit culture reliance—pass culture parameter explicitly. <br> 3. Surface-only edits: avoid letting analysts make unrecorded free-text edits in PQ preview; require exports to be saved as source artifact with <code>sourceFingerprint</code>. <br> <strong>5.5 PQ parity testing guidance:</strong> <br> 1. Generate <code>pqParityReport</code> comparing PQ-produced canonical string and backend canonical string; differences flagged and triaged. <br> 2. Keep sample golden fixtures for PQ to test canonicalVersion parity across environments. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>6. Conceptual DAX — measures and reporting patterns (no code)</strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>6.1 Core DAX modeling principles for policy observability:</strong> <br> 1. Use canonical keys (<code>policyHash</code>, <code>migrationId</code>, <code>runId</code>, <code>previewHash</code>) to relate policy snapshots to run manifests and reconciliation tables. <br> 2. Keep PII out of visuals; use tokenized identifiers and evidenceRef drill-throughs requiring approvals. <br> 3. Design measures to support canary monitoring, migration KPIs, and operational dashboards for governance. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>6.2 Essential measures (conceptual descriptions):</strong> <br> 1. <code>DepnExpenseDeltaPct(policyA, policyB, period)</code> — percent difference in depreciation expense between two policies for a chosen period and asset set; used in canary evaluation. <br> 2. <code>RunParityChange(policyA, policyB)</code> — count or percent of schedule rows that changed between two runs. <br> 3. <code>SuggestionAcceptanceRate(previewRef)</code> — ratio of accepted JE suggestions to suggested JEs in a preview; measures analyst friction post-policy change. <br> 4. <code>OpenManualActions(policyHash)</code> — count of schedule rows flagged <code>requiresManualInput</code>. <br> 5. <code>TopDeltaAssets(N)</code> — list of N assets with highest absolute depreciation delta between policies. <br> <strong>6.3 Advanced governance measures (conceptual):</strong> <br> 1. <code>PolicyPromotionLatency</code> — time between migration manifest final approval and <code>ApplyPolicySnapshot</code> completion. <br> 2. <code>GoldenParityMismatchCount</code> — number of CI golden tests failing attributable to policy changes. <br> 3. <code>CanaryKPI_BreachFlag</code> — boolean whether any KPI breached thresholds during canary. <br> <strong>6.4 Drillthrough & UX guidance:</strong> <br> 1. Provide drillthrough from a KPI to the <code>migrationManifest</code>, <code>canaryResults</code>, and sample <code>runManifests</code> including evidenceRefs to the <code>fa_policy_&lt;policyHash&gt;.json</code>. <br> 2. Include <code>approvalRef</code> and <code>approver</code> controls in visuals so auditors can inspect chain-of-custody. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>7. Testing strategy & exhaustive CI/golden parity matrix for <code>modPolicy</code></strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>7.1 Unit tests (must cover):</strong> <br> 1. Text normalization edge-cases: combining characters, diacritics, normalization variants, Turkish dotted-dottedless <code>i</code> cases per locale. <br> 2. Numeric parsing across cultures: thousands separators, ambiguous decimals, negative zeros. <br> 3. Row checksum reproducibility given permutations of non-functional metadata. <br> 4. Per-row validation rules (e.g., <code>defaultUsefulLifeMonths &gt; 0</code>). <br> <strong>7.2 Integration tests (must cover):</strong> <br> 1. Load workbook → canonicalize → compute <code>policyHash</code> → persist → retrieve via <code>PolicyGet</code> and confirm immutability. <br> 2. Full <code>ValidatePolicyChange</code> → <code>GenerateMigrationManifest</code> → <code>ExecutePolicyCanary</code> path using mock <code>ComputeDepreciation</code> to assert KPI computations. <br> <strong>7.3 Golden parity tests:</strong> <br> 1. Maintain canonical fixtures with expected <code>policyHash</code> (stored in Evidence Store). <br> 2. Run PQ & backend canonicalization on fixtures and assert <code>policyHash</code> equality. <br> 3. Any canonicalization change must increase <code>canonicalVersion</code> and include migration manifest to update CI golden fixtures. <br> <strong>7.4 Property & fuzz tests:</strong> <br> 1. Non-semantic metadata changes do not alter <code>policyHash</code>. <br> 2. Ordering permutations of non-ordered arrays have no effect on <code>policyHash</code>. <br> 3. Small semantic changes always produce different <code>policyHash</code>. <br> <strong>7.5 Performance & load tests:</strong> <br> 1. <code>LoadPolicySnapshot</code> with very large policy tables (50k+ rows) must complete within defined SLO or at least produce progress telemetry and safe persistence. <br> 2. Canary orchestration simulator tests scheduling thousands of cohorts. <br> <strong>7.6 Security tests:</strong> <br> 1. Access control tests for <code>PolicyGet</code> and evidence retrieval requiring approvals. <br> 2. Audit emission tests under high throughput. <br> <strong>7.7 CI gating:</strong> <br> 1. Golden parity failures must block merges on protected branches. <br> 2. Migration manifests required for any semantic policy changes before production promotion. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8. Observability, SLOs, and incident runbooks for <code>modPolicy</code></strong> </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8.1 Mandatory audit events (every function emits appropriate events):</strong> <br> 1. <code>fa.policy.loaded</code> (on LoadPolicySnapshot) <br> 2. <code>fa.policy.migration.submitted</code> (on GenerateMigrationManifest) <br> 3. <code>fa.policy.migration.canary</code> (on ExecutePolicyCanary) <br> 4. <code>fa.policy.promoted</code> (on ApplyPolicySnapshot) <br> 5. <code>fa.policy.rollback</code> (on RollbackPolicy) <br> 6. <code>fa.policy.audit</code> generic event for ad-hoc actions <br> Each audit row includes <code>correlationId</code>, <code>policyHash</code>, <code>manifestRefs</code>, <code>operatorId</code>, <code>paramsHash</code>, and <code>evidenceRefs</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8.2 Evidence storage & naming conventions:</strong> <br> 1. <code>fa_policy_&lt;policyHash&gt;.json</code> — persisted policy snapshot. <br> 2. <code>policy_raw_&lt;sourceFingerprint&gt;.&lt;ext&gt;</code> — raw input. <br> 3. <code>migration_manifest_&lt;migrationId&gt;.json</code> — migration manifest. <br> 4. <code>policy_canary_&lt;migrationId&gt;_&lt;ts&gt;.zip</code> — canary artifacts. <br> All artifacts stored with <code>checksum</code> (sha256), <code>retentionPolicy</code>, and <code>legalTags</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8.3 Key SLO examples (suggested):</strong> <br> 1. <code>PolicyLoadLatencyP50</code> target < 500ms for small snapshots (<1k rows). <br> 2. <code>PolicyPromotionLatencyP50</code> pointer swap < 2s (excluding downstream recompute). <br> 3. <code>GoldenParityFailureRate</code> target 0 in protected branches. <br> 4. <code>CanaryAutoFailWithin</code> — auto-detection of KPI breach within 2 monitoring cycles (policy-configured). </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8.4 Parity verification job (daily) responsibilities:</strong> <br> 1. Recompute <code>policyHash</code> for persisted <code>fa_policy_&lt;policyHash&gt;.json</code> and compare to recorded <code>policyHash</code>. <br> 2. Emit <code>verify.parity.failed</code> if mismatch and open investigation ticket with <code>correlationId</code>. <br> 3. Where PQ pilots are used, run PQ vs backend parity checks and record <code>pqParityReport</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>8.5 Incident triage runbook (explicit steps):</strong> <br> 1. Capture <code>correlationId</code> and <code>policyHash</code> from alert context. <br> 2. Retrieve <code>fa_policy_&lt;policyHash&gt;.json</code>, <code>migrationManifest</code> (if applicable), <code>validationReport</code>, and <code>canaryResults</code> via evidenceRefs. <br> 3. Inspect <code>validationReport</code> for classification and <code>issues[]</code>. <br> 4. If parity mismatch exists, re-run <code>CanonicalizePolicy</code> in debug mode and compare intermediate canonical rows. <br> 5. If promotion without approvals occurred, run <code>RollbackPolicy</code> and escalate to compliance; persist all steps as audit rows. <br> 6. Keep all forensic artifacts in Evidence Store and attach to incident. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>9. Operator CLI patterns & recommended commands (examples)</strong> <br> 1. <code>fa.policy.load --file policy_2026-01.xlsx --mode strict --author alice</code> → runs <code>LoadPolicySnapshot</code>, returns <code>policyHash</code> and <code>policyManifestRef</code>. <br> 2. <code>fa.policy.validate-change --old fa_policy_&lt;oldHash&gt; --new policy_2026-01.xlsx --sample 1000</code> → runs <code>ValidatePolicyChange</code> and returns <code>validationReport</code>. <br> 3. <code>fa.policy.migrate --manifest migration_manifest_123.json --operator alice</code> → registers manifest and schedules canary per <code>canaryPlan</code>. <br> 4. <code>fa.policy.canary.status --migrationId 123</code> → fetches latest <code>canaryResults</code>. <br> 5. <code>fa.policy.promote --policyHash sha256:&lt;hex&gt; --operator alice --approvals ap-321,ap-456</code> → calls <code>ApplyPolicySnapshot</code>. <br> 6. <code>fa.policy.rollback --policyHash sha256:&lt;hex&gt; --operator alice --reason &quot;emergency&quot;</code> → calls <code>RollbackPolicy</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>10. Acceptance criteria & release gates (strict)</strong> <br> 1. Unit tests confirm deterministic canonicalization across locales. <br> 2. Integration tests validate ingestion → canonicalization → <code>policyHash</code> generation → retrieval. <br> 3. Golden parity tests ensure PQ and backend <code>policyHash</code> match for fixtures; failures block merges. <br> 4. Migration manifests present and canary executed with KPIs within thresholds before promotion. <br> 5. Two-person approvals enforced for regulated promotions; <code>ApplyPolicySnapshot</code> enforces <code>approvalMatrix</code>. <br> 6. Evidence & retention policies applied; parity verification scheduled. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>11. Security, privacy & compliance notes</strong> <br> 1. Policy snapshots may reference controlled mappings that have PII in attachments; never inline PII in <code>policyManifest</code> or audit rows. <br> 2. Evidence retrieval for attachments containing PII requires <code>approvalRef</code> and chain-of-custody logging. <br> 3. Ephemeral credential model required for any flows that mutate downstream GL systems; these are handled by apply flows in downstream modules, but <code>modPolicy</code> must include approval evidence checks. <br> 4. Ensure secrets & tokens never included in evidence blobs or policy artifacts. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>12. Long-form appendices & templates (concise pointers)</strong> <br> <strong>12.1 MigrationManifest template fields:</strong> <br> 1. <code>migrationId</code> <br> 2. <code>author</code> <br> 3. <code>createdTs</code> <br> 4. <code>changeRationale</code> <br> 5. <code>affectedPolicyRows[]</code> (before/after canonical with rowChecksum) <br> 6. <code>sampleFixtures[]</code> (evidenceRef + goldenChecksums) <br> 7. <code>estimatedAffectedCount</code> <br> 8. <code>canaryPlan</code> (cohorts + KPI thresholds) <br> 9. <code>rollbackPlan</code> <br> 10. <code>approvals[]</code> <br> 11. <code>testMatrix</code> (CI jobs and fixtures) <br> <strong>12.2 PolicyManifest fields recommended:</strong> <br> 1. <code>policyHash</code> <br> 2. <code>canonicalVersion</code> <br> 3. <code>rulesSummary</code> <br> 4. <code>rowCount</code> <br> 5. <code>sourceFingerprint</code> <br> 6. <code>issues[]</code> <br> 7. <code>createdTs</code> <br> 8. <code>author</code> <br> <strong>12.3 Evidence naming & checksum policy:</strong> <br> - All artifacts use sha256 over canonicalized payloads and include <code>sha256:&lt;hex&gt;</code> in manifests; evidence objects are immutable with <code>createdTs</code> and <code>legalTags</code>. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>13. Implementation tips & pitfalls (practical engineering guidance)</strong> <br> 1. Canonicalization must be implemented as a deterministic pipeline; avoid in-place mutation of rows. <br> 2. Keep <code>canonicalVersion</code> in configuration and in the manifest; any change to canonicalization rules must increment <code>canonicalVersion</code>. <br> 3. Maintain a small, authoritative canonicalization test harness (unit tests with fixtures and property tests). <br> 4. For PQ pilots, insist on producing canonical strings identical to backend; if PQ cannot produce same hash, export canonical string and compute hash in backend. <br> 5. Implement <code>policy.load</code> in streaming fashion for very large workbooks to avoid memory pressure. <br> 6. For complex <code>residualAbsorptionScope</code> policies, run batch-level simulations in staging before applying to production. </td></tr><tr><td data-label="modPolicy — Per-function Expert Technical Breakdown"> <strong>14. Final operational note & next-artifact options:</strong> <br> This expanded <code>modPolicy</code> specification provides exhaustive per-row narratives, deterministic canonicalization recipes, complete function-level contracts, examples, PQ pilot guidance, and DAX reporting patterns. If you want the next artifacts, choose from: <br> 1. Formal JSON Schema for <code>policySnapshot</code> and <code>migrationManifest</code> with exact canonical field ordering. <br> 2. Canonical policy golden fixtures and expected <code>policyHash</code> values for CI. <br> 3. Step-by-step Power Query canonicalization recipe with example intermediate outputs (for PQ pilots). <br> 4. Compact runbook PDF summarizing triage steps and CLI commands for policy operations. <br> Specify selected artifact(s) and environment preference and the chosen artifacts will be produced following the canonical recipes above. </td></tr></tbody></table></div><div class="row-count">Rows: 54</div></div><div class="table-caption" id="Table5" data-table="Docu_0185_05" style="margin-top:2mm;margin-left:3mm;"><strong>Table 5</strong></div>
<div class="table-wrapper" data-table-id="table-5"><div class="table-heading-bar" aria-label="Table heading"></div><div class="table-container"><div class="table-header-wrapper" style="display:flex; justify-content:space-between; align-items:center; margin-bottom:5px;"><div class="copy-buttons"><button type="button" class="copy-plain-btn" data-action="copy-plain" onclick="copyTablePlain(this)">Copy Plain Table</button><button type="button" class="copy-markdown-btn" data-action="copy-markdown" onclick="copyTableMarkdown(this)">Copy Markdown Table</button><button type="button" class="export-csv-btn" data-action="export-csv" onclick="exportTableCSV(this)">Export CSV</button><button type="button" class="export-json-btn" data-action="export-json" onclick="exportTableJSON(this)">Export JSON</button><button type="button" class="export-xlsx-btn" data-action="export-xlsx" onclick="exportTableXLSX(this)">Export XLSX</button><button type="button" class="export-pdf-btn" data-action="export-pdf" onclick="exportTablePDF(this)">Export PDF</button><button type="button" class="export-markdown-btn export-markdown-initial" data-action="export-markdown" onclick="exportTableMarkdown(this)" style="display:none" data-initial-hidden="1">Export Markdown</button></div><div style="display:flex; align-items:center;"><button type="button" class="toggle-table-btn" data-action="toggle-collapse" onclick="toggleTable(this)">Collapse Table</button></div></div><table class="tv-table" role="table"><thead><tr><th class="tv-col-left" role="button" aria-label="Sort by modCanonical — Per-function Expert Technical Breakdown"><div class="th-with-sort"><div style="flex:1; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;">modCanonical — Per-function Expert Technical Breakdown</div><button class="sort-btn sort-state-0" title="Toggle sort" aria-label="Toggle sort"><span class="sort-icon" aria-hidden="true"></span></button></div></th></tr></thead><tbody><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Preface & intent (concise):</strong> This document is the single-source authoritative expansion of <code>modCanonical</code> for Project 005. It defines deterministic canonicalization primitives used everywhere in the pipeline: ingest, matching, depreciation engine, JE generation, export, reconciliation, parity tests, and audit. Each function is specified as a production contract: inputs, outputs, responsibilities, invariants, failure modes & remediation, telemetry signals, CI/golden test expectations, and implementation notes for VBA/back-end parity. Every numbered list below uses <code>&lt;br&gt;</code> line breaks for downstream rendering consistency. Changes to canonical semantics that affect financial outputs MUST be governed by a <code>migrationManifest</code> and golden parity tests. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>High-level summary (one paragraph):</strong> <code>modCanonical</code> implements deterministic, auditable conversions from raw evidence to canonical tokens and canonical serialized rows. It enforces Unicode normalization (NFKC), deterministic punctuation mapping, locale-aware numeric parsing with fixed-scale decimal serialization and integer minor units, ISO date/time canonicalization with timezone normalization and proration metadata, deterministic escaping and serialization ordering (pipe <code>|</code> separator), canonical list serialization (stable JSON), and <code>sha256:</code> hashing with explicit <code>canonicalVersion</code> stamping. All primitives are pure where possible, produce detailed diagnostics, and are instrumented for telemetry and parity testing across runtime environments (Power Query pilots, VBA host, backend worker). </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Scope & audience:</strong> Implementation engineers (VBA & backend), QA/golden-parity owners, power analysts (PQ pilots), test engineers, compliance/audit teams, and operations. Use this document as a contract and checklist: implement primitives, run parity tests, and maintain golden fixtures for each <code>canonicalVersion</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>High-level invariants (global):</strong> <br> 1. Determinism: identical canonical inputs + <code>canonicalVersion</code> → identical canonical artifacts and hash outputs across runtimes. <br> 2. Evidence-first: raw payloads remain immutable in Evidence Store; canonicalization produces derived artifacts and never overwrites raw evidence. <br> 3. PII minimization: analyst surfaces show tokenized identifiers; any raw PII retrieval requires approvals and chain-of-custody audit. <br> 4. Manifest stamping: every artifact manifest includes <code>canonicalVersion</code>, <code>hashProvider</code> metadata, and <code>fieldOrder</code> used for hashing. <br> 5. Migration governance: any change to canonical rules that affects financial outputs requires <code>migrationManifest</code> + canary + approvals before production use. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Canonical models & per-row forensic narratives (summary):</strong> This section states per-model semantics, which feed directly into <code>modCanonical</code> primitives. For each canonical model the serialization <code>fieldOrder</code> is authoritative and required for hashing parity. Models covered: <code>AssetRow</code>, <code>CapexTransactionRow</code>, <code>DepreciationScheduleRow</code>, <code>DisposalRow</code>, <code>RevaluationRow</code>, <code>JE_Line</code>, and manifests. Each row type stores both canonicalized fields (for hashing and downstream use) and evidence references (<code>rawPayloadRef</code>) enabling full forensic replay. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>AssetRow — comprehensive narrative & forensic handling:</strong> <br> • Purpose: canonical, auditable anchor representing a physical/intangible asset. <br> • Deterministic identity: <code>assetId</code> must be stable across re-ingests and derived deterministically when not provided by source; recommended recipe: <code>sha256(canonicalAssetKey)</code> with canonicalAssetKey = <code>NormalizeText(assetTag || &#x27;|&#x27; || description || &#x27;|&#x27; || FormatDateISO(acquisitionDate))</code>. Persist the recipe in manifest so any implementer can reproduce <code>assetId</code>. <br> • Text fields: <code>assetTag</code>, <code>description</code> must preserve raw forms in <code>rawPayloadRef.rawField</code> and store canonical tokens computed via <code>NormalizeText</code> (NFKC, trim, collapseWhitespace, casefold optionally, diacritic strip optionally). <br> • Monetary fields: <code>acquisitionCost</code>, <code>salvageValue</code> must be stored as canonical decimal strings (exact scale) and <code>amountMinorUnits</code> (integer) with explicit <code>roundingScale</code> and <code>currency</code>. For cross-currency situations store <code>fxRateRef</code> and <code>acquisitionCostConvertedMinorUnits</code>. <br> • Depreciation metadata: <code>usefulLifeMonths</code>, <code>depreciationMethod</code>, <code>usefulLifeSource</code> (<code>policy_default | policy_override | asset_override</code>) recorded with reason and operator id when overridden. For <code>Custom</code> methods store <code>methodParams</code> as canonical JSON with stable key ordering. <br> • Component accounting: <code>componentOf</code> pointer to parent <code>assetId</code> and <code>componentRole</code> describing capitalization treatment. Changes to component relationships create immutable <code>assetRevisionId</code> and link to prior snapshots. <br> • Provenance & checksum: <code>rawPayloadRef</code>, <code>assetRowChecksum</code> computed from canonical serialization excluding transient provenance fields. Include <code>createdTs</code>, <code>ingestRunRef</code>, and <code>evidenceRefs</code> in manifest. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>CapexTransactionRow — comprehensive narrative & forensic handling:</strong> <br> • Purpose: canonical representation of AP/Capex evidence for candidate mapping and capitalization decisions. <br> • Deterministic id: <code>capexRowId</code> formed from <code>sourceFingerprint|offset|canonicalTokens</code>. Record generator recipe in manifest. <br> • Amount fields: <code>amount</code> canonical decimal string with <code>amountMinorUnits</code>, <code>scale</code>, <code>signConvention</code>, and <code>originalSignRepresentation</code>. If feed has <code>Debit</code>/<code>Credit</code> columns detect sign convention automatically and persist <code>signConvention</code>. <br> • Candidate mapping: <code>assetIdCandidates[]</code> includes <code>candidateScore</code>, <code>matchSignals[]</code>, <code>candidateRowChecksum</code>. Candidate scoring weights are defined in <code>policySnapshot.matchingWeights</code> and are persisted with the candidate list to ensure reproducible scoring decisions. If many candidates persist them ordered by descending score and deterministic tie-breakers recorded in manifest. <br> • Metadata: <code>vendor</code> canonical token, <code>invoiceRef</code>, <code>poNumber</code>, <code>costCenter</code>, <code>currency</code>. Use vendor dictionary and alias table; record normalization mapping for each vendor to enable audit. <br> • Provenance & checksum: <code>rawPayloadRef</code> and <code>capexRowChecksum</code> computed from canonical serialization. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>DepreciationScheduleRow — comprehensive narrative & forensic handling:</strong> <br> • Purpose: canonical scheduled depreciation entry per period for a given asset revision and policy snapshot. <br> • Deterministic id: <code>scheduleId</code> derived from (<code>assetId|periodStart|periodEnd|policyHash|assetRevisionId</code>) so schedules under different policies remain separate. <br> • Fields saved: <code>preRoundedAmount</code> (high-precision decimal string), <code>depreciationAmount</code> (post-rounding), <code>prorationFactor</code>, <code>roundingScale</code>, <code>residualAbsorbed</code>, <code>accumulatedDepreciationToDate</code>, <code>bookValueEnd</code>, <code>method</code>, <code>methodParams</code>. <br> • Proration: explicitly annotate <code>prorationBasis</code> (<code>days</code>, <code>months</code>, <code>half_month</code>), <code>daysInPeriod</code>, <code>daysCounted</code> to permit forensic verification of proration calculations. <br> • Residual absorption: compute at asset-level and grouping-level per policy; persist <code>residualRationale</code> and <code>residualAbsorbed</code>. Determine deterministic target period via tie-breaker rules and record the tie-break trace. <br> • Provenance: include <code>evidenceRefs[]</code> pointing to <code>assetRowChecksum</code>, <code>capexRowChecksums</code>, and the <code>policyHash</code> used; compute <code>scheduleRowChecksum</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>DisposalRow / RevaluationRow / ImpairmentRow — comprehensive narrative & forensic handling:</strong> <br> • Purpose: event rows carrying mutative events with tax & approval semantics. <br> • Fields: <code>eventId</code>, <code>assetId</code>, <code>eventDate</code>, <code>eventType</code>, <code>proceeds</code> (with <code>proceedsMinorUnits</code> and <code>proceedsCurrency</code>), <code>fxRateRef</code> if cross-currency, <code>adjustedBookValue</code>, <code>gainLossRecognized</code>, <code>taxTreatment</code> object, <code>approvalRef</code>, <code>notes</code>. <br> • Revaluation rows must include <code>revalBasis</code> and <code>revalInputs[]</code> (e.g., appraisals, market index references) and attach evidenceRefs so an independent reviewer can verify the revaluation. <br> • Event immutability: once accepted and applied persist event with <code>eventRowChecksum</code>. Reversions must be handled via <code>RevertJEs</code> flows and produce forensic manifests. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>JE_Line and JE bundle narrative:</strong> <br> • Purpose: JE lines created from schedules and events, grouped into atomic JE bundles for export/posting. <br> • JE line fields: <code>jeLineId</code>, <code>jeId</code>, <code>account</code> (canonical GL account), <code>debitCredit</code>, <code>amount</code>, <code>currency</code>, <code>narrative</code> including <code>assetId</code> for traceability, <code>costCenter</code>, <code>lineSource</code> (scheduleRowId/disposalRowId), <code>confidence</code>. <br> • JE bundle invariants: <code>jeBundle</code> must balance at configured <code>roundingScale</code>. If tiny imbalance arises due to rounding, apply deterministic bundle-level residual absorption and persist <code>residualAbsorbedBy</code>. If imbalance exceeds tolerance fail preview and route for manual remediation. <br> • JE checksum: <code>jeChecksum</code> computed across canonicalized ordered <code>jeLines[]</code> and <code>jeMetadata</code> so loader idempotency is achievable. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Manifests & artifact contracts (concise):</strong> <br> • <code>policySnapshot</code> has <code>policyHash</code>, <code>rulesSummary</code>, <code>author</code>, <code>createdTs</code>. <br> • <code>assetIngestManifest</code> and <code>capexIngestManifest</code> have <code>sourceFingerprint</code>, <code>ingestChecksum</code>, <code>rowsCount</code>, <code>rowsSample</code>, <code>issues[]</code>, <code>loadTs</code>, <code>ingestPolicyMode</code>. <br> • <code>depreciationRunManifest</code> includes <code>runId</code>, <code>runHash</code>, <code>policyHash</code>, <code>assetIngestChecksum</code>, <code>capexIngestChecksum</code>, <code>paramsHash</code>, <code>rowsCount</code>, <code>createdTs</code>, <code>operatorId</code>, <code>canonicalVersion</code>, and <code>changedAssetRevisionIds[]</code> for incremental replays. <br> • <code>previewManifest</code> contains <code>previewHash</code>, <code>includedFiles[]</code>, <code>jePreviewSummary</code>. <br> • <code>exportManifest</code> contains <code>exportChecksum</code>, <code>exportSpecRef</code>, <code>rowsCount</code>, <code>operatorId</code>, <code>createdTs</code>. <br> Manifests must embed the <code>canonicalVersion</code> and <code>hashProvider</code> metadata used to compute artifact checksums. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Canonicalization & hashing recipe (detailed):</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Text normalization recipe:</strong> <br> 1. Apply Unicode NFKC normalization first. <br> 2. Normalize newline characters to single U+0020 or policy-defined token. <br> 3. Trim leading/trailing whitespace when <code>trim=True</code>. <br> 4. Collapse sequences of whitespace characters into single U+0020 if <code>collapseWhitespace=True</code>. <br> 5. Map punctuation per <code>policySnapshot.punctuationMapping</code> (e.g., en-dash → hyphen). <br> 6. Casefold using Unicode casefold table (not <code>LCase</code>) for deterministic cross-locale behavior; require explicit <code>locale</code> for mappings that are locale sensitive such as Turkish dotted/dotless i. <br> 7. Optionally strip diacritics if <code>stripDiacritics=True</code> using deterministic mapping tables while recording <code>diacriticStripArtifact</code> for auditing. <br> 8. Preserve <code>rawField</code> value in evidence. <br> Implementation note: when host platform lacks full unicode APIs provide deterministic fallback tables limited to characters frequently encountered in target corpus; document fallback coverage in manifest. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Numeric canonicalization recipe:</strong> <br> 1. Record <code>sourceCulture</code> and <code>parseAttemptLogs</code> for ambiguous cases. <br> 2. Remove thousand separators if allowed by <code>options</code>. <br> 3. Normalize decimal separator to <code>.</code>. <br> 4. Convert sign variants (Unicode minus) to normal <code>-</code>. <br> 5. Parse to <code>internalPrecision</code> (recommended <code>scale + 6</code> or minimum <code>10</code> decimal places) and compute <code>preRoundedValue</code>. <br> 6. Round using deterministic <code>round-half-to-even</code> unless <code>roundingMode</code> overridden in <code>policySnapshot</code>. <br> 7. Format canonical decimal string with fractional digits zero-padded to <code>scale</code>. <br> 8. Compute <code>amountMinorUnits</code> via exact integer multiplication by 10^scale and persist as integer or string depending on host capacity. <br> 9. Normalize negative zero <code>-0.00</code> → <code>0.00</code>. <br> Edge-case rule: ambiguous parses must be flagged; in <code>tolerant</code> mode persist candidates with confidence scores; in <code>strict</code> mode fail ingest. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Date/time canonicalization recipe:</strong> <br> 1. Use <code>YYYY-MM-DD</code> for date-only fields; for time-of-day use <code>YYYY-MM-DDTHH:MM:SSZ</code> normalized to UTC. <br> 2. If <code>sourceTimezone</code> provided, convert to UTC deterministically; if missing and <code>includeTime=True</code> surface <code>CNV_DATE_TZ_MISSING</code>. <br> 3. Strip or round milliseconds per <code>policySnapshot.roundMilliseconds</code> (round to 3 digits or drop). <br> 4. For proration/day count operations store <code>dayCountBasis</code> and <code>businessDayAdjustments</code> applied. <br> 5. Persist <code>rawDateString</code> and <code>parseAttemptLogs</code> to manifest for forensic debugging. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Serialization & separators recipe:</strong> <br> 1. Each canonical model defines an exact <code>fieldOrder</code> list used for serialization and hashing; <code>fieldOrder</code> must be stored inside the manifest. <br> 2. Use <code>|</code> as the canonical field separator. <br> 3. Escaping: replace any <code>|</code> inside a field with a deterministic escape token (policy default <code>␠PIPE_ESC␠</code>) or backslash-escape with documented rules. Double-escape the escape token if it appears in field content. <br> 4. Do not append trailing newline; ensure canonical string ends exactly after last field content. <br> 5. For lists embed as compact JSON strings with deterministic object key ordering and deterministic element ordering for logically unordered lists via <code>CanonicalizeList</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Hashing & manifest stamping recipe:</strong> <br> 1. Encode the canonical string as UTF-8 and compute SHA-256. <br> 2. Prefix with <code>sha256:</code> and persist into row fields and manifests. <br> 3. Include <code>canonicalVersion</code>, <code>hashProvider</code> (implementation name/version), and <code>fieldOrder</code> mapping in manifests so that anyone can reproduce the hash. <br> 4. If <code>canonicalVersion</code> changes in a way that affects hashing semantics record the change in <code>migrationManifest</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Deterministic tie-breaker recipe:</strong> <br> 1. Primary metric (e.g., highest preRounded absolute amount). <br> 2. Lexicographic smallest <code>assetId</code> or <code>rowId</code>. <br> 3. Deterministic seeded pseudo-random using <code>sha256(runHash | canonicalIdentifiers...)</code> as seed: compute <code>sha256(seedString)</code>, map hex to numeric, modulo number of tied candidates. <br> 4. Persist tie-break trace in manifest to permit replay. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function-level contracts (complete) — exhaustive per-function listings</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — NormalizeText(value, options) → canonicalToken</strong> <br> <strong>Inputs:</strong> <code>value</code> (raw Unicode string), <code>options</code> dictionary keys: <code>form</code> (<code>NFKC</code>), <code>trim</code> (Boolean), <code>collapseWhitespace</code> (Boolean), <code>casefold</code> (Boolean), <code>stripDiacritics</code> (Boolean), <code>normalizePunct</code> (Boolean), <code>punctMappingRef</code> (policy), <code>locale</code> (optional). <br> <strong>Outputs:</strong> <code>canonicalToken</code> (string), side-effect-free, and <code>diagnostics</code> (parseAttemptLogs) available to caller. <br> <strong>Responsibilities:</strong> <br> 1. Apply NFKC normalization. <br> 2. Convert newline sequences to single space or policy token. <br> 3. Trim/collapse whitespace as requested. <br> 4. Casefold using unicode casefold table; if <code>locale</code> impacts result, require <code>locale</code> or emit <code>CNV_TEXT_LOCALE_AMBIGUOUS</code>. <br> 5. Map punctuation per <code>punctMappingRef</code>. <br> 6. When <code>stripDiacritics=True</code> remove diacritics via deterministic mapping; if mapping removes semantic distinctions for <code>locale</code> record <code>CNV_TEXT_DIACRITIC_LOSS</code>. <br> <strong>Invariants:</strong> deterministic outputs given identical inputs and options; do not modify raw evidence. <br> <strong>Failure modes & remediation:</strong> <br> • Unsupported encoding or unpaired surrogate → return <code>&quot;&quot;</code>, emit <code>CNV_TEXT_INVALID</code> and link evidenceRef for remediation. <br> • Locale ambiguity → <code>CNV_TEXT_LOCALE_AMBIGUOUS</code> and require analyst input in strict mode. <br> <strong>Telemetry:</strong> <code>canonical.normalize.text.count</code>, <code>canonical.normalize.text.failures</code>. <br> <strong>CI tests:</strong> full unicode NFKC matrix, punctuation mapping fixtures, Turkish casing tests. <br> <strong>VBA notes:</strong> prefer OS Normalization APIs; fallback mapping tables must be documented and include coverage notes. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — ValidateNumericLocale(rawString, sourceCulture) → diagnostics</strong> <br> <strong>Inputs:</strong> <code>rawString</code>, optional <code>sourceCulture</code>. <br> <strong>Outputs:</strong> <code>diagnostics</code> dictionary containing <code>detectedCulture</code>, <code>candidates[]</code> with <code>{parsedValue, confidence}</code>, <code>warnings[]</code>. <br> <strong>Responsibilities:</strong> <br> 1. Heuristically inspect separators and grouping to produce parse candidates. <br> 2. Provide confidence scores and remediation suggestions for manifest <code>issues[]</code>. <br> <strong>Invariants:</strong> deterministic heuristics; must be stable across runs. <br> <strong>Failure modes & remediation:</strong> too noisy input → tag <code>needsManualReview</code>. <br> <strong>Telemetry:</strong> <code>canonical.validateNumericLocale.ambiguousRate</code>. <br> <strong>CI tests:</strong> ambiguous patterns like <code>1.234</code>, <code>1,234</code>, and <code>1.234,56</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — CanonicalDecimal(rawString, scale, options) → canonicalDecimalString</strong> <br> <strong>Inputs:</strong> <code>rawString</code>, <code>scale</code> integer, <code>options</code> keys: <code>sourceCulture</code>, <code>thousandSeparatorsAllowed</code> (Boolean), <code>normalizeMinusSign</code> (Boolean), <code>internalPrecision</code> optional, <code>roundingMode</code> default <code>round-half-to-even</code>. <br> <strong>Outputs:</strong> <code>canonicalDecimalString</code> (exact <code>scale</code> fractional digits), <code>preRoundedValue</code> (high-precision representation), <code>parseAttemptLogs</code>. <br> <strong>Responsibilities:</strong> <br> 1. Normalize sign and thousand separators per <code>options</code>. <br> 2. Parse using <code>sourceCulture</code> when provided; if ambiguous produce candidates and annotate <code>CNV_NUM_LOCALE_AMBIGUOUS</code>. <br> 3. Convert to high internal precision and compute <code>preRoundedValue</code>. <br> 4. Apply deterministic rounding to <code>scale</code>. <br> 5. Format canonical decimal string with zero-padded fractional digits. <br> <strong>Invariants:</strong> <code>canonicalDecimalString</code> identical across runtimes for same inputs/options/canonicalVersion. <br> <strong>Failure & remediation:</strong> malformed input → <code>CNV_NUM_PARSEERROR</code>; overflow → <code>CNV_NUM_OVERFLOW</code> with remediation to split or escalate. <br> <strong>Telemetry:</strong> <code>canonical.decimal.parsed</code>, <code>canonical.decimal.parseFailures</code>. <br> <strong>CI tests:</strong> locale permutations, negative zero normalization, rounding parity. <br> <strong>VBA notes:</strong> prefer <code>Decimal</code> variant or string-based arithmetic to preserve parity. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — ParseDecimalToMinorUnits(canonicalDecimal, scale) → amountMinorUnits (string)</strong> <br> <strong>Inputs:</strong> canonicalDecimal string with exactly <code>scale</code> fractional digits, scale integer. <br> <strong>Outputs:</strong> <code>amountMinorUnits</code> string to avoid overflow on hosts that lack 64-bit integers. <br> <strong>Responsibilities:</strong> exact integer multiplication via string arithmetic to avoid floating errors. <br> <strong>Invariants:</strong> reversible to canonicalDecimal by dividing by 10^scale and zero-padding fraction. <br> <strong>Failure & remediation:</strong> arithmetic overflow handled by string output; document representation in manifest. <br> <strong>CI tests:</strong> boundary around 64-bit limits, negative values. <br> <strong>VBA notes:</strong> implement as string multiply helper or call big-int helper when available. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — FormatDateISO(rawDate, options) → canonicalDateString</strong> <br> <strong>Inputs:</strong> <code>rawDate</code>, <code>options</code> keys: <code>includeTime</code> (Boolean), <code>sourceCulture</code>, <code>sourceTimezone</code>, <code>roundMilliseconds</code> (Boolean), <code>dayCountBasis</code> (policy). <br> <strong>Outputs:</strong> canonical date string <code>YYYY-MM-DD</code> or <code>YYYY-MM-DDTHH:MM:SSZ</code>, <code>parseAttemptLogs</code>. <br> <strong>Responsibilities:</strong> deterministic parsing, timezone normalization to UTC when time exists, and capture ambiguous parse diagnostics. <br> <strong>Invariants:</strong> canonical date identical across runs given same inputs/options/canonicalVersion. <br> <strong>Failure & remediation:</strong> ambiguous parse → <code>CNV_DATE_AMBIGUOUS</code>. For missing timezone when required → <code>CNV_DATE_TZ_MISSING</code>. <br> <strong>Telemetry:</strong> <code>canonical.date.parseFailures</code>. <br> <strong>CI tests:</strong> day/month ambiguity, DST boundaries. <br> <strong>VBA notes:</strong> avoid <code>CDate</code> on ambiguous strings; parse via explicit regex and DateSerial; defer complex timezone conversions to backend if environment lacks TZ library. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — EscapeFieldSeparators(fieldValue, separator) → escapedFieldValue</strong> <br> <strong>Inputs:</strong> <code>fieldValue</code> string and <code>separator</code> string (default <code>|</code>). <br> <strong>Outputs:</strong> <code>escapedFieldValue</code>. <br> <strong>Responsibilities:</strong> deterministically escape any separator occurrences and chosen escape token occurrences by double-escaping if necessary. Policy must choose escape token (e.g., <code>␠PIPE_ESC␠</code>) and document it in <code>canonicalVersion</code>. <br> <strong>Invariants:</strong> escaping must be reversible if policy allows un-escaping. <br> <strong>Failure & remediation:</strong> if field includes escape token sequence and conflicting patterns occur, use double-escape protocol and persist explanation in manifest. <br> <strong>CI tests:</strong> nested separator and escape tokens. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — CanonicalizeList(values, elementOptions, sortDeterministic) → compactJsonString</strong> <br> <strong>Inputs:</strong> <code>values</code> (array/list), <code>elementOptions</code> controlling per-element canonicalization, <code>sortDeterministic</code> boolean for logically unordered sets. <br> <strong>Outputs:</strong> compact JSON string with deterministic ordering & escaping. <br> <strong>Responsibilities:</strong> canonicalize each element via <code>NormalizeText</code> or <code>CanonicalDecimal</code>, sort when requested by deterministic comparator (primary canonical element string, secondary original index), and serialize with deterministic object key ordering. <br> <strong>Invariants:</strong> logically unordered input sets produce stable output across runs. <br> <strong>Failure & remediation:</strong> nested complex objects not supported must be flattened upstream. <br> <strong>CI tests:</strong> permutations yield identical output. <br> <strong>VBA notes:</strong> implement stable sort and JSON serializer that strictly controls whitespace and key ordering. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — SerializeCanonicalRow(rowDict, fieldOrder, options) → canonicalString</strong> <br> <strong>Inputs:</strong> <code>rowDict</code> mapping fieldName→canonicalValue (strings), <code>fieldOrder</code> deterministic collection, <code>options</code> keys: <code>separator</code> (<code>|</code>), <code>escapePolicy</code>. <br> <strong>Outputs:</strong> <code>canonicalString</code> used for hashing (post UTF-8 encoding). <br> <strong>Responsibilities:</strong> <br> 1. Enforce exact <code>fieldOrder</code> and omit transient provenance fields. <br> 2. For missing optional fields add empty tokens to preserve position. <br> 3. Escape fields and embed arrays via <code>CanonicalizeList</code>. <br> 4. Join with single <code>separator</code> and ensure no trailing newline or whitespace. <br> <strong>Invariants:</strong> byte-identical canonicalString across runtimes given same inputs/options/canonicalVersion. <br> <strong>Failure & remediation:</strong> missing required field triggers <code>SERIAL_MISSING_FIELD</code>—strict mode fails ingest, tolerant mode persists issue. <br> <strong>Telemetry:</strong> <code>canonical.serialize.rows</code>, <code>canonical.serialize.failures</code>. <br> <strong>CI tests:</strong> field order parity, escaping, embedded JSON parity. <br> <strong>VBA notes:</strong> build token array and <code>Join</code> for performance and convert to UTF-8 explicitly before hashing. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — ComputeSHA256(canonicalString) → 'sha256:<hex>'</strong> <br> <strong>Inputs:</strong> <code>canonicalString</code> (string). <br> <strong>Outputs:</strong> <code>sha256:&lt;hex&gt;</code> lower-case. <br> <strong>Responsibilities:</strong> deterministic UTF-8 encoding then SHA-256 hex encoding; return prefixed string. <br> <strong>Invariants:</strong> identical bytes → identical hash across platforms; manifest must include <code>hashProvider</code> metadata. <br> <strong>Failure & remediation:</strong> missing crypto provider <code>HASH_PROVIDER_MISSING</code> — remediate by bundling portable SHA-256 implementation or using OS crypto API. <br> <strong>Telemetry:</strong> <code>canonical.hash.count</code>, <code>canonical.hash.error</code>. <br> <strong>CI tests:</strong> RFC test vectors and hex normalization. <br> <strong>VBA notes:</strong> use OS CryptoAPI wrappers or a vetted portable SHA-256 helper; ensure proper UTF-8 byte conversion (ADODB.Stream trick or byte-array helper). </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — HashWithPrefix(entityType, canonicalString, manifestContext) → 'sha256:<hex>' (plus manifest side-effect)</strong> <br> <strong>Inputs:</strong> <code>entityType</code> (string), <code>canonicalString</code>, <code>manifestContext</code> dictionary to annotate. <br> <strong>Outputs:</strong> <code>sha256:&lt;hex&gt;</code> and manifestContext updated. <br> <strong>Responsibilities:</strong> compute <code>sha256</code> and update <code>manifestContext</code> with <code>entityType</code>, <code>fieldOrder</code> used, <code>canonicalVersion</code>, and <code>hashProvider</code>. Persist manifestContext together with artifact. <br> <strong>Invariants:</strong> manifestContext must enable independent replay of hashing. <br> <strong>CI tests:</strong> verify manifest stamping and parity across hosts. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — GetCanonicalVersion() and ManifestStamper(manifest) → stampedManifest</strong> <br> <strong>Purpose:</strong> centralize canonical version and ensure manifests are stamped consistently. <br> <strong>Responsibilities:</strong> <br> 1. Return semantic <code>canonicalVersion</code> string used by the organization. <br> 2. <code>ManifestStamper</code> injects <code>canonicalVersion</code>, <code>toolVersion</code>, <code>platformFingerprint</code> and returns deterministically ordered canonical manifest string for hashing. <br> <strong>Invariants:</strong> any change to <code>canonicalVersion</code> that affects hashing must be accompanied by <code>migrationManifest</code>. <br> <strong>CI tests:</strong> manifest stamping parity. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Function — DeterministicTieBreaker(primaryMetric, candidates, seedContext) → selectedCandidate and tieTrace</strong> <br> <strong>Inputs:</strong> <code>primaryMetric</code>, <code>candidates</code> collection, <code>seedContext</code> (string). <br> <strong>Outputs:</strong> selected candidate (stable) and <code>tieTrace</code> describing decision steps. <br> <strong>Responsibilities & tie-break order:</strong> <br> 1. Highest primary metric chosen. <br> 2. If tie, lexicographic smallest canonical id (assetId/rowId). <br> 3. If still tied, compute seeded deterministic pseudo-random selection using <code>sha256(seedContext | concatenatedCandidateIds)</code> mapping to index. <br> 4. Record <code>tieTrace</code> in manifest to enable replay. <br> <strong>Invariants:</strong> deterministic selection reproducible with same <code>seedContext</code>. <br> <strong>CI tests:</strong> tie permutations produce same selection and tieTrace across runs. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Module-level diagnostics & error codes (exhaustive table concept):</strong> <br> • <code>CNV_TEXT_INVALID</code> — encoding/invalid Unicode detected; remediation: re-encode source to UTF-8. <br> • <code>CNV_TEXT_LOCALE_AMBIGUOUS</code> — locale-sensitive text mapping ambiguous; remediation: specify <code>locale</code> or confirm mapping. <br> • <code>CNV_TEXT_DIACRITIC_LOSS</code> — diacritic strip removes meaning; remediation: require <code>stripDiacritics=False</code> or manual review. <br> • <code>CNV_NUM_LOCALE_AMBIGUOUS</code> — numeric parse ambiguous; remediation: set <code>sourceCulture</code> or manual review for high-value rows. <br> • <code>CNV_NUM_OVERFLOW</code> — numeric value exceeds host type; remediation: use string minor units or big-int helper. <br> • <code>CNV_DATE_PARSE_ERROR</code> — date unparseable; remediation: provide normalized date or fix source. <br> • <code>CNV_DATE_TZ_MISSING</code> — timezone missing when time-of-day required; remediation: provide timezone or treat per policy fallback. <br> • <code>SERIAL_MISSING_FIELD</code> — required field missing; remediation: map header synonyms or correct source. <br> • <code>SER_ESCAPING_ERROR</code> — escape token conflict detected; remediation: change escape token or double-escape logic. <br> • <code>HASH_PROVIDER_MISSING</code> — crypto provider missing; remediation: deploy portable SHA-256 helper or use server-side hashing step. <br> Each code maps to a remediation snippet recorded in manifest so operator can follow runbook steps. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Observability & telemetry contract (module-level):</strong> <br> 1. All functions accept and propagate <code>correlationId</code>. <br> 2. Emit namespaced counters and histograms under <code>canonical.*</code> (examples: <code>canonical.normalize.text.count</code>, <code>canonical.decimal.parseFailures</code>, <code>canonical.serialize.latencyMs</code>). <br> 3. Telemetry must never include raw PII; include hashed fingerprints only. <br> 4. Include <code>runId</code>, <code>policyHash</code>, <code>ingestChecksum</code>, <code>operatorId</code>, and <code>environment</code> as telemetry tags to support triage. <br> 5. Daily parity verification job to recompute <code>runHash</code> for recent artifacts and emit <code>verify.parity.failed</code> when mismatches appear. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Testing & CI/golden parity strategy (exhaustive):</strong> <br> 1. Unit tests must cover Unicode NFKC normalization, punctuation mapping, diacritic stripping, casefolding (including Turkish), and edge-case punctuation. <br> 2. Unit tests for numeric parsing must cover 50+ locale permutations, grouping variations, negative zero, banker's rounding, overflow, and scale preservation. <br> 3. Unit tests for date parsing must cover ambiguous formats, DST boundary transitions, and timezone normalization. <br> 4. Unit tests for serialization must cover field-order invariance, escaping, and canonical JSON for lists. <br> 5. Integration tests: ingest→canonicalize→serialize→hash pipelines producing exact expected row and manifest checksums for canonical fixtures. <br> 6. Golden parity tests: maintain canonical fixtures with expected <code>sha256:</code> values for <code>assetRow</code>, <code>capexRow</code>, <code>scheduleRow</code>, and manifests per <code>canonicalVersion</code>. CI must run parity across PQ pilot, VBA host, and backend; mismatches block merges. <br> 7. Property tests: ordering independence; header synonym invariance; idempotence of repeated canonicalization. <br> 8. Performance tests: streaming ingest throughput for 1k, 10k, 100k assets; PQ preview latency for typical sample sizes; hashing throughput per core. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Power Query (PQ) conceptual pilot guidance (detailed, no snippets):</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>When PQ is appropriate:</strong> <br> 1. Analyst-driven previews for small cohorts (< 5k rows depending on transformation complexity). <br> 2. Rapid parity checks with backend before production promotion. <br> 3. Early-stage mapping debugging, vendor alias cleanup, header synonym exploration, and generating <code>previewArtifact</code> for analyst acceptance. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>PQ architected pattern (conceptual):</strong> <br> 1. Parameterize key variables: <code>headerSynonyms</code>, <code>decimalLocaleMap</code>, <code>policySnapshotRef</code>, and <code>canonicalVersion</code>. <br> 2. Build modular queries: <code>Source → Staging → NormalizeTextStep → NumericParseStep → DateParseStep → SerializeStep → PreviewPackageStep</code>. Each step exposes a table for inspection to facilitate parity debugging. <br> 3. For <code>policySnapshot</code> store policy as a parameterized table in PQ with deterministic sorting and compute a local <code>policyHash</code> string for preview manifests. <br> 4. Capture <code>preview_manifest</code> and compute <code>previewHash</code> via deterministic serialization in PQ; if host hashing not available, delegate final parity hash to backend job. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>PQ canonicalization conceptual recipe & limitations:</strong> <br> 1. Text normalization: use <code>Text.Normalize</code> if available; otherwise use deterministic mapping tables for diacritics and punctuation. <br> 2. Numeric parsing: pre-clean separators and ensure decimal separator is <code>.</code>, then use <code>Number.FromText</code> with explicit culture. Represent high-precision <code>preRoundedValue</code> as string when PQ lacks precision. <br> 3. Date parsing: use explicit format parsing and capture parse failures into <code>issues[]</code>. <br> 4. Anti-patterns & mitigations: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. Per-row custom functions causing slow PQ runs — prefer table-based transforms. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. Relying on PQ floating-point precision for high internalPrecision — instead store preRounded strings and validate against backend. <br> &nbsp;&nbsp;&nbsp;&nbsp;c. Using ad-hoc hashing functions — compute canonical strings in PQ and have backend compute authoritative <code>runHash</code> to avoid host inconsistencies. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>PQ parity verification conceptual flow:</strong> <br> 1. PQ run produces <code>preview_manifest</code> and <code>previewHash</code>; backend parity job replays the same canonicalization on same raw inputs and asserts <code>runHash</code> and <code>previewHash</code>. <br> 2. If parity fails capture intermediate step diffs (NormalizeText output, numeric preRounded values, serialized canonicalString) to isolate divergence. <br> 3. PQ pilot must maintain a small canonical fixture suite in CI to catch regressions early. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Conceptual DAX reporting patterns (no DAX snippets):</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Modeling principles:</strong> <br> 1. Use canonical keys (<code>assetId</code>, <code>policyHash</code>, <code>runId</code>, <code>scheduleRowChecksum</code>) as grain keys for relationships. <br> 2. Avoid raw PII in visuals: use tokenized IDs and evidenceRef drillthrough; evidence retrieval must be approval-gated. <br> 3. Include <code>policyHash</code> and <code>canonicalVersion</code> as slicers to permit forensic comparisons across policy changes. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Core measures (conceptual descriptions):</strong> <br> 1. <code>DepreciationExpense</code>: aggregate <code>depreciationAmount</code> filtered by period and category. <br> 2. <code>AccumulatedDepreciation</code>: running total of <code>accumulatedDepreciationToDate</code>. <br> 3. <code>NetBookValue</code>: <code>SUM(bookValueEnd)</code> used for control account reconciliation. <br> 4. <code>FA_ReconVariance</code>: <code>SUBLEDGER_ACCUM - GL_ACCUM</code> per control GL account and cost center. <br> 5. <code>BeyondToleranceFlag</code>: materiality logic using absolute threshold if GLAmount = 0 else relative percent threshold. <br> 6. <code>OpenManualActions</code>: count of schedule rows flagged <code>requiresManualInput = True</code>. <br> 7. <code>RunParityDeltaCount</code>: count of rows with differing <code>scheduleRowChecksum</code> between two <code>runId</code>s to detect policy migration impact. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Operational visuals & drillthrough patterns (conceptual):</strong> <br> 1. Trend chart: <code>DepreciationExpense</code> by month stacked by <code>category</code>; include markers showing <code>policyHash</code> promotions and canary runs. <br> 2. Matrix: <code>controlGLAccount</code> × <code>costCenter</code> with variance cells colored by <code>BeyondToleranceFlag</code>; include slicers for <code>policyHash</code>, <code>period</code>, <code>runId</code>. <br> 3. Exception drillthrough: from variance row open detail page showing sample schedule rows, related <code>previewArtifact</code> entries, linked <code>evidenceRefs</code>, and an <code>approvalRequest</code> CTA that auto-populates a standard evidence retrieval manifest. <br> 4. KPI card: <code>SuggestionAcceptanceRate</code> for analyst adoption of suggested JEs over time. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Failure modes, mitigation & operator runbooks (expanded and actionable)</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Case: CNV_NUM_LOCALE_AMBIGUOUS widespread</strong> <br> 1. Symptom: ingest manifest shows large number of <code>CNV_NUM_LOCALE_AMBIGUOUS</code> flagged rows; <code>candidateParses</code> present. <br> 2. Immediate triage: capture <code>correlationId</code> and retrieve <code>capexIngestManifest</code> sample evidenceRefs. <br> 3. Quick remediation steps: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. If vendor-specific pattern emerges, apply <code>sourceCulture</code> override per vendor and re-run only flagged rows in streaming mode; persist <code>correctionOf</code> to link to original <code>sourceFingerprint</code>. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. If source can be corrected, request corrected feed including <code>culture</code> metadata; re-ingest. <br> &nbsp;&nbsp;&nbsp;&nbsp;c. For small-high value ambiguous items route to analyst review queue with <code>parseAttemptLogs</code> and <code>candidateParses</code>. <br> 4. Long-term mitigation: enforce producer-level standards to include explicit culture formatting or decimal normalization at source. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Case: HASH_PROVIDER_MISSING on PQ host</strong> <br> 1. Symptom: hashing fails in PQ preview due to missing crypto provider. <br> 2. Triage: check PQ host capability and <code>platformFingerprint</code>. <br> 3. Remediation: deploy portable SHA-256 helper (small script or COM helper) or compute previewHash on backend; stamp manifest with <code>hashProvider</code> and <code>computedBy</code> fields. <br> 4. Preventative: include hashed helper in PQ pilot environment pre-reqs and test during PQ CI. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Case: SERIAL_MISSING_FIELD due to header drift</strong> <br> 1. Symptom: <code>SerializeCanonicalRow</code> fails because required field absent due to changed header labels. <br> 2. Triage: inspect <code>assetIngestManifest.headerMap</code> and sample raw rows. <br> 3. Remediation steps: <br> &nbsp;&nbsp;&nbsp;&nbsp;a. Update <code>headerSynonyms</code> mapping and rerun ingest for affected sourceFingerprint using streaming corrections. <br> &nbsp;&nbsp;&nbsp;&nbsp;b. If source recurrently changes headers, create a pre-ingest validation job that raises <code>preflight</code> errors to source owner. <br> 4. Preventative: policy that producers must adhere to agreed schema or include header synonyms with regularized header mapping fed into ingest config. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Detailed worked forensic examples (very extended)</strong> </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Example 1 — Multi-invoice capital addition & component creation (deep forensic narrative):</strong> <br> 1. Two invoices (INV-A $12,500 and INV-B $2,200) map to a chassis and accessory module respectively. INV-B description includes <code>assetTag</code> matching existing <code>AS-000789</code>. <br> 2. <code>LoadCapexTransactions</code> creates <code>capexRow</code> canonical rows with <code>capexRowChecksum</code> and applies <code>FindAssetCandidates</code> which produces <code>assetIdCandidates</code> with scores and <code>matchSignals</code>. All mapping weights used are recorded in <code>policySnapshot.matchingWeights</code>. <br> 3. <code>ComputeDepreciationRun</code> applies <code>componentPolicy</code> and deterministically creates <code>component</code> asset row for accessory with <code>componentOf=AS-000789</code> and computes <code>assetRevisionId = sha256(assetRowChecksum|capexRowChecksum|decisionTsCanonical)</code>. Document <code>additionTreatment</code> = <code>create_component</code>. <br> 4. Recompute parent and child schedules with preserved historical schedules; each new schedule row gets <code>scheduleRowChecksum</code>. Persist <code>depreciationRunManifest</code> capturing decisions and <code>runHash</code>. <br> 5. <code>GenerateDepreciationJE</code> groups schedules per <code>jeTemplateSpec</code> and includes component breakout lines referencing <code>componentOf</code>. <br> 6. Analysts review <code>fa_preview_&lt;runId&gt;_&lt;previewHash&gt;.zip</code>, accept JE suggestions; <code>GenerateJEExport</code> writes <code>FA_JE_Export_&lt;runId&gt;_&lt;exportChecksum&gt;.csv</code>. <code>ApplyCorrections</code> enforces two-person approval due to combined posting thresholds; <code>applyDescriptor</code> persisted prior to post. Audit chain includes <code>evidenceRefs</code> linking invoices, <code>assetIngestManifest</code>, <code>capexIngestManifest</code>, and <code>depreciationRunManifest</code>. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Example 2 — Disposal mid-period cross-currency (deep forensic narrative):</strong> <br> 1. Disposal event for asset <code>AS-000456</code> on <code>2026-07-15</code> with proceeds €2,200. Book currency is USD; NBV at disposal date $1,900. <br> 2. <code>policySnapshot</code> references <code>fxRates_20260715</code> providing EUR→USD 1.0833; <code>ComputeDepreciationRun</code> uses <code>fxRateRef</code> to convert proceeds precisely into USD minor units, storing both <code>preRoundedProceedsUSD</code> and rounded results per <code>roundingScale</code>. <br> 3. <code>gainLossRecognized</code> computed deterministically as <code>proceedsUSD - NBV</code> after correct rounding. <code>DisposalRow</code> includes <code>proceedsMinorUnits</code>, <code>fxRateRef</code>, <code>eventRowChecksum</code> and <code>approvalRef</code> if policy threshold breached. <br> 4. JE suggestions generated with <code>evidenceRefs</code> linking to disposal event and <code>depreciationRunManifest</code>; if approvals missing JE cannot be applied and is flagged in preview. <br> 5. If disposal required proration of depreciation to disposal date, <code>ComputeDepreciationRun</code> creates a partial period schedule row with <code>prorationFactor</code>, <code>daysInPeriod</code>, <code>daysCounted</code> and <code>residualAbsorbed</code> adjustments recorded and hashed. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Example 3 — Large-batch rounding pathology & group residual absorption (deep forensic narrative):</strong> <br> 1. Fleet of assets each with recurring fractional monthly amounts creates per-asset residuals summing to significant group-level residual across cost center. <br> 2. Policy may require group-level absorption to zero aggregate residual per <code>costCenter</code> before JE generation. <code>ComputeDepreciationRun</code> computes residual per asset, aggregates group residuals, and applies deterministic absorption rules at group-level (choose absorb target asset by highest preRounded amount within group; if tie use assetId lexicographic order; if still tie use seeded deterministic pseudo-random derived from <code>runHash</code>). <br> 3. Persist per-asset <code>residualAbsorbed</code> and group-level <code>residualSummary</code> in manifest. Auditors can trace exactly which assets received absorption and why via <code>residualRationale</code> and tieTrace data. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Example 4 — Units-of-Production missing usage metrics (deep forensic narrative):</strong> <br> 1. Asset uses <code>UnitsOfProduction</code> method expecting <code>totalExpectedUsage</code>. Usage for current period missing. <br> 2. <code>ComputeDepreciationRun</code> flags schedule rows as <code>requiresManualInput</code> and emits <code>fa.depn.run.requires_manual_input</code> with examples and <code>requiresManualInputCount</code>. <br> 3. Analysts collect usage via asset telemetry or manual entries, annotate asset revision with <code>manualInputs</code> and <code>inputBy</code> metadata, then re-run <code>ComputeDepreciationRun</code> for affected <code>assetRevisionId</code> subset. The manifest records the delta and <code>runHash</code> for the corrected run. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Production readiness & acceptance checklist (explicit):</strong> <br> 1. Unit tests covering the full unicode normalization and numeric parsing matrix executed across target runtimes. <br> 2. Golden fixtures with canonicalString & <code>sha256:</code> values included in CI for each <code>canonicalVersion</code>. <br> 3. Manifest stamping and <code>hashProvider</code> metadata validated in CI across PQ pilot, VBA host, and backend. <br> 4. Error codes and runbooks published and linked in ingest UI. <br> 5. Telemetry and parity verification job scheduled and tested (daily run). <br> 6. Migration governance checklist and template <code>migrationManifest</code> in place for canonical changes. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Deployment & VBA compatibility notes (practical):</strong> <br> 1. Provide pure-VBA deterministic fallbacks for small PQ pilot runs: minimal NFKC mapping tables, deterministic casefold maps, simple string-based decimal arithmetic, and an included portable SHA-256 helper COM for hosts lacking OS crypto. <br> 2. For enterprise/scale runs prefer platform APIs (NormalizeString, BCrypt) wrapped by small helpers callable from VBA to preserve parity. <br> 3. Document platform fingerprint requirements and list exact helper components required for parity (normalization helper, big-int helper, hash helper). <br> 4. Include a test harness that runs canonicalization for sample rows and compares produced <code>sha256:</code> values to golden fixtures to validate environment parity. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Next artifacts available on demand (select from below):</strong> <br> 1. Formal JSON Schema for canonical models (<code>AssetRow</code>, <code>CapexTransactionRow</code>, <code>DepreciationScheduleRow</code>, <code>applyDescriptor</code>, <code>recon_report</code>) including exact <code>fieldOrder</code> used for hashing. <br> 2. Golden fixture package: canonical CSVs + expected <code>sha256:</code> values for immediate CI inclusion. <br> 3. Power Query pilot cookbook: parameterized query recipe with intermediate step expectations for parity debugging. <br> 4. Compact runbook PDF summarizing triage commands and operator CLI examples. <br> Choose which artifact(s) you want and the preferred output format; they will be produced next. </td></tr><tr><td data-label="modCanonical — Per-function Expert Technical Breakdown"> <strong>Final operational note (concise):</strong> <code>modCanonical</code> is the determinism backbone. Implement as a small, well-tested, and versioned library. Maintain <code>canonicalVersion</code> discipline, keep golden fixtures in CI, require migration governance for semantic changes, and instrument telemetry and parity verification to detect regressions early. </td></tr></tbody></table></div><div class="row-count">Rows: 56</div></div><script src="assets/xlsx.full.min.js?v=1758605028" defer></script>
<script src="assets/script.js?v=1759748863" defer></script>
<script src="assets/worker.js?v=1758331710" defer></script>
<script>
(function(){
  const template = "{table}_{date}";
  const userVal = "";
  const hrefPrefix = "assets";
  function formatName(tableName) {
    const date = (new Date()).toISOString().slice(0,10);
    return template.replace('{table}', tableName).replace('{date}', date).replace('{user}', userVal);
  }
  const btn = document.getElementById('exportBtn');
  if(btn) {
    btn.addEventListener('click', async function() {
      try {
        const html = document.documentElement.outerHTML;
        if(html.length > 2000000) { alert('Export refused: html too large'); return; }
        if(window.Worker) {
          const workerUrl = (function(){ try{ return hrefPrefix + '/worker.js'; }catch(e){ return null; } })();
          if(workerUrl) {
            try {
              const worker = new Worker(workerUrl);
              worker.postMessage({html: html, format: 'pdf'});
              worker.onmessage = function(e) { console.log('worker:', e.data); alert('Worker replied: '+(e.data.msg||e.data.status)); };
            } catch(err) { console.warn('Worker create failed', err); alert('Worker not available'); }
          } else { alert('Worker not available'); }
        } else { alert('Export worker not supported in this environment.'); }
      } catch(err) { console.warn('Export failed', err); alert('Export worker not available. See console for details.'); }
    });
  }
})();
window.addEventListener('load', function(){ try{ document.querySelectorAll('.table-wrapper').forEach(function(e){ e.style.opacity='1'; }); }catch(e){} });
</script>
</div>
</body>
</html>